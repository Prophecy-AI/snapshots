# Seed Prompt: Aerial Cactus Identification

## Problem Type
Binary image classification (aerial imagery) with AUC evaluation metric. Images are 32x32 RGB thumbnails.

**Reference notebooks for data characteristics:**
- `eda.ipynb` - Contains full EDA: class distribution (~75% positive), image dimensions (32x32 RGB), sample visualizations

## Model Architectures

### Primary Approaches for Small 32x32 Images
For small-resolution image classification, winning Kaggle solutions typically use:
- **ResNet-18/34**: Well-suited for small images when trained from scratch or fine-tuned
- **Wide-ResNet**: Provides better performance on small datasets through increased width rather than depth
- **EfficientNet-B0**: Good balance of accuracy and efficiency for small images
- **Custom CNNs**: Simple architectures with 4-6 convolutional layers often work well for 32x32 images

### Aerial/Satellite Imagery Specific
For aerial imagery competitions, successful approaches include:
- **Encoder-decoder architectures**: U-Net style architectures can be effective even for classification
- **Multiscale processing**: Process images at multiple scales to capture different levels of detail
- **Spectral-aware models**: Since these are RGB aerial images, standard CNNs work well

## Data Augmentation Strategies

### Essential for Small Images
Heavy augmentation is critical for 32x32 images to prevent overfitting:
- **Geometric transforms**: Random rotations (±15°), horizontal/vertical flips, random crops
- **Color augmentation**: Color jitter, brightness/contrast adjustments, hue shifts
- **Advanced techniques**: CutMix, MixUp, Random Erasing
- **Test-time augmentation (TTA)**: Multi-scale and flip averaging during inference

### Class-Aware Augmentation
Given the class imbalance (~75% positive):
- Apply more aggressive augmentation to minority class (no cactus)
- Use class-balanced sampling in data loaders
- Consider oversampling minority class during training

## Handling Class Imbalance

### Effective Techniques
For the ~75%/25% class distribution:
1. **Loss weighting**: Assign higher weights to minority class samples
2. **Label smoothing**: Apply 0.1 smoothing to reduce overconfidence on dominant class
3. **Batch composition**: Ensure minority class appears frequently in each batch
4. **Focal Loss**: Consider for hard example mining
5. **Class-balanced sampling**: Oversample minority class or undersample majority class

### Validation Strategy
- Use stratified splits to maintain class distribution
- Monitor both AUC and per-class metrics
- Early stopping based on validation AUC

## Training Strategies

### Optimization
- **Optimizer**: AdamW or SGD with momentum (0.9)
- **Learning rate**: Start with 1e-3 (Adam) or 1e-1 (SGD), use cosine annealing with warm-up
- **Batch size**: 32-128 (smaller batches may help with class imbalance)
- **Weight decay**: 1e-4 to 1e-2 for regularization

### Regularization
- **Dropout**: 0.2-0.5 in fully connected layers
- **Weight decay**: Essential for small datasets
- **Early stopping**: Monitor validation AUC
- **Stochastic Weight Averaging (SWA)**: Often improves generalization

## Ensembling

### Model Ensembling Strategies
- **Diverse architectures**: Combine ResNet, EfficientNet, and custom CNNs
- **Snapshot ensembling**: Use multiple checkpoints from same training run
- **Test-time augmentation**: Average predictions across multiple augmentations
- **Weighted averaging**: Weight models by validation performance

### Recommended Ensemble Size
- 3-5 models typically sufficient for small datasets
- Focus on diversity rather than quantity
- Consider both architecture diversity and training seed diversity

## Preprocessing

### Image Normalization
- Standard ImageNet normalization works well
- Consider dataset-specific normalization if time permits
- Ensure consistent preprocessing between train and test

### Data Loading
- Use efficient data loading (PyTorch DataLoader with multiple workers)
- Cache decoded images if memory permits
- Consider prefetching for faster training

## Validation Strategy

### Cross-Validation
- **Stratified K-Fold (k=5)**: Maintain class distribution in each fold
- **Hold-out validation**: 80/20 split if computational resources limited
- **Multiple seeds**: Run experiments with different random seeds

### Performance Monitoring
- **Primary metric**: AUC (as per competition)
- **Secondary metrics**: Accuracy, precision, recall, F1
- **Per-class performance**: Ensure good performance on minority class

## Implementation Notes

### Framework Recommendations
- **PyTorch**: Flexible and widely used in Kaggle competitions
- **PyTorch Lightning**: Provides reproducible training loops and best practices
- **Mixed precision**: Use for faster training (FP16)

### Computational Efficiency
- Use progressive resizing if training from scratch
- Consider knowledge distillation for model compression
- Use gradient accumulation for large effective batch sizes

## Competition-Specific Considerations

### Kernels-Only Competition
- Optimize for inference speed and memory usage
- Consider model size limitations
- Use efficient architectures that balance accuracy and speed
- Pre-compute features if possible within kernel constraints

### Aerial Imagery Characteristics
- Cacti may appear at various orientations → use rotation augmentation
- Lighting variations → use color augmentation
- Small objects in 32x32 images → ensure model can capture fine details
- Potential for similar backgrounds → focus on discriminative features

## Key Success Factors
1. **Strong augmentation pipeline**: Critical for small images
2. **Class imbalance handling**: Important for optimal AUC
3. **Model ensembling**: 3-5 diverse models
4. **Test-time augmentation**: Often provides 1-2% boost
5. **Careful validation**: Stratified splits, monitor AUC closely
6. **Regularization**: Essential for small dataset