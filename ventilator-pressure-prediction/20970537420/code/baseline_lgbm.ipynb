{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec1f98d",
   "metadata": {},
   "source": [
    "# Ventilator Pressure Prediction - Baseline Model\n",
    "\n",
    "This notebook implements a baseline LightGBM model for predicting ventilator pressure.\n",
    "\n",
    "## Approach\n",
    "- Use LightGBM with time series features\n",
    "- Basic feature engineering: lags, rolling statistics\n",
    "- 5-fold time series cross-validation\n",
    "- Predict pressure for each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eeb0873",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T20:19:55.995434Z",
     "iopub.status.busy": "2026-01-13T20:19:55.994875Z",
     "iopub.status.idle": "2026-01-13T20:19:57.036228Z",
     "shell.execute_reply": "2026-01-13T20:19:57.035639Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab55245",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78da412f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T20:19:57.038595Z",
     "iopub.status.busy": "2026-01-13T20:19:57.038297Z",
     "iopub.status.idle": "2026-01-13T20:20:00.902080Z",
     "shell.execute_reply": "2026-01-13T20:20:00.901554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (5432400, 8)\n",
      "Test data shape: (603600, 7)\n",
      "Training columns: ['id', 'breath_id', 'R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']\n",
      "Test columns: ['id', 'breath_id', 'R', 'C', 'time_step', 'u_in', 'u_out']\n",
      "\n",
      "Training data info:\n",
      "   id  breath_id  R   C  time_step      u_in  u_out  pressure\n",
      "0   1      85053  5  10   0.000000  4.174419      0  6.118700\n",
      "1   2      85053  5  10   0.033812  7.050149      0  5.907794\n",
      "2   3      85053  5  10   0.067497  7.564931      0  7.313837\n",
      "3   4      85053  5  10   0.101394  8.103306      0  8.227765\n",
      "4   5      85053  5  10   0.135344  8.502619      0  9.422901\n",
      "\n",
      "Unique breaths in train: 67905\n",
      "Unique breaths in test: 7545\n"
     ]
    }
   ],
   "source": [
    "# Load training and test data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Training columns: {train_df.columns.tolist()}\")\n",
    "print(f\"Test columns: {test_df.columns.tolist()}\")\n",
    "\n",
    "# Display basic info about the data\n",
    "print(\"\\nTraining data info:\")\n",
    "print(train_df.head())\n",
    "print(f\"\\nUnique breaths in train: {train_df['breath_id'].nunique()}\")\n",
    "print(f\"Unique breaths in test: {test_df['breath_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23146b6e",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Create basic time series features:\n",
    "- Lag features (previous pressure values)\n",
    "- Rolling statistics\n",
    "- Interaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, is_train=True):\n",
    "    \"\"\"Create features for the model\"\"\"\n",
    "    \n",
    "    # Sort by breath_id and time_step to ensure proper ordering\n",
    "    df = df.sort_values(['breath_id', 'time_step']).reset_index(drop=True)\n",
    "    \n",
    "    # Basic features\n",
    "    features = ['R', 'C', 'time_step', 'u_in', 'u_out']\n",
    "    \n",
    "    # Create lag features (previous values within the same breath)\n",
    "    for lag in [1, 2, 3]:\n",
    "        df[f'u_in_lag_{lag}'] = df.groupby('breath_id')['u_in'].shift(lag)\n",
    "        df[f'u_out_lag_{lag}'] = df.groupby('breath_id')['u_out'].shift(lag)\n",
    "        \n",
    "        # Fill NaN values with 0 for lag features\n",
    "        df[f'u_in_lag_{lag}'] = df[f'u_in_lag_{lag}'].fillna(0)\n",
    "        df[f'u_out_lag_{lag}'] = df[f'u_out_lag_{lag}'].fillna(0)\n",
    "    \n",
    "    # Rolling statistics for u_in\n",
    "    for window in [5, 10]:\n",
    "        df[f'u_in_rolling_mean_{window}'] = df.groupby('breath_id')['u_in'].rolling(window, min_periods=1).mean().reset_index(0, drop=True)\n",
    "        df[f'u_in_rolling_std_{window}'] = df.groupby('breath_id')['u_in'].rolling(window, min_periods=1).std().reset_index(0, drop=True)\n",
    "    \n",
    "    # Rate of change of u_in\n",
    "    df['u_in_diff'] = df.groupby('breath_id')['u_in'].diff().fillna(0)\n",
    "    \n",
    "    # Interaction features\n",
    "    df['R_C_interaction'] = df['R'] * df['C']\n",
    "    df['u_in_R_interaction'] = df['u_in'] * df['R']\n",
    "    df['u_in_C_interaction'] = df['u_in'] * df['C']\n",
    "    \n",
    "    # Time since start of breath\n",
    "    df['time_since_start'] = df.groupby('breath_id')['time_step'].transform(lambda x: x - x.min())\n",
    "    \n",
    "    # Cumulative sum of u_in within breath\n",
    "    df['u_in_cumsum'] = df.groupby('breath_id')['u_in'].cumsum()\n",
    "    \n",
    "    # Add all created features to the feature list\n",
    "    feature_cols = [col for col in df.columns if col not in ['id', 'breath_id', 'pressure']]\n",
    "    \n",
    "    return df, feature_cols\n",
    "\n",
    "# Create features for training data\n",
    "print(\"Creating features for training data...\")\n",
    "train_df, feature_cols = create_features(train_df, is_train=True)\n",
    "\n",
    "# Create features for test data\n",
    "print(\"Creating features for test data...\")\n",
    "test_df, _ = create_features(test_df, is_train=False)\n",
    "\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Feature columns: {feature_cols[:10]}...\")  # Show first 10 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d295c291",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "X = train_df[feature_cols]\n",
    "y = train_df['pressure']\n",
    "\n",
    "print(f\"Training features shape: {X.shape}\")\n",
    "print(f\"Training target shape: {y.shape}\")\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\nMissing values in features: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in target: {y.isnull().sum()}\")\n",
    "\n",
    "# Fill any remaining NaN values with 0\n",
    "X = X.fillna(0)\n",
    "test_df[feature_cols] = test_df[feature_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325485b",
   "metadata": {},
   "source": [
    "## Cross-Validation Setup\n",
    "\n",
    "Use KFold cross-validation since we're dealing with time series data within each breath, but breaths are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa951c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create breath-level splits for cross-validation\n",
    "# Each breath is independent, so we can use KFold on breath_ids\n",
    "breath_ids = train_df['breath_id'].unique()\n",
    "n_splits = 5\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "folds = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(breath_ids)):\n",
    "    train_breaths = breath_ids[train_idx]\n",
    "    val_breaths = breath_ids[val_idx]\n",
    "    \n",
    "    # Get indices for these breaths\n",
    "    train_indices = train_df[train_df['breath_id'].isin(train_breaths)].index\n",
    "    val_indices = train_df[train_df['breath_id'].isin(val_breaths)].index\n",
    "    \n",
    "    folds.append((train_indices, val_indices))\n",
    "    \n",
    "print(f\"Created {len(folds)} folds\")\n",
    "print(f\"Total breaths: {len(breath_ids)}\")\n",
    "for i, (train_idx, val_idx) in enumerate(folds):\n",
    "    train_breath_count = len(train_df.loc[train_idx, 'breath_id'].unique())\n",
    "    val_breath_count = len(train_df.loc[val_idx, 'breath_id'].unique())\n",
    "    print(f\"Fold {i+1}: {train_breath_count} train breaths, {val_breath_count} val breaths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62164ed2",
   "metadata": {},
   "source": [
    "## Train Model with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e601f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Store predictions and scores\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "test_predictions = np.zeros(len(test_df))\n",
    "fold_scores = []\n",
    "\n",
    "print(\"Training LightGBM model with cross-validation...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "    print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_set = lgb.Dataset(X_train, label=y_train)\n",
    "    val_set = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        lgb_params,\n",
    "        train_set,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=[val_set],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(100),\n",
    "            lgb.log_evaluation(100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Calculate validation score\n",
    "    val_score = mean_absolute_error(y_val, val_pred)\n",
    "    fold_scores.append(val_score)\n",
    "    print(f\"Fold {fold + 1} MAE: {val_score:.4f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_pred = model.predict(test_df[feature_cols], num_iteration=model.best_iteration)\n",
    "    test_predictions += test_pred / n_splits\n",
    "\n",
    "# Calculate overall CV score\n",
    "cv_score = mean_absolute_error(y, oof_predictions)\n",
    "print(f\"\\nOverall CV MAE: {cv_score:.4f}\")\n",
    "print(f\"Fold scores: {fold_scores}\")\n",
    "print(f\"Mean ± Std: {np.mean(fold_scores):.4f} ± {np.std(fold_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5a317",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 most important features:\")\n",
    "print(feature_importance.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6938ccf",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'pressure': test_predictions\n",
    "})\n",
    "\n",
    "# Ensure the submission has the correct format\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"Submission head:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")\n",
    "\n",
    "# Verify submission format matches sample\n",
    "sample_submission = pd.read_csv('/home/data/sample_submission.csv')\n",
    "print(f\"\\nSample submission shape: {sample_submission.shape}\")\n",
    "print(f\"Sample submission head:\")\n",
    "print(sample_submission.head())\n",
    "\n",
    "# Check if IDs match\n",
    "if set(submission['id']) == set(sample_submission['id']):\n",
    "    print(\"✓ Submission IDs match sample submission IDs\")\n",
    "else:\n",
    "    print(\"⚠ Warning: Submission IDs don't match sample submission IDs\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
