{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6dfe816",
   "metadata": {},
   "source": [
    "# Baseline Model: XGBoost + LightGBM\n",
    "\n",
    "Following the winning solution patterns:\n",
    "- Start with XGBoost and LightGBM as foundation\n",
    "- Minimal feature engineering (product features for NPK interactions)\n",
    "- Stratified K-Fold validation (5 folds)\n",
    "- Treat features as categorical where appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd9d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Target distribution:\")\n",
    "print(train['Fertilizer Name'].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic feature engineering - minimal as recommended\n",
    "# Add simple product features for NPK interactions\n",
    "for df in [train, test]:\n",
    "    df['NPK_product'] = df['Nitrogen'] * df['Potassium'] * df['Phosphorous']\n",
    "    df['N_P_ratio'] = df['Nitrogen'] / (df['Phosphorous'] + 1)\n",
    "    df['N_K_ratio'] = df['Nitrogen'] / (df['Potassium'] + 1)\n",
    "    df['P_K_ratio'] = df['Phosphorous'] / (df['Potassium'] + 1)\n",
    "\n",
    "# Identify feature types\n",
    "categorical_features = ['Soil Type', 'Crop Type']\n",
    "numerical_features = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous', \n",
    "                      'NPK_product', 'N_P_ratio', 'N_K_ratio', 'P_K_ratio']\n",
    "\n",
    "print(f\"Categorical features: {categorical_features}\")\n",
    "print(f\"Numerical features: {numerical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c4124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "le_dict = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on combined train+test to handle unseen categories\n",
    "    combined = pd.concat([train[col], test[col]], axis=0)\n",
    "    le.fit(combined)\n",
    "    train[col + '_encoded'] = le.transform(train[col])\n",
    "    test[col + '_encoded'] = le.transform(test[col])\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Prepare feature matrix\n",
    "feature_cols = [col + '_encoded' for col in categorical_features] + numerical_features\n",
    "X = train[feature_cols].copy()\n",
    "X_test = test[feature_cols].copy()\n",
    "y = train['Fertilizer Name'].copy()\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Test feature matrix shape: {X_test.shape}\")\n",
    "print(f\"Number of classes: {y.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a446ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)\n",
    "print(f\"Classes: {le_target.classes_}\")\n",
    "print(f\"Number of classes: {len(le_target.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize predictions\n",
    "oof_predictions = np.zeros((len(X), len(le_target.classes_)))\n",
    "test_predictions_xgb = np.zeros((len(X_test), len(le_target.classes_)))\n",
    "test_predictions_lgb = np.zeros((len(X_test), len(le_target.classes_)))\n",
    "\n",
    "# XGBoost parameters (following winning solution patterns)\n",
    "xgb_params = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'num_class': len(le_target.classes_),\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'n_estimators': 500,\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda',\n",
    "    'random_state': 42,\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "# LightGBM parameters\n",
    "lgb_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_class': len(le_target.classes_),\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 8,\n",
    "    'n_estimators': 500,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "print(\"Starting cross-validation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation loop\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_encoded)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "    \n",
    "    # Train XGBoost\n",
    "    print(\"Training XGBoost...\")\n",
    "    model_xgb = xgb.XGBClassifier(**xgb_params)\n",
    "    model_xgb.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Train LightGBM\n",
    "    print(\"Training LightGBM...\")\n",
    "    model_lgb = lgb.LGBMClassifier(**lgb_params)\n",
    "    model_lgb.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    pred_xgb = model_xgb.predict_proba(X_val)\n",
    "    pred_lgb = model_lgb.predict_proba(X_val)\n",
    "    \n",
    "    # Average predictions\n",
    "    pred_avg = (pred_xgb + pred_lgb) / 2\n",
    "    oof_predictions[val_idx] = pred_avg\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_pred_xgb = model_xgb.predict_proba(X_test)\n",
    "    test_pred_lgb = model_lgb.predict_proba(X_test)\n",
    "    \n",
    "    test_predictions_xgb += test_pred_xgb / n_splits\n",
    "    test_predictions_lgb += test_pred_lgb / n_splits\n",
    "    \n",
    "    # Calculate fold score (MAP@3 approximation using top-3 accuracy)\n",
    "    # For now, we'll use a simple metric - will calculate proper MAP@3 later\n",
    "    top3_pred = np.argsort(pred_avg, axis=1)[:, -3:][:, ::-1]\n",
    "    correct = np.sum(top3_pred == y_val.reshape(-1, 1))\n",
    "    fold_score = correct / (len(y_val) * 3)\n",
    "    fold_scores.append(fold_score)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} top-3 accuracy: {fold_score:.4f}\")\n",
    "\n",
    "print(f\"\\nMean top-3 accuracy: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate proper MAP@3 score\n",
    "def map_at_3(predictions, true_labels):\n",
    "    \"\"\"Calculate MAP@3 score\"\"\"\n",
    "    map_scores = []\n",
    "    \n",
    "    for i in range(len(true_labels)):\n",
    "        # Get top 3 predictions\n",
    "        pred_idx = np.argsort(predictions[i])[-3:][::-1]\n",
    "        \n",
    "        # Calculate average precision for this observation\n",
    "        score = 0.0\n",
    "        num_hits = 0\n",
    "        \n",
    "        for k, pred in enumerate(pred_idx, 1):\n",
    "            if pred == true_labels[i]:\n",
    "                num_hits += 1\n",
    "                score += num_hits / k\n",
    "                break  # Only one correct label per observation\n",
    "        \n",
    "        map_scores.append(score)\n",
    "    \n",
    "    return np.mean(map_scores)\n",
    "\n",
    "# Calculate CV score\n",
    "cv_score = map_at_3(oof_predictions, y_encoded)\n",
    "print(f\"CV MAP@3 Score: {cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b8510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average predictions from both models\n",
    "final_test_predictions = (test_predictions_xgb + test_predictions_lgb) / 2\n",
    "\n",
    "# Get top 3 predictions for each test sample\n",
    "top3_predictions = np.argsort(final_test_predictions, axis=1)[:, -3:][:, ::-1]\n",
    "\n",
    "# Convert back to fertilizer names\n",
    "predicted_names = []\n",
    "for pred in top3_predictions:\n",
    "    names = le_target.inverse_transform(pred)\n",
    "    predicted_names.append(' '.join(names))\n",
    "\n",
    "# Create submission\n",
    "test_ids = test['id'].values\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Fertilizer Name': predicted_names\n",
    "})\n",
    "\n",
    "print(\"Submission format:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(\"Submission saved to /home/submission/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment folder\n",
    "import os\n",
    "os.makedirs('experiments/001_baseline', exist_ok=True)\n",
    "\n",
    "# Save OOF predictions for potential ensembling later\n",
    "np.save('experiments/001_baseline/oof_predictions.npy', oof_predictions)\n",
    "np.save('experiments/001_baseline/test_predictions_xgb.npy', test_predictions_xgb)\n",
    "np.save('experiments/001_baseline/test_predictions_lgb.npy', test_predictions_lgb)\n",
    "\n",
    "# Save feature columns and encoders\n",
    "import pickle\n",
    "with open('experiments/001_baseline/feature_cols.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_cols, f)\n",
    "with open('experiments/001_baseline/le_target.pkl', 'wb') as f:\n",
    "    pickle.dump(le_target, f)\n",
    "\n",
    "print(\"Experiment artifacts saved to experiments/001_baseline/\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
