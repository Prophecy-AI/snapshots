{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ff6ab9",
   "metadata": {},
   "source": [
    "# Baseline Experiment: Meta Features Only with LightGBM\n",
    "\n",
    "This is the first baseline experiment following the seed strategy:\n",
    "- Use only meta/numerical features (no text processing yet)\n",
    "- LightGBM with class imbalance handling\n",
    "- Stratified K-Fold validation (k=5)\n",
    "- Focus on AUC-ROC metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a17fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d5e26c",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Target distribution: {train_df['requester_received_pizza'].value_counts().to_dict()}\")\n",
    "print(f\"Positive rate: {train_df['requester_received_pizza'].mean():.3f}\")\n",
    "\n",
    "# Load test data\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "print(f\"\\nTest data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc22cd",
   "metadata": {},
   "source": [
    "## Feature Engineering - Meta Features Only\n",
    "\n",
    "Based on EDA findings, we'll use:\n",
    "- User activity metrics (posts, comments on RAOP)\n",
    "- Account age\n",
    "- Text length features (correlate with success)\n",
    "- Temporal features\n",
    "- Exclude post-retrieval features to prevent leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Engineer features from the raw data\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Basic text length features (strong correlation with target per EDA)\n",
    "    features['request_text_length'] = df['request_text'].str.len()\n",
    "    features['request_title_length'] = df['request_title'].str.len()\n",
    "    \n",
    "    # User activity on RAOP (highly predictive per EDA - 0.46 correlation)\n",
    "    features['requester_number_of_posts_on_raop_at_request'] = df['requester_number_of_posts_on_raop_at_request']\n",
    "    features['requester_number_of_comments_on_raop_at_request'] = df['requester_number_of_comments_on_raop_at_request']\n",
    "    \n",
    "    # Account age\n",
    "    features['requester_account_age_in_days_at_request'] = df['requester_account_age_in_days_at_request']\n",
    "    features['requester_days_since_first_post_on_raop_at_request'] = df['requester_days_since_first_post_on_raop_at_request']\n",
    "    \n",
    "    # Subreddit diversity (number of unique subreddits)\n",
    "    features['requester_number_of_subreddits_at_request'] = df['requester_number_of_subreddits_at_request']\n",
    "    \n",
    "    # Post timing (hour of day)\n",
    "    features['request_hour'] = pd.to_datetime(df['unix_timestamp_of_request_utc'], unit='s').dt.hour\n",
    "    features['request_day_of_week'] = pd.to_datetime(df['unix_timestamp_of_request_utc'], unit='s').dt.dayofweek\n",
    "    \n",
    "    # Ratios\n",
    "    features['posts_to_comments_ratio'] = (\n",
    "        df['requester_number_of_posts_on_raop_at_request'] / \n",
    "        (df['requester_number_of_comments_on_raop_at_request'] + 1)\n",
    "    )\n",
    "    \n",
    "    features['account_age_to_posts_ratio'] = (\n",
    "        df['requester_account_age_in_days_at_request'] / \n",
    "        (df['requester_number_of_posts_on_raop_at_request'] + 1)\n",
    "    )\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    feature_df = pd.DataFrame(features)\n",
    "    \n",
    "    # Fill missing values\n",
    "    feature_df = feature_df.fillna(0)\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "# Engineer features for train and test\n",
    "print(\"Engineering features...\")\n",
    "X_train = engineer_features(train_df)\n",
    "X_test = engineer_features(test_df)\n",
    "\n",
    "print(f\"Feature matrix shape: {X_train.shape}\")\n",
    "print(f\"Features: {list(X_train.columns)}\")\n",
    "\n",
    "# Target variable\n",
    "y_train = train_df['requester_received_pizza'].astype(int)\n",
    "\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(X_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53214c77",
   "metadata": {},
   "source": [
    "## Model Training with Stratified K-Fold\n",
    "\n",
    "Using LightGBM with class imbalance handling (scale_pos_weight ~ 3:1 ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c876bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cross-validation\n",
    "N_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Model parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "# Calculate scale_pos_weight for class imbalance\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Scale pos weight: {scale_pos_weight:.2f}\")\n",
    "params['scale_pos_weight'] = scale_pos_weight\n",
    "\n",
    "# Cross-validation\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros(len(X_train))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "print(f\"\\nStarting {N_FOLDS}-fold cross-validation...\")\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(f\"\\nFold {fold + 1}/{N_FOLDS}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_set = lgb.Dataset(X_tr, label=y_tr)\n",
    "    valid_set = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_set],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(50),\n",
    "            lgb.log_evaluation(100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    oof_predictions[valid_idx] = val_pred\n",
    "    \n",
    "    # Calculate fold score\n",
    "    fold_score = roc_auc_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_score)\n",
    "    print(f\"Fold {fold + 1} AUC: {fold_score:.4f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    test_predictions += test_pred / N_FOLDS\n",
    "\n",
    "# Overall CV score\n",
    "cv_score = roc_auc_score(y_train, oof_predictions)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Cross-validation AUC: {cv_score:.4f}\")\n",
    "print(f\"Mean fold AUC: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")\n",
    "print(f\"Fold scores: {fold_scores}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90053946",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1017307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from the last fold model\n",
    "feature_importance = model.feature_importance(importance_type='gain')\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "# Create importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 most important features:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c24335d",
   "metadata": {},
   "source": [
    "## Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80153c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample submission to get the format\n",
    "sample_sub = pd.read_csv('/home/data/sampleSubmission.csv')\n",
    "print(f\"Sample submission shape: {sample_sub.shape}\")\n",
    "print(sample_sub.head())\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_001_baseline_meta_only.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
