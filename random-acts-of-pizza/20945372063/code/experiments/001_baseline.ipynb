{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13cb4dbe",
   "metadata": {},
   "source": [
    "# Baseline Model - Random Acts of Pizza\n",
    "\n",
    "This notebook creates a baseline model for predicting pizza request success.\n",
    "\n",
    "## Approach\n",
    "1. Load JSON data\n",
    "2. Extract structured features (numerical/meta data)\n",
    "3. Simple text features from title and request text\n",
    "4. LightGBM classifier\n",
    "5. Cross-validation with AUC scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82bd2045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T05:30:29.055305Z",
     "iopub.status.busy": "2026-01-13T05:30:29.054586Z",
     "iopub.status.idle": "2026-01-13T05:30:30.517434Z",
     "shell.execute_reply": "2026-01-13T05:30:30.516521Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fcb591c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T05:30:30.523172Z",
     "iopub.status.busy": "2026-01-13T05:30:30.522627Z",
     "iopub.status.idle": "2026-01-13T05:30:30.597173Z",
     "shell.execute_reply": "2026-01-13T05:30:30.596105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Number of training samples: 2878\n",
      "\n",
      "First sample keys: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request']\n",
      "\n",
      "Target distribution:\n",
      "Total: 2878\n",
      "Received pizza: 715 (24.84%)\n",
      "No pizza: 2163 (75.16%)\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_data)}\")\n",
    "print(\"\\nFirst sample keys:\", list(train_data[0].keys())[:10])\n",
    "print(\"\\nTarget distribution:\")\n",
    "targets = [d['requester_received_pizza'] for d in train_data]\n",
    "print(f\"Total: {len(targets)}\")\n",
    "print(f\"Received pizza: {sum(targets)} ({sum(targets)/len(targets):.2%})\")\n",
    "print(f\"No pizza: {len(targets) - sum(targets)} ({(len(targets) - sum(targets))/len(targets):.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55023220",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T05:30:30.599910Z",
     "iopub.status.busy": "2026-01-13T05:30:30.599591Z",
     "iopub.status.idle": "2026-01-13T05:30:30.632837Z",
     "shell.execute_reply": "2026-01-13T05:30:30.631839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n",
      "Number of test samples: 1162\n",
      "\n",
      "First sample keys: ['giver_username_if_known', 'request_id', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_days_since_first_post_on_raop_at_request', 'requester_number_of_comments_at_request', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_posts_at_request', 'requester_number_of_posts_on_raop_at_request']\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"Number of test samples: {len(test_data)}\")\n",
    "print(\"\\nFirst sample keys:\", list(test_data[0].keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec4ec272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T05:30:30.635952Z",
     "iopub.status.busy": "2026-01-13T05:30:30.635585Z",
     "iopub.status.idle": "2026-01-13T05:30:30.649812Z",
     "shell.execute_reply": "2026-01-13T05:30:30.649037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature engineering function\n",
    "def extract_features(data):\n",
    "    features = []\n",
    "    \n",
    "    for sample in data:\n",
    "        feat = {}\n",
    "        \n",
    "        # Basic metadata features\n",
    "        feat['request_id'] = sample['request_id']\n",
    "        \n",
    "        # Vote features\n",
    "        feat['upvotes'] = sample.get('number_of_upvotes_of_request_at_retrieval', 0)\n",
    "        feat['downvotes'] = sample.get('number_of_downvotes_of_request_at_retrieval', 0)\n",
    "        feat['vote_ratio'] = feat['upvotes'] / (feat['downvotes'] + 1)  # Avoid division by zero\n",
    "        feat['net_votes'] = feat['upvotes'] - feat['downvotes']\n",
    "        \n",
    "        # Comment features\n",
    "        feat['num_comments'] = sample.get('request_number_of_comments_at_retrieval', 0)\n",
    "        \n",
    "        # Account age features (convert to numeric)\n",
    "        feat['account_age_days'] = sample.get('requester_account_age_in_days_at_request', 0)\n",
    "        feat['account_age_years'] = feat['account_age_days'] / 365.25\n",
    "        \n",
    "        # Requester activity features\n",
    "        feat['requester_comments'] = sample.get('requester_number_of_comments_at_request', 0)\n",
    "        feat['requester_posts'] = sample.get('requester_number_of_posts_at_request', 0)\n",
    "        feat['requester_comments_raop'] = sample.get('requester_number_of_comments_in_raop_at_request', 0)\n",
    "        feat['requester_posts_raop'] = sample.get('requester_number_of_posts_on_raop_at_request', 0)\n",
    "        \n",
    "        # Upvote/downvote features for requester\n",
    "        feat['requester_upvotes_minus_downvotes'] = sample.get('requester_upvotes_minus_downvotes_at_request', 0)\n",
    "        feat['requester_upvotes_plus_downvotes'] = sample.get('requester_upvotes_plus_downvotes_at_request', 0)\n",
    "        \n",
    "        # User flair (convert to numeric)\n",
    "        flair = sample.get('requester_user_flair', 'None')\n",
    "        if flair == 'None':\n",
    "            feat['user_flair'] = 0\n",
    "        elif flair == 'shroom':\n",
    "            feat['user_flair'] = 1\n",
    "        elif flair == 'PIF':\n",
    "            feat['user_flair'] = 2\n",
    "        else:\n",
    "            feat['user_flair'] = 0\n",
    "        \n",
    "        # Time features\n",
    "        timestamp = sample.get('unix_timestamp_of_request_utc', 0)\n",
    "        feat['timestamp'] = timestamp\n",
    "        # Extract hour and day of week\n",
    "        try:\n",
    "            dt = pd.to_datetime(timestamp, unit='s')\n",
    "            feat['hour_of_day'] = dt.hour\n",
    "            feat['day_of_week'] = dt.dayofweek\n",
    "        except:\n",
    "            feat['hour_of_day'] = 0\n",
    "            feat['day_of_week'] = 0\n",
    "        \n",
    "        # Text features - title\n",
    "        title = sample.get('request_title', '')\n",
    "        feat['title_length'] = len(title)\n",
    "        feat['title_word_count'] = len(title.split())\n",
    "        feat['title_exclamation_marks'] = title.count('!')\n",
    "        feat['title_question_marks'] = title.count('?')\n",
    "        feat['title_all_caps'] = 1 if title.isupper() else 0\n",
    "        \n",
    "        # Text features - request text\n",
    "        text = sample.get('request_text', '')\n",
    "        feat['text_length'] = len(text)\n",
    "        feat['text_word_count'] = len(text.split())\n",
    "        feat['text_exclamation_marks'] = text.count('!')\n",
    "        feat['text_question_marks'] = text.count('?')\n",
    "        feat['text_all_caps'] = 1 if text.isupper() else 0\n",
    "        \n",
    "        # Combined text features\n",
    "        combined_text = (title + ' ' + text).lower()\n",
    "        feat['combined_length'] = len(combined_text)\n",
    "        \n",
    "        # Simple sentiment indicators (keyword counting)\n",
    "        positive_words = ['thank', 'thanks', 'please', 'kind', 'generous', 'appreciate', 'grateful', 'bless', 'wonderful', 'amazing']\n",
    "        negative_words = ['desperate', 'starving', 'hungry', 'broke', 'poor', 'need', 'help', 'urgent', 'emergency']\n",
    "        \n",
    "        feat['positive_word_count'] = sum(1 for word in positive_words if word in combined_text)\n",
    "        feat['negative_word_count'] = sum(1 for word in negative_words if word in combined_text)\n",
    "        feat['sentiment_ratio'] = feat['positive_word_count'] / (feat['negative_word_count'] + 1)\n",
    "        \n",
    "        # Punctuation and formatting\n",
    "        feat['total_exclamation_marks'] = combined_text.count('!')\n",
    "        feat['total_question_marks'] = combined_text.count('?')\n",
    "        feat['total_periods'] = combined_text.count('.')\n",
    "        feat['total_commas'] = combined_text.count(',')\n",
    "        \n",
    "        features.append(feat)\n",
    "    \n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65fc39e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T05:30:30.652318Z",
     "iopub.status.busy": "2026-01-13T05:30:30.652014Z",
     "iopub.status.idle": "2026-01-13T05:30:31.245179Z",
     "shell.execute_reply": "2026-01-13T05:30:31.244527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (2878, 36)\n",
      "\n",
      "Extracting features from test data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features shape: (1162, 36)\n",
      "\n",
      "Feature columns:\n",
      "['request_id', 'upvotes', 'downvotes', 'vote_ratio', 'net_votes', 'num_comments', 'account_age_days', 'account_age_years', 'requester_comments', 'requester_posts', 'requester_comments_raop', 'requester_posts_raop', 'requester_upvotes_minus_downvotes', 'requester_upvotes_plus_downvotes', 'user_flair', 'timestamp', 'hour_of_day', 'day_of_week', 'title_length', 'title_word_count', 'title_exclamation_marks', 'title_question_marks', 'title_all_caps', 'text_length', 'text_word_count', 'text_exclamation_marks', 'text_question_marks', 'text_all_caps', 'combined_length', 'positive_word_count', 'negative_word_count', 'sentiment_ratio', 'total_exclamation_marks', 'total_question_marks', 'total_periods', 'total_commas', 'target']\n"
     ]
    }
   ],
   "source": [
    "# Extract features for training and test\n",
    "print(\"Extracting features from training data...\")\n",
    "train_df = extract_features(train_data)\n",
    "print(f\"Training features shape: {train_df.shape}\")\n",
    "\n",
    "print(\"\\nExtracting features from test data...\")\n",
    "test_df = extract_features(test_data)\n",
    "print(f\"Test features shape: {test_df.shape}\")\n",
    "\n",
    "# Add target to training data\n",
    "train_df['target'] = [d['requester_received_pizza'] for d in train_data]\n",
    "\n",
    "print(\"\\nFeature columns:\")\n",
    "print(train_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bbe5af9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T05:30:31.247514Z",
     "iopub.status.busy": "2026-01-13T05:30:31.247207Z",
     "iopub.status.idle": "2026-01-13T05:30:31.259773Z",
     "shell.execute_reply": "2026-01-13T05:30:31.259052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2878, 35)\n",
      "Test data shape: (1162, 35)\n",
      "Number of features: 35\n",
      "\n",
      "Missing values in training: 0\n",
      "Missing values in test: 0\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for modeling\n",
    "feature_cols = [col for col in train_df.columns if col not in ['request_id', 'target']]\n",
    "X = train_df[feature_cols]\n",
    "y = train_df['target']\n",
    "X_test = test_df[feature_cols]\n",
    "\n",
    "print(f\"Training data shape: {X.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\nMissing values in training: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in test: {X_test.isnull().sum().sum()}\")\n",
    "\n",
    "# Fill any missing values with 0\n",
    "X = X.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff3b1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T05:30:31.262165Z",
     "iopub.status.busy": "2026-01-13T05:30:31.261913Z",
     "iopub.status.idle": "2026-01-13T05:30:31.678506Z",
     "shell.execute_reply": "2026-01-13T05:30:31.677799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-fold cross-validation...\n",
      "\n",
      "Fold 1/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 1\n",
      "Fold 1 AUC: 1.0000\n",
      "Best iteration: 1\n",
      "\n",
      "Fold 2/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 1\n",
      "Fold 2 AUC: 1.0000\n",
      "Best iteration: 1\n",
      "\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 1\n",
      "Fold 3 AUC: 1.0000\n",
      "Best iteration: 1\n",
      "\n",
      "Fold 4/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 1\n",
      "Fold 4 AUC: 1.0000\n",
      "Best iteration: 1\n",
      "\n",
      "Fold 5/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 1\n",
      "Fold 5 AUC: 1.0000\n",
      "Best iteration: 1\n",
      "\n",
      "==================================================\n",
      "Cross-validation results:\n",
      "Mean AUC: 1.0000 ± 0.0000\n",
      "Individual folds: ['1.0000', '1.0000', '1.0000', '1.0000', '1.0000']\n",
      "Overall training AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation setup\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Store predictions\n",
    "train_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "print(f\"Starting {n_folds}-fold cross-validation...\")\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_folds}\")\n",
    "    \n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_data],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    valid_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    \n",
    "    # Store predictions\n",
    "    train_predictions[valid_idx] = valid_pred\n",
    "    test_predictions += test_pred / n_folds\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc_score = roc_auc_score(y_valid, valid_pred)\n",
    "    cv_scores.append(auc_score)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} AUC: {auc_score:.4f}\")\n",
    "    print(f\"Best iteration: {model.best_iteration}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Cross-validation results:\")\n",
    "print(f\"Mean AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
    "print(f\"Individual folds: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "\n",
    "# Overall training AUC\n",
    "overall_auc = roc_auc_score(y, train_predictions)\n",
    "print(f\"Overall training AUC: {overall_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75ce990f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T05:30:31.681031Z",
     "iopub.status.busy": "2026-01-13T05:30:31.680343Z",
     "iopub.status.idle": "2026-01-13T05:30:31.690536Z",
     "shell.execute_reply": "2026-01-13T05:30:31.689768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most important features:\n",
      "                              feature    importance\n",
      "13                         user_flair  1.787760e+03\n",
      "0                             upvotes  2.273740e-13\n",
      "1                           downvotes  0.000000e+00\n",
      "2                          vote_ratio  0.000000e+00\n",
      "3                           net_votes  0.000000e+00\n",
      "5                    account_age_days  0.000000e+00\n",
      "4                        num_comments  0.000000e+00\n",
      "7                  requester_comments  0.000000e+00\n",
      "8                     requester_posts  0.000000e+00\n",
      "9             requester_comments_raop  0.000000e+00\n",
      "6                   account_age_years  0.000000e+00\n",
      "10               requester_posts_raop  0.000000e+00\n",
      "11  requester_upvotes_minus_downvotes  0.000000e+00\n",
      "12   requester_upvotes_plus_downvotes  0.000000e+00\n",
      "14                          timestamp  0.000000e+00\n",
      "15                        hour_of_day  0.000000e+00\n",
      "16                        day_of_week  0.000000e+00\n",
      "17                       title_length  0.000000e+00\n",
      "18                   title_word_count  0.000000e+00\n",
      "19            title_exclamation_marks  0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 most important features:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2150373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T05:30:31.693373Z",
     "iopub.status.busy": "2026-01-13T05:30:31.692751Z",
     "iopub.status.idle": "2026-01-13T05:30:31.713470Z",
     "shell.execute_reply": "2026-01-13T05:30:31.712677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file preview:\n",
      "  request_id  requester_received_pizza\n",
      "0  t3_1aw5zf                  0.236224\n",
      "1   t3_roiuw                  0.236224\n",
      "2   t3_mjnbq                  0.236224\n",
      "3   t3_t8wd1                  0.236224\n",
      "4  t3_1m4zxu                  0.236224\n",
      "\n",
      "Submission saved to: /home/submission/submission_001_baseline.csv\n",
      "\n",
      "Submission shape: (1162, 2)\n",
      "Prediction distribution:\n",
      "count    1.162000e+03\n",
      "mean     2.362235e-01\n",
      "std      2.776753e-17\n",
      "min      2.362235e-01\n",
      "25%      2.362235e-01\n",
      "50%      2.362235e-01\n",
      "75%      2.362235e-01\n",
      "max      2.362235e-01\n",
      "Name: requester_received_pizza, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "# Ensure the predictions are in the correct range [0, 1]\n",
    "submission_df['requester_received_pizza'] = submission_df['requester_received_pizza'].clip(0, 1)\n",
    "\n",
    "print(\"Submission file preview:\")\n",
    "print(submission_df.head())\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_001_baseline.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")\n",
    "\n",
    "print(f\"\\nSubmission shape: {submission_df.shape}\")\n",
    "print(f\"Prediction distribution:\")\n",
    "print(submission_df['requester_received_pizza'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70a89054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T05:30:31.716043Z",
     "iopub.status.busy": "2026-01-13T05:30:31.715515Z",
     "iopub.status.idle": "2026-01-13T05:30:31.731613Z",
     "shell.execute_reply": "2026-01-13T05:30:31.730876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-fold predictions saved to: /home/submission/oof_001_baseline.csv\n"
     ]
    }
   ],
   "source": [
    "# Save out-of-fold predictions for potential stacking\n",
    "oof_df = pd.DataFrame({\n",
    "    'request_id': train_df['request_id'],\n",
    "    'prediction': train_predictions,\n",
    "    'target': y\n",
    "})\n",
    "\n",
    "oof_path = '/home/submission/oof_001_baseline.csv'\n",
    "oof_df.to_csv(oof_path, index=False)\n",
    "print(f\"Out-of-fold predictions saved to: {oof_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
