{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9982497c",
   "metadata": {},
   "source": [
    "# Baseline Experiment: LightGBM with Simple Features\n",
    "\n",
    "This notebook implements a baseline model using LightGBM with simple text and tabular features.\n",
    "\n",
    "**Strategy:**\n",
    "- Simple text features: length, word count, presence of 'EDIT'\n",
    "- Tabular features as-is with minimal preprocessing\n",
    "- Stratified 5-fold CV to handle class imbalance\n",
    "- LightGBM for speed and good performance with mixed data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb3f925",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T00:35:58.248338Z",
     "iopub.status.busy": "2026-01-10T00:35:58.248086Z",
     "iopub.status.idle": "2026-01-10T00:35:59.121530Z",
     "shell.execute_reply": "2026-01-10T00:35:59.120985Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de77c2",
   "metadata": {},
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0570a42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T00:35:59.123113Z",
     "iopub.status.busy": "2026-01-10T00:35:59.122853Z",
     "iopub.status.idle": "2026-01-10T00:35:59.186594Z",
     "shell.execute_reply": "2026-01-10T00:35:59.186172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2878\n",
      "Test samples: 1162\n",
      "Sample keys: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_path = '/home/data/train.json'\n",
    "test_path = '/home/data/test.json'\n",
    "\n",
    "with open(train_path, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(test_path, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "print(f\"Sample keys: {list(train_data[0].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729ada34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T00:35:59.187784Z",
     "iopub.status.busy": "2026-01-10T00:35:59.187548Z",
     "iopub.status.idle": "2026-01-10T00:35:59.207999Z",
     "shell.execute_reply": "2026-01-10T00:35:59.207610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2878, 32)\n",
      "Test data shape: (1162, 17)\n",
      "\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    0.751564\n",
      "True     0.248436\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame for easier manipulation\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(\"Training data shape:\", train_df.shape)\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train_df['requester_received_pizza'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f54a5d",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf36680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features(df):\n",
    "    \"\"\"Extract simple text features from request text and title\"\"\"\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Use request_text if available, otherwise use request_text_edit_aware\n",
    "    text_col = 'request_text' if 'request_text' in df.columns else 'request_text_edit_aware'\n",
    "    \n",
    "    # Request text features\n",
    "    features['text_length'] = df[text_col].fillna('').apply(len)\n",
    "    features['text_word_count'] = df[text_col].fillna('').apply(lambda x: len(x.split()))\n",
    "    features['text_has_edit'] = df[text_col].fillna('').str.contains('EDIT', case=False).astype(int)\n",
    "    \n",
    "    # Title features  \n",
    "    features['title_length'] = df['request_title'].fillna('').apply(len)\n",
    "    features['title_word_count'] = df['request_title'].fillna('').apply(lambda x: len(x.split()))\n",
    "    \n",
    "    # Combined text features\n",
    "    features['total_text_length'] = features['text_length'] + features['title_length']\n",
    "    features['total_word_count'] = features['text_word_count'] + features['title_word_count']\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_tabular_features(df):\n",
    "    \"\"\"Extract and preprocess tabular features\"\"\"\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Numeric features that might exist in the dataset\n",
    "    numeric_cols = [\n",
    "        'requester_account_age_in_days_at_request',\n",
    "        'requester_account_age_in_days_at_retrieval',\n",
    "        'requester_number_of_comments_at_request',\n",
    "        'requester_number_of_comments_at_retrieval',\n",
    "        'requester_number_of_posts_at_request',\n",
    "        'requester_number_of_posts_at_retrieval',\n",
    "        'requester_upvotes_minus_downvotes_at_request',\n",
    "        'requester_upvotes_minus_downvotes_at_retrieval',\n",
    "        'requester_upvotes_plus_downvotes_at_request',\n",
    "        'requester_upvotes_plus_downvotes_at_retrieval',\n",
    "        'number_of_upvotes_of_request_at_retrieval',\n",
    "        'number_of_downvotes_of_request_at_retrieval',\n",
    "        'request_number_of_comments_at_retrieval'\n",
    "    ]\n",
    "    \n",
    "    # Add numeric features if they exist\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            features[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "        else:\n",
    "            features[col] = 0  # Add column with zeros if it doesn't exist\n",
    "    \n",
    "    # Binary features\n",
    "    if 'post_was_edited' in df.columns:\n",
    "        features['post_was_edited'] = df['post_was_edited'].astype(int)\n",
    "    else:\n",
    "        features['post_was_edited'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features for train and test\n",
    "train_text_features = extract_text_features(train_df)\n",
    "train_tabular_features = extract_tabular_features(train_df)\n",
    "train_features = pd.concat([train_text_features, train_tabular_features], axis=1)\n",
    "\n",
    "test_text_features = extract_text_features(test_df)\n",
    "test_tabular_features = extract_tabular_features(test_df)\n",
    "test_features = pd.concat([test_text_features, test_tabular_features], axis=1)\n",
    "\n",
    "# Ensure both train and test have the same columns\n",
    "train_features = train_features.reindex(columns=test_features.columns)\n",
    "\n",
    "print(f\"Train features shape: {train_features.shape}\")\n",
    "print(f\"Test features shape: {test_features.shape}\")\n",
    "print(f\"Columns match: {list(train_features.columns) == list(test_features.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d400aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No categorical features to encode in this baseline model\n",
    "print(\"No categorical features to encode in baseline model\")\n",
    "print(f\"Final train features shape: {train_features.shape}\")\n",
    "print(f\"Final test features shape: {test_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a710f865",
   "metadata": {},
   "source": [
    "## Model Training with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "X = train_features.copy()\n",
    "y = train_df['requester_received_pizza'].astype(int)\n",
    "\n",
    "# Fill any remaining NaN values\n",
    "X = X.fillna(0)\n",
    "test_features = test_features.fillna(0)\n",
    "\n",
    "print(f\"Training data: {X.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# Define cross-validation strategy\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# Store predictions\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(test_features))\n",
    "cv_scores = []\n",
    "\n",
    "print(f\"\\nStarting {n_folds}-fold stratified cross-validation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM model with cross-validation\n",
    "fold = 1\n",
    "for train_idx, valid_idx in skf.split(X, y):\n",
    "    print(f\"\\nFold {fold}/{n_folds}\")\n",
    "    \n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Define parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': RANDOM_SEED\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_data],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    oof_predictions[valid_idx] = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    test_predictions += model.predict(test_features, num_iteration=model.best_iteration) / n_folds\n",
    "    \n",
    "    # Calculate fold score\n",
    "    fold_score = roc_auc_score(y_valid, oof_predictions[valid_idx])\n",
    "    cv_scores.append(fold_score)\n",
    "    print(f\"Fold {fold} AUC: {fold_score:.4f}\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# Calculate overall CV score\n",
    "overall_cv_score = roc_auc_score(y, oof_predictions)\n",
    "print(f\"\\nOverall CV AUC: {overall_cv_score:.4f}\")\n",
    "print(f\"Mean CV AUC: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afb187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 most important features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf222c05",
   "metadata": {},
   "source": [
    "## Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "# Ensure submission format matches sample\n",
    "print(\"Submission shape:\", submission.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_001_baseline.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify submission format\n",
    "sample_sub = pd.read_csv('/home/data/sampleSubmission.csv')\n",
    "print(\"Sample submission shape:\", sample_sub.shape)\n",
    "print(\"Our submission shape:\", submission.shape)\n",
    "print(\"Columns match:\", list(submission.columns) == list(sample_sub.columns))\n",
    "print(\"Request IDs match:\", set(submission['request_id']) == set(sample_sub['request_id']))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
