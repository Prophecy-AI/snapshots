{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f579f6c1",
   "metadata": {},
   "source": [
    "# Evolver Loop 4 Analysis: Understanding exp_003 Failure\n",
    "\n",
    "**Objective**: Analyze why enhanced keyword features experiment (exp_003) degraded performance from 0.6253 to 0.6196\n",
    "\n",
    "**Key questions**:\n",
    "1. Why did count-based keywords perform worse than binary indicators?\n",
    "2. What can we learn about feature engineering effectiveness?\n",
    "3. What should we try next based on this failure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562bffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train_path = '/home/data/train.json'\n",
    "with open(train_path, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Positive rate: {train_df['requester_received_pizza'].mean():.3f}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(train_df[['request_title', 'request_text', 'requester_received_pizza']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a30b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze keyword patterns in successful vs failed requests\n",
    "def extract_keywords(text, keywords):\n",
    "    \"\"\"Extract keyword counts from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return {kw: 0 for kw in keywords}\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    counts = {}\n",
    "    for kw in keywords:\n",
    "        # Use word boundaries for accurate matching\n",
    "        import re\n",
    "        pattern = r'\\b' + re.escape(kw) + r'\\b'\n",
    "        counts[kw] = len(re.findall(pattern, text_lower))\n",
    "    return counts\n",
    "\n",
    "# Keywords from exp_003 (original + new)\n",
    "original_keywords = ['thanks', 'thank', 'please', 'because', 'pay', 'forward']\n",
    "new_keywords = ['appreciate', 'grateful', 'children', 'family', 'need', 'help', 'desperate', 'hungry']\n",
    "all_keywords = original_keywords + new_keywords\n",
    "\n",
    "print(\"Analyzing keyword patterns...\")\n",
    "\n",
    "# Combine title and text for analysis\n",
    "train_df['full_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text'].fillna('')\n",
    "\n",
    "# Extract keyword counts for all samples\n",
    "keyword_data = []\n",
    "for idx, row in train_df.iterrows():\n",
    "    counts = extract_keywords(row['full_text'], all_keywords)\n",
    "    counts['requester_received_pizza'] = row['requester_received_pizza']\n",
    "    keyword_data.append(counts)\n",
    "\n",
    "keyword_df = pd.DataFrame(keyword_data)\n",
    "\n",
    "# Calculate success rates by keyword presence\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEYWORD ANALYSIS: Success rates by presence/absence\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "for kw in all_keywords:\n",
    "    present = keyword_df[keyword_df[kw] > 0]\n",
    "    absent = keyword_df[keyword_df[kw] == 0]\n",
    "    \n",
    "    if len(present) > 20:  # Only analyze keywords with sufficient samples\n",
    "        success_rate_present = present['requester_received_pizza'].mean()\n",
    "        success_rate_absent = absent['requester_received_pizza'].mean()\n",
    "        lift = success_rate_present - success_rate_absent\n",
    "        \n",
    "        results.append({\n",
    "            'keyword': kw,\n",
    "            'present_count': len(present),\n",
    "            'absent_count': len(absent),\n",
    "            'success_rate_present': success_rate_present,\n",
    "            'success_rate_absent': success_rate_absent,\n",
    "            'lift': lift,\n",
    "            'baseline': train_df['requester_received_pizza'].mean()\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('lift', ascending=False)\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a1c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze frequency distribution of keywords\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEYWORD FREQUENCY DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for kw in all_keywords:\n",
    "    freq_dist = keyword_df[kw].value_counts().sort_index()\n",
    "    print(f\"\\n{kw.upper()}:\")\n",
    "    print(f\"  Mean occurrences: {keyword_df[kw].mean():.3f}\")\n",
    "    print(f\"  Max occurrences: {keyword_df[kw].max()}\")\n",
    "    print(f\"  % with 0 occurrences: {(keyword_df[kw] == 0).mean()*100:.1f}%\")\n",
    "    print(f\"  % with 1 occurrence: {(keyword_df[kw] == 1).mean()*100:.1f}%\")\n",
    "    print(f\"  % with 2+ occurrences: {(keyword_df[kw] >= 2).mean()*100:.1f}%\")\n",
    "    \n",
    "    # Show distribution for first few values\n",
    "    for val in sorted(freq_dist.index)[:5]:\n",
    "        if val > 0:\n",
    "            count = freq_dist[val]\n",
    "            success_rate = keyword_df[keyword_df[kw] == val]['requester_received_pizza'].mean()\n",
    "            print(f\"    {val} occurrence(s): {count} samples, {success_rate:.1%} success rate\")\n",
    "\n",
    "# Analyze correlation between keyword count and success\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORRELATION ANALYSIS: Keyword count vs success\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "correlations = []\n",
    "for kw in all_keywords:\n",
    "    corr = keyword_df[kw].corr(keyword_df['requester_received_pizza'])\n",
    "    correlations.append({'keyword': kw, 'correlation': corr})\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('correlation', ascending=False)\n",
    "print(corr_df.round(4))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
