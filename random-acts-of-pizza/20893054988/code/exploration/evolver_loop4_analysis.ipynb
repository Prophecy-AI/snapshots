{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f579f6c1",
   "metadata": {},
   "source": [
    "# Evolver Loop 4 Analysis: Understanding exp_003 Failure\n",
    "\n",
    "**Objective**: Analyze why enhanced keyword features experiment (exp_003) degraded performance from 0.6253 to 0.6196\n",
    "\n",
    "**Key questions**:\n",
    "1. Why did count-based keywords perform worse than binary indicators?\n",
    "2. What can we learn about feature engineering effectiveness?\n",
    "3. What should we try next based on this failure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562bffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train_path = '/home/data/train.json'\n",
    "with open(train_path, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Positive rate: {train_df['requester_received_pizza'].mean():.3f}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(train_df[['request_title', 'request_text', 'requester_received_pizza']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a30b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze keyword patterns in successful vs failed requests\n",
    "def extract_keywords(text, keywords):\n",
    "    \"\"\"Extract keyword counts from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return {kw: 0 for kw in keywords}\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    counts = {}\n",
    "    for kw in keywords:\n",
    "        # Use word boundaries for accurate matching\n",
    "        import re\n",
    "        pattern = r'\\b' + re.escape(kw) + r'\\b'\n",
    "        counts[kw] = len(re.findall(pattern, text_lower))\n",
    "    return counts\n",
    "\n",
    "# Keywords from exp_003 (original + new)\n",
    "original_keywords = ['thanks', 'thank', 'please', 'because', 'pay', 'forward']\n",
    "new_keywords = ['appreciate', 'grateful', 'children', 'family', 'need', 'help', 'desperate', 'hungry']\n",
    "all_keywords = original_keywords + new_keywords\n",
    "\n",
    "print(\"Analyzing keyword patterns...\")\n",
    "\n",
    "# Combine title and text for analysis\n",
    "train_df['full_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text'].fillna('')\n",
    "\n",
    "# Extract keyword counts for all samples\n",
    "keyword_data = []\n",
    "for idx, row in train_df.iterrows():\n",
    "    counts = extract_keywords(row['full_text'], all_keywords)\n",
    "    counts['requester_received_pizza'] = row['requester_received_pizza']\n",
    "    keyword_data.append(counts)\n",
    "\n",
    "keyword_df = pd.DataFrame(keyword_data)\n",
    "\n",
    "# Calculate success rates by keyword presence\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEYWORD ANALYSIS: Success rates by presence/absence\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "for kw in all_keywords:\n",
    "    present = keyword_df[keyword_df[kw] > 0]\n",
    "    absent = keyword_df[keyword_df[kw] == 0]\n",
    "    \n",
    "    if len(present) > 20:  # Only analyze keywords with sufficient samples\n",
    "        success_rate_present = present['requester_received_pizza'].mean()\n",
    "        success_rate_absent = absent['requester_received_pizza'].mean()\n",
    "        lift = success_rate_present - success_rate_absent\n",
    "        \n",
    "        results.append({\n",
    "            'keyword': kw,\n",
    "            'present_count': len(present),\n",
    "            'absent_count': len(absent),\n",
    "            'success_rate_present': success_rate_present,\n",
    "            'success_rate_absent': success_rate_absent,\n",
    "            'lift': lift,\n",
    "            'baseline': train_df['requester_received_pizza'].mean()\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('lift', ascending=False)\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a1c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze frequency distribution of keywords\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEYWORD FREQUENCY DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for kw in all_keywords:\n",
    "    freq_dist = keyword_df[kw].value_counts().sort_index()\n",
    "    print(f\"\\n{kw.upper()}:\")\n",
    "    print(f\"  Mean occurrences: {keyword_df[kw].mean():.3f}\")\n",
    "    print(f\"  Max occurrences: {keyword_df[kw].max()}\")\n",
    "    print(f\"  % with 0 occurrences: {(keyword_df[kw] == 0).mean()*100:.1f}%\")\n",
    "    print(f\"  % with 1 occurrence: {(keyword_df[kw] == 1).mean()*100:.1f}%\")\n",
    "    print(f\"  % with 2+ occurrences: {(keyword_df[kw] >= 2).mean()*100:.1f}%\")\n",
    "    \n",
    "    # Show distribution for first few values\n",
    "    for val in sorted(freq_dist.index)[:5]:\n",
    "        if val > 0:\n",
    "            count = freq_dist[val]\n",
    "            success_rate = keyword_df[keyword_df[kw] == val]['requester_received_pizza'].mean()\n",
    "            print(f\"    {val} occurrence(s): {count} samples, {success_rate:.1%} success rate\")\n",
    "\n",
    "# Analyze correlation between keyword count and success\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORRELATION ANALYSIS: Keyword count vs success\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "correlations = []\n",
    "for kw in all_keywords:\n",
    "    corr = keyword_df[kw].corr(keyword_df['requester_received_pizza'])\n",
    "    correlations.append({'keyword': kw, 'correlation': corr})\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('correlation', ascending=False)\n",
    "print(corr_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39afada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare binary vs count approach effectiveness\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BINARY vs COUNT: Which approach works better?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# For each keyword, compare predictive power of binary vs count\n",
    "comparison_results = []\n",
    "\n",
    "for kw in all_keywords:\n",
    "    # Binary approach (presence/absence)\n",
    "    binary_present = (keyword_df[kw] > 0).astype(int)\n",
    "    binary_corr = abs(binary_present.corr(keyword_df['requester_received_pizza']))\n",
    "    \n",
    "    # Count approach (number of occurrences)\n",
    "    count_corr = abs(keyword_df[kw].corr(keyword_df['requester_received_pizza']))\n",
    "    \n",
    "    # Determine which is better\n",
    "    better_approach = \"BINARY\" if binary_corr > count_corr else \"COUNT\"\n",
    "    difference = abs(binary_corr - count_corr)\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'keyword': kw,\n",
    "        'binary_correlation': binary_corr,\n",
    "        'count_correlation': count_corr,\n",
    "        'better_approach': better_approach,\n",
    "        'difference': difference,\n",
    "        'mean_occurrences': keyword_df[kw].mean()\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results).sort_values('difference', ascending=False)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY: Binary vs Count Performance\")\n",
    "print(f\"{'='*60}\")\n",
    "binary_better = (comparison_df['better_approach'] == 'BINARY').sum()\n",
    "count_better = (comparison_df['better_approach'] == 'COUNT').sum()\n",
    "print(f\"Keywords where BINARY is better: {binary_better}/{len(all_keywords)}\")\n",
    "print(f\"Keywords where COUNT is better: {count_better}/{len(all_keywords)}\")\n",
    "\n",
    "# Analyze why binary might be better\n",
    "print(f\"\\nKeywords with very low frequency (mean < 0.1):\")\n",
    "low_freq = comparison_df[comparison_df['mean_occurrences'] < 0.1]\n",
    "print(low_freq[['keyword', 'mean_occurrences', 'better_approach']].round(4))\n",
    "\n",
    "print(f\"\\nKeywords with higher frequency (mean >= 0.1):\")\n",
    "high_freq = comparison_df[comparison_df['mean_occurrences'] >= 0.1]\n",
    "print(high_freq[['keyword', 'mean_occurrences', 'better_approach']].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze text preprocessing issues\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEXT PREPROCESSING ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sample some text to see what patterns exist\n",
    "sample_texts = train_df['full_text'].sample(5, random_state=42).tolist()\n",
    "\n",
    "print(\"Sample raw texts:\")\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    print(f\"\\n--- Sample {i} ---\")\n",
    "    print(text[:300] + \"...\" if len(text) > 300 else text)\n",
    "\n",
    "# Check for Reddit-specific patterns\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REDDIT PATTERN DETECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "reddit_patterns = {\n",
    "    'r/ references': r'r/[a-zA-Z0-9_]+',\n",
    "    'u/ references': r'u/[a-zA-Z0-9_]+',\n",
    "    'URLs': r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\n",
    "    'Markdown links': r'\\[.*?\\]\\(.*?\\)',\n",
    "    'Email addresses': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "}\n",
    "\n",
    "pattern_counts = defaultdict(int)\n",
    "pattern_examples = defaultdict(list)\n",
    "\n",
    "for text in train_df['full_text']:\n",
    "    if pd.isna(text):\n",
    "        continue\n",
    "    for pattern_name, pattern_regex in reddit_patterns.items():\n",
    "        matches = re.findall(pattern_regex, text)\n",
    "        if matches:\n",
    "            pattern_counts[pattern_name] += 1\n",
    "            if len(pattern_examples[pattern_name]) < 3:\n",
    "                pattern_examples[pattern_name].extend(matches[:3-len(pattern_examples[pattern_name])])\n",
    "\n",
    "print(\"Reddit pattern frequencies:\")\n",
    "for pattern_name, count in pattern_counts.items():\n",
    "    print(f\"  {pattern_name}: {count} texts ({count/len(train_df)*100:.1f}%)\")\n",
    "    if pattern_examples[pattern_name]:\n",
    "        print(f\"    Examples: {pattern_examples[pattern_name][:2]}\")\n",
    "\n",
    "# Check for common abbreviations that might affect keyword matching\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMMON ABBREVIATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "abbreviations = ['pls', 'plz', 'thx', 'thnx', 'ty', 'pl', 'pizza', 'plz', 'thanx']\n",
    "for abbr in abbreviations:\n",
    "    count = train_df['full_text'].str.contains(f'\\b{abbr}\\b', case=False, na=False).sum()\n",
    "    if count > 0:\n",
    "        print(f\"  '{abbr}': {count} occurrences ({count/len(train_df)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
