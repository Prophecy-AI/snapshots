## Competition Overview
This is a binary classification problem predicting whether a Reddit pizza request will be successful. The dataset contains 2,878 training samples with moderate class imbalance (24.8% positive rate). Features include text (request title and body) and tabular metadata (user activity, engagement metrics, timestamps).

**Reference notebooks for data characteristics:**
- `eda.ipynb` - Contains full EDA: feature distributions, missing values, target distribution, correlations, text length analysis

## Problem Type & Key Challenges
- **Multimodal classification**: Combine text (title, body) with tabular features (user activity, engagement metrics)
- **Moderate class imbalance**: 24.8% success rate requires careful handling
- **Text preprocessing**: Need to handle edit-aware text versions and potential leakage
- **High-cardinality categorical**: User flair with 75% missing values, giver usernames

## Models & Architecture

### Primary Approaches (Based on Kaggle Winning Solutions)
1. **Two-stage pipeline** (Most reliable for tabular + text):
   - Encode text with pretrained transformers (BERT/RoBERTa) to get embeddings
   - Concatenate with tabular features
   - Feed to gradient boosting (LightGBM/XGBoost/CatBoost)
   - This approach consistently wins multimodal Kaggle competitions

2. **Single multimodal models**:
   - Convert tabular features to text format and prepend to original text
   - Fine-tune transformer on combined text
   - Works well for smaller datasets (<10K samples)

3. **Ensemble strategies**:
   - Combine 3-5 diverse models (different architectures, seeds, feature sets)
   - Weighted averaging based on validation performance
   - Stacking often beats simple averaging for heterogeneous models

### Model Selection Guidelines
- **Gradient boosting**: Start with LightGBM for tabular features alone (strong baseline)
- **Neural networks**: Use when text is primary signal or dataset >100K samples
- **Transformers**: Essential for capturing nuanced text patterns in requests

## Preprocessing & Feature Engineering

### Text Features
- **TF-IDF**: Strong baseline for title + body text (word and character n-grams)
- **Text length features**: Character count, word count, sentence count
- **Sentiment analysis**: Polarity scores for request text
- **Keyword extraction**: Presence of specific words ("please", "thank", "hungry", "family")
- **Readability scores**: Flesch-Kincaid, etc.
- **Reddit-specific**: Subreddit mentions, username references, edit patterns

### Tabular Features
- **Temporal features**: Hour of day, day of week, month from timestamps
- **Engagement ratios**: Comments/posts ratios, upvote/downvote ratios
- **User experience**: Account age, days since first RAOP post
- **Community involvement**: RAOP-specific activity vs general Reddit activity
- **Missing value handling**: For user flair (75% missing), treat as separate category

### Feature Interactions
- Text length × user activity (engaged users with longer posts)
- Temporal × user flair (success patterns over time)
- Upvote ratios × comment counts (community reception)

## Handling Class Imbalance

### Data-Level Techniques
- **SMOTE oversampling**: Use imbalanced-learn library for minority class
- **Stratified sampling**: Preserve class ratios in cross-validation
- **Class weights**: Pass balanced weights to models (scale_pos_weight in XGBoost)

### Model-Level Techniques
- **Evaluation metric**: Use AUC-ROC (competition metric) or F1-score
- **Threshold tuning**: Optimize decision threshold on validation set
- **Ensemble weighting**: Give more weight to models that handle imbalance well

## Validation Strategy
- **Stratified K-Fold**: 5 folds to preserve class distribution
- **Time-based splits**: If temporal leakage is a concern (check timestamps)
- **Group K-Fold**: By requester_username to prevent user leakage
- **Early stopping**: Use validation AUC for all gradient boosting models

## Optimization & Hyperparameter Tuning
- **Bayesian optimization**: Use Optuna or Hyperopt for efficient search
- **Key parameters to tune**:
  - LightGBM: num_leaves, learning_rate, min_child_samples
  - XGBoost: max_depth, subsample, colsample_bytree
  - Transformers: learning_rate, batch_size, warmup_steps
- **Learning rate scheduling**: Cosine annealing for neural networks

## Post-Processing
- **Probability calibration**: Use Platt scaling or isotonic regression
- **Ensemble blending**: Weighted average based on validation AUC
- **Submission formatting**: Ensure proper CSV format with header

## Key Insights from EDA
- Strong predictive signals: requester_number_of_posts_on_raop_at_retrieval (corr 0.46), request_number_of_comments_at_retrieval (corr 0.29)
- User flair is highly predictive but 75% missing - verify if available at prediction time
- Text features show moderate correlation - need sophisticated NLP
- Community engagement metrics are more predictive than account age alone