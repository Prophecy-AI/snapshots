{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f40556",
   "metadata": {},
   "source": [
    "# Baseline Model - LightGBM\n",
    "\n",
    "Simple baseline using LightGBM with basic features:\n",
    "- Text length features\n",
    "- User flair encoding\n",
    "- Numeric features\n",
    "- StratifiedKFold for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fbeb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create experiments directory\n",
    "Path('/home/code/experiments').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading training data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = [json.loads(line) for line in f]\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Columns: {list(train_df.columns)}\")\n",
    "\n",
    "print(\"\\nLoading test data...\")\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = [json.loads(line) for line in f]\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "print(f\"Test data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd9a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic feature engineering\n",
    "print(\"Creating basic features...\")\n",
    "\n",
    "# Target\n",
    "target = 'requester_received_pizza'\n",
    "\n",
    "# Text length features\n",
    "train_df['title_length'] = train_df['request_title'].fillna('').str.len()\n",
    "train_df['text_length'] = train_df['request_text'].fillna('').str.len()\n",
    "train_df['text_edit_length'] = train_df['request_text_edit_aware'].fillna('').str.len()\n",
    "\n",
    "test_df['title_length'] = test_df['request_title'].fillna('').str.len()\n",
    "test_df['text_length'] = test_df['request_text'].fillna('').str.len()\n",
    "test_df['text_edit_length'] = test_df['request_text_edit_aware'].fillna('').str.len()\n",
    "\n",
    "# User flair encoding (strong predictive feature according to EDA)\n",
    "flair_mapping = {'None': 0, 'shroom': 1, 'PIF': 2}\n",
    "train_df['user_flair_encoded'] = train_df['requester_user_flair'].map(flair_mapping)\n",
    "test_df['user_flair_encoded'] = test_df['requester_user_flair'].map(flair_mapping)\n",
    "\n",
    "# Fill missing values\n",
    "numeric_features = [\n",
    "    'number_of_downvotes_of_request_at_retrieval',\n",
    "    'number_of_upvotes_of_request_at_retrieval',\n",
    "    'request_number_of_comments_at_retrieval',\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_number_of_subreddits_at_request'\n",
    "]\n",
    "\n",
    "for col in numeric_features:\n",
    "    train_df[col] = pd.to_numeric(train_df[col], errors='coerce').fillna(0)\n",
    "    test_df[col] = pd.to_numeric(test_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Select features for modeling\n",
    "feature_cols = numeric_features + [\n",
    "    'title_length', 'text_length', 'text_edit_length', 'user_flair_encoded'\n",
    "]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features: {feature_cols}\")\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df[target]\n",
    "X_test = test_df[feature_cols]\n",
    "\n",
    "print(f\"Training features shape: {X.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Target distribution: {y.mean():.3f} (positive rate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "print(f\"Starting {n_folds}-fold cross-validation...\")\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_folds}\")\n",
    "    \n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    # LightGBM parameters (basic)\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'random_state': 42 + fold\n",
    "    }\n",
    "    \n",
    "    # Create datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_data],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(50),\n",
    "            lgb.log_evaluation(0)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    valid_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    \n",
    "    # Store predictions\n",
    "    oof_predictions[valid_idx] = valid_pred\n",
    "    test_predictions += test_pred / n_folds\n",
    "    \n",
    "    # Calculate fold score\n",
    "    fold_score = roc_auc_score(y_valid, valid_pred)\n",
    "    cv_scores.append(fold_score)\n",
    "    print(f\"Fold {fold + 1} AUC: {fold_score:.4f}\")\n",
    "\n",
    "# Overall CV score\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "print(f\"\\nCV Score: {mean_cv_score:.4f} Â± {std_cv_score:.4f}\")\n",
    "\n",
    "# OOF score\n",
    "oof_score = roc_auc_score(y, oof_predictions)\n",
    "print(f\"OOF AUC: {oof_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 features by importance:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f082345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "# Ensure submission format matches sample\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "\n",
    "# Check distribution\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(f\"Mean: {submission['requester_received_pizza'].mean():.4f}\")\n",
    "print(f\"Std: {submission['requester_received_pizza'].std():.4f}\")\n",
    "print(f\"Min: {submission['requester_received_pizza'].min():.4f}\")\n",
    "print(f\"Max: {submission['requester_received_pizza'].max():.4f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
