{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dbcda24",
   "metadata": {},
   "source": [
    "# AutoGluon Multimodal Model\n",
    "\n",
    "Using AutoGluon's TabularPredictor with multimodal features:\n",
    "- Text features: request_title, request_text, request_text_edit_aware\n",
    "- Categorical: requester_user_flair\n",
    "- Numeric: all other features\n",
    "- Handles class imbalance automatically\n",
    "- Uses ensemble of multiple models including text transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e56eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T00:54:07.075631Z",
     "iopub.status.busy": "2026-01-10T00:54:07.074539Z",
     "iopub.status.idle": "2026-01-10T00:54:07.082178Z",
     "shell.execute_reply": "2026-01-10T00:54:07.081093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create experiments directory\n",
    "Path('/home/code/experiments').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Loading data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb1147d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T01:08:48.932578Z",
     "iopub.status.busy": "2026-01-10T01:08:48.931818Z",
     "iopub.status.idle": "2026-01-10T01:08:49.101834Z",
     "shell.execute_reply": "2026-01-10T01:08:49.101059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (4040, 32)\n",
      "Test data shape: (1631, 17)\n",
      "\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    3046\n",
      "True      994\n",
      "Name: count, dtype: int64\n",
      "Positive rate: 0.246\n"
     ]
    }
   ],
   "source": [
    "# Load training data - file appears to be a JSON array, not line-delimited\n",
    "import json\n",
    "\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    # Try to load as a single JSON array\n",
    "    try:\n",
    "        train_data = json.load(f)\n",
    "    except:\n",
    "        # If that fails, try line-delimited\n",
    "        f.seek(0)\n",
    "        train_data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "\n",
    "# Load test data\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    try:\n",
    "        test_data = json.load(f)\n",
    "    except:\n",
    "        f.seek(0)\n",
    "        test_data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Check target distribution\n",
    "target = 'requester_received_pizza'\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train_df[target].value_counts())\n",
    "print(f\"Positive rate: {train_df[target].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81368f6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T01:08:49.104639Z",
     "iopub.status.busy": "2026-01-10T01:08:49.103904Z",
     "iopub.status.idle": "2026-01-10T01:08:51.876691Z",
     "shell.execute_reply": "2026-01-10T01:08:51.875994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon is available\n"
     ]
    }
   ],
   "source": [
    "# Install AutoGluon if not available\n",
    "try:\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "    print(\"AutoGluon is available\")\n",
    "except ImportError:\n",
    "    print(\"Installing AutoGluon...\")\n",
    "    !pip install -q autogluon\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "    print(\"AutoGluon installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b4210f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T01:08:51.878913Z",
     "iopub.status.busy": "2026-01-10T01:08:51.878445Z",
     "iopub.status.idle": "2026-01-10T01:08:51.884384Z",
     "shell.execute_reply": "2026-01-10T01:08:51.883780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 29 features\n",
      "Feature types:\n",
      "  number_of_downvotes_of_request_at_retrieval: int64\n",
      "  number_of_upvotes_of_request_at_retrieval: int64\n",
      "  post_was_edited: object\n",
      "  request_number_of_comments_at_retrieval: int64\n",
      "  request_text: object\n",
      "  request_text_edit_aware: object\n",
      "  request_title: object\n",
      "  requester_account_age_in_days_at_request: float64\n",
      "  requester_account_age_in_days_at_retrieval: float64\n",
      "  requester_days_since_first_post_on_raop_at_request: float64\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Prepare data - AutoGluon can handle text directly\n",
    "# Keep all features, let AutoGluon handle the preprocessing\n",
    "\n",
    "# Define feature columns (exclude ID columns and target)\n",
    "exclude_cols = ['request_id', 'requester_received_pizza', 'giver_username_if_known']\n",
    "feature_cols = [col for col in train_df.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features\")\n",
    "print(f\"Feature types:\")\n",
    "for col in feature_cols[:10]:\n",
    "    print(f\"  {col}: {train_df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f2a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure AutoGluon for class imbalance\n",
    "# Use 'best_quality' preset for maximum performance\n",
    "# Set time limit to avoid running too long\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=target,\n",
    "    problem_type='binary',\n",
    "    eval_metric='roc_auc',  # Good for imbalanced classification\n",
    "    path='/home/code/experiments/autogluon_models'\n",
    ").fit(\n",
    "    train_data=train_df[feature_cols + [target]],\n",
    "    presets='best_quality',\n",
    "    time_limit=1200,  # 20 minutes\n",
    "    verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a04631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cross-validation scores\n",
    "cv_results = predictor.fit_summary()\n",
    "print(\"\\nCross-validation results:\")\n",
    "print(f\"Best model: {cv_results['model_best']}\")\n",
    "print(f\"Best validation score: {cv_results['val_score']:.4f}\")\n",
    "\n",
    "# Get leaderboard\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "print(\"\\nModel leaderboard:\")\n",
    "print(leaderboard[['model', 'score_val', 'pred_time_val']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e863f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "test_predictions = predictor.predict_proba(test_df[feature_cols])[[1]]  # Get probability of positive class\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "\n",
    "# Check prediction distribution\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(f\"Mean: {submission['requester_received_pizza'].mean():.4f}\")\n",
    "print(f\"Std: {submission['requester_received_pizza'].std():.4f}\")\n",
    "print(f\"Min: {submission['requester_received_pizza'].min():.4f}\")\n",
    "print(f\"Max: {submission['requester_received_pizza'].max():.4f}\")\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_autogluon.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
