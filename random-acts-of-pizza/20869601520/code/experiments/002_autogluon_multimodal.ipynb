{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dbcda24",
   "metadata": {},
   "source": [
    "# AutoGluon Multimodal Model\n",
    "\n",
    "Using AutoGluon's TabularPredictor with multimodal features:\n",
    "- Text features: request_title, request_text, request_text_edit_aware\n",
    "- Categorical: requester_user_flair\n",
    "- Numeric: all other features\n",
    "- Handles class imbalance automatically\n",
    "- Uses ensemble of multiple models including text transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27e56eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T01:57:49.296210Z",
     "iopub.status.busy": "2026-01-10T01:57:49.295531Z",
     "iopub.status.idle": "2026-01-10T01:57:49.300331Z",
     "shell.execute_reply": "2026-01-10T01:57:49.299730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create experiments directory\n",
    "Path('/home/code/experiments').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Loading data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fb1147d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T01:58:04.380087Z",
     "iopub.status.busy": "2026-01-10T01:58:04.379317Z",
     "iopub.status.idle": "2026-01-10T01:58:04.516692Z",
     "shell.execute_reply": "2026-01-10T01:58:04.516065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (4040, 32)\n",
      "Test data shape: (1631, 17)\n",
      "\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    3046\n",
      "True      994\n",
      "Name: count, dtype: int64\n",
      "Positive rate: 0.246\n"
     ]
    }
   ],
   "source": [
    "# Load training data - file appears to be a JSON array, not line-delimited\n",
    "import json\n",
    "\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    # Try to load as a single JSON array\n",
    "    try:\n",
    "        train_data = json.load(f)\n",
    "    except:\n",
    "        # If that fails, try line-delimited\n",
    "        f.seek(0)\n",
    "        train_data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "\n",
    "# Load test data\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    try:\n",
    "        test_data = json.load(f)\n",
    "    except:\n",
    "        f.seek(0)\n",
    "        test_data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Check target distribution\n",
    "target = 'requester_received_pizza'\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train_df[target].value_counts())\n",
    "print(f\"Positive rate: {train_df[target].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81368f6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T01:58:19.550018Z",
     "iopub.status.busy": "2026-01-10T01:58:19.549716Z",
     "iopub.status.idle": "2026-01-10T01:58:19.555633Z",
     "shell.execute_reply": "2026-01-10T01:58:19.554946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13 features\n",
      "Features:\n",
      "  1. requester_account_age_in_days_at_request: float64\n",
      "  2. requester_days_since_first_post_on_raop_at_request: float64\n",
      "  3. requester_number_of_comments_at_request: int64\n",
      "  4. requester_number_of_comments_in_raop_at_request: int64\n",
      "  5. requester_number_of_posts_at_request: int64\n",
      "  6. requester_number_of_posts_on_raop_at_request: int64\n",
      "  7. requester_number_of_subreddits_at_request: int64\n",
      "  8. requester_upvotes_minus_downvotes_at_request: int64\n",
      "  9. requester_upvotes_plus_downvotes_at_request: int64\n",
      "  10. unix_timestamp_of_request: float64\n",
      "  11. request_text_edit_aware: object\n",
      "  12. request_title: object\n",
      "  13. requester_subreddits_at_request: object\n"
     ]
    }
   ],
   "source": [
    "# Define features - only use columns available in BOTH train and test\n",
    "# Test set only has \"at_request\" features, not \"at_retrieval\" features\n",
    "feature_cols = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request', \n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'unix_timestamp_of_request',\n",
    "    # Text features\n",
    "    'request_text_edit_aware',\n",
    "    'request_title',\n",
    "    'requester_subreddits_at_request'\n",
    "]\n",
    "\n",
    "# Target column\n",
    "target = 'requester_received_pizza'\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features\")\n",
    "print(\"Features:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {col}: {train_df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0b4210f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T01:58:29.165696Z",
     "iopub.status.busy": "2026-01-10T01:58:29.165371Z",
     "iopub.status.idle": "2026-01-10T01:58:29.181276Z",
     "shell.execute_reply": "2026-01-10T01:58:29.180531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "int64      7\n",
      "float64    3\n",
      "object     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Object columns (3):\n",
      "  request_text_edit_aware: <class 'str'> - Hi I am in need of food for my 4 children we are a military family that has really hit hard times an...\n",
      "  request_title: <class 'str'> - Request Colorado Springs Help Us Please...\n",
      "  requester_subreddits_at_request: <class 'list'> - []...\n",
      "\n",
      "Converted requester_subreddits_at_request from list to string\n"
     ]
    }
   ],
   "source": [
    "# Check data types for the selected features\n",
    "print(\"Data types:\")\n",
    "print(train_df[feature_cols].dtypes.value_counts())\n",
    "\n",
    "# Check for object columns that might contain lists\n",
    "object_cols = train_df[feature_cols].select_dtypes(include=['object']).columns\n",
    "print(f\"\\nObject columns ({len(object_cols)}):\")\n",
    "for col in object_cols:\n",
    "    sample_val = train_df[col].iloc[0]\n",
    "    print(f\"  {col}: {type(sample_val)} - {str(sample_val)[:100]}...\")\n",
    "    \n",
    "# Convert list columns to string representation\n",
    "list_col = 'requester_subreddits_at_request'\n",
    "if list_col in feature_cols:\n",
    "    train_df[list_col] = train_df[list_col].apply(lambda x: ','.join(x) if isinstance(x, list) else str(x))\n",
    "    test_df[list_col] = test_df[list_col].apply(lambda x: ','.join(x) if isinstance(x, list) else str(x))\n",
    "    print(f\"\\nConverted {list_col} from list to string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d6aa0d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T01:58:39.761175Z",
     "iopub.status.busy": "2026-01-10T01:58:39.760446Z",
     "iopub.status.idle": "2026-01-10T01:58:39.771604Z",
     "shell.execute_reply": "2026-01-10T01:58:39.770877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "int64      7\n",
      "float64    3\n",
      "object     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Object columns (3):\n",
      "  request_text_edit_aware: <class 'str'> - Hi I am in need of food for my 4 children we are a military family that has really hit hard times an...\n",
      "  request_title: <class 'str'> - Request Colorado Springs Help Us Please...\n",
      "  requester_subreddits_at_request: <class 'str'> - ...\n",
      "\n",
      "No list columns found\n"
     ]
    }
   ],
   "source": [
    "# Import AutoGluon\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "print(\"AutoGluon imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f2a8bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T02:06:36.008904Z",
     "iopub.status.busy": "2026-01-10T02:06:36.008564Z",
     "iopub.status.idle": "2026-01-10T02:07:24.813986Z",
     "shell.execute_reply": "2026-01-10T02:07:24.813387Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #21~24.04.1-Ubuntu SMP Fri Oct 17 00:56:30 UTC 2025\n",
      "CPU Count:          12\n",
      "Pytorch Version:    2.9.1+cu128\n",
      "CUDA Version:       12.8\n",
      "GPU Memory:         GPU 0: 79.25/79.25 GB\n",
      "Total GPU Memory:   Free: 79.25 GB, Allocated: 0.00 GB, Total: 79.25 GB\n",
      "GPU Count:          1\n",
      "Memory Avail:       160.18 GB / 167.04 GB (95.9%)\n",
      "Disk Space Avail:   938.67 GB / 3389.36 GB (27.7%)\n",
      "===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['medium_quality_faster_train']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 600s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoGluon will save models to \"/home/code/experiments/autogluon_models_v2\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Data Rows:    4040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Data Columns: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label Column:       requester_received_pizza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Problem Type:       binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Feature Generators to preprocess the data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting AutoMLPipelineFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tAvailable Memory:                    164028.33 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Original)  Memory Usage: 3.58 MB (0.0% of available memory)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 1 Generators:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tFitting AsTypeFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 2 Generators:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tFitting FillNaFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 3 Generators:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tFitting IdentityFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tFitting CategoryFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tFitting TextSpecialFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\tFitting BinnedFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tFitting TextNgramFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\tFitting CountVectorizer for text features: ['request_text_edit_aware', 'request_title']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\tCountVectorizer fit with vocabulary size = 2442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 4 Generators:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tFitting DropUniqueFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 5 Generators:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tFitting DropDuplicatesFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTypes of features in original data (raw dtype, special dtypes):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t('float', [])        : 3 | ['requester_account_age_in_days_at_request', 'requester_days_since_first_post_on_raop_at_request', 'unix_timestamp_of_request']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t('int', [])          : 7 | ['requester_number_of_comments_at_request', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_posts_at_request', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t('object', [])       : 1 | ['requester_subreddits_at_request']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t('object', ['text']) : 2 | ['request_text_edit_aware', 'request_title']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTypes of features in processed data (raw dtype, special dtypes):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t('category', [])                    :    1 | ['requester_subreddits_at_request']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t('category', ['text_as_category'])  :    2 | ['request_text_edit_aware', 'request_title']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t('float', [])                       :    3 | ['requester_account_age_in_days_at_request', 'requester_days_since_first_post_on_raop_at_request', 'unix_timestamp_of_request']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t('int', [])                         :    7 | ['requester_number_of_comments_at_request', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_posts_at_request', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t('int', ['binned', 'text_special']) :   56 | ['request_text_edit_aware.char_count', 'request_text_edit_aware.word_count', 'request_text_edit_aware.capital_ratio', 'request_text_edit_aware.lower_ratio', 'request_text_edit_aware.digit_ratio', ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t('int', ['text_ngram'])             : 2430 | ['__nlp__.10', '__nlp__.100', '__nlp__.11', '__nlp__.12', '__nlp__.15', ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t5.0s = Fit runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t13 features in original data used to generate 2499 features in processed data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 19.26 MB (0.0% of available memory)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data preprocessing and feature engineering runtime = 5.19s ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTo change this, specify the eval_metric parameter of Predictor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatically generating train/validation split with holdout_frac=0.1238, Train Rows: 3539, Val Rows: 501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBMXT ... Training model for up to 594.81s of the 594.81s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting with cpus=6, gpus=0, mem=0.5/160.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7086\t = Validation score   (roc_auc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t2.06s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBM ... Training model for up to 592.73s of the 592.73s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting with cpus=6, gpus=0, mem=0.5/160.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6986\t = Validation score   (roc_auc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t2.06s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestGini ... Training model for up to 590.64s of the 590.64s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting with cpus=12, gpus=0, mem=0.0/160.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6849\t = Validation score   (roc_auc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t1.97s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.08s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestEntr ... Training model for up to 588.55s of the 588.55s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting with cpus=12, gpus=0, mem=0.0/160.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6932\t = Validation score   (roc_auc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t1.89s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.08s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: CatBoost ... Training model for up to 586.54s of the 586.54s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting with cpus=6, gpus=0, mem=2.6/160.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6874\t = Validation score   (roc_auc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t7.98s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.36s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: ExtraTreesGini ... Training model for up to 578.19s of the 578.19s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting with cpus=12, gpus=0, mem=0.0/159.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6643\t = Validation score   (roc_auc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t2.02s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.08s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: ExtraTreesEntr ... Training model for up to 576.04s of the 576.04s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting with cpus=12, gpus=0, mem=0.0/159.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6518\t = Validation score   (roc_auc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t1.97s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.08s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: NeuralNetFastAI ... Training model for up to 573.95s of the 573.95s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting with cpus=6, gpus=0, mem=0.2/159.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 7: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6463\t = Validation score   (roc_auc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t3.69s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: XGBoost ... Training model for up to 570.23s of the 570.23s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting with cpus=6, gpus=0, mem=1.0/159.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6949\t = Validation score   (roc_auc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t5.06s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.03s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: NeuralNetTorch ... Training model for up to 565.13s of the 565.13s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting with cpus=6, gpus=0, mem=0.1/159.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6563\t = Validation score   (roc_auc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t7.89s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.03s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBMLarge ... Training model for up to 557.20s of the 557.20s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting with cpus=6, gpus=0, mem=2.0/159.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6923\t = Validation score   (roc_auc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t5.13s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.02s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 552.04s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting 1 model on all data | Fitting with cpus=12, gpus=0, mem=0.0/159.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tEnsemble Weights: {'LightGBMXT': 0.56, 'RandomForestEntr': 0.2, 'XGBoost': 0.12, 'ExtraTreesGini': 0.08, 'NeuralNetFastAI': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7157\t = Validation score   (roc_auc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.06s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.0s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoGluon training complete, total runtime = 48.1s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2228.5 rows/s (501 batch size)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/code/experiments/autogluon_models_v2\")\n"
     ]
    }
   ],
   "source": [
    "# Configure AutoGluon for class imbalance\n",
    "# Use 'medium_quality_faster_train' preset for faster training\n",
    "# Set time limit to avoid running too long\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=target,\n",
    "    problem_type='binary',\n",
    "    eval_metric='roc_auc',  # Good for imbalanced classification\n",
    "    path='/home/code/experiments/autogluon_models_v2'\n",
    ").fit(\n",
    "    train_data=train_df[feature_cols + [target]],\n",
    "    presets='medium_quality_faster_train',\n",
    "    time_limit=600,  # 10 minutes\n",
    "    verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a04631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "test_predictions = predictor.predict_proba(test_df[feature_cols])\n",
    "\n",
    "# Get the probability for the positive class (True)\n",
    "if isinstance(test_predictions, pd.DataFrame):\n",
    "    # AutoGluon returns a DataFrame with columns for each class\n",
    "    positive_class = predictor.positive_class\n",
    "    test_pred_proba = test_predictions[positive_class]\n",
    "else:\n",
    "    # If it's a Series or array\n",
    "    test_pred_proba = test_predictions\n",
    "\n",
    "print(f\"Test predictions shape: {test_pred_proba.shape}\")\n",
    "print(f\"Test predictions sample:\\n{test_pred_proba.head()}\")\n",
    "\n",
    "# Get leaderboard to see model performance\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "print(\"\\nLeaderboard (top 5 models):\")\n",
    "print(leaderboard.head())\n",
    "\n",
    "# Get the best model's validation score\n",
    "best_model_score = leaderboard.iloc[0]['score_val']\n",
    "print(f\"\\nBest model validation score: {best_model_score:.4f}\")\n",
    "\n",
    "# Create submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_pred_proba\n",
    "})\n",
    "\n",
    "print(f\"\\nSubmission shape: {submission_df.shape}\")\n",
    "print(f\"Submission sample:\\n{submission_df.head()}\")\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/autogluon_submission.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e863f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "test_predictions = predictor.predict_proba(test_df[feature_cols])[[1]]  # Get probability of positive class\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "\n",
    "# Check prediction distribution\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(f\"Mean: {submission['requester_received_pizza'].mean():.4f}\")\n",
    "print(f\"Std: {submission['requester_received_pizza'].std():.4f}\")\n",
    "print(f\"Min: {submission['requester_received_pizza'].min():.4f}\")\n",
    "print(f\"Max: {submission['requester_received_pizza'].max():.4f}\")\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_autogluon.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5059b74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T01:34:26.039273Z",
     "iopub.status.busy": "2026-01-10T01:34:26.038760Z",
     "iopub.status.idle": "2026-01-10T01:34:26.046555Z",
     "shell.execute_reply": "2026-01-10T01:34:26.045396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n",
      "\n",
      "Test columns: ['giver_username_if_known', 'request_id', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_days_since_first_post_on_raop_at_request', 'requester_number_of_comments_at_request', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_posts_at_request', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_request', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n",
      "\n",
      "Missing from test: {'post_was_edited', 'requester_account_age_in_days_at_retrieval', 'request_text', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_user_flair', 'requester_days_since_first_post_on_raop_at_retrieval', 'request_number_of_comments_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'requester_number_of_posts_at_retrieval', 'requester_number_of_comments_at_retrieval', 'number_of_downvotes_of_request_at_retrieval', 'requester_upvotes_minus_downvotes_at_retrieval'}\n",
      "\n",
      "Extra in test: set()\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check what columns are available in test set\n",
    "print(\"Train columns:\", train_df.columns.tolist())\n",
    "print(\"\\nTest columns:\", test_df.columns.tolist())\n",
    "print(\"\\nMissing from test:\", set(feature_cols) - set(test_df.columns))\n",
    "print(\"\\nExtra in test:\", set(test_df.columns) - set(train_df.columns))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
