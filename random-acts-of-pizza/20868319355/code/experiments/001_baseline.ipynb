{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75efac83",
   "metadata": {},
   "source": [
    "# Baseline Experiment - Random Acts of Pizza\n",
    "\n",
    "## Strategy\n",
    "- Combine text features (title + text) with numerical/categorical features\n",
    "- Use TF-IDF for text representation\n",
    "- Use LightGBM for classification\n",
    "- 5-fold stratified cross-validation\n",
    "- Evaluate with AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7639467d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:58:28.516577Z",
     "iopub.status.busy": "2026-01-09T23:58:28.516330Z",
     "iopub.status.idle": "2026-01-09T23:58:29.404162Z",
     "shell.execute_reply": "2026-01-09T23:58:29.403525Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "496906a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:58:29.406183Z",
     "iopub.status.busy": "2026-01-09T23:58:29.405795Z",
     "iopub.status.idle": "2026-01-09T23:58:29.519188Z",
     "shell.execute_reply": "2026-01-09T23:58:29.518749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n",
      "Training samples: 2878\n",
      "Test samples: 1162\n",
      "Positive rate in training: 0.248\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "from scipy.sparse import hstack\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Load data\n",
    "print(\"Loading training data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "\n",
    "# Extract labels\n",
    "train_labels = [item['requester_received_pizza'] for item in train_data]\n",
    "print(f\"Positive rate in training: {sum(train_labels)/len(train_labels):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a71100a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:58:29.520427Z",
     "iopub.status.busy": "2026-01-09T23:58:29.520068Z",
     "iopub.status.idle": "2026-01-09T23:58:29.541939Z",
     "shell.execute_reply": "2026-01-09T23:58:29.541558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to DataFrames...\n",
      "Training DataFrame shape: (2878, 32)\n",
      "Test DataFrame shape: (1162, 17)\n",
      "\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    2163\n",
      "True      715\n",
      "Name: count, dtype: int64\n",
      "Positive rate: 0.248\n",
      "\n",
      "Columns in train but not in test:\n",
      "{'requester_received_pizza', 'number_of_upvotes_of_request_at_retrieval', 'requester_number_of_posts_on_raop_at_retrieval', 'request_text', 'requester_user_flair', 'requester_upvotes_minus_downvotes_at_retrieval', 'request_number_of_comments_at_retrieval', 'post_was_edited', 'requester_number_of_posts_at_retrieval', 'requester_account_age_in_days_at_retrieval', 'number_of_downvotes_of_request_at_retrieval', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_comments_at_retrieval'}\n",
      "\n",
      "Columns in test but not in train:\n",
      "set()\n",
      "Added missing column 'number_of_upvotes_of_request_at_retrieval' to test data with default value: 0\n",
      "Added missing column 'requester_number_of_posts_on_raop_at_retrieval' to test data with default value: 0\n",
      "Added missing column 'request_text' to test data with default value: \n",
      "Added missing column 'requester_user_flair' to test data with default value: \n",
      "Added missing column 'requester_upvotes_minus_downvotes_at_retrieval' to test data with default value: 0\n",
      "Added missing column 'request_number_of_comments_at_retrieval' to test data with default value: 0\n",
      "Added missing column 'post_was_edited' to test data with default value: \n",
      "Added missing column 'requester_number_of_posts_at_retrieval' to test data with default value: 0\n",
      "Added missing column 'requester_account_age_in_days_at_retrieval' to test data with default value: 0\n",
      "Added missing column 'number_of_downvotes_of_request_at_retrieval' to test data with default value: 0\n",
      "Added missing column 'requester_days_since_first_post_on_raop_at_retrieval' to test data with default value: 0\n",
      "Added missing column 'requester_upvotes_plus_downvotes_at_retrieval' to test data with default value: 0\n",
      "Added missing column 'requester_number_of_comments_in_raop_at_retrieval' to test data with default value: 0\n",
      "Added missing column 'requester_number_of_comments_at_retrieval' to test data with default value: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert JSON data to DataFrames for easier manipulation\n",
    "print(\"Converting to DataFrames...\")\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"Training DataFrame shape: {train_df.shape}\")\n",
    "print(f\"Test DataFrame shape: {test_df.shape}\")\n",
    "\n",
    "# Show basic info about the target\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train_df['requester_received_pizza'].value_counts())\n",
    "print(f\"Positive rate: {train_df['requester_received_pizza'].mean():.3f}\")\n",
    "\n",
    "# Debug: Check column differences\n",
    "print(\"\\nColumns in train but not in test:\")\n",
    "train_cols = set(train_df.columns)\n",
    "test_cols = set(test_df.columns)\n",
    "missing_in_test = train_cols - test_cols\n",
    "print(missing_in_test)\n",
    "\n",
    "print(\"\\nColumns in test but not in train:\")\n",
    "missing_in_train = test_cols - train_cols\n",
    "print(missing_in_train)\n",
    "\n",
    "# Add missing columns to test data with default values\n",
    "for col in missing_in_test:\n",
    "    if col == 'requester_received_pizza':\n",
    "        continue  # This is the target, don't add to test\n",
    "    \n",
    "    # Determine appropriate default value\n",
    "    if train_df[col].dtype in ['int64', 'float64']:\n",
    "        default_val = 0\n",
    "    elif train_df[col].dtype == 'bool':\n",
    "        default_val = False\n",
    "    else:\n",
    "        default_val = ''\n",
    "    \n",
    "    test_df[col] = default_val\n",
    "    print(f\"Added missing column '{col}' to test data with default value: {default_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d982b36f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:58:29.543109Z",
     "iopub.status.busy": "2026-01-09T23:58:29.542899Z",
     "iopub.status.idle": "2026-01-09T23:58:29.561680Z",
     "shell.execute_reply": "2026-01-09T23:58:29.561342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features...\n",
      "Checking for missing text fields in training data...\n",
      "Missing request_text in train: 0\n",
      "Missing request_title in train: 0\n",
      "Checking for missing text fields in test data...\n",
      "Missing request_text in test: 0\n",
      "Missing request_title in test: 0\n",
      "Feature engineering completed!\n"
     ]
    }
   ],
   "source": [
    "# Basic feature engineering\n",
    "print(\"Creating features...\")\n",
    "\n",
    "# Debug: Check for missing text fields\n",
    "print(\"Checking for missing text fields in training data...\")\n",
    "missing_text_train = train_df['request_text'].isna().sum()\n",
    "missing_title_train = train_df['request_title'].isna().sum()\n",
    "print(f\"Missing request_text in train: {missing_text_train}\")\n",
    "print(f\"Missing request_title in train: {missing_title_train}\")\n",
    "\n",
    "print(\"Checking for missing text fields in test data...\")\n",
    "missing_text_test = test_df['request_text'].isna().sum() if 'request_text' in test_df.columns else len(test_df)\n",
    "missing_title_test = test_df['request_title'].isna().sum() if 'request_title' in test_df.columns else len(test_df)\n",
    "print(f\"Missing request_text in test: {missing_text_test}\")\n",
    "print(f\"Missing request_title in test: {missing_title_test}\")\n",
    "\n",
    "# Handle missing columns in test data\n",
    "if 'request_text' not in test_df.columns:\n",
    "    test_df['request_text'] = ''\n",
    "if 'request_title' not in test_df.columns:\n",
    "    test_df['request_title'] = ''\n",
    "\n",
    "# Fill missing values\n",
    "train_df['request_text'] = train_df['request_text'].fillna('')\n",
    "train_df['request_title'] = train_df['request_title'].fillna('')\n",
    "test_df['request_text'] = test_df['request_text'].fillna('')\n",
    "test_df['request_title'] = test_df['request_title'].fillna('')\n",
    "\n",
    "# Text features\n",
    "train_df['combined_text'] = train_df['request_title'] + ' ' + train_df['request_text']\n",
    "test_df['combined_text'] = test_df['request_title'] + ' ' + test_df['request_text']\n",
    "\n",
    "# Length features\n",
    "train_df['title_length'] = train_df['request_title'].str.len()\n",
    "train_df['text_length'] = train_df['request_text'].str.len()\n",
    "train_df['combined_length'] = train_df['combined_text'].str.len()\n",
    "\n",
    "test_df['title_length'] = test_df['request_title'].str.len()\n",
    "test_df['text_length'] = test_df['request_text'].str.len()\n",
    "test_df['combined_length'] = test_df['combined_text'].str.len()\n",
    "\n",
    "# Ratios - handle division by zero\n",
    "train_df['upvote_ratio'] = train_df['number_of_upvotes_of_request_at_retrieval'] / (train_df['number_of_upvotes_of_request_at_retrieval'] + train_df['number_of_downvotes_of_request_at_retrieval'] + 1)\n",
    "train_df['requester_vote_ratio'] = train_df['requester_upvotes_minus_downvotes_at_request'] / (train_df['requester_upvotes_plus_downvotes_at_request'] + 1)\n",
    "train_df['account_age_years'] = train_df['requester_account_age_in_days_at_request'] / 365.25\n",
    "\n",
    "test_df['upvote_ratio'] = test_df['number_of_upvotes_of_request_at_retrieval'] / (test_df['number_of_upvotes_of_request_at_retrieval'] + test_df['number_of_downvotes_of_request_at_retrieval'] + 1)\n",
    "test_df['requester_vote_ratio'] = test_df['requester_upvotes_minus_downvotes_at_request'] / (test_df['requester_upvotes_plus_downvotes_at_request'] + 1)\n",
    "test_df['account_age_years'] = test_df['requester_account_age_in_days_at_request'] / 365.25\n",
    "\n",
    "# Activity rates - handle division by zero\n",
    "train_df['comments_per_day'] = train_df['requester_number_of_comments_at_request'] / (train_df['requester_account_age_in_days_at_request'] + 1)\n",
    "train_df['posts_per_day'] = train_df['requester_number_of_posts_at_request'] / (train_df['requester_account_age_in_days_at_request'] + 1)\n",
    "train_df['subreddit_diversity'] = train_df['requester_number_of_subreddits_at_request'] / (train_df['requester_number_of_posts_at_request'] + 1)\n",
    "\n",
    "test_df['comments_per_day'] = test_df['requester_number_of_comments_at_request'] / (test_df['requester_account_age_in_days_at_request'] + 1)\n",
    "test_df['posts_per_day'] = test_df['requester_number_of_posts_at_request'] / (test_df['requester_account_age_in_days_at_request'] + 1)\n",
    "test_df['subreddit_diversity'] = test_df['requester_number_of_subreddits_at_request'] / (test_df['requester_number_of_posts_at_request'] + 1)\n",
    "\n",
    "print(\"Feature engineering completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b374ab0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:58:29.562620Z",
     "iopub.status.busy": "2026-01-09T23:58:29.562383Z",
     "iopub.status.idle": "2026-01-09T23:58:29.569009Z",
     "shell.execute_reply": "2026-01-09T23:58:29.568695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: 21\n",
      "Categorical features: 1\n"
     ]
    }
   ],
   "source": [
    "# Prepare numerical and categorical features\n",
    "print(f\"Numerical features: {len(numerical_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# Fill missing values in numerical features\n",
    "for col in numerical_features:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(0)\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = test_df[col].fillna(0)\n",
    "\n",
    "# No categorical features to encode since requester_user_flair is missing in test\n",
    "print(\"Feature preparation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e9891d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:30:59.598321Z",
     "iopub.status.busy": "2026-01-09T23:30:59.598224Z",
     "iopub.status.idle": "2026-01-09T23:30:59.923227Z",
     "shell.execute_reply": "2026-01-09T23:30:59.922821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (2878, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Prepare text features with TF-IDF\n",
    "print(\"Vectorizing text...\")\n",
    "\n",
    "# Use a subset of TF-IDF features to keep memory manageable\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit features for speed\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),  # Unigrams and bigrams\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "text_tfidf = vectorizer.fit_transform(train_df['combined_text'])\n",
    "print(f\"TF-IDF shape: {text_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b512d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:30:59.924402Z",
     "iopub.status.busy": "2026-01-09T23:30:59.924161Z",
     "iopub.status.idle": "2026-01-09T23:30:59.934568Z",
     "shell.execute_reply": "2026-01-09T23:30:59.934217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature matrix shape: (2878, 5022)\n",
      "Target shape: (2878,)\n"
     ]
    }
   ],
   "source": [
    "# Combine all features\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# Prepare numerical features as sparse matrix\n",
    "numerical_matrix = train_df[numerical_features + ['requester_user_flair_encoded']].values\n",
    "\n",
    "# Combine text TF-IDF with numerical features\n",
    "X = hstack([text_tfidf, numerical_matrix])\n",
    "X = csr_matrix(X)  # Convert to CSR for efficient row indexing\n",
    "y = train_df['requester_received_pizza'].values\n",
    "\n",
    "print(f\"Final feature matrix shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d16692b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:30:59.935668Z",
     "iopub.status.busy": "2026-01-09T23:30:59.935418Z",
     "iopub.status.idle": "2026-01-09T23:30:59.938208Z",
     "shell.execute_reply": "2026-01-09T23:30:59.937853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up cross-validation...\n",
      "Starting 5-fold cross-validation...\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation setup\n",
    "print(\"Setting up cross-validation...\")\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "\n",
    "print(f\"Starting {n_folds}-fold cross-validation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b6f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_folds}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    # Parameters (simplified for baseline)\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=500,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(50),\n",
    "            lgb.log_evaluation(0)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Calculate AUC\n",
    "    fold_auc = roc_auc_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_auc)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} AUC: {fold_auc:.4f}\")\n",
    "\n",
    "# Overall CV score\n",
    "mean_auc = np.mean(fold_scores)\n",
    "std_auc = np.std(fold_scores)\n",
    "print(f\"\\nCV Score: {mean_auc:.4f} Â± {std_auc:.4f}\")\n",
    "\n",
    "# OOF AUC\n",
    "oof_auc = roc_auc_score(y, oof_predictions)\n",
    "print(f\"OOF AUC: {oof_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac51fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Apply same feature engineering to test data\n",
    "print(\"Engineering test features...\")\n",
    "\n",
    "# Handle missing columns in test data (in case they weren't added earlier)\n",
    "if 'request_text' not in test_df.columns:\n",
    "    test_df['request_text'] = ''\n",
    "if 'request_title' not in test_df.columns:\n",
    "    test_df['request_title'] = ''\n",
    "\n",
    "# Fill missing values\n",
    "test_df['request_text'] = test_df['request_text'].fillna('')\n",
    "test_df['request_title'] = test_df['request_title'].fillna('')\n",
    "\n",
    "# Text features\n",
    "test_df['combined_text'] = test_df['request_title'] + ' ' + test_df['request_text']\n",
    "\n",
    "# Length features\n",
    "test_df['title_length'] = test_df['request_title'].str.len()\n",
    "test_df['text_length'] = test_df['request_text'].str.len()\n",
    "test_df['combined_length'] = test_df['combined_text'].str.len()\n",
    "\n",
    "# Ratios\n",
    "test_df['upvote_ratio'] = test_df['number_of_upvotes_of_request_at_retrieval'] / (test_df['number_of_upvotes_of_request_at_retrieval'] + test_df['number_of_downvotes_of_request_at_retrieval'] + 1)\n",
    "test_df['requester_vote_ratio'] = test_df['requester_upvotes_plus_downvotes_at_request'] / (test_df['requester_upvotes_plus_downvotes_at_request'] + 1)\n",
    "\n",
    "# Account age features\n",
    "test_df['account_age_years'] = test_df['requester_account_age_in_days_at_request'] / 365.25\n",
    "\n",
    "# Activity features\n",
    "test_df['comments_per_day'] = test_df['requester_number_of_comments_at_request'] / (test_df['requester_account_age_in_days_at_request'] + 1)\n",
    "test_df['posts_per_day'] = test_df['requester_number_of_posts_at_request'] / (test_df['requester_account_age_in_days_at_request'] + 1)\n",
    "test_df['subreddit_diversity'] = test_df['requester_number_of_subreddits_at_request'] / (test_df['requester_number_of_posts_at_request'] + 1)\n",
    "\n",
    "# Handle categorical features\n",
    "test_df['requester_user_flair'] = test_df['requester_user_flair'].fillna('missing')\n",
    "test_df['requester_user_flair_encoded'] = le.transform(test_df['requester_user_flair'])\n",
    "\n",
    "print(\"Test feature engineering completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af67d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test text with TF-IDF\n",
    "print(\"Transforming test text...\")\n",
    "test_text_tfidf = vectorizer.transform(test_df['combined_text'])\n",
    "\n",
    "# Prepare test numerical features\n",
    "test_numerical_matrix = test_df[numerical_features + ['requester_user_flair_encoded']].values\n",
    "\n",
    "# Combine test features\n",
    "X_test = hstack([test_text_tfidf, test_numerical_matrix])\n",
    "print(f\"Test feature matrix shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on full training data and predict on test set\n",
    "print(\"Training final model on full training data...\")\n",
    "\n",
    "final_train_data = lgb.Dataset(X, label=y)\n",
    "\n",
    "final_model = lgb.train(\n",
    "    params,\n",
    "    final_train_data,\n",
    "    num_boost_round=500,\n",
    "    valid_sets=[final_train_data],\n",
    "    callbacks=[\n",
    "        lgb.log_evaluation(0)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Making predictions on test set...\")\n",
    "test_predictions = final_model.predict(X_test)\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission file saved to: {submission_path}\")\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(f\"Prediction distribution:\")\n",
    "print(submission_df['requester_received_pizza'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "711d8f0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T01:37:40.530146Z",
     "iopub.status.busy": "2026-01-10T01:37:40.529882Z",
     "iopub.status.idle": "2026-01-10T01:37:40.533834Z",
     "shell.execute_reply": "2026-01-10T01:37:40.533400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns:\n",
      "['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc', 'combined_text', 'title_length', 'text_length', 'combined_length', 'upvote_ratio', 'requester_vote_ratio', 'account_age_years', 'comments_per_day', 'posts_per_day', 'subreddit_diversity', 'requester_user_flair_encoded']\n",
      "\n",
      "Total train columns: 43\n",
      "\n",
      "Test columns:\n",
      "['giver_username_if_known', 'request_id', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_days_since_first_post_on_raop_at_request', 'requester_number_of_comments_at_request', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_posts_at_request', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_request', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc', 'request_text', 'combined_text', 'title_length', 'text_length', 'combined_length']\n",
      "\n",
      "Total test columns: 22\n",
      "\n",
      "Checking which numerical features exist in train:\n",
      "number_of_upvotes_of_request_at_retrieval: True\n",
      "number_of_downvotes_of_request_at_retrieval: True\n",
      "request_number_of_comments_at_retrieval: True\n",
      "requester_account_age_in_days_at_request: True\n",
      "requester_days_since_first_post_on_raop_at_request: True\n",
      "requester_number_of_comments_at_request: True\n",
      "requester_number_of_posts_at_request: True\n",
      "requester_number_of_comments_in_raop_at_request: True\n",
      "requester_number_of_posts_on_raop_at_request: True\n",
      "requester_number_of_subreddits_at_request: True\n",
      "requester_upvotes_minus_downvotes_at_request: True\n",
      "requester_upvotes_plus_downvotes_at_request: True\n",
      "title_length: True\n",
      "text_length: True\n",
      "combined_length: True\n",
      "upvote_ratio: True\n",
      "requester_vote_ratio: True\n",
      "account_age_years: True\n",
      "comments_per_day: True\n",
      "posts_per_day: True\n",
      "subreddit_diversity: True\n"
     ]
    }
   ],
   "source": [
    "# Check what columns actually exist in train and test\n",
    "print(\"Train columns:\")\n",
    "print(train_df.columns.tolist())\n",
    "print(f\"\\nTotal train columns: {len(train_df.columns)}\")\n",
    "\n",
    "print(\"\\nTest columns:\")\n",
    "print(test_df.columns.tolist())\n",
    "print(f\"\\nTotal test columns: {len(test_df.columns)}\")\n",
    "\n",
    "# Check which numerical features actually exist\n",
    "print(\"\\nChecking which numerical features exist in train:\")\n",
    "for col in numerical_features:\n",
    "    exists = col in train_df.columns\n",
    "    print(f\"{col}: {exists}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27006021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T01:38:02.226976Z",
     "iopub.status.busy": "2026-01-10T01:38:02.226704Z",
     "iopub.status.idle": "2026-01-10T01:38:02.230637Z",
     "shell.execute_reply": "2026-01-10T01:38:02.230206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features missing in test data:\n",
      "  number_of_upvotes_of_request_at_retrieval\n",
      "  number_of_downvotes_of_request_at_retrieval\n",
      "  request_number_of_comments_at_retrieval\n",
      "  upvote_ratio\n",
      "  requester_vote_ratio\n",
      "  account_age_years\n",
      "  comments_per_day\n",
      "  posts_per_day\n",
      "  subreddit_diversity\n",
      "\n",
      "Total missing: 9\n",
      "\n",
      "Categorical features in test:\n",
      "  requester_user_flair: False\n"
     ]
    }
   ],
   "source": [
    "# Check which features are missing in test\n",
    "print(\"Features missing in test data:\")\n",
    "missing_in_test = []\n",
    "for col in numerical_features:\n",
    "    if col not in test_df.columns:\n",
    "        missing_in_test.append(col)\n",
    "        print(f\"  {col}\")\n",
    "\n",
    "print(f\"\\nTotal missing: {len(missing_in_test)}\")\n",
    "\n",
    "# Also check for categorical features\n",
    "print(f\"\\nCategorical features in test:\")\n",
    "for col in categorical_features:\n",
    "    exists = col in test_df.columns\n",
    "    print(f\"  {col}: {exists}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bad1d4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T01:38:37.751605Z",
     "iopub.status.busy": "2026-01-10T01:38:37.751433Z",
     "iopub.status.idle": "2026-01-10T01:38:37.755534Z",
     "shell.execute_reply": "2026-01-10T01:38:37.755113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised numerical features: 12\n",
      "Revised categorical features: 0\n",
      "\n",
      "Verifying features exist in both datasets:\n",
      "  requester_account_age_in_days_at_request: train=True, test=True\n",
      "  requester_days_since_first_post_on_raop_at_request: train=True, test=True\n",
      "  requester_number_of_comments_at_request: train=True, test=True\n",
      "  requester_number_of_posts_at_request: train=True, test=True\n",
      "  requester_number_of_comments_in_raop_at_request: train=True, test=True\n",
      "  requester_number_of_posts_on_raop_at_request: train=True, test=True\n",
      "  requester_number_of_subreddits_at_request: train=True, test=True\n",
      "  requester_upvotes_minus_downvotes_at_request: train=True, test=True\n",
      "  requester_upvotes_plus_downvotes_at_request: train=True, test=True\n",
      "  title_length: train=True, test=True\n",
      "  text_length: train=True, test=True\n",
      "  combined_length: train=True, test=True\n"
     ]
    }
   ],
   "source": [
    "# Revised feature lists based on what's available in both train and test\n",
    "numerical_features = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'title_length',\n",
    "    'text_length',\n",
    "    'combined_length'\n",
    "]\n",
    "\n",
    "# Categorical features - requester_user_flair is missing in test, so we'll skip it\n",
    "categorical_features = []  # Empty for now\n",
    "\n",
    "print(f\"Revised numerical features: {len(numerical_features)}\")\n",
    "print(f\"Revised categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# Verify all features exist in both train and test\n",
    "print(\"\\nVerifying features exist in both datasets:\")\n",
    "for col in numerical_features:\n",
    "    train_exists = col in train_df.columns\n",
    "    test_exists = col in test_df.columns\n",
    "    print(f\"  {col}: train={train_exists}, test={test_exists}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
