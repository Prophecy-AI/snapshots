{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75efac83",
   "metadata": {},
   "source": [
    "# Baseline Experiment - Random Acts of Pizza\n",
    "\n",
    "## Strategy\n",
    "- Combine text features (title + text) with numerical/categorical features\n",
    "- Use TF-IDF for text representation\n",
    "- Use LightGBM for classification\n",
    "- 5-fold stratified cross-validation\n",
    "- Evaluate with AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7639467d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:30:58.558399Z",
     "iopub.status.busy": "2026-01-09T23:30:58.558091Z",
     "iopub.status.idle": "2026-01-09T23:30:59.506364Z",
     "shell.execute_reply": "2026-01-09T23:30:59.505904Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "496906a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:30:59.507727Z",
     "iopub.status.busy": "2026-01-09T23:30:59.507561Z",
     "iopub.status.idle": "2026-01-09T23:30:59.554272Z",
     "shell.execute_reply": "2026-01-09T23:30:59.553729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Number of training samples: 2878\n",
      "Keys in first sample: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_data)}\")\n",
    "print(f\"Keys in first sample: {list(train_data[0].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a71100a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:30:59.555420Z",
     "iopub.status.busy": "2026-01-09T23:30:59.555231Z",
     "iopub.status.idle": "2026-01-09T23:30:59.576740Z",
     "shell.execute_reply": "2026-01-09T23:30:59.576355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2878, 32)\n",
      "\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    2163\n",
      "True      715\n",
      "Name: count, dtype: int64\n",
      "Positive rate: 0.248\n"
     ]
    }
   ],
   "source": [
    "def extract_features(data):\n",
    "    \"\"\"Extract comprehensive features from pizza request data\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for item in data:\n",
    "        feat = {}\n",
    "        \n",
    "        # Get text - use request_text_edit_aware first, fall back to request_text\n",
    "        text = item.get('request_text_edit_aware', '') or item.get('request_text', '')\n",
    "        title = item.get('request_title', '')\n",
    "        full_text = f\"{title} {text}\" if title and text else (title or text)\n",
    "        \n",
    "        # Text features\n",
    "        feat['text_length'] = len(full_text) if full_text else 0\n",
    "        feat['word_count'] = len(full_text.split()) if full_text else 0\n",
    "        feat['char_count'] = len(full_text.replace(' ', '')) if full_text else 0\n",
    "        \n",
    "        # Sentiment indicators\n",
    "        positive_words = ['thank', 'thanks', 'appreciate', 'grateful', 'please', 'kind', 'generous', 'awesome', 'amazing', 'wonderful']\n",
    "        negative_words = ['desperate', 'starving', 'broke', 'hungry', 'broke', 'poor', 'suffering', 'depressed', 'suicidal', 'dying']\n",
    "        \n",
    "        text_lower = full_text.lower() if full_text else ''\n",
    "        feat['positive_word_count'] = sum(1 for word in positive_words if word in text_lower)\n",
    "        feat['negative_word_count'] = sum(1 for word in negative_words if word in text_lower)\n",
    "        feat['sentiment_score'] = feat['positive_word_count'] - feat['negative_word_count']\n",
    "        \n",
    "        # Punctuation and style\n",
    "        feat['exclamation_count'] = full_text.count('!') if full_text else 0\n",
    "        feat['question_count'] = full_text.count('?') if full_text else 0\n",
    "        feat['caps_count'] = sum(1 for c in full_text if c.isupper()) if full_text else 0\n",
    "        feat['caps_ratio'] = feat['caps_count'] / max(feat['char_count'], 1)\n",
    "        \n",
    "        # Requester account features\n",
    "        feat['account_age_days'] = item.get('requester_account_age_in_days_at_request', 0)\n",
    "        feat['account_age_years'] = feat['account_age_days'] / 365.25\n",
    "        feat['is_new_account'] = 1 if feat['account_age_days'] < 30 else 0\n",
    "        \n",
    "        # Posting history\n",
    "        feat['total_posts'] = item.get('requester_number_of_posts_at_request', 0)\n",
    "        feat['total_comments'] = item.get('requester_number_of_comments_at_request', 0)\n",
    "        feat['raop_posts'] = item.get('requester_number_of_posts_on_raop_at_request', 0)\n",
    "        feat['raop_comments'] = item.get('requester_number_of_comments_in_raop_at_request', 0)\n",
    "        \n",
    "        # Karma features\n",
    "        feat['upvotes_minus_downvotes'] = item.get('requester_upvotes_minus_downvotes_at_request', 0)\n",
    "        feat['upvotes_plus_downvotes'] = item.get('requester_upvotes_plus_downvotes_at_request', 0)\n",
    "        feat['karma_ratio'] = feat['upvotes_minus_downvotes'] / max(feat['upvotes_plus_downvotes'], 1)\n",
    "        \n",
    "        # Subreddit diversity\n",
    "        subreddits = item.get('requester_subreddits_at_request', [])\n",
    "        feat['num_subreddits'] = len(subreddits) if subreddits else 0\n",
    "        feat['has_diverse_subreddits'] = 1 if feat['num_subreddits'] > 10 else 0\n",
    "        \n",
    "        # Time features\n",
    "        timestamp = item.get('unix_timestamp_of_request_utc', 0)\n",
    "        if timestamp:\n",
    "            dt = datetime.fromtimestamp(timestamp)\n",
    "            feat['hour_of_day'] = dt.hour\n",
    "            feat['day_of_week'] = dt.weekday()\n",
    "            feat['is_weekend'] = 1 if dt.weekday() >= 5 else 0\n",
    "            feat['is_evening'] = 1 if 18 <= dt.hour <= 23 else 0\n",
    "        else:\n",
    "            feat['hour_of_day'] = 0\n",
    "            feat['day_of_week'] = 0\n",
    "            feat['is_weekend'] = 0\n",
    "            feat['is_evening'] = 0\n",
    "        \n",
    "        # Request metadata\n",
    "        feat['post_was_edited'] = 1 if item.get('post_was_edited', False) else 0\n",
    "        feat['title_length'] = len(title) if title else 0\n",
    "        feat['title_word_count'] = len(title.split()) if title else 0\n",
    "        \n",
    "        # Interaction features\n",
    "        feat['comments_per_post'] = feat['total_comments'] / max(feat['total_posts'], 1)\n",
    "        feat['karma_per_comment'] = feat['upvotes_minus_downvotes'] / max(feat['total_comments'], 1)\n",
    "        feat['karma_per_post'] = feat['upvotes_minus_downvotes'] / max(feat['total_posts'], 1)\n",
    "        \n",
    "        # Add all features to list\n",
    "        features.append(feat)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d982b36f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:30:59.577791Z",
     "iopub.status.busy": "2026-01-09T23:30:59.577528Z",
     "iopub.status.idle": "2026-01-09T23:30:59.589581Z",
     "shell.execute_reply": "2026-01-09T23:30:59.589232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features...\n",
      "Feature engineering completed!\n"
     ]
    }
   ],
   "source": [
    "# Basic feature engineering\n",
    "print(\"Creating features...\")\n",
    "\n",
    "# Text features - combine title and text\n",
    "train_df['combined_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text'].fillna('')\n",
    "\n",
    "# Length features\n",
    "train_df['title_length'] = train_df['request_title'].fillna('').str.len()\n",
    "train_df['text_length'] = train_df['request_text'].fillna('').str.len()\n",
    "train_df['combined_length'] = train_df['combined_text'].str.len()\n",
    "\n",
    "# Upvote/downvote ratios\n",
    "train_df['upvote_ratio'] = train_df['number_of_upvotes_of_request_at_retrieval'] / (train_df['number_of_upvotes_of_request_at_retrieval'] + train_df['number_of_downvotes_of_request_at_retrieval'] + 1)\n",
    "train_df['requester_vote_ratio'] = train_df['requester_upvotes_plus_downvotes_at_request'] / (train_df['requester_upvotes_plus_downvotes_at_request'] + 1)\n",
    "\n",
    "# Account age features (convert to years)\n",
    "train_df['account_age_years'] = train_df['requester_account_age_in_days_at_request'] / 365.25\n",
    "\n",
    "# Activity features\n",
    "train_df['comments_per_day'] = train_df['requester_number_of_comments_at_request'] / (train_df['requester_account_age_in_days_at_request'] + 1)\n",
    "train_df['posts_per_day'] = train_df['requester_number_of_posts_at_request'] / (train_df['requester_account_age_in_days_at_request'] + 1)\n",
    "\n",
    "# Subreddit diversity\n",
    "train_df['subreddit_diversity'] = train_df['requester_number_of_subreddits_at_request'] / (train_df['requester_number_of_posts_at_request'] + 1)\n",
    "\n",
    "print(\"Feature engineering completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b374ab0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:30:59.590527Z",
     "iopub.status.busy": "2026-01-09T23:30:59.590281Z",
     "iopub.status.idle": "2026-01-09T23:30:59.597530Z",
     "shell.execute_reply": "2026-01-09T23:30:59.597184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: 21\n",
      "Categorical features: 1\n"
     ]
    }
   ],
   "source": [
    "# Prepare numerical and categorical features\n",
    "numerical_features = [\n",
    "    'number_of_upvotes_of_request_at_retrieval',\n",
    "    'number_of_downvotes_of_request_at_retrieval', \n",
    "    'request_number_of_comments_at_retrieval',\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'title_length',\n",
    "    'text_length',\n",
    "    'combined_length',\n",
    "    'upvote_ratio',\n",
    "    'requester_vote_ratio',\n",
    "    'account_age_years',\n",
    "    'comments_per_day',\n",
    "    'posts_per_day',\n",
    "    'subreddit_diversity'\n",
    "]\n",
    "\n",
    "# Handle categorical features\n",
    "categorical_features = ['requester_user_flair']\n",
    "\n",
    "# Fill missing values\n",
    "for col in numerical_features:\n",
    "    train_df[col] = train_df[col].fillna(0)\n",
    "\n",
    "# Encode categorical features\n",
    "flair_encoder = LabelEncoder()\n",
    "train_df['requester_user_flair_encoded'] = flair_encoder.fit_transform(train_df['requester_user_flair'].fillna('None'))\n",
    "\n",
    "print(f\"Numerical features: {len(numerical_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e9891d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:30:59.598321Z",
     "iopub.status.busy": "2026-01-09T23:30:59.598224Z",
     "iopub.status.idle": "2026-01-09T23:30:59.923227Z",
     "shell.execute_reply": "2026-01-09T23:30:59.922821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (2878, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Prepare text features with TF-IDF\n",
    "print(\"Vectorizing text...\")\n",
    "\n",
    "# Use a subset of TF-IDF features to keep memory manageable\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit features for speed\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),  # Unigrams and bigrams\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "text_tfidf = vectorizer.fit_transform(train_df['combined_text'])\n",
    "print(f\"TF-IDF shape: {text_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b512d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:30:59.924402Z",
     "iopub.status.busy": "2026-01-09T23:30:59.924161Z",
     "iopub.status.idle": "2026-01-09T23:30:59.934568Z",
     "shell.execute_reply": "2026-01-09T23:30:59.934217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature matrix shape: (2878, 5022)\n",
      "Target shape: (2878,)\n"
     ]
    }
   ],
   "source": [
    "# Combine all features\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# Prepare numerical features as sparse matrix\n",
    "numerical_matrix = train_df[numerical_features + ['requester_user_flair_encoded']].values\n",
    "\n",
    "# Combine text TF-IDF with numerical features\n",
    "X = hstack([text_tfidf, numerical_matrix])\n",
    "X = csr_matrix(X)  # Convert to CSR for efficient row indexing\n",
    "y = train_df['requester_received_pizza'].values\n",
    "\n",
    "print(f\"Final feature matrix shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d16692b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T23:30:59.935668Z",
     "iopub.status.busy": "2026-01-09T23:30:59.935418Z",
     "iopub.status.idle": "2026-01-09T23:30:59.938208Z",
     "shell.execute_reply": "2026-01-09T23:30:59.937853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up cross-validation...\n",
      "Starting 5-fold cross-validation...\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation setup\n",
    "print(\"Setting up cross-validation...\")\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "\n",
    "print(f\"Starting {n_folds}-fold cross-validation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b6f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_folds}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    # Parameters (simplified for baseline)\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=500,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(50),\n",
    "            lgb.log_evaluation(0)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Calculate AUC\n",
    "    fold_auc = roc_auc_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_auc)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} AUC: {fold_auc:.4f}\")\n",
    "\n",
    "# Overall CV score\n",
    "mean_auc = np.mean(fold_scores)\n",
    "std_auc = np.std(fold_scores)\n",
    "print(f\"\\nCV Score: {mean_auc:.4f} Â± {std_auc:.4f}\")\n",
    "\n",
    "# OOF AUC\n",
    "oof_auc = roc_auc_score(y, oof_predictions)\n",
    "print(f\"OOF AUC: {oof_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac51fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Apply same feature engineering to test data\n",
    "print(\"Engineering test features...\")\n",
    "\n",
    "# Text features\n",
    "test_df['combined_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text'].fillna('')\n",
    "\n",
    "# Length features\n",
    "test_df['title_length'] = test_df['request_title'].fillna('').str.len()\n",
    "test_df['text_length'] = test_df['request_text'].fillna('').str.len()\n",
    "test_df['combined_length'] = test_df['combined_text'].str.len()\n",
    "\n",
    "# Ratios\n",
    "test_df['upvote_ratio'] = test_df['number_of_upvotes_of_request_at_retrieval'] / (test_df['number_of_upvotes_of_request_at_retrieval'] + test_df['number_of_downvotes_of_request_at_retrieval'] + 1)\n",
    "test_df['requester_vote_ratio'] = test_df['requester_upvotes_plus_downvotes_at_request'] / (test_df['requester_upvotes_plus_downvotes_at_request'] + 1)\n",
    "\n",
    "# Account age\n",
    "test_df['account_age_years'] = test_df['requester_account_age_in_days_at_request'] / 365.25\n",
    "\n",
    "# Activity features\n",
    "test_df['comments_per_day'] = test_df['requester_number_of_comments_at_request'] / (test_df['requester_account_age_in_days_at_request'] + 1)\n",
    "test_df['posts_per_day'] = test_df['requester_number_of_posts_at_request'] / (test_df['requester_account_age_in_days_at_request'] + 1)\n",
    "\n",
    "# Subreddit diversity\n",
    "test_df['subreddit_diversity'] = test_df['requester_number_of_subreddits_at_request'] / (test_df['requester_number_of_posts_at_request'] + 1)\n",
    "\n",
    "# Fill missing values\n",
    "for col in numerical_features:\n",
    "    test_df[col] = test_df[col].fillna(0)\n",
    "\n",
    "# Encode categorical features\n",
    "test_df['requester_user_flair_encoded'] = flair_encoder.transform(test_df['requester_user_flair'].fillna('None'))\n",
    "\n",
    "print(\"Test feature engineering completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af67d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test text with TF-IDF\n",
    "print(\"Transforming test text...\")\n",
    "test_text_tfidf = vectorizer.transform(test_df['combined_text'])\n",
    "\n",
    "# Prepare test numerical features\n",
    "test_numerical_matrix = test_df[numerical_features + ['requester_user_flair_encoded']].values\n",
    "\n",
    "# Combine test features\n",
    "X_test = hstack([test_text_tfidf, test_numerical_matrix])\n",
    "print(f\"Test feature matrix shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on full training data and predict on test set\n",
    "print(\"Training final model on full training data...\")\n",
    "\n",
    "final_train_data = lgb.Dataset(X, label=y)\n",
    "\n",
    "final_model = lgb.train(\n",
    "    params,\n",
    "    final_train_data,\n",
    "    num_boost_round=500,\n",
    "    valid_sets=[final_train_data],\n",
    "    callbacks=[\n",
    "        lgb.log_evaluation(0)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Making predictions on test set...\")\n",
    "test_predictions = final_model.predict(X_test)\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission file saved to: {submission_path}\")\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(f\"Prediction distribution:\")\n",
    "print(submission_df['requester_received_pizza'].describe())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
