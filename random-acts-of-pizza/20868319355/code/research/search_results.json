{
  "query": "What are effective feature engineering techniques for Reddit comment classification using user flair and engagement metrics?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Effective feature engineering for Reddit comment classification that leverages **user flair** and **engagement metrics** combines textual signals with rich metadata about the author and the comment\u2019s interaction history.  \n\nFirst, treat the flair as a categorical attribute that can be **one\u2011hot encoded** or, for higher\u2011dimensional models, transformed into dense embeddings (e.g., using\u202f`sklearn`\u202f`DictVectorizer` or\u202f`torch.nn.Embedding`). Because flairs often encode community\u2011specific roles (e.g., \u201cModerator\u201d, \u201cNewbie\u201d, \u201cExpert\u201d), they act as a strong prior about a user\u2019s likely posting style and can be concatenated with text\u2011based vectors (TF\u2011IDF, word2vec, BERT) before feeding the combined feature set to a classifier\u202f([GitHub \u2013 11\u2011aryan/Reddit\u2011Flair\u2011Classification](https://github.com/11-aryan/Reddit-Flair-Classification)).  \n\nSecond, extract **engagement metrics** that capture how the community reacts to a comment: up\u2011vote count, down\u2011vote count, net score, award count, reply depth, number of child comments, and the author\u2019s karma (both comment and link karma). Temporal features such as the hour of day, day of week, and elapsed time since the parent post also help model \u201crecency\u201d effects. These signals can be **standardized** and added as numeric columns alongside the text features. Research on Reddit endorsement shows that structural cues (reply tree depth, number of responses) and author reputation significantly improve prediction accuracy\u202f([ACL Anthology \u2013 Learning Latent Local Conversation Modes for Predicting Comment Endorsement](https://aclanthology.org/W16-6209.pdf);\u202f[Talking to the crowd: What do people react to in online discussions?](https://aclanthology.org/D15-1239.pdf)).  \n\nFinally, consider **interaction\u2011level features** that combine flair and engagement, such as \u201caverage score of previous comments by users with the same flair\u201d or \u201cflair\u2011specific up\u2011vote ratios\u201d. Feature\u2011crosses can be generated automatically with tools like\u202f`PolynomialFeatures`\u202for manually engineered for tree\u2011based models (e.g., XGBoost) that handle mixed categorical\u2011numeric data well. Open\u2011source notebooks (e.g., the Reddit up\u2011vote predictor repo) demonstrate how to merge PRAW\u2011scraped comment data with these engineered columns and achieve strong baseline performance\u202f([GitHub \u2013 Jacobjeevan/Reddit\u2011Upvote\u2011Predictor](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor)).  \n\nTogether, these techniques\u2014flair encoding, comprehensive engagement statistics, temporal/contextual cues, and cross\u2011features\u2014provide a robust foundation for classifying Reddit comments by topic, sentiment, or predicted popularity.",
      "url": ""
    },
    {
      "title": "GitHub - 11-aryan/Reddit-Flair-Classification: Classification of reddit flairs using a dataset generated by scraping Reddit data with PRAW",
      "text": "[Skip to content](https://github.com/11-aryan/Reddit-Flair-Classification#start-of-content)\n\nYou signed in with another tab or window. Reload to refresh your session.You signed out in another tab or window. Reload to refresh your session.You switched accounts on another tab or window. Reload to refresh your session.Dismiss alert\n\n{{ message }}\n\n[11-aryan](https://github.com/11-aryan)/ **[Reddit-Flair-Classification](https://github.com/11-aryan/Reddit-Flair-Classification)** Public\n\n- [Notifications](https://github.com/login?return_to=%2F11-aryan%2FReddit-Flair-Classification) You must be signed in to change notification settings\n- [Fork\\\n0](https://github.com/login?return_to=%2F11-aryan%2FReddit-Flair-Classification)\n- [Star\\\n0](https://github.com/login?return_to=%2F11-aryan%2FReddit-Flair-Classification)\n\n\nClassification of reddit flairs using a dataset generated by scraping Reddit data with PRAW\n\n[0\\\nstars](https://github.com/11-aryan/Reddit-Flair-Classification/stargazers) [0\\\nforks](https://github.com/11-aryan/Reddit-Flair-Classification/forks) [Branches](https://github.com/11-aryan/Reddit-Flair-Classification/branches) [Tags](https://github.com/11-aryan/Reddit-Flair-Classification/tags) [Activity](https://github.com/11-aryan/Reddit-Flair-Classification/activity)\n\n[Star](https://github.com/login?return_to=%2F11-aryan%2FReddit-Flair-Classification)\n\n[Notifications](https://github.com/login?return_to=%2F11-aryan%2FReddit-Flair-Classification) You must be signed in to change notification settings\n\n# 11-aryan/Reddit-Flair-Classification\n\nmain\n\n[Branches](https://github.com/11-aryan/Reddit-Flair-Classification/branches) [Tags](https://github.com/11-aryan/Reddit-Flair-Classification/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[29 Commits](https://github.com/11-aryan/Reddit-Flair-Classification/commits/main/) |\n| [Data](https://github.com/11-aryan/Reddit-Flair-Classification/tree/main/Data) | [Data](https://github.com/11-aryan/Reddit-Flair-Classification/tree/main/Data) |  |  |\n| [Images](https://github.com/11-aryan/Reddit-Flair-Classification/tree/main/Images) | [Images](https://github.com/11-aryan/Reddit-Flair-Classification/tree/main/Images) |  |  |\n| [Flair\\_Classification\\_1\\_Generating\\_Data.ipynb](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/Flair_Classification_1_Generating_Data.ipynb) | [Flair\\_Classification\\_1\\_Generating\\_Data.ipynb](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/Flair_Classification_1_Generating_Data.ipynb) |  |  |\n| [Flair\\_Classification\\_2\\_Training.ipynb](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/Flair_Classification_2_Training.ipynb) | [Flair\\_Classification\\_2\\_Training.ipynb](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/Flair_Classification_2_Training.ipynb) |  |  |\n| [Flair\\_Classification\\_BERT.ipynb](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/Flair_Classification_BERT.ipynb) | [Flair\\_Classification\\_BERT.ipynb](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/Flair_Classification_BERT.ipynb) |  |  |\n| [README.md](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/README.md) | [README.md](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/README.md) |  |  |\n| [preprocess\\_text\\_util.py](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/preprocess_text_util.py) | [preprocess\\_text\\_util.py](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/preprocess_text_util.py) |  |  |\n| [savedModel1.pkl](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/savedModel1.pkl) | [savedModel1.pkl](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/savedModel1.pkl) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Reddit-Flair-Classification\n\nEach Reddit post is tagged for filtering purposes. These tags are called **flairs** in the Reddit world.\n\nIn this project, a comparative data analysis using existing Machine Learning and Natural language processing techniques is provided to detect the flair of each Reddit post using the data generated by webscraping reddit using **PRAW** (Python Reddit API Wrapper).\n\nData analysis was done on the data using different features and a pipeline of various natural language processing techniques like _Count Vectorization_ and _Tfldf Transformation_, and various machine learning techniques like , _Decision Tree, Support Vector Machines (SVM), Logistic Regression, Naive-Bayes, pretrained BERT_, was used to research on the data, and classify the flairs\n\nLink to the web app: [https://reddit-flair-classification.onrender.com/](https://reddit-flair-classification.onrender.com/)\n\n(If the page shows error wait for sometime and reload the page)\n\n[![](https://user-images.githubusercontent.com/55359898/209970405-ca7c3c07-97da-4e3f-a255-9b26a6934d52.png)](https://user-images.githubusercontent.com/55359898/209970405-ca7c3c07-97da-4e3f-a255-9b26a6934d52.png)\n\n### Requirements:\n\n```\npython 3.7.1\npraw==6.5.1\npyqt5==5.7.1\nnltk==3.4.5\nFlask==1.0.2\nnumpy==1.16.4\ngunicorn==19.9.0\nJinja2==2.11.3\nWerkzeug==0.15.6\nMarkupSafe==1.1.1\nClick==7.0\nitsdangerous==1.1.0\nscikit-learn==0.22.2.post1\n\n```\n\n### Description of Jupyter Notebooks\n\n[Flair\\_Classification\\_1\\_Generating\\_Data.ipynb](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/Flair_Classification_1_Generating_Data.ipynb) : Contains the code to extract data from Reddit with PRAW and create the dataset.\n\n[Flair\\_Classification\\_2\\_Training.ipynb](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/Flair_Classification_2_Training.ipynb): Contains EDA and the comparison of the performances of different models on the data.\n\n[Flair\\_Classification\\_BERT.ipynb](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/Flair_Classification_BERT.ipynb): Using pretrained BERT from tensorflow hub.\nn\n\n### Generating the dataset\n\nThe data was generated using **PRAW** (Python Reddit API warpper) to extract data from reddit posts followed by text preprocessing.\nThere might be many types of flairs, but the **13** _most common flairs_ are used to train the data to avoid class imbalance. The final data has **100** samples of each flair, and a total of **1120** records.\n\nHere's a sample of the data:\n[![](https://github.com/11-aryan/Reddit-Flair-Classification/raw/main/Images/rfsampleData.png)](https://github.com/11-aryan/Reddit-Flair-Classification/blob/main/Images/rfsampleData.png)\n\n### Training Results\n\nThe following accuracy was obtained with different models:\n\n- Linear Regression: **0.5090**\n- Support Vector Machine: **0.5060**\n- Naive Bayes: **0.4818**\n- Decision Tree: **0.4909**\n- Random Forest: **0.5242**\n\n_Random Forest_ performed slightly better than others, but the accuracy is still quite low.\n\nUsing **BERT** to train on the text embeddings obtained from _Universal Sentence Encoder_ from tensorflow hub significantly improved the accuracy to **0.7095**\n\n## About\n\nClassification of reddit flairs using a dataset generated by scraping Reddit data with PRAW\n\n### Topics\n\n[python](https://github.com/topics/python) [machine-learning](https://github.com/topics/machine-learning) [natural-language-processing](https://github.com/topics/natural-language-processing) [reddit](https://github.com/topics/reddit) [text-classification](https://github.com/topics/text-classification) [scikit-learn](https://github.com/topics/scikit-learn) [reddit-api](https://github.com/topics/reddit-api) [classification](https://github.com/topics/classification) [dataset-generation](https://github.com/topics/dataset-generation) [webscraping](https://github.com/topics/webscraping) [bert](https://github.com/topics/bert)\n\n### Resources\n\n[Readme](https://github.com/11-aryan/Reddit-Flair-Classification#readme-ov-file)\n\n[Activity](https://g...",
      "url": "https://github.com/11-aryan/Reddit-Flair-Classification"
    },
    {
      "title": "GitHub - Jacobjeevan/Reddit-Upvote-Predictor: Text Analysis on Reddit Data",
      "text": "[Skip to content](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor#start-of-content)\n\nYou signed in with another tab or window. Reload to refresh your session.You signed out in another tab or window. Reload to refresh your session.You switched accounts on another tab or window. Reload to refresh your session.Dismiss alert\n\n{{ message }}\n\n[Jacobjeevan](https://github.com/Jacobjeevan)/ **[Reddit-Upvote-Predictor](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor)** Public\n\n- [Notifications](https://github.com/login?return_to=%2FJacobjeevan%2FReddit-Upvote-Predictor) You must be signed in to change notification settings\n- [Fork\\\n0](https://github.com/login?return_to=%2FJacobjeevan%2FReddit-Upvote-Predictor)\n- [Star\\\n0](https://github.com/login?return_to=%2FJacobjeevan%2FReddit-Upvote-Predictor)\n\n\nText Analysis on Reddit Data\n\n### License\n\n[MIT license](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/blob/master/LICENSE)\n\n[0\\\nstars](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/stargazers) [0\\\nforks](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/forks) [Branches](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/branches) [Tags](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/tags) [Activity](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/activity)\n\n[Star](https://github.com/login?return_to=%2FJacobjeevan%2FReddit-Upvote-Predictor)\n\n[Notifications](https://github.com/login?return_to=%2FJacobjeevan%2FReddit-Upvote-Predictor) You must be signed in to change notification settings\n\n# Jacobjeevan/Reddit-Upvote-Predictor\n\nmaster\n\n[Branches](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/branches) [Tags](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[34 Commits](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/commits/master/) |\n| [notebooks](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/tree/master/notebooks) | [notebooks](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/tree/master/notebooks) |  |  |\n| [src/data](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/tree/master/src/data) | [src/data](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/tree/master/src/data) |  |  |\n| [.gitignore](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/blob/master/.gitignore) | [.gitignore](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/blob/master/.gitignore) |  |  |\n| [LICENSE](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/blob/master/LICENSE) | [LICENSE](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/blob/master/LICENSE) |  |  |\n| [README.md](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/blob/master/README.md) | [README.md](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/blob/master/README.md) |  |  |\n| [requirements.txt](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/blob/master/requirements.txt) | [requirements.txt](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/blob/master/requirements.txt) |  |  |\n| [setup.sh](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/blob/master/setup.sh) | [setup.sh](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/blob/master/setup.sh) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Reddit Upvote Predictor\n\nReddit is a social news aggregation, web content rating, and discussion website. People registered on the website can submit content in links, text post, images, and as comments to other posts.\n\nSimilar to Facebook\u2019s likes and Twitter\u2019s favorites, Reddit has an upvote system where users are allowed to vote up or down on others\u2019 posts and comments.\n\n**So why reddit data?**\n\nWe chose reddit primarily because we wanted to explore our favorite movie subreddits. Initially we were thinking of doing sentiment analysis (and looking at change in sentiment over time, for instance: Ben Affleck's Batman casting), but had to reduce the scope due to the arduous task of manually labeling the data.\n\nSo we pivoted, and decided to design a model that would predict the number of upvotes a comment might receive.\n\nNotes:\n\nThe project started off as a term project for Natural Language Processing (CS 662); It was an open ended group project with another student. Work was divided across the models; My partner worked on SimpleTransformers model (currently not in this repo due to changes in the library), while I worked on FlairNLP and FastAI (currently removed from repo) based models; All work was initially pushed to Github classroom, moved to Github public for further development.\n\n## Current/Future Work:\n\nPopular NLP based models were used because of its relevance within the class. For future work, I would like to go back to basics:\n\n- Rework any existing code, fix bugs and repackage as python code\n- Get word vectors (Sklearn's Vectorizer methods) and use them to train simpler and more interpretable models such as Logistic Regression and SVM.\n- Repeat the same with word embeddings (Glove/Flair Embeddings)\n\n# Running:\n\n## Step 1: Clone from Github:\n\n> git clone [https://github.com/Jacobjeevan/Reddit-Upvote-Predictor](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor)\n\n## Step 2: Environment Setup:\n\n> Run setup.sh to setup Virtual environment and required dependencies.\n\n## Step 3: Setup Praw.ini\n\n> Create a developer app on reddit, get the client\\_id, client\\_secret and replace them in praw.ini file. Also replace username and password fields with respective credentials.\n\n## Step 4: Run fetch\\_dataset.py\n\n> Run fetch\\_dataset.py to scrape and save relevant information from user input subreddit.\n\n## Step 5: Run preprocess\\_dataset.py\n\n> Run preprocess\\_dataset.py to preprocess and clean the scraped data for training the models.\n\n## Step 6: Run notebooks\n\n> Run the notebooks under src/reports folder to run the models. Current work also includes converting the models into scripts for future use.\n\n## About\n\nText Analysis on Reddit Data\n\n### Topics\n\n[natural-language-processing](https://github.com/topics/natural-language-processing) [reddit](https://github.com/topics/reddit) [fastai](https://github.com/topics/fastai) [bert](https://github.com/topics/bert)\n\n### Resources\n\n[Readme](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor#readme-ov-file)\n\n### License\n\n[MIT license](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor#MIT-1-ov-file)\n\n[Activity](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/activity)\n\n### Stars\n\n[**0**\\\nstars](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/stargazers)\n\n### Watchers\n\n[**1**\\\nwatching](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/watchers)\n\n### Forks\n\n[**0**\\\nforks](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FJacobjeevan%2FReddit-Upvote-Predictor&report=Jacobjeevan+%28user%29)\n\n## [Releases](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/releases)\n\nNo releases published\n\n## [Packages\\ 0](https://github.com/users/Jacobjeevan/packages?repo_name=Reddit-Upvote-Predictor)\n\nNo packages published\n\n## [Contributors\\ 2](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/graphs/contributors)\n\n## Languages\n\n- [Jupyter Notebook99.9%](https://github.com/Jacobjeevan/Reddit-Upvote-Predictor/search?l=jupyter-notebook)\n- Other0.1%\n\nYou can\u2019t perform that action at this time.",
      "url": "https://github.com/Jacobjeevan/Reddit-Upvote-Predictor"
    },
    {
      "title": "Learning Latent Local Conversation Modes for Predicting Comment Endorsement in Online Discussions",
      "text": "Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media, pages 55\u201364,\nAustin, TX, November 1, 2016. \rc 2016 Association for Computational Linguistics\nLearning Latent Local Conversation Modes for Predicting Community\nEndorsement in Online Discussions\nHao Fang Hao Cheng Mari Ostendorf\nUniversity of Washington\n{hfang,chenghao,ostendorf}@uw.edu\nAbstract\nMany social media platforms offer a mecha\u0002nism for readers to react to comments, both\npositively and negatively, which in aggregate\ncan be thought of as community endorsement.\nThis paper addresses the problem of predict\u0002ing community endorsement in online discus\u0002sions, leveraging both the participant response\nstructure and the text of the comment. The\ndifferent types of features are integrated in a\nneural network that uses a novel architecture\nto learn latent modes of discussion structure\nthat perform as well as deep neural networks\nbut are more interpretable. In addition, the la\u0002tent modes can be used to weight text features\nthereby improving prediction accuracy.\n1 Introduction\nOnline discussion forums provide a platform for\npeople with shared interests (online communities) to\ndiscuss current events and common concerns. Many\nforums provide a mechanism for readers to indicate\npositive/negative reactions to comments in the dis\u0002cussion, with up/down votes, \u201cliking,\u201d or indicating\nwhether a comment is useful. The cumulative re\u0002action, which we will refer to as \u201ccommunity en\u0002dorsement,\u201d can be useful to readers for prioritizing\nwhat they read or in gathering information for deci\u0002sion making. This paper introduces the task of au\u0002tomatically predicting the level of endorsement of\na comment based on the response structure of the\ndiscussion and the text of the comment. To address\nthis task, we introduce a neural network architecture\nthat learns latent discussion structure (or, conversa\u0002tion) modes and adjusts the relative dependence on\ntext vs. structural cues in classification. The neural\nnetwork framework is also useful for combining text\nwith the disparate features that characterize the sub\u0002mission context of a comment, i.e. relative timing in\nthe discussion, response structure (characterized by\ngraph features), and author indexing.\nThe idea of conversation modes stems from the\nobservation that regions of a discussion can be quali\u0002tatively different: low vs. high activity, many partici\u0002pants vs. a few, etc. Points of high activity in the dis\u0002cussion (comments that elicit many responses) tend\nto have higher community endorsement, but some\npoints of high activity are due to controversy. We\nhypothesize that these cases can be distinguished by\nthe submission context, which we characterize with\na vector of graph and timing features extracted from\nthe local subgraph of a comment. The context vec\u0002tors are modeled as a weighted combination of latent\nbasis vectors corresponding to the different modes,\nwhere bases are learned using the weak supervision\nsignal of community endorsement. We further hy\u0002pothesize that the nature of the submission context\nimpacts the relative importance of the actual text in\na comment; hence, a mode-dependent gating mecha\u0002nism is introduced to weight the contribution of text\nfeatures in estimating community endorsement.\nThe model is assessed in experiments on Red\u0002dit discussion forum data, using karma (the differ\u0002ence in numbers of up and down votes) as a proxy\nfor community endorsement, showing benefits from\nboth the latent modes and the gating. As described\nfurther below, the prediction task differs somewhat\nfrom prior work on popularity prediction in two re\u0002spects. First, the data is not constrained to control\n55\nfor either submission context or comment/post con\u0002tent, but rather the goal is to learn different context\nmodes that impact the importance of the message.\nSecond, the use of the full discussion thread vs. a\nlimited time window puts a focus on participant in\u0002teraction in understanding community endorsement.\n2 Related Work\nThe cumulative response of readers to social me\u0002dia and online content has been studied using a\nvariety of measurements, including: the volume\nof comments in response to blog posts (Yano and\nSmith, 2010) and news articles (Tasgkias et al.,\n2009; Tatar et al., 2011), the number of Twitter\nshares of news articles (Bandari et al., 2012), the\nnumber of reshares on Facebook (Cheng et al., 2014)\nand retweets on Twitter (Suh et al., 2010; Hong et\nal., 2011; Tan et al., 2014; Zhao et al., 2015), and\nthe difference in the number of reader up and down\nvotes on posts and comments in Reddit discussion\nforums (Lakkaraju et al., 2013; Jaech et al., 2015).\nAn advantage of working with the Reddit data is that\nboth positive and negative reactions are accounted\nfor, so the total (karma in Reddit) is a reasonable\nproxy for community endorsement.\nFor all the different types of measures, a challenge\nin predicting the cumulative reaction is that the cases\nof most interest are at the tails of a Zipfian distribu\u0002tion. Various prediction tasks have been proposed\nwith this in mind, including regression on a log score\n(Bandari et al., 2012), classification into 3-4 groups\n(e.g. none, low, high) (Tasgkias et al., 2009; Hong et\nal., 2011; Yano and Smith, 2010), a binary decision\nas to whether the score will double given a current\nscore (Lakkaraju et al., 2013), and relative ranking\nof comments (Tan et al., 2014; Jaech et al., 2015).\nIn our work, we take the approach of classification,\nbut use a finer grain quantization with bins automat\u0002ically determined by the score distribution.\nThe work on cumulative reaction has mostly con\u0002sidered two different scenarios: predicting responses\nbefore a comment/document has been published vs.\nafter a limited lookahead time for extracting fea\u0002tures based on the initial response. While the frame\u0002work proposed here could handle either scenario,\nthe experiments reported allow the classifier to use\na longer future window, until most of the discussion\nhas played out. This provides insight into the dif\u0002ficulty of the task and illustrates that volume of re\u0002sponses alone does not reliably predict endorsement.\nA few studies investigate language factors that\nmay impact popularity through carefully controlled\nexperiments. To tease apart the factor of content\nquality, Lakkaraju et al. (2013) predict resharing\nof duplicated image submissions, investigating both\nthe submission context (community, time of day,\nresubmission statistics) and language factors. Our\nwork differs in that content is not controlled and the\nsubmission context includes the response structure\nand relative timing of the comment within the dis\u0002cussion. Tan et al. (2014) futher control the author\nand temporal factors in addition to the topic of the\ncontent, by ranking pairs of tweets with almost iden\u0002tical content made by the same author within a lim\u0002ited time window. Jaech et al. (2015) control the\ntemporal factor for ranking Reddit comments made\nin a time-limited window and study different lan\u0002guage factors. Here, rather than manually control\u0002ling the submission context, we propose a model to\ndiscover latent modes of submission context (rela\u0002tive timing, response structure) and analyze its util\u0002ity in predicting community endorsement. Further\u0002more, we study how the usefulness of language in\u0002formation in estimating the community endorsement\nvaries depending on submission context.\n3 Data and Task\nData: Reddit (https://www.reddit.com)\nis a discussion forum with thousands of sub\u0002communities organized as subreddits. Users can\ninitiate a tree-structured discussion thread by mak\u0002ing a post in a subreddit. Comments are made either\ndirectly to the root post or to other comments within\nthe thread, sometimes triggering sub-discussions.\nEach comment can receive upvotes and downvotes\nfrom registered users; the difference is shown as\nthe karma score beside the comment. The graph\nstructure of a Reddit disccussion thread is shown in\nFig. 1.1In this paper, three popular subred...",
      "url": "https://aclanthology.org/W16-6209.pdf"
    },
    {
      "title": "Talking to the crowd: What do people react to in online discussions?",
      "text": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2026\u20132031,\nLisbon, Portugal, 17-21 September 2015. \rc 2015 Association for Computational Linguistics.\nTalking to the crowd: What do people react to in online discussions?\nAaron Jaech, Vicky Zayats, Hao Fang, Mari Ostendorf and Hannaneh Hajishirzi\nDept. of Electrical Engineering\nUniversity of Washington\n{ajaech,vzayats,hfang,ostendor,hannaneh}@uw.edu\nAbstract\nThis paper addresses the question of how\nlanguage use affects community reaction\nto comments in online discussion forums,\nand the relative importance of the mes\u0002sage vs. the messenger. A new comment\nranking task is proposed based on com\u0002munity annotated karma in Reddit discus\u0002sions, which controls for topic and tim\u0002ing of comments. Experimental work\nwith discussion threads from six subred\u0002dits shows that the importance of different\ntypes of language features varies with the\ncommunity of interest.\n1 Introduction\nOnline discussion forums are a popular platform\nfor people to share their views about current events\nand learn about issues of concern to them. Discus\u0002sion forums tend to specialize on different topics,\nand people participating in them form communi\u0002ties of interest. The reaction of people within a\ncommunity to comments posted provides an indi\u0002cation of community endorsement of opinions and\nvalue of information. In most discussions, the vast\nmajority of comments spawn little reaction. In this\npaper, we look at whether (and how) language use\naffects the reaction, compared to the relative im\u0002portance of the author and timing of the post.\nEarly work on factors that appear to influence\ncrowd-based judgments of comments in the Slash\u0002dot forum (Lampe and Resnick, 2004) indicate\nthat timing, starting score, length of the comment,\nand poster anonymity/reputation appear to play\na role (where anonymity has a negative effect).\nJudging by differences in popularity of various\ndiscussion forums, topic is clearly important. Ev\u0002idence that language use also matters is provided\nby recent work (Danescu-Niculescu-Mizil et al.,\n2012; Lakkaraju et al., 2013; Althoff et al., 2014;\nTan et al., 2014). Teasing these different factors\napart, however, is a challenge. The work presented\nin this paper provides additional insight into this\nquestion by controlling for these factors in a dif\u0002ferent way than previous work and by examining\nmultiple communities of interest. Specifically, us\u0002ing data from Reddit discussion forums, we look at\nthe role of author reputation as measured in terms\nof a karma k-index, and control for topic and tim\u0002ing by ranking comments in a constrained window\nwithin a discussion.\nThe primary contributions of this work include\nfindings about the role of author reputation and\nvariation across communities in terms of aspects\nof language use that matter, as well as the problem\nformulation, associated data collection, and devel\u0002opment of a variety of features for characterizing\ninformativeness, community response, relevance\nand mood.\n2 Data\nReddit1is the largest public online discussion fo\u0002rum with a wide variety of subreddits, which\nmakes it a good data source for studying how tex\u0002tual content in a discussion impacts the response\nof the crowd. On Reddit, people initiate a dis\u0002cussion thread with a post (a question, a link to\na news item, etc.), and others respond with com\u0002ments. Registered users vote on which posts and\ncomments are important. The total amount of up\nvotes minus the down votes (roughly) is called\nkarma; it provides an indication of community en\u0002dorsement and popularity of a comment, as used\nin (Lakkaraju et al., 2013). Karma is valued as it\nimpacts the order in which the posts or comments\nare displayed, with the high karma content rising\nto the top. Karma points are also accumulated by\nmembers of the discussion forum as a function of\nthe karma associated with their comments.\n1\nhttp://www.reddit.com\n2026\nsubreddit # Posts # Comments/Post\nFITNESS 3K 16.3\nASKSCIENCE 4K 8.8\nPOLITICS 7K 23.7\nASKWOMEN 4K 50.5\nASKMEN 4K 58.3\nWORLDNEWS 12K 26.1\nTable 1: Data collection statistics.\nThe Reddit data is highly skewed. Although\nthere are thousands of active communities, only\na handful of them are large. Similarly, out of\nthe more than a million comments made per day2,\nmost of them receive little to no attention; the dis\u0002tributions of positive comment karma and author\nkarma are Zipfian. Slightly more than half of all\ncomments have exactly one karma point (no votes\nbeyond the author), and only 5% of comments\nhave less than one karma point.\nFor this study, we downloaded all the posts and\nassociated comments made to six subreddits over\na few weeks, as summarized in Table 1, as well as\nkarma of participants in the discussion3. All avail\u0002able comments on each post were downloaded at\nleast 48 hours after the post was made.4\n3 Uptake Factors\nFactors other than the language use that influence\nwhether a comment will have uptake from the\ncommunity include the topic, the timing of the\nmessage, and the messenger. These factors are all\nevident in the Reddit discussions. Some subred\u0002dits are more popular and thus have higher karma\ncomments than others, reflecting the influence of\ntopic. Comments that are posted early in the dis\u0002cussion are more likely to have high karma, since\nthey have more potential responses.\nPrevious studies on Twitter show that the rep\u0002utation of the author substantially increases the\nchances of the retweet (Suh et al., 2010; Cha et\nal., 2010), and reputation is also raised as a fac\u0002tor in Slashdot (Lampe and Resnick, 2004). On\nReddit most users are anonymous, but it is possi\u0002ble that members of a forum become familiar with\nparticular usernames associated with high karma\ncomments. In order to see how important per\u00022\nhttp://www.redditblog.com/2014/12/reddit-in-2014.html\n3Our data collection is available online at\nhttps://ssli.ee.washington.edu/tial/data/reddit\n4Based on our initial look at the data, we noticed that most\nposts receive all of their comments within 48 hours. Some\ncomments are deleted before we are able to download them.\nTop1 Top3\nASKSCIENCE 9.3 25.9\nFITNESS 1.4 12.3\nPOLITICS 0.3 7.4\nASKWOMEN 2.2 13.5\nASKMEN 3.9 11.9\nWORLDNEWS 3.1 6.4\nTable 2: Percentage of discussions where the top\ncomment is made by the top k-index person (or top\n3 people) in the discussion.\nsonal reputation is, we looked at how often the\ntop karma comments are associated with the top\nkarma participants in the discussion. Since an in\u0002dividual\u2019s karma can be skewed by a few very pop\u0002ular posts, we measure reputation instead using a\nmeasure we call the k-index, defined to be equal\nto the number of comments in each user\u2019s history\nthat have karma \u2265 k. The k-index is analgous to\nthe h-index (Hirsch, 2005) and arguably a better\nindicator of extended impact than total karma.\nThe results in Table 2 address the question of\nwhether the top karma comments always come\nfrom the top karma person. The Top1 column\nshows the percentage of threads where the top\nkarma comment in a discussion happens to be\nmade by the highest k-index person participating\nin the discussion; the next column shows the per\u0002centage of threads where the comment comes from\nany one of the top 3 k-index people. We find\nthat, in fact, the highest karma comment in a dis\u0002cussion is rarely from the highest k-index people.\nThe highest percentage is in ASKSCIENCE, where\nexpertise is more highly valued. If we consider\nwhether any one of the multiple comments that the\ntop k-index person made is the top karma com\u0002ment in the discussion, then the frequency is even\nlower.\n4 Methods\n4.1 Tasks\nHaving shown that the reputation of the author\nof a post is not a dominating factor in predicting\nhigh karma comments, we propose to control for\ntopic and timing by ranking a set of 10 comments\nthat were made consecutively in a short window\nof time within one discussion thread according to\nthe karma they finally received. The ranking has\naccess to the comment history about these posts.\n...",
      "url": "https://aclanthology.org/D15-1239.pdf"
    },
    {
      "title": "GitHub - PythonGoesReddit/Reddit_MDA: Text processing, tagging, and feature marking of Reddit data since ..., for multi-dimensional text analysis",
      "text": "[Skip to content](https://github.com/github.com#start-of-content)\n\nYou signed in with another tab or window. Reload to refresh your session.You signed out in another tab or window. Reload to refresh your session.You switched accounts on another tab or window. Reload to refresh your session.Dismiss alert\n\n[PythonGoesReddit](https://github.com/PythonGoesReddit)/ **[Reddit\\_MDA](https://github.com/PythonGoesReddit/Reddit_MDA)** Public\n\n- [Notifications](https://github.com/login?return_to=%2FPythonGoesReddit%2FReddit_MDA) You must be signed in to change notification settings\n- [Fork\\\n0](https://github.com/login?return_to=%2FPythonGoesReddit%2FReddit_MDA)\n- [Star\\\n0](https://github.com/login?return_to=%2FPythonGoesReddit%2FReddit_MDA)\n\n\nText processing, tagging, and feature marking of Reddit data since ..., for multi-dimensional text analysis\n\n[0\\\nstars](https://github.com/PythonGoesReddit/Reddit_MDA/stargazers) [0\\\nforks](https://github.com/PythonGoesReddit/Reddit_MDA/forks) [Branches](https://github.com/PythonGoesReddit/Reddit_MDA/branches) [Tags](https://github.com/PythonGoesReddit/Reddit_MDA/tags) [Activity](https://github.com/PythonGoesReddit/Reddit_MDA/activity)\n\n[Star](https://github.com/login?return_to=%2FPythonGoesReddit%2FReddit_MDA)\n\n[Notifications](https://github.com/login?return_to=%2FPythonGoesReddit%2FReddit_MDA) You must be signed in to change notification settings\n\n# PythonGoesReddit/Reddit\\_MDA\n\nmaster\n\n[Branches](https://github.com/PythonGoesReddit/Reddit_MDA/branches) [Tags](https://github.com/PythonGoesReddit/Reddit_MDA/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[359 Commits](https://github.com/PythonGoesReddit/Reddit_MDA/commits/master/) |\n| [.ipynb\\_checkpoints](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/.ipynb_checkpoints) | [.ipynb\\_checkpoints](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/.ipynb_checkpoints) |\n| [Manual\\_coding\\_files](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/Manual_coding_files) | [Manual\\_coding\\_files](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/Manual_coding_files) |\n| [Tagged\\_JSONS](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/Tagged_JSONS) | [Tagged\\_JSONS](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/Tagged_JSONS) |\n| [\\_\\_pycache\\_\\_](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/__pycache__) | [\\_\\_pycache\\_\\_](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/__pycache__) |\n| [.RData](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/.RData) | [.RData](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/.RData) |\n| [.gitignore](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/.gitignore) | [.gitignore](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/.gitignore) |\n| [AMALGUM\\_Flair.zip](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/AMALGUM_Flair.zip) | [AMALGUM\\_Flair.zip](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/AMALGUM_Flair.zip) |\n| [Accuracy\\_evaluator.ipynb](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Accuracy_evaluator.ipynb) | [Accuracy\\_evaluator.ipynb](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Accuracy_evaluator.ipynb) |\n| [Appendix\\_FeatureTags.md](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Appendix_FeatureTags.md) | [Appendix\\_FeatureTags.md](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Appendix_FeatureTags.md) |\n| [FLAIR\\_AMALGUM\\_POS.py](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/FLAIR_AMALGUM_POS.py) | [FLAIR\\_AMALGUM\\_POS.py](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/FLAIR_AMALGUM_POS.py) |\n| [Feature\\_coding\\_accuracies.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies.tsv) | [Feature\\_coding\\_accuracies.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies.tsv) |\n| [Feature\\_coding\\_accuracies\\_flair.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair.tsv) | [Feature\\_coding\\_accuracies\\_flair.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair.tsv) |\n| [Feature\\_coding\\_accuracies\\_flair\\_17-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_17-05-23.csv) | [Feature\\_coding\\_accuracies\\_flair\\_17-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_17-05-23.csv) |\n| [Feature\\_coding\\_accuracies\\_flair\\_18-10-23.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_18-10-23.tsv) | [Feature\\_coding\\_accuracies\\_flair\\_18-10-23.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_18-10-23.tsv) |\n| [Feature\\_coding\\_accuracies\\_flair\\_24-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_24-05-23.csv) | [Feature\\_coding\\_accuracies\\_flair\\_24-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_24-05-23.csv) |\n| [Feature\\_coding\\_accuracies\\_flair\\_Assignment.xlsx](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_Assignment.xlsx) | [Feature\\_coding\\_accuracies\\_flair\\_Assignment.xlsx](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_Assignment.xlsx) |\n| [Feature\\_coding\\_accuracies\\_flair\\_Assignment\\_Updated.xlsx](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_Assignment_Updated.xlsx) | [Feature\\_coding\\_accuracies\\_flair\\_Assignment\\_Updated.xlsx](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_Assignment_Updated.xlsx) |\n| [Feature\\_coding\\_discrepancies.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies.tsv) | [Feature\\_coding\\_discrepancies.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies.tsv) |\n| [Feature\\_coding\\_discrepancies\\_flair.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair.tsv) | [Feature\\_coding\\_discrepancies\\_flair.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair.tsv) |\n| [Feature\\_coding\\_discrepancies\\_flair\\_17-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_17-05-23.csv) | [Feature\\_coding\\_discrepancies\\_flair\\_17-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_17-05-23.csv) |\n| [Feature\\_coding\\_discrepancies\\_flair\\_18-10-23.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_18-10-23.tsv) | [Feature\\_coding\\_discrepancies\\_flair\\_18-10-23.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_18-10-23.tsv) |\n| [Feature\\_coding\\_discrepancies\\_flair\\_24-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_24-05-23.csv) | [Feature\\_coding\\_discrepancies\\_flair\\_24-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_24-05-23.csv) |\n| [Feature\\_coding\\_discrepancies\\_flair\\_corrected.xlsx](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_corrected.xlsx) | [Feature\\_coding\\_discrepancies\\_flair\\_corrected.xlsx](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_corrected.xlsx) |\n| [Feature\\_documentation.Rmd](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feat...",
      "url": "https://github.com/PythonGoesReddit/Reddit_MDA"
    },
    {
      "title": "GitHub - dgupta04/Reddit-Flair-Detector: Reddit Flair Analyser powered by Scikit-learn",
      "text": "[Skip to content](https://github.com/dgupta04/Reddit-Flair-Detector#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/dgupta04/Reddit-Flair-Detector) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/dgupta04/Reddit-Flair-Detector) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/dgupta04/Reddit-Flair-Detector) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[dgupta04](https://github.com/dgupta04)/ **[Reddit-Flair-Detector](https://github.com/dgupta04/Reddit-Flair-Detector)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Fdgupta04%2FReddit-Flair-Detector) You must be signed in to change notification settings\n- [Fork\\\n1](https://github.com/login?return_to=%2Fdgupta04%2FReddit-Flair-Detector)\n- [Star\\\n1](https://github.com/login?return_to=%2Fdgupta04%2FReddit-Flair-Detector)\n\n\nReddit Flair Analyser powered by Scikit-learn\n\n[1\\\nstar](https://github.com/dgupta04/Reddit-Flair-Detector/stargazers) [1\\\nfork](https://github.com/dgupta04/Reddit-Flair-Detector/forks) [Branches](https://github.com/dgupta04/Reddit-Flair-Detector/branches) [Tags](https://github.com/dgupta04/Reddit-Flair-Detector/tags) [Activity](https://github.com/dgupta04/Reddit-Flair-Detector/activity)\n\n[Star](https://github.com/login?return_to=%2Fdgupta04%2FReddit-Flair-Detector)\n\n[Notifications](https://github.com/login?return_to=%2Fdgupta04%2FReddit-Flair-Detector) You must be signed in to change notification settings\n\n# dgupta04/Reddit-Flair-Detector\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmaster\n\n[Branches](https://github.com/dgupta04/Reddit-Flair-Detector/branches) [Tags](https://github.com/dgupta04/Reddit-Flair-Detector/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[39 Commits](https://github.com/dgupta04/Reddit-Flair-Detector/commits/master/) |\n| [\\_\\_pycache\\_\\_](https://github.com/dgupta04/Reddit-Flair-Detector/tree/master/__pycache__) | [\\_\\_pycache\\_\\_](https://github.com/dgupta04/Reddit-Flair-Detector/tree/master/__pycache__) |  |  |\n| [csv\\_data](https://github.com/dgupta04/Reddit-Flair-Detector/tree/master/csv_data) | [csv\\_data](https://github.com/dgupta04/Reddit-Flair-Detector/tree/master/csv_data) |  |  |\n| [db](https://github.com/dgupta04/Reddit-Flair-Detector/tree/master/db) | [db](https://github.com/dgupta04/Reddit-Flair-Detector/tree/master/db) |  |  |\n| [model](https://github.com/dgupta04/Reddit-Flair-Detector/tree/master/model) | [model](https://github.com/dgupta04/Reddit-Flair-Detector/tree/master/model) |  |  |\n| [templates](https://github.com/dgupta04/Reddit-Flair-Detector/tree/master/templates) | [templates](https://github.com/dgupta04/Reddit-Flair-Detector/tree/master/templates) |  |  |\n| [worker](https://github.com/dgupta04/Reddit-Flair-Detector/tree/master/worker) | [worker](https://github.com/dgupta04/Reddit-Flair-Detector/tree/master/worker) |  |  |\n| [.DS\\_Store](https://github.com/dgupta04/Reddit-Flair-Detector/blob/master/.DS_Store) | [.DS\\_Store](https://github.com/dgupta04/Reddit-Flair-Detector/blob/master/.DS_Store) |  |  |\n| [.gitignore](https://github.com/dgupta04/Reddit-Flair-Detector/blob/master/.gitignore) | [.gitignore](https://github.com/dgupta04/Reddit-Flair-Detector/blob/master/.gitignore) |  |  |\n| [Procfile](https://github.com/dgupta04/Reddit-Flair-Detector/blob/master/Procfile) | [Procfile](https://github.com/dgupta04/Reddit-Flair-Detector/blob/master/Procfile) |  |  |\n| [README.md](https://github.com/dgupta04/Reddit-Flair-Detector/blob/master/README.md) | [README.md](https://github.com/dgupta04/Reddit-Flair-Detector/blob/master/README.md) |  |  |\n| [app.py](https://github.com/dgupta04/Reddit-Flair-Detector/blob/master/app.py) | [app.py](https://github.com/dgupta04/Reddit-Flair-Detector/blob/master/app.py) |  |  |\n| [requirements.txt](https://github.com/dgupta04/Reddit-Flair-Detector/blob/master/requirements.txt) | [requirements.txt](https://github.com/dgupta04/Reddit-Flair-Detector/blob/master/requirements.txt) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Reddit Flair Detector\n\nI developed a flair detector, which detects the flair of any post given from the [r/india](https://www.reddit.com/r/india) subreddit.\n\n# Directory structure\n\nThe root directory has the following components:\n\n- [app.py](https://github.com/dgupta04/Precog2019/blob/master/app.py) \\- The main Flask application while which powers the whole UI\n- [worker](https://github.com/dgupta04/Precog2019/blob/master/worker) \\- Folder containing the code snippets for data extraction, model generation and prediction\n  - [worker/dataCollector.py](https://github.com/dgupta04/Precog2019/blob/master/worker/dataCollector.py) \\- Extracts the data from the [r/india](https://www.reddit.com/r/india) subreddit and stores it into [csv\\_data/data.csv](https://github.com/dgupta04/Precog2019/blob/master/csv_data/data.csv)\n  - [worker/modelGenerator.py](https://github.com/dgupta04/Precog2019/blob/master/worker/modelGenerator.py) \\- Reads the data, performs pre-processing tasks and generates various models using a combination of features. The model with the highest frequency goes to the joblib dump\n  - [worker/predictor.py](https://github.com/dgupta04/Precog2019/blob/master/worker/predictor.py) \\- the core prediction algorithm running after the URL is fed on the main website\n  - [worker/config.py](https://github.com/dgupta04/Precog2019/blob/master/worker/config.py) \\- the credentials used for accessing the Reddit API. Can be altered according to user preference.\n  - [worker/util.py](https://github.com/dgupta04/Precog2019/blob/master/worker/util.py) \\- utility functions for pre-processing tasks\n  - [worker/mongoStorage.py](https://github.com/dgupta04/Precog2019/blob/master/worker/mongoStorage.py) \\- Python script to store data in MongoDB collections\n- [Procfile](https://github.com/dgupta04/Precog2019/blob/master/Procfile) \\- used for initiating Heroku app\n- [requirements.txt](https://github.com/dgupta04/Precog2019/blob/master/requirements.txt) \\- Python package requirements, installed on deployment\n- [.gitignore](https://github.com/dgupta04/Precog2019/blob/master/.gitignore) \\- files to be ignored by git\n- [db](https://github.com/dgupta04/Precog2019/blob/master/db) \\- contains the MongoDB collections to be accessed by the user\n- [templates](https://github.com/dgupta04/Precog2019/blob/master/templates) \\- templates for different webpages, with Jinja2 templating format\n\n# Codebase\n\nThe entire codebase is written in the Python language due to ease of usage and powerful computation abilities. I developed the web application using the Flask framework, which is deployed using the gunicorn WSGI server on Heroku.\n\n# Running locally\n\nTo run the code locally on your machine, please execute the following commands:\n\n1. `git clone https://github.com/dgupta04/Reddit-Flair-Detector` to clone the repository locally\n2. `pip install -r requirements.txt` to install all the dependencies\n3. `mongod --dbpath=\"./db\"` to run the existing MongoDB instance\n4. `mongo` to access all the MongoDB collections\n5. `flask run` to run the application locally on the assigned port number.\n\n# The approach\n\nPerforming an ML classification on textual data requires the use of many algorithms for tasks like pre-processing the data, extarcting useful features from it and feeding it into a classifier which generates maximum accuracy.\n\nAlthough discrete features like upvotes and timestamp; and binary features like Over-18 and isSelf are available to us, these features are not useful in predicting the flair of a post due to huge variations and outlier values. Thus, textual features like comments, the body of the post and its title were used as the main features.\n\n### 1\\. Collecting data\n...",
      "url": "https://github.com/dgupta04/Reddit-Flair-Detector"
    },
    {
      "title": "Search code, repositories, users, issues, pull requests...",
      "text": "GitHub - saum7800/reddit-flair-prediction: End to End ML project from collecting dataset to deploying model on a web app\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/saum7800/reddit-flair-prediction)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/saum7800/reddit-flair-prediction)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=saum7800/reddit-flair-prediction)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[saum7800](https://github.com/saum7800)/**[reddit-flair-prediction](https://github.com/saum7800/reddit-flair-prediction)**Public\n* [Notifications](https://github.com/login?return_to=/saum7800/reddit-flair-prediction)You must be signed in to change notification settings\n* [Fork0](https://github.com/login?return_to=/saum7800/reddit-flair-prediction)\n* [Star2](https://github.com/login?return_to=/saum7800/reddit-flair-prediction)\nEnd to End ML project from collecting dataset to deploying model on a web app\n[34.87.119.42/](http://34.87.119.42/)\n[2stars](https://github.com/saum7800/reddit-flair-prediction/stargazers)[0forks](https://github.com/saum7800/reddit-flair-prediction/forks)[Branches](https://github.com/saum7800/reddit-flair-prediction/branches)[Tags](https://github.com/saum7800/reddit-flair-prediction/tags)[Activity](https://github.com/saum7800/reddit-flair-prediction/activity)\n[Star](https://github.com/login?return_to=/saum7800/reddit-flair-prediction)\n[Notifications](https://github.com/login?return_to=/saum7800/reddit-flair-prediction)You must be signed in to change notification settings\n# saum7800/reddit-flair-prediction\nmaster\n[Branches](https://github.com/saum7800/reddit-flair-prediction/branches)[Tags](https://github.com/saum7800/reddit-flair-prediction/tags)\n[](https://github.com/saum7800/reddit-flair-prediction/branches)[](https://github.com/saum7800/reddit-flair-prediction/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[7 Commits](https://github.com/saum7800/reddit-flair-prediction/commits/master/)\n[](https://github.com/saum7800/reddit-flair-prediction/commits/master/)\n|\n[4web\\_app](https://github.com/saum7800/reddit-flair-prediction/tree/master/4web_app)\n|\n[4web\\_app](https://github.com/saum7800/reddit-flair-prediction/tree/master/4web_app)\n|\n|\n|\n[extra](https://github.com/saum7800/reddit-flair-prediction/tree/master/extra)\n|\n[extra](https://github.com/saum7800/reddit-flair-prediction/tree/master/extra)\n|\n|\n|\n[1reddit data collection.ipynb](https://github.com/saum7800/reddit-flair-prediction/blob/master/1reddit%20data%20collection.ipynb)\n|\n[1reddit data collection.ipynb](https://github.com/saum7800/reddit-flair-prediction/blob/master/1reddit%20data%20collection.ipynb)\n|\n|\n|\n[2reddit exploratory data analysis.ipynb](https://github.com/saum7800/reddit-flair-prediction/blob/master/2reddit%20exploratory%20data%20analysis.ipynb)\n|\n[2reddit exploratory data analysis.ipynb](https://github.com/saum7800/reddit-flair-prediction/blob/master/2reddit%20exploratory%20data%20analysis.ipynb)\n|\n|\n|\n[3ATrain\\_flair\\_predictor\\_traditional.ipynb](https://github.com/saum7800/reddit-flair-prediction/blob/master/3ATrain_flair_predictor_traditional.ipynb)\n|\n[3ATrain\\_flair\\_predictor\\_traditional.ipynb](https://github.com/saum7800/reddit-flair-prediction/blob/master/3ATrain_flair_predictor_traditional.ipynb)\n|\n|\n|\n[3B\\_train\\_from\\_scratch.ipynb](https://github.com/saum7800/reddit-flair-prediction/blob/master/3B_train_from_scratch.ipynb)\n|\n[3B\\_train\\_from\\_scratch.ipynb](https://github.com/saum7800/reddit-flair-prediction/blob/master/3B_train_from_scratch.ipynb)\n|\n|\n|\n[3C\\_Embedding\\_layer\\_classification.ipynb](https://github.com/saum7800/reddit-flair-prediction/blob/master/3C_Embedding_layer_classification.ipynb)\n|\n[3C\\_Embedding\\_layer\\_classification.ipynb](https://github.com/saum7800/reddit-flair-prediction/blob/master/3C_Embedding_layer_classification.ipynb)\n|\n|\n|\n[3D\\_Bert\\_Trainer.ipynb](https://github.com/saum7800/reddit-flair-prediction/blob/master/3D_Bert_Trainer.ipynb)\n|\n[3D\\_Bert\\_Trainer.ipynb](https://github.com/saum7800/reddit-flair-prediction/blob/master/3D_Bert_Trainer.ipynb)\n|\n|\n|\n[README.md](https://github.com/saum7800/reddit-flair-prediction/blob/master/README.md)\n|\n[README.md](https://github.com/saum7800/reddit-flair-prediction/blob/master/README.md)\n|\n|\n|\n[dataset\\_final.csv](https://github.com/saum7800/reddit-flair-prediction/blob/master/dataset_final.csv)\n|\n[dataset\\_final.csv](https://github.com/saum7800/reddit-flair-prediction/blob/master/dataset_final.csv)\n|\n|\n|\n[reddit\\_data.csv](https://github.com/saum7800/reddit-flair-prediction/blob/master/reddit_data.csv)\n|\n[reddit\\_data.csv](https://github.com/saum7800/reddit-flair-prediction/blob/master/reddit_data.csv)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# Reddit Flair Prediction\n[](#reddit-flair-prediction)\nThis project is made to predict the flair of a reddit submission on the[India sub-reddit](https://www.reddit.com/r/india/). Each sub-reddit has flairs associated to it which are like categories of the different types of submissions. Flairs to a post are added by the User posting and hence every post does not necessarily have an associated flair. The India sub-reddit has 10 extremely popular flairs that we will be predicting from. They are:\n1. Non-Political\n2. Politics\n3. Policy/Economy\n4. AskIndia\n5. Science/Technology\n6. Business/Finance\n7. Reddiquette\n8. Sports\n9. Photography\n10. Coronavirus\nThe project is divided into four parts:\n1. Data Collection\n2. Exploratory data analysis of data collected\n3. Training models for flair predictor\n4. Deploying best model as a Django web-app\n### [Data Collection](<https://github.com/saum7800/reddit-flair-prediction/blob/master/1reddit data collection.ipynb>)\n[](#data-collection)\nI have described how I have procured the dataset in this[notebook](<https://nbviewer.jupyter.org/github/saum7800/reddit-flair-prediction/blob/master/1reddit data collection.ipynb>). If you are running this notebook on your loca machine, make sure you**do not**run the last cell as it will overwrite the dataset present with newer data which may not work properly with the subsequent notebooks.\n### [Exploratory Data Analysis](<https://github.com/saum7800/reddit-flair-prediction/blob/master/2reddit exploratory data analysis.ipynb>)\n[](#exploratory-data-analysis)\nAfter procuring the large dataset from part 1, we will clean up and explore the new dataset to find interesting nuances that we may not have expected and also reaffirm some expected outcomes. The notebook contains interactive plots in the result and is hence best viewed on nbviewer[here](<https://nbviewer.jupyter.org/github/saum7800/reddit-flair-prediction/blob/master/2reddit exploratory data analysis.ipynb>).\n### Fl...",
      "url": "https://github.com/saum7800/reddit-flair-prediction"
    },
    {
      "title": "GitHub - anushkanarula/Reddit-Flair: Reddit Flair Detector",
      "text": "[Skip to content](https://github.com/anushkanarula/Reddit-Flair#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/anushkanarula/Reddit-Flair) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/anushkanarula/Reddit-Flair) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/anushkanarula/Reddit-Flair) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[anushkanarula](https://github.com/anushkanarula)/ **[Reddit-Flair](https://github.com/anushkanarula/Reddit-Flair)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Fanushkanarula%2FReddit-Flair) You must be signed in to change notification settings\n- [Fork\\\n0](https://github.com/login?return_to=%2Fanushkanarula%2FReddit-Flair)\n- [Star\\\n1](https://github.com/login?return_to=%2Fanushkanarula%2FReddit-Flair)\n\n\nReddit Flair Detector\n\n[reddit-flair-detect-web.herokuapp.com/](https://reddit-flair-detect-web.herokuapp.com/)\n\n[1\\\nstar](https://github.com/anushkanarula/Reddit-Flair/stargazers) [0\\\nforks](https://github.com/anushkanarula/Reddit-Flair/forks) [Branches](https://github.com/anushkanarula/Reddit-Flair/branches) [Tags](https://github.com/anushkanarula/Reddit-Flair/tags) [Activity](https://github.com/anushkanarula/Reddit-Flair/activity)\n\n[Star](https://github.com/login?return_to=%2Fanushkanarula%2FReddit-Flair)\n\n[Notifications](https://github.com/login?return_to=%2Fanushkanarula%2FReddit-Flair) You must be signed in to change notification settings\n\n# anushkanarula/Reddit-Flair\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmaster\n\n[Branches](https://github.com/anushkanarula/Reddit-Flair/branches) [Tags](https://github.com/anushkanarula/Reddit-Flair/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[50 Commits](https://github.com/anushkanarula/Reddit-Flair/commits/master/) |\n| [.ipynb\\_checkpoints](https://github.com/anushkanarula/Reddit-Flair/tree/master/.ipynb_checkpoints) | [.ipynb\\_checkpoints](https://github.com/anushkanarula/Reddit-Flair/tree/master/.ipynb_checkpoints) |  |  |\n| [data](https://github.com/anushkanarula/Reddit-Flair/tree/master/data) | [data](https://github.com/anushkanarula/Reddit-Flair/tree/master/data) |  |  |\n| [model](https://github.com/anushkanarula/Reddit-Flair/tree/master/model) | [model](https://github.com/anushkanarula/Reddit-Flair/tree/master/model) |  |  |\n| [scripts](https://github.com/anushkanarula/Reddit-Flair/tree/master/scripts) | [scripts](https://github.com/anushkanarula/Reddit-Flair/tree/master/scripts) |  |  |\n| [static](https://github.com/anushkanarula/Reddit-Flair/tree/master/static) | [static](https://github.com/anushkanarula/Reddit-Flair/tree/master/static) |  |  |\n| [templates](https://github.com/anushkanarula/Reddit-Flair/tree/master/templates) | [templates](https://github.com/anushkanarula/Reddit-Flair/tree/master/templates) |  |  |\n| [LR.pkl](https://github.com/anushkanarula/Reddit-Flair/blob/master/LR.pkl) | [LR.pkl](https://github.com/anushkanarula/Reddit-Flair/blob/master/LR.pkl) |  |  |\n| [Procfile](https://github.com/anushkanarula/Reddit-Flair/blob/master/Procfile) | [Procfile](https://github.com/anushkanarula/Reddit-Flair/blob/master/Procfile) |  |  |\n| [README.md](https://github.com/anushkanarula/Reddit-Flair/blob/master/README.md) | [README.md](https://github.com/anushkanarula/Reddit-Flair/blob/master/README.md) |  |  |\n| [app.py](https://github.com/anushkanarula/Reddit-Flair/blob/master/app.py) | [app.py](https://github.com/anushkanarula/Reddit-Flair/blob/master/app.py) |  |  |\n| [data.csv](https://github.com/anushkanarula/Reddit-Flair/blob/master/data.csv) | [data.csv](https://github.com/anushkanarula/Reddit-Flair/blob/master/data.csv) |  |  |\n| [data\\_scraping.ipynb](https://github.com/anushkanarula/Reddit-Flair/blob/master/data_scraping.ipynb) | [data\\_scraping.ipynb](https://github.com/anushkanarula/Reddit-Flair/blob/master/data_scraping.ipynb) |  |  |\n| [flair\\_detection.ipynb](https://github.com/anushkanarula/Reddit-Flair/blob/master/flair_detection.ipynb) | [flair\\_detection.ipynb](https://github.com/anushkanarula/Reddit-Flair/blob/master/flair_detection.ipynb) |  |  |\n| [graph.png](https://github.com/anushkanarula/Reddit-Flair/blob/master/graph.png) | [graph.png](https://github.com/anushkanarula/Reddit-Flair/blob/master/graph.png) |  |  |\n| [nltk.txt](https://github.com/anushkanarula/Reddit-Flair/blob/master/nltk.txt) | [nltk.txt](https://github.com/anushkanarula/Reddit-Flair/blob/master/nltk.txt) |  |  |\n| [requirements.txt](https://github.com/anushkanarula/Reddit-Flair/blob/master/requirements.txt) | [requirements.txt](https://github.com/anushkanarula/Reddit-Flair/blob/master/requirements.txt) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Reddit-Flair\n\nA Reddit Flair web application to detect flairs of India subreddit posts using Machine Learning algorithms.\n\n### Structure\n\nThe directory largely contains 2 ipython notebooks and 1 web directory:\nData-scraping Notebook contains all the code that was used to fetch data using PRAW API from reddit and adding it to the mongodb database using pymongo. It was the fetched back from the data base and pre-processed to add it into a CSV file to do the data analysis and build the machine learning model.\nFlair-detection Notebook contains the code used to do the data analysis and train various machine learning models and check the accuracy on different features.\nWebsite Directory the directory contains the flask implementation of the app and the requirements and procfile for heroku deployment. The detail of each file in the directory can be found in the readme.md file of the directory.\n\n### Codebase\n\nThe entire code has been developed using Python programming language, utilizing it's powerful text processing and machine learning modules. The application has been developed using Flask web framework and hosted on Heroku web server.\n\n### Approach\n\nGoing through various literatures available for text processing and suitable machine learning algorithms for text classification, I based my approach using [\\[2\\]](https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568) which described various machine learning models like Naive-Bayes, Linear SVM and Logistic Regression for text classification with code snippets. Along with this, I tried other models like Random Forest and Multi-Layer Perceptron for the task. I have obtained test accuracies on various scenarios which can be found in the next section.\n\nThe approach taken for the task is as follows:\n\n1. Collect 100 India subreddit data for each of the 12 flairs using `praw` module [\\[1\\]](http://www.storybench.org/how-to-scrape-reddit-with-python/) and [2](http://machineloveus.com/mining-reddit-data-or-links-to-33-python-cheat-sheets/).\n2. The data includes _title, comments, body, url, author, score, id, time-created_ and _number of comments_.\n3. For **comments**, only top level comments (top 10) are considered in dataset and no sub-comments are present.\n4. The _**title, comments**_ and _**body**_ are cleaned by removing bad symbols and stopwords using `nltk`.\n5. Five types of features are considered for the the given task:\n\n```\na) Title\nb) Comments\nc) Urls\nd) Body\ne) Combining Title, Comments and Urls as one feature.\n\n```\n\n1. The dataset is split into **80% train** and **20% test** data using `train-test-split` of `scikit-learn`.\n2. The dataset is then converted into a `Vector` and `TF-IDF` form.\n3. Then, the following ML algorithms (using `scikit-learn` libraries) are applied on the dataset:\n\n```\na) Naive-Bayes\nb) Linear Support Vector Machine\nc) Logistic Regression\nd) Random Forest\ne) MLP\n\n```\n\n1. Training and Testing on the dataset showed the **Random Forest** showed...",
      "url": "https://github.com/anushkanarula/Reddit-Flair"
    }
  ]
}