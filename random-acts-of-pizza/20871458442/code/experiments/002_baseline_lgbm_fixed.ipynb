{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676054d3",
   "metadata": {},
   "source": [
    "# Fixed Baseline: LightGBM without Leaky Features\n",
    "\n",
    "This notebook implements a corrected baseline model that excludes features not present in the test set.\n",
    "\n",
    "## Key Fix\n",
    "- **Removed user flair features**: `requester_user_flair` is not present in test data, causing the model to fail\n",
    "- Using only features available in both train and test sets\n",
    "- Focus on text features and metadata that generalize\n",
    "\n",
    "## Strategy\n",
    "- Engineer text features (TF-IDF, length, word count)\n",
    "- Use metadata features (account age, activity metrics, vote counts)\n",
    "- Apply stratified k-fold cross-validation\n",
    "- Handle class imbalance with scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6edc2226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T03:30:18.842172Z",
     "iopub.status.busy": "2026-01-10T03:30:18.841183Z",
     "iopub.status.idle": "2026-01-10T03:30:18.847479Z",
     "shell.execute_reply": "2026-01-10T03:30:18.846502Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6045cb5",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae63be6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T03:30:18.850262Z",
     "iopub.status.busy": "2026-01-10T03:30:18.849938Z",
     "iopub.status.idle": "2026-01-10T03:30:18.974257Z",
     "shell.execute_reply": "2026-01-10T03:30:18.973495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2878, 32)\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    0.751564\n",
      "True     0.248436\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test data shape: (1162, 17)\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Target distribution:\")\n",
    "print(train_df['requester_received_pizza'].value_counts(normalize=True))\n",
    "\n",
    "# Load test data\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "print(f\"\\nTest data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e57e4df",
   "metadata": {},
   "source": [
    "## Feature Engineering (Fixed)\n",
    "\n",
    "**Key Change**: Only use features available in BOTH train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a831f9a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T03:30:18.976621Z",
     "iopub.status.busy": "2026-01-10T03:30:18.975981Z",
     "iopub.status.idle": "2026-01-10T03:30:19.049139Z",
     "shell.execute_reply": "2026-01-10T03:30:19.048403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered features shape: (2878, 16)\n",
      "Feature columns: ['text_length', 'word_count', 'title_length', 'avg_word_length', 'account_age_days', 'num_comments', 'num_posts', 'num_subreddits', 'comments_per_post', 'subreddits_per_post', 'upvotes_minus_downvotes', 'upvotes_plus_downvotes', 'timestamp', 'hour_of_day', 'day_of_week', 'is_weekend']\n"
     ]
    }
   ],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Engineer features from the raw data - ONLY use features available in test set\"\"\"\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Text features\n",
    "    # Use request_text_edit_aware to avoid leakage from edits\n",
    "    text_col = 'request_text_edit_aware' if 'request_text_edit_aware' in df.columns else 'request_text'\n",
    "    \n",
    "    # Combine title and text for unified analysis\n",
    "    df['combined_text'] = df['request_title'].fillna('') + ' ' + df[text_col].fillna('')\n",
    "    \n",
    "    # Basic text length features\n",
    "    features['text_length'] = df['combined_text'].str.len()\n",
    "    features['word_count'] = df['combined_text'].str.split().str.len()\n",
    "    features['title_length'] = df['request_title'].str.len()\n",
    "    features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1)\n",
    "    \n",
    "    # Account activity features (use at_request versions since at_retrieval not in test)\n",
    "    features['account_age_days'] = df['requester_account_age_in_days_at_request']\n",
    "    features['num_comments'] = df['requester_number_of_comments_at_request']\n",
    "    features['num_posts'] = df['requester_number_of_posts_at_request']\n",
    "    features['num_subreddits'] = df['requester_number_of_subreddits_at_request']\n",
    "    \n",
    "    # Activity ratios\n",
    "    features['comments_per_post'] = features['num_comments'] / (features['num_posts'] + 1)\n",
    "    features['subreddits_per_post'] = features['num_subreddits'] / (features['num_posts'] + 1)\n",
    "    \n",
    "    # Vote features (available in both train and test)\n",
    "    features['upvotes_minus_downvotes'] = df['requester_upvotes_minus_downvotes_at_request']\n",
    "    features['upvotes_plus_downvotes'] = df['requester_upvotes_plus_downvotes_at_request']\n",
    "    \n",
    "    # Time features\n",
    "    features['timestamp'] = df['unix_timestamp_of_request']\n",
    "    features['hour_of_day'] = pd.to_datetime(df['unix_timestamp_of_request'], unit='s').dt.hour\n",
    "    features['day_of_week'] = pd.to_datetime(df['unix_timestamp_of_request'], unit='s').dt.dayofweek\n",
    "    features['is_weekend'] = features['day_of_week'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # Handle missing values\n",
    "    features = features.fillna(0)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Engineer features for train and test\n",
    "train_features = engineer_features(train_df)\n",
    "test_features = engineer_features(test_df)\n",
    "\n",
    "print(f\"Engineered features shape: {train_features.shape}\")\n",
    "print(f\"Feature columns: {list(train_features.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd945f3",
   "metadata": {},
   "source": [
    "## TF-IDF Features for Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed629909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T03:30:19.051483Z",
     "iopub.status.busy": "2026-01-10T03:30:19.050904Z",
     "iopub.status.idle": "2026-01-10T03:30:19.652013Z",
     "shell.execute_reply": "2026-01-10T03:30:19.651224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF features shape: (2878, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF features for the text\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=2000,  # Increased from 1000 for better text representation\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),  # Unigrams and bigrams\n",
    "    min_df=3,  # Reduced from 5 to capture more features\n",
    "    max_df=0.95  # Ignore very common terms\n",
    ")\n",
    "\n",
    "# Fit on training text\n",
    "train_text = train_df['combined_text'].fillna('')\n",
    "tfidf_train = vectorizer.fit_transform(train_text)\n",
    "\n",
    "# Transform test text\n",
    "test_text = test_df['combined_text'].fillna('')\n",
    "tfidf_test = vectorizer.transform(test_text)\n",
    "\n",
    "print(f\"TF-IDF features shape: {tfidf_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a484ac",
   "metadata": {},
   "source": [
    "## Combine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a0fbc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T03:30:19.654594Z",
     "iopub.status.busy": "2026-01-10T03:30:19.653990Z",
     "iopub.status.idle": "2026-01-10T03:30:19.664452Z",
     "shell.execute_reply": "2026-01-10T03:30:19.663681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training matrix shape: (2878, 2016)\n",
      "Final test matrix shape: (1162, 2016)\n"
     ]
    }
   ],
   "source": [
    "# Convert engineered features to sparse matrix format\n",
    "train_engineered = csr_matrix(train_features.values)\n",
    "test_engineered = csr_matrix(test_features.values)\n",
    "\n",
    "# Combine TF-IDF and engineered features\n",
    "X_train = hstack([tfidf_train, train_engineered])\n",
    "X_test = hstack([tfidf_test, test_engineered])\n",
    "\n",
    "y_train = train_df['requester_received_pizza'].values\n",
    "\n",
    "print(f\"Final training matrix shape: {X_train.shape}\")\n",
    "print(f\"Final test matrix shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb1ef8c",
   "metadata": {},
   "source": [
    "## Model Training with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b419a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up stratified k-fold cross-validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize arrays for out-of-fold predictions\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "test_predictions = np.zeros(len(test_df))\n",
    "\n",
    "# Track scores across folds\n",
    "cv_scores = []\n",
    "\n",
    "print(f\"Training LightGBM model with {n_splits}-fold stratified CV...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_set = lgb.Dataset(X_tr, label=y_tr)\n",
    "    val_set = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Define parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 63,  # Increased from 31 for more complex model\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'num_threads': 4\n",
    "    }\n",
    "    \n",
    "    # Handle class imbalance with scale_pos_weight\n",
    "    pos_rate = y_tr.mean()\n",
    "    params['scale_pos_weight'] = (1 - pos_rate) / pos_rate\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=2000,  # Increased for better learning\n",
    "        valid_sets=[val_set],\n",
    "        valid_names=['val'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(100),  # Increased patience\n",
    "            lgb.log_evaluation(100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    \n",
    "    # Store predictions\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    test_predictions += test_pred / n_splits\n",
    "    \n",
    "    # Calculate fold score\n",
    "    fold_score = roc_auc_score(y_val, val_pred)\n",
    "    cv_scores.append(fold_score)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} AUC: {fold_score:.4f}\")\n",
    "\n",
    "# Calculate overall CV score\n",
    "overall_score = roc_auc_score(y_train, oof_predictions)\n",
    "print(f\"\\nOverall CV AUC: {overall_score:.4f}\")\n",
    "print(f\"Mean CV AUC: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7798c",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from the last fold model\n",
    "feature_names = (list(vectorizer.get_feature_names_out()) + \n",
    "                 list(train_features.columns))\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 most important features:\")\n",
    "print(importance_df.head(20))\n",
    "\n",
    "# Check how many features have non-zero importance\n",
    "non_zero_features = importance_df[importance_df['importance'] > 0]\n",
    "print(f\"\\nNumber of features with non-zero importance: {len(non_zero_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77c3320",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5299480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "# Ensure the format matches sample submission\n",
    "submission['requester_received_pizza'] = submission['requester_received_pizza'].clip(0, 1)\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"Prediction distribution:\")\n",
    "print(submission['requester_received_pizza'].describe())\n",
    "\n",
    "# Check if predictions are varied (not all the same)\n",
    "unique_predictions = submission['requester_received_pizza'].nunique()\n",
    "print(f\"\\nNumber of unique prediction values: {unique_predictions}\")\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(\"\\nSubmission saved to /home/submission/submission.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
