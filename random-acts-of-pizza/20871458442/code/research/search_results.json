{
  "query": "How do you combine BERT text embeddings with tabular metadata features for classification?",
  "results": [
    {
      "title": "ANSWER",
      "text": "**Based on the Multimodal\u2011Toolkit tutorial and the official `BertWithTabular` implementation (and the AutoGluon example), you can fuse BERT text embeddings with tabular metadata for a classification model by either (a) turning the tabular fields into text and feeding the concatenated string to a standard BERT model, or (b) using a dedicated multimodal BERT wrapper that combines the pooled BERT output with a learned tabular feature encoder.**\u202f([mccormickml.com](https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert), [Multimodal\u2011Toolkit docs](https://multimodal-toolkit.readthedocs.io/en/latest/_modules/multimodal_transformers/model/tabular_transformers.html), [AutoGluon tutorial](https://auto.gluon.ai/0.7.0/tutorials/tabular_prediction/tabular-multimodal-text-others.html))\n\n### Quick workflow (using the `BertWithTabular` class)\n\n1. **Prepare the data**  \n   * Encode categorical columns (e.g., one\u2011hot or embedding indices) and scale numeric columns.  \n   * Record the dimensionalities: `cat_feat_dim` = number of categorical columns, `numerical_feat_dim` = number of numeric columns.  \n\n2. **Create a `TabularConfig`** that tells the model how many tabular features you have and which fusion method to use (e.g., `\"attention_on_cat_and_numerical_feats\"`).  \n   ```python\n   from transformers import BertConfig\n   from multimodal_transformers.model import TabularConfig, BertWithTabular\n\n   bert_cfg = BertConfig.from_pretrained('bert-base-uncased')\n   tab_cfg = TabularConfig(\n       combine_feat_method='attention_on_cat_and_numerical_feats',\n       cat_feat_dim=9,          # \u2190 your categorical feature count\n       numerical_feat_dim=5)   # \u2190 your numeric feature count\n   bert_cfg.tabular_config = tab_cfg\n   ```\n\n3. **Instantiate the multimodal model** \u2013 it inherits the usual BERT classification head and adds a `TabularFeatCombiner` that merges the tabular representation with the pooled BERT output.  \n   ```python\n   model = BertWithTabular(bert_cfg)\n   ```\n\n4. **Build the forward pass**  \n   * Tokenize the raw text as usual (`input_ids`, `attention_mask`).  \n   * Pass the tabular tensors (`cat_feats`, `num_feats`) alongside the text tensors to the model:  \n   ```python\n   outputs = model(\n       input_ids=text_ids,\n       attention_mask=mask,\n       cat_feats=cat_tensor,\n       numerical_feats=num_tensor\n   )\n   loss = outputs.loss   # for training\n   logits = outputs.logits   # for inference\n   ```\n\n5. **Train / evaluate**  \n   * Use any standard PyTorch training loop or HuggingFace `Trainer`.  \n   * The loss combines the classification objective with the multimodal representation automatically; no extra code is needed.  \n\n6. **(Optional) Feature\u2011to\u2011text shortcut**  \n   If you prefer not to use the custom wrapper, simply concatenate a textual representation of the tabular fields to the original review (e.g., `\"age: 34, upvotes: 12, dept: men\"`), prepend it to the review text, and feed the whole string to a vanilla BERT classifier. This \u201cfeatures\u2011to\u2011text\u201d trick was shown to work well on a 23\u202fk clothing\u2011review dataset ([mccormickml.com](https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert)).  \n\n7. **Alternative high\u2011level solution (AutoGluon)**  \n   * Load your mixed dataset into a `pandas` DataFrame, marking the text column as a string and the rest as numeric/categorical.  \n   * Call `TabularPredictor.fit(train_data, label='target')`; AutoGluon automatically builds a multimodal pipeline that includes a pretrained BERT text encoder plus LightGBM / CatBoost for the tabular part, handling the fusion internally ([AutoGluon docs](https://auto.gluon.ai/0.7.0/tutorials/tabular_prediction/tabular-multimodal-text-others.html)).  \n\nThese steps give you a working classification pipeline that leverages BERT\u2019s contextual text embeddings together with structured metadata, either via a dedicated multimodal BERT model or through a higher\u2011level AutoGluon interface.",
      "url": ""
    },
    {
      "title": "",
      "text": "# Combining Categorical and Numerical Features with Text in BERT\n\n29 Jun 2021\n\nIn this tutorial we\u2019ll look at the topic of classifying text with BERT, but where we also have additional numerical or categorical features that we want to use to improve our predictions.\n\nTo help motivate our discussion, we\u2019ll be working with a dataset of about 23k clothing reviews. For each review, we have the review text, but also additional information such as:\n\n- The age of the reviewer (numerical feature)\n- The number of upvotes on the review (numerical feature)\n- The department and category of the clothing item (categorical features)\n\nFor each review, we also have a binary label, which is whether or not the reviewer ultimately recommends the item. This is what we are trying to predict.\n\nThis dataset was scraped from an (un-specified) e-commerce website by Nick Brooks and made available on Kaggle [here](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews).\n\nIn Section 2 of this Notebook, I\u2019ve implemented four different \u201cbaseline\u201d strategies which score fairly well, but which don\u2019t incorporate all of the features together.\n\nThen, in Section 3, I\u2019ve implemented a simple strategy to combine _everything_ and feed it through BERT. Specifically, I make text out of the additional features, and prepend this text to the review.\n\nThere is a GitHub project called the [Multimodal-Toolkit](https://github.com/georgian-io/Multimodal-Toolkit) which is how I learned about this clothing review dataset. The toolkit implements a number of more complicated techniques, but their benchmarks (as well as our results below) show that this simple features-to-text strategy works best for this dataset.\n\nIn our weekly discussion group, I talked through this Notebook and we also met with Ken Gu, the author of the Multi-Modal Toolkit! You can watch the recording [here](https://youtu.be/XPt9pIpe1vo).\n\nYou can find the Colab Notebook version of this post [here](https://colab.research.google.com/drive/1YRHK4HO8RktGzlYmGjBo056kzVD4_j9o).\n\nBy Chris McCormick\n\n# Contents\n\n- [Contents](https://mccormickml.com/mccormickml.com#contents)\n- [S1. Clothing Review Dataset](https://mccormickml.com/mccormickml.com#s1-clothing-review-dataset)\n  - [1.1. Download & Parse](https://mccormickml.com/mccormickml.com#11-download--parse)\n  - [1.2. Train-Validation-Test Split](https://mccormickml.com/mccormickml.com#12-train-validation-test-split)\n- [S2. Baseline Strategies](https://mccormickml.com/mccormickml.com#s2-baseline-strategies)\n  - [2.1. Always Recommend](https://mccormickml.com/mccormickml.com#21-always-recommend)\n  - [2.2. Threshold on Rating](https://mccormickml.com/mccormickml.com#22-threshold-on-rating)\n  - [2.3. XGBoost](https://mccormickml.com/mccormickml.com#23-xgboost)\n  - [2.4. BERT on Review Text Only](https://mccormickml.com/mccormickml.com#24-bert-on-review-text-only)\n- [S3. BERT with All Features](https://mccormickml.com/mccormickml.com#s3-bert-with-all-features)\n  - [3.1. All Features to Text](https://mccormickml.com/mccormickml.com#31-all-features-to-text)\n  - [3.2. GPU & Transformers Setup](https://mccormickml.com/mccormickml.com#32-gpu--transformers-setup)\n  - [3.3. Training Parameters](https://mccormickml.com/mccormickml.com#33-training-parameters)\n  - [3.3. Tokenize & Encode](https://mccormickml.com/mccormickml.com#33-tokenize--encode)\n  - [3.4. Training](https://mccormickml.com/mccormickml.com#34-training)\n    - [3.4.1. Setup](https://mccormickml.com/mccormickml.com#341-setup)\n    - [3.4.2. Training Loop](https://mccormickml.com/mccormickml.com#342-training-loop)\n    - [3.4.3. Training Results](https://mccormickml.com/mccormickml.com#343-training-results)\n  - [3.5. Test](https://mccormickml.com/mccormickml.com#35-test)\n- [Conclusion](https://mccormickml.com/mccormickml.com#conclusion)\n\n# S1. Clothing Review Dataset\n\n## 1.1. Download & Parse\n\nRetrieve the .csv file for the dataset.\n\n```\nimport gdown\n\nprint('Downloading dataset...\\n')\n\n# Download the file.\ngdown.download('https://drive.google.com/uc?id=1ZYdt0zN4LjWqP3cQDblNhXjeohcryY5H',\n                'Womens Clothing E-Commerce Reviews.csv',\n                quiet=False)\n\nprint('\\n\\nDONE.')\n```\n\n```\nDownloading dataset...\n\nDownloading...\nFrom: https://drive.google.com/uc?id=1ZYdt0zN4LjWqP3cQDblNhXjeohcryY5H\nTo: /content/Womens Clothing E-Commerce Reviews.csv\n8.48MB [00:00, 48.7MB/s]\n\nDONE.\n\n```\n\nParse the dataset csv file into a pandas DataFrame.\n\n```\nimport pandas as pd\n\ndata_df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv', index_col=0)\n\ndata_df.head()\n```\n\n| Clothing ID | Age | Title | Review Text | Rating | Recommended IND | Positive Feedback Count | Division Name | Department Name | Class Name |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | 767 | 33 | NaN | Absolutely wonderful - silky and sexy and comf... | 4 | 1 | 0 | Initmates | Intimate | Intimates |\n| 1 | 1080 | 34 | NaN | Love this dress! it's sooo pretty. i happene... | 5 | 1 | 4 | General | Dresses | Dresses |\n| 2 | 1077 | 60 | Some major design flaws | I had such high hopes for this dress and reall... | 3 | 0 | 0 | General | Dresses | Dresses |\n| 3 | 1049 | 50 | My favorite buy! | I love, love, love this jumpsuit. it's fun, fl... | 5 | 1 | 0 | General Petite | Bottoms | Pants |\n| 4 | 847 | 47 | Flattering shirt | This shirt is very flattering to all due to th... | 5 | 1 | 6 | General | Tops | Blouses |\n\n_Features_\n\n\u201c **Recommended IND**\u201d is the label we are trying to predict for this dataset. \u201c1\u201d means the reviewer recommended the product and \u201c0\u201d means they do not.\n\nThe following are _categorical_ features:\n\n- Division Name\n- Department Name\n- Class Name\n- Clothing ID\n\nAnd the following are _numerical_ features:\n\n- Age\n- Rating\n- Positive Feedback Count\n\n_Feature Analysis_\n\nThere is an excellent Notebook on Kaggle [here](https://www.kaggle.com/bhaveshkumar2806/complete-eda-and-visualization-of-text-data) which does some thorough analysis on each of the features in this dataset.\n\nNote that, in addition to the \u201cRecommended\u201d label, there is also a \u201c **Rating**\u201d column where the reviewer rates the product from 1 - 5. The analysis in the above Notebook shows that almost all items rated 3 - 5 are recommended, and almost all rated 1 - 2 are not recommended. We\u2019ll see in our second baseline classifier that you can get a very high accuracy with this feature alone. However, it _is_ still possible to do better by incorporating the other features!\n\n## 1.2. Train-Validation-Test Split\n\nI want to use the same training, validation, and test splits for all of the approaches we try so that it\u2019s a fair comparison.\n\nHowever, different approaches are going to require different transformations on the data, and for simplicity I want to apply those transformations _before_ splitting the dataset.\n\nTo solve this, we\u2019re going to create lists of indeces for each of the three portions. That way, for a given classification approach, we can load the whole dataset, apply our transformations, and then split it according to these pre-determined indeces.\n\n```\nimport random\nimport numpy as np\n\n# First, calculate the split sizes. 80% training, 10% validation, 10% test.\ntrain_size = int(0.8 * len(data_df))\nval_size = int(0.1 * len(data_df))\ntest_size = len(data_df) - (train_size + val_size)\n\n# Sanity check the sizes.\nassert((train_size + val_size + test_size) == len(data_df))\n\n# Create a list of indeces for all of the samples in the dataset.\nindeces = np.arange(0, len(data_df))\n\n# Shuffle the indeces randomly.\nrandom.shuffle(indeces)\n\n# Get a list of indeces for each of the splits.\ntrain_idx = indeces[0:train_size]\nval_idx = indeces[train_size:(train_size + val_size)]\ntest_idx = indeces[(train_size + val_size):]\n\n# Sanity check\nassert(len(train_idx) == train_size)\nassert(len(test_idx) == test_size)\n\n# With these lists, we can now select the corresponding dataframe rows using,\n# e.g., train_df = data_df.iloc[train_idx]\n\nprint('  Training size: {:,}'.format(train_size))\n...",
      "url": "https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert"
    },
    {
      "title": "multimodal_transformers.model.tabular_transformers \u2014 Multimodal Transformers documentation",
      "text": "- \u00bb\n- [Module code](https://multimodal-toolkit.readthedocs.io/en/latest/_modules/index.html) \u00bb\n- multimodal\\_transformers.model.tabular\\_transformers\n\n* * *\n\n# Source code for multimodal\\_transformers.model.tabular\\_transformers\n\n```\nfrom torch import nn\nfrom transformers import (\n    BertForSequenceClassification,\n    RobertaForSequenceClassification,\n    DistilBertForSequenceClassification,\n    AlbertForSequenceClassification,\n    XLNetForSequenceClassification,\n    XLMForSequenceClassification\n)\nfrom transformers.modeling_bert import BERT_INPUTS_DOCSTRING\nfrom transformers.modeling_roberta import ROBERTA_INPUTS_DOCSTRING\nfrom transformers.modeling_distilbert import DISTILBERT_INPUTS_DOCSTRING\nfrom transformers.modeling_albert import ALBERT_INPUTS_DOCSTRING\nfrom transformers.modeling_xlnet import XLNET_INPUTS_DOCSTRING\nfrom transformers.modeling_xlm import XLM_INPUTS_DOCSTRING\nfrom transformers.configuration_xlm_roberta import XLMRobertaConfig\nfrom transformers.file_utils import add_start_docstrings_to_callable\n\nfrom .tabular_combiner import TabularFeatCombiner\nfrom .tabular_config import TabularConfig\nfrom .layer_utils import MLP, calc_mlp_dims, hf_loss_func\n\n[docs]class BertWithTabular(BertForSequenceClassification):\n    \"\"\"\n    Bert Model transformer with a sequence classification/regression head as well as\n    a TabularFeatCombiner module to combine categorical and numerical features\n    with the Bert pooled output\n\n    Parameters:\n        hf_model_config (:class:`~transformers.BertConfig`):\n            Model configuration class with all the parameters of the model.\n            This object must also have a tabular_config member variable that is a\n            :obj:`TabularConfig` instance specifying the configs for :obj:`TabularFeatCombiner`\n    \"\"\"\n\n    def __init__(self, hf_model_config):\n        super().__init__(hf_model_config)\n        tabular_config = hf_model_config.tabular_config\n        if type(tabular_config) is dict:  # when loading from saved model\n            tabular_config = TabularConfig(**tabular_config)\n        else:\n            self.config.tabular_config = tabular_config.__dict__\n\n        tabular_config.text_feat_dim = hf_model_config.hidden_size\n        tabular_config.hidden_dropout_prob = hf_model_config.hidden_dropout_prob\n        self.tabular_combiner = TabularFeatCombiner(tabular_config)\n        self.num_labels = tabular_config.num_labels\n        combined_feat_dim = self.tabular_combiner.final_out_dim\n        if tabular_config.use_simple_classifier:\n            self.tabular_classifier = nn.Linear(combined_feat_dim,\n                                                tabular_config.num_labels)\n        else:\n            dims = calc_mlp_dims(combined_feat_dim,\n                                 division=tabular_config.mlp_division,\n                                 output_dim=tabular_config.num_labels)\n            self.tabular_classifier = MLP(combined_feat_dim,\n                                          tabular_config.num_labels,\n                                          num_hidden_lyr=len(dims),\n                                          dropout_prob=tabular_config.mlp_dropout,\n                                          hidden_channels=dims,\n                                          bn=True)\n\n[docs]    @add_start_docstrings_to_callable(BERT_INPUTS_DOCSTRING.format(\"(batch_size, sequence_length)\"))\n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        head_mask=None,\n        inputs_embeds=None,\n        labels=None,\n        class_weights=None,\n        output_attentions=None,\n        output_hidden_states=None,\n        cat_feats=None,\n        numerical_feats=None\n    ):\n        r\"\"\"\n        class_weights (:obj:`torch.FloatTensor` of shape :obj:`(tabular_config.num_labels,)`, `optional`, defaults to :obj:`None`):\n            Class weights to be used for cross entropy loss function for classification task\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n            Labels for computing the sequence classification/regression loss.\n            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n            If :obj:`tabular_config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n            If :obj:`tabular_config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n        cat_feats (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, tabular_config.cat_feat_dim)`, `optional`, defaults to :obj:`None`):\n            Categorical features to be passed in to the TabularFeatCombiner\n        numerical_feats (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, tabular_config.numerical_feat_dim)`, `optional`, defaults to :obj:`None`):\n            Numerical features to be passed in to the TabularFeatCombiner\n    Returns:\n        :obj:`tuple` comprising various elements depending on configuration and inputs:\n        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n            Classification (or regression if tabular_config.num_labels==1) loss.\n        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, tabular_config.num_labels)`):\n            Classification (or regression if tabular_config.num_labels==1) scores (before SoftMax).\n        classifier_layer_outputs(:obj:`list` of :obj:`torch.FloatTensor`):\n            The outputs of each layer of the final classification layers. The 0th index of this list is the\n            combining module's output\n        \"\"\"\n        outputs = self.bert(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            position_ids=position_ids,\n            head_mask=head_mask,\n            inputs_embeds=inputs_embeds,\n            output_attentions=output_attentions,\n            output_hidden_states=output_hidden_states,\n        )\n        pooled_output = outputs[1]\n        pooled_output = self.dropout(pooled_output)\n        combined_feats = self.tabular_combiner(pooled_output,\n                                               cat_feats,\n                                               numerical_feats)\n        loss, logits, classifier_layer_outputs = hf_loss_func(combined_feats,\n                                                              self.tabular_classifier,\n                                                              labels,\n                                                              self.num_labels,\n                                                              class_weights)\n        return loss, logits, classifier_layer_outputs\n\n[docs]class RobertaWithTabular(RobertaForSequenceClassification):\n    \"\"\"\n    Roberta Model transformer with a sequence classification/regression head as well as\n    a TabularFeatCombiner module to combine categorical and numerical features\n    with the Roberta pooled output\n\n    Parameters:\n        hf_model_config (:class:`~transformers.RobertaConfig`):\n            Model configuration class with all the parameters of the model.\n            This object must also have a tabular_config member variable that is a\n            :obj:`TabularConfig` instance specifying the configs for :obj:`TabularFeatCombiner`\n    \"\"\"\n    def __init__(self, hf_model_config):\n        super().__init__(hf_model_config)\n        tabular_config = hf_model_config.tabular_config\n        if type(tabular_config) is dict:  # when loading from saved model\n            tabular_config = TabularConfig(**tabular_config)\n        else:\n            self.config.tabular_config = tabular_config.__dict__\n\n        tabular_config.text_feat_dim = hf_model_config.hidden_size\n        tabular_config.hidden_dropout_prob = hf_model_config.hidden_dropout_prob\n        self.tabular_combiner = TabularFeatCombiner(tabular_config)\n        self.num_labels = tabular_config.num_labels\n        combined_feat_dim = self.tabular_combiner.final_ou...",
      "url": "https://multimodal-toolkit.readthedocs.io/en/latest/_modules/multimodal_transformers/model/tabular_transformers.html"
    },
    {
      "title": "Combining BERT/Transformers and Classical Tabular Models \u2014 AutoGluon Documentation 0.7.0 documentation",
      "text": "<div><div>\n<h2>Multimodal Data Tables: Combining BERT/Transformers and Classical Tabular Models<a href=\"#multimodal-data-tables-combining-bert-transformers-and-classical-tabular-models\">\u00b6</a></h2>\n<p><strong>Tip</strong>: If your data contains images, consider also checking out\n<a href=\"https://auto.gluon.ai/0.7.0/tutorials/tabular_prediction/tabular-multimodal.html#sec-tabularprediction-multimodal\"><span>Multimodal Data Tables: Tabular, Text, and Image</span></a> which handles images in\naddition to text and tabular features.</p>\n<p>Here we introduce how to use AutoGluon Tabular to deal with multimodal\ntabular data that contains text, numeric, and categorical columns. In\nAutoGluon, <strong>raw text data</strong> is considered as a first-class citizen of\ndata tables. AutoGluon Tabular can help you train and combine a diverse\nset of models including classical tabular models like\nLightGBM/RF/CatBoost as well as our pretrained NLP model based\nmultimodal network that is introduced in Section\n\u201c<span>sec_textprediction_architecture</span>\u201d of\n<span>sec_textprediction_multimodal</span> (used by AutoGluon\u2019s\n<code><span>TextPredictor</span></code>).</p>\n<div><pre><span></span><span>%</span><span>matplotlib</span> <span>inline</span>\n<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>\n<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>\n<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>\n<span>import</span> <span>pprint</span>\n<span>import</span> <span>random</span>\n<span>from</span> <span>autogluon.tabular</span> <span>import</span> <span>TabularPredictor</span>\n<span>np</span><span>.</span><span>random</span><span>.</span><span>seed</span><span>(</span><span>123</span><span>)</span>\n<span>random</span><span>.</span><span>seed</span><span>(</span><span>123</span><span>)</span>\n</pre></div>\n<div>\n<h2>Product Sentiment Analysis Dataset<a href=\"#product-sentiment-analysis-dataset\">\u00b6</a></h2>\n<p>We consider the product sentiment analysis dataset from a <a href=\"https://www.machinehack.com/hackathons/product_sentiment_classification_weekend_hackathon_19/leaderboard\">MachineHack\nhackathon</a>.\nThe goal is to predict a user\u2019s sentiment towards a product given their\nreview (raw text) and a categorical feature indicating the product\u2019s\ntype (e.g., Tablet, Mobile, etc.). We have already split the original\ndataset to be 90% for training and 10% for development/testing (if\nsubmitting your models to the hackathon, we recommend training them on\n100% of the dataset).</p>\n<div><pre><span></span>!mkdir -p product_sentiment_machine_hack\n!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/train.csv -O product_sentiment_machine_hack/train.csv\n!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/dev.csv -O product_sentiment_machine_hack/dev.csv\n!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/test.csv -O product_sentiment_machine_hack/test.csv\n</pre></div>\n<div><pre><span></span>--2023-02-22 23:29:24-- https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/train.csv\nResolving autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)... 52.217.130.97, 52.217.110.220, 52.216.137.228, ...\nConnecting to autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)|52.217.130.97|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 689486 (673K) [text/csv]\nSaving to: \u2018product_sentiment_machine_hack/train.csv\u2019\nproduct_sentiment_m 100%[===================&gt;] 673.33K --.-KB/s in 0.009s\n2023-02-22 23:29:24 (73.9 MB/s) - \u2018product_sentiment_machine_hack/train.csv\u2019 saved [689486/689486]\n--2023-02-22 23:29:24-- https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/dev.csv\nResolving autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)... 52.216.10.27, 52.217.225.57, 3.5.11.212, ...\nConnecting to autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)|52.216.10.27|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 75517 (74K) [text/csv]\nSaving to: \u2018product_sentiment_machine_hack/dev.csv\u2019\nproduct_sentiment_m 100%[===================&gt;] 73.75K --.-KB/s in 0.001s\n2023-02-22 23:29:24 (57.6 MB/s) - \u2018product_sentiment_machine_hack/dev.csv\u2019 saved [75517/75517]\n--2023-02-22 23:29:24-- https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/test.csv\nResolving autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)... 52.217.130.97, 52.216.10.27, 52.217.225.57, ...\nConnecting to autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)|52.217.130.97|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 312194 (305K) [text/csv]\nSaving to: \u2018product_sentiment_machine_hack/test.csv\u2019\nproduct_sentiment_m 100%[===================&gt;] 304.88K --.-KB/s in 0.002s\n2023-02-22 23:29:24 (137 MB/s) - \u2018product_sentiment_machine_hack/test.csv\u2019 saved [312194/312194]\n</pre></div>\n<div><pre><span></span><span>subsample_size</span> <span>=</span> <span>2000</span> <span># for quick demo, try setting to larger values</span>\n<span>feature_columns</span> <span>=</span> <span>[</span><span>'Product_Description'</span><span>,</span> <span>'Product_Type'</span><span>]</span>\n<span>label</span> <span>=</span> <span>'Sentiment'</span>\n<span>train_df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'product_sentiment_machine_hack/train.csv'</span><span>,</span> <span>index_col</span><span>=</span><span>0</span><span>)</span><span>.</span><span>sample</span><span>(</span><span>2000</span><span>,</span> <span>random_state</span><span>=</span><span>123</span><span>)</span>\n<span>dev_df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'product_sentiment_machine_hack/dev.csv'</span><span>,</span> <span>index_col</span><span>=</span><span>0</span><span>)</span>\n<span>test_df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'product_sentiment_machine_hack/test.csv'</span><span>,</span> <span>index_col</span><span>=</span><span>0</span><span>)</span>\n<span>train_df</span> <span>=</span> <span>train_df</span><span>[</span><span>feature_columns</span> <span>+</span> <span>[</span><span>label</span><span>]]</span>\n<span>dev_df</span> <span>=</span> <span>dev_df</span><span>[</span><span>feature_columns</span> <span>+</span> <span>[</span><span>label</span><span>]]</span>\n<span>test_df</span> <span>=</span> <span>test_df</span><span>[</span><span>feature_columns</span><span>]</span>\n<span>print</span><span>(</span><span>'Number of training samples:'</span><span>,</span> <span>len</span><span>(</span><span>train_df</span><span>))</span>\n<span>print</span><span>(</span><span>'Number of dev samples:'</span><span>,</span> <span>len</span><span>(</span><span>dev_df</span><span>))</span>\n<span>print</span><span>(</span><span>'Number of test samples:'</span><span>,</span> <span>len</span><span>(</span><span>test_df</span><span>))</span>\n</pre></div>\n<div><pre><span></span><span>Number</span> <span>of</span> <span>training</span> <span>samples</span><span>:</span> <span>2000</span>\n<span>Number</span> <span>of</span> <span>dev</span> <span>samples</span><span>:</span> <span>637</span>\n<span>Number</span> <span>of</span> <span>test</span> <span>samples</span><span>:</span> <span>2728</span>\n</pre></div>\n<p>There are two features in the dataset: the users\u2019 review of the product\nand the product\u2019s type, and four possible classes to predict.</p>\n<div>\n<table>\n <thead>\n <tr>\n <th></th>\n <th>Product_Description</th>\n <th>Product_Type</th>\n <th>Sentiment</th>\n </tr>\n </thead>\n <tbody>\n <tr>\n <th>4532</th>\n <td>they took away the lego pit but ...",
      "url": "https://auto.gluon.ai/0.7.0/tutorials/tabular_prediction/tabular-multimodal-text-others.html"
    },
    {
      "title": "Introduction by Example \u00b6",
      "text": "Introduction by Example &mdash; Multimodal Transformers documentation\n* [](../index.html)&raquo;\n* Introduction by Example\n* [Edit on GitHub](https://github.com/georgianpartners/Multimodal-Toolkit/blob/master/docs/source/notes/introduction.rst)\n# Introduction by Example[\u00b6](#introduction-by-example)\nThis guide covers how to use the transformer with tabular models in your own project. We use a`BertWithTabular`model as an example.\n* [How to Initialize Transformer With Tabular Models](#how-to-initialize-transformer-with-tabular-models)\n* [Forward Pass of Transformer With Tabular Models](#forward-pass-of-transformer-with-tabular-models)\n* [Modifications: Only One Type of Tabular Feature or No Tabular Features](#modifications-only-one-type-of-tabular-feature-or-no-tabular-features)\n* [Inference](#inference)\nFor a working script see the[github repository.](https://github.com/georgianpartners/Multimodal-Toolkit)\n## [How to Initialize Transformer With Tabular Models](#id1)[\u00b6](#how-to-initialize-transformer-with-tabular-models)\nThe models which support tabular features are located in[`multimodal\\_transformers.model.tabular\\_transformers`](../modules/model.html#module-multimodal_transformers.model.tabular_transformers).\nThese adapted transformer modules expect the same transformer config instances as\nthe ones from HuggingFace. However, expect a`multimodal\\_transformers.model.TabularConfig`instance specifying\nthe configs.\nSay for example we had categorical features of dim 9 and numerical features of dim 5.\n```\nfromtransformersimportBertConfigfrommultimodal\\_transformers.modelimportBertWithTabularfrommultimodal\\_transformers.modelimportTabularConfigbert\\_config=BertConfig.from\\_pretrained(&#39;bert-base-uncased&#39;)tabular\\_config=TabularConfig(combine\\_feat\\_method=&#39;&#39;attention\\_on\\_cat\\_and\\_numerical\\_feats&#39;&#39;,# change this to specify the method of combining tabular datacat\\_feat\\_dim=9,# need to specify thisnumerical\\_feat\\_dim=5,# need to specify thisnum\\_labels=2,# need to specify this, assuming our task is binary classificationuse\\_num\\_bn=False,)bert\\_config.tabular\\_config=tabular\\_configmodel=BertWithTabular.from\\_pretrained(&#39;bert-base-uncased&#39;,config=bert\\_config)\n```\nIn fact for any HuggingFace transformer model supported in[`multimodal\\_transformers.model.tabular\\_transformers`](../modules/model.html#module-multimodal_transformers.model.tabular_transformers)we\ncan initialize it using`multimodal\\_transformers.model.AutoModelWithTabular`to\nleverage any community trained transformer models\n```\nfromtransformersimportAutoConfigfrommultimodal\\_transformers.modelimportAutoModelWithTabularfrommultimodal\\_transformers.modelimportTabularConfighf\\_config=AutoConfig.from\\_pretrained(&#39;ipuneetrathore/bert-base-cased-finetuned-finBERT&#39;)tabular\\_config=TabularConfig(combine\\_feat\\_method=&#39;&#39;attention\\_on\\_cat\\_and\\_numerical\\_feats&#39;&#39;,# change this to specify the method of combining tabular datacat\\_feat\\_dim=9,# need to specify thisnumerical\\_feat\\_dim=5,# need to specify thisnum\\_labels=2,# need to specify this, assuming our task is binary classification)hf\\_config.tabular\\_config=tabular\\_configmodel=AutoModelWithTabular.from\\_pretrained(&#39;ipuneetrathore/bert-base-cased-finetuned-finBERT&#39;,config=hf\\_config)\n```\n## [Forward Pass of Transformer With Tabular Models](#id2)[\u00b6](#forward-pass-of-transformer-with-tabular-models)\nDuring the forward pass we pass HuggingFace\u2019s normal[transformer inputs](https://huggingface.co/transformers/glossary.html)as well as our categorical and numerical features.\nThe forward pass returns\n* `torch.FloatTensor`of shape`(1,)`: The classification (or regression if tabular\\_config.num\\_labels==1) loss\n* `torch.FloatTensor`of shape`(batch\\_size,tabular\\_config.num\\_labels)`: The classification (or regression if tabular\\_config.num\\_labels==1) scores (before SoftMax)\n* `list`of`torch.FloatTensor`The outputs of each layer of the final classification layers. The 0th index of this list is the\ncombining module\u2019s output\nThe following example shows a forward pass on two data examples\n```\nfromtransformersimportBertTokenizertokenizer=BertTokenizer.from\\_pretrained(&quot;bert-base-cased&quot;)text\\_1=&quot;HuggingFace is based in NYC&quot;text\\_2=&quot;Where is HuggingFace based?&quot;model\\_inputs=tokenizer([text\\_1,text\\_2])# 5 numerical featuresnumerical\\_feat=torch.rand(2,5).float()# 9 categorical featurescategorical\\_feat=torch.tensor([[0,0,0,1,0,1,0,1,0],[1,0,0,0,1,0,1,0,0]]).float()labels=torch.tensor([1,0])model\\_inputs[&#39;&#39;cat\\_feats&#39;&#39;]=categorical\\_featmodel\\_inputs[&#39;&#39;num\\_feats&#39;&#39;]=numerical\\_featmodel\\_inputs[&#39;labels&#39;]=labelsloss,logits,layer\\_outs=model(\\*\\*model\\_inputs)\n```\nWe can also pass in the arguments explicitly\n```\nloss,logits,layer\\_outs=model(model\\_inputs[&#39;&#39;input\\_ids&#39;&#39;],token\\_type\\_ids=model\\_inputs[&#39;&#39;token\\_type\\_ids&#39;&#39;],labels=labels,cat\\_feats=categorical\\_feat,numerical\\_feats=numerical\\_feat)\n```\n## [Modifications: Only One Type of Tabular Feature or No Tabular Features](#id3)[\u00b6](#modifications-only-one-type-of-tabular-feature-or-no-tabular-features)\nIf there are no tabular features, the models basically default to the ForSequenceClassification\nmodels from HuggingFace. We must specify`combine\\_feat\\_method='text\\_only'`in`multimodal\\_transformers.model.TabularConfig`. During the forward pass\nwe can simply pass the text related inputs\n```\nloss,logits,layer\\_outs=model(model\\_inputs[&#39;&#39;input\\_ids&#39;&#39;],token\\_type\\_ids=model\\_inputs[&#39;&#39;token\\_type\\_ids&#39;&#39;],labels=labels,)\n```\nIf only one of the features is available, we first must specify a`combine\\_feat\\_method`that supports only one type of feature available.\nSee supported methods for more details.\nWhen initializing our tabular config we specify the dimensions of the feature we have.\nFor example if we only have categorical features\n```\ntabular\\_config=TabularConfig(combine\\_feat\\_method=&#39;&#39;attention\\_on\\_cat\\_and\\_numerical\\_feats&#39;&#39;,# change this to specify the method of combining tabular datacat\\_feat\\_dim=9,# need to specify thisnum\\_labels=2,# need to specify this, assuming our task is binary classification)\n```\nDuring the forward pass, we also pass only the tabular data that we have.\n```\nloss,logits,layer\\_outs=model(model\\_inputs[&#39;&#39;input\\_ids&#39;&#39;],token\\_type\\_ids=model\\_inputs[&#39;&#39;token\\_type\\_ids&#39;&#39;],labels=labels,cat\\_feats=categorical\\_feat,)\n```\n## [Inference](#id4)[\u00b6](#inference)\nDuring inference we do not need to pass the labels and we can take the logits from the second output from the forward pass of the model.\n```\nwithtorch.no\\_grad():\\_,logits,classifier\\_outputs=model(model\\_inputs[&#39;&#39;input\\_ids&#39;&#39;],token\\_type\\_ids=model\\_inputs[&#39;&#39;token\\_type\\_ids&#39;&#39;],cat\\_feats=categorical\\_feat,numerical\\_feats=numerical\\_feat)\n```",
      "url": "https://multimodal-toolkit.readthedocs.io/en/latest/notes/introduction.html"
    },
    {
      "title": "Revisiting Multimodal Transformers for Tabular Data with Text Fields",
      "text": "<div><div><h5>Abstract</h5><p><span>Tabular data with text fields can be leveraged in applications such as financial risk assessment or medical diagnosis prediction. When employing multimodal approaches to make predictions based on these modalities, it is crucial to make the most appropriate modeling choices in terms of numerical feature encoding or fusion strategy. In this paper, we focus on multimodal classification tasks based on tabular datasets with text fields. We build on multimodal Transformers to propose the Tabular-Text Transformer (TTT), a tabular/text dual-stream Transformer network. This architecture includes a distance-to-quantile embedding scheme for numerical features and an overall attention module which concurrently considers self-attention and cross-modal attention. Further, we leverage the two well-informed modality streams to estimate whether a prediction is uncertain or not. To explain uncertainty in terms of feature values, we use a sampling-based approximation of Shapley values in a bimodal context, with two options for the value function. To show the efficacy and relevance of this approach, we compare it to six baselines and measure its ability to quantify and explain uncertainty against various methods. Our code is available at https://github.com/thomas-bonnier/TabularTextTransformer.</span></p></div></div>",
      "url": "https://aclanthology.org/2024.findings-acl.87"
    },
    {
      "title": "A Package for Learning on Tabular and Text Data with Transformers",
      "text": "Proceedings of the Third Workshop on Multimodal Artificial Intelligence, pages 69\u201373\nJune 6, 2021. \u00a92021 Association for Computational Linguistics\n69\nMultimodal-Toolkit: A Package for Learning on Tabular and\nText Data with Transformers\nKen Gu\nGeorgian\nken.gu@georgian.io\nAkshay Budhkar\nGeorgian\nakshay@georgian.io\nAbstract\nRecent progress in natural language process\u0002ing has led to Transformer architectures be\u0002coming the predominant model used for nat\u0002ural language tasks. However, in many real\u0002world datasets, additional modalities are in\u0002cluded which the Transformer does not di\u0002rectly leverage. We present Multimodal\u0002Toolkit,1\nan open-source Python package to\nincorporate text and tabular (categorical and\nnumerical) data with Transformers for down\u0002stream applications. Our toolkit integrates\nwell with Hugging Face\u2019s existing API such as\ntokenization and the model hub2 which allows\neasy download of different pre-trained models.\n1 Introduction\nIn recent years, Transformers (Vaswani et al.,\n2017) have become popular for model pre-training\n(Howard and Ruder, 2018; Peters et al., 2018; De\u0002vlin et al., 2019) and have yielded state-of-the-art\nresults on many natural language processing (NLP)\ntasks. In addition, well-documented Transformer\nlibraries such as Hugging Face Transformers (Wolf\net al., 2020), and AllenNLP (Gardner et al., 2018)\nhave democratized NLP, making it easier to pro\u0002ductionize and experiment on Transformers.\nHowever, there are not a lot of comprehensive\ntools for Transformers to work with tabular data.\nOften in real-world datasets, there are tabular data\nas well as unstructured text data which can pro\u0002vide meaningful signals for the task at hand. For\ninstance, in the small example in Figure 1, each\nrow is a data point. Columns Title and Review\nText contain text features, columns Division\nName, Class Name, and Department Name\ncontain categorical features, and the Age column\nis a numerical feature. To the best of our knowl\u0002edge, no tool exists that makes it simple for Trans\u0002formers to handle this extra modality. Therefore,\n1Github: https://git.io/JO5a6\n2https://huggingface.co/docs\nFigure 1: An example of a clothing review classifica\u0002tion dataset. Each row is a data point consisting of text,\ncategorical features, and numerical features.\ngiven the advances of Transformers for natural\nlanguage tasks and the maturity of existing Trans\u0002former libraries, we introduce Multimodal-Toolkit,\na lightweight Python package built on top of Hug\u0002ging Face Transformers. Our package extends ex\u0002isting Transformers in the Hugging Face\u2019s Trans\u0002formers library to seamlessly handle structured tab\u0002ular data while keeping the existing tokenization\n(including subword segmentation), experimental\npipeline, and pre-trained model hub functionalities\nof Hugging Face Transformers. We show the effec\u0002tiveness of our toolkit on three real-world datasets.\n2 Related Work\nThere have been several proposed Transformer\nmodels that aim to handle text features and addi\u0002tional features of another modality. For pre-trained\nTransformers on images and text, models such as\nViLBERT (Lu et al., 2019) and VLBERT (Su et al.,\n2020) are mainly the same as the original BERT\nmodel but treat the extra image modality as addi\u0002tional tokens to the input. These models require\npre-training on multimodal image and text data.\nOn the other hand, while treating image features\n70\nas additional input tokens, MMBT (Kiela et al.,\n2019) proposes to use pre-trained BERT directly\nand fine-tune on image and text data. This is simi\u0002lar to Multimodal-Toolkit in which no pre-training\non text and tabular data is needed.\nLikewise, Transformers have been adapted to\nalign, audio, visual, and text modalities in which\nthere is a natural ground truth alignment. MulT\n(Tsai et al., 2019) is similar to ViLBert in which\nco-attention is used between pairs of modalities but\nalso includes temporal convolutions so that input to\u0002kens are aware of their temporal neighbors. Mean\u0002while, Rahman et al. (2020) injects cross modality\nattention at certain Transformer layers via a gating\nmechanism.\nFinally, knowledge graph embeddings have also\nbeen effectively combined with input text tokens\nin Transformers. Ostendorff et al. (2019) com\u0002bines knowledge graph embeddings on authors\nwith book titles and other metadata features via\nsimple concatenation for book genre classification.\nOn the other hand, for more general language tasks,\nERNIE (Zhang et al., 2019) first matches the to\u0002kens in the input text with entities in the knowledge\ngraph. With this matching, the model fuses these\nembeddings to produce entity-aware text embed\u0002dings and text-aware entity embeddings.\nHowever, these models do not capture categor\u0002ical and numerical data explicitly. Hugging Face\ndoes include LXMERT (Tan and Bansal, 2019) to\nhandle language and vision modality but this can\nnot be easily adapted for categorical and numeri\u0002cal data. Nevertheless, existing multimodal Trans\u0002former models do give good insights into how to\ncombine categorical and numerical features. ViL\u0002BERT and VLBERT for example include image\nmodality as input tokens which lead to one of our\nsimple baseline of categorical and numerical fea\u0002tures as additional token inputs to the model. Like\u0002wise, the gating mechanism Rahman et al. (2020),\nattention, and different weighting schemes have\nall been shown to be useful in combining different\nmodalities.\n3 Design\nThe goal of Multimodal-Toolkit is to allow users\nto quickly adapt state-of-the-art Transformer mod\u0002els for situations involving text and tabular data\nwhich occur often in real-world datasets. More\u0002over, we want to bring the benefits of Transformers\nto more use cases while making it simple for users\nFigure 2: The framework of Multimodal-Toolkit.\nThere is a data processing module that outputs pro\u0002cessed text, numerical, and categorical features that are\nthen fed as input to our Transformer With Tabular mod\u0002ule consisting of a Hugging Face Transformer and our\ncombining module.\nof Hugging Face Transformers to adopt. Therefore,\nwe maintain the existing interface of the popular\nHugging Face Transformers library.\nThis design enables us to easily include more\nTransformer models, leverage strengths of spe\u0002cific models, use a feature-rich training pipeline,\nand integrate the thousands of community trained\nmodels on Hugging Face\u2019s model hub. We sup\u0002port a variety of Transformers (e.g. BERT, AL\u0002BERT, RoBERTa, XLNET) for both classification\nand regression tasks. All together, this becomes a\nreusable Transformer With Tabular component. We\nalso provide a data preprocessing module for cate\u0002gorical and numerical features. An overview of the\nsystem is shown in Figure 2. Currently, the library\nsupports PyTorch Transformers implementations.\n3.1 Combining Module\nWe implement a combining module that is model\nagnostic that takes as input, x, the text features\noutputted from a Transformer model and prepro\u0002cessed categorical (c) and numerical (n) features,\nand outputs a combined multimodal representation\nm. Although existing multimodal Transformers\nincorporate cross-modal attention inside middle\nTransformer layers, we choose the design in which\nthe modality combination comes after the Trans\u0002former because this module can be easily included\nwithout much adaptation of the existing Hugging\nFace Transformer interface and can be easily ex\u0002tended to new Transformers included in the future.\nInside the combining module, we implement var-\n71\nCombine Feature Method Equation\nText only m = x\nConcat m = x||c||n\nIndividual MLPs on categorical and\u0002numerical features then concat (MLP + Concat) m = x||MLP(c)||MLP(n)\nMLP on concatenated categorical and\nnumerical features then concat (Concat + MLP) m = x||MLP(c||n)\nAttention on categorical and numerical\nfeatures (Attention)\nm = \u03b1x,xWxx + \u03b1x,cWcc + \u03b1x,nWnn\n\u03b1i,j =\nexp(LeakyReLU(a\nT\n[Wixi||Wjxj ]))\nP\nk\u2208{x,c,n}\nexp(LeakyReLU(aT [Wixi||Wkxk]))\nGating on categorical and numerical\nfeatures and then sum (Rahman et al., 2020)\n(Gating)\nm = x + \u03b1h\nh = gc \f (Wcc...",
      "url": "https://aclanthology.org/2021.maiworkshop-1.10.pdf"
    },
    {
      "title": "How to Incorporate Tabular Data with HuggingFace Transformers - KDnuggets",
      "text": "# How to Incorporate Tabular Data with HuggingFace Transformers\n\nIn real-world scenarios, we often encounter data that includes text and tabular features. Leveraging the latest advances for transformers, effectively handling situations with both data structures can increase performance in your models.\n\n* * *\n\n[comments](https://www.kdnuggets.com/2020/11/tabular-data-huggingface-transformers.html#comments)\n\n**By [Ken Gu](https://www.linkedin.com/in/ken-gu/), Applied Research Scientist Intern at Georgian**.\n\nTransformer-based models are a game-changer when it comes to using unstructured text data. As of September 2020, the top-performing models in the General Language Understanding Evaluation (GLUE) benchmark are all BERT transformer-based models. At\u00a0[Georgian](http://georgian.io/), we find ourselves working with supporting tabular feature information as well as unstructured text data. We found that by using the tabular data in\u00a0[our models](http://georgian.io/platform/research-at-georgian/), we could further improve performance, so we set out to build a toolkit that makes it easier for others to do the same.\n\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2090%200'%3E%3C/svg%3E)\n\n_The 9 tasks that are part of the GLUE benchmark._\n\n### Building on Top of Transformers\n\nThe main benefits of using transformers are that they can learn long-range dependencies between text and can be trained in parallel (as opposed to sequence to sequence models), meaning they can be pre-trained on large amounts of data.\n\nGiven these advantages, BERT is now a staple model in many real-world applications. Likewise, with libraries such as [HuggingFace Transformers](https://huggingface.co/transformers/), it\u2019s easy to build high-performance transformer models on common NLP problems.\n\nTransformer models using unstructured text data are well understood. However, in the real-world, text data is often supported by rich structured data or other unstructured data like audio or visual information. Each one of these might provide signals that one alone would not. We call these different ways of experiencing data \u2014 audio, visual, or text \u2014 modalities.\n\nThink about e-commerce reviews as an example. In addition to the review text itself, we also have information about the seller, buyer, and product available as numerical and categorical features.\n\nWe set out to explore how we could use text and tabular data together to provide stronger signals in our projects. We started by exploring the field known as multimodal learning, which focuses on how to process different modalities in machine learning.\n\n### Multimodal Literature Review\n\nThe current models for multimodal learning mainly focus on learning from the sensory modalities such as audio, visual, and text.\n\nWithin multimodal learning, there are several branches of research. The MultiComp Lab at Carnegie Mellon University provides an excellent\u00a0[taxonomy](http://multicomp.cs.cmu.edu/research/taxonomy/). Our problem falls under what is known as\u00a0**Multimodal Fusion \u2014** joining information from two or more modalities to make a prediction.\n\nAs text data is our primary modality, our review focues on the literature that treats text as the main modality and introduces models that leverage the transformer architecture.\n\n**Trivial Solution to Structured Data**\n\nBefore we dive into the literature, it\u2019s worth mentioning that there is a simple solution that can be used where the structured data is treated as regular text and is appended to the standard text inputs. Taking the e-commerce reviews example, the input can be structured as follows: Review. Buyer Info. Seller Info. Numbers/Labels. Etc. One caveat with this approach, however, is that it is limited by the maximum token length that a transformer can handle.\n\n### Transformer on Images and Text\n\nIn the last couple of years, transformer extensions for image and text have really advanced.\u00a0[Supervised Multimodal Bitransformers for Classifying Images and Text](https://arxiv.org/pdf/1909.02950.pdf)\u00a0by Kiela et al. (2019) uses pre-trained ResNet and pre-trained BERT features on unimodal images and text, respectively, and feeds this into a Bidirectional transformer. The key innovation is adapting the image features as additional tokens to the transformer model.\n\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2090%200'%3E%3C/svg%3E)\n\n_An illustration of the multimodal transformer. This model takes the output of ResNet on subregions of the image as input image tokens._\n\nAdditionally, there are models \u2014\u00a0[ViLBERT](https://arxiv.org/abs/1908.02265)\u00a0(Lu et al. 2019) and [VLBert](https://arxiv.org/pdf/1908.08530.pdf)\u00a0(Su et al. 2020) \u2014 that define pretraining tasks for images and text. Both models pre-train on the\u00a0[Conceptual Captions dataset](https://ai.google.com/research/ConceptualCaptions), which contains roughly 3.3 million image-caption pairs (web images with captions from alt text). In both cases, for any given image, a pre-trained object detection model like Faster R-CNN obtains vector representations for regions of the image, which count as input token embeddings to the transformer model.\n\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2090%200'%3E%3C/svg%3E)\n\n_The VLBert model diagram. It takes image regions outputted by Faster R-CNN as input image tokens._\n\nAs an example, ViLBert pre-trains on the following training objectives:\n\n1. **Masked multimodal modeling:** Mask input image and word tokens. For the image, the model tries to predict a vector capturing image features for the corresponding image region, while for text, it predicts the masked text based on the textual and visual clues.\n2. **Multimodal alignment:** Whether the image and text pair are actually from the same image and caption pair.\n\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2090%200'%3E%3C/svg%3E)\n\n_The two pre-training tasks for ViLBert._\n\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20172%20226'%3E%3C/svg%3E)\n\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20156%20141'%3E%3C/svg%3E)\n\n_An example of masked multimodal learning. Given the image and text, if we mask out_ dog _, then the model should be able to use the unmasked visual information to correctly predict the masked word to be_ dog _._\n\nAll these models use the bidirectional transformer model that is the backbone of BERT. The differences are the pre-training tasks the models are trained on and slight additions to the transformer. In the case of ViLBERT, the authors also introduce a co-attention transformer layer (shown below) to define the attention mechanism between the modalities explicitly.\n\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2090%200'%3E%3C/svg%3E)\n\n_The standard transformer block vs. the co-attention transformer block. The co-attention block injects attention-weighted vectors of another modality (linguistic, for example) into the hidden representations of the current modality (visual)._\n\nFinally, there\u2019s also\u00a0[LXMERT](https://arxiv.org/abs/1908.07490)\u00a0(Tan and Mohit 2019), another pre-trained transformer model that, as of\u00a0[Transformers version 3.1.0](https://pypi.org/project/transformers/3.1.0/), is implemented as part of the library. The input to LXMERT is the same as ViLBERT and VLBERT. However, LXMERT pre-trains on aggregated datasets, which also include visual question answering datasets. In total, LXMERT pre-trains on 9.18 million image text pairs.\n\n### Transformers on Aligning Audio, Visual, and Text\n\nBeyond transformers for combining image and text, there are multimodal models for audio, video, and text modalities in which there is a natural ground truth temporal alignment. Papers for this approach include MulT, [Multimodal Transformer for Unaligned Multimodal Language Sequences](https://arx...",
      "url": "https://kdnuggets.com/2020/11/tabular-data-huggingface-transformers.html"
    },
    {
      "title": "Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/abs/2411.01645"
    }
  ]
}