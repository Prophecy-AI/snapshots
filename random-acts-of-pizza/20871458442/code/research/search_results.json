{
  "query": "What are the best techniques for handling class imbalance in text classification competitions?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Class imbalance is a pervasive problem in text\u2011classification contests because many real\u2011world label distributions follow a long\u2011tail pattern (e.g., sentiment, medical codes, patent categories).  The most effective ways to mitigate it combine **data\u2011level** and **algorithm\u2011level** strategies.  At the data level, oversampling the minority classes (random oversampling, SMOTE and its variants, or more sophisticated synthetic text generation) and undersampling the majority classes are still the workhorses; the imbalanced\u2011learn library provides a comprehensive guide to these samplers and shows how they can be applied to multi\u2011class text data ([imbalanced\u2011learn](https://imbalanced-learn.org/stable/user_guide.html)).  Recent systematic evaluations confirm that SMOTE\u2011based oversampling often yields the biggest boost for transformer\u2011based classifiers, while careful under\u2011sampling can reduce training time without harming performance ([Scientific Reports, 2025](https://www.nature.com/articles/s41598-025-05791-7)).\n\nAlgorithmic tweaks are equally important.  Re\u2011weighting the loss by the inverse class frequency or using **focal loss**\u2014which down\u2011weights easy majority examples\u2014has become a standard baseline and was shown to improve results on the SemEval\u20112025 Task\u202f9 competition ([Ustnlp16, 2025](https://arxiv.org/abs/2505.00021)).  More generally, the survey of class\u2011imbalance methods in NLP categorises effective approaches as loss\u2011function design, staged learning (e.g., a first stage on balanced data followed by fine\u2011tuning on the original distribution), and model\u2011design changes such as hierarchical classifiers ([Henning\u202fet\u202fal., 2023](https://arxiv.org/abs/2210.04675)).  Surprisingly, a recent study demonstrates that **tuning standard training components**\u2014larger batch sizes, stronger data augmentation (e.g., back\u2011translation), appropriate optimizers, and label smoothing\u2014can match or exceed specialized imbalance methods, offering a simple yet powerful recipe for competition settings ([Shwartz\u2011Ziv\u202fet\u202fal., 2023](https://arxiv.org/pdf/2312.02517.pdf)).\n\nIn practice, the best pipeline for a text\u2011classification contest typically starts with modest oversampling (or SMOTE) to give the minority classes enough signal, adds a class\u2011weighted or focal loss, and then fine\u2011tunes hyper\u2011parameters such as batch size, augmentation strength, optimizer choice, and label\u2011smoothing factor.  This combination leverages both data\u2011level balance and robust training dynamics, and has been validated across recent surveys, competition reports, and state\u2011of\u2011the\u2011art research.",
      "url": ""
    },
    {
      "title": "A Survey of Methods for Addressing Class Imbalance in Deep-Learning Based Natural Language Processing",
      "text": "[View PDF](https://arxiv.org/pdf/2210.04675)\n\n> Abstract:Many natural language processing (NLP) tasks are naturally imbalanced, as some target categories occur much more frequently than others in the real world. In such scenarios, current NLP models still tend to perform poorly on less frequent classes. Addressing class imbalance in NLP is an active research topic, yet, finding a good approach for a particular task and imbalance scenario is difficult.\n>\n> With this survey, the first overview on class imbalance in deep-learning based NLP, we provide guidance for NLP researchers and practitioners dealing with imbalanced data. We first discuss various types of controlled and real-world class imbalance. Our survey then covers approaches that have been explicitly proposed for class-imbalanced NLP tasks or, originating in the computer vision community, have been evaluated on them. We organize the methods by whether they are based on sampling, data augmentation, choice of loss function, staged learning, or model design. Finally, we discuss open problems such as dealing with multi-label scenarios, and propose systematic benchmarking and reporting in order to move forward on this problem as a community.\n\n## Submission history\n\nFrom: Sophie Henning \\[ [view email](https://arxiv.org/show-email/50bb0663/2210.04675)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2210.04675v1)**\nMon, 10 Oct 2022 13:26:40 UTC (94 KB)\n\n**\\[v2\\]**\nWed, 22 Feb 2023 10:39:43 UTC (196 KB)",
      "url": "https://arxiv.org/abs/2210.04675"
    },
    {
      "title": "Computer Science > Computation and Language",
      "text": "[2505.00021] Ustnlp16 at SemEval-2025 Task 9: Improving Model Performance through Imbalance Handling and Focal Loss\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2505.00021\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Computation and Language\n**arXiv:2505.00021**(cs)\n[Submitted on 24 Apr 2025]\n# Title:Ustnlp16 at SemEval-2025 Task 9: Improving Model Performance through Imbalance Handling and Focal Loss\nAuthors:[Zhuoang Cai](https://arxiv.org/search/cs?searchtype=author&amp;query=Cai,+Z),[Zhenghao Li](https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Z),[Yang Liu](https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y),[Liyuan Guo](https://arxiv.org/search/cs?searchtype=author&amp;query=Guo,+L),[Yangqiu Song](https://arxiv.org/search/cs?searchtype=author&amp;query=Song,+Y)\nView a PDF of the paper titled Ustnlp16 at SemEval-2025 Task 9: Improving Model Performance through Imbalance Handling and Focal Loss, by Zhuoang Cai and 4 other authors\n[View PDF](https://arxiv.org/pdf/2505.00021)[HTML (experimental)](https://arxiv.org/html/2505.00021v1)> > Abstract:\n> Classification tasks often suffer from imbal- anced data distribution, which presents chal- lenges in food hazard detection due to severe class imbalances, short and unstructured text, and overlapping semantic categories. In this paper, we present our system for SemEval- 2025 Task 9: Food Hazard Detection, which ad- dresses these issues by applying data augmenta- tion techniques to improve classification perfor- mance. We utilize transformer-based models, BERT and RoBERTa, as backbone classifiers and explore various data balancing strategies, including random oversampling, Easy Data Augmentation (EDA), and focal loss. Our ex- periments show that EDA effectively mitigates class imbalance, leading to significant improve- ments in accuracy and F1 scores. Furthermore, combining focal loss with oversampling and EDA further enhances model robustness, par- ticularly for hard-to-classify examples. These findings contribute to the development of more effective NLP-based classification models for food hazard detection. Subjects:|Computation and Language (cs.CL); Artificial Intelligence (cs.AI)|\nCite as:|[arXiv:2505.00021](https://arxiv.org/abs/2505.00021)[cs.CL]|\n|(or[arXiv:2505.00021v1](https://arxiv.org/abs/2505.00021v1)[cs.CL]for this version)|\n|[https://doi.org/10.48550/arXiv.2505.00021](https://doi.org/10.48550/arXiv.2505.00021)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Zhuoang Cai [[view email](https://arxiv.org/show-email/36d54e5c/2505.00021)]\n**[v1]**Thu, 24 Apr 2025 16:35:44 UTC (805 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Ustnlp16 at SemEval-2025 Task 9: Improving Model Performance through Imbalance Handling and Focal Loss, by Zhuoang Cai and 4 other authors\n* [View PDF](https://arxiv.org/pdf/2505.00021)\n* [HTML (experimental)](https://arxiv.org/html/2505.00021v1)\n* [TeX Source](https://arxiv.org/src/2505.00021)\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\nCurrent browse context:\ncs.CL\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2505.00021&amp;function=prev&amp;context=cs.CL) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2505.00021&amp;function=next&amp;context=cs.CL)\n[new](https://arxiv.org/list/cs.CL/new)|[recent](https://arxiv.org/list/cs.CL/recent)|[2025-05](https://arxiv.org/list/cs.CL/2025-05)\nChange to browse by:\n[cs](https://arxiv.org/abs/2505.00021?context=cs)\n[cs.AI](https://arxiv.org/abs/2505.00021?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2505.00021)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2505.00021)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2505.00021)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2505.00021&amp;description=Ustnlp16 at SemEval-2025 Task 9: Improving Model Performance through Imbalance Handling and Focal Loss>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2505.00021&amp;title=Ustnlp16 at SemEval-2025 Task 9: Improving Model Performance through Imbalance Handling and Focal Loss>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2505.00021)|[Disable MathJax](javascript:setMathjaxC...",
      "url": "https://arxiv.org/abs/2505.00021"
    },
    {
      "title": "User Guide #",
      "text": "User guide: contents &#8212; Version 0.14.1\n[Skip to main content](#main-content)\n**Back to top**Ctrl+K\n[![Version 0.14.1 - Home](_static/logo_wide.png)![Version 0.14.1 - Home](https://imbalanced-learn.org/stable/_static/img/logo_wide_dark.png)](index.html)\n**SearchCtrl+K\n******\n* [**GitHub](https://github.com/scikit-learn-contrib/imbalanced-learn)\n**SearchCtrl+K\n******\n* [**GitHub](https://github.com/scikit-learn-contrib/imbalanced-learn)\n# User Guide[#](#user-guide)\n* [1. Introduction](introduction.html)\n* [1.1. API\u2019s of imbalanced-learn samplers](introduction.html#api-s-of-imbalanced-learn-samplers)\n* [1.2. Problem statement regarding imbalanced data sets](introduction.html#problem-statement-regarding-imbalanced-data-sets)\n* [2. Over-sampling](over_sampling.html)\n* [2.1. A practical guide](over_sampling.html#a-practical-guide)\n* [2.1.1. Naive random over-sampling](over_sampling.html#naive-random-over-sampling)\n* [2.1.2. From random over-sampling to SMOTE and ADASYN](over_sampling.html#from-random-over-sampling-to-smote-and-adasyn)\n* [2.1.3. Ill-posed examples](over_sampling.html#ill-posed-examples)\n* [2.1.4. SMOTE variants](over_sampling.html#smote-variants)\n* [2.2. Mathematical formulation](over_sampling.html#mathematical-formulation)\n* [2.2.1. Sample generation](over_sampling.html#sample-generation)\n* [2.2.2. Multi-class management](over_sampling.html#multi-class-management)\n* [3. Under-sampling](under_sampling.html)\n* [3.1. Prototype generation](under_sampling.html#prototype-generation)\n* [3.2. Prototype selection](under_sampling.html#prototype-selection)\n* [3.2.1. Controlled under-sampling techniques](under_sampling.html#controlled-under-sampling-techniques)\n* [3.2.1.1. Random under-sampling](under_sampling.html#random-under-sampling)\n* [3.2.1.2. Mathematical formulation](under_sampling.html#mathematical-formulation)\n* [3.2.2. Cleaning under-sampling techniques](under_sampling.html#cleaning-under-sampling-techniques)\n* [3.2.2.1. Tomek\u2019s links](under_sampling.html#tomek-s-links)\n* [3.2.2.2. Editing data using nearest neighbours](under_sampling.html#editing-data-using-nearest-neighbours)\n* [3.2.2.2.1. Edited nearest neighbours](under_sampling.html#edited-nearest-neighbours)\n* [3.2.2.2.2. Repeated Edited Nearest Neighbours](under_sampling.html#repeated-edited-nearest-neighbours)\n* [3.2.2.2.3. All KNN](under_sampling.html#all-knn)\n* [3.2.2.3. Condensed nearest neighbors](under_sampling.html#condensed-nearest-neighbors)\n* [3.2.2.3.1. One Sided Selection](under_sampling.html#one-sided-selection)\n* [3.2.3. Additional undersampling techniques](under_sampling.html#additional-undersampling-techniques)\n* [3.2.3.1. Instance hardness threshold](under_sampling.html#id11)\n* [4. Combination of over- and under-sampling](combine.html)\n* [5. Ensemble of samplers](ensemble.html)\n* [5.1. Classifier including inner balancing samplers](ensemble.html#classifier-including-inner-balancing-samplers)\n* [5.1.1. Bagging classifier](ensemble.html#bagging-classifier)\n* [5.1.2. Forest of randomized trees](ensemble.html#forest-of-randomized-trees)\n* [5.1.3. Boosting](ensemble.html#boosting)\n* [6. Miscellaneous samplers](miscellaneous.html)\n* [6.1. Custom samplers](miscellaneous.html#custom-samplers)\n* [6.2. Custom generators](miscellaneous.html#custom-generators)\n* [6.2.1. TensorFlow generator](miscellaneous.html#tensorflow-generator)\n* [6.2.2. Keras generator](miscellaneous.html#keras-generator)\n* [7. Metrics](metrics.html)\n* [7.1. Classification metrics](metrics.html#classification-metrics)\n* [7.1.1. Sensitivity and specificity metrics](metrics.html#sensitivity-and-specificity-metrics)\n* [7.1.2. Additional metrics specific to imbalanced datasets](metrics.html#additional-metrics-specific-to-imbalanced-datasets)\n* [7.1.3. Macro-Averaged Mean Absolute Error (MA-MAE)](metrics.html#macro-averaged-mean-absolute-error-ma-mae)\n* [7.1.4. Summary of important metrics](metrics.html#summary-of-important-metrics)\n* [7.2. Pairwise metrics](metrics.html#pairwise-metrics)\n* [7.2.1. Value Difference Metric](metrics.html#value-difference-metric)\n* [8. Cross validation](model_selection.html)\n* [8.1. Instance hardness and average precision](model_selection.html#instance-hardness-and-average-precision)\n* [8.2. Create imbalanced dataset with samples with large instance hardness](model_selection.html#create-imbalanced-dataset-with-samples-with-large-instance-hardness)\n* [8.3. Assess cross validation performance variance using`InstanceHardnessCV`splitter](model_selection.html#assess-cross-validation-performance-variance-using-instancehardnesscv-splitter)\n* [9. Common pitfalls and recommended practices](common_pitfalls.html)\n* [9.1. Data leakage](common_pitfalls.html#data-leakage)\n* [10. Dataset loading utilities](datasets/index.html)\n* [10.1. Imbalanced datasets for benchmark](datasets/index.html#imbalanced-datasets-for-benchmark)\n* [10.2. Imbalanced generator](datasets/index.html#imbalanced-generator)\n* [11. Developer guideline](developers_utils.html)\n* [11.1. Developer utilities](developers_utils.html#developer-utilities)\n* [11.1.1. Validation Tools](developers_utils.html#validation-tools)\n* [11.1.2. Deprecation](developers_utils.html#deprecation)\n* [11.2. Making a release](developers_utils.html#making-a-release)\n* [11.2.1. Major release](developers_utils.html#major-release)\n* [11.2.2. Bug fix release](developers_utils.html#bug-fix-release)\n* [12. References](zzz_references.html)\n[**Edit on GitHub](https://github.com/scikit-learn-contrib/imbalanced-learn/edit/master/doc/user_guide.rst)\n### This Page\n* [Show Source](_sources/user_guide.rst.txt)",
      "url": "https://imbalanced-learn.org/stable/user_guide.html"
    },
    {
      "title": "A comprehensive evaluation of oversampling techniques for enhancing text classification performance",
      "text": "A comprehensive evaluation of oversampling techniques for enhancing text classification performance | Scientific Reports\n[Skip to main content](#content)\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\nthe best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\nInternet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\nand JavaScript.\nAdvertisement\n[![Scientific Reports](https://media.springernature.com/full/nature-cms/uploads/product/srep/header-d3c533c187c710c1bedbd8e293815d5f.svg)](https://www.nature.com/srep)\n* [View all journals](https://www.nature.com/siteindex)\n* [Search](#search-menu)\n* [Log in](https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41598-025-05791-7?error=cookies_not_supported&code=03e2ec5c-c011-4bec-9529-d28b11a510d0)\n* [ContentExplore content](#explore)\n* [Aboutthe journal](#about-the-journal)\n* [Publishwith us](#publish-with-us)\n* [Sign up for alerts](https://journal-alerts.springernature.com/subscribe?journal_id&#x3D;41598)\n* [RSS feed](https://www.nature.com/srep.rss)\nA comprehensive evaluation of oversampling techniques for enhancing text classification performance\n[Download PDF](https://www.nature.com/articles/s41598-025-05791-7.pdf)\n[Download PDF](https://www.nature.com/articles/s41598-025-05791-7.pdf)\n* Article\n* [Open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)\n* Published:01 July 2025# A comprehensive evaluation of oversampling techniques for enhancing text classification performance\n* [Salimkan Fatma Taskiran](#auth-Salimkan_Fatma-Taskiran-Aff1)[1](#Aff1),\n* [Bahaeddin Turkoglu](#auth-Bahaeddin-Turkoglu-Aff2)[2](#Aff2),\n* [Ersin Kaya](#auth-Ersin-Kaya-Aff1)[1](#Aff1)&amp;\n* \u2026* [Tunc Asuroglu](#auth-Tunc-Asuroglu-Aff3-Aff4)[3](#Aff3),[4](#Aff4)Show authors\n[*Scientific Reports*](https://www.nature.com/srep)**volume15**, Article\u00a0number:21631(2025)[Cite this article](#citeas)\n* 3628Accesses\n* 4Citations\n* [Metricsdetails](https://www.nature.com/articles/s41598-025-05791-7/metrics)\n### Subjects\n* [Computational science](https://www.nature.com/subjects/computational-science)\n* [Computer science](https://www.nature.com/subjects/computer-science)\n## Abstract\nClass imbalance is a common and critical challenge in text classification tasks, where the underrepresentation of certain classes often impairs the ability of classifiers to learn minority class patterns effectively. According to the \u201cgarbage in, garbage out\u201d principle, even high-performing models may fail when trained on skewed distributions. To address this issue, this study investigates the impact of oversampling techniques, specifically the Synthetic Minority Over-sampling Technique (SMOTE) and thirty of its variants, on two benchmark text classification datasets: TREC and Emotions. Each dataset was vectorized using the MiniLMv2 transformer model to obtain semantically rich representations, and classification was performed using six machine learning algorithms. The balanced and imbalanced scenarios were compared in terms of F1-Score and Balanced Accuracy. This work constitutes, to the best of our knowledge, the first large-scale, systematic benchmarking of SMOTE-based oversampling methods in the context of transformer-embedded text classification. Furthermore, statistical significance of the observed performance differences was validated using the Friedman test. The results provide practical insights into the selection of oversampling techniques tailored to dataset characteristics and classifier sensitivity, supporting more robust and fair learning in imbalanced natural language processing tasks.\n### Similar content being viewed by others\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-025-01031-0/MediaObjects/41598_2025_1031_Fig1_HTML.png)\n### [Mitigating class imbalance in churn prediction with ensemble methods and SMOTE](https://www.nature.com/articles/s41598-025-01031-0?fromPaywallRec=false)\nArticleOpen access09 May 2025\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-025-05122-w/MediaObjects/41598_2025_5122_Fig1_HTML.png)\n### [Smart adaptive ensemble model for multiclass imbalanced nonstationary data streams](https://www.nature.com/articles/s41598-025-05122-w?fromPaywallRec=false)\nArticleOpen access01 July 2025\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-025-13929-w/MediaObjects/41598_2025_13929_Fig1_HTML.png)\n### [Improving learning from the complex multi-class imbalanced and overlapped data by mapping into higher dimension using SVM++](https://www.nature.com/articles/s41598-025-13929-w?fromPaywallRec=false)\nArticleOpen access25 August 2025\n## Introduction\nImbalanced datasets represent a significant challenge commonly encountered in real-world problems. In the field of classification problems, imbalanced datasets arise when the numbers of samples representing different classes varies substantially[1](https://www.nature.com/articles/s41598-025-05791-7#ref-CR1). Such datasets can adversely impact the training process of classifier models. As the model tends to focus on the majority class during training, it may fail to adequately learn the minority classes. This issue becomes particularly pronounced in problems where certain classes have very few instances. Consequently, although the overall accuracy of the model may appear high, its performance in correctly classifying the minority class remains insufficient.\nClassification models typically operate under the assumption that each class within a dataset contains an equal number of instances. However, this assumption becomes inadequate when the minority class holds greater importance than others. Developing highly effective classifiers for such imbalanced datasets remains a significant challenge. As the imbalance in the dataset increases, the model tends to overfit the majority class, impairing its ability to achieve the desired performance on minority classes and leading to biased outcomes. Hence, the reliability of the model in real-world applications deteriorates, resulting in failures in critical scenarios where the accurate detection of minority classes is essential[2](https://www.nature.com/articles/s41598-025-05791-7#ref-CR2). The classification of text data frequently encounters severe class imbalance challenges in critical real-world applications, including hate speech detection, cyberbullying identification, fraud detection in communication systems, and sentiment analysis of underrepresented viewpoints[3](#ref-CR3),[4](#ref-CR4),[5](#ref-CR5),[6](#ref-CR6),[7](#ref-CR7),[8](#ref-CR8),[9](https://www.nature.com/articles/s41598-025-05791-7#ref-CR9). In these domains, failure to accurately detect minority classes can result in serious ethical, legal, and operational consequences. By systematically evaluating a broad range of SMOTE-based oversampling methods, this study offers a practical framework for enhancing classifier robustness and promoting fairness in imbalanced natural language processing tasks.\nImbalanced datasets constitute a prevalent challenge across various domains, irrespective of data type. In text classification, this imbalance often stems from the natural dominance of certain topics or sentiments over less frequent ones[10](https://www.nature.com/articles/s41598-025-05791-7#ref-CR10). For instance, in major natural language processing tasks such as sentiment analysis, positive reviews may substantially outnumber negative ones, resulting in an imbalanced dataset[11](https://www.nature.com/articles/s41598-025-05791-7#ref-CR11). This situation may cause models to preferentially learn majority classes while neglecting the minority ones. Several strategies have been developed to achieve successful outc...",
      "url": "https://www.nature.com/articles/s41598-025-05791-7"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2312.02517] Simplifying Neural Network Training Under Class Imbalance\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2312.02517\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2312.02517**(cs)\n[Submitted on 5 Dec 2023]\n# Title:Simplifying Neural Network Training Under Class Imbalance\nAuthors:[Ravid Shwartz-Ziv](https://arxiv.org/search/cs?searchtype=author&amp;query=Shwartz-Ziv,+R),[Micah Goldblum](https://arxiv.org/search/cs?searchtype=author&amp;query=Goldblum,+M),[Yucen Lily Li](https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Y+L),[C. Bayan Bruss](https://arxiv.org/search/cs?searchtype=author&amp;query=Bruss,+C+B),[Andrew Gordon Wilson](https://arxiv.org/search/cs?searchtype=author&amp;query=Wilson,+A+G)\nView a PDF of the paper titled Simplifying Neural Network Training Under Class Imbalance, by Ravid Shwartz-Ziv and Micah Goldblum and Yucen Lily Li and C. Bayan Bruss and Andrew Gordon Wilson\n[View PDF](https://arxiv.org/pdf/2312.02517)> > Abstract:\n> Real-world datasets are often highly class-imbalanced, which can adversely impact the performance of deep learning models. The majority of research on training neural networks under class imbalance has focused on specialized loss functions, sampling techniques, or two-stage training procedures. Notably, we demonstrate that simply tuning existing components of standard deep learning pipelines, such as the batch size, data augmentation, optimizer, and label smoothing, can achieve state-of-the-art performance without any such specialized class imbalance methods. We also provide key prescriptions and considerations for training under class imbalance, and an understanding of why imbalance methods succeed or fail. Comments:|NeurIPS 2023. Code available at[this https URL](https://github.com/ravidziv/SimplifyingImbalancedTraining)|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI)|\nCite as:|[arXiv:2312.02517](https://arxiv.org/abs/2312.02517)[cs.LG]|\n|(or[arXiv:2312.02517v1](https://arxiv.org/abs/2312.02517v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2312.02517](https://doi.org/10.48550/arXiv.2312.02517)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Ravid Shwartz Ziv [[view email](https://arxiv.org/show-email/a0fb557a/2312.02517)]\n**[v1]**Tue, 5 Dec 2023 05:52:44 UTC (3,675 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Simplifying Neural Network Training Under Class Imbalance, by Ravid Shwartz-Ziv and Micah Goldblum and Yucen Lily Li and C. Bayan Bruss and Andrew Gordon Wilson\n* [View PDF](https://arxiv.org/pdf/2312.02517)\n* [TeX Source](https://arxiv.org/src/2312.02517)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2312.02517&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2312.02517&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2023-12](https://arxiv.org/list/cs.LG/2023-12)\nChange to browse by:\n[cs](https://arxiv.org/abs/2312.02517?context=cs)\n[cs.AI](https://arxiv.org/abs/2312.02517?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2312.02517)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2312.02517)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2312.02517)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2312.02517&amp;description=Simplifying Neural Network Training Under Class Imbalance>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2312.02517&amp;title=Simplifying Neural Network Training Under Class Imbalance>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2312.02517)|[Disable MathJax](javascript:setMathjaxCookie())([What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2312.02517"
    },
    {
      "title": "A Survey of Methods for Addressing Class Imbalance in Deep-Learning Based Natural Language Processing",
      "text": "## [A Survey of Methods for Addressing Class Imbalance in Deep-Learning Based Natural Language Processing](https://aclanthology.org/2023.eacl-main.38.pdf)\n\n[Sophie Henning](https://aclanthology.org/people/sophie-henning/),\n[William Beluch](https://aclanthology.org/people/william-beluch/),\n[Alexander Fraser](https://aclanthology.org/people/alexander-fraser/),\n[Annemarie Friedrich](https://aclanthology.org/people/annemarie-friedrich/)\n\n##### Abstract\n\nMany natural language processing (NLP) tasks are naturally imbalanced, as some target categories occur much more frequently than others in the real world. In such scenarios, current NLP models tend to perform poorly on less frequent classes. Addressing class imbalance in NLP is an active research topic, yet, finding a good approach for a particular task and imbalance scenario is difficult. In this survey, the first overview on class imbalance in deep-learning based NLP, we first discuss various types of controlled and real-world class imbalance. Our survey then covers approaches that have been explicitly proposed for class-imbalanced NLP tasks or, originating in the computer vision community, have been evaluated on them. We organize the methods by whether they are based on sampling, data augmentation, choice of loss function, staged learning, or model design. Finally, we discuss open problems and how to move forward.\n\nAnthology ID:2023.eacl-main.38Volume:[Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics](https://aclanthology.org/volumes/2023.eacl-main/)Month:MayYear:2023Address:Dubrovnik, CroatiaEditors:[Andreas Vlachos](https://aclanthology.org/people/andreas-vlachos/),\n[Isabelle Augenstein](https://aclanthology.org/people/isabelle-augenstein/)Venue:[EACL](https://aclanthology.org/venues/eacl/)SIG:Publisher:Association for Computational LinguisticsNote:Pages:523\u2013540Language:URL:[https://aclanthology.org/2023.eacl-main.38/](https://aclanthology.org/2023.eacl-main.38/)DOI:[10.18653/v1/2023.eacl-main.38](https://doi.org/10.18653/v1/2023.eacl-main.38)Bibkey:henning-etal-2023-surveyCite (ACL):Sophie Henning, William Beluch, Alexander Fraser, and Annemarie Friedrich. 2023. [A Survey of Methods for Addressing Class Imbalance in Deep-Learning Based Natural Language Processing](https://aclanthology.org/2023.eacl-main.38/). In _Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics_, pages 523\u2013540, Dubrovnik, Croatia. Association for Computational Linguistics.Cite (Informal):[A Survey of Methods for Addressing Class Imbalance in Deep-Learning Based Natural Language Processing](https://aclanthology.org/2023.eacl-main.38/) (Henning et al., EACL 2023)Copy Citation:BibTeXMarkdownMODS XMLEndnoteMore options\u2026PDF:[https://aclanthology.org/2023.eacl-main.38.pdf](https://aclanthology.org/2023.eacl-main.38.pdf)Video:[https://aclanthology.org/2023.eacl-main.38.mp4](https://aclanthology.org/2023.eacl-main.38.mp4)\n\n[PDF](https://aclanthology.org/2023.eacl-main.38.pdf) [Cite](https://aclanthology.org/aclanthology.org) [Search](https://www.semanticscholar.org/search?q=A+Survey+of+Methods+for+Addressing+Class+Imbalance+in+Deep-Learning+Based+Natural+Language+Processing) [Video](https://aclanthology.org/2023.eacl-main.38.mp4) [Fix data](https://aclanthology.org/aclanthology.org)",
      "url": "https://aclanthology.org/2023.eacl-main.38"
    },
    {
      "title": "",
      "text": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 523\u2013540\nMay 2-6, 2023 \u00a92023 Association for Computational Linguistics\nA Survey of Methods for Addressing Class Imbalance\nin Deep-Learning Based Natural Language Processing\nSophie Henning1,2 William Beluch1 Alexander Fraser2 Annemarie Friedrich1\n1 Bosch Center for Artificial Intelligence, Renningen, Germany\n2 Center for Information and Language Processing, LMU Munich, Germany\nsophieelisabeth.henning|william.beluch@de.bosch.com\nfraser@cis.lmu.de\nannemarie.friedrich@de.bosch.com\nAbstract\nMany natural language processing (NLP) tasks\nare naturally imbalanced, as some target cate\u0002gories occur much more frequently than others\nin the real world. In such scenarios, current\nNLP models tend to perform poorly on less\nfrequent classes. Addressing class imbalance\nin NLP is an active research topic, yet, finding\na good approach for a particular task and im\u0002balance scenario is difficult.\nIn this survey, the first overview on class im\u0002balance in deep-learning based NLP, we first\ndiscuss various types of controlled and real\u0002world class imbalance. Our survey then covers\napproaches that have been explicitly proposed\nfor class-imbalanced NLP tasks or, originating\nin the computer vision community, have been\nevaluated on them. We organize the methods\nby whether they are based on sampling, data\naugmentation, choice of loss function, staged\nlearning, or model design. Finally, we discuss\nopen problems and how to move forward.\n1 Introduction\nClass imbalance is a major problem in natural lan\u0002guage processing (NLP), because target category\ndistributions are almost always skewed in NLP\ntasks. As illustrated by Figure 1, this often leads to\npoor performance on minority classes. Which cate\u0002gories matter is highly task-specific and may even\ndepend on the intended downstream use. Develop\u0002ing methods that improve model performance in\nimbalanced data settings has been an active area for\ndecades (e.g., Bruzzone and Serpico, 1997; Japkow\u0002icz et al., 2000; Estabrooks and Japkowicz, 2001;\nPark and Zhang, 2002; Tan, 2005), and is recently\ngaining momentum in the context of maturing neu\u0002ral approaches (e.g., Buda et al., 2018; Kang et al.,\n2020; Li et al., 2020; Yang et al., 2020; Jiang et al.,\n2021; Spangher et al., 2021). The problem is exac\u0002erbated when classes overlap in the feature space\n(Lin et al., 2019; Tian et al., 2020). For example,\nlabels\n0k\n2.5k\n#train inst.\n10\n1 10\n2 103\nlabel count\n0\n1\ntest F1\n(a) Single-label relation\nclassification on TACRED\n(Zhou and Chen, 2021)\nlabels\n0k\n1k\n#train inst.\n10\n1 10\n2 103\nCPC class train count\n0\n1\ntest F1\n(b) Hierarchical multi-label\npatent classification\n(Pujari et al., 2021)\nlabels\n0k\n2.5k\n#train inst.\n3000 2000 1000 0\nlabel count\n0\n1\ntest F1\n(c) Implicit discourse rela\u0002tion classification (PDTB)\n(Shi and Demberg, 2019)\nlabels\n0k\n20k\n#train inst.\n10\n2 10\n4\nrelation train count\n0\n1\ndev F1\n(d) UD dependency parsing\nusing RoBERTa on EWT\n(Gr\u00fcnewald et al., 2021)\nFigure 1: Class imbalance has a negative effect on per\u0002formance especially for minority classes in a variety of\nNLP tasks. Upper charts show label count distributions,\nlower part show test/dev F1 by training instance count\n(lighter colors indicate fewer test/dev instances). All\nmodels are based on transformers.\nin patent classification, technical categories differ\nlargely in frequency, and the concepts mentioned\nin the different categories can be very similar.\nOn a large variety of NLP tasks, transformer\nmodels such as BERT (Vaswani et al., 2017; Devlin\net al., 2019) outperform both their neural predeces\u0002sors and traditional models (Liu et al., 2019; Xie\net al., 2020; Mathew et al., 2021). Performance\nfor minority classes is also often higher when us\u0002ing self-supervised pre-trained models (e.g., Li and\nScarton, 2020; Niklaus et al., 2021), which paral\u0002lels findings from computer vision (Liu et al., 2022).\nHowever, the advent of BERT has not solved the\nclass imbalance problem in NLP, as illustrated by\nFigure 1. T\u00e4nzer et al. (2022) find that on syn\u0002thetically imbalanced named entity datasets with\n523\n0\n500\n1000\n# of samples\n(a) Step imbalance, \u00b5 = 0.4, \u03c1 = 10\n0\n500\n1000\n(b) Linear imbalance, \u03c1 = 10\n0\n500\n1000\n(c) Long-tailed distribution\nFigure 2: Instance counts per label follow different distributions: examples of class imbalance types.\nmajority classes having thousands of examples, at\nleast 25 instances are required to predict a class\nat all, and 100 examples to learn to predict it with\nsome accuracy.\nDespite the relevance of class imbalance to NLP,\nrelated surveys only exist in the computer vision\ndomain (Johnson and Khoshgoftaar, 2019b; Zhang\net al., 2021b). Incorporating methods addressing\nclass imbalance can lead to performance gains of\nup to 20%. Yet, NLP research often overlooks how\nimportant this is in practical applications, where\nminority classes may be of special interest.\nOur contribution is to draw a clear landscape\nof approaches applicable to deep-learning (DL)\nbased NLP. We set out with a problem defini\u0002tion (Sec. 2), and then organize approaches by\nwhether they are based on sampling, data aug\u0002mentation, choice of loss function, staged learn\u0002ing, or model design (Sec. 3). Our extensive sur\u0002vey finds that re-sampling, data augmentation, and\nchanging the loss function can be relatively simple\nways to increase performance in class-imbalanced\nsettings and are thus straightforward choices for\nNLP practitioners.1 While promising research di\u0002rections, staged learning or model modifications\noften are implementation-wise and/or computation\u0002ally costlier. Moreover, we discuss particular chal\u0002lenges of non-standard classification settings, e.g.,\nimbalanced multi-label classification and catch-all\nclasses, and provide useful connections to related\ncomputer vision work. Finally, we outline promis\u0002ing directions for future research (Sec. 4).\nScope of this survey. We focus on approaches\nevaluated on or developed for neural methods.\nWork from \u201ctraditional\u201d NLP (e.g., Tomanek and\nHahn, 2009; Li et al., 2011; Li and Nenkova, 2014;\nKunchukuttan and Bhattacharyya, 2015) as well as\nNatural Language Generation (e.g., Nishino et al.,\n2020) and Automatic Speech Recognition (e.g.,\nWinata et al., 2020; Deng et al., 2022) are not ad\u00021We provide practical advice on identifying potentially ap\u0002plicable class imbalance methods in the Appendix (Figure 3).\ndressed in this survey. Other types of imbalances\nsuch as differently sized data sets of subtasks in\ncontinual learning (Ahrens et al., 2021) or imbal\u0002anced regression (Yang et al., 2021) are also beyond\nthe scope of this survey. In Sec. 3.5, we briefly\ntouch upon the related area of few-shot learning\n(Wang et al., 2020c).\nRelated surveys. We review imbalance-specific\ndata augmentation approaches in Sec. 3.2. Feng\net al. (2021) give a broader overview of data aug\u0002mentation in NLP, Hedderich et al. (2021) provide\nan overview of low-resource NLP, and Ramponi\nand Plank (2020) discuss neural domain adaptation.\n2 Problem Definition\nClass imbalance refers to a classification set\u0002ting in which one or multiple classes (minority\nclasses) are considerably less frequent than others\n(majority classes). More concrete definitions, e.g.,\nregarding the relative share up to which a class\nis seen as a minority class, depend on the task,\ndataset and labelset size. Much research focuses on\nimproving all minority classes equally while main\u0002taining or at least monitoring majority class perfor\u0002mance (e.g., Huang et al., 2021; Yang et al., 2020;\nSpangher et al., 2021). We next discuss prototypi\u0002cal types of imbalance (Sec. 2.1) and then compare\ncontrolled and real-world settings (Sec. 2.2).\n2.1 Types of Imbalance\nTo systematically investigate the effect of imbal\u0002ance, Buda et al. (2018) define two prototypical\ntypes of label distributions, which we explain next.\nStep imbalance is characterized by the fraction\nof minority classes, \u00b5, and the size ratio between\nma...",
      "url": "https://aclanthology.org/2023.eacl-main.38.pdf"
    },
    {
      "title": "Methods for addressing class imbalance in deep learning-based natural language processing - \u0391\u0399hub",
      "text": "<div><div> \n \n \n \n \n \n \n \n <p><em>Figure 1: Modern Transformer-based Natural Language Processing (NLP) methods still struggle with <strong>class imbalance</strong>: class-wise performance (second row, each dot represents one class) decreases with class frequency in training data (first row) for a variety of NLP tasks. Datasets/scores: <a href=\"https://nlp.stanford.edu/projects/tacred/\">TACRED</a>, <a href=\"https://arxiv.org/abs/2102.01373\">Zhou and Chen [2021]</a>, <a href=\"https://github.com/boschresearch/hierarchical_patent_classification_ecir2021\">USPTO</a>, <a href=\"https://link.springer.com/chapter/10.1007/978-3-030-72113-8_34\">Pujari et al. [2021]</a>, <a href=\"http://lrec-conf.org/proceedings/lrec2008/pdf/754_paper.pdf\">PDTB</a>, <a href=\"https://aclanthology.org/D19-1586/\">Shi and Demberg [2019]</a>, <a href=\"https://universaldependencies.org/treebanks/en_ewt/index.html\">UD-EWT</a>, <a href=\"https://aclanthology.org/2021.iwpt-1.13/\">Gr\u00fcnewald et al. [2021]</a>.</em></p>\n<p>Natural Language Processing (NLP) tasks are often addressed by training supervised models using manually labeled datasets. This comes with the challenge that categories rarely occur with the exact same frequency; in practice, the distribution of samples across classes is usually highly skewed. In sentiment analysis, there may be a large number of negative reviews, with only a small number of positive reviews. Text classification tasks such as patent categorization or medical code prediction even use inventories of hundreds of classes with label distributions following a long tail.</p>\n<p>Such <strong>class imbalance</strong> in the training and evaluation datasets can pose a challenge for NLP models, which are more heavily influenced by majority class data during training. As a result, NLP models tend to perform poorly on the minority classes, which often contain the cases that are most important and informative to the downstream user. For example, the TACRED relation extraction dataset covers more than 40 relations between entities such as persons and organizations, e.g., <span>org:founded_by</span> indicates the founder of an organization. An infrequent relation in this dataset is <span>org:shareholders</span>, which holds between organizations and their shareholders. Though infrequent, the relation may be of special interest in a business use case that aims to identify the players in a business field. While impressive improvements have been measured on NLP benchmarks in the past years, the problem of training models in class-imbalanced scenarios remains challenging (see Figure 1).</p>\n<p>Whether you are an NLP researcher or an NLP developer, you have probably come across this issue and may now be looking for options how to address it. This blogpost gives an overview of class imbalance methods for deep learning-based NLP organized by method type <a href=\"https://doi.org/10.48550/arXiv.2210.04675\">[Henning et al., 2022]</a>. Which methods are suitable for your use case depends on the nature of your classification task, e.g., whether all classes are equally important to you, and also on practical considerations such as computational resources. Our practical decision aid in Figure 2 suggests starting points for typical use cases. We then give intuitive explanations for a selected set of methods for addressing class imbalance in NLP. At the end, we discuss open challenges and directions for further research.</p>\n<p><em>Figure 2: A practical decision aid for addressing class-imbalanced problems in NLP following <a href=\"https://doi.org/10.48550/arXiv.2210.04675\">Henning et al. [2022]</a>.</em></p>\n<h4>What is Natural Language Processing?</h4>\n<p>NLP aims to enable computers to understand, interpret, and generate human language and is thus an interdisciplinary field at the intersection of linguistics, computer science, and artificial intelligence. Recent advances in NLP have been driven by the availability of large datasets and the development of powerful deep learning models such as Transformers.</p>\n<h4>How does class imbalance affect NLP models?</h4>\n<p>If a model fails to learn a good decision boundary easily, it will predict the majority class in case of doubt. This problem may be aggravated in NLP tasks that require treating a large, often heterogenous <strong>catch-all class</strong> that contains all instances that are not of interest to the task, while the remaining (minority) classes are approximately same-sized. An example of this is the \u201cOutside\u201d label in <a href=\"https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)\">IOB sequence tagging</a>.</p>\n<p><strong>Evaluation results</strong> might be misleading in class-imbalanced scenarios. For example, accuracy might be high even if the model does not predict the minority class(es) at all. Accuracy is an example of a metric that is dominated by the large classes \u2013 every instance contributes equally to the metric and large classes have many more instances than the minority class(es). It is therefore important to carefully choose evaluation metrics that are appropriate for the use case. For instance, if all classes are equally important, the unweighted average of per-class <a href=\"https://en.wikipedia.org/wiki/F-score\">F1 scores</a> (<em>macro F1</em>) is a viable option. If we care mainly about finding instances of a minority class as in the org:shareholder problem above, optimizing for the F1 score of this class may be more meaningful.</p>\n<h4>Re-Sampling</h4>\n<p><em>Figure 3: Random oversampling usually outperforms undersampling, but increases training time.</em></p>\n<p>To increase the importance of minority instances in training, the label distribution can be changed by various sampling strategies that duplicate or remove instances. Sampling can either be executed once or repeatedly during training. In <em>random oversampling</em> (<strong>ROS</strong>), a random choice of minority instances are duplicated, whereas in <em>random undersampling</em> (<strong>RUS</strong>), a random choice of majority instances are removed from the dataset (see Figure 3). When applied in deep learning, ROS usually outperforms RUS. More flexible class-based sampling variants can also further improve results. For example, the amount of re-sampling can be tuned separately for each class. This can be done repeatedly during training based on the current model performance on the various classes.</p>\n<p>In multi-label classification, over-sampling an instance with a minority label may simultaneously amplify the majority class count due to label dependencies between majority and minority classes <a href=\"https://aclanthology.org/2021.emnlp-main.643\">[Huang et al., 2021]</a>. Effective sampling in such settings is still an open issue. Existing approaches monitor the class distributions during sampling or assign instance-based sampling probabilities.</p>\n<p>A good starting point for implementing sampling techniques is the <a href=\"https://imbalanced-learn.org/stable/\">imblearn package</a> for Python.</p>\n<h4>Data Augmentation</h4>\n<p>While re-sampling approaches make the model focus more on the minority classes and thereby can lead to moderate gains, their effectiveness is inherently limited by the available data. To overcome this limitation, one could, for instance, write or select additional minority examples. However, this is particularly laborious in naturally imbalanced settings. First, looking for additional minority instances means trying to find the needle in the haystack. By definition, minority instances are rare in natural data, so large amounts of text data need to be collected to retrieve these instances. Second, the minority class examples found with this type of effort may be biased, e.g., due to collection via keyword queries. Synthetically generating additional minority instances (see Figure 4) thus is a promising direction.</p>\n<p><em>Figure 4: Data Augmentation methods can help in class-imbalanced N...",
      "url": "https://aihub.org/2023/03/30/methods-for-addressing-class-imbalance-in-deep-learning-based-natural-language-processing"
    }
  ]
}