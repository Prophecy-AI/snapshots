{
  "query": "What are winning approaches for text classification with metadata features on Kaggle?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Winning Kaggle solutions for text\u2011classification tasks that also contain rich metadata usually treat the non\u2011text fields as a **second modality** and fuse them with a strong language model.  A common recipe is to (1)\u202ffine\u2011tune a pretrained transformer (BERT, RoBERTa, etc.) on the raw text, (2)\u202fencode categorical or numerical metadata either as additional tokens that are prepended/appended to the input sequence or as separate embeddings that are concatenated to the final CLS vector, and (3)\u202ftrain a lightweight tabular model (e.g., LightGBM, CatBoost) on the same metadata and blend its predictions with the transformer output.  This \u201ctext\u2011plus\u2011metadata\u201d strategy is illustrated by the\u202fMessagenet\u202fapproach, which builds dedicated blocks for each metadata type (sender, timestamp, etc.) and jointly trains them with a BERT backbone, yielding higher accuracy than text\u2011only models\u202f([arxiv](https://export.arxiv.org/pdf/2301.01808v1.pdf)).  A simpler but equally effective technique is to turn metadata into a short string (e.g.,\u202f`author=John|date=2022\u201101`) and prepend it to the document before tokenisation; the\u202fMcCormick\u202ftutorial shows that this \u201cfeatures\u2011to\u2011text\u201d trick works best for a Kaggle clothing\u2011review dataset\u202f([mccormickml.com](https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert)).  \n\nBeyond the fusion step, the **META** framework demonstrates that metadata can also serve as a source of weak supervision.  By constructing a text\u2011rich network of documents and their metadata and extracting high\u2011confidence \u201cseed motifs,\u201d META iteratively expands both seed words and seed motifs to generate pseudo\u2011labels, achieving state\u2011of\u2011the\u2011art performance on real\u2011world datasets\u202f([aclanthology](https://aclanthology.org/2020.emnlp-main.670)).  Kaggle competitors often adopt a similar idea: they create label\u2011rich features from metadata (e.g., author reputation, tweet country, keyword frequency) and use them either as additional inputs to the model or as auxiliary targets in a multi\u2011task setup.  \n\nFinally, the usual Kaggle \u201cbest\u2011practice\u201d toolbox\u2014large pretrained language models, aggressive data cleaning, stratified cross\u2011validation, and model ensembling\u2014remains essential.  The Neptune blog summarises the top tricks from several high\u2011paying Kaggle competitions, noting that blending text\u2011only and metadata\u2011aware models consistently pushes scores into the winning range\u202f([neptune.ai](https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions)).  Combining these ideas\u2014metadata\u2011driven weak supervision, multimodal transformer architectures, and robust ensembling\u2014constitutes the current winning playbook for text classification with metadata on Kaggle.",
      "url": ""
    },
    {
      "title": "META: Metadata-Empowered Weak Supervision for Text Classification",
      "text": "## [META: Metadata-Empowered Weak Supervision for Text Classification](https://aclanthology.org/2020.emnlp-main.670.pdf)\n\n[Dheeraj Mekala](https://aclanthology.org/people/dheeraj-mekala/),\n[Xinyang Zhang](https://aclanthology.org/people/xinyang-zhang/),\n[Jingbo Shang](https://aclanthology.org/people/jingbo-shang/)\n\n##### Abstract\n\nRecent advances in weakly supervised learning enable training high-quality text classifiers by only providing a few user-provided seed words. Existing methods mainly use text data alone to generate pseudo-labels despite the fact that metadata information (e.g., author and timestamp) is widely available across various domains. Strong label indicators exist in the metadata and it has been long overlooked mainly due to the following challenges: (1) metadata is multi-typed, requiring systematic modeling of different types and their combinations, (2) metadata is noisy, some metadata entities (e.g., authors, venues) are more compelling label indicators than others. In this paper, we propose a novel framework, META, which goes beyond the existing paradigm and leverages metadata as an additional source of weak supervision. Specifically, we organize the text data and metadata together into a text-rich network and adopt network motifs to capture appropriate combinations of metadata. Based on seed words, we rank and filter motif instances to distill highly label-indicative ones as \u201cseed motifs\u201d, which provide additional weak supervision. Following a bootstrapping manner, we train the classifier and expand the seed words and seed motifs iteratively. Extensive experiments and case studies on real-world datasets demonstrate superior performance and significant advantages of leveraging metadata as weak supervision.\n\nAnthology ID:2020.emnlp-main.670Volume:[Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)](https://aclanthology.org/volumes/2020.emnlp-main/)Month:NovemberYear:2020Address:OnlineEditors:[Bonnie Webber](https://aclanthology.org/people/bonnie-webber/),\n[Trevor Cohn](https://aclanthology.org/people/trevor-cohn/),\n[Yulan He](https://aclanthology.org/people/yulan-he/),\n[Yang Liu](https://aclanthology.org/people/yang-liu-icsi/)Venue:[EMNLP](https://aclanthology.org/venues/emnlp/)SIG:Publisher:Association for Computational LinguisticsNote:Pages:8351\u20138361Language:URL:[https://aclanthology.org/2020.emnlp-main.670/](https://aclanthology.org/2020.emnlp-main.670/)DOI:[10.18653/v1/2020.emnlp-main.670](https://doi.org/10.18653/v1/2020.emnlp-main.670)Bibkey:mekala-etal-2020-metaCite (ACL):Dheeraj Mekala, Xinyang Zhang, and Jingbo Shang. 2020. [META: Metadata-Empowered Weak Supervision for Text Classification](https://aclanthology.org/2020.emnlp-main.670/). In _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)_, pages 8351\u20138361, Online. Association for Computational Linguistics.Cite (Informal):[META: Metadata-Empowered Weak Supervision for Text Classification](https://aclanthology.org/2020.emnlp-main.670/) (Mekala et al., EMNLP 2020)Copy Citation:BibTeXMarkdownMODS XMLEndnoteMore options\u2026PDF:[https://aclanthology.org/2020.emnlp-main.670.pdf](https://aclanthology.org/2020.emnlp-main.670.pdf)Video:[https://slideslive.com/38939087](https://slideslive.com/38939087)\n\n[PDF](https://aclanthology.org/2020.emnlp-main.670.pdf) [Cite](https://aclanthology.org/aclanthology.org) [Search](https://www.semanticscholar.org/search?q=META%3A+Metadata-Empowered+Weak+Supervision+for+Text+Classification) [Video](https://slideslive.com/38939087) [Fix data](https://aclanthology.org/aclanthology.org)",
      "url": "https://aclanthology.org/2020.emnlp-main.670"
    },
    {
      "title": "",
      "text": "Adar Kahana adarkahana@microsoft.com\nMicrosoft R&D center\nILDC\nOren Elisha orelisha@microsoft.com\nMicrosoft R&D center\nILDC\nMESSAGENET: MESSAGE CLASSIFICATION USING NATURAL LANGUAGE PROCESSING AND META-DATA\nMessage classification \u00b7 Meta data injection \u00b7 Deep learning \u00b7 Natural language processing\nIn this paper we propose a new Deep Learning (DL) approach for message classification. Our method is based on the state-of-the-art Natural Language Processing (NLP) building blocks, combined with a novel technique for infusing the meta-data input that is typically available in messages such as the sender information, timestamps, attached image, audio, affiliations, and more. As we demonstrate throughout the paper, going beyond the mere text by leveraging all available channels in the message, could yield an improved representation and higher classification accuracy. To achieve message representation, each type of input is processed in a dedicated block in the neural network architecture that is suitable for the data type. Such an implementation enables training all blocks together simultaneously, and forming cross channels features in the network. We show in the Experiments Section that in some cases, message's meta-data holds an additional information that cannot be extracted just from the text, and when using this information we achieve better performance. Furthermore, we demonstrate that our multi-modality block approach outperforms other approaches for injecting the meta data to the the text classifier.Many real world applications require message classification and regression, such as handling spam emails [1], ticket routing [2], article sentiment review [3] and more. Accurate message classification could improve critical scenarios such as in call centers (routing tickets based on topic) [2], alert systems (flagging highly important alert messages) [4], and categorizing incoming messages (automatically unclutter emails)[1,5]. The main distinction between text and message classification is the availability of additional attributes, such as the sender information, timestamps, attached image, audio, affiliations, and more. New message classification contests often appear in the prominent platforms (i.e., Kaggle [6]), showing how this topic is sought after. There are already many data-sets to explore in this field, but no clear winner algorithm that fits all scenarios with high accuracy, efficiency and simplicity (in terms of implementation and interpretation).A notable advancement in the field of NLP is the attention based transformers architecture[7]. This family of methods excels in finding local connections between words, and better understanding the meaning of a sentence. A leading example is the Bidirectional Encoder Representations from Transformers (BERT) [8] as well as its variations [9, 10, 11], winning certain benchmarks[12,13]. Several packages, such as Huggingface Transformers[14], make such models accessible and easy to use as well as provide pre-trained versions. In addition, one can use transfer learning [15] to further train BERT on their on data, creating a tailored model for the specific task at hand.BERT, and often other transformer based models, are designed to handle text. They operate on the words of a given text by encoding them into tokens, and by the connections between the tokens they learn the context of sentences. This approach is limited, since sometimes more information can be extracted and used, not necessarily textual. Throughout this paper we refer to this information as meta-data to distinguish it from the main stream of textual content (though one may recognize it as the core data, depending on the application). For example, a meta-data could be the time stamp of when the text was written, sent, published, etc. Another example is the writer of the text, when dealing with a small\nlist of writers of a corpus. There have been some attempts to incorporate these into BERT models, for example by assigning artificial tokens for writers or for temporal segments (token per month for example) [16]. This approach is limited since not all meta-data entries are suitable for encoding by tokenization. In the example of temporal segments, more segments introduce more tokens, leading to large computational resources consumption, and less segments cause loss of information. Another approach is to concatenate the embeddings, created by the transformer module, with the outputs of an embedding module for the meta-data. In this approach, a transformer for the text is trained (using direct or transfer learning) on the text, and other separate modules (time series embedding, senders embeddings, etc.) are used to embed the meta-data. All the embeddings are",
      "url": "https://export.arxiv.org/pdf/2301.01808v1.pdf"
    },
    {
      "title": "Text Classification: All Tips and Tricks from 5 Kaggle Competitions",
      "text": "In this article, I will discuss some great tips and tricks to [improve the performance](https://neptune.ai/blog/improving-machine-learning-deep-learning-models) of your text classification model. These tricks are obtained from solutions of some of Kaggle\u2019s top NLP competitions.\n\nNamely, I\u2019ve gone through:\n\n- [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification) \u2013 $65,000\n- [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/) \u2013 $35,000\n- [Quora Insincere Questions Classification](http://kaggle.com/c/quora-insincere-questions-classification) \u2013 $25,000\n- [Google QUEST Q&A Labeling](https://www.kaggle.com/c/google-quest-challenge) \u2013 $25,000\n- [TensorFlow 2.0 Question Answering](https://www.kaggle.com/c/tensorflow2-question-answering) \u2013 $50,000\n\nand found a ton of great ideas.\n\nWithout much lag, let\u2019s begin.\n\n## Dealing with larger datasets\n\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for Kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\n\n- Optimize the memory by [reducing the size of some attributes](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\n- Use open-source libraries such as [Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space\n- Use [cudf](https://github.com/rapidsai/cudf)\n- Convert data to [parquet](https://arrow.apache.org/docs/python/parquet.html) format\n- Convert data to [feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03) format\n\n## Small datasets and external data\n\nBut, what can one do if the dataset is small? Let\u2019s see some techniques to tackle this situation.\n\nOne way to increase the performance of any machine learning model is to use some external data frame that contains some variables that influence the predicate variable.\n\nLet\u2019s see some of the external datasets.\n\n- Use of [squad](https://rajpurkar.github.io/SQuAD-explorer/) data for Question Answering tasks\n- Other [datasets](http://nlpprogress.com/english/question_answering.html) for QA tasks\n- Wikitext long term dependency language modeling [dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\n- [Stackexchange data](https://archive.org/download/stackexchange)\n- Prepare a dictionary of commonly misspelled words and corrected words.\n- Use of [helper datasets](https://www.kaggle.com/kyakovlev/jigsaw-general-helper-public) for cleaning\n- [Pseudo labeling](https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969/) is the process of adding confidently predicted test data to your training data\n- Use different data [sampling methods](https://www.kaggle.com/shahules/tackling-class-imbalance)\n- Text augmentation by [Exchanging words with synonym](https://arxiv.org/pdf/1502.01710.pdf) [s](https://arxiv.org/pdf/1502.01710.pdf)\n- Text augmentation by [noising in RNN](https://arxiv.org/pdf/1703.02573.pdf)\n- Text augmentation by [translation to other languages and back](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/48038)\n\n## Data exploration and gaining insights\n\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\n\n- Twitter data [exploration methods](https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda)\n- Simple [EDA for tweets](https://www.kaggle.com/nz0722/simple-eda-text-preprocessing-jigsaw)\n- [EDA](https://www.kaggle.com/tunguz/just-some-simple-eda) for Quora data\n- [EDA](https://www.kaggle.com/kailex/r-eda-for-q-gru) in \u00a0R for Quora data\n- Complete [EDA](https://www.kaggle.com/codename007/start-from-here-quest-complete-eda-fe) with stack exchange data\n- My previous article on [EDA for natural language processing](https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools)\n\n## Data cleaning\n\nData cleaning is one of the important and integral parts of any NLP problem. Text data always needs some preprocessing and cleaning before we can represent it in a suitable form.\n\n- Use this [notebook](https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing) to clean social media data\n- [Data cleaning](https://www.kaggle.com/kyakovlev/preprocessing-bert-public) for BERT\n- Use [textblob](https://textblob.readthedocs.io/en/dev/quickstart.html) to correct misspellings\n- [Cleaning](https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing) for pre-trained embeddings\n- [Language detection and translation](https://www.pythonprogramming.in/language-detection-and-translation-using-textblob.html) for multilingual tasks\n- Preprocessing for Glove [part 1](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part1-eda) and [part 2](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part2-usage)\n- [Increasing word coverage](https://www.kaggle.com/sunnymarkliu/more-text-cleaning-to-increase-word-coverage) to get more from pre-trained word embeddings\n\n## Text representations\n\nBefore we feed our text data to the Neural network or ML model, the text input needs to be represented in a suitable format. These representations determine the performance of the model to a large extent.\n\n- Pretrained [Glove](https://nlp.stanford.edu/projects/glove/) vectors\n- Pretrained [fasttext](https://fasttext.cc/docs/en/english-vectors.html) vectors\n- Pretrained [word2vec](https://radimrehurek.com/gensim/models/word2vec.html) vectors\n- My previous article on these [3 embeddings](https://neptune.ai/blog/document-classification-small-datasets)\n- Combining [pre-trained vectors](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778/). This can help in better representation of text and decreasing OOV words\n- [Paragram](https://cogcomp.seas.upenn.edu/page/resource_view/106) embeddings\n- [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/1)\n- Use USE to generate [sentence-level features](https://www.kaggle.com/abhishek/distilbert-use-features-oof)\n- 3 methods to [combine embeddings](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778)\n\nContextual embeddings models\n\n- [BERT](https://github.com/google-research/bert) Bidirectional Encoder Representations from Transformers\n- [GPT](https://github.com/openai/finetune-transformer-lm)\n- [Roberta](https://github.com/pytorch/fairseq/tree/master/examples/roberta) a Robustly Optimized BERT\n- [Albert](https://github.com/google-research/ALBERT) a Lite BERT for Self-supervised Learning of Language Representations\n- [Distilbert](https://github.com/huggingface/transformers/tree/master/examples/distillation) a lighter version of BERT\n- [XLNET](https://github.com/zihangdai/xlnet/)\n\n## Modeling\n\n### Model architecture\n\nChoosing the right architecture is important to develop a proper machine learning model, sequence to sequence models like LSTMs, GRUs perform well in NLP problems and is always worth trying. Stacking 2 layers of LSTM/GRU networks is a common approach.\n\n- [Stacking Bidirectional CuDNNLSTM](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644/)\n- [Stacking LSTM networks](https://www.kaggle.com/sakami/google-quest-single-lstm/)\n- [LSTM and 5 fold Attention](https://www.kaggle.com/christofhenkel/keras-baseline-lstm-attention-5-fold/)\n- [Bi...",
      "url": "https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions"
    },
    {
      "title": "",
      "text": "# Combining Categorical and Numerical Features with Text in BERT\n\n29 Jun 2021\n\nIn this tutorial we\u2019ll look at the topic of classifying text with BERT, but where we also have additional numerical or categorical features that we want to use to improve our predictions.\n\nTo help motivate our discussion, we\u2019ll be working with a dataset of about 23k clothing reviews. For each review, we have the review text, but also additional information such as:\n\n- The age of the reviewer (numerical feature)\n- The number of upvotes on the review (numerical feature)\n- The department and category of the clothing item (categorical features)\n\nFor each review, we also have a binary label, which is whether or not the reviewer ultimately recommends the item. This is what we are trying to predict.\n\nThis dataset was scraped from an (un-specified) e-commerce website by Nick Brooks and made available on Kaggle [here](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews).\n\nIn Section 2 of this Notebook, I\u2019ve implemented four different \u201cbaseline\u201d strategies which score fairly well, but which don\u2019t incorporate all of the features together.\n\nThen, in Section 3, I\u2019ve implemented a simple strategy to combine _everything_ and feed it through BERT. Specifically, I make text out of the additional features, and prepend this text to the review.\n\nThere is a GitHub project called the [Multimodal-Toolkit](https://github.com/georgian-io/Multimodal-Toolkit) which is how I learned about this clothing review dataset. The toolkit implements a number of more complicated techniques, but their benchmarks (as well as our results below) show that this simple features-to-text strategy works best for this dataset.\n\nIn our weekly discussion group, I talked through this Notebook and we also met with Ken Gu, the author of the Multi-Modal Toolkit! You can watch the recording [here](https://youtu.be/XPt9pIpe1vo).\n\nYou can find the Colab Notebook version of this post [here](https://colab.research.google.com/drive/1YRHK4HO8RktGzlYmGjBo056kzVD4_j9o).\n\nBy Chris McCormick\n\n# Contents\n\n- [Contents](https://mccormickml.com/mccormickml.com#contents)\n- [S1. Clothing Review Dataset](https://mccormickml.com/mccormickml.com#s1-clothing-review-dataset)\n  - [1.1. Download & Parse](https://mccormickml.com/mccormickml.com#11-download--parse)\n  - [1.2. Train-Validation-Test Split](https://mccormickml.com/mccormickml.com#12-train-validation-test-split)\n- [S2. Baseline Strategies](https://mccormickml.com/mccormickml.com#s2-baseline-strategies)\n  - [2.1. Always Recommend](https://mccormickml.com/mccormickml.com#21-always-recommend)\n  - [2.2. Threshold on Rating](https://mccormickml.com/mccormickml.com#22-threshold-on-rating)\n  - [2.3. XGBoost](https://mccormickml.com/mccormickml.com#23-xgboost)\n  - [2.4. BERT on Review Text Only](https://mccormickml.com/mccormickml.com#24-bert-on-review-text-only)\n- [S3. BERT with All Features](https://mccormickml.com/mccormickml.com#s3-bert-with-all-features)\n  - [3.1. All Features to Text](https://mccormickml.com/mccormickml.com#31-all-features-to-text)\n  - [3.2. GPU & Transformers Setup](https://mccormickml.com/mccormickml.com#32-gpu--transformers-setup)\n  - [3.3. Training Parameters](https://mccormickml.com/mccormickml.com#33-training-parameters)\n  - [3.3. Tokenize & Encode](https://mccormickml.com/mccormickml.com#33-tokenize--encode)\n  - [3.4. Training](https://mccormickml.com/mccormickml.com#34-training)\n    - [3.4.1. Setup](https://mccormickml.com/mccormickml.com#341-setup)\n    - [3.4.2. Training Loop](https://mccormickml.com/mccormickml.com#342-training-loop)\n    - [3.4.3. Training Results](https://mccormickml.com/mccormickml.com#343-training-results)\n  - [3.5. Test](https://mccormickml.com/mccormickml.com#35-test)\n- [Conclusion](https://mccormickml.com/mccormickml.com#conclusion)\n\n# S1. Clothing Review Dataset\n\n## 1.1. Download & Parse\n\nRetrieve the .csv file for the dataset.\n\n```\nimport gdown\n\nprint('Downloading dataset...\\n')\n\n# Download the file.\ngdown.download('https://drive.google.com/uc?id=1ZYdt0zN4LjWqP3cQDblNhXjeohcryY5H',\n                'Womens Clothing E-Commerce Reviews.csv',\n                quiet=False)\n\nprint('\\n\\nDONE.')\n```\n\n```\nDownloading dataset...\n\nDownloading...\nFrom: https://drive.google.com/uc?id=1ZYdt0zN4LjWqP3cQDblNhXjeohcryY5H\nTo: /content/Womens Clothing E-Commerce Reviews.csv\n8.48MB [00:00, 48.7MB/s]\n\nDONE.\n\n```\n\nParse the dataset csv file into a pandas DataFrame.\n\n```\nimport pandas as pd\n\ndata_df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv', index_col=0)\n\ndata_df.head()\n```\n\n| Clothing ID | Age | Title | Review Text | Rating | Recommended IND | Positive Feedback Count | Division Name | Department Name | Class Name |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | 767 | 33 | NaN | Absolutely wonderful - silky and sexy and comf... | 4 | 1 | 0 | Initmates | Intimate | Intimates |\n| 1 | 1080 | 34 | NaN | Love this dress! it's sooo pretty. i happene... | 5 | 1 | 4 | General | Dresses | Dresses |\n| 2 | 1077 | 60 | Some major design flaws | I had such high hopes for this dress and reall... | 3 | 0 | 0 | General | Dresses | Dresses |\n| 3 | 1049 | 50 | My favorite buy! | I love, love, love this jumpsuit. it's fun, fl... | 5 | 1 | 0 | General Petite | Bottoms | Pants |\n| 4 | 847 | 47 | Flattering shirt | This shirt is very flattering to all due to th... | 5 | 1 | 6 | General | Tops | Blouses |\n\n_Features_\n\n\u201c **Recommended IND**\u201d is the label we are trying to predict for this dataset. \u201c1\u201d means the reviewer recommended the product and \u201c0\u201d means they do not.\n\nThe following are _categorical_ features:\n\n- Division Name\n- Department Name\n- Class Name\n- Clothing ID\n\nAnd the following are _numerical_ features:\n\n- Age\n- Rating\n- Positive Feedback Count\n\n_Feature Analysis_\n\nThere is an excellent Notebook on Kaggle [here](https://www.kaggle.com/bhaveshkumar2806/complete-eda-and-visualization-of-text-data) which does some thorough analysis on each of the features in this dataset.\n\nNote that, in addition to the \u201cRecommended\u201d label, there is also a \u201c **Rating**\u201d column where the reviewer rates the product from 1 - 5. The analysis in the above Notebook shows that almost all items rated 3 - 5 are recommended, and almost all rated 1 - 2 are not recommended. We\u2019ll see in our second baseline classifier that you can get a very high accuracy with this feature alone. However, it _is_ still possible to do better by incorporating the other features!\n\n## 1.2. Train-Validation-Test Split\n\nI want to use the same training, validation, and test splits for all of the approaches we try so that it\u2019s a fair comparison.\n\nHowever, different approaches are going to require different transformations on the data, and for simplicity I want to apply those transformations _before_ splitting the dataset.\n\nTo solve this, we\u2019re going to create lists of indeces for each of the three portions. That way, for a given classification approach, we can load the whole dataset, apply our transformations, and then split it according to these pre-determined indeces.\n\n```\nimport random\nimport numpy as np\n\n# First, calculate the split sizes. 80% training, 10% validation, 10% test.\ntrain_size = int(0.8 * len(data_df))\nval_size = int(0.1 * len(data_df))\ntest_size = len(data_df) - (train_size + val_size)\n\n# Sanity check the sizes.\nassert((train_size + val_size + test_size) == len(data_df))\n\n# Create a list of indeces for all of the samples in the dataset.\nindeces = np.arange(0, len(data_df))\n\n# Shuffle the indeces randomly.\nrandom.shuffle(indeces)\n\n# Get a list of indeces for each of the splits.\ntrain_idx = indeces[0:train_size]\nval_idx = indeces[train_size:(train_size + val_size)]\ntest_idx = indeces[(train_size + val_size):]\n\n# Sanity check\nassert(len(train_idx) == train_size)\nassert(len(test_idx) == test_size)\n\n# With these lists, we can now select the corresponding dataframe rows using,\n# e.g., train_df = data_df.iloc[train_idx]\n\nprint('  Training size: {:,}'.format(train_size))\n...",
      "url": "https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert"
    },
    {
      "title": "",
      "text": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 8351\u20138361,\nNovember 16\u201320, 2020. \rc 2020 Association for Computational Linguistics\n8351\nMETA: Metadata-Empowered Weak Supervision for Text Classification\nDheeraj Mekala1 Xinyang Zhang2 Jingbo Shang1,3\n1 Department of Computer Science and Engineering, University of California San Diego, CA, USA\n2 Department of Computer Science, University of at Illinois Urbana-Champaign, IL, USA\n3 Hal\u0131c\u0131oglu Data Science Institute, University of California San Diego, CA, USA \u02d8\n1,3\n{dmekala, jshang}@ucsd.edu 2 xz43@illinois.edu\nAbstract\nRecent advances in weakly supervised learn\u0002ing enable training high-quality text classifiers\nby only providing a few user-provided seed\nwords. Existing methods mainly use text data\nalone to generate pseudo-labels despite the\nfact that metadata information (e.g., author\nand timestamp) is widely available across var\u0002ious domains. Strong label indicators exist in\nthe metadata and it has been long overlooked\nmainly due to the following challenges: (1)\nmetadata is multi-typed, requiring systematic\nmodeling of different types and their combi\u0002nations, (2) metadata is noisy, some metadata\nentities (e.g., authors, venues) are more com\u0002pelling label indicators than others. In this\npaper, we propose a novel framework, META,\nwhich goes beyond the existing paradigm and\nleverages metadata as an additional source of\nweak supervision. Specifically, we organize\nthe text data and metadata together into a\ntext-rich network and adopt network motifs to\ncapture appropriate combinations of metadata.\nBased on seed words, we rank and filter mo\u0002tif instances to distill highly label-indicative\nones as \u201cseed motifs\u201d, which provide addi\u0002tional weak supervision. Following a boot\u0002strapping manner, we train the classifier and\nexpand the seed words and seed motifs itera\u0002tively. Extensive experiments and case stud\u0002ies on real-world datasets demonstrate supe\u0002rior performance and significant advantages of\nleveraging metadata as weak supervision.\n1 Introduction\nWeakly supervised text classification has recently\ngained much attention from the researchers because\nit reduces the burden of annotating the data. So far,\nthe major source of weak supervision lies in text\ndata itself (Agichtein and Gravano, 2000; Kuipers\net al., 2006; Riloff et al., 2003; Tao et al., 2015;\nMeng et al., 2018; Mekala and Shang, 2020). These\nmethods typically require a few user-provided seed\nPaper Authors Year Category\nP1 G. Hinton, S. Osindero, YW. Teh 2006 ML\nP2 G. Hinton, O. Vinyals, J. Dean 2015 ML\nP3 J. Dean, S.Ghemawat 2008 Sys\n(a) Examples of research papers with metadata.\nO. Vinyals\nG. Hinton\n2016\nneural\nsystem\ndata\nlearning\nJ. Dean Doc\nAuthor 1 Author 2\nP2\nO. Vinyals G. Hinton\nP1 P2\n\u2026 \u2026\n\u2026\n(b) A text-rich network view of \nthe papers.\n(c) A motif pattern and \na motif instance.\nFigure 1: Text corpus, text-rich network, and motif.\nwords for each class as weak supervision. They ex\u0002pand seed words with generated pseudo labels and\nimprove their text classifier in an iterative fashion.\nMetadata information (e.g., author, published\nyear) in addition to textual information, is widely\navailable across various domains (e.g., news arti\u0002cles, social media posts, and scientific papers) and\nit could serve as a strong, complementary weak\nsupervision source. Take a look at the research\npapers in Figure 1(a) as an example. It shall be\nlearned in a data-driven manner that G. Hinton is a\nhighly-reputed machine learning researcher, thus\nhis presence is a strong indicator of a paper belong\u0002ing to the Machine Learning category.\nDistilling effective metadata for weak supervi\u0002sion faces several major challenges. Metadata is\noften multi-typed, each type and the type combi\u0002nations could have very different semantics and\nmay not be equally important. Moreover, even en\u0002tities within a single metadata type could be noisy.\nContinuing our example in Figure 1(a), we shall\nnotice that year is less helpful than an author to do\nclassification. Among the authors, J. Dean might\nbe an important figure but has research interests\n8352\nm1,1 .95 .01 .04\nm1,2 .32 .30 .38\nText Classifier\nSeed Words \u2460 Pseudo Label Generation \u2462 Motif Ranking & \u2026\nC1 Neural Network\nC2 Image Classification\nC3 Translation\nPaper\nAuthor 1 Author 2\nM1\nM2\nm2,1 .03 .89 .08\nm2,2 .31 .26 .43\nInstance C1 C2 C3\nKlein Manning\nP1 P2\n\u2461 Classifier Training / Prediction\nRecursion\nUser Given\nMotif Pattern\nMatched (Seed)\nMotif Instances\n\u2026\n\u2026\nC1 m1,1 m1,6 m2,3 m1,4 \u2026\nC2 m2,1 m2,4 m1,2 m1,4 \u2026\nC3 m1,3 m2,5 m2,2 m1,7 \u2026\n... Expansion\nExpand from high score to low\nNew seed set cutoff\nFigure 2: Our META framework. In each iteration, we generate pseudo labels for documents, train the text classifier,\nand rank all words and motif instances in a unified ranking framework. We then expand seed sets until an automatic\ncutoff is reached. The quality of the classifier and the seed sets are improved through iterations.\nspanning across different domains. However, if we\njoin the author with year, it carries more accurate\nsemantics, and we may discover J. Dean has more\ninterest in machine learning in recent years, thus\nbecoming highly label-indicative.\nBearing the challenges in mind, we propose\nMETA, a principled framework for metadata\u0002empowered weakly-supervised text classification.\nAs illustrated in Figure 1 and Figure 2, we first\norganize the text data and metadata together into\na text-rich network. The network structure gives\nus a holistic view of the corpus and enables us to\nrank and select useful metadata entities. We lever\u0002age motif patterns (Benson et al., 2016; Milo et al.,\n2002; Shang et al., 2020) to model typed metadata\nas well as their combinations. A motif pattern is\na subgraph pattern at the meta-level that captures\nhigher-order connections and the semantics repre\u0002sented by these connections. It serves as a useful\ntool to model typed edges, typed paths (a.k.a. meta\u0002paths) (Sun et al., 2011), and higher-order struc\u0002tures in the network. With little effort, users can\nspecify a few possibly useful motif patterns as in\u0002put to our model. We develop a unified, principled\nranking mechanism to select label-indicative motif\ninstances and words, forming expanded weak su\u0002pervision. Note that, such instance-level selection\nprocess also implicitly refines the motif patterns,\nensuring the robust performance of META even\nwhen irrelevant motif patterns exist in input. It is\nworth a mention that META is compatible with any\ntext classifiers.\nOur contributions are summarized as follows:\n\u2022 We explore to incorporate metadata information\nas an additional source of weak supervision for\ntext classification along with seed words.\n\u2022 We propose a novel framework META, which in\u0002troduces motif patterns to capture the high-order\ncombinations among different types of metadata\nand conducts a unified ranking and selection of\nlabel-indicative motif instances and words.\n\u2022 We conduct experiments on two real-world\ndatasets. The results and case studies demon\u0002strate the superiority of incorporating metadata\nas parts of weak supervision and verify the effec\u0002tiveness of META.\nReproducibility. Our code is made publicly avail\u0002able at GitHub1\n.\n2 Preliminaries\n2.1 Documents as Text-rich Network\nGiven a collection of n text documents D =\n{D1, D2, . . . , Dn}, and their corresponding meta\u0002data, we propose to organize them into a text-rich\nnetwork, as illustrated in Figure 1(b). A text-rich\nnetwork is a heterogeneous network with docu\u0002ments, words, different types of metadata as nodes,\nand their associations as edges. For example, our\ntext-rich network for research papers has papers,\nwords, authors, and publication years as nodes.\nEach paper is connected to its associated words\nand metadata nodes. Such a network provides a\nholistic and structured representation of the input.\n2.2 Seed Words and Motif Patterns\nUsers are asked to provide a few seed words S\n= {Sw\n1\n, S\nw\n2\n, . . . , S\nw\nl\n} for each of l classes (i.e.,\nC1, C2, . . . , ...",
      "url": "https://aclanthology.org/2020.emnlp-main.670.pdf"
    },
    {
      "title": "GitHub - dheeraj7596/META: Code for the paper \"META: Metadata-Empowered Weak Supervision for Text Classification\"",
      "text": "[Skip to content](https://github.com/dheeraj7596/META#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/dheeraj7596/META) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/dheeraj7596/META) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/dheeraj7596/META) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[dheeraj7596](https://github.com/dheeraj7596)/ **[META](https://github.com/dheeraj7596/META)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Fdheeraj7596%2FMETA) You must be signed in to change notification settings\n- [Fork\\\n0](https://github.com/login?return_to=%2Fdheeraj7596%2FMETA)\n- [Star\\\n7](https://github.com/login?return_to=%2Fdheeraj7596%2FMETA)\n\n\nCode for the paper \"META: Metadata-Empowered Weak Supervision for Text Classification\"\n\n[7\\\nstars](https://github.com/dheeraj7596/META/stargazers) [0\\\nforks](https://github.com/dheeraj7596/META/forks) [Branches](https://github.com/dheeraj7596/META/branches) [Tags](https://github.com/dheeraj7596/META/tags) [Activity](https://github.com/dheeraj7596/META/activity)\n\n[Star](https://github.com/login?return_to=%2Fdheeraj7596%2FMETA)\n\n[Notifications](https://github.com/login?return_to=%2Fdheeraj7596%2FMETA) You must be signed in to change notification settings\n\n# dheeraj7596/META\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmaster\n\n[Branches](https://github.com/dheeraj7596/META/branches) [Tags](https://github.com/dheeraj7596/META/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[24 Commits](https://github.com/dheeraj7596/META/commits/master/) |\n| [data](https://github.com/dheeraj7596/META/tree/master/data) | [data](https://github.com/dheeraj7596/META/tree/master/data) |  |  |\n| [docs](https://github.com/dheeraj7596/META/tree/master/docs) | [docs](https://github.com/dheeraj7596/META/tree/master/docs) |  |  |\n| [keras\\_han](https://github.com/dheeraj7596/META/tree/master/keras_han) | [keras\\_han](https://github.com/dheeraj7596/META/tree/master/keras_han) |  |  |\n| [util](https://github.com/dheeraj7596/META/tree/master/util) | [util](https://github.com/dheeraj7596/META/tree/master/util) |  |  |\n| [README.md](https://github.com/dheeraj7596/META/blob/master/README.md) | [README.md](https://github.com/dheeraj7596/META/blob/master/README.md) |  |  |\n| [preprocess.py](https://github.com/dheeraj7596/META/blob/master/preprocess.py) | [preprocess.py](https://github.com/dheeraj7596/META/blob/master/preprocess.py) |  |  |\n| [train.py](https://github.com/dheeraj7596/META/blob/master/train.py) | [train.py](https://github.com/dheeraj7596/META/blob/master/train.py) |  |  |\n| [train.sh](https://github.com/dheeraj7596/META/blob/master/train.sh) | [train.sh](https://github.com/dheeraj7596/META/blob/master/train.sh) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# META: Metadata-Empowered Weak Supervision for Text Classification\n\n- [Model](https://github.com/dheeraj7596/META#model)\n- [Training](https://github.com/dheeraj7596/META#training)\n  - [Required Inputs](https://github.com/dheeraj7596/META#required-inputs)\n  - [Commands](https://github.com/dheeraj7596/META#commands)\n  - [Requirements](https://github.com/dheeraj7596/META#requirements)\n- [Citation](https://github.com/dheeraj7596/META#citation)\n\n## Model\n\n[![META-Framework](https://github.com/dheeraj7596/META/raw/master/docs/META-overview.png)](https://github.com/dheeraj7596/META/blob/master/docs/META-overview.png)\n\n## Training\n\n### Required inputs\n\nEach Dataset should contain following files:\n\n- **DataFrame pickle file**\n  - Example: `data/books/df.pkl`\n    - This dataset can contain any number of columns but must contain two columns named `text`, `label`\n    - `text` contains text and `label` contains its corresponding label.\n    - Must be named as `df.pkl`\n- **Seed Words Json file**\n  - Example: `data/books/seedwords.json`\n    - This json file contains seed words list for each label.\n    - Must be named as `seedwords.json`\n- **Metadata config file**\n  - Example: `data/books/metadata_config.json`\n    - This json file contains metadata type as key and there must be `separator` in the values which indicates\n      the separator of that entry in the dataframe.\n    - If no separator is required, the value for `separator` should be `null`.\n    - For example, if authors information are provided as a comma-separated string, the `separator` should be `\",\"`.\n- **Motif Patterns file**\n  - Example: `data/books/motif_patterns.txt`\n    - This text file contains one motif pattern per line.\n    - A motif pattern is represented as comma-separated string. For example: `authors, authors` represents\n      co-authorship.\n\n### Commands\n\n#### META - Iterative Framework:\n\nThe `train.sh` requires five arguments in the following order:\n\n- `use_gpu`: indicates whether to use GPU. This should be set to 1 to use GPU and 0 to use CPU.\n- `GPU`: refers to GPU id.\n- `dataset_path`: refers to absolute path of dataset.\n- `tmp_path`: refers to a path to a temporary directory which is used for dumping intermediate files.\n- `print_flag`: indicates whether to print the expanded phrases and motif instances. This should be set to 1\nto print and 0 to not print.\n\nFor example, to train META on books dataset on GPU Id 4, please run:\n\n```\n$ ./train.sh 1 4 <DATA_PATH TO BOOKS> <TEMP_DIR PATH> 1\n```\n\n### Requirements\n\nThis project is based on `python==3.7`. The dependencies are as follow:\n\n```\nkeras==2.1.5\nscikit-learn==0.21.3\nscipy=1.3.1\ngensim==3.8.1\nnumpy==1.17.2\nfast-pagerank==0.0.4\ntensorflow==1.15\nnltk\nbleach==3.1.5\npandas\nbeautifulsoup4\n\n```\n\n## Citation\n\n```\n@inproceedings{mekala-etal-2020-meta,\n    title = \"{META}: Metadata-Empowered Weak Supervision for Text Classification\",\n    author = \"Mekala, Dheeraj  and\n      Zhang, Xinyang  and\n      Shang, Jingbo\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.670\",\n    doi = \"10.18653/v1/2020.emnlp-main.670\",\n    pages = \"8351--8361\",\n    abstract = \"Recent advances in weakly supervised learning enable training high-quality text classifiers by only providing a few user-provided seed words. Existing methods mainly use text data alone to generate pseudo-labels despite the fact that metadata information (e.g., author and timestamp) is widely available across various domains. Strong label indicators exist in the metadata and it has been long overlooked mainly due to the following challenges: (1) metadata is multi-typed, requiring systematic modeling of different types and their combinations, (2) metadata is noisy, some metadata entities (e.g., authors, venues) are more compelling label indicators than others. In this paper, we propose a novel framework, META, which goes beyond the existing paradigm and leverages metadata as an additional source of weak supervision. Specifically, we organize the text data and metadata together into a text-rich network and adopt network motifs to capture appropriate combinations of metadata. Based on seed words, we rank and filter motif instances to distill highly label-indicative ones as {``}seed motifs{''}, which provide additional weak supervision. Following a bootstrapping manner, we train the classifier and expand the seed words and seed motifs iteratively. Extensive experiments and case studies on real-world datasets demonstrate superior performance and significant advantages of leveraging metadata as weak supervision.\",\n}\n\n```\n\n## About\n\nCode for the paper \"META: Metadata-Empowered Weak Supervision for Text Classification\"\n\n### Topics\n\n[...",
      "url": "https://github.com/dheeraj7596/META"
    },
    {
      "title": "GitHub - AnakinHuang/kaggle-project-classification-of-tweets-from-northern-europe: Classifies 500K+ political tweets from Northern Europe using NLP and machine learning to analyze political discourse.",
      "text": "<div><div><article><p></p><h2>\ud83d\udc26 Kaggle Project: Classification of Tweets from Northern Europe</h2><a href=\"#-kaggle-project-classification-of-tweets-from-northern-europe\"></a><p></p>\n<p><a href=\"https://camo.githubusercontent.com/439fd5ffe2ac21b3daa03ac6474978163be089da5fbba2790769ae2275464e35/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d425344253230332d2d436c617573652d626c75652e737667\"></a></p>\n<p></p><h2>\ud83d\ude80 Overview</h2><a href=\"#-overview\"></a><p></p>\n<p>This project analyzes a dataset of <strong>509,031 tweets</strong> from politicians across <strong>seven Northern European countries</strong>, aiming to classify tweets by <strong>political spectrum (Left, Right, Center)</strong> and <strong>geography</strong>. Using <strong>Natural Language Processing (NLP)</strong> and machine learning, we extracted key insights into political discourse and developed a classifier with strong performance.</p>\n<hr/>\n<p></p><h2>\ud83d\udcca Dataset</h2><a href=\"#-dataset\"></a><p></p>\n<ul>\n<li><strong>Countries:</strong> Belgium, Denmark, Iceland, Ireland, Netherlands, Norway, Sweden</li>\n<li><strong>Time span:</strong> Dec 2008 \u2013 Jan 2023</li>\n<li><strong>Dataset size:</strong> 509,031 tweets\n<ul>\n<li><strong>Training set:</strong> 407,223 tweets</li>\n<li><strong>Test set:</strong> 101,808 tweets</li>\n</ul>\n</li>\n</ul>\n<p><strong>Attributes:</strong></p>\n<ul>\n<li>Tweet text</li>\n<li>Country</li>\n<li>Gender</li>\n<li>Political spectrum label (for supervised learning)</li>\n</ul>\n<hr/>\n<p></p><h2>\ud83d\udd2c Methods</h2><a href=\"#-methods\"></a><p></p>\n<p></p><h3>Data Cleaning &amp; Preprocessing</h3><a href=\"#data-cleaning--preprocessing\"></a><p></p>\n<ul>\n<li>Text cleaning: Lowercasing, punctuation removal, stopword removal, lemmatization.</li>\n<li>New feature creation: <code>text_clean_country_gender_user</code> combining multiple metadata.</li>\n</ul>\n<p></p><h3>Feature Engineering</h3><a href=\"#feature-engineering\"></a><p></p>\n<ul>\n<li><strong>Vectorization:</strong>\n<ul>\n<li>Count Vectorizer</li>\n<li>TF-IDF transformation</li>\n</ul>\n</li>\n</ul>\n<p></p><h3>Modeling</h3><a href=\"#modeling\"></a><p></p>\n<ul>\n<li><strong>Classifier:</strong> Linear Support Vector Classifier (LinearSVC)</li>\n<li><strong>Validation:</strong> 10-fold cross-validation</li>\n</ul>\n<p></p><h3>Topic Modeling</h3><a href=\"#topic-modeling\"></a><p></p>\n<ul>\n<li><strong>LDA (Latent Dirichlet Allocation)</strong></li>\n<li><strong>NMF (Non-negative Matrix Factorization)</strong></li>\n</ul>\n<hr/>\n<p></p><h2>\ud83d\udcc8 Results</h2><a href=\"#-results\"></a><p></p>\n<p>\u2705 <strong>Key findings:</strong></p>\n<ul>\n<li>Tweets span diverse topics from <strong>domestic politics</strong> to <strong>international relations</strong>.</li>\n<li>Different political leanings across countries: e.g., Netherlands leans Center, Iceland leans Left.</li>\n<li>Gender distribution varies: Sweden had a <strong>female-majority</strong>, others skewed male.</li>\n</ul>\n<hr/>\n<p></p><h2>\ud83d\udee0\ufe0f Requirements</h2><a href=\"#\ufe0f-requirements\"></a><p></p>\n<ul>\n<li>Python 3.8+</li>\n<li>Key libraries:\n<ul>\n<li>pandas, numpy</li>\n<li>scikit-learn</li>\n<li>nltk, spaCy</li>\n<li>gensim</li>\n<li>matplotlib, seaborn</li>\n</ul>\n</li>\n</ul>\n<p>Install via:</p>\n<div><pre>pip install -r requirements.txt</pre></div>\n<hr/>\n<p></p><h2>\ud83d\udda5\ufe0f Usage</h2><a href=\"#\ufe0f-usage\"></a><p></p>\n<p>1\ufe0f\u20e3 <strong>Clone the repository:</strong></p>\n<div><pre>git clone https://github.com/AnakinHuang/kaggle-project-classification-of-tweets-from-northern-europe.git\n<span>cd</span> kaggle-project-classification-of-tweets-from-northern-europe</pre></div>\n<p>2\ufe0f\u20e3 <strong>Install dependencies:</strong></p>\n<div><pre>pip install -r requirements.txt</pre></div>\n<p>3\ufe0f\u20e3 <strong>Run analysis:</strong></p>\n<ul>\n<li>Open <code>kaggle_project.ipynb</code> for full preprocessing, modeling, and evaluation workflows.</li>\n</ul>\n<hr/>\n<p></p><h2>\ud83d\udcc2 Repository Structure</h2><a href=\"#-repository-structure\"></a><p></p>\n<div><pre><code>\u251c\u2500\u2500 data/ # Dataset (not included)\n\u251c\u2500\u2500 kaggle_project.ipynb # Main Jupyter notebook\n\u251c\u2500\u2500 kaggle_project_report.pdf # Final project report\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 requirements.txt # Dependencies\n\u2514\u2500\u2500 LICENSE\n</code></pre></div>\n<hr/>\n<p></p><h2>\ud83d\udc65 Contributors</h2><a href=\"#-contributors\"></a><p></p>\n<ul>\n<li><strong>Yuesong Huang</strong> (<a href=\"mailto:yhu116@u.rochester.edu\">yhu116@u.rochester.edu</a>)</li>\n<li><strong>Junhua Huang</strong> (<a href=\"mailto:jhuang77@u.rochester.edu\">jhuang77@u.rochester.edu</a>)</li>\n</ul>\n<hr/>\n<p></p><h2>\ud83d\udcc4 License</h2><a href=\"#-license\"></a><p></p>\n<p>This project is licensed under the BSD 3-Clause License \u2013 see the <a href=\"https://github.com/AnakinHuang/kaggle-project-classification-of-tweets-from-northern-europe/blob/main/LICENSE\">LICENSE</a> file for details.</p>\n<hr/>\n</article></div></div>",
      "url": "https://github.com/AnakinHuang/kaggle-project-classification-of-tweets-from-northern-europe"
    },
    {
      "title": "GitHub - SergKhachikyan/NaturalLanguageProcessingwithDisasterTweets: Natural Language Processing with Disaster Tweets (Kaggle) This repository contains my full pipeline for the Kaggle competition NLP - Getting Started. The goal is to classify whether a tweet is about a real disaster or not (target = 1 or 0).",
      "text": "<div><div><article><p></p><h2>\ud83e\udde0 Natural Language Processing with Disaster Tweets (Kaggle)</h2><a href=\"#-natural-language-processing-with-disaster-tweets-kaggle\"></a><p></p>\n<p>This repository contains my full pipeline for the Kaggle competition <a href=\"https://www.kaggle.com/competitions/nlp-getting-started\">NLP - Getting Started</a>. The goal is to classify whether a tweet is about a real disaster or not (<code>target = 1</code> or <code>0</code>).</p>\n<p></p><h3>\ud83d\ude80 Installation</h3><a href=\"#-installation\"></a><p></p>\n<ol>\n<li>Clone the repository:</li>\n</ol>\n<div><pre><code>git clone https://github.com/SergKhachikyan/London_House_Price_Prediction_Advanced_Techniques.git\n</code></pre></div>\n<ol>\n<li>Change directory:</li>\n</ol>\n<div><pre><code>cd London_House_Price_Prediction_Advanced_Techniques\n</code></pre></div>\n<ol>\n<li>Create virtual environment:</li>\n</ol>\n<ol>\n<li>Activate virtual environment:</li>\n</ol>\n<ol>\n<li>Update the package manager:</li>\n</ol>\n<p>6.Install dependencies:</p>\n<div><pre><code>pip install -r requirements.txt\n</code></pre></div>\n<p>7.Launch the notebook:</p>\n<div><pre><code>jupyter notebook untitled.ipynb\n</code></pre></div>\n<p></p><h3>\ud83d\udcc2 Project Structure:</h3><a href=\"#-project-structure\"></a><p></p>\n<ul>\n<li><code>train.csv</code> / <code>test.csv</code> \u2013 original dataset</li>\n<li><code>submission.csv</code> \u2013 prediction file for Kaggle submission</li>\n<li><code>NLP_Disaster_Tweets.ipynb</code> \u2013 main notebook with full preprocessing, training and evaluation</li>\n<li><code>README.md</code> \u2013 this file</li>\n</ul>\n<p></p><h3>\u2705 Key Steps:</h3><a href=\"#-key-steps\"></a><p></p>\n<ul>\n<li>Missing values in <code>keyword</code> filled using weighted random sampling based on value_counts distribution (with <code>normalize=True</code>)</li>\n<li>Texts cleaned with <code>clean_text()</code> function: lowercased, removed links, punctuation, digits, extra whitespaces</li>\n<li><code>TfidfVectorizer</code> used with <code>max_features=10000</code>, <code>ngram_range=(1,2)</code>, <code>stop_words='english'</code>, <code>min_df=3</code></li>\n<li>Trained multiple models: <code>RandomForestClassifier</code>, <code>GridSearchCV(RF)</code>, <code>XGBoostClassifier</code>, <code>LogisticRegression(class_weight='balanced')</code></li>\n<li>Best performance: <code>LogisticRegression</code> with TF-IDF vectorizer gave <strong>Public Score: <code>0.79098</code></strong></li>\n<li>Evaluation based on <code>classification_report()</code> with attention to F1-score for class <code>1</code> (disaster-related tweets)</li>\n</ul>\n<p></p><h3>\ud83d\udcca Model Comparison (Validation Set):</h3><a href=\"#-model-comparison-validation-set\"></a><p></p>\n<p></p><h3>\ud83d\udd25 Best Model:</h3><a href=\"#-best-model\"></a><p></p>\n<p>LogisticRegression(\nC=1.0,\nclass_weight='balanced',\nmax_iter=1000,\nrandom_state=42,\nn_jobs=-1\n)</p>\n<p></p><h3>\ud83d\udee0 Possible Next Steps:</h3><a href=\"#-possible-next-steps\"></a><p></p>\n<ul>\n<li>Include keyword as encoded feature</li>\n<li>Try StackingClassifier with LogReg + XGB + RF</li>\n<li>Switch to transformers like BERT/RoBERTa</li>\n<li>Tune TF-IDF (min_df, max_df) or try CountVectorizer</li>\n<li>Feature importance via coef_ in LogReg</li>\n</ul>\n<p></p><h3>\ud83d\udcc8 Submission Format:</h3><a href=\"#-submission-format\"></a><p></p>\n<p>csv\nid,target\n0,1\n1,0\n2,1\n...</p>\n<p></p><h3>\ud83d\udcac Final Note:</h3><a href=\"#-final-note\"></a><p></p>\n<p>This repo helped me go from 0.75x public score to 0.79098. The most effective combo was cleaned text + tf-idf + balanced logistic regression. Clean, simple, and powerful.</p>\n</article></div></div>",
      "url": "https://github.com/SergKhachikyan/NaturalLanguageProcessingwithDisasterTweets"
    }
  ]
}