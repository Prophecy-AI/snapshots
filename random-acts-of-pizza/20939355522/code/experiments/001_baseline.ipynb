{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda3ba19",
   "metadata": {},
   "source": [
    "# Baseline Experiment 001\n",
    "\n",
    "Simple baseline using TF-IDF text features + basic tabular features with Logistic Regression.\n",
    "\n",
    "Features:\n",
    "- TF-IDF on request_text_edit_aware\n",
    "- Basic tabular features (requester_account_age, requester_upvotes_plus_downvotes_at_retrieval, etc.)\n",
    "- Simple flair encoding\n",
    "- Text length features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b98ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T00:45:42.773616Z",
     "iopub.status.busy": "2026-01-13T00:45:42.772913Z",
     "iopub.status.idle": "2026-01-13T00:45:42.835884Z",
     "shell.execute_reply": "2026-01-13T00:45:42.835298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Training samples: 2878\n",
      "Positive rate: 0.248\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load data\n",
    "print(\"Loading training data...\")\n",
    "train_path = \"/home/data/train.json\"\n",
    "with open(train_path, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Positive rate: {np.mean([d['requester_received_pizza'] for d in train_data]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a791d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T00:45:42.837911Z",
     "iopub.status.busy": "2026-01-13T00:45:42.837688Z",
     "iopub.status.idle": "2026-01-13T00:45:42.885237Z",
     "shell.execute_reply": "2026-01-13T00:45:42.884590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating basic features...\n",
      "Features created:\n",
      "   text_length  title_length  has_flair  flair_shroom  flair_pif  \\\n",
      "0          214            65          0             0          0   \n",
      "1          169           122          0             0          0   \n",
      "2          694            85          0             0          0   \n",
      "3         1028            39          1             1          0   \n",
      "4          163            33          0             0          0   \n",
      "\n",
      "   requester_upvotes_ratio  account_age_days  \n",
      "0                 0.875000        647.297060  \n",
      "1                 0.999543        966.278588  \n",
      "2                 0.750000        721.636238  \n",
      "3                 0.994898        757.480891  \n",
      "4                 0.999713       1170.732118  \n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame and basic features\n",
    "print(\"Creating basic features...\")\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "# Basic text features\n",
    "train_df['text_length'] = train_df['request_text_edit_aware'].str.len()\n",
    "train_df['title_length'] = train_df['request_title'].str.len()\n",
    "train_df['total_length'] = train_df['text_length'] + train_df['title_length']\n",
    "\n",
    "# Flair encoding (handle missing values)\n",
    "train_df['has_flair'] = train_df['requester_user_flair'].notna().astype(int)\n",
    "train_df['flair_shroom'] = (train_df['requester_user_flair'] == 'shroom').astype(int)\n",
    "train_df['flair_pif'] = (train_df['requester_user_flair'] == 'PIF').astype(int)\n",
    "train_df['flair_other'] = (train_df['has_flair'] & ~train_df['flair_shroom'] & ~train_df['flair_pif']).astype(int)\n",
    "\n",
    "# Fill missing flair with 'None'\n",
    "train_df['requester_user_flair'] = train_df['requester_user_flair'].fillna('None')\n",
    "\n",
    "# Vote ratios\n",
    "train_df['requester_upvotes_ratio'] = train_df['requester_upvotes_plus_downvotes_at_retrieval'] / (train_df['requester_upvotes_plus_downvotes_at_retrieval'] + 1)\n",
    "\n",
    "# Account age in days\n",
    "train_df['account_age_days'] = train_df['requester_account_age_in_days_at_retrieval']\n",
    "\n",
    "print(\"Features created:\")\n",
    "print(train_df[['text_length', 'title_length', 'has_flair', 'flair_shroom', 'flair_pif', 'requester_upvotes_ratio', 'account_age_days']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e66bf66b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T00:45:42.887615Z",
     "iopub.status.busy": "2026-01-13T00:45:42.887052Z",
     "iopub.status.idle": "2026-01-13T00:45:43.345841Z",
     "shell.execute_reply": "2026-01-13T00:45:43.345280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing TF-IDF features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (2878, 5000)\n",
      "Tabular features shape: (2878, 11)\n",
      "Combined feature shape: (2878, 5011)\n",
      "Target distribution: [2163  715]\n"
     ]
    }
   ],
   "source": [
    "# Prepare text data for TF-IDF\n",
    "print(\"Preparing TF-IDF features...\")\n",
    "\n",
    "# Use request_text_edit_aware to avoid leakage from success indicators\n",
    "text_data = train_df['request_text_edit_aware'].fillna('')\n",
    "\n",
    "# TF-IDF vectorizer with reasonable parameters\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit features to prevent overfitting\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),  # Include bigrams\n",
    "    min_df=2,  # Ignore very rare terms\n",
    "    max_df=0.95  # Ignore very common terms\n",
    ")\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(text_data)\n",
    "print(f\"TF-IDF shape: {tfidf_features.shape}\")\n",
    "\n",
    "# Tabular features\n",
    "tabular_features = train_df[[\n",
    "    'text_length', 'title_length', 'total_length',\n",
    "    'has_flair', 'flair_shroom', 'flair_pif', 'flair_other',\n",
    "    'requester_upvotes_plus_downvotes_at_retrieval',\n",
    "    'requester_upvotes_ratio',\n",
    "    'account_age_days',\n",
    "    'request_number_of_comments_at_retrieval'\n",
    "]].values\n",
    "\n",
    "print(f\"Tabular features shape: {tabular_features.shape}\")\n",
    "\n",
    "# Scale tabular features\n",
    "scaler = StandardScaler()\n",
    "tabular_features_scaled = scaler.fit_transform(tabular_features)\n",
    "\n",
    "# Combine features\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# Convert tabular features to sparse format for efficient stacking\n",
    "tabular_sparse = csr_matrix(tabular_features_scaled)\n",
    "\n",
    "X = hstack([tfidf_features, tabular_sparse])\n",
    "print(f\"Combined feature shape: {X.shape}\")\n",
    "\n",
    "# Target\n",
    "y = train_df['requester_received_pizza'].values\n",
    "print(f\"Target distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85ed171d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T00:45:43.347708Z",
     "iopub.status.busy": "2026-01-13T00:45:43.347508Z",
     "iopub.status.idle": "2026-01-13T00:45:46.513168Z",
     "shell.execute_reply": "2026-01-13T00:45:46.512013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Stratified 5-fold CV...\n",
      "\n",
      "Fold 1\n",
      "  Positive rate: 0.248, Scale pos weight: 3.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold AUC: 1.0000\n",
      "\n",
      "Fold 2\n",
      "  Positive rate: 0.248, Scale pos weight: 3.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold AUC: 1.0000\n",
      "\n",
      "Fold 3\n",
      "  Positive rate: 0.248, Scale pos weight: 3.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold AUC: 1.0000\n",
      "\n",
      "Fold 4\n",
      "  Positive rate: 0.248, Scale pos weight: 3.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold AUC: 1.0000\n",
      "\n",
      "Fold 5\n",
      "  Positive rate: 0.248, Scale pos weight: 3.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold AUC: 1.0000\n",
      "\n",
      "CV Score: 1.0000 ± 0.0000\n",
      "OOF AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-Fold CV\n",
    "print(\"Running Stratified 5-fold CV...\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "    \n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Calculate class weight for imbalance\n",
    "    pos_rate = np.mean(y_train)\n",
    "    scale_pos_weight = (1 - pos_rate) / pos_rate\n",
    "    print(f\"  Positive rate: {pos_rate:.3f}, Scale pos weight: {scale_pos_weight:.2f}\")\n",
    "    \n",
    "    # Train logistic regression with class weighting\n",
    "    model = LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Calculate AUC\n",
    "    fold_auc = roc_auc_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_auc)\n",
    "    print(f\"  Fold AUC: {fold_auc:.4f}\")\n",
    "\n",
    "# Overall CV score\n",
    "mean_auc = np.mean(fold_scores)\n",
    "std_auc = np.std(fold_scores)\n",
    "print(f\"\\nCV Score: {mean_auc:.4f} ± {std_auc:.4f}\")\n",
    "\n",
    "# OOF AUC\n",
    "oof_auc = roc_auc_score(y, oof_predictions)\n",
    "print(f\"OOF AUC: {oof_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data and create predictions\n",
    "print(\"Loading test data...\")\n",
    "test_path = \"/home/data/test.json\"\n",
    "with open(test_path, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "# Create same features for test data\n",
    "print(\"Creating test features...\")\n",
    "\n",
    "# Text features\n",
    "test_df['text_length'] = test_df['request_text_edit_aware'].str.len()\n",
    "test_df['title_length'] = test_df['request_title'].str.len()\n",
    "test_df['total_length'] = test_df['text_length'] + test_df['title_length']\n",
    "\n",
    "# Note: Test data has different column names - use _at_request instead of _at_retrieval\n",
    "# Vote ratios\n",
    "test_df['requester_upvotes_ratio'] = test_df['requester_upvotes_plus_downvotes_at_request'] / (test_df['requester_upvotes_plus_downvotes_at_request'] + 1)\n",
    "\n",
    "# Account age\n",
    "test_df['account_age_days'] = test_df['requester_account_age_in_days_at_request']\n",
    "\n",
    "# Comments at request (no flair in test data)\n",
    "test_df['has_flair'] = 0  # No flair in test data\n",
    "test_df['flair_shroom'] = 0\n",
    "test_df['flair_pif'] = 0\n",
    "test_df['flair_other'] = 0\n",
    "\n",
    "# TF-IDF features for test\n",
    "test_text = test_df['request_text_edit_aware'].fillna('')\n",
    "test_tfidf = tfidf.transform(test_text)\n",
    "\n",
    "# Tabular features for test\n",
    "test_tabular = test_df[[\n",
    "    'text_length', 'title_length', 'total_length',\n",
    "    'has_flair', 'flair_shroom', 'flair_pif', 'flair_other',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_upvotes_ratio',\n",
    "    'account_age_days',\n",
    "    'requester_number_of_comments_at_request'\n",
    "]].values\n",
    "\n",
    "test_tabular_scaled = scaler.transform(test_tabular)\n",
    "\n",
    "# Combine test features\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "test_tabular_sparse = csr_matrix(test_tabular_scaled)\n",
    "X_test = hstack([test_tfidf, test_tabular_sparse])\n",
    "print(f\"Test feature shape: {X_test.shape}\")\n",
    "\n",
    "# Predict on test\n",
    "print(\"Making predictions...\")\n",
    "test_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_pred\n",
    "})\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nPrediction stats: min={test_pred.min():.3f}, max={test_pred.max():.3f}, mean={test_pred.mean():.3f}\")\n",
    "\n",
    "# Save submission\n",
    "submission_path = \"/home/submission/submission_001_baseline.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
