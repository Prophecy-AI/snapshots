## Current Status
- Best CV: 1.0 from exp_000 (meaningless due to data leakage)
- Experiments above gold: 0
- **Critical Issue**: Perfect score is caused by data leakage, not model quality

## Response to Evaluator
- **Technical verdict was UNRELIABLE**: I completely agree. The 1.0 AUC is meaningless.
- **Evaluator's top priority**: Rebuild baseline WITHOUT flair features - **This is my #1 priority**
- **Key concerns raised**:
  1. **Data leakage through flair**: Confirmed - 'shroom' (677 samples) and 'PIF' (38 samples) have 100% success rates. These are post-hoc indicators awarded AFTER successful requests.
  2. **Lack of feature validation**: Correct - we must validate feature availability at prediction time
  3. **No diagnostic analysis**: Right - we should have investigated the perfect score immediately
  4. **Temporal split issue**: Confirmed - train has _at_retrieval columns, test has _at_request columns

**My response**: I will rebuild from scratch using ONLY features available at request time, completely eliminating all leakage sources before proceeding.

## Data Understanding
**Reference notebooks**: See `exploration/evolver_loop1_analysis.ipynb` for detailed leakage investigation

**Key patterns discovered**:
- **Leakage confirmed**: 'shroom' flair = 100% success (677 samples), 'PIF' flair = 100% success (38 samples)
- **Temporal split**: Train includes post-outcome features (_at_retrieval), test only has pre-outcome features (_at_request)
- **Safe features** (available at request time):
  - All _at_request features (account age, votes, comments, posts)
  - Text features: TF-IDF, text_length (0.120 correlation), title_length
  - Top correlations: requester_number_of_posts_on_raop_at_request (0.133), requester_number_of_comments_in_raop_at_request (0.132)

**Critical insight**: Test data has NO flair column at all, confirming that flair is not available at prediction time.

## Recommended Approaches (Priority Order)

### 1. Rebuild Clean Baseline (HIGHEST PRIORITY)
Remove ALL leakage sources and rebuild:
- **Remove**: All flair features (has_flair, flair_shroom, flair_pif, flair_other)
- **Remove**: All _at_retrieval features (post-outcome data)
- **Keep**: Only _at_request features and text features
- **Model**: Start with Logistic Regression, then try XGBoost/LightGBM
- **Expected performance**: AUC in 0.75-0.85 range (reasonable for this problem)

### 2. Add Reddit-Specific Features
Based on research, engineer features that work well for Reddit:
- **Text features**: TF-IDF with ngrams (1,2), subreddit mentions (/r/ patterns)
- **Readability scores**: Flesch-Kincaid, sentiment analysis
- **User engagement**: Requester's historical activity patterns
- **Temporal features**: Hour of day, day of week from timestamp

### 3. Try Gradient Boosting Models
XGBoost/LightGBM typically outperform logistic regression for mixed text + tabular:
- Better handling of feature interactions
- More robust to noisy features
- Built-in feature importance for diagnostics

### 4. Implement Proper Validation
Consider time-based validation given temporal nature:
- Stratified K-fold as baseline
- But investigate if time-based split would be more appropriate
- Monitor for leakage between folds

### 5. Diagnostic Analysis
For each experiment:
- Check feature importances to identify suspicious features
- Build ablated models (remove top features one by one)
- Examine predictions distribution - should not be degenerate

## What NOT to Try
- **DO NOT use any flair features** - they're all post-hoc indicators
- **DO NOT use _at_retrieval features** - they're post-outcome and cause leakage
- **DO NOT trust perfect scores** - if AUC > 0.95, investigate immediately for leakage
- **DO NOT skip feature validation** - verify every feature is available at request time

## Validation Notes
- **CV scheme**: Stratified 5-fold with shuffling (current implementation is correct)
- **Confidence**: Low confidence in current 1.0 AUC (completely unreliable)
- **Target**: Achieve stable AUC in 0.75-0.85 range without leakage
- **Reproducibility**: Run multiple experiments with different seeds to verify stability

## Expected Timeline
1. **Immediate**: Rebuild clean baseline (1-2 experiments)
2. **Next**: Add Reddit-specific features and try XGBoost
3. **Then**: Ensemble approaches if single models plateau
4. **Final**: Only submit when CV consistently exceeds gold threshold with clean features