{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c83e0994",
   "metadata": {},
   "source": [
    "# Evolver Loop 2 Analysis\n",
    "\n",
    "Analyze the clean baseline results and identify opportunities for improvement.\n",
    "\n",
    "Key questions:\n",
    "1. Why is the clean baseline only 0.6406 AUC?\n",
    "2. What features are most important in the clean model?\n",
    "3. Where can we gain the most improvement?\n",
    "4. Should we investigate temporal validation given the _at_request vs _at_retrieval split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "187a0a86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T03:16:01.537696Z",
     "iopub.status.busy": "2026-01-13T03:16:01.537019Z",
     "iopub.status.idle": "2026-01-13T03:16:03.094608Z",
     "shell.execute_reply": "2026-01-13T03:16:03.094024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Training samples: 2878\n",
      "Positive rate: 0.248\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "print(\"Loading training data...\")\n",
    "train_path = \"/home/data/train.json\"\n",
    "with open(train_path, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Positive rate: {train_df['requester_received_pizza'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0bae06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T03:16:03.167737Z",
     "iopub.status.busy": "2026-01-13T03:16:03.166964Z",
     "iopub.status.idle": "2026-01-13T03:16:03.186113Z",
     "shell.execute_reply": "2026-01-13T03:16:03.185620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating clean features...\n",
      "text_length: 0.120\n",
      "title_length: 0.015\n",
      "total_length: 0.121\n",
      "requester_upvotes_ratio: 0.105\n",
      "account_age_days: 0.043\n",
      "comments_at_request: 0.132\n",
      "posts_at_request: 0.133\n",
      "days_since_first_post: 0.109\n",
      "\n",
      "Features by absolute correlation:\n",
      "  posts_at_request: 0.133\n",
      "  comments_at_request: 0.132\n",
      "  total_length: 0.121\n",
      "  text_length: 0.120\n",
      "  days_since_first_post: 0.109\n",
      "  requester_upvotes_ratio: 0.105\n",
      "  account_age_days: 0.043\n",
      "  title_length: 0.015\n"
     ]
    }
   ],
   "source": [
    "# Create clean features (same as exp_001)\n",
    "print(\"Creating clean features...\")\n",
    "\n",
    "# Text features\n",
    "train_df['text_length'] = train_df['request_text_edit_aware'].str.len()\n",
    "train_df['title_length'] = train_df['request_title'].str.len()\n",
    "train_df['total_length'] = train_df['text_length'] + train_df['title_length']\n",
    "\n",
    "# Safe tabular features (at_request only)\n",
    "train_df['requester_upvotes_ratio'] = train_df['requester_upvotes_plus_downvotes_at_request'] / (train_df['requester_upvotes_plus_downvotes_at_request'] + 1)\n",
    "train_df['account_age_days'] = train_df['requester_account_age_in_days_at_request']\n",
    "train_df['comments_at_request'] = train_df['requester_number_of_comments_in_raop_at_request']\n",
    "train_df['posts_at_request'] = train_df['requester_number_of_posts_on_raop_at_request']\n",
    "train_df['days_since_first_post'] = train_df['requester_days_since_first_post_on_raop_at_request']\n",
    "\n",
    "# Check feature correlations with target\n",
    "features_to_check = ['text_length', 'title_length', 'total_length', \n",
    "                     'requester_upvotes_ratio', 'account_age_days',\n",
    "                     'comments_at_request', 'posts_at_request', 'days_since_first_post']\n",
    "\n",
    "correlations = {}\n",
    "for feat in features_to_check:\n",
    "    corr = train_df[feat].corr(train_df['requester_received_pizza'])\n",
    "    correlations[feat] = corr\n",
    "    print(f\"{feat}: {corr:.3f}\")\n",
    "\n",
    "# Sort by absolute correlation\n",
    "sorted_corr = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "print(\"\\nFeatures by absolute correlation:\")\n",
    "for feat, corr in sorted_corr:\n",
    "    print(f\"  {feat}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8a93bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T03:16:03.188123Z",
     "iopub.status.busy": "2026-01-13T03:16:03.187630Z",
     "iopub.status.idle": "2026-01-13T03:16:04.451406Z",
     "shell.execute_reply": "2026-01-13T03:16:04.450776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building clean baseline model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (2878, 5008)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validated AUC: 0.6388\n",
      "This matches exp_001 score of 0.6406\n"
     ]
    }
   ],
   "source": [
    "# Build the same model as exp_001 to verify\n",
    "print(\"Building clean baseline model...\")\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english', \n",
    "                       ngram_range=(1, 2), min_df=2, max_df=0.95)\n",
    "text_data = train_df['request_text_edit_aware'].fillna('')\n",
    "tfidf_features = tfidf.fit_transform(text_data)\n",
    "\n",
    "# Tabular features\n",
    "tabular_features = train_df[features_to_check].values\n",
    "scaler = StandardScaler()\n",
    "tabular_features_scaled = scaler.fit_transform(tabular_features)\n",
    "\n",
    "# Combine\n",
    "X = hstack([tfidf_features, csr_matrix(tabular_features_scaled)])\n",
    "y = train_df['requester_received_pizza'].values\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "\n",
    "# Cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Get cross-validated predictions to analyze\n",
    "y_pred_proba = cross_val_predict(\n",
    "    LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n",
    "    X, y, cv=skf, method='predict_proba', n_jobs=5\n",
    ")[:, 1]\n",
    "\n",
    "cv_auc = roc_auc_score(y, y_pred_proba)\n",
    "print(f\"\\nCross-validated AUC: {cv_auc:.4f}\")\n",
    "print(f\"This matches exp_001 score of 0.6406\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c08197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze predictions vs actuals\n",
    "print(\"Analyzing prediction quality...\")\n",
    "\n",
    "# Check prediction distribution\n",
    "print(f\"Prediction mean: {y_pred_proba.mean():.3f}\")\n",
    "print(f\"Prediction std: {y_pred_proba.std():.3f}\")\n",
    "print(f\"Prediction min: {y_pred_proba.min():.3f}\")\n",
    "print(f\"Prediction max: {y_pred_proba.max():.3f}\")\n",
    "\n",
    "# Check calibration\n",
    "positive_mask = y == 1\n",
    "negative_mask = y == 0\n",
    "\n",
    "print(f\"\\nMean prediction for positives: {y_pred_proba[positive_mask].mean():.3f}\")\n",
    "print(f\"Mean prediction for negatives: {y_pred_proba[negative_mask].mean():.3f}\")\n",
    "\n",
    "# This shows the model is struggling to separate the classes well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis for the clean model\n",
    "print(\"Analyzing feature importance...\")\n",
    "\n",
    "# Train a single model to get coefficients\n",
    "model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature names\n",
    "tfidf_feature_names = [f'tfidf_{i}' for i in range(tfidf_features.shape[1])]\n",
    "tabular_feature_names = features_to_check\n",
    "all_feature_names = tfidf_feature_names + tabular_feature_names\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Find top positive and negative features\n",
    "feature_importance = list(zip(all_feature_names, coefficients))\n",
    "feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"Top 20 most important features:\")\n",
    "for i, (name, coef) in enumerate(feature_importance[:20]):\n",
    "    print(f\"{i+1:2d}. {name}: {coef:.4f}\")\n",
    "\n",
    "# Count how many are TF-IDF vs tabular\n",
    "tfidf_important = sum(1 for name, _ in feature_importance[:50] if name.startswith('tfidf_'))\n",
    "tabular_important = sum(1 for name, _ in feature_importance[:50] if not name.startswith('tfidf_'))\n",
    "\n",
    "print(f\"\\nAmong top 50 features:\")\n",
    "print(f\"  TF-IDF features: {tfidf_important}\")\n",
    "print(f\"  Tabular features: {tabular_important}\")\n",
    "\n",
    "# This tells us whether text or tabular features are driving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b0fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze misclassified examples to understand patterns\n",
    "print(\"Analyzing misclassifications...\")\n",
    "\n",
    "# Add predictions to dataframe for analysis\n",
    "train_df['pred_proba'] = y_pred_proba\n",
    "train_df['pred_label'] = (y_pred_proba > 0.5).astype(int)\n",
    "train_df['correct'] = (train_df['pred_label'] == train_df['requester_received_pizza'])\n",
    "\n",
    "# False positives (predicted success but actually failed)\n",
    "false_positives = train_df[(train_df['pred_label'] == 1) & (train_df['requester_received_pizza'] == 0)]\n",
    "print(f\"False positives: {len(false_positives)} ({len(false_positives)/len(train_df)*100:.1f}%)\")\n",
    "\n",
    "# False negatives (predicted failure but actually succeeded)\n",
    "false_negatives = train_df[(train_df['pred_label'] == 0) & (train_df['requester_received_pizza'] == 1)]\n",
    "print(f\"False negatives: {len(false_negatives)} ({len(false_negatives)/len(train_df)*100:.1f}%)\")\n",
    "\n",
    "# Check characteristics of false negatives (these are costly errors)\n",
    "print(f\"\\nFalse negatives - mean posts_at_request: {false_negatives['posts_at_request'].mean():.2f}\")\n",
    "print(f\"All samples - mean posts_at_request: {train_df['posts_at_request'].mean():.2f}\")\n",
    "\n",
    "print(f\"\\nFalse negatives - mean comments_at_request: {false_negatives['comments_at_request'].mean():.2f}\")\n",
    "print(f\"All samples - mean comments_at_request: {train_df['comments_at_request'].mean():.2f}\")\n",
    "\n",
    "# This helps us understand what patterns the model is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc19b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze misclassified examples to understand patterns\n",
    "print(\"Analyzing misclassifications...\")\n",
    "\n",
    "# Add predictions to dataframe for analysis\n",
    "train_df['pred_proba'] = y_pred_proba\n",
    "train_df['pred_label'] = (y_pred_proba > 0.5).astype(int)\n",
    "train_df['correct'] = (train_df['pred_label'] == train_df['requester_received_pizza'])\n",
    "\n",
    "# False positives (predicted success but actually failed)\n",
    "false_positives = train_df[(train_df['pred_label'] == 1) & (train_df['requester_received_pizza'] == 0)]\n",
    "print(f\"False positives: {len(false_positives)} ({len(false_positives)/len(train_df)*100:.1f}%)\")\n",
    "\n",
    "# False negatives (predicted failure but actually succeeded)\n",
    "false_negatives = train_df[(train_df['pred_label'] == 0) & (train_df['requester_received_pizza'] == 1)]\n",
    "print(f\"False negatives: {len(false_negatives)} ({len(false_negatives)/len(train_df)*100:.1f}%)\")\n",
    "\n",
    "# Check characteristics of false negatives (these are costly errors)\n",
    "print(f\"\\nFalse negatives - mean posts_at_request: {false_negatives['posts_at_request'].mean():.2f}\")\n",
    "print(f\"All samples - mean posts_at_request: {train_df['posts_at_request'].mean():.2f}\")\n",
    "\n",
    "print(f\"\\nFalse negatives - mean comments_at_request: {false_negates['comments_at_request'].mean():.2f}\")\n",
    "print(f\"All samples - mean comments_at_request: {train_df['comments_at_request'].mean():.2f}\")\n",
    "\n",
    "# This helps us understand what patterns the model is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c99f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of findings and recommendations\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1. CLEAN BASELINE PERFORMANCE: {cv_auc:.4f} AUC\")\n",
    "print(\"   - This is realistic (not leaked) but needs improvement\")\n",
    "print(\"   - Gold threshold is 0.979080, need +0.3385 points\")\n",
    "\n",
    "print(f\"\\n2. FEATURE CORRELATIONS (top 3):\")\n",
    "for feat, corr in sorted_corr[:3]:\n",
    "    print(f\"   - {feat}: {corr:.3f}\")\n",
    "\n",
    "print(f\"\\n3. MODEL RELIES HEAVILY ON:\")\n",
    "if tfidf_important > tabular_important:\n",
    "    print(\"   - TEXT features (TF-IDF dominates top 50)\")\n",
    "    print(\"   - Recommendation: Enhance text representation\")\n",
    "else:\n",
    "    print(\"   - TABULAR features (meta features dominate)\")\n",
    "    print(\"   - Recommendation: Engineer more interaction features\")\n",
    "\n",
    "print(f\"\\n4. PREDICTION QUALITY ISSUES:\")\n",
    "print(f\"   - Mean prediction for positives: {y_pred_proba[positive_mask].mean():.3f}\")\n",
    "print(f\"   - Mean prediction for negatives: {y_pred_proba[negative_mask].mean():.3f}\")\n",
    "print(\"   - Model struggles to separate classes well\")\n",
    "\n",
    "print(f\"\\n5. KEY OPPORTUNITIES:\")\n",
    "print(\"   a) Upgrade model: XGBoost/LightGBM (typically +0.05-0.10 AUC)\")\n",
    "print(\"   b) Better text features: sentiment, readability, character ngrams\")\n",
    "print(\"   c) Interaction features: posts Ã— comments, activity ratios\")\n",
    "print(\"   d) Temporal features: hour, day_of_week patterns\")\n",
    "print(\"   e) Advanced text: BERT/RoBERTa embeddings\")\n",
    "\n",
    "print(f\"\\n6. NEXT STEPS (priority order):\")\n",
    "print(\"   1. Try XGBoost with current features (quick win)\")\n",
    "print(\"   2. Add text meta-features (sentiment, readability)\")\n",
    "print(\"   3. Engineer interaction features\")\n",
    "print(\"   4. Try BERT embeddings if needed\")\n",
    "\n",
    "# Save key findings\n",
    "with open('/home/code/analysis_summary_loop2.txt', 'w') as f:\n",
    "    f.write(f\"Clean Baseline AUC: {cv_auc:.4f}\\n\")\n",
    "    f.write(f\"Need improvement: {0.979080 - cv_auc:.4f} points to reach gold\\n\")\n",
    "    f.write(f\"Top feature: {sorted_corr[0][0]} (correlation: {sorted_corr[0][1]:.3f})\\n\")\n",
    "    f.write(f\"Text features in top 50: {tfidf_important}\\n\")\n",
    "    f.write(f\"Tabular features in top 50: {tabular_important}\\n\")\n",
    "\n",
    "print(f\"\\nAnalysis complete. Summary saved to analysis_summary_loop2.txt\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
