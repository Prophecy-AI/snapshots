## Data Understanding

**Reference notebooks for data characteristics:**
- `eda.ipynb` - Contains full EDA: 2,878 training samples, 24.8% positive class (significant imbalance), text features (request_text, request_title) with mean lengths of 403 and 72 characters respectively, rich metadata about user activity
- Test set contains only features available at request time ("_at_request" suffix), while train has additional retrieval-time features
- Key challenge: Class imbalance (approx 1:3 ratio) and combining text with tabular metadata

## Models

For text classification with metadata on Kaggle, winning approaches typically use:

**Primary Models:**
- Gradient boosting (LightGBM/XGBoost) on engineered features - fast, strong baseline for tabular + text features
- Fine-tuned transformers (BERT/RoBERTa) for text understanding, especially effective for social media text
- Neural networks combining text embeddings with metadata through concatenation

**Model Selection Guidelines:**
- Use LightGBM/XGBoost when you have strong feature engineering and limited compute
- Use transformers when text semantics are critical and you have sufficient compute
- For best results: Ensemble 3-5 diverse models (e.g., transformer + gradient boosting + neural net)

## Preprocessing & Feature Engineering

**Text Processing (Critical for Reddit data):**
- Merge request_title and request_text into single document for processing
- Clean Reddit-specific noise: URLs, HTML tags, emojis, special characters, extra whitespace
- Convert to lowercase
- Lemmatize rather than stem to preserve meaning
- Build custom stopword list: start with standard stopwords, add subreddit-specific frequent terms
- For classical models: TF-IDF with unigrams and bigrams, then chi-square feature selection (top 10K-20K features)
- For transformers: minimal preprocessing (basic cleaning only)
- Consider using request_text_edit_aware to remove success indicators (edits thanking givers)

**Metadata Features:**
- Account activity metrics (comments, posts, upvotes) are strong predictors - log scale or bin to reduce skew
- Account age and RAOP-specific activity (days_since_first_post_on_raop) are valuable
- Subreddit diversity (requester_number_of_subreddits) may indicate user engagement patterns
- Temporal features: hour of day, day of week from unix_timestamp_of_request
- Create interaction features: e.g., author_karma × post_activity, time_of_day × comment_rate
- Temporal decay features: time since account creation, time since last activity
- Handle missing values carefully - many fields have missing data
- For categorical: requester_user_flair (None/shroom/PIF) - strong signal of past behavior

**Combining Text and Metadata:**
Two effective approaches:
1. **Concatenation approach**: Join text fields with metadata as strings, feed to transformer
2. **Separate embeddings**: Text embedding from transformer + processed metadata → concatenated classifier
3. **Hybrid approach**: Use text features for transformer, engineered metadata features for gradient boosting, then ensemble

## Handling Class Imbalance

**Critical for this competition (24.8% positive rate):**
- Use class_weight='balanced' or equivalent in models
- Consider focal loss or other cost-sensitive approaches
- Oversampling minority class (SMOTE or simple duplication) can help
- Monitor AUC-ROC rather than accuracy for validation
- Stratified K-fold (k=5) essential to maintain class distribution

## Validation Strategy

**Essential approaches:**
- Stratified K-fold (k=5) to handle class imbalance
- Time-based splits if temporal patterns exist (check timestamps in eda.ipynb)
- Use AUC-ROC for validation metric (matches competition evaluation)
- Early stopping on validation AUC to prevent overfitting

## Ensembling

**Winning ensemble strategies:**
- Stack 3-5 diverse models (e.g., BERT + LightGBM + Neural Net + Logistic Regression)
- Use out-of-fold predictions for stacking to avoid leakage
- Simple averaging can work but stacking often performs better for heterogeneous models
- Weight models by validation performance

## Optimization

**Hyperparameter tuning:**
- Bayesian optimization (Optuna) effective for tree models and neural nets
- Learning rate scheduling important for transformers
- For LightGBM: focus on num_leaves, learning_rate, min_child_samples
- For transformers: focus on learning_rate, batch_size, warmup_steps