{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f6a606",
   "metadata": {},
   "source": [
    "# Loop 4 Analysis: Understanding Character N-gram Patterns\n",
    "\n",
    "**Goal**: Analyze what the top character n-grams actually represent to guide further feature engineering\n",
    "\n",
    "**Focus**: Map character n-grams back to actual text patterns to understand what's working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a49ae88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T13:13:42.886027Z",
     "iopub.status.busy": "2026-01-12T13:13:42.885171Z",
     "iopub.status.idle": "2026-01-12T13:13:44.439930Z",
     "shell.execute_reply": "2026-01-12T13:13:44.439318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2878, 32)\n",
      "Test shape: (1162, 17)\n",
      "Target distribution: {False: 2163, True: 715}\n",
      "Positive rate: 0.248\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "print(\"Loading training data...\")\n",
    "train_df = pd.read_json('/home/data/train.json', orient='records')\n",
    "test_df = pd.read_json('/home/data/test.json', orient='records')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Target distribution: {train_df['requester_received_pizza'].value_counts().to_dict()}\")\n",
    "print(f\"Positive rate: {train_df['requester_received_pizza'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72597c",
   "metadata": {},
   "source": [
    "## Analyze Top Character N-grams from exp_003\n",
    "\n",
    "The evaluator noted these top character n-grams:\n",
    "- char_ss (likely from \"pizza\", \"bless\", \"blessing\")\n",
    "- char_f a (likely from \"for a\", \"from a\")\n",
    "- char_e a (likely from \"please\", \"get a\", \"have a\")\n",
    "- char_thi (likely from \"this\", \"thing\")\n",
    "- char_ere (likely from \"here\", \"there\", \"where\")\n",
    "\n",
    "Let's map these back to actual text patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01dad603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T13:13:44.442716Z",
     "iopub.status.busy": "2026-01-12T13:13:44.442113Z",
     "iopub.status.idle": "2026-01-12T13:13:44.448180Z",
     "shell.execute_reply": "2026-01-12T13:13:44.447559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: I would really appreciate a pizza, I'm so hungry\n",
      "Sample n-grams: ['i_w', '_wo', 'wou', 'oul', 'uld', 'ld_', 'd_r', '_re', 'rea', 'eal']\n",
      "\n",
      "Text: Please help, my family is struggling\n",
      "Sample n-grams: ['ple', 'lea', 'eas', 'ase', 'se_', 'e_h', '_he', 'hel', 'elp', 'lp,']\n",
      "\n",
      "Text: I can pay back next week\n",
      "Sample n-grams: ['i_c', '_ca', 'can', 'an_', 'n_p', '_pa', 'pay', 'ay_', 'y_b', '_ba']\n",
      "\n",
      "Text: Thank you for reading this\n",
      "Sample n-grams: ['tha', 'han', 'ank', 'nk_', 'k_y', '_yo', 'you', 'ou_', 'u_f', '_fo']\n"
     ]
    }
   ],
   "source": [
    "# Function to extract character n-grams\n",
    "def get_char_ngrams(text, n_range=(3,5)):\n",
    "    \"\"\"Extract character n-grams from text\"\"\"\n",
    "    text = text.lower().replace(' ', '_')  # Replace spaces with underscore to capture word boundaries\n",
    "    ngrams = []\n",
    "    for n in range(n_range[0], n_range[1] + 1):\n",
    "        for i in range(len(text) - n + 1):\n",
    "            ngrams.append(text[i:i+n])\n",
    "    return ngrams\n",
    "\n",
    "# Test on some examples\n",
    "sample_texts = [\n",
    "    \"I would really appreciate a pizza, I'm so hungry\",\n",
    "    \"Please help, my family is struggling\",\n",
    "    \"I can pay back next week\",\n",
    "    \"Thank you for reading this\"\n",
    "]\n",
    "\n",
    "for text in sample_texts:\n",
    "    ngrams = get_char_ngrams(text)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Sample n-grams: {ngrams[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1b702c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T13:13:44.449957Z",
     "iopub.status.busy": "2026-01-12T13:13:44.449767Z",
     "iopub.status.idle": "2026-01-12T13:13:44.936167Z",
     "shell.execute_reply": "2026-01-12T13:13:44.935574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing character n-gram patterns...\n",
      "Successful texts: 715\n",
      "Failed texts: 2163\n",
      "\n",
      "Extracting n-grams from successful requests...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting n-grams from failed requests...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique n-grams in successful: 81229\n",
      "Unique n-grams in failed: 70838\n"
     ]
    }
   ],
   "source": [
    "# Analyze character n-gram patterns in successful vs failed requests\n",
    "print(\"Analyzing character n-gram patterns...\")\n",
    "\n",
    "# Get texts for successful and failed requests\n",
    "successful_texts = train_df[train_df['requester_received_pizza'] == 1]['request_text_edit_aware'].tolist()\n",
    "failed_texts = train_df[train_df['requester_received_pizza'] == 0]['request_text_edit_aware'].tolist()\n",
    "\n",
    "print(f\"Successful texts: {len(successful_texts)}\")\n",
    "print(f\"Failed texts: {len(failed_texts)}\")\n",
    "\n",
    "# Sample for analysis (full dataset would be too slow)\n",
    "sample_size = 500\n",
    "np.random.seed(42)\n",
    "successful_sample = np.random.choice(successful_texts, min(sample_size, len(successful_texts)), replace=False)\n",
    "failed_sample = np.random.choice(failed_texts, min(sample_size, len(failed_texts)), replace=False)\n",
    "\n",
    "# Extract n-grams\n",
    "print(\"\\nExtracting n-grams from successful requests...\")\n",
    "success_ngrams = []\n",
    "for text in successful_sample:\n",
    "    success_ngrams.extend(get_char_ngrams(text))\n",
    "\n",
    "print(\"Extracting n-grams from failed requests...\")\n",
    "failed_ngrams = []\n",
    "for text in failed_sample:\n",
    "    failed_ngrams.extend(get_char_ngrams(text))\n",
    "\n",
    "# Count frequencies\n",
    "success_counts = Counter(success_ngrams)\n",
    "failed_counts = Counter(failed_ngrams)\n",
    "\n",
    "print(f\"Unique n-grams in successful: {len(success_counts)}\")\n",
    "print(f\"Unique n-grams in failed: {len(failed_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6220cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find n-grams with highest success ratio\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP N-GRAMS BY SUCCESS RATIO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate success ratio for n-grams that appear at least 5 times total\n",
    "min_count = 5\n",
    "ratios = []\n",
    "\n",
    "for ngram in set(list(success_counts.keys()) + list(failed_counts.keys())):\n",
    "    success = success_counts.get(ngram, 0)\n",
    "    failed = failed_counts.get(ngram, 0)\n",
    "    total = success + failed\n",
    "    \n",
    "    if total >= min_count:\n",
    "        # Success ratio = proportion in successful texts\n",
    "        ratio = success / total if total > 0 else 0\n",
    "        ratios.append({\n",
    "            'ngram': ngram,\n",
    "            'success': success,\n",
    "            'failed': failed,\n",
    "            'total': total,\n",
    "            'success_ratio': ratio\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "ratio_df = pd.DataFrame(ratios)\n",
    "ratio_df = ratio_df.sort_values('success_ratio', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 n-grams most associated with SUCCESS:\")\n",
    "print(ratio_df.head(20)[['ngram', 'success', 'failed', 'total', 'success_ratio']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nTop 20 n-grams most associated with FAILURE:\")\n",
    "print(ratio_df.tail(20)[['ngram', 'success', 'failed', 'total', 'success_ratio']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbebf9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze specific patterns mentioned by evaluator\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYZING SPECIFIC PATTERNS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Patterns to investigate\n",
    "patterns = ['ss', 'f_a', 'e_a', 'thi', 'ere', ' a_p', 'pl', 'ea', 'zza', 'hun', 'ple', 'for', 'thi', 'ere']\n",
    "\n",
    "print(\"\\nAnalyzing evaluator's suggested patterns:\")\n",
    "for pattern in patterns:\n",
    "    if pattern in success_counts or pattern in failed_counts:\n",
    "        success = success_counts.get(pattern, 0)\n",
    "        failed = failed_counts.get(pattern, 0)\n",
    "        total = success + failed\n",
    "        ratio = success / total if total > 0 else 0\n",
    "        print(f\"  {pattern:6s}: success={success:3d}, failed={failed:3d}, ratio={ratio:.3f}\")\n",
    "\n",
    "# Find n-grams containing 'pizza' or 'please' or 'help'\n",
    "print(\"\\n\\nN-grams related to 'pizza', 'please', 'help':\")\n",
    "pizza_related = [n for n in success_counts.keys() if 'piz' in n or 'zza' in n]\n",
    "please_related = [n for n in success_counts.keys() if 'ple' in n or 'eas' in n]\n",
    "help_related = [n for n in success_counts.keys() if 'hel' in n]\n",
    "\n",
    "print(f\"  Pizza-related n-grams: {len(pizza_related)} unique\")\n",
    "print(f\"  Please-related n-grams: {len(please_related)} unique\")\n",
    "print(f\"  Help-related n-grams: {len(help_related)} unique\")\n",
    "\n",
    "# Show most common ones\n",
    "if pizza_related:\n",
    "    pizza_counts = [(n, success_counts[n] + failed_counts.get(n, 0)) for n in pizza_related]\n",
    "    pizza_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(f\"  Top pizza n-grams: {pizza_counts[:5]}\")\n",
    "\n",
    "if please_related:\n",
    "    please_counts = [(n, success_counts[n] + failed_counts.get(n, 0)) for n in please_related]\n",
    "    please_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(f\"  Top please n-grams: {please_counts[:5]}\")\n",
    "\n",
    "if help_related:\n",
    "    help_counts = [(n, success_counts[n] + failed_counts.get(n, 0)) for n in help_related]\n",
    "    help_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(f\"  Top help n-grams: {help_counts[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6781aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find examples of texts containing top n-grams\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE TEXTS WITH TOP N-GRAMS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get top n-grams by success ratio (with sufficient frequency)\n",
    "top_ngrams = ratio_df[(ratio_df['total'] >= 10) & (ratio_df['success_ratio'] >= 0.7)].head(10)\n",
    "\n",
    "print(\"\\nTop predictive n-grams (>=10 occurrences, >=70% success rate):\")\n",
    "for _, row in top_ngrams.iterrows():\n",
    "    ngram = row['ngram']\n",
    "    print(f\"\\n  N-gram: '{ngram}' (success ratio: {row['success_ratio']:.3f}, count: {row['total']})\")\n",
    "    \n",
    "    # Find example texts containing this n-gram\n",
    "    examples_found = 0\n",
    "    for text in successful_sample[:100]:  # Check first 100 successful texts\n",
    "        if ngram in get_char_ngrams(text):\n",
    "            # Clean up the text for display\n",
    "            clean_text = text[:150] + \"...\" if len(text) > 150 else text\n",
    "            print(f\"    Example: {clean_text}\")\n",
    "            examples_found += 1\n",
    "            if examples_found >= 2:  # Show 2 examples max\n",
    "                break\n",
    "    \n",
    "    if examples_found == 0:\n",
    "        print(f\"    (No examples found in sample)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1432ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what 'ss' pattern represents\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEEP DIVE: 'ss' PATTERN ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find words containing 'ss' in successful texts\n",
    "ss_words_success = []\n",
    "for text in successful_sample:\n",
    "    words = text.lower().split()\n",
    "    ss_words = [w for w in words if 'ss' in w]\n",
    "    ss_words_success.extend(ss_words)\n",
    "\n",
    "ss_words_failed = []\n",
    "for text in failed_sample:\n",
    "    words = text.lower().split()\n",
    "    ss_words = [w for w in words if 'ss' in w]\n",
    "    ss_words_failed.extend(ss_words)\n",
    "\n",
    "ss_success_counts = Counter(ss_words_success)\n",
    "ss_failed_counts = Counter(ss_words_failed)\n",
    "\n",
    "print(\"\\nTop words containing 'ss' in SUCCESSFUL requests:\")\n",
    "ss_success_df = pd.DataFrame(ss_success_counts.most_common(20), columns=['word', 'count'])\n",
    "print(ss_success_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nTop words containing 'ss' in FAILED requests:\")\n",
    "ss_failed_df = pd.DataFrame(ss_failed_counts.most_common(20), columns=['word', 'count'])\n",
    "print(ss_failed_df.to_string(index=False))\n",
    "\n",
    "# Calculate ratio for specific words\n",
    "print(\"\\n\\nSuccess ratio for words containing 'ss':\")\n",
    "ss_words = set(list(ss_success_counts.keys()) + list(ss_failed_counts.keys()))\n",
    "ss_ratios = []\n",
    "\n",
    "for word in ss_words:\n",
    "    success = ss_success_counts.get(word, 0)\n",
    "    failed = ss_failed_counts.get(word, 0)\n",
    "    total = success + failed\n",
    "    if total >= 3:  # At least 3 occurrences\n",
    "        ratio = success / total\n",
    "        ss_ratios.append({\n",
    "            'word': word,\n",
    "            'success': success,\n",
    "            'failed': failed,\n",
    "            'total': total,\n",
    "            'ratio': ratio\n",
    "        })\n",
    "\n",
    "ss_ratio_df = pd.DataFrame(ss_ratios).sort_values('ratio', ascending=False)\n",
    "print(ss_ratio_df.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52411730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save findings\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY OF KEY FINDINGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "findings = []\n",
    "\n",
    "# Top predictive patterns\n",
    "top_patterns = ratio_df.head(10)\n",
    "for _, row in top_patterns.iterrows():\n",
    "    findings.append(f\"Character n-gram '{row['ngram']}' has {row['success_ratio']:.3f} success ratio ({row['success']}/{row['total']} occurrences)\")\n",
    "\n",
    "# Specific insights about 'ss'\n",
    "ss_in_success = sum(1 for text in successful_sample if 'ss' in get_char_ngrams(text))\n",
    "ss_in_failed = sum(1 for text in failed_sample if 'ss' in get_char_ngrams(text))\n",
    "ss_ratio = ss_in_success / (ss_in_success + ss_in_failed) if (ss_in_success + ss_in_failed) > 0 else 0\n",
    "\n",
    "findings.append(f\"'ss' pattern appears in {ss_ratio:.3f} of successful vs failed requests\")\n",
    "findings.append(\"'ss' pattern likely captures words like 'bless', 'blessing', 'pizza', 'pass', 'blessed'\")\n",
    "\n",
    "# Save to file\n",
    "with open('/home/code/analysis_findings_loop4.txt', 'w') as f:\n",
    "    f.write(\"LOOP 4 ANALYSIS FINDINGS\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    for i, finding in enumerate(findings, 1):\n",
    "        f.write(f\"{i}. {finding}\\n\")\n",
    "\n",
    "print(\"\\nKey findings saved to analysis_findings_loop4.txt\")\n",
    "for i, finding in enumerate(findings, 1):\n",
    "    print(f\"{i}. {finding}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
