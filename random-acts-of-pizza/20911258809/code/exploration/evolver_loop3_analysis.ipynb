{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47024c8",
   "metadata": {},
   "source": [
    "# Evolver Loop 3: Analysis of exp_003 Results\n",
    "\n",
    "## Goal\n",
    "Analyze the successful TF-IDF fixes from exp_003 and identify next steps to reach gold threshold (0.979080).\n",
    "\n",
    "Current best: 0.6555 AUC (exp_003)\n",
    "Gold threshold: 0.979080\n",
    "Gap: 0.3236 points\n",
    "\n",
    "## Key Findings from exp_003\n",
    "- Character n-grams dominate feature importance (4 of top 10 features)\n",
    "- Feature selection worked: 3,000 features better than 10,000\n",
    "- Removed stop words to keep domain vocabulary\n",
    "- CV improved from 0.6217 → 0.6555 (+0.0338)\n",
    "- Low variance (±0.0104) indicates stable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da6ebb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T12:39:51.991399Z",
     "iopub.status.busy": "2026-01-12T12:39:51.990797Z",
     "iopub.status.idle": "2026-01-12T12:39:53.707226Z",
     "shell.execute_reply": "2026-01-12T12:39:53.706508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train: 2878 samples, 715 positive (0.248)\n",
      "Test: 1162 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "train = pd.DataFrame(train_data)\n",
    "test = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"Train: {len(train)} samples, {sum(train['requester_received_pizza'])} positive ({sum(train['requester_received_pizza'])/len(train):.3f})\")\n",
    "print(f\"Test: {len(test)} samples\")\n",
    "\n",
    "# Extract text\n",
    "y = train['requester_received_pizza'].values\n",
    "text_train = train['request_text_edit_aware'].fillna('').str.lower()\n",
    "text_test = test['request_text_edit_aware'].fillna('').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3331f0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T12:39:53.709820Z",
     "iopub.status.busy": "2026-01-12T12:39:53.709171Z",
     "iopub.status.idle": "2026-01-12T12:39:56.972204Z",
     "shell.execute_reply": "2026-01-12T12:39:56.971372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting character n-gram vectorizer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character n-grams shape: (2878, 2000)\n",
      "Top 20 character n-grams:\n",
      "   1.  a \n",
      "   2.  a b\n",
      "   3.  a c\n",
      "   4.  a f\n",
      "   5.  a l\n",
      "   6.  a n\n",
      "   7.  a p\n",
      "   8.  a pi\n",
      "   9.  a r\n",
      "  10.  a s\n",
      "  11.  a w\n",
      "  12.  ab\n",
      "  13.  abo\n",
      "  14.  abou\n",
      "  15.  ac\n",
      "  16.  acc\n",
      "  17.  af\n",
      "  18.  aft\n",
      "  19.  afte\n",
      "  20.  ag\n",
      "\n",
      "================================================================================\n",
      "ANALYZING TOP CHARACTER N-GRAMS\n",
      "================================================================================\n",
      "\n",
      " 1. ' a '\n",
      "   In SUCCESSFUL requests:\n",
      "      - ...i will go ahead and say that i got a pizza meal from here before as to not seem like i'...\n",
      "      - ...zalodad and myself would love to have a pizza with our kids tonight! my husband lost his j...\n",
      "   In FAILED requests:\n",
      "      - ...i will soon be going on a long deployment which i'm not aloud to discuss but...\n",
      "      - ...ould all really appreciate it, and would even send a picture of the three of us enjoying the said pizza...\n",
      "   Frequency: 616/715 (0.862) in successes\n",
      "   Frequency: 1693/2163 (0.783) in failures\n",
      "\n",
      " 2. ' a b'\n",
      "   In SUCCESSFUL requests:\n",
      "      - ...ing until they call me in for that expendable job, a background check for one, and a test request for th...\n",
      "      - ...uld be much appreciated.   hope you all are having a better day then mine! thanks ...\n",
      "   In FAILED requests:\n",
      "      - ...self. if there's someone out there looking to help a broke student out, let me know!...\n",
      "      - ...okay , title was a bit dramatic.  but he is really sick.  he's been sn...\n",
      "   Frequency: 102/715 (0.143) in successes\n",
      "   Frequency: 284/2163 (0.131) in failures\n",
      "\n",
      " 3. ' a c'\n",
      "   In SUCCESSFUL requests:\n",
      "      - ...i don't get paid till next week. plus we have only a couple of dollars for gas and hardly anything in th...\n",
      "      - ...friend; my parents dropped off the bag of potatoes a couple of weeks ago. i don't wanna complain or anyt...\n",
      "   In FAILED requests:\n",
      "      - ...izza from dominoes or something. i am starving and a college student please help!...\n",
      "      - ...me a pizza it'll make a huge difference. i'll have a couple of slices now and the rest should tide me ov...\n",
      "   Frequency: 127/715 (0.178) in successes\n",
      "   Frequency: 283/2163 (0.131) in failures\n",
      "\n",
      " 4. ' a f'\n",
      "   In SUCCESSFUL requests:\n",
      "      - ...whine or drag on. basically, i've been jobless for a few months now. my sister is my roommate; i'm basic...\n",
      "      - ... willing to spring for a pizza which would last me a few days, i would be entirely grateful!...\n",
      "   In FAILED requests:\n",
      "      - ... pm me or write on this post in response to get me a free pizza from dominoes or something. i am starvin...\n",
      "      - ...could have a slice tonight and lunch and meals for a few days.  i'd greatly appreciate it and you have m...\n",
      "   Frequency: 129/715 (0.180) in successes\n",
      "   Frequency: 309/2163 (0.143) in failures\n",
      "\n",
      " 5. ' a l'\n",
      "   In SUCCESSFUL requests:\n",
      "      - ...i know a hard drive sounds like a luxury but i do online classes and there's no way i...\n",
      "      - ...g woman living with my longtime boyfriend and like a lot of people, times are tough. i had a temporary l...\n",
      "   In FAILED requests:\n",
      "      - ...i will soon be going on a long deployment which i'm not aloud to discuss but ...\n",
      "      - ...it took a lot of courage to make this post, and it's very had...\n",
      "   Frequency: 117/715 (0.164) in successes\n",
      "   Frequency: 332/2163 (0.153) in failures\n",
      "\n",
      " 6. ' a n'\n",
      "   In SUCCESSFUL requests:\n",
      "      - ...r over a month, and have actively been looking for a new job to no avail, and well, as such i dont have ...\n",
      "      - ...d's house. i lost my job and have been looking for a new one for about a month and a half now, so far, t...\n",
      "   In FAILED requests:\n",
      "      - ...u do, send me your e-mail so we can chat and share a nice time...we can both eat pizza at the same time...\n",
      "      - ...t 12 months until his mom's out of school and into a new job) so he's been eating jello  , and the chick...\n",
      "   Frequency: 87/715 (0.122) in successes\n",
      "   Frequency: 191/2163 (0.088) in failures\n",
      "\n",
      " 7. ' a p'\n",
      "   In SUCCESSFUL requests:\n",
      "      - ...i will go ahead and say that i got a pizza meal from here before as to not seem like i'm...\n",
      "      - ...zalodad and myself would love to have a pizza with our kids tonight! my husband lost his jo...\n",
      "   In FAILED requests:\n",
      "      - ...ould all really appreciate it, and would even send a picture of the three of us enjoying the said pizza ...\n",
      "      - ... so appreciate it if someone can provide them with a pizza. i am in atlanta, ga. they are in southern fl...\n",
      "   Frequency: 309/715 (0.432) in successes\n",
      "   Frequency: 830/2163 (0.384) in failures\n",
      "\n",
      " 8. ' a pi'\n",
      "   In SUCCESSFUL requests:\n",
      "      - ...i will go ahead and say that i got a pizza meal from here before as to not seem like i'm ...\n",
      "      - ...zalodad and myself would love to have a pizza with our kids tonight! my husband lost his job...\n",
      "   In FAILED requests:\n",
      "      - ...ould all really appreciate it, and would even send a picture of the three of us enjoying the said pizza (...\n",
      "      - ... so appreciate it if someone can provide them with a pizza. i am in atlanta, ga. they are in southern fl....\n",
      "   Frequency: 266/715 (0.372) in successes\n",
      "   Frequency: 702/2163 (0.325) in failures\n",
      "\n",
      " 9. ' a r'\n",
      "   In SUCCESSFUL requests:\n",
      "      - ...while, but always decided against actually posting a request because there are people in so much worse s...\n",
      "      - ...ng a college student, i'm also tight on money - so a random pizza would be awesome. :)  i'm not sure wha...\n",
      "   In FAILED requests:\n",
      "      - ...we live. i send home what i can for family. i rent a room so what i send my family is enough to pay the ...\n",
      "      - ...is week i'll put in a post to pay it back.  i have a real reddit name of over 2 years this is just a thr...\n",
      "   Frequency: 94/715 (0.131) in successes\n",
      "   Frequency: 196/2163 (0.091) in failures\n",
      "\n",
      "10. ' a s'\n",
      "   In SUCCESSFUL requests:\n",
      "      - ... wage + .40 to fill in the gaps of unemployment of a second job, if that makes sense, but i'm waiting un...\n",
      "      - ...if anyone has a $5 gc to dominos i could get a small pizza. in return i could put on my best santa...\n",
      "   In FAILED requests:\n",
      "      - ...room for luxuries like pizza. my family would love a special treat and i would so appreciate it if someo...\n",
      "      - ...meone nice enough to send me a pizza, i could have a slice tonight and lunch and meals for a few days.  ...\n",
      "   Frequency: 131/715 (0.183) in successes\n",
      "   Frequency: 329/2163 (0.152) in failures\n"
     ]
    }
   ],
   "source": [
    "# Analyze character n-gram patterns from exp_003\n",
    "# We need to understand what the top character n-grams represent\n",
    "\n",
    "# Recreate the char n-gram vectorizer used in exp_003\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer='char',\n",
    "    ngram_range=(3, 5),\n",
    "    max_features=2000,\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "print(\"Fitting character n-gram vectorizer...\")\n",
    "X_char_train = char_vectorizer.fit_transform(text_train)\n",
    "X_char_test = char_vectorizer.transform(text_test)\n",
    "\n",
    "char_feature_names = char_vectorizer.get_feature_names_out()\n",
    "print(f\"Character n-grams shape: {X_char_train.shape}\")\n",
    "print(f\"Top 20 character n-grams:\")\n",
    "for i, name in enumerate(char_feature_names[:20]):\n",
    "    print(f\"  {i+1:2d}. {name}\")\n",
    "\n",
    "# Let's see what these n-grams actually correspond to in the text\n",
    "# by finding examples where they appear\n",
    "\n",
    "def find_ngram_examples(text_series, ngram, n_examples=3):\n",
    "    \"\"\"Find examples of texts containing a specific n-gram\"\"\"\n",
    "    examples = []\n",
    "    for idx, text in enumerate(text_series):\n",
    "        if ngram in text:\n",
    "            # Find the context around the n-gram\n",
    "            pos = text.find(ngram)\n",
    "            start = max(0, pos - 50)\n",
    "            end = min(len(text), pos + len(ngram) + 50)\n",
    "            context = text[start:end].replace('\\n', ' ')\n",
    "            examples.append(context)\n",
    "            if len(examples) >= n_examples:\n",
    "                break\n",
    "    return examples\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING TOP CHARACTER N-GRAMS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analyze the top 10 character n-grams\n",
    "for i in range(min(10, len(char_feature_names))):\n",
    "    ngram = char_feature_names[i]\n",
    "    print(f\"\\n{i+1:2d}. '{ngram}'\")\n",
    "    \n",
    "    # Find examples in successful and failed requests\n",
    "    success_examples = find_ngram_examples(\n",
    "        text_train[y == 1], ngram, n_examples=2\n",
    "    )\n",
    "    fail_examples = find_ngram_examples(\n",
    "        text_train[y == 0], ngram, n_examples=2\n",
    "    )\n",
    "    \n",
    "    if success_examples:\n",
    "        print(f\"   In SUCCESSFUL requests:\")\n",
    "        for ex in success_examples:\n",
    "            print(f\"      - ...{ex}...\")\n",
    "    \n",
    "    if fail_examples:\n",
    "        print(f\"   In FAILED requests:\")\n",
    "        for ex in fail_examples:\n",
    "            print(f\"      - ...{ex}...\")\n",
    "    \n",
    "    # Count frequency\n",
    "    success_count = sum(text_train[y == 1].str.contains(ngram, na=False))\n",
    "    fail_count = sum(text_train[y == 0].str.contains(ngram, na=False))\n",
    "    success_rate = success_count / len(text_train[y == 1]) if len(text_train[y == 1]) > 0 else 0\n",
    "    fail_rate = fail_count / len(text_train[y == 0]) if len(text_train[y == 0]) > 0 else 0\n",
    "    \n",
    "    print(f\"   Frequency: {success_count}/{len(text_train[y == 1])} ({success_rate:.3f}) in successes\")\n",
    "    print(f\"   Frequency: {fail_count}/{len(text_train[y == 0])} ({fail_rate:.3f}) in failures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e29bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's analyze what these character n-grams actually represent\n",
    "# The top features in exp_003 were: char_ss, char_f a, char_e a, char_thi, char_ere\n",
    "\n",
    "# Let's look for these specific patterns\n",
    "key_patterns = ['ss', 'f a', 'e a', 'thi', 'ere', ' a ', ' a p', ' a pi']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DEEP DIVE: KEY CHARACTER PATTERNS FROM exp_003\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for pattern in key_patterns:\n",
    "    print(f\"\\nPattern: '{pattern}'\")\n",
    "    \n",
    "    # Find examples\n",
    "    success_examples = find_ngram_examples(text_train[y == 1], pattern, n_examples=3)\n",
    "    fail_examples = find_ngram_examples(text_train[y == 0], pattern, n_examples=3)\n",
    "    \n",
    "    # Count frequency\n",
    "    success_count = sum(text_train[y == 1].str.contains(pattern, na=False))\n",
    "    fail_count = sum(text_train[y == 0].str.contains(pattern, na=False))\n",
    "    total_success = len(text_train[y == 1])\n",
    "    total_fail = len(text_train[y == 0])\n",
    "    \n",
    "    success_rate = success_count / total_success\n",
    "    fail_rate = fail_count / total_fail\n",
    "    \n",
    "    print(f\"  Frequency in successes: {success_count}/{total_success} ({success_rate:.3f})\")\n",
    "    print(f\"  Frequency in failures: {fail_count}/{total_fail} ({fail_rate:.3f})\")\n",
    "    print(f\"  Ratio (success/fail): {success_rate/fail_rate:.3f}\")\n",
    "    \n",
    "    # Show examples\n",
    "    if success_examples:\n",
    "        print(f\"  Examples in SUCCESSFUL requests:\")\n",
    "        for ex in success_examples[:2]:\n",
    "            print(f\"    - ...{ex}...\")\n",
    "    \n",
    "    if fail_examples:\n",
    "        print(f\"  Examples in FAILED requests:\")\n",
    "        for ex in fail_examples[:2]:\n",
    "            print(f\"    - ...{ex}...\")\n",
    "    \n",
    "    # What words contain this pattern?\n",
    "    # Extract all words containing this pattern from successful requests\n",
    "    success_words = Counter()\n",
    "    for text in text_train[y == 1]:\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            if pattern in word:\n",
    "                success_words[word] += 1\n",
    "    \n",
    "    if success_words:\n",
    "        print(f\"  Common words with '{pattern}' in successes:\")\n",
    "        for word, count in success_words.most_common(5):\n",
    "            print(f\"    - '{word}' (x{count})\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
