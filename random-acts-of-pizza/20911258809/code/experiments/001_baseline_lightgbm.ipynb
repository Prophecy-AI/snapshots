{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1732849d",
   "metadata": {},
   "source": [
    "# Baseline Model: LightGBM with TF-IDF Features\n",
    "\n",
    "This notebook implements a baseline model using LightGBM with basic feature engineering:\n",
    "- TF-IDF on merged text fields\n",
    "- Metadata feature processing\n",
    "- Stratified K-fold validation\n",
    "- Class imbalance handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce280820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T20:44:19.517757Z",
     "iopub.status.busy": "2026-01-12T20:44:19.517163Z",
     "iopub.status.idle": "2026-01-12T20:44:20.996360Z",
     "shell.execute_reply": "2026-01-12T20:44:20.995569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train shape: (2878, 32)\n",
      "Test shape: (1162, 17)\n",
      "Target distribution: {False: 2163, True: 715}\n",
      "Success rate: 0.248\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Target distribution: {train_df['requester_received_pizza'].value_counts().to_dict()}\")\n",
    "print(f\"Success rate: {train_df['requester_received_pizza'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf90d18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T20:46:36.736195Z",
     "iopub.status.busy": "2026-01-12T20:46:36.735574Z",
     "iopub.status.idle": "2026-01-12T20:46:37.437769Z",
     "shell.execute_reply": "2026-01-12T20:46:37.436890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Engineering features...\n",
      "Creating TF-IDF features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (2878, 10000)\n",
      "No flair feature found, skipping...\n",
      "Metadata shape: (2878, 9)\n",
      "Final feature matrix shape: (2878, 10009)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "print(\"\\nEngineering features...\")\n",
    "\n",
    "# Text features: merge title and text\n",
    "train_df['combined_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text_edit_aware'].fillna('')\n",
    "test_df['combined_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text_edit_aware'].fillna('')\n",
    "\n",
    "# Create TF-IDF features\n",
    "print(\"Creating TF-IDF features...\")\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "tfidf_features_train = tfidf.fit_transform(train_df['combined_text'])\n",
    "tfidf_features_test = tfidf.transform(test_df['combined_text'])\n",
    "\n",
    "print(f\"TF-IDF shape: {tfidf_features_train.shape}\")\n",
    "\n",
    "# Metadata features (only those available at request time)\n",
    "metadata_features = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request'\n",
    "]\n",
    "\n",
    "# Process metadata features\n",
    "meta_train = train_df[metadata_features].copy()\n",
    "meta_test = test_df[metadata_features].copy()\n",
    "\n",
    "# Handle missing values and log transform skewed features\n",
    "for col in metadata_features:\n",
    "    # Fill missing values with median\n",
    "    median_val = meta_train[col].median()\n",
    "    meta_train[col].fillna(median_val, inplace=True)\n",
    "    meta_test[col].fillna(median_val, inplace=True)\n",
    "    \n",
    "    # Log transform highly skewed features\n",
    "    if meta_train[col].skew() > 2:\n",
    "        meta_train[col] = np.log1p(meta_train[col])\n",
    "        meta_test[col] = np.log1p(meta_test[col])\n",
    "\n",
    "# One-hot encode requester_user_flair if it exists\n",
    "if 'requester_user_flair' in train_df.columns and 'requester_user_flair' in test_df.columns:\n",
    "    flair_train = pd.get_dummies(train_df['requester_user_flair'], prefix='flair')\n",
    "    flair_test = pd.get_dummies(test_df['requester_user_flair'], prefix='flair')\n",
    "    \n",
    "    # Align flair columns (test might not have all categories)\n",
    "    for col in flair_train.columns:\n",
    "        if col not in flair_test.columns:\n",
    "            flair_test[col] = 0\n",
    "    for col in flair_test.columns:\n",
    "        if col not in flair_train.columns:\n",
    "            flair_train[col] = 0\n",
    "    \n",
    "    # Ensure same column order\n",
    "    flair_test = flair_test[flair_train.columns]\n",
    "    \n",
    "    print(f\"Flair shape: {flair_train.shape}\")\n",
    "else:\n",
    "    # Create dummy features if flair doesn't exist\n",
    "    flair_train = pd.DataFrame(index=train_df.index)\n",
    "    flair_test = pd.DataFrame(index=test_df.index)\n",
    "    print(\"No flair feature found, skipping...\")\n",
    "\n",
    "print(f\"Metadata shape: {meta_train.shape}\")\n",
    "\n",
    "# Combine all features\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train = hstack([tfidf_features_train, meta_train.values, flair_train.values])\n",
    "X_test = hstack([tfidf_features_test, meta_test.values, flair_test.values])\n",
    "\n",
    "y_train = train_df['requester_received_pizza'].values\n",
    "\n",
    "print(f\"Final feature matrix shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1170b4c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T20:48:57.099336Z",
     "iopub.status.busy": "2026-01-12T20:48:57.098537Z",
     "iopub.status.idle": "2026-01-12T20:48:59.519237Z",
     "shell.execute_reply": "2026-01-12T20:48:59.518352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with Stratified K-Fold...\n",
      "\n",
      "Fold 1/5\n",
      "[LightGBM] [Info] Number of positive: 572, number of negative: 1730\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22354\n",
      "[LightGBM] [Info] Number of data points in the train set: 2302, number of used features: 846\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.248480 -> initscore=-1.106738\n",
      "[LightGBM] [Info] Start training from score -1.106738\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.62971\tvalid_0's binary_logloss: 0.553298\n",
      "Fold 1 AUC: 0.6297\n",
      "\n",
      "Fold 2/5\n",
      "[LightGBM] [Info] Number of positive: 572, number of negative: 1730\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22157\n",
      "[LightGBM] [Info] Number of data points in the train set: 2302, number of used features: 833\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.248480 -> initscore=-1.106738\n",
      "[LightGBM] [Info] Start training from score -1.106738\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.524322\tvalid_0's binary_logloss: 0.560253\n",
      "Fold 2 AUC: 0.5243\n",
      "\n",
      "Fold 3/5\n",
      "[LightGBM] [Info] Number of positive: 572, number of negative: 1730\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22425\n",
      "[LightGBM] [Info] Number of data points in the train set: 2302, number of used features: 848\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.248480 -> initscore=-1.106738\n",
      "[LightGBM] [Info] Start training from score -1.106738\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.593259\tvalid_0's binary_logloss: 0.556542\n",
      "Fold 3 AUC: 0.5933\n",
      "\n",
      "Fold 4/5\n",
      "[LightGBM] [Info] Number of positive: 572, number of negative: 1731\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22353\n",
      "[LightGBM] [Info] Number of data points in the train set: 2303, number of used features: 838\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.248372 -> initscore=-1.107316\n",
      "[LightGBM] [Info] Start training from score -1.107316\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.569582\tvalid_0's binary_logloss: 0.558515\n",
      "Fold 4 AUC: 0.5696\n",
      "\n",
      "Fold 5/5\n",
      "[LightGBM] [Info] Number of positive: 572, number of negative: 1731\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22307\n",
      "[LightGBM] [Info] Number of data points in the train set: 2303, number of used features: 849\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.248372 -> initscore=-1.107316\n",
      "[LightGBM] [Info] Start training from score -1.107316\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.634356\tvalid_0's binary_logloss: 0.552978\n",
      "Fold 5 AUC: 0.6344\n",
      "\n",
      "==================================================\n",
      "Mean AUC: 0.5902 ± 0.0407\n",
      "OOF AUC: 0.5827\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Model Training with Stratified K-Fold\n",
    "print(\"\\nTraining model with Stratified K-Fold...\")\n",
    "\n",
    "# Convert sparse matrices to CSR format for efficient indexing\n",
    "from scipy.sparse import csr_matrix\n",
    "X_train_csr = X_train.tocsr()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "auc_scores = []\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "test_predictions = np.zeros(len(test_df))\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in skf.split(X_train_csr, y_train):\n",
    "    print(f\"\\nFold {fold}/5\")\n",
    "    \n",
    "    X_tr = X_train_csr[train_idx]\n",
    "    X_val = X_train_csr[val_idx]\n",
    "    y_tr = y_train[train_idx]\n",
    "    y_val = y_train[val_idx]\n",
    "    \n",
    "    # Calculate scale_pos_weight for handling class imbalance\n",
    "    neg_count = (y_tr == 0).sum()\n",
    "    pos_count = (y_tr == 1).sum()\n",
    "    scale_pos_weight = neg_count / pos_count\n",
    "    \n",
    "    # Train LightGBM\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    test_pred = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_val, val_pred)\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"Fold {fold} AUC: {auc:.4f}\")\n",
    "    \n",
    "    # Store OOF predictions\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    test_predictions += test_pred / 5\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Mean AUC: {np.mean(auc_scores):.4f} ± {np.std(auc_scores):.4f}\")\n",
    "print(f\"OOF AUC: {roc_auc_score(y_train, oof_predictions):.4f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8a9bfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T20:49:22.309487Z",
     "iopub.status.busy": "2026-01-12T20:49:22.308751Z",
     "iopub.status.idle": "2026-01-12T20:49:22.332968Z",
     "shell.execute_reply": "2026-01-12T20:49:22.332154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating submission file...\n",
      "Submission shape: (1162, 2)\n",
      "Submission columns: ['request_id', 'requester_received_pizza']\n",
      "Sample predictions: [0.26907746 0.26704352 0.26075883 0.30887097 0.27959236]\n",
      "Submission saved to /home/submission/submission.csv\n",
      "OOF predictions saved to /home/submission/oof_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Create submission file\n",
    "print(\"\\nCreating submission file...\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "# Ensure submission format matches sample\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"Submission columns: {submission.columns.tolist()}\")\n",
    "print(f\"Sample predictions: {test_predictions[:5]}\")\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(\"Submission saved to /home/submission/submission.csv\")\n",
    "\n",
    "# Also save OOF predictions for potential stacking\n",
    "pd.DataFrame({\n",
    "    'request_id': train_df['request_id'],\n",
    "    'oof_prediction': oof_predictions,\n",
    "    'target': y_train\n",
    "}).to_csv('/home/submission/oof_predictions.csv', index=False)\n",
    "print(\"OOF predictions saved to /home/submission/oof_predictions.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
