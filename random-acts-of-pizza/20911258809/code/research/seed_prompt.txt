## Current Status
- Best CV: 0.6433 from exp_000 (001_baseline_lgbm)
- Target: 0.979080 (33.6 point gap)
- Gap is too large for incremental improvements - requires fundamental strategy change

## Response to Evaluator
- **Technical verdict was TRUSTWORTHY**. Execution is sound, but strategy is fundamentally mismatched to the problem.
- **Evaluator's top priority: Implement TF-IDF n-gram features**. I completely agree - this is non-negotiable. The research is explicit that winners use n-grams, and our data findings show strong correlations (imgur links r=0.095, reciprocity words r=0.108, hardship words r=0.102) that we're not exploiting.
- **Key concerns raised**:
  - *"Problem is about TEXT, but approach focuses on metadata"* → Absolutely correct. Need to pivot to text-centric modeling
  - *"Zero n-gram or TF-IDF features"* → Critical gap. Must implement immediately
  - *"No analysis of WHAT people write"* → Need psycholinguistic features (LIWC-style categories)
  - *"Class imbalance not explicitly addressed"* → Will ensure scale_pos_weight=3.025 is used

## Data Understanding
- **Reference notebooks**: See `exploration/evolver_loop1_analysis.ipynb` for TF-IDF correlation analysis and `exploration/evolver_loop2_analysis.ipynb` for baseline establishment
- **Key patterns to exploit**:
  - **TF-IDF n-grams**: 'imgur' links (r=0.095), 'ask help' (r=0.073), 'dominos' (r=0.066), family words ('father' r=0.066, 'daughter' r=0.064)
  - **Psycholinguistic categories**: Reciprocity words (r=0.108), hardship words (r=0.102), family words (r=0.090), gratitude words (r=0.081)
  - **Successful requests use**: 24% more reciprocity language, 21% more hardship mentions
  - **Sentiment is weak**: r=-0.008, not predictive

## Recommended Approaches (Priority Order)

### 1. Implement TF-IDF N-gram Features (HIGHEST PRIORITY)
- **Why**: Research explicitly states this is what winners do. Data shows strong correlations we're not using.
- **What**: 
  - Use `TfidfVectorizer` on `request_text_edit_aware` (leakage-free version)
  - Configure: `ngram_range=(1,3)`, `max_features=10000`, `min_df=2`, `max_df=0.9`, `sublinear_tf=True`
  - Also try character n-grams: `analyzer='char'`, `ngram_range=(3,5)` for capturing patterns like 'pizza', 'please'
- **Combine with metadata**: Use `scipy.sparse.hstack([X_tfidf, X_meta])` as per research
- **Model**: Test both LightGBM (handles sparse) and Logistic Regression (linear baseline)

### 2. Add Psycholinguistic Word Categories
- **Why**: Data findings show strong predictive power (reciprocity r=0.108, hardship r=0.102)
- **What**: Create features counting words in specific categories:
  - **Reciprocity**: 'offer', 'pay', 'return', 'favor', 'back', 'help', 'kindness', 'generous'
  - **Hardship**: 'struggle', 'broke', 'bills', 'unemployed', 'hungry', 'hard', 'difficult', 'tough'
  - **Family**: 'family', 'kids', 'children', 'mother', 'father', 'daughter', 'son', 'wife', 'husband'
  - **Gratitude**: 'thank', 'appreciate', 'grateful', 'bless', 'kind', 'generous'
  - **Food-specific**: 'pizza', 'hungry', 'food', 'meal', 'eat', 'starving', 'dinner', 'lunch'
- **How**: Simple regex counting, normalized by text length

### 3. Test Linear vs Tree-based Models on Combined Features
- **Why**: Research shows linear models work well on TF-IDF + metadata
- **What**:
  - **Logistic Regression**: `class_weight='balanced'`, `C=1.0`, `max_iter=1000`
  - **LightGBM**: `scale_pos_weight=3.025`, handle sparse features efficiently
  - **Compare**: Which model type works better for this specific feature combination?

### 4. Ensure Proper Class Imbalance Handling
- **Why**: 75.16% negative, 24.84% positive (3:1 ratio)
- **What**: 
  - Use `scale_pos_weight=3.025` for LightGBM
  - Use `class_weight='balanced'` for Logistic Regression
  - Verify both approaches give similar results

### 5. Analyze Predictive Words/Phrases
- **Why**: Understanding what works helps refine features
- **What**: After training, extract feature importances:
  - For Logistic Regression: highest positive/negative coefficients
  - For LightGBM: feature importance plots
  - Focus on top TF-IDF terms and psycholinguistic categories

## What NOT to Try
- **More complex metadata features**: Already have basic metadata, text features are the priority
- **Hyperparameter tuning**: Don't waste time on tuning until we have proper text features (current gap is 33.6 points, not 3 points)
- **Neural networks/LLMs**: Too complex for now. Start with proven Kaggle winners' approach (TF-IDF + linear/tree models)
- **Advanced ensembling**: Need better base models first. Current 0.6433 AUC is too low for ensembling to help

## Validation Notes
- **CV scheme**: 5-fold stratified CV (same as baseline)
- **Leakage prevention**: Use only `request_text_edit_aware` (not `request_text`), only "at_request" timestamps
- **Confidence**: High confidence in approach - research is explicit and data findings support it
- **Expected improvement**: Should see significant jump from 0.6433 AUC. If not, re-examine TF-IDF implementation or try different n-gram ranges

## Success Criteria
- Next experiment should achieve >0.75 AUC (significant improvement from text features)
- TF-IDF features should dominate feature importance
- Psycholinguistic categories should show measurable impact