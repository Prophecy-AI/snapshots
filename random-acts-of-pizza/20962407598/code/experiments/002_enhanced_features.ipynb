{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6508860",
   "metadata": {},
   "source": [
    "# Enhanced Features Experiment\n",
    "\n",
    "Based on EDA findings:\n",
    "- Text length matters (0.1199 correlation)\n",
    "- Interaction features stronger than raw features\n",
    "- Temporal patterns exist\n",
    "- High variance suggests need for robust features\n",
    "\n",
    "Improvements:\n",
    "1. Enhanced TF-IDF (n-grams, more features)\n",
    "2. Better interaction features\n",
    "3. Class weighting for imbalance\n",
    "4. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32fc7feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:33:05.211078Z",
     "iopub.status.busy": "2026-01-13T17:33:05.210396Z",
     "iopub.status.idle": "2026-01-13T17:33:05.383803Z",
     "shell.execute_reply": "2026-01-13T17:33:05.383246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train: 2878, Test: 1162\n",
      "Target distribution: {False: 0.7515635858234886, True: 0.24843641417651147}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")\n",
    "print(f\"Target distribution: {train_df['requester_received_pizza'].value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a91df600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:33:05.385939Z",
     "iopub.status.busy": "2026-01-13T17:33:05.385425Z",
     "iopub.status.idle": "2026-01-13T17:33:05.504079Z",
     "shell.execute_reply": "2026-01-13T17:33:05.503566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating enhanced text features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text features created: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc', 'text_length', 'word_count', 'title_length', 'title_word_count', 'avg_word_length', 'has_please', 'has_help', 'has_appreciate', 'has_grateful', 'has_thank', 'has_thanks', 'has_kind', 'has_generous', 'has_need', 'exclamation_count', 'question_count']\n"
     ]
    }
   ],
   "source": [
    "# Enhanced text features\n",
    "print(\"Creating enhanced text features...\")\n",
    "\n",
    "# Text length features (from EDA - high correlation)\n",
    "train_df['text_length'] = train_df['request_text_edit_aware'].str.len()\n",
    "test_df['text_length'] = test_df['request_text_edit_aware'].str.len()\n",
    "train_df['word_count'] = train_df['request_text_edit_aware'].str.split().str.len()\n",
    "test_df['word_count'] = test_df['request_text_edit_aware'].str.split().str.len()\n",
    "train_df['title_length'] = train_df['request_title'].str.len()\n",
    "test_df['title_length'] = test_df['request_title'].str.len()\n",
    "train_df['title_word_count'] = train_df['request_title'].str.split().str.len()\n",
    "test_df['title_word_count'] = test_df['request_title'].str.split().str.len()\n",
    "\n",
    "# Readability and language features\n",
    "train_df['avg_word_length'] = train_df['text_length'] / (train_df['word_count'] + 1)\n",
    "test_df['avg_word_length'] = test_df['text_length'] / (test_df['word_count'] + 1)\n",
    "\n",
    "# Persuasion language (from EDA - \"been\" is important)\n",
    "persuasion_words = ['please', 'help', 'appreciate', 'grateful', 'thank', 'thanks', 'kind', 'generous', 'need']\n",
    "for word in persuasion_words:\n",
    "    train_df[f'has_{word}'] = train_df['request_text_edit_aware'].str.lower().str.contains(word).astype(int)\n",
    "    test_df[f'has_{word}'] = test_df['request_text_edit_aware'].str.lower().str.contains(word).astype(int)\n",
    "\n",
    "# Punctuation patterns\n",
    "train_df['exclamation_count'] = train_df['request_text_edit_aware'].str.count('!')\n",
    "test_df['exclamation_count'] = test_df['request_text_edit_aware'].str.count('!')\n",
    "train_df['question_count'] = train_df['request_text_edit_aware'].str.count('\\?')\n",
    "test_df['question_count'] = test_df['request_text_edit_aware'].str.count('\\?')\n",
    "\n",
    "print(f\"Text features created: {[col for col in train_df.columns if col not in ['request_text_edit_aware', 'request_title', 'requester_received_pizza']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e09fa97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:33:05.506019Z",
     "iopub.status.busy": "2026-01-13T17:33:05.505516Z",
     "iopub.status.idle": "2026-01-13T17:33:05.528224Z",
     "shell.execute_reply": "2026-01-13T17:33:05.527755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating enhanced interaction features...\n",
      "Interaction features created\n"
     ]
    }
   ],
   "source": [
    "# Enhanced interaction features (from EDA - stronger than raw features)\n",
    "print(\"Creating enhanced interaction features...\")\n",
    "\n",
    "# User credibility score (from EDA insight)\n",
    "train_df['user_credibility'] = (train_df['requester_upvotes_plus_downvotes_at_request']) / (train_df['requester_account_age_in_days_at_request'] + 1)\n",
    "test_df['user_credibility'] = (test_df['requester_upvotes_plus_downvotes_at_request']) / (test_df['requester_account_age_in_days_at_request'] + 1)\n",
    "\n",
    "# Engagement ratio (from EDA)\n",
    "train_df['comments_per_post'] = train_df['requester_number_of_comments_at_request'] / (train_df['requester_number_of_posts_at_request'] + 1)\n",
    "test_df['comments_per_post'] = test_df['requester_number_of_comments_at_request'] / (test_df['requester_number_of_posts_at_request'] + 1)\n",
    "\n",
    "# Upvote ratio (from EDA - 0.0953 correlation)\n",
    "train_df['upvote_ratio'] = train_df['requester_upvotes_minus_downvotes_at_request'] / (train_df['requester_upvotes_plus_downvotes_at_request'] + 1)\n",
    "test_df['upvote_ratio'] = test_df['requester_upvotes_minus_downvotes_at_request'] / (test_df['requester_upvotes_plus_downvotes_at_request'] + 1)\n",
    "\n",
    "# Subreddit diversity\n",
    "train_df['subreddit_diversity'] = train_df['requester_number_of_subreddits_at_request'] / (train_df['requester_account_age_in_days_at_request'] + 1)\n",
    "test_df['subreddit_diversity'] = test_df['requester_number_of_subreddits_at_request'] / (test_df['requester_account_age_in_days_at_request'] + 1)\n",
    "\n",
    "# Request quality score\n",
    "train_df['request_quality'] = train_df['word_count'] * train_df['upvote_ratio']\n",
    "test_df['request_quality'] = test_df['word_count'] * test_df['upvote_ratio']\n",
    "\n",
    "# Temporal features (from EDA - hour 15 is best)\n",
    "train_df['request_hour'] = pd.to_datetime(train_df['unix_timestamp_of_request'], unit='s').dt.hour\n",
    "test_df['request_hour'] = pd.to_datetime(test_df['unix_timestamp_of_request'], unit='s').dt.hour\n",
    "train_df['request_day_of_week'] = pd.to_datetime(train_df['unix_timestamp_of_request'], unit='s').dt.dayofweek\n",
    "test_df['request_day_of_week'] = pd.to_datetime(test_df['unix_timestamp_of_request'], unit='s').dt.dayofweek\n",
    "\n",
    "# Hour interaction (hour 15 is best from EDA)\n",
    "train_df['is_hour_15'] = (train_df['request_hour'] == 15).astype(int)\n",
    "test_df['is_hour_15'] = (test_df['request_hour'] == 15).astype(int)\n",
    "\n",
    "print(f\"Interaction features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3e9e6ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:33:05.529851Z",
     "iopub.status.busy": "2026-01-13T17:33:05.529492Z",
     "iopub.status.idle": "2026-01-13T17:33:07.028018Z",
     "shell.execute_reply": "2026-01-13T17:33:07.027482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating enhanced TF-IDF features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (2878, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Enhanced TF-IDF features\n",
    "print(\"Creating enhanced TF-IDF features...\")\n",
    "\n",
    "# Combine title and text for better context\n",
    "combined_text_train = train_df['request_title'].fillna('') + ' ' + train_df['request_text_edit_aware'].fillna('')\n",
    "combined_text_test = test_df['request_title'].fillna('') + ' ' + test_df['request_text_edit_aware'].fillna('')\n",
    "\n",
    "# Enhanced TF-IDF with n-grams and more features\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,  # More features than baseline\n",
    "    ngram_range=(1, 3),  # Include phrases\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True,   # Better scaling\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "# Fit on combined train+test for consistency\n",
    "all_text = pd.concat([combined_text_train, combined_text_test])\n",
    "tfidf.fit(all_text)\n",
    "\n",
    "# Transform\n",
    "tfidf_train = tfidf.transform(combined_text_train)\n",
    "tfidf_test = tfidf.transform(combined_text_test)\n",
    "\n",
    "print(f\"TF-IDF shape: {tfidf_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0575732a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:33:07.030138Z",
     "iopub.status.busy": "2026-01-13T17:33:07.029733Z",
     "iopub.status.idle": "2026-01-13T17:33:07.040464Z",
     "shell.execute_reply": "2026-01-13T17:33:07.039970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing numerical features...\n",
      "Using 30 numerical features\n",
      "Numerical features shape: (2878, 30)\n"
     ]
    }
   ],
   "source": [
    "# Prepare numerical features\n",
    "print(\"Preparing numerical features...\")\n",
    "\n",
    "# Define feature groups\n",
    "base_features = [\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_account_age_in_days_at_request'\n",
    "]\n",
    "\n",
    "text_features = ['text_length', 'word_count', 'title_length', 'title_word_count', 'avg_word_length']\n",
    "persuasion_features = [f'has_{word}' for word in persuasion_words]\n",
    "punctuation_features = ['exclamation_count', 'question_count']\n",
    "interaction_features = [\n",
    "    'user_credibility', 'comments_per_post', 'upvote_ratio', 'subreddit_diversity', \n",
    "    'request_quality', 'request_hour', 'request_day_of_week', 'is_hour_15'\n",
    "]\n",
    "\n",
    "all_num_features = base_features + text_features + persuasion_features + punctuation_features + interaction_features\n",
    "\n",
    "# Select only features that exist\n",
    "available_features = [f for f in all_num_features if f in train_df.columns]\n",
    "print(f\"Using {len(available_features)} numerical features\")\n",
    "\n",
    "# Prepare data\n",
    "X_num_train = train_df[available_features].values\n",
    "X_num_test = test_df[available_features].values\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_num_train_scaled = scaler.fit_transform(X_num_train)\n",
    "X_num_test_scaled = scaler.transform(X_num_test)\n",
    "\n",
    "print(f\"Numerical features shape: {X_num_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a21648db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:33:07.041905Z",
     "iopub.status.busy": "2026-01-13T17:33:07.041750Z",
     "iopub.status.idle": "2026-01-13T17:33:07.051909Z",
     "shell.execute_reply": "2026-01-13T17:33:07.051462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining all features...\n",
      "Final training shape: (2878, 10030)\n",
      "Final test shape: (1162, 10030)\n"
     ]
    }
   ],
   "source": [
    "# Combine all features\n",
    "print(\"Combining all features...\")\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train_combined = hstack([tfidf_train, X_num_train_scaled])\n",
    "X_test_combined = hstack([tfidf_test, X_num_test_scaled])\n",
    "\n",
    "y = train_df['requester_received_pizza'].astype(int).values\n",
    "\n",
    "print(f\"Final training shape: {X_train_combined.shape}\")\n",
    "print(f\"Final test shape: {X_test_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eac301ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:33:07.053571Z",
     "iopub.status.busy": "2026-01-13T17:33:07.053199Z",
     "iopub.status.idle": "2026-01-13T17:33:07.065128Z",
     "shell.execute_reply": "2026-01-13T17:33:07.064653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining all features...\n",
      "Final training shape: (2878, 10030)\n",
      "Final test shape: (1162, 10030)\n"
     ]
    }
   ],
   "source": [
    "# Combine all features\n",
    "print(\"Combining all features...\")\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train_combined = hstack([tfidf_train, X_num_train_scaled])\n",
    "X_test_combined = hstack([tfidf_test, X_num_test_scaled])\n",
    "\n",
    "y = train_df['requester_received_pizza'].astype(int).values\n",
    "\n",
    "print(f\"Final training shape: {X_train_combined.shape}\")\n",
    "print(f\"Final test shape: {X_test_combined.shape}\")\n",
    "\n",
    "# Convert to csr format for better indexing\n",
    "X_train_combined = X_train_combined.tocsr()\n",
    "X_test_combined = X_test_combined.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b1feb09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:33:07.066604Z",
     "iopub.status.busy": "2026-01-13T17:33:07.066429Z",
     "iopub.status.idle": "2026-01-13T17:33:10.423360Z",
     "shell.execute_reply": "2026-01-13T17:33:10.422651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cross-validation...\n",
      "\n",
      "Fold 1/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[9]\tvalid's auc: 0.645408\n",
      "Fold 1 AUC: 0.6454\n",
      "\n",
      "Fold 2/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[109]\tvalid's auc: 0.603337\n",
      "Fold 2 AUC: 0.6033\n",
      "\n",
      "Fold 3/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid's auc: 0.646538\n",
      "Fold 3 AUC: 0.6465\n",
      "\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[140]\tvalid's auc: 0.60394\n",
      "Fold 4 AUC: 0.6039\n",
      "\n",
      "Fold 5/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid's auc: 0.615984\n",
      "Fold 5 AUC: 0.6160\n",
      "\n",
      "CV Score: 0.6129 ± 0.0193\n",
      "Individual folds: [0.645407710072837, 0.6033366171934301, 0.6465382192864872, 0.6039400414400414, 0.6159835534835535]\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation with class weighting\n",
    "print(\"Starting cross-validation...\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "\n",
    "# Class weighting for imbalance\n",
    "scale_pos_weight = 3.0  # From strategy (75%/25% = 3.0)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_combined, y)):\n",
    "    print(f\"\\nFold {fold+1}/5\")\n",
    "    \n",
    "    X_tr, X_val = X_train_combined[train_idx], X_train_combined[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'scale_pos_weight': scale_pos_weight\n",
    "    }\n",
    "    \n",
    "    # Create datasets\n",
    "    train_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    valid_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_data],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predict\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Score\n",
    "    fold_score = roc_auc_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_score)\n",
    "    print(f\"Fold {fold+1} AUC: {fold_score:.4f}\")\n",
    "\n",
    "# Overall CV score\n",
    "cv_score = roc_auc_score(y, oof_predictions)\n",
    "print(f\"\\nCV Score: {cv_score:.4f} ± {np.std(fold_scores):.4f}\")\n",
    "print(f\"Individual folds: {fold_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d132c108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:33:10.425248Z",
     "iopub.status.busy": "2026-01-13T17:33:10.425043Z",
     "iopub.status.idle": "2026-01-13T17:33:15.322244Z",
     "shell.execute_reply": "2026-01-13T17:33:15.321530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model on full data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved with 1162 predictions\n",
      "Prediction range: [0.0000, 0.9984]\n",
      "Mean prediction: 0.1747\n"
     ]
    }
   ],
   "source": [
    "# Train final model and generate predictions\n",
    "print(\"Training final model on full data...\")\n",
    "\n",
    "# Train on full training data\n",
    "final_model = lgb.train(\n",
    "    params,\n",
    "    lgb.Dataset(X_train_combined, label=y),\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.log_evaluation(0)]\n",
    ")\n",
    "\n",
    "# Generate predictions\n",
    "test_predictions = final_model.predict(X_test_combined)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} predictions\")\n",
    "print(f\"Prediction range: [{test_predictions.min():.4f}, {test_predictions.max():.4f}]\")\n",
    "print(f\"Mean prediction: {test_predictions.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffd84cb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:33:15.324055Z",
     "iopub.status.busy": "2026-01-13T17:33:15.323852Z",
     "iopub.status.idle": "2026-01-13T17:33:15.346503Z",
     "shell.execute_reply": "2026-01-13T17:33:15.345851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance analysis...\n",
      "Top 20 features by importance:\n",
      "                                            feature   importance\n",
      "10010                               avg_word_length  1712.280545\n",
      "10026                               request_quality  1362.698362\n",
      "10006                                   text_length  1338.409746\n",
      "10008                                  title_length  1327.522380\n",
      "10022                              user_credibility  1210.680005\n",
      "6149                                     tfidf_6149  1209.567809\n",
      "10003  requester_upvotes_minus_downvotes_at_request  1163.149899\n",
      "10025                           subreddit_diversity  1120.229912\n",
      "10023                             comments_per_post   976.880296\n",
      "10027                                  request_hour   965.925284\n",
      "10024                                  upvote_ratio   960.104073\n",
      "10007                                    word_count   930.119092\n",
      "10005      requester_account_age_in_days_at_request   911.730028\n",
      "10000       requester_number_of_comments_at_request   864.261865\n",
      "10004   requester_upvotes_plus_downvotes_at_request   763.860863\n",
      "4327                                     tfidf_4327   757.295217\n",
      "10009                              title_word_count   721.234280\n",
      "10001          requester_number_of_posts_at_request   711.380535\n",
      "3541                                     tfidf_3541   678.707642\n",
      "5332                                     tfidf_5332   671.709891\n",
      "Feature importance saved to experiments/002_feature_importance.csv\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis\n",
    "print(\"Feature importance analysis...\")\n",
    "\n",
    "# Get feature names\n",
    "tfidf_feature_names = [f'tfidf_{i}' for i in range(tfidf_train.shape[1])]\n",
    "feature_names = tfidf_feature_names + available_features\n",
    "\n",
    "# Get importance from final model (trained on full data)\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': final_model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 features by importance:\")\n",
    "print(importance_df.head(20))\n",
    "\n",
    "# Save importance\n",
    "importance_df.to_csv('/home/code/experiments/002_feature_importance.csv', index=False)\n",
    "print(\"Feature importance saved to experiments/002_feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c74efa04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:33:15.348360Z",
     "iopub.status.busy": "2026-01-13T17:33:15.347862Z",
     "iopub.status.idle": "2026-01-13T17:33:20.361881Z",
     "shell.execute_reply": "2026-01-13T17:33:20.361366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model on full data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved with 1162 predictions\n",
      "Prediction range: [0.0000, 0.9984]\n",
      "Mean prediction: 0.1747\n"
     ]
    }
   ],
   "source": [
    "# Train final model and generate predictions\n",
    "print(\"Training final model on full data...\")\n",
    "\n",
    "# Train on full training data\n",
    "final_model = lgb.train(\n",
    "    params,\n",
    "    lgb.Dataset(X_train_combined, label=y),\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.log_evaluation(0)]\n",
    ")\n",
    "\n",
    "# Generate predictions\n",
    "test_predictions = final_model.predict(X_test_combined)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} predictions\")\n",
    "print(f\"Prediction range: [{test_predictions.min():.4f}, {test_predictions.max():.4f}]\")\n",
    "print(f\"Mean prediction: {test_predictions.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
