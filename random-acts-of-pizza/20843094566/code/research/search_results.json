{
  "query": "How do Kaggle winners handle class imbalance in text classification competitions?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Based on the strategies described by Kaggle winners in the Jigsaw\u2011toxic\u2011comment and other text\u2011classification contests, the most common ways to tame severe class imbalance are:\n\n1. **Analyze the label distribution and set class\u2011wise loss weights** \u2013 compute the frequency of each class and pass the inverse frequencies (or a smoothed version) to the loss function (e.g., weighted\u202fbinary\u2011cross\u2011entropy or focal loss). This forces the model to pay more attention to rare toxic or insincere labels.\u202f([Towards Data Science](https://towardsdatascience.com/how-i-handled-imbalanced-text-data-ba9b757ab1d8))  \n\n2. **Oversample the minority class at the data\u2011loader level** \u2013 duplicate or augment under\u2011represented samples so each training batch contains a roughly balanced mix. Simple duplication works well, and many winners combine it with text\u2011augmentation (back\u2011translation, synonym replacement) to increase diversity.\u202f([Towards Data Science](https://towardsdatascience.com/how-i-handled-imbalanced-text-data-ba9b757ab1d8))  \n\n3. **Use stratified K\u2011fold splits** \u2013 ensure every fold preserves the original class ratios, preventing the validation set from being overly easy or hard and giving a reliable estimate of performance on the imbalanced target.\u202f([Neptune blog on text\u2011classification tips](https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions))  \n\n4. **Apply a balanced\u2011batch sampler or custom DataLoader** \u2013 instead of random sampling, build each batch by drawing an equal number of examples from each class (or from groups of similar frequency). This keeps gradient updates stable throughout training.\u202f([Towards Data Science](https://towardsdatascience.com/how-i-handled-imbalanced-text-data-ba9b757ab1d8))  \n\n5. **Leverage ensemble blending with models trained on different sampling schemes** \u2013 many top teams train one model on the original data, another on an oversampled version, and then blend their predictions. The diversity of sampling strategies often yields a boost on the leaderboard.\u202f([Neptune blog on text\u2011classification tips](https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions))  \n\n**Quick checklist for a new competition**\n\n- Compute class frequencies \u2192 set `pos_weight` or class\u2011wise weights in the loss.  \n- Create an oversampled/augmented training set for the rare classes.  \n- Split with `StratifiedKFold` (or `StratifiedGroupKFold` if needed).  \n- Implement a balanced\u2011batch sampler (e.g., `torch.utils.data.WeightedRandomSampler`).  \n- Train at least two models (original vs. oversampled) and blend their probabilities.  \n\nFollowing these steps mirrors the proven workflow of Kaggle winners handling class\u2011imbalanced text classification problems.",
      "url": ""
    },
    {
      "title": "Text Classification: All Tips and Tricks from 5 Kaggle Competitions",
      "text": "In this article, I will discuss some great tips and tricks to [improve the performance](https://neptune.ai/blog/improving-machine-learning-deep-learning-models) of your text classification model. These tricks are obtained from solutions of some of Kaggle\u2019s top NLP competitions.\n\nNamely, I\u2019ve gone through:\n\n- [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification) \u2013 $65,000\n- [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/) \u2013 $35,000\n- [Quora Insincere Questions Classification](http://kaggle.com/c/quora-insincere-questions-classification) \u2013 $25,000\n- [Google QUEST Q&A Labeling](https://www.kaggle.com/c/google-quest-challenge) \u2013 $25,000\n- [TensorFlow 2.0 Question Answering](https://www.kaggle.com/c/tensorflow2-question-answering) \u2013 $50,000\n\nand found a ton of great ideas.\n\nWithout much lag, let\u2019s begin.\n\n## Dealing with larger datasets\n\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for Kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\n\n- Optimize the memory by [reducing the size of some attributes](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\n- Use open-source libraries such as [Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space\n- Use [cudf](https://github.com/rapidsai/cudf)\n- Convert data to [parquet](https://arrow.apache.org/docs/python/parquet.html) format\n- Convert data to [feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03) format\n\n## Small datasets and external data\n\nBut, what can one do if the dataset is small? Let\u2019s see some techniques to tackle this situation.\n\nOne way to increase the performance of any machine learning model is to use some external data frame that contains some variables that influence the predicate variable.\n\nLet\u2019s see some of the external datasets.\n\n- Use of [squad](https://rajpurkar.github.io/SQuAD-explorer/) data for Question Answering tasks\n- Other [datasets](http://nlpprogress.com/english/question_answering.html) for QA tasks\n- Wikitext long term dependency language modeling [dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\n- [Stackexchange data](https://archive.org/download/stackexchange)\n- Prepare a dictionary of commonly misspelled words and corrected words.\n- Use of [helper datasets](https://www.kaggle.com/kyakovlev/jigsaw-general-helper-public) for cleaning\n- [Pseudo labeling](https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969/) is the process of adding confidently predicted test data to your training data\n- Use different data [sampling methods](https://www.kaggle.com/shahules/tackling-class-imbalance)\n- Text augmentation by [Exchanging words with synonym](https://arxiv.org/pdf/1502.01710.pdf) [s](https://arxiv.org/pdf/1502.01710.pdf)\n- Text augmentation by [noising in RNN](https://arxiv.org/pdf/1703.02573.pdf)\n- Text augmentation by [translation to other languages and back](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/48038)\n\n## Data exploration and gaining insights\n\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\n\n- Twitter data [exploration methods](https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda)\n- Simple [EDA for tweets](https://www.kaggle.com/nz0722/simple-eda-text-preprocessing-jigsaw)\n- [EDA](https://www.kaggle.com/tunguz/just-some-simple-eda) for Quora data\n- [EDA](https://www.kaggle.com/kailex/r-eda-for-q-gru) in \u00a0R for Quora data\n- Complete [EDA](https://www.kaggle.com/codename007/start-from-here-quest-complete-eda-fe) with stack exchange data\n- My previous article on [EDA for natural language processing](https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools)\n\n## Data cleaning\n\nData cleaning is one of the important and integral parts of any NLP problem. Text data always needs some preprocessing and cleaning before we can represent it in a suitable form.\n\n- Use this [notebook](https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing) to clean social media data\n- [Data cleaning](https://www.kaggle.com/kyakovlev/preprocessing-bert-public) for BERT\n- Use [textblob](https://textblob.readthedocs.io/en/dev/quickstart.html) to correct misspellings\n- [Cleaning](https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing) for pre-trained embeddings\n- [Language detection and translation](https://www.pythonprogramming.in/language-detection-and-translation-using-textblob.html) for multilingual tasks\n- Preprocessing for Glove [part 1](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part1-eda) and [part 2](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part2-usage)\n- [Increasing word coverage](https://www.kaggle.com/sunnymarkliu/more-text-cleaning-to-increase-word-coverage) to get more from pre-trained word embeddings\n\n## Text representations\n\nBefore we feed our text data to the Neural network or ML model, the text input needs to be represented in a suitable format. These representations determine the performance of the model to a large extent.\n\n- Pretrained [Glove](https://nlp.stanford.edu/projects/glove/) vectors\n- Pretrained [fasttext](https://fasttext.cc/docs/en/english-vectors.html) vectors\n- Pretrained [word2vec](https://radimrehurek.com/gensim/models/word2vec.html) vectors\n- My previous article on these [3 embeddings](https://neptune.ai/blog/document-classification-small-datasets)\n- Combining [pre-trained vectors](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778/). This can help in better representation of text and decreasing OOV words\n- [Paragram](https://cogcomp.seas.upenn.edu/page/resource_view/106) embeddings\n- [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/1)\n- Use USE to generate [sentence-level features](https://www.kaggle.com/abhishek/distilbert-use-features-oof)\n- 3 methods to [combine embeddings](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778)\n\nContextual embeddings models\n\n- [BERT](https://github.com/google-research/bert) Bidirectional Encoder Representations from Transformers\n- [GPT](https://github.com/openai/finetune-transformer-lm)\n- [Roberta](https://github.com/pytorch/fairseq/tree/master/examples/roberta) a Robustly Optimized BERT\n- [Albert](https://github.com/google-research/ALBERT) a Lite BERT for Self-supervised Learning of Language Representations\n- [Distilbert](https://github.com/huggingface/transformers/tree/master/examples/distillation) a lighter version of BERT\n- [XLNET](https://github.com/zihangdai/xlnet/)\n\n## Modeling\n\n### Model architecture\n\nChoosing the right architecture is important to develop a proper machine learning model, sequence to sequence models like LSTMs, GRUs perform well in NLP problems and is always worth trying. Stacking 2 layers of LSTM/GRU networks is a common approach.\n\n- [Stacking Bidirectional CuDNNLSTM](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644/)\n- [Stacking LSTM networks](https://www.kaggle.com/sakami/google-quest-single-lstm/)\n- [LSTM and 5 fold Attention](https://www.kaggle.com/christofhenkel/keras-baseline-lstm-attention-5-fold/)\n- [Bi...",
      "url": "https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions"
    },
    {
      "title": "Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions",
      "text": "Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions[\n**\ud83d\udce3 BIG NEWS:****Neptune is joining OpenAI!**\u2192 Read the message from our CEO \ud83d\udce3![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\nWhat do you want to find?\nSearch\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\nSearch in Blog...\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\nSearch in Blog...\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\n[Neptune Blog](https://neptune.ai/blog)# Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Shahul-Es-new-scaled.jpeg?fit=2560%2C1920&ssl=1)\n[Shahul ES](https://neptune.ai/blog/author/shahules)\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)3 min\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)1st September, 2023\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)[Tabular Data](https://neptune.ai/blog/category/tabular-data)\nIn this article, I will discuss some great tips and tricks to improve the performance of your structured data binary classification model. These tricks are obtained from solutions of some of Kaggle\u2019s top tabular data competitions. Without much lag, let\u2019s begin.\nThese are the five competitions that I have gone through to create this article:\n* [**Home credit default risk**](https://www.kaggle.com/c/home-credit-default-risk/)\n* [**Santander Customer Transaction Prediction**](https://www.kaggle.com/c/santander-customer-transaction-prediction/notebooks)\n* [**VSB Power Line Fault Detection**](https://www.kaggle.com/c/vsb-power-line-fault-detection/overview/evaluation)\n* [**Microsoft Malware Prediction**](https://www.kaggle.com/c/microsoft-malware-prediction/overview)\n* [**IEEE-CIS Fraud Detection**](https://www.kaggle.com/c/ieee-fraud-detection/overview/evaluation/)## Dealing with larger datasets\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\n* Faster[data loading with pandas.](https://www.kaggle.com/c/home-credit-default-risk/discussion/59575)\n* Data compression techniques to[reduce the size of data by 70%](https://www.kaggle.com/nickycan/compress-70-of-dataset).\n* Optimize the memory by r[educing the size of some attributes.](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\n* Use open-source libraries such as[Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space.\n* Use[cudf](https://github.com/rapidsai/cudf).\n* Convert data to[parquet](https://arrow.apache.org/docs/python/parquet.html)format.\n* Converting data to[feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03)format.\n* Reducing memory usage for[optimizing RAM](https://www.kaggle.com/mjbahmani/reducing-memory-size-for-ieee).## Data exploration\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\n* EDA for microsoft[malware detection.](https://www.kaggle.com/youhanlee/my-eda-i-want-to-see-all)\n* Time Series[EDA for malware detection.](https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68)\n* Complete[EDA for home credit loan prediction](https://www.kaggle.com/codename007/home-credit-complete-eda-feature-importance).\n* Complete[EDA for Santader prediction.](https://www.kaggle.com/gpreda/santander-eda-and-prediction)\n* EDA for[VSB Power Line Fault Detection.](https://www.kaggle.com/go1dfish/basic-eda)## Data preparation\nAfter data exploration, the first thing to do is to use those insights to prepare the data. To tackle issues like class imbalance, encoding categorical data, etc. Let\u2019s see the methods used to do it.\n* Methods to t[ackle class imbalance](https://www.kaggle.com/shahules/tackling-class-imbalance).\n* Data augmentation by[Synthetic Minority Oversampling Technique](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/).\n* Fast inplace[shuffle for augmentation](https://www.kaggle.com/jiweiliu/fast-inplace-shuffle-for-augmentation).\n* Finding[synthetic samples in the dataset.](https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split)\n* [Signal denoising](https://www.kaggle.com/jackvial/dwt-signal-denoising)used in signal processing competitions.\n* Finding[patterns of missing data](https://www.kaggle.com/jpmiller/patterns-of-missing-data).\n* Methods to handle[missing data](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779).\n* An overview of various[encoding techniques for categorical data.](https://www.kaggle.com/shahules/an-overview-of-encoding-techniques)\n* Building[model to predict missing values.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64598)\n* Random[shuffling of data](https://www.kaggle.com/brandenkmurray/randomly-shuffled-data-also-works)to create new synthetic training set.## Feature engineering\nNext, you can check the most popular feature and feature engineering techniques used in these top kaggle competitions. The feature engineering part varies from problem to problem depending on the domain.\n* Target[encoding cross validation](https://medium.com/@pouryaayria/k-fold-target-encoding-dfe9a594874b/)for better encoding.\n* Entity embedding to[handle categories](https://www.kaggle.com/abhishek/entity-embeddings-to-handle-categories).\n* Encoding c[yclic features for deep learning.](https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning)\n* Manual[feature engineering methods](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering).\n* Automated feature engineering techniques[using featuretools](https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics).\n* Top hard crafted features used in[microsoft malware detection](https://www.kaggle.com/sanderf/7th-place-solution-microsoft-malware-prediction).\n* Denoising NN for[feature extraction](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798).\n* Feature engineering[using RAPIDS framework.](https://www.kaggle.com/cdeotte/rapids-feature-engineering-fraud-0-96/)\n* Things to remember while processing f[eatures using LGBM.](https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575)\n* [Lag features and moving averages.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64593)\n* [Principal component analysis](https://medium.com/machine-learning-researcher/dimensionality-reduction-pca-and-lda-6be91734f567)for...",
      "url": "https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions"
    },
    {
      "title": "How I handled imbalanced text data - Towards Data Science",
      "text": "[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fba9b757ab1d8&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------)\n\n[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-handled-imbalanced-text-data-ba9b757ab1d8&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-handled-imbalanced-text-data-ba9b757ab1d8&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\n\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_topnav-----------)\n\n[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-handled-imbalanced-text-data-ba9b757ab1d8&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-handled-imbalanced-text-data-ba9b757ab1d8&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\n\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n\n# **How I handled imbalanced text data**\n\n## Blueprint to tackle one of the most common problems in AI\n\n[![Yogesh Kothiya](https://miro.medium.com/v2/resize:fill:88:88/1*zNkUFlexn9RWHc--UuuQ5w.jpeg)](https://medium.com/@kothiya.yogesh?source=post_page-----ba9b757ab1d8--------------------------------)[![Towards Data Science](https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg)](https://towardsdatascience.com/?source=post_page-----ba9b757ab1d8--------------------------------)\n\n[Yogesh Kothiya](https://medium.com/@kothiya.yogesh?source=post_page-----ba9b757ab1d8--------------------------------)\n\n\u00b7\n\n[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd310856a9437&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-handled-imbalanced-text-data-ba9b757ab1d8&user=Yogesh+Kothiya&userId=d310856a9437&source=post_page-d310856a9437----ba9b757ab1d8---------------------post_header-----------)\n\nPublished in\n\n[Towards Data Science](https://towardsdatascience.com/?source=post_page-----ba9b757ab1d8--------------------------------)\n\n\u00b7\n\n5 min read\n\n\u00b7\n\nMay 15, 2019\n\n--\n\n2\n\nListen\n\nShare\n\nPhoto by [Form](https://unsplash.com/@theformfitness?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\n\nThe problem of imbalanced class distribution is prevalent in the field of data science and ML engineers come across it frequently. I am a chatbot developer at [IMImoble Pvt Ltd](https://imimobile.com/) and faced this scenario recently while training intent classification module. Any live business chatbot accessible to real-world users is bound to attract a significant number of out-of-scope queries along with messages pertaining to the task it is designed to perform. Even among the relevant task-oriented messages, imbalances are to be expected as all topics covered by the bot can\u2019t be equally popular. For example, in a banking use case, balance inquiries will outnumber home loan applications.\n\nBot building is not similar to traditional application development. While the latter is relatively stable and is updated less often, the former needs frequent updates to improve user experience and intelligence of the bot. The imbalanced dataset is the problem where data belonging to one class is significantly higher or lower than that belonging to other classes. Most ML/DL classification algorithms aren\u2019t equipped to handle imbalanced classes and tend to get biased towards majority classes.\n\n# **Why accuracy is a sham in the case of an imbalanced dataset**\n\nAiming only for high accuracy for the imbalanced dataset can be counter-productive because standard classifier algorithms like Decision Trees and Logistic Regression do not have the ability to handle imbalanced classes incorporated into them. This leads to a heavy bias towards larger classes and classes with fewer data points are treated as noise and are often ignored. The result is a higher misclassification rate for minority classes compared to the majority classes. Therefore, the accuracy metric is not as relevant when evaluating the performance of a model trained on imbalanced data.\n\nConsider the following case: you have two classes \u2014 A and B. Class A is 95% of your dataset and class B is the other 5%. You can reach an accuracy of 95% by simply predicting class A every time, but this provides a useless classifier for your intended use case. Instead, a properly calibrated method may achieve a lower accuracy but would have a substantially higher true positive rate (or recall), which is really the metric you should have been optimizing for.\n\n[This](https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/) article explains several methods to handle imbalanced dataset but most of them don\u2019t work well for text data. In this article, I am sharing all the tricks and techniques I have used to balance my dataset along with the code which boosted f1-score by 30%.\n\n# Strategies for handling Imbalanced Datasets:\n\n**Can you gather more data?**\n\nYou might think that this is not the solution you\u2019re looking for but gathering more meaningful and diverse data is always better than sampling original data or generating artificial data from existing data points.\n\n**Removing data redundancy:**\n\n1. Removing duplicate data \u2014 The dataset I was dealing with contained a lot of similar and even duplicate data points. \u201cWhere is my order\u201d and \u201cWhere is the order\u201d has the same semantic meaning. Removing such duplicate message will help you reduce the size of your majority class.\n2. There were many messages which had the same semantic meaning, for example, consider the following messages, which convey the same meaning. Keeping one or two such utterances and removing others also helps in balancing classes. Well, you can use those messages in the validation set. There are many ways to find text similarity but I have used Jaccard Similarity because it is very easy to implement and it considers only unique sets of words while calculating similarity. You can look at other techniques in [this](https://medium.com/@adriensieg/text-similarities-da019229c894) article.\n\n_Can I change the delivery time for my delivery?_\n\n_Can I change time of my delivery?_\n\n_Can I change delivery time?_\n\n3\\. Merge minority classes \u2014 Sometimes multiple classes have overlapping features. It\u2019s better to merge those multiple minority classes. This trick helped me improve f1-score by more than 10%.\n\n**Resample training dataset:**\n\nThe simplest way to fix imbalanced dataset is simply balancing them by oversampling instances of the minority class or undersampling instances of the majority class. Using advanced techniques like SMOTE(Synthetic Minority Over-sampling Technique) will help you create new synthetic instances from minority class.\n\n1. Undersampling \u2014 An effort to eliminate data point from the majority class randomly until the classes are balanced. There is a likelihood of information loss which might lead to poor model training.\n2. Oversampling \u2014 This is the process to replicate minority class instances randomly. This approach can overfit and lead to inaccurate predictions on test data.\n3. SMOTE \u2014 SMOTE generates synthetic samples by taking each minority class sample and introducing synthetic examples along the line segments joining any/all of the k minority class nearest neighbors as shown in below GIF. More importantly, this approach effectively forces the decision region of the minority class to beco...",
      "url": "https://towardsdatascience.com/how-i-handled-imbalanced-text-data-ba9b757ab1d8?gi=f37886eebb72"
    },
    {
      "title": "AIcrowd | Dealing with Class Imbalance | Posts",
      "text": "Loading\n\n#### [ADDI Alzheimers Detection Challenge](https://www.aicrowd.com/challenges/addi-alzheimers-detection-challenge)\n\n# Dealing with Class Imbalance\n\nLooking at different ways to address class imbalance in this dataset\n\nJohnowhitaker7 May 2021\n\n[20](https://www.aicrowd.com/participants/sign_in) [Open in Colab](https://colab.research.google.com/gist/aicrowd-bot/d9ed51a8b9be2026f0ff96c2b5cad9c2)\n\nIn this notebook I take a close look at some different ways we can address the difference in class balance between train and validation (and presumably test)\n\nWe look at changing sample weights, over\u00a0and under-sampling, SMOTE and some other tips and tricks.\n\nI hope you find it helpful :)\n\n# Introduction [\u00b6](https://www.aicrowd.com/www.aicrowd.com\\#Introduction)\n\nSo you've made your first model for this challenge and it's getting a log loss of ~0.9 - a ways behind the leaders on 0.6X. You're starting to think about feature engineering, adding more models to your ensemble, maybe trying one of those tabular deep learning models the cool kids are talking about. **STOP!** Before any of that, there is one BIG issue we need to deal with: class (im)balance.\n\nThe validation set (and presumably the test set) has a different class distribution to the training data. In this notebook we will look at many different ways we can correct for this class imbalance - picking one of these will boost your score tremendously (we're taking ~0.66 with a single simple random forest model). So, let's dive in.\n\n# Setup [\u00b6](https://www.aicrowd.com/www.aicrowd.com\\#Setup)\n\nImporting the libraries we'll be using, loading the data and getting ready to run our experiments.\n\nIn\u00a0\\[1\\]:\n\n```\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import f1_score, log_loss\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\n```\n\nIn\u00a0\\[2\\]:\n\n```\n#The training data\ndf = pd.read_csv('ds_shared_drive/train.csv')\nprint(df.shape)\ndf.head(2)\n```\n\n```\n(32777, 122)\n\n```\n\nOut\\[2\\]:\n\n| row\\_id | number\\_of\\_digits | missing\\_digit\\_1 | missing\\_digit\\_2 | missing\\_digit\\_3 | missing\\_digit\\_4 | missing\\_digit\\_5 | missing\\_digit\\_6 | missing\\_digit\\_7 | missing\\_digit\\_8 | ... | bottom\\_area\\_perc | left\\_area\\_perc | right\\_area\\_perc | hor\\_count | vert\\_count | eleven\\_ten\\_error | other\\_error | time\\_diff | centre\\_dot\\_detect | diagnosis |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | S0CIXBKIUEOUBNURP | 12.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.52617 | 0.524975 | 0.474667 | 0 | 0 | 0 | 1 | -105.0 | 0.0 | normal |\n| 1 | IW1Z4Z3H720OPW8LL | 12.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.00081 | 0.516212 | 0.483330 | 0 | 1 | 0 | 1 | NaN | NaN | normal |\n\n2 rows \u00d7 122 columns\n\nIn\u00a0\\[3\\]:\n\n```\n# The validation data (we merge in the labels for convenience)\nval = pd.read_csv('ds_shared_drive/validation.csv')\nval = pd.merge(val, pd.read_csv('ds_shared_drive/validation_ground_truth.csv'),\n               how='left', on='row_id')\nprint(val.shape)\nval.head()\n```\n\n```\n(362, 122)\n\n```\n\nOut\\[3\\]:\n\n| row\\_id | number\\_of\\_digits | missing\\_digit\\_1 | missing\\_digit\\_2 | missing\\_digit\\_3 | missing\\_digit\\_4 | missing\\_digit\\_5 | missing\\_digit\\_6 | missing\\_digit\\_7 | missing\\_digit\\_8 | ... | bottom\\_area\\_perc | left\\_area\\_perc | right\\_area\\_perc | hor\\_count | vert\\_count | eleven\\_ten\\_error | other\\_error | time\\_diff | centre\\_dot\\_detect | diagnosis |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | LA9JQ1JZMJ9D2MBZV | 11.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.499368 | 0.553194 | 0.446447 | 0 | 0 | 0 | 1 | NaN | NaN | post\\_alzheimer |\n| 1 | PSSRCWAPTAG72A1NT | 6.0 | 1.0 | 1.0 | 0.0 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | ... | 0.427196 | 0.496352 | 0.503273 | 0 | 1 | 0 | 1 | NaN | NaN | normal |\n| 2 | GCTODIZJB42VCBZRZ | 11.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | ... | 0.505583 | 0.503047 | 0.496615 | 1 | 0 | 0 | 0 | 0.0 | 0.0 | normal |\n| 3 | 7YMVQGV1CDB1WZFNE | 3.0 | 1.0 | 0.0 | 1.0 | 0.0 | 1.0 | 1.0 | 1.0 | 1.0 | ... | 0.444633 | 0.580023 | 0.419575 | 0 | 1 | 0 | 1 | NaN | NaN | post\\_alzheimer |\n| 4 | PHEQC6DV3LTFJYIJU | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 0.0 | ... | 0.395976 | 0.494990 | 0.504604 | 0 | 0 | 0 | 1 | 150.0 | 0.0 | normal |\n\n5 rows \u00d7 122 columns\n\nIn\u00a0\\[4\\]:\n\n```\n# We'll keep track of how different approaches perform\nresults = []\n```\n\n# Baseline \\#1 - Training on all data [\u00b6](https://www.aicrowd.com/www.aicrowd.com\\#Baseline-%231---Training-on-all-data)\n\nThis is a case where we don't do any correction for the class imbalance. Some models will do better than others - tree-based models like CatBoost will be less sensitive than some other model types, but they will still over-estimate the probability that a given sample will fall into the majority class when making predicitons on the validation set (since the 'normal' class is so much more common in the training data).\n\nIn\u00a0\\[5\\]:\n\n```\n# Prep the data\nX = df.drop(['row_id', 'diagnosis'], axis=1).fillna(0)\ny = df['diagnosis']\nX_val = val.drop(['row_id', 'diagnosis'], axis=1).fillna(0)\ny_val = val['diagnosis']\n\n# Train the model\nmodel = CatBoostClassifier(verbose=False, cat_features=['intersection_pos_rel_centre'])\n\n# Evaluate on val set\nmodel.fit(X, y, eval_set = (X_val, y_val), early_stopping_rounds = 30)\n\n# Store results\nr = {'Approach':'No modifications',\n     'Log Loss':log_loss(y_val, model.predict_proba(X_val)),\n     'F1':f1_score(y_val, model.predict(X_val), average='macro')\n    }\nresults.append(r)\n\nprint(r) # Show results\n```\n\n```\n{'Approach': 'No modifications', 'Log Loss': 0.6745549053231596, 'F1': 0.2848101265822785}\n\n```\n\nA log loss of 0.67 on the validation set isn't terrible. We are using the validation set for early stopping - without that in place we get a log loss of 0.78 on our validation set and 0.8X on the leaderboard. So in a way, by using the validation set for early stopping we are already starting to combat our class balance problem... but we can do much better!\n\n# Adjusting Sample Weights [\u00b6](https://www.aicrowd.com/www.aicrowd.com\\#Adjusting-Sample-Weights)\n\nModels like CatBoost allow us to assign more weight to specific samples. In this case, we use this to place less weight on samples in the over-represented classes, combating the bias introduced by the imbalance:\n\nIn\u00a0\\[6\\]:\n\n```\n# Prep the data\nX = df.drop(['row_id', 'diagnosis'], axis=1).fillna(0)\ny = df['diagnosis']\nX_val = val.drop(['row_id', 'diagnosis'], axis=1).fillna(0)\ny_val = val['diagnosis']\n\n#Our class weights\nweights = {\n    'normal':9/74, # Chosen based on some quick mental maths comparing the distribution of train vs val\n    'post_alzheimer':0.85,\n    'pre_alzheimer':1\n}\n\n# Applying these weights as sample weights by using Pool to wrap our training data\ntrain_data = Pool(\n    data = X,\n    label = y,\n    weight = y.map(weights), # << The important bit\n    cat_features = [list(X.columns).index('intersection_pos_rel_centre')]\n)\n\neval_data = Pool(\n    data = X_val,\n    label = y_val,\n    weight = y_val.map(lambda x: 1.0), # all validation samples get a weight of 1\n    cat_features = [list(X.columns).index('intersection_pos_rel_centre')]\n)\n\n# Train the model\nmodel = CatBoostClassifier(verbose=False)\n\n# Evaluate on val set\nmodel.fit(train_data, eval_set = eval_data, early_stopping_rounds = 30)\n\n# Store results\nr = {'Approach':'Modifying Sample Weights',\n     'Log Loss':log_loss(y_val, model.predict_proba(X_val)),\n     'F1':f1_score(y_val, model.predict(X_val), average='macro')\n    }\nresults.append(r)\n\nprint(r) # Show results\n```\n\n```\n{'Approach': 'Modifying Sample Weights', 'Log Loss': 0.5593949556085255, 'F1': 0.4727603953181...",
      "url": "https://www.aicrowd.com/showcase/dealing-with-class-imbalance"
    },
    {
      "title": "",
      "text": "<div><section>\n <figure><figcaption>\n <p><a href=\"https://pixabay.com/en/pollution-toxic-products-environment-3075857/\">Photo Credit</a></p>\n </figcaption>\n</figure>\n<h2>Introduction</h2>\n<p><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\">Jigsaw toxic comment classification challenge</a> features a multi-label text classification problem with a highly imbalanced dataset. The test set used originally was revealed to be already public on the Internet, so <a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/47835\">a new dataset was released</a> mid-competition, and the evaluation metric was <a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/48639\">changed from Log Loss to AUC</a>.</p>\n<p>I tried a few ideas after building up my PyTorch pipeline but did not find any innovative approach that looks promising. Text normalization is the only strategy I had found to give solid improvements, but it is very time consuming. The final result (105th place/about top 3%) was quite fitting IMO given the time I spent on this competition(not a lot).</p>\n<p>(There were some <a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52574\">heated discussion</a> around the topic of some top-ranking teams with Kaggle grand masters getting disqualified after the competition ended.)</p>\n<p>Public kernel blends performed well in this competition (i.e. did not over-fit the public leaderboard too much). I expected it to overfit, but still selected one final submission that used the best public blend of blends to play it safe. Fortunately it paid off and gave me a 0.0001 boost in AUC on private leaderboard:</p>\n<figure><figcaption>\n <p><a href=\"https://docs.google.com/spreadsheets/d/1R3u6tXDa9CVByaRW9FY8FpxRTqwZsBWfLYuqC1gu8A8/edit?usp=sharing\">Table 1: Selected submissions in descending order of private scores</a></p>\n </figcaption>\n</figure>\n<p>In this post, I\u2019ll review some of the techniques used and shared by top competitors. I do not have enough time to test every one of them myself. Part 2 of this series will be implementing a top 5 solution by my own, if I ever find time to do it.</p>\n<h2>List of Techniques</h2>\n<p>I tired to attribute techniques to all appropriate sources, but I\u2019m sure I\u2019ve missed some sources here and there. <strong><em>Not all techniques are covered because of the vast amount of contents shared by generous Kagglers</em></strong>. I might come back and edit this list in the near future.</p>\n<ul>\n<li>Translation as Augmentation (test time and train time) [1][2][13]</li>\n<li>Pseudo-labelling [1]</li>\n<li>Text normalization [3][4]</li>\n<li>Multi-level stacking \u2014 4 levels [3]; 2 levels [11]; 1level stacking + 1 level weighted averaging [12]</li>\n<li>Non-English embeddings [2]</li>\n<li>Diverse pre-trained embeddings \u2014 Train multiple model separately on different embeddings</li>\n<li>Combine several pre-trained embeddings \u2014 concatenate after a RNN layer [3]; Concatenate at embedding level [5]; Variant of <a href=\"https://arxiv.org/abs/1705.02798\">Reinforced Mnemonic Reader</a> [7]</li>\n<li>When truncating texts, retain both head and tail of the texts [1]</li>\n<li>K-max pooling[6]</li>\n<li>Multiple-level of stacking [3]</li>\n<li>Deepmoji-style attention model [3]</li>\n<li>(NN) Additional row-level features:<em>\u201cUnique words rate\u201d and \u201cRate of all-caps words\u201d</em>[4]</li>\n<li>(NN) Additional word-level feature(s): If a word contains only capital letters [4]</li>\n<li>(GBM) Engineered features other than tf-idf [12]</li>\n<li>BytePair Encoding [5][8]</li>\n<li><a href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf\">R-net</a> [7]</li>\n<li>CapsuleNet [11]</li>\n<li>Label aware attention layer [7]</li>\n<li>(20180413 Update) leaky information \u2014 small overlaps of IPs between training and testing dataset. One overlapping username. [14]</li>\n</ul>\n<h2>Pseudo-labelling and Head-Tail Truncating</h2>\n<p>I\u2019ve already tried these two techniques and trained a couple of models for each.</p>\n<p>Head-tail truncating (keeping 250 tokens at head, 50 tokens at tail) helped only a bit for bi-GRU, but not for QRNN. It basically had no effect on my final ensemble.</p>\n<p>For pseudo-labelling(PL), I used the test-set predictions from my best ensemble as suggested in [1], and they improved the final ensemble a little (see table 1). I\u2019d assume that adding more model trained with PL will further boost the final AUC. However, the problem of this approach is the leakage it produces. The ensemble model had seen the the all the validation data, and that information leaked into its test set predictions. So the local CV will be distorted and not comparable to those trained without PL. Nonetheless, this technique does create the best single model, so it\u2019ll be quite useful for production deployment.</p>\n<p>I think the more conservative way of doing PL is to repeat the train-predict-train(with PL) process, so the model is trained twice for every fold. But that\u2019ll definitely takes more time.</p>\n<h2>References:</h2>\n<ol>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52557\">The 1st place solution overview</a> by <a href=\"https://www.kaggle.com/leecming\">Chun Ming Lee</a> from team <em>Toxic Crusaders</em></li>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52612\">The 2nd place solution overview</a> by <a href=\"https://www.kaggle.com/neongen\">neongen</a> from team <em>neongen &amp; Computer says no</em></li>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52762\">The 3rd place solution overview</a> by <a href=\"https://www.kaggle.com/tunguz\">Bojan Tunguz</a> from team <em>Adversarial Autoencoder</em></li>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644\">About my 0.9872 single model</a> by <a href=\"https://www.kaggle.com/mrboor\">Alexander Burmistrov</a> from team <em>Adversarial Autoencoder</em></li>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52630\">The 5th place brief solution</a> by <a href=\"https://www.kaggle.com/kazanova\">\u039c\u03b1\u03c1\u03b9\u03bf\u03c2 \u039c\u03b9\u03c7\u03b1\u03b7\u03bb\u03b9\u03b4\u03b7\u03c2 KazAnova</a> from team <em>TPMPM</em></li>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52526\">Congrats (from ghost 11th team)</a> by <a href=\"https://www.kaggle.com/cpmpml\">CPMP</a></li>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52702\">The 12th place single model solution share</a> by <a href=\"https://www.kaggle.com/goldenlock\">BackFactoryVillage</a> from team <em>Knights of the Round Table</em></li>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52563\">The 15th solution summary: Byte Pair Encoding</a> by <a href=\"https://www.kaggle.com/tezdhar\">Mohsin hasan</a> from team <em>Zehar 2.0</em></li>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52647\">The 25th Place Notes (0.9872 public; 0.9873 private)</a> by <a href=\"https://www.kaggle.com/jtrotman\">James Trotman</a> (solo)</li>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52719\">The 27th place solution overview</a> by <a href=\"https://www.kaggle.com/zake7749\">Justin Yang</a> from team <em>Sotoxic</em></li>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52666\">The 33rd Place Solution Using Embedding Imputation (0.9872 private, 0.9876 public)</a> by <a href=\"https://www.kaggle.com/mmotoki\">Matt Motoki</a> (solo)</li>\n<li><a href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52645\">The 34th, Lots of FE and Poor Understanding of NNs [CODE INCLUDED]</a> by <a href=\"https://www...",
      "url": "https://blog.ceshine.net/post/kaggle-toxic-comment-classification-challenge"
    },
    {
      "title": "Classification on imbalanced data \n\n    \n    \n       \n    \n\n     \n      \n      Stay organized with collections\n     \n     \n      \n      Save and categorize content based on your preferences.",
      "text": "Classification on imbalanced data | TensorFlow Core[Skip to main content](#main-content)\n[![TensorFlow](https://www.gstatic.com/devrel-devsite/prod/ve08add287a6b4bdf8961ab8a1be50bf551be3816cdd70b7cc934114ff3ad5f10/tensorflow/images/lockup.svg)](https://www.tensorflow.org/)\n* /\n* English\n* Espa\u00f1ol \u2013Am\u00e9rica Latina\n* Fran\u00e7ais\n* Indonesia\n* Italiano\n* Polski\n* Portugu\u00eas \u2013Brasil\n* Ti\u00ea\u0301ng Vi\u00ea\u0323t\n* T\u00fcrk\u00e7e\n* \u0420\u0443\u0441\u0441\u043a\u0438\u0439* \u05e2\u05d1\u05e8\u05d9\u05ea* \u0627\u0644\u0639\u0631\u0628\u064a\u0651\u0629* \u0641\u0627\u0631\u0633\u06cc* \u0939\u093f\u0902\u0926\u0940* \u09ac\u09be\u0982\u09b2\u09be* \u0e20\u0e32\u0e29\u0e32\u0e44\u0e17\u0e22* \u4e2d\u6587\u2013\u7b80\u4f53* \u65e5\u672c\u8a9e* \ud55c\uad6d\uc5b4[GitHub](https://github.com/tensorflow)Sign in\n* [TensorFlow Core](https://www.tensorflow.org/tutorials)\n* [TensorFlow](https://www.tensorflow.org/)\n* [Learn](https://www.tensorflow.org/learn)\n* [TensorFlow Core](https://www.tensorflow.org/tutorials)\n# Classification on imbalanced dataStay organized with collectionsSave and categorize content based on your preferences.\n[![](https://www.tensorflow.org/images/tf_logo_32px.png)View on TensorFlow.org](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data)|[![](https://www.tensorflow.org/images/colab_logo_32px.png)Run in Google Colab](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb)|[![](https://www.tensorflow.org/images/GitHub-Mark-32px.png)View source on GitHub](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb)|[![](https://www.tensorflow.org/images/download_logo_32px.png)Download notebook](https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/imbalanced_data.ipynb)|\nThis tutorial demonstrates how to classify a highly imbalanced dataset in which the number of examples in one class greatly outnumbers the examples in another. You will work with the[Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)dataset hosted on Kaggle. The aim is to detect a mere 492 fraudulent transactions from 284,807 transactions in total. You will use[Keras](https://www.tensorflow.org/guide/keras/overview)to define the model and[class weights](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model)to help the model learn from the imbalanced data. .\nThis tutorial contains complete code to:\n* Load a CSV file using Pandas.\n* Create train, validation, and test sets.\n* Define and train a model using Keras (including setting class weights).\n* Evaluate the model using various metrics (including precision and recall).\n* Select a threshold for a probabilistic classifier to get a deterministic classifier.\n* Try and compare with class weighted modelling and oversampling.## Setup\n```\n`importtensorflowastffromtensorflowimportkerasimportosimporttempfileimportmatplotlibasmplimportmatplotlib.pyplotaspltimportnumpyasnpimportpandasaspdimportseabornassnsimportsklearnfromsklearn.metricsimportconfusion\\_matrixfromsklearn.model\\_selectionimporttrain\\_test\\_splitfromsklearn.preprocessingimportStandardScaler`\n```\n```\n2024-08-20 01:23:52.305388: E external/local\\_xla/xla/stream\\_executor/cuda/cuda\\_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-20 01:23:52.326935: E external/local\\_xla/xla/stream\\_executor/cuda/cuda\\_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-20 01:23:52.333533: E external/local\\_xla/xla/stream\\_executor/cuda/cuda\\_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n```\n```\n`mpl.rcParams['figure.figsize']=(12,10)colors=plt.rcParams['axes.prop\\_cycle'].by\\_key()['color']`\n```\n## Data processing and exploration\n### Download the Kaggle Credit Card Fraud data set\nPandas is a Python library with many helpful utilities for loading and working with structured data. It can be used to download CSVs into a Pandas[DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame).\n**Note:**This dataset has been collected and analysed during a research collaboration of Worldline and the[Machine Learning Group](http://mlg.ulb.ac.be)of ULB (Universit\u00e9 Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available[here](https://www.researchgate.net/project/Fraud-detection-5)and the page of the[DefeatFraud](https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/)project\n```\n`file=tf.keras.utilsraw\\_df=pd.read\\_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')raw\\_df.head()`\n```\n```\n`raw\\_df[['Time','V1','V2','V3','V4','V5','V26','V27','V28','Amount','Class']].describe()`\n```\n### Examine the class label imbalance\nLet's look at the dataset imbalance:\n```\n`neg,pos=np.bincount(raw\\_df['Class'])total=neg+posprint('Examples:\\\\nTotal:{}\\\\nPositive:{}({:.2f}% of total)\\\\n'.format(total,pos,100\\*pos/total))`\n```\n```\nExamples:\nTotal: 284807\nPositive: 492 (0.17% of total)\n```\nThis shows the small fraction of positive samples.\n### Clean, split and normalize the data\nThe raw data has a few issues. First the`Time`and`Amount`columns are too variable to use directly. Drop the`Time`column (since it's not clear what it means) and take the log of the`Amount`column to reduce its range.\n```\n`cleaned\\_df=raw\\_df.copy()# You don't want the `Time` column.cleaned\\_df.pop('Time')# The `Amount` column covers a huge range. Convert to log-space.eps=0.001# 0 =&gt; 0.1\u00a2cleaned\\_df['Log Amount']=np.log(cleaned\\_df.pop('Amount')+eps)`\n```\nSplit the dataset into train, validation, and test sets. The validation set is used during the model fitting to evaluate the loss and any metrics, however the model is not fit with this data. The test set is completely unused during the training phase and is only used at the end to evaluate how well the model generalizes to new data. This is especially important with imbalanced datasets where[overfitting](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting)is a significant concern from the lack of training data.\n```\n`# Use a utility from sklearn to split and shuffle your dataset.train\\_df,test\\_df=train\\_test\\_split(cleaned\\_df,test\\_size=0.2)train\\_df,val\\_df=train\\_test\\_split(train\\_df,test\\_size=0.2)# Form np arrays of labels and features.train\\_labels=np.array(train\\_df.pop('Class')).reshape(-1,1)bool\\_train\\_labels=train\\_labels[:,0]!=0val\\_labels=np.array(val\\_df.pop('Class')).reshape(-1,1)test\\_labels=np.array(test\\_df.pop('Class')).reshape(-1,1)train\\_features=np.array(train\\_df)val\\_features=np.array(val\\_df)test\\_features=np.array(test\\_df)`\n```\nWe check whether the distribution of the classes in the three sets is about the same or not.\n```\n`print(f'Average class probability in training set:{train\\_labels.mean():.4f}')print(f'Average class probability in validation set:{val\\_labels.mean():.4f}')print(f'Average class probability in test set:{test\\_labels.mean():.4f}')`\n```\n```\nAverage class probability in training set: 0.0017\nAverage class probability in validation set: 0.0018\nAverage class probability in test set: 0.0018\n```\nGiven the small number of positive labels, this seems about right.\nNormalize the input features using the sklearn StandardScaler.\nThis will set the mean to 0 and standard deviation to 1.\n**Note:**The`StandardScaler`is only fit using the`train\\_features`to be sure the model is not peeking at the validation or test sets.\n```\n`scaler=StandardScaler()train\\_features=scaler.fit\\_transform(train\\_features)val\\_features=scaler.transform(val\\_features)test\\_features=scaler.transform(test\\_features)train\\_features=np.clip(train\\_features,-5,5)val\\_features=np.clip(val\\_features,-5,5)test\\_features=np.clip(test\\_features,-5,5)print('Training labels shape:',train\\_labels.shape)print('Validation labels shape:',...",
      "url": "https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
    },
    {
      "title": "GitHub - rafiko1/jigsaw-multilingual-competition: TensorFlow code used by the 1st place winner of the 2020 Kaggle multilingual Toxic Comments competition",
      "text": "[Skip to content](https://github.com/rafiko1/jigsaw-multilingual-competition#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/rafiko1/jigsaw-multilingual-competition) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/rafiko1/jigsaw-multilingual-competition) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/rafiko1/jigsaw-multilingual-competition) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[rafiko1](https://github.com/rafiko1)/ **[jigsaw-multilingual-competition](https://github.com/rafiko1/jigsaw-multilingual-competition)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Frafiko1%2Fjigsaw-multilingual-competition) You must be signed in to change notification settings\n- [Fork\\\n0](https://github.com/login?return_to=%2Frafiko1%2Fjigsaw-multilingual-competition)\n- [Star\\\n4](https://github.com/login?return_to=%2Frafiko1%2Fjigsaw-multilingual-competition)\n\n\nTensorFlow code used by the 1st place winner of the 2020 Kaggle multilingual Toxic Comments competition\n\n[4\\\nstars](https://github.com/rafiko1/jigsaw-multilingual-competition/stargazers) [0\\\nforks](https://github.com/rafiko1/jigsaw-multilingual-competition/forks) [Branches](https://github.com/rafiko1/jigsaw-multilingual-competition/branches) [Tags](https://github.com/rafiko1/jigsaw-multilingual-competition/tags) [Activity](https://github.com/rafiko1/jigsaw-multilingual-competition/activity)\n\n[Star](https://github.com/login?return_to=%2Frafiko1%2Fjigsaw-multilingual-competition)\n\n[Notifications](https://github.com/login?return_to=%2Frafiko1%2Fjigsaw-multilingual-competition) You must be signed in to change notification settings\n\n# rafiko1/jigsaw-multilingual-competition\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmaster\n\n[Branches](https://github.com/rafiko1/jigsaw-multilingual-competition/branches) [Tags](https://github.com/rafiko1/jigsaw-multilingual-competition/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[74 Commits](https://github.com/rafiko1/jigsaw-multilingual-competition/commits/master/) |\n| [README.md](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/README.md) | [README.md](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/README.md) |  |  |\n| [post\\_processing\\_example.ipynb](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/post_processing_example.ipynb) | [post\\_processing\\_example.ipynb](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/post_processing_example.ipynb) |  |  |\n| [template-es-it-tr.ipynb](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/template-es-it-tr.ipynb) | [template-es-it-tr.ipynb](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/template-es-it-tr.ipynb) |  |  |\n| [template-pt-ru-fr.ipynb](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/template-pt-ru-fr.ipynb) | [template-pt-ru-fr.ipynb](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/template-pt-ru-fr.ipynb) |  |  |\n| [template-train-bias.ipynb](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/template-train-bias.ipynb) | [template-train-bias.ipynb](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/template-train-bias.ipynb) |  |  |\n| View all files |\n\n## Repository files navigation\n\n### Introduction\n\nThe Tensorflow code released here, was implemented using Kaggle TPUv3 by the 1st place winner of the [2020 Jigsaw Multilingual Kaggle competition](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification). It was the 3rd annual competition organized by the Jigsaw team. It followed [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge), the original 2018 competition, and [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification) in 2019.\n\nThe goal was to run multilingual toxicity predictions on six different languages (i.e. es, tr, it, ru, pt and fr), and promote the usage of TPU.\n\nOur solution is detailed in this [Kaggle forum post](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification/discussion/160862).\n\nThe code is part of the overall solution with another part leveraging similar [Pytorch models](https://github.com/leecming/jigsaw-multilingual) trained locally.\n\n### Recipe for training:\n\n1. Bootstrap test-set predictions (pseudo-labels) for all languages using the\nXLM-Roberta-Large multilingual model (XLM-R)\n2. Train a monolingual/multilingual\nmodel, and predict test-set samples in the relevant language(s)\n3. Blend predictions from the current model with the previous ensemble\npredictions - update pseudo-labels\n4. Repeat steps 2 and 3 with various pretrained monolingual and multilingual\nmodels.\n\nRelevant upgrades to training:\n\n1. Implement pseudolabels togehter with train labels in step 2\n2. Use a post-processing technique\n\nWe provide 3 sets of sample pseudo-labels (scoring on public LB: 9372, 9500, 9537) for you to test training monolingual and multilingual models against.\n\nFor post-processing, we also provide 11 pseudolabels where subsequent Russian labels were updated after training.\n\nYou can refer to the **Data and model files** section below for more info.\n\n### Getting started\n\n- Training a XLM-R Spanish baseline [here](https://www.kaggle.com/rafiko1/1st-place-baseline-xlm-r-es-it-tr)\n- Make use of the post-processing technique on Russian examples [here](https://www.kaggle.com/rafiko1/1st-place-jigsaw-post-processing-example)\n\n### Code\n\n| Training | Comment |\n| --- | --- |\n| [Template for es/it/tr](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/template-es-it-tr.ipynb) | monolingual approach for languages with validation set (es/it/tr). Default model: XLM-R |\n| [Template for pt/ru/fr](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/template-pt-ru-fr.ipynb) | monolingual approach for languages without validation set (pt/ru/fr). Default model: XLM-R |\n| [Template train-bias](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/template-train-bias.ipynb) | monolingual approach using train-bias dataset. Default model: XLM-R |\n\n| Post-processing | Comment |\n| --- | --- |\n| [Post-processing example](https://github.com/rafiko1/jigsaw-multilingual-competition/blob/master/post-processing-example.ipynb) | Post-processing technique using Russian-specific pseudolabels as example |\n\n### Data and model files\n\n1. HuggingFace models are downloaded directly via API so there is no need to manually download them.\n2. Public kernel [Jigsaw TPU: XLM-Roberta](https://www.kaggle.com/xhlulu/jigsaw-tpu-xlm-roberta) that inspired the code (can be used as bootstrap labels)\n3. Translations of the Toxic 2018 dataset and pseudo-labels for public LB 9372, public LB 9500, public LB 9537 can be found [here](https://www.kaggle.com/leecming/multilingual-toxic-comments-training-data).\n4. Translation of the Toxic 2019 Unintended bias dataset is found [here](https://www.kaggle.com/rafiko1/translated-train-bias-all-langs)\n5. Post-processing intended: 11 Russian-specific updated pseudolabels [here](https://www.kaggle.com/rafiko1/ru-changed-subs)\n\n### Notes\n\n1. Below lists the various pretrained HuggingFace transformer models we used -\n\n| Language | Models |\n| --- | --- |\n| All | jplu/tf-xlm-roberta-large |\n| French | camembert-base, camembert/camembert-large, flaubert/flaubert\\_large\\_cased |\n| Italian | dbmdz/bert-base-italian-xxl-cased, dbmdz/bert-base-italian-xxl-uncased, m-polignano-uniba/bert\\_uncased\\_L-12\\_H-768\\_A-12\\_italian\\_alb3rt0 |\n| Portuguese | neuralmind...",
      "url": "https://github.com/rafiko1/jigsaw-multilingual-competition"
    },
    {
      "title": "Jigsaw Unintended Bias in Toxicity Classification \u2014 Kaggle Competition",
      "text": "[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F48c799fe2046&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&source=post_page---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40vaibhavb837%2Fjigsaw-unintended-bias-in-toxicity-classification-kaggle-competition-48c799fe2046&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40vaibhavb837%2Fjigsaw-unintended-bias-in-toxicity-classification-kaggle-competition-48c799fe2046&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n\n# Jigsaw Unintended Bias in Toxicity Classification \u2014 Kaggle Competition\n\n[![Vaibhavb](https://miro.medium.com/v2/da:true/resize:fill:64:64/0*CS05pEhg6ng-uxS7)](https://medium.com/@vaibhavb837?source=post_page---byline--48c799fe2046---------------------------------------)\n\n[Vaibhavb](https://medium.com/@vaibhavb837?source=post_page---byline--48c799fe2046---------------------------------------)\n\nFollow\n\n10 min read\n\n\u00b7\n\nOct 17, 2020\n\n--\n\n1\n\nListen\n\nShare\n\n> Jigsaw is a unit within Google that forecasts and confronts emerging threats, creating future-defining research and technology to keep our world safer.\n\n> The Conversation AI team, a research initiative founded by Jigsaw and Google (both part of Alphabet), builds technology to protect voices in the conversation. A main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful, or otherwise likely to make someone leave a discussion.\n\n# Business Problem:\n\n**Problem source:**\n\n[**Jigsaw Unintended Bias in Toxicity Classification** \\\n\\\n**Detect toxicity across a diverse range of conversations**\\\n\\\nwww.kaggle.com](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/description?source=post_page-----48c799fe2046---------------------------------------)\n\n## Problem statement:\n\nWhen the **Conversation AI** team first built toxicity models, they found that the models incorrectly learned to associate the names of frequently attacked identities with toxicity. Models predicted a high likelihood of toxicity for comments containing those identities (e.g. \u201cgay\u201d), even when those comments were not actually toxic (such as \u201cI am a gay woman\u201d). This happens because training data was pulled from available sources where, unfortunately, certain identities are overwhelmingly referred to in offensive ways. Training a model from data with these imbalances risks simply mirroring those biases back to users.\n\n**Task:** We have to build a model that recognizes toxicity and minimizes this type of unintended bias concerning mentions of identities. We\u2019ll be using a dataset labeled for identity mentions and optimizing a metric designed to measure unintended bias.\n\n**_Disclaimer:_** _The dataset for this competition contains text that may be considered profane, vulgar, or offensive._\n\n## Data collection:\n\n**File descriptions:** Data Size: 0.8 GB\n\n- **train.csv** \u2014 the training set, which includes toxicity labels and subgroups\n- **test.csv**\u2014 the test set, which does not include toxicity labels or subgroups\n- **sample\\_submission.csv** \u2014 a sample submission file in the correct format\n\n## Background:\n\nAt the end of 2017, the [**Civil Comments**](https://medium.com/@aja_15265/saying-goodbye-to-civil-comments-41859d3a2b1d) platform shut down and chose to make their ~2m public comments from their platform available in a lasting open archive so that researchers could understand and improve civility in online conversations for years to come. Jigsaw sponsored this effort and extended annotation of this data by human raters for various toxic conversational attributes.\n\nIn the data supplied for this competition, the text of the individual comment is found in the comment\\_text column. Each comment in Train has a toxicity label (target), and models should predict the target toxicity for the Test data. This attribute (and all others) are fractional values which represent the fraction of human raters who believed the attribute applied to the given comment. For evaluation, the test set examples with target >= 0.5 will be considered to be in a positive class (toxic).\n\n## Competition Evaluation:\n\nThis competition will use a newly developed metric that combines several submatrices to balance overall performance with various aspects of unintended bias.\n\nFirst, we\u2019ll define each submatrix.\n\n**Overall AUC:** This is the ROC-AUC for the full evaluation set.\n\n**Generalized Mean of Bias AUCs:**\n\n**Generalized Mean of Bias AUCs**\n\n**M\u209a** = the _p_ \u1d57\u02b0 power-mean function\n\n**m\u209b** = the bias metric **_m_** calculated for subgroup **_s_**\n\n**N** = number of identity subgroups\n\n> For this competition, we use a p value of -5 to encourage competitors to improve the model for the identity subgroups with the lowest model performance.\n\n## **Final Metric:**\n\n**A** = number of submatrices (3)\n\n**m\u209b**, **\u2090** = bias metric for identity subgroup **_s_** using submatrix **_a_**\n\n**w\u2090** = a weighting for the relative importance of each submatrix; all four **_w_** values set to 0.25\n\n# Loading Data:\n\n```\n# TRAIN DATA\ntrain = pd.read_csv(\u2018project_dataset/train.csv\u2019)# TEST DATA\ntest = pd.read_csv('project_dataset/test.csv')\n```\n\n> **Dimensions:**\n>\n> _Train_\\- (1804874, 45)\n>\n> _Test_ \\- (97320, 2)\n\nTrain Dataset ( **train.head()**)\n\nTest Dataset ( **test.head()**)\n\n**Point:** In this competition, **target** >= 0.5 will be considered to be in a positive class (toxic)\n\n```\nt_c = (train['target'].values>=0.5).astype(np.int).sum()\nprint(\"Total number of toxic comments in the dataset:\", t_c)nt_c = (train['target'].values<=0.5).astype(np.int).sum()\nprint(\"Total number of non-toxic comments in the dataset:\", nt_c)\n```\n\n> Total number of toxic comments in the dataset: 144334\n>\n> Total number of non-toxic comments in the dataset: 1698436\n\nChecking if their\u2019s any null elements in the dataset:\n\n```\ntrain.isnull().sum()\n```\n\n**Note:** There are **1399744** number of null entries in several columns in the training dataset.\n\nThe data also has several additional toxicity subtype attributes. Models do not need to predict these attributes for the competition, they are included as an additional avenue for research. Subtype attributes are:\n\n1. severe\\_toxicity\n2. obscene\n3. threat\n4. insult\n5. identity\\_attack\n6. sexual\\_explicit\n\n**Plotting number of comments VS comment types**\n\nThe dataset is highly imbalanced in nature. Here, we can observe that most of the dataset is clean and we have very few comments where the comment is considered as severely toxic.\n\n**Violin Plot of Comment length and toxicity (0 or 1)**\n\nWe can observe some outliers in the training dataset but the average length of a comment is similar in both the train and test dataset.\n\n**The dataset also provides us the time of comments so we can also check how time has affected the type of comments**\n\nWhat we observe are as follows:\n\n1. White identity in the comments is used the most.\n2. when it comes to religious basis then Muslim identity is used most frequently.\n3. homosexual identity is used most commonly in comments.\n4. comments about transgender people have been commented on most.\n\nWe have done the necessary EDA for our data now let\u2019s build the model to tackle this problem. For this NLP problem, we are going to use LSTM and BERT models.\n\n**What is LSTM?**\n\nLet me put it in simple words, LSTM is **Long short-term memory** networks a type of R...",
      "url": "https://medium.com/@vaibhavb837/jigsaw-unintended-bias-in-toxicity-classification-kaggle-competition-48c799fe2046"
    }
  ]
}