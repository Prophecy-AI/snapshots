{
  "query": "What are the most effective feature engineering techniques specifically for the Random Acts of Pizza dataset? What user behavior patterns and temporal features are most predictive?",
  "results": [
    {
      "title": "ANSWER",
      "text": "The Random Acts of Pizza (RAOP) data set is small (\u2248\u202f5\u202f000 requests) but rich in both textual content and user\u2011level metadata, so the most successful pipelines combine **text\u2011centric engineering** with **social\u2011behavioral and temporal signals**.\n\n**Effective feature\u2011engineering tricks** that consistently raise predictive accuracy are:  \n*\u202fTreat the request **title** as a separate field and give it extra weight (e.g., repeat it 10\u202f\u00d7 before vectorisation)\u202f\u2014\u202fthis boosts signal without adding new data\u202f([berkeley.edu](https://www.ischool.berkeley.edu/sites/default/files/sproject_attachments/w207_final_project_-_raop.pdf)).  \n*\u202fPre\u2011process the raw request body by normalising numbers to a placeholder token (e.g., \u201cNUM\u201d) and stripping non\u2011alphanumeric characters, then extract **n\u2011grams (1\u20113)** and convert them to **TF\u2011IDF vectors**\u202f([berkeley.edu](https://www.ischool.berkeley.edu/sites/default/files/sproject_attachments/w207_final_project_-_raop.pdf)).  \n*\u202fAdd **requester\u2011level numeric features**: total number of posts at the time of the request, net up\u2011votes (up\u2011votes\u202f\u2212\u202fdown\u2011votes), total karma (up\u202f+\u202fdown), and **account age in days**\u202f([berkeley.edu](https://www.ischool.berkeley.edu/sites/default/files/sproject_attachments/w207_final_project_-_raop.pdf)).  \n*\u202fApply **topic modelling or word\u2011embedding representations** (e.g., LDA or BERT) on the request text to capture latent themes that go beyond surface n\u2011grams\u202f([runze.github.io](https://runze.github.io/technical-posts/random-acts-of-pizza)).  \n*\u202fCombine the above with **simple classifiers** (Random Forest, AdaBoost) that handle the high\u2011dimensional TF\u2011IDF space while exploiting the structured numeric cues; reported accuracies reach \u2248\u202f76\u202f% on held\u2011out data\u202f([berkeley.edu](https://www.ischool.berkeley.edu/sites/default/files/sproject_attachments/w207_final_project_-_raop.pdf)).\n\n**Predictive user\u2011behavior patterns and temporal cues** uncovered in the original Stanford analysis are:  \n*\u202fAskers with **higher prior activity** (more posts, higher karma) and **older Reddit accounts** are markedly more likely to receive pizza\u202f([stanford.edu](https://stanford.edu/~jurafsky/pubs/icwsm2014_pizza.pdf)).  \n*\u202fLinguistic signals of **gratitude, evidentiality, and generalized reciprocity** (e.g., \u201cI\u2019m grateful\u201d, \u201cI can pay it forward\u201d) strongly correlate with success\u202f([stanford.edu](https://stanford.edu/~jurafsky/pubs/icwsm2014_pizza.pdf)).  \n*\u202fA clear **narrative of need**\u2014explicitly stating why the requester needs pizza\u2014adds predictive power, as does **demonstrating trustworthiness** (e.g., linking to personal circumstances).  \n*\u202fTemporal features such as **hour\u2011of\u2011day** and **day\u2011of\u2011week** matter: requests posted during peak community activity (evenings, especially weekdays) have higher fulfillment rates\u202f([stanford.edu](http://snap.stanford.edu/class/cs224w-2013/projects2013/cs224w-025-final.pdf)).  \n*\u202fRequests made **closer to the asker\u2019s account creation** (i.e., newer users) tend to be less successful, suggesting that community reputation builds over time\u202f([stanford.edu](https://stanford.edu/~jurafsky/pubs/icwsm2014_pizza.pdf)).\n\nIn practice, the strongest RAOP models therefore fuse **TF\u2011IDF or embedding\u2011based text features (with title weighting and preprocessing)**, **requester activity metrics**, and **simple temporal bins** (hour, weekday) \u2013 all of which capture the behavioral and timing patterns that the literature identifies as most predictive of a pizza grant.",
      "url": ""
    },
    {
      "title": "[PDF] Random Acts of Pizza: Success Factors of Online Requests",
      "text": "Random Acts of Pizza: Success Factors of Online Requests\nTim Althoff and Niloufar Salehi and Tuan Nguyen\n{althoff, niloufar, tylernht}@stanford.edu\nProject Group Number: 25\nAbstract\nMany online communities such as Q&A sites, crowd-funding\nplatforms, and online charities are based on users request\u0002ing from one another and receiving responses from within\nthe community; the success of these requests is critical to the\nsuccess of the community. In this paper, we explore the vari\u0002ous factors that influence success. One of the most interesting\naspects in this regard is how the formulation of the requests\naffects it\u2019s chances of succeeding. We argue that previous at\u0002tempts at unraveling factors of success were complicated by\ntheir diverse nature. We introduce a dataset of several thou\u0002sand of requests over the course of more than two years where\nevery requests asks for the very same, a pizza. This allows us\nto analyze the question of how successful request were made,\nin a way that has not been approached before. Our findings\ninclude that putting in some effort, creating a sense of trust,\nand the constructing the right kind of narrative are signifi\u0002cantly correlated with success.\nIntroduction\nWe live in a time where we increasingly turn to the web for\nhelp. However, our needs often go far beyond what a public\ndomain can offer, we need help from real people. A large\nnumber of platforms allow users to post requests through\nwhich they can ask others for help. Understanding the dy\u0002namics of successful requests is critical in many domains\nsuch as crowdfunding projects for startups on crowdfunding\nplatforms like Kickstarter [4], asking for answers to specific\nquestions on Quora [7] or StackOverflow [9], disadvantaged\npeople asking for loans on social peer to peer lending sites\nsuch as Kiva [5] or donations to non-profits and charities\nsuch as GlobalGiving [3] or Donors Choose [2], and people\nfacing hardship and asking for help on online communities\nsuch as Reddit [8]. Not all of these requests are success\u0002ful however, which raises the question of what differentiates\nthe fortunate. Prior research suggests aspects such as what\nis asked for, how it is asked, and who is asking whom as\nlargely influential in the process.\nWe explore these factors by simplifying some of the com\u0002plexities faced in previous work. In this paper we present\na novel case study of factors of online requests that natu\u0002rally controls for the subject of the request (try asking the\nCopyright \rc 2013, Stanford Social Network Analysis course\nproject (CS224W). All rights reserved.\ninternet for a Ferrari!). Further, we eliminate group dynam\u0002ics by looking at requests that a single person could satisfy.\nMoreover, knowledge gathering platforms discourage dupli\u0002cate requests (questions) and thereby introducing complex\nbiases (particularly, when one is trying to control for con\u0002tent to try to understand how people are asking for it). In\nthis project, we study \u201cRandom Acts of Pizza\u201d, an online\ncommunity devoted to giving away free pizzas to strangers\nthat ask for one. We argue that this is a unique platform for\nour study since all requests ask for the same thing, a pizza.\nCompared to many previously studied settings, the structure\nof textual requests in this particular community is relatively\nsimple. For instance, prior interaction between the requester\nand the giver before the request or during the decision mak\u0002ing process is rare and there are no video messages or com\u0002munication (as on Kickstarter) that have been shown to have\na strong influence on success [28]. Furthermore, it is not dis\u0002couraged to post a request with similar content to an existing\nrequest. This is not the case in the study of online popularity,\nQ&A sites or Kickstarter-like crowdfunding platforms.\nOur contribution in this paper is three-fold: (1) We present\na new dataset of online requests that all ask for the same\nthing and that has, to the best of our knowledge, not been\nsubject to scientific analysis before. (2) We present an anal\u0002ysis of various factors of success for online requests through\nmatching and statistical hypothesis testing. (3) We trans\u0002late our findings into concrete guidelines for the requester\nto maximize her chances of success.\nWe find that several factors are significantly correlated\nwith success of online requests: It helps to put in effort to\nwrite a longer narrative, to create a sense of trust by telling a\npersonal story and including pictures, to signal to give back\nto the community in the future, and to be an active and well\u0002regarded member of the community (see Results section for\nmore details and a discussion)\nThe remainder of this paper is structured as follows. We\nfirst present related work on success of online requests. Then\nthe problem statement and the corresponding dataset is in\u0002troduced. The next section elaborates on several factors that\ncould have an impact on success. We explain our methodol\u0002ogy in Methods section before we summarize our findings\nin the Results section. Lastly, we conclude this paper with\na short discussion and summary and describe avenues for\nfuture work.\nRelated Work\nIn the following, we review related work in the domain of\nonline requests and different factors of success such as con\u0002tent, temporal dynamics, the narrative, user similarity and\nstatus.\nThe Cost Spectrum of Online Interaction\nOnline communities and online social networks allow users\nto interact with each other as well as each other\u2019s content.\nMost will allow you to like or up-vote posts of other people,\nto (re)share them, or to comment on them. These modes of\ninteractions have been studied extensively in the context of\nonline popularity [23, 35]. Often the goal of studying online\npopularity is to understand what drivers user consumption,\nwhat content to display on websites, or how to design \u201cviral\u201d\nmarketing campaigns.\nOne dimension that has (to the best of our knowledge) not\nbeen studied explicitly yet is the cost of these interactions.\nVotes, re-shares and comments are usually free of charge\nand also cost very little time. Thus, the threshold to interact\nin these ways is fairly low and they happen relatively often.\nHowever, other modes of interaction have higher costs. For\ninstance, answering somebody else\u2019s question might take\nconsiderable effort and time, and help funding projects on\ncrowdsourcing platforms or donating to certain non-profits\neven comes at a financial cost. In contrast to the mentioned\nlow cost interactions people specifically ask for a nontrivial\namount of help. The act of asking for something is com\u0002monly called a request (see our problem definition below)\nand have adopted this terminology in this paper.\nHowever, determining the factors that influence popu\u0002larity poses similar challenges in that the content either\nneeds to be modeled explicitely [35] or controlled for [23].\nLakkaraju et al. [23] use resubmissions of the same content\n(in this case a picture) to control for content and study how\nthe title, the community, and the time matter for online pop\u0002ularity. When analyzing factors of success of online requests\nthis \u201ccontent\u201d is very similar to \u201cwhat is being asked for\u201d. In\nthis paper, we attempt to understand how one should ask for\nit by controlling what is being asked for.\nTemporal Dynamics of Successful Requests\nPrevious research has largely focused on crowdfunding plat\u0002forms such as Kickstarter [4] or peer to peer lending sites\nsuch as Prosper [6] and more often studied their temporal\ndynamics rather than the content of the requests. For in\u0002stance, Ceyhan et al. [16] find that loans with some early\nfunding are more likely to get fully funded (coined herd\u0002ing effect). Similar effects were found on Kickstarter when\nmodeling funding success as a time series prediction task\nthat included previous donations as well as social features\nsuch as the number of tweets about the project [18]. Partic\u0002ularly, the last donation to fully fund a project was found\nto exhibit special characteristics such...",
      "url": "http://snap.stanford.edu/class/cs224w-2013/projects2013/cs224w-025-final.pdf"
    },
    {
      "title": "[PDF] Random Acts of Pizza - UC Berkeley School of Information",
      "text": "Random Acts of Pizza\nKevin Foley, Felix Tsui, and Cameron Bell\nBackground\nDataset\n\u25cf 5671 requests\n\u25cf Contains information about:\n\u25cb The post itself (upvotes, downvotes, timing, title)\n\u25cb The requestor\nExploratory Analysis\nExploratory Analysis\nrequest_text_edit_aware\nHi I am in need of food for my 4 children we a...\nI spent the last money I had on gas today. Im ...\nMy girlfriend decided it would be a good idea ...\nIt's cold, I'n hungry, and to be completely ho...\nhey guys:\\n I love this sub. I think it's grea...\nFeature Engineering\nrequest_title\n0 [Request] Colorado Springs Help Us Please\n1 [Request] California, No cash and I could use ...\n2 [Request] Hungry couple in Dundee, Scotland wo...\n3 [Request] In Canada (Ontario), just got home f...\n4 [Request] Old friend coming to visit. Would LO...\nrequester_#_of_posts\n(at request)\n0\n15\n0\n1\n14\nExamples:\nFeature Engineering\n6 methods that were progressively more accurate:\n\u25cf Request text only\n\u25cf Request text and title\n\u25cf Request text and title, with the title weighted (simply repeated 10 times)\n\u25cf Preprocessed data, turning all numbers into \u2018NUM\u2019 and removing\nnon-alphanumeric characters\n\u25cf Preprocessed 3 n-gram data\n\u25cf Preprocessed data, transformed into TF-IDF vectors\nFeature Engineering\nWe also added numerical values about the requester into our model:\ntraining_features = [\n'requester_number_of_posts_at_request',\n'requester_upvotes_plus_downvotes_at_request',\n'requester_upvotes_minus_downvotes_at_request',\n'requester_account_age_in_days_at_request']\nMachine Learning Algorithms\nBaseline: K Nearest Neighbors\n\u25cf Pros\n\u25cb Simple to implement\n\u25cb Easy to understand\n\u25cb Does not require training\n\u25cf Cons\n\u25cb Difficult to choose the best distance metric (cosine, pythagorean)\n\u25cb Can be slow\n\u25cf Accuracy = 0.75\nRandom Forest\n\u25cf Pros\n\u25cb Easy to understand\n\u25cb Excels with nonlinear boundaries\n\u25cf Cons\n\u25cb Can tend to overfit (if not pruned well)\n\u25cf Accuracy = 72.77%\nAdaBoost\n(Adaptive Boosting)\n\u25cf Pros\n\u25cb Easy implementation (\u201cout of the box\u201d)\n\u25cb Reduces dimensionality and focuses on difficult-to-classify samples\n\u25cf Cons\n\u25cb Weak classifiers included in the model can bring down accuracy without pruning\n\u25cf Accuracy = 76 %\nLogistic Regression\n\u25cf Pros\n\u25cb Simple to implement\n\u25cb Flexible, works with probabilities\n\u25cf Cons\n\u25cb Not super intuitive\n\u25cf Accuracy = 51.92 %\nNaive Bayes\n\u25cf Pros\n\u25cb Works with probabilities (great for our problem!)\n\u25cb Very fast computation (algorithm is computer-friendly)\n\u25cf Cons\n\u25cb Assumes that all features are independent of each other\n\u25cf Accuracy = 76.1 %\nRNN LSTM Neural Network\n\u25cf Pros\n\u25cb Unsupervised (automatic feature engineering)\n\u25cb Powerful\n\u25cf Cons\n\u25cb \u201cBlack Box\u201d\n\u25cb Can overfit\n\u25cf Accuracy: 76.11 %\nCombined\nWe combined:\n\u25cf K-Nearest Neighbors (on text and title)\n\u25cf K-Nearest Neighbors (on preprocessed text and title)\n\u25cf Random Forest\n\u25cf Adaboost\n\u25cf Logistic Regression\nAccuracy = 76.36 %\nThank you!",
      "url": "https://www.ischool.berkeley.edu/sites/default/files/sproject_attachments/w207_final_project_-_raop.pdf"
    },
    {
      "title": "Random acts of pizza - a Kaggle competition",
      "text": "- [Home](https://runze.github.io/)\n- [Technical Posts](https://runze.github.io/technical-posts/)\n- [Other Musings](https://runze.github.io/other-musings/)\n- [About](https://runze.github.io/about/)\n- [GitHub](https://github.com/Runze)\n- [LinkedIn](https://www.linkedin.com/in/runze-wang/)\n\nBuilt with\u00a0[Hugo](https://gohugo.io/)Theme\u00a0[Blackburn](https://github.com/yoshiharuyamashita/blackburn)\n\n2014-08-19\n\n[Kaggle](https://runze.github.io/tags/kaggle)\u00a0/\n[Machine learning](https://runze.github.io/tags/machine-learning)\u00a0/\n[R](https://runze.github.io/tags/r)\u00a0/\n[Text mining](https://runze.github.io/tags/text-mining)\n\nThis weekend, I participated in a Kaggle not-for-prize competition that uses data obtained from Reddit\u2019s Random Acts of Pizza [forum](http://www.reddit.com/r/Random_Acts_Of_Pizza/)\u00a0to analyze and predict the outcome of a request for pizza, and it was _heaps_ of fun (I always wanted to say that)! Compared with other Kaggle competitions I had tried before, I found this one\u00a0a bit easier because\u00a0the dataset is not very large (~5,000 records) and is hence perfect for model experimenting, and, more importantly, the competition is based on a real\u00a0[research](http://cs.stanford.edu/~althoff/raop-dataset/altruistic_requests_icwsm.pdf) done by a couple Stanford researchers, which provides me with a lot of guidelines in how to proceed. As my first shot, following the\u00a0paper, I replicated their\u00a0study by constructing\u00a0the same set of variables, and used\u00a0them to train a few predictive models. The result, .69 ROC, landed me at [No. 13](https://www.kaggle.com/c/random-acts-of-pizza/leaderboard) (out of 110)! I have put all my code on [github](https://github.com/Runze/pizza) (including the part related to topic modeling and data exploration) and here is a detailed explanation of what I did.\n\n**Topic modeling**\n\nFollowing the authors\u2019 strategy, the first thing I did was mining the requests (as it turned out, there are a fair amount of posts with blank content. Hence, I concatenated the request content\u00a0with the request title). After cleaning them up, removing stop words and keeping only nouns (using the [openNLP](http://cran.r-project.org/web/packages/openNLP/openNLP.pdf) package), I created a document-term matrix (DTM) using them and removed the very high- and low-frequency words (as they don\u2019t\u00a0help separate\u00a0topics) using the\u00a0[term frequency\u2013inverse document frequency](http://en.wikipedia.org/wiki/Tf%E2%80%93idf)\u00a0(tf-idf)\u00a0metric (per the method and code\u00a0described in this [vignette](http://cran.r-project.org/web/packages/topicmodels/vignettes/topicmodels.pdf)). Using this trimmed DTM, I applied the\u00a0[Latent Dirichlet allocation](http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) (LDA) algorithm from the topicmodels package (again per the vignette linked above) to identify topics. Note in the paper, the authors used \u201cnon-negative matrix factorization (NMF)\u201d to perform topic modeling. However, I wasn\u2019t able to find a package in R to do that. That aside, the 10 buckets of topics I got are not as clearly defined and distinguished as those found by the authors. In fact, I couldn\u2019t\u00a0see any clear-cut difference in the frequent terms used in my\u00a0topics at all.\u00a0Curious, I tried to find the optimal number of topics through a 10-fold cross-validation and evaluated the resulting split using perplexity, which, as defined in the vignette, uses the log likelihood and shares an inverse relationship with it (hence, the lower the perplexity the better the model fits).\u00a0Funnily, the results, as shown below, suggest 10 is indeed the optimal split (in the range of 2 to 10):\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/perplex.jpg)\n\nPerhaps a little hard to see, but 8 out of 10 cross-validation holdout sets picked 10 as the optimal value.\u00a0Here are the most frequent terms used in the 10\u00a0topics identified by my model:\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda10.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda9.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda8.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda7.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda6.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda5.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda4.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda3.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda2.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda1.png)\n\nAlthough there are some patterns detected such as financial difficulties, family, parties, and so on, they are far less clear than\u00a0those identified by the paper. Besides the different algorithms\u00a0used, it may as\u00a0well\u00a0be that the authors performed more sophisticated cleaning and mining than I did. Out of curiosity, in addition to topic modeling, I also tried simple spherical k-means which, by default, restricts one document to only\u00a0one cluster and hence forces the \u201ctopic\u201d separation. As a result, my resulting 5 clusters (not shown here) are more different from each other and the patterns are closer to those found by the authors. Nevertheless, topic modeling\u00a0was _heaps_ of fun!\n\n**Create and explore variables**\n\nFollowing the authors\u2019 methodology, I created the same set of variables that\u00a0they used in their logistic regression. With regard to what these variables are, what they represent, and how they are constructed, please refer to the original paper. Here, I\u2019ll just show their relationship with the success rate of the pizza request. First, let\u2019s look at the 5 narrative buckets created using the key words suggested by the authors. They are created by matching the requests against those key words using regular expressions, counting the frequencies, dividing those by the total\u00a0length of the request (including the title), and converted them into deciles. Here are the relationships between the deciles and the success rate for each bucket (the 0 deciles shown below\u00a0represent the requests that do not have any key words for a particular bucket):\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/narrative.jpg)\n\nInterestingly, with the exception of money and craving,\u00a0these narrative categories do not exhibit a clear linear relationship with the outcome. One\u00a0of the reasons is that no other factors that may drive the outcome are\u00a0controlled yet. At least for those that do show a clear trend, the relationship is in line with what the study has found (e.g., more mentions of money troubles lead to a greater chance of success whereas more mentions of craving lead to the opposite).\n\nThe other\u00a0variables are more straightforward and their outcome is also more intuitive. Hence, I\u2019ll just show their relationship with the success rate\u00a0here. You can find the creation process in my code linked above.\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/explore.jpeg)\n\n**Training models**\n\nNow that we have all the variables, we can finally train some models! The first model I tried is the same logistic regression used by the authors. Even without the paper, I think logistic regression, or linear regression in general, should always be the first thing to try because its inference\u00a0power is very\u00a0valuable in understanding the relationship between the explanatory\u00a0variables and the outcome. Even if prediction is the sole purpose, I think it\u2019s necessary, not to mention fun, to understand what the model can tell us about the hidden relationships. Here are the coefficients and their statistical significance I got from the logit\u00a0model:\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/screenshot.png)\n\nComparing with the paper, I found my\u00a0results are generally in line with the\u00a0authors\u2019. Specifically, we both found that gratitude, hyperlink (e.g., image), reciprocity, request length, karma, whether...",
      "url": "https://runze.github.io/technical-posts/random-acts-of-pizza"
    },
    {
      "title": "",
      "text": "How to Ask for a Favor: A Case Study on the Success of Altruistic Requests\nTim Althoff\u2217, Cristian Danescu-Niculescu-Mizil\u2020, Dan Jurafsky\u2217\n\u2217Stanford University, \u2020Max Planck Institute SWS\nalthoff|jurafsky@stanford.edu, cristian@mpi-sws.org\nAbstract\nRequests are at the core of many social media systems such\nas question & answer sites and online philanthropy commu\u0002nities. While the success of such requests is critical to the\nsuccess of the community, the factors that lead community\nmembers to satisfy a request are largely unknown. Success\nof a request depends on factors like who is asking, how they\nare asking, when are they asking, and most critically what\nis being requested, ranging from small favors to substantial\nmonetary donations. We present a case study of altruistic re\u0002quests in an online community where all requests ask for the\nvery same contribution and do not offer anything tangible in\nreturn, allowing us to disentangle what is requested from tex\u0002tual and social factors. Drawing from social psychology liter\u0002ature, we extract high-level social features from text that op\u0002erationalize social relations between recipient and donor and\ndemonstrate that these extracted relations are predictive of\nsuccess. More specifically, we find that clearly communicat\u0002ing need through the narrative is essential and that linguistic\nindications of gratitude, evidentiality, and generalized reci\u0002procity, as well as high status of the asker further increase the\nlikelihood of success. Building on this understanding, we de\u0002velop a model that can predict the success of unseen requests,\nsignificantly improving over several baselines. We link these\nfindings to research in psychology on helping behavior, pro\u0002viding a basis for further analysis of success in social media\nsystems.\n1 Introduction\nWe live in a time where people increasingly turn to the\nweb for help. Our needs, however, often go far beyond\nmere information from existing webpages and we need\nhelp from real people. For example, we ask for answers to\nspecific questions on StackOverflow.com, for donations on\nDonorsChoose.org, or for help on online social communi\u0002ties such as Reddit.com. In each of these cases a user per\u0002forms a request, which we define as an act of asking for\u0002mally for something. All these communities rely heavily on\ntheir members to help satisfy the request. Yet, the factors\nthat lead community members to satisfy a request remain\nlargely unknown. Understanding the dynamics and factors\nof successful requests has the potential to substantially im\u0002prove such communities by educating users about better for\u0002Copyright \u20ddc 2014, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nmulating requests and promoting likely-to-succeed requests\n(Greenberg et al. 2013; Mitra and Gilbert 2014). In addi\u0002tion to these practical benefits, understanding the factors that\nmake a request successful has implications for questions in\nsocial psychology and linguistic pragmatics.\nStudies on the popular crowdfunding platform Kickstarter\nhave shown that the success of a request depends most\ncrucially on what is being requested, that is, whether it\nis a small favor like an answer to a simple question or a\nlarge financial contribution (Mitra and Gilbert 2014; Mol\u0002lick 2014). Many other factors need to be controlled as well;\nwhat the giver receives in return, when they are asking, and\neven group dynamics, since people are more likely to give\nto projects that others are already giving to (Etter, Gross\u0002glauser, and Thiran 2013; Ceyhan, Shi, and Leskovec 2011;\nMitra and Gilbert 2014). Satisfying a request on peer-to-peer\nlending or crowd-funding platforms can also bring a reward,\nand this also can drive the selection process. It is extremely\ndifficult to disentangle the effects of all these factors in deter\u0002mining what makes people satisfy requests, and what makes\nthem select some requests over others.\nIn this paper, we develop a framework for controlling for\neach of these potential confounds while studying the role\nof two aspects that characterize compelling requests: social\nfactors (who is asking and how the recipient is related to\nthe donor and community) and linguistic factors (how they\nare asking and what linguistic devices accompany successful\nrequests). With the notable exception of Mitra and Gilbert\n(2014), the effect of language on the success of requests has\nlargely been ignored thus far.1\nOur goal is to understand what motivates people to give\nwhen they do not receive anything tangible in return. That is,\nwe focus on the important special case of altruistic requests\nin which the giver receives no rewards. This controls for the\nincentive to obtain attractive rewards commonly offered on\ncrowdfunding sites such as Kickstarter; the absence of exter\u0002nal factors such as tangible rewards also makes the language\nitself all the more important in persuading others to help. In\nthis domain we also do not need to consider crowdfunding\u0002related marketing strategies such as emphasizing limited\n1Linguistic factors have also been considered to influence the\nresponse quantity, quality, and speed to questions in online com\u0002munities and social networks (Teevan, Morris, and Panovich 2011;\nBurke et al. 2007, inter alia).\ntime offers (scarcity) or showing that other people made the\nsame decision already (social proof) (Cialdini 2001), which\nare known to manifest themselves in language (Mitra and\nGilbert 2014). Second, we focus on requests that a single\nuser can fulfill, thereby additionally eliminating group be\u0002havior effects such as herding (Ceyhan, Shi, and Leskovec\n2011) or completing donation biases (Wash 2013). Finally,\nwe focus on one community in which what is being asked\nfor is held constant. This allows us to explore a large num\u0002ber of different requests of different individual users, at dif\u0002ferent times, that all have the same goal. Controlling for the\nrequest goal therefore allows us to study how to optimize a\nparticular request solely by optimizing its presentation, and\nhelps provide a direct practical benefit to the requester (by\ncontrast, advising a requester who needs something to in\u0002stead ask for something different may be advice of limited\npractical use).\nWe therefore chose to study donations in \u201cRandom Acts\nof Pizza\u201d, an online community devoted to giving away free\npizza to strangers that ask for one. Random Acts of Pizza2\n(RAOP) is a community within the social news and enter\u0002tainment website Reddit.com. Users can submit requests for\nfree pizza and if their story is compelling enough a fellow\nuser might decide to send them one, \u201cbecause... who doesn\u2019t\nlike helping out a stranger? The purpose is to have fun, eat\npizza and help each other out. Together, we aim to restore\nfaith in humanity, one slice at a time.3\u201d A typical post might\nsound something like this: \u201cIt\u2019s been a long time since my\nmother and I have had proper food. I\u2019ve been struggling to\nfind any kind of work so I can supplement my mom\u2019s so\u0002cial security... A real pizza would certainly lift our spirits\n(Berman 2011).\u201d\nThis platform addresses many of the potential confounds\nthat complicate other platforms or studies: all requests ask\nfor the same thing, a pizza, there are no additional incen\u0002tives or rewards, each request is satisfied by a single user,\nusers and requests are embedded in a social network within\nReddit, and requests are largely textual. This dataset thus\nprovides us with an unusually clear picture of the effect of\nlanguage and social factors on success.\nThe remainder of this paper is organized as follows: in\u0002spired by studies in crowdfunding, user-to-user evaluations\nin social networks, and helping behavior in social psychol\u0002ogy, we introduce a variety of textual and social factors that\nare potentially associated with successful requests. We use\ntopic modeling and automatic detection to extract a particu\u0002larly complex factor, the narrative structure of requests. We\nemploy a logistic regression framework to test...",
      "url": "https://stanford.edu/~jurafsky/pubs/icwsm2014_pizza.pdf"
    },
    {
      "title": "8 Feature Engineering Techniques for Machine Learning - ProjectPro",
      "text": "8 Feature Engineering Techniques for Machine Learning\n# 8 Feature Engineering Techniques for Machine Learning\nCrack the code of feature engineering and gain a competitive edge in data science with this comprehensive guide on Feature Engineering techniques for ML. | ProjectPro\n[Get access to all Machine Learning Projects](https://www.projectpro.io/project/project-demo?source=blogGetAccessMobstac&utm_source=blog423&utm_medium=leadformbutton&utm_campaign=mobstac)[View all Machine Learning Projects](https://www.projectpro.io/projects/data-science-projects/machine-learning-projects-in-python?utm_source=blog423&utm_medium=projectpagebutton&utm_campaign=mobstac)\n![8 Feature Engineering Techniques for Machine Learning](https://daxg39y63pxwu.cloudfront.net/images/blog/8-feature-engineering-techniques-for-machine-learning/Feature_Engineering_in_ML.webp)\nLast Updated: 28 Oct 2024[| BY ProjectPro](https://www.projectpro.io/blog/author/projectpro)\nWant to make your machine learning models more accurate? Try feature engineering! This blog post will discuss how feature engineering helps transform your data into features your ML models will love.\n[![data_science_project ]()](https://www.projectpro.io/project-use-case/real-estate-price-prediction-model-using-fastapi-and-heroku?utm_source=423&amp;utm_medium=fold1)\n**Build Real Estate Price Prediction Model with NLP and FastAPI**\nDownloadable solution code | Explanatory videos | Tech Support\n[Start Project](https://www.projectpro.io/project-use-case/real-estate-price-prediction-model-using-fastapi-and-heroku?utm_source=423&amp;utm_medium=fold1)\nImagine you are a chef preparing a gourmet meal. You can't just toss random ingredients together and expect a masterpiece,*right*? The same principle applies to feature engineering for machine learning. Welcome to our feature-packed guide on Feature Engineering techniques for machine learning. Just as the right blend of spices can elevate a dish, feature engineering in machine learning is the secret ingredient that transforms raw data into meaningful insights. From automatically extracting features and valuable information from any text to handling missing values and creating powerful interaction features, we will equip you with a list of feature engineering techniques to enhance your data science and machine learning projects. Get ready to become the master chef of your[predictive models](https://www.projectpro.io/article/predictive-modelling-techniques/598)!\n![Image for Feature Engineering Techniques in ML]( \"Feature Engineering Techniques\")\n## Table of Contents\n* [What Is Feature Engineering For Machine Learning?](#mcetoc_1h5hf6njgaa)\n* [Why Is Feature Engineering Important For Machine Learning?](#mcetoc_1h5hf6njgaf)\n* [Feature Engineering Techniques For Machine Learning -Deconstructing The &lsquo;Art&rsquo;](#mcetoc_1h5hf6njgag)\n* [Feature Engineering Python-A Sweet Takeaway!](#mcetoc_1h5hf6njgap)\n* [Master Feature Engineering Techniques With ProjectPro](#mcetoc_1h5hf6njgaq)\n* [FAQs On Feature Engineering Techniques](#mcetoc_1h5hf6njgar)\n## **What Is Feature Engineering For Machine Learning?**\nBefore moving straight on to feature engineering, let us get a quick overview of features and the various types of features in machine learning.\n### **What Are Features In Machine Learning?**\nMachine learning algorithms are designed to process large amounts of data and identify useful patterns for making predictions or decisions. In supervised learning, features are the algorithm's input variables to make predictions. For example, in a spam filter, the features include the sender's email address, the subject line, the message content, and so on. By analyzing these features, the machine learning algorithm can determine whether the email will likely be spam. In unsupervised learning, features are used to identify data patterns without predefined labels or categories. For instance, features might be used in a[clustering](https://www.projectpro.io/article/clustering-projects-in-machine-learning/636)algorithm to group similar data points based on their shared characteristics.\n### **Types of Features in Machine Learning**\nFeatures in machine learning can roughly be termed as the building blocks of any machine learning model and the input variables that a machine learning algorithm uses to make predictions or decisions. Here are the different types of features in machine learning-\n* **Numerical Features-**These features are continuous values that can be measured on a scale. Examples of numerical features include age, height, weight, and income. Numerical features can be used in machine learning algorithms directly.\n* **Categorical Features-**These features are discrete values that can be grouped into categories. Examples of categorical features include gender, color, and zip code. Categorical features in machine learning typically need to be converted to numerical features before they can be used in machine learning algorithms. You can easily do this using one-hot, label, and ordinal encoding.\n* **Time-series Features-**These features are measurements that are taken over time. Time-series features include stock prices, weather data, and sensor readings. You can use these features to train machine learning models that can predict future values or identify patterns in the data.\n* **Text Features-**These features are text strings that can represent words, phrases, or sentences. Examples of text features include product reviews, social media posts, and medical records. You can use text features to train machine learning models that can understand the meaning of text or classify text into different categories.\nThe type of feature that is most suitable for a particular machine-learning task will depend on the specific problem that is being solved. For example, if you are trying to predict the price of a house, you might use numerical features such as the size of the house, the number of bedrooms, and the house's location. If you classify a piece of text as spam or not, you might use text features such as the words used in the text and the order in which they are used.\n[![ProjectPro Free Projects on Big Data and Data Science]( \"ProjectPro Free Projects on Big Data and Data Science\")](https://www.projectpro.io/project/project-demo?utm_source=Blog423&amp;utm_medium=ProductValue)\n### **How To Select Features in Machine Learning?**\nSelecting the right features is crucial for ensuring the effectiveness of a machine-learning model. The choice of features can significantly impact the accuracy and efficiency of the model.\nOne way to select features is by using domain knowledge. For example, if you are building a spam filter, you know that certain words or phrases are more commonly used in spam emails than legitimate ones. You can use this knowledge to include those words or phrases as features in the model.\nAnother approach involves feature extraction and selection techniques such as correlation analysis, principal components analysis (PCA), or recursive feature elimination (RFE). These techniques help you identify the most relevant features of the model while ignoring irrelevant or redundant ones.\nHere are some tips on how to select the most appropriate features in machine learning-\n* You must understand the problem you are trying to solve. Try to answer the questions, &lsquo;what are the features that are most relevant to the problem?&rsquo;, &lsquo;what features are likely to be most predictive of the target variable?&rsquo;, etc.\n* You need to explore the data. You must look at the distribution of the features and see if there are any outliers or missing values. You may need to clean the data or remove features that are not informative.\n* You need to use feature selection techniques. Several[feature selection techniques](https://www.projectpro.io/article/feature-selection-methods-in-machine-learning/562), such as filter, wrapper, and embedded methods, are available. Each technique has strengths and we...",
      "url": "https://www.projectpro.io/article/8-feature-engineering-techniques-for-machine-learning/423"
    },
    {
      "title": "Random Acts of Pizza - Kaggle",
      "text": "Checking your browser - reCAPTCHA\nChecking your browser before accessing www.kaggle.com ...\nClick[here](#)if you are not automatically redirected after 5 seconds.",
      "url": "https://www.kaggle.com/c/random-acts-of-pizza"
    },
    {
      "title": "Pizza data test - Kaggle",
      "text": "Checking your browser - reCAPTCHA\nChecking your browser before accessing www.kaggle.com ...\nClick[here](#)if you are not automatically redirected after 5 seconds.",
      "url": "https://www.kaggle.com/code/zhichaoking/pizza-data-test"
    },
    {
      "title": "GitHub - miketp333/Random_Acts_of_Pizza_Machine_Learning",
      "text": "[Skip to content](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[miketp333](https://github.com/miketp333)/ **[Random\\_Acts\\_of\\_Pizza\\_Machine\\_Learning](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Fmiketp333%2FRandom_Acts_of_Pizza_Machine_Learning) You must be signed in to change notification settings\n- [Fork\\\n0](https://github.com/login?return_to=%2Fmiketp333%2FRandom_Acts_of_Pizza_Machine_Learning)\n- [Star\\\n1](https://github.com/login?return_to=%2Fmiketp333%2FRandom_Acts_of_Pizza_Machine_Learning)\n\n\n[1\\\nstar](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/stargazers) [0\\\nforks](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/forks) [Branches](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/branches) [Tags](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tags) [Activity](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/activity)\n\n[Star](https://github.com/login?return_to=%2Fmiketp333%2FRandom_Acts_of_Pizza_Machine_Learning)\n\n[Notifications](https://github.com/login?return_to=%2Fmiketp333%2FRandom_Acts_of_Pizza_Machine_Learning) You must be signed in to change notification settings\n\n# miketp333/Random\\_Acts\\_of\\_Pizza\\_Machine\\_Learning\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmaster\n\n[Branches](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/branches) [Tags](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[30 Commits](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/commits/master/) |\n| [.ipynb\\_checkpoints](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tree/master/.ipynb_checkpoints) | [.ipynb\\_checkpoints](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tree/master/.ipynb_checkpoints) |  |  |\n| [Data](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tree/master/Data) | [Data](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tree/master/Data) |  |  |\n| [Old](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tree/master/Old) | [Old](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tree/master/Old) |  |  |\n| [README.md](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/blob/master/README.md) | [README.md](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/blob/master/README.md) |  |  |\n| [final\\_project.ipynb](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/blob/master/final_project.ipynb) | [final\\_project.ipynb](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/blob/master/final_project.ipynb) |  |  |\n| View all files |\n\n## Repository files navigation\n\n## Random Acts of Pizza\n\n##### by Garber Boris, Josiah McDonald and Michael Powers\n\n##### July 2018\n\nThis dataset contains 5671 textual requests for pizza from the Reddit community Random Acts of Pizza together with their outcome (successful/unsuccessful) and meta-data. We use multiple machine learning approaches to build models that predict if a request will be successful or not. Some of our methods rely on the paper How to Ask for a Favor: A Case Study on the Success of Altruistic Requests (Althoff et al., 2014).\n\nSource Data: [https://www.kaggle.com/c/random-acts-of-pizza](https://www.kaggle.com/c/random-acts-of-pizza)\n\nSource Paper: [https://cs.stanford.edu/~althoff/raop-dataset/altruistic\\_requests\\_icwsm.pdf](https://cs.stanford.edu/~althoff/raop-dataset/altruistic_requests_icwsm.pdf)\n\n## About\n\nNo description, website, or topics provided.\n\n### Resources\n\n[Readme](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning#readme-ov-file)\n\n[Activity](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/activity)\n\n### Stars\n\n[**1**\\\nstar](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/stargazers)\n\n### Watchers\n\n[**4**\\\nwatching](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/watchers)\n\n### Forks\n\n[**0**\\\nforks](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fmiketp333%2FRandom_Acts_of_Pizza_Machine_Learning&report=miketp333+%28user%29)\n\n## [Releases](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/releases)\n\nNo releases published\n\n## [Packages\\ 0](https://github.com/users/miketp333/packages?repo_name=Random_Acts_of_Pizza_Machine_Learning)\n\nNo packages published\n\n## [Contributors\\ 3](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/graphs/contributors)\n\n## Languages\n\n- [Jupyter Notebook100.0%](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/search?l=jupyter-notebook)\n\nYou can\u2019t perform that action at this time.",
      "url": "https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning"
    }
  ]
}