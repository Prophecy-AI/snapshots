{
  "query": "What are the optimal hyperparameters for LightGBM in text classification tasks with high-dimensional sparse features like TF-IDF?",
  "results": [
    {
      "title": "ANSWER",
      "text": "LightGBM works especially well on TF\u2011IDF matrices because its histogram\u2011based algorithm and **exclusive feature bundling** can compress millions of sparse columns into a compact representation, keeping training fast and memory\u2011efficient ([lightgbm.readthedocs.io](https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html)). When the data consist of high\u2011dimensional, mostly\u2011zero vectors, it is important to control tree complexity and regularisation so that the model does not over\u2011fit the many rare terms.\n\nFor text\u2011classification tasks the following hyper\u2011parameter settings are widely regarded as a good starting point:\n\n* **`objective` = `multiclass`** (or `binary` for two\u2011class problems) and **`metric` = `multi_logloss`** \u2013 let LightGBM pick the right loss automatically ([Stack\u202fOverflow example](https://stackoverflow.com/questions/50250432/python-lightgbm-text-classicication-with-tfidf)).  \n* **`learning_rate`**\u202f\u2248\u202f0.05\u20130.1 combined with **`num_iterations`** (or `num_boost_round`)\u202f\u2248\u202f500\u20132000 and **`early_stopping_rounds`**\u202f\u2248\u202f50\u2013100 to avoid unnecessary boosting.  \n* **`num_leaves`**\u202f\u2248\u202f30\u201380 and **`max_depth`**\u202f\u2248\u202f7\u201312.  A smaller `num_leaves` than the theoretical `2^max_depth` curbs the depth\u2011wise explosion of leaf\u2011wise growth and reduces over\u2011fitting on sparse data ([Parameters\u2011Tuning guide](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html)).  \n* **`min_data_in_leaf`** (alias `min_child_samples`)\u202f\u2248\u202f20\u2013100; higher values are safer when the training set is modest (\u2248\u202f600\u202fsamples in the example) because each leaf must contain enough non\u2011zero features to be reliable ([Parameters\u2011Tuning guide](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html)).  \n* **`feature_fraction`**\u202f\u2248\u202f0.8 and **`bagging_fraction`**\u202f\u2248\u202f0.8 with **`bagging_freq`**\u202f=\u202f5\u201310 \u2013 random sub\u2011sampling of features and rows improves generalisation on high\u2011dimensional vocabularies ([Beginner\u2019s Guide](https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702)).  \n* **`lambda_l1`**\u202f=\u202f0.0\u20130.5 and **`lambda_l2`**\u202f=\u202f0.0\u20130.5 for L1/L2 regularisation, which further dampens the influence of noisy rare terms.  \n* **`max_bin`**\u202f\u2248\u202f255 (default) works well; lowering it (e.g., 127) can speed up training without hurting accuracy when the TF\u2011IDF values are already discretised.  \n* Keep **`zero_as_missing` = false** (the default) so that the many zeros in a TF\u2011IDF matrix are treated as genuine \u201cterm absent\u201d values rather than missing data ([Advanced\u2011Topics](https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html)).  \n\nBecause the optimal region can vary with corpus size and label distribution, many practitioners run an automated search (e.g., Optuna or FLAML) over the ranges above to fine\u2011tune the model ([Optuna integration](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html)). Starting with these defaults usually yields a strong baseline for TF\u2011IDF\u2011based text classification, after which a modest grid or Bayesian search can push performance further.",
      "url": ""
    },
    {
      "title": "Beginner's Guide to the Must-Know LightGBM Hyperparameters",
      "text": "Beginner&#039;s Guide to the Must-Know LightGBM Hyperparameters | Towards Data Science\n[![Towards Data Science](https://towardsdatascience.com/wp-content/uploads/2025/02/TDS-Vector-Logo.svg)](https://towardsdatascience.com/)\nPublish AI, ML &amp; data-science insights to a global community of data professionals.\nSign in\n[Submit an Article](https://contributor.insightmediagroup.io/)\n* [LinkedIn](https://www.linkedin.com/company/towards-data-science/?originalSubdomain=ca)\n* [X](https://x.com/TDataScience)\nToggle Search\nSearch\n[Data Science](https://towardsdatascience.com/category/data-science/)\n# Beginner&#8217;s Guide to the Must-Know LightGBM Hyperparameters\nThe most important LightGBM parameters, what they do, and how to tune them\n[Leonie Monigatti](https://towardsdatascience.com/author/iamleonie/)\nMar 7, 2023\n5 min read\nShare\n![Knobs for tuning LightGBM hyperparameters (Image by the author)](https://towardsdatascience.com/wp-content/uploads/2023/03/1gDW1lYGGBn1fIF-kscw06g@2x.jpeg)Knobs for tuning LightGBM hyperparameters (Image by the author)\n[LightGBM](https://lightgbm.readthedocs.io/en/latest/index.html)is a popular gradient-boosting framework. Usually, you will begin specifying the following**core parameters**:\n* `objective`and`metric`for your problem setting\n* `seed`for reproducibility\n* `verbose`for debugging\n* `num\\_iterations`,`learning\\_rate`, and`early\\_stopping\\_round`for training\nBut where do you go from here?[LightGBM](https://lightgbm.readthedocs.io/en/latest/index.html)has over 100 parameters [2] that can be tuned. Additionally, each parameter has one or more aliases, which makes it difficult for beginners to get a clear picture of the essential parameters.\nThus, this article discusses the most important and commonly used[LightGBM](https://lightgbm.readthedocs.io/en/latest/index.html)hyperparameters, which are listed below:\n* [Tree Shape](#1b4c)&#8211;`num\\_leaves`and`max\\_depth`\n* [Tree Growth](#cd6f)&#8211;`min\\_data\\_in\\_leaf`and`min\\_gain\\_to\\_split`\n* [Data Sampling](#85d1)&#8211;`bagging\\_fraction`,`bagging\\_freq`, and`feature\\_fraction`\n* [Regularization](#2d6f)&#8211;`lambda\\_l1`and`lambda\\_l2`\nIn the following, the default values are taken from the[documentation](https://lightgbm.readthedocs.io/en/latest/Parameters.html)[2], and the recommended ranges for hyperparameter tuning are referenced from the[article](https://towardsdatascience.com/kagglers-guide-to-lightgbm-hyperparameter-tuning-with-optuna-in-2021-ed048d9838b5)[5] and the books [1] and [4].\n## Tree Shape\nIn contrast to[XGBoost](https://xgboost.readthedocs.io/en/stable/),[LightGBM](https://lightgbm.readthedocs.io/en/latest/index.html)grows the decision trees**leaf-wise**instead of level-wise. You can use`num\\_leaves`and`max\\_depth`to control the size of a single tree.\n![Specifying LightGBM tree shape with num_leaves and max_depth (Image by the author)](https://towardsdatascience.com/wp-content/uploads/2023/03/1TsBtl2sSMQXPOrsEupUzHQ.jpeg)Specifying LightGBM tree shape with num\\_leaves and max\\_depth (Image by the author)\nThe parameter`num\\_leaves`controls the maximum number of leaves in one tree [2].\n* Default: 31\n* Good starting point for baseline: 16\n* Tuning range: (8, 256) with`num\\_leaves &lt;&lt; 2^(max\\_depth)`[3]\nThe parameter`max\\_depth`controls the maximum depth for the tree model [2].\n* Default: -1 (no limit)\n* Good starting point for baseline: Default\n* Tuning range: (3, 16)\nThe smaller the trees (small`num\\_leaves`and`max\\_depth`), the faster the training speed &#8211; but this can also decrease accuracy [3].\nSince`num\\_leaves`impacts the tree growth in LGBM more than`max\\_depth`[5], Morohashi [4] doesn&#8217;t necessarily recommend tuning this parameter and to deviate from the default value.\n## Tree Growth\nAside from the depth and number of leaves, you can specify under which conditions a leaf will split. Thus, you can specify how the tree will grow.\n![Specifying LightGBM tree growth with min_data_in_leaf and min_gain_to_split (Image by the author)](https://towardsdatascience.com/wp-content/uploads/2023/03/1Q1Ubntx2JhOKs75Ob6vxLw.jpeg)Specifying LightGBM tree growth with`min\\_data\\_in\\_leaf`and`min\\_gain\\_to\\_split`(Image by the author)\nThe parameter`min\\_data\\_in\\_leaf`specifies the minimum number of data points in one leaf [2]. If this parameter is too small, the model will overfit to the training data [2].\n* Default: 20\n* Good starting point for baseline: Default\n* Tuning range: (5, 300) but depends on the size of the dataset. Hundreds are enough for a large dataset [3]. As a rule of thumb: The larger the dataset, the larger`min\\_data\\_in\\_leaf`.\nThe parameter`min\\_gain\\_to\\_split`specifies the minimum gain a leaf has to have to perform a split [2].\n* Default: 0\n* Good starting point for baseline: Default\n* Tuning range: (0, 15)\nIf you limit tree growth by increasing the parameter`min\\_gain\\_to\\_split`, the resulting smaller trees will lead to a faster training time &#8211; but this can also decrease accuracy [3].\n## Data Sampling\nData sampling is a technique to force the model to generalize. The general idea is not to feed the model all the data at each iteration. Instead, the model will only see a fraction of the training data at each iteration.\n### Bagging\nAt every`bagging\\_freq`-th iteration, LGBM will randomly select`bagging\\_fraction \\* 100 %`of the data to use for the next`bagging\\_freq`iterations [2]. E.g., if`bagging\\_fraction = 0.8`and`bagging\\_freq = 2`, LGBM will sample 80 % of the training data every second iteration before training each tree.\nThis technique can be used to speed up training [2].\n* Default:`bagging\\_fraction = 1.0`and`bagging\\_freq = 0`(disabled)\n* Good starting point for baseline:`bagging\\_fraction = 0.9`and`bagging\\_freq = 1`\n* Tuning range:`bagging\\_fraction`(0.5, 1)![Bagging with bagging_fraction = 0.8 in LightGBM (Image by the author)](https://towardsdatascience.com/wp-content/uploads/2023/03/188gPyw4pgZGxt-xHj8pJGA.jpeg)Bagging with bagging\\_fraction = 0.8 in LightGBM (Image by the author)### Sub-feature sampling\nAt every iteration, LGBM will randomly select`feature\\_fraction \\* 100 %`of the data [2]. E.g., if`feature\\_fraction = 0.8`, LGBM will sample 80 % of the features before training each tree.\n* Default: 1\n* Good starting point for baseline: 0.9\n* Tuning range: (0.5, 1)![Sub-feature sampling with feature_fraction = 0.8 in LightGBM (Image by the author)](https://towardsdatascience.com/wp-content/uploads/2023/03/1O_EXga-y79Ph2OZ5MQBmBA.jpeg)Sub-feature sampling with feature\\_fraction = 0.8 in LightGBM (Image by the author)\nWhile sub-feature sampling can also be used to speed up training like bagging [2], it can help if there is multicollinearity present in the features [1].\n## Regularization\nYou can apply regularization techniques to your Machine Learning model to deal with overfitting. As the parameter names already suggest, the parameter`lambda\\_l1`is used for L1 regularization and`lambda\\_l2`for L2 regularization.\n* **L1 regularization**penalizes the absolute values of the weights and thus is robust against outliers\n* **L2 regularization**penalizes the sum of squares of the weights and thus is sensitive to outliers\nYou can either decide to use only one of the two types of regularization or you can combine them if you like.\nFor both parameters, the parameter values behave similarly:\n* Default: 0 (disabled)\n* Good starting point for baseline: Default\n* Tuning range: (0.01, 100)## Summary\nThis article gave you a quick rundown of the most essential[LightGBM](https://lightgbm.readthedocs.io/en/latest/index.html)hyperparameters to tune. Below you can find an overview of them with their recommended tuning ranges.\n![Overview of the most important LightGBM hyperparameters and their tuning ranges (Image by the author).](https://towardsdatascience.com/wp-content/uploads/2023/03/1nE2I_8IcPuB_dMU9uG0ePg.png)Overview of the most important[LightGBM](https://lightgbm.readthedocs.io/en/latest/index.html)hyperparameters and t...",
      "url": "https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702"
    },
    {
      "title": "Advanced Topics \u2014 LightGBM 4.6.0.99 documentation",
      "text": "Advanced Topics &mdash; LightGBM 4.6.0.99 documentation\n* [](index.html)\n* Advanced Topics\n* [View page source](_sources/Advanced-Topics.rst.txt)\n# Advanced Topics[\uf0c1](#advanced-topics)\n## Missing Value Handle[\uf0c1](#missing-value-handle)\n* LightGBM enables the missing value handle by default. Disable it by setting`use\\_missing=false`.\n* LightGBM uses NA (NaN) to represent missing values by default. Change it to use zero by setting`zero\\_as\\_missing=true`.\n* When`zero\\_as\\_missing=false`(default), the unrecorded values in sparse matrices (and LightSVM) are treated as zeros.\n* When`zero\\_as\\_missing=true`, NA and zeros (including unrecorded values in sparse matrices (and LightSVM)) are treated as missing.\n## Categorical Feature Support[\uf0c1](#categorical-feature-support)\n* LightGBM offers good accuracy with integer-encoded categorical features. LightGBM applies[Fisher (1958)](https://www.jstor.org/stable/2281952)to find the optimal split over categories as[described here](./Features.html#optimal-split-for-categorical-features). This often performs better than one-hot encoding.\n* Use`categorical\\_feature`to specify the categorical features.\nRefer to the parameter`categorical\\_feature`in[Parameters](./Parameters.html#categorical_feature).\n* Categorical features will be cast to`int32`(integer codes will be extracted from pandas categoricals in the Python-package) so they must be encoded as non-negative integers (negative values will be treated as missing)\nless than`Int32.MaxValue`(2147483647).\nIt is best to use a contiguous range of integers started from zero.\nFloating point numbers in categorical features will be rounded towards 0.\n* Use`min\\_data\\_per\\_group`,`cat\\_smooth`to deal with over-fitting (when`#data`is small or`#category`is large).\n* For a categorical feature with high cardinality (`#category`is large), it often works best to\ntreat the feature as numeric, either by simply ignoring the categorical interpretation of the integers or\nby embedding the categories in a low-dimensional numeric space.\n## LambdaRank[\uf0c1](#lambdarank)\n* The label should be of type`int`, such that larger numbers correspond to higher relevance (e.g. 0:bad, 1:fair, 2:good, 3:perfect).\n* Use`label\\_gain`to set the gain(weight) of`int`label.\n* Use`lambdarank\\_truncation\\_level`to truncate the max DCG.\n## Cost Efficient Gradient Boosting[\uf0c1](#cost-efficient-gradient-boosting)\n[Cost Efficient Gradient Boosting](https://proceedings.neurips.cc/paper/2017/hash/4fac9ba115140ac4f1c22da82aa0bc7f-Abstract.html)(CEGB) makes it possible to penalise boosting based on the cost of obtaining feature values.\nCEGB penalises learning in the following ways:\n* Each time a tree is split, a penalty of`cegb\\_penalty\\_split`is applied.\n* When a feature is used for the first time,`cegb\\_penalty\\_feature\\_coupled`is applied. This penalty can be different for each feature and should be specified as one`double`per feature.\n* When a feature is used for the first time for a data row,`cegb\\_penalty\\_feature\\_lazy`is applied. Like`cegb\\_penalty\\_feature\\_coupled`, this penalty is specified as one`double`per feature.\nEach of the penalties above is scaled by`cegb\\_tradeoff`.\nUsing this parameter, it is possible to change the overall strength of the CEGB penalties by changing only one parameter.\n## Parameters Tuning[\uf0c1](#parameters-tuning)\n* Refer to[Parameters Tuning](./Parameters-Tuning.html).\n## Distributed Learning[\uf0c1](#distributed-learning)\n* Refer to[Distributed Learning Guide](./Parallel-Learning-Guide.html).\n## GPU Support[\uf0c1](#gpu-support)\n* Refer to[GPU Tutorial](./GPU-Tutorial.html)and[GPU Targets](./GPU-Targets.html).\n## Support for Position Bias Treatment[\uf0c1](#support-for-position-bias-treatment)\nOften the relevance labels provided in Learning-to-Rank tasks might be derived from implicit user feedback (e.g., clicks) and therefore might be biased due to their position/location on the screen when having been presented to a user.\nLightGBM can make use of positional data.\nFor example, consider the case where you expect that the first 3 results from a search engine will be visible in users\u2019 browsers without scrolling, and all other results for a query would require scrolling.\nLightGBM could be told to account for the position bias from results being \u201cabove the fold\u201d by providing a`positions`array encoded as follows:\n```\n000110001...\n```\nWhere`0=&quot;abovethefold&quot;`and`1=&quot;requiresscrolling&quot;`.\nThe specific values are not important, as long as they are consistent across all observations in the training data.\nAn encoding like`100=&quot;abovethefold&quot;`and`17=&quot;requiresscrolling&quot;`would result in exactly the same trained model.\nIn that way,`positions`in LightGBM\u2019s API are similar to a categorical feature.\nJust as with non-ordinal categorical features, an integer representation is just used for memory and computational efficiency\u2026 LightGBM does not care about the absolute or relative magnitude of the values.\nUnlike a categorical feature, however,`positions`are used to adjust the target to reduce the bias in predictions made by the trained model.\nThe position file corresponds with training data file line by line, and has one position per line. And if the name of training data file is`train.txt`, the position file should be named as`train.txt.position`and placed in the same folder as the data file.\nIn this case, LightGBM will load the position file automatically if it exists. The positions can also be specified through the`Dataset`constructor when using Python API. If the positions are specified in both approaches, the`.position`file will be ignored.\nCurrently, implemented is an approach to model position bias by using an idea of Generalized Additive Models ([GAM](https://en.wikipedia.org/wiki/Generalized_additive_model)) to linearly decompose the document score`s`into the sum of a relevance component`f`and a positional component`g`:`s(x,pos)=f(x)+g(pos)`where the former component depends on the original query-document features and the latter depends on the position of an item.\nDuring the training, the compound scoring function`s(x,pos)`is fit with a standard ranking algorithm (e.g., LambdaMART) which boils down to jointly learning the relevance component`f(x)`(it is later returned as an unbiased model) and the position factors`g(pos)`that help better explain the observed (biased) labels.\nSimilar score decomposition ideas have previously been applied for classification &amp; pointwise ranking tasks with assumptions of binary labels and binary relevance (a.k.a. \u201ctwo-tower\u201d models, refer to the papers:[Towards Disentangling Relevance and Bias in Unbiased Learning to Rank](https://arxiv.org/abs/2212.13937),[PAL: a position-bias aware learning framework for CTR prediction in live recommender systems](https://dl.acm.org/doi/10.1145/3298689.3347033),[A General Framework for Debiasing in CTR Prediction](https://arxiv.org/abs/2112.02767)).\nIn LightGBM, we adapt this idea to general pairwise Lerarning-to-Rank with arbitrary ordinal relevance labels.\nBesides, GAMs have been used in the context of explainable ML ([Accurate Intelligible Models with Pairwise Interactions](https://www.cs.cornell.edu/~yinlou/projects/gam/)) to linearly decompose the contribution of each feature (and possibly their pairwise interactions) to the overall score, for subsequent analysis and interpretation of their effects in the trained models.",
      "url": "https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html"
    },
    {
      "title": "Parameters Tuning \uf0c1",
      "text": "Parameters Tuning &mdash; LightGBM 4.6.0.99 documentation\n* [](index.html)\n* Parameters Tuning\n* [View page source](_sources/Parameters-Tuning.rst.txt)\n# Parameters Tuning[\uf0c1](#parameters-tuning)\nThis page contains parameters tuning guides for different scenarios.\n**List of other helpful links**\n* [Parameters](./Parameters.html)\n* [Python API](./Python-API.html)\n* [FLAML](https://github.com/microsoft/FLAML)for automated hyperparameter tuning\n* [Optuna](https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258)for automated hyperparameter tuning\n## Tune Parameters for the Leaf-wise (Best-first) Tree[\uf0c1](#tune-parameters-for-the-leaf-wise-best-first-tree)\nLightGBM uses the[leaf-wise](./Features.html#leaf-wise-best-first-tree-growth)tree growth algorithm, while many other popular tools use depth-wise tree growth.\nCompared with depth-wise growth, the leaf-wise algorithm can converge much faster.\nHowever, the leaf-wise growth may be over-fitting if not used with the appropriate parameters.\nTo get good results using a leaf-wise tree, these are some important parameters:\n1. `num\\_leaves`. This is the main parameter to control the complexity of the tree model.\nTheoretically, we can set`num\\_leaves=2^(max\\_depth)`to obtain the same number of leaves as depth-wise tree.\nHowever, this simple conversion is not good in practice.\nA leaf-wise tree is typically much deeper than a depth-wise tree for a fixed number of leaves. Unconstrained depth can induce over-fitting.\nThus, when trying to tune the`num\\_leaves`, we should let it be smaller than`2^(max\\_depth)`.\nFor example, when the`max\\_depth=7`the depth-wise tree can get good accuracy,\nbut setting`num\\_leaves`to`127`may cause over-fitting, and setting it to`70`or`80`may get better accuracy than depth-wise.\n2. `min\\_data\\_in\\_leaf`. This is a very important parameter to prevent over-fitting in a leaf-wise tree.\nIts optimal value depends on the number of training samples and`num\\_leaves`.\nSetting it to a large value can avoid growing too deep a tree, but may cause under-fitting.\nIn practice, setting it to hundreds or thousands is enough for a large dataset.\n3. `max\\_depth`. You also can use`max\\_depth`to limit the tree depth explicitly.\nIf you set`max\\_depth`, also explicitly set`num\\_leaves`to some value`&lt;=2^max\\_depth`.\n## For Faster Speed[\uf0c1](#for-faster-speed)\n### Add More Computational Resources[\uf0c1](#add-more-computational-resources)\nOn systems where it is available, LightGBM uses OpenMP to parallelize many operations. The maximum number of threads used by LightGBM is controlled by the parameter`num\\_threads`. By default, this will defer to the default behavior of OpenMP (one thread per real CPU core or the value in environment variable`OMP\\_NUM\\_THREADS`, if it is set). For best performance, set this to the number of**real**CPU cores available.\nYou might be able to achieve faster training by moving to a machine with more available CPU cores.\nUsing distributed (multi-machine) training might also reduce training time. See the[Distributed Learning Guide](./Parallel-Learning-Guide.html)for details.\n### Use a GPU-enabled version of LightGBM[\uf0c1](#use-a-gpu-enabled-version-of-lightgbm)\nYou might find that training is faster using a GPU-enabled build of LightGBM. See the[GPU Tutorial](./GPU-Tutorial.html)for details.\n### Grow Shallower Trees[\uf0c1](#grow-shallower-trees)\nThe total training time for LightGBM increases with the total number of tree nodes added. LightGBM comes with several parameters that can be used to control the number of nodes per tree.\nThe suggestions below will speed up training, but might hurt training accuracy.\n#### Decrease`max\\_depth`[\uf0c1](#decrease-max-depth)\nThis parameter is an integer that controls the maximum distance between the root node of each tree and a leaf node. Decrease`max\\_depth`to reduce training time.\n#### Decrease`num\\_leaves`[\uf0c1](#decrease-num-leaves)\nLightGBM adds nodes to trees based on the gain from adding that node, regardless of depth. This figure from[the feature documentation](./Features.html#leaf-wise-best-first-tree-growth)illustrates the process.\n![Three consecutive images of decision trees, where each shows the tree with an additional two leaf nodes added. Shows that leaf-wise growth can result in trees that have some branches which are longer than others.](_images/leaf-wise.png)\nBecause of this growth strategy, it isn\u2019t straightforward to use`max\\_depth`alone to limit the complexity of trees. The`num\\_leaves`parameter sets the maximum number of nodes per tree. Decrease`num\\_leaves`to reduce training time.\n#### Increase`min\\_gain\\_to\\_split`[\uf0c1](#increase-min-gain-to-split)\nWhen adding a new tree node, LightGBM chooses the split point that has the largest gain. Gain is basically the reduction in training loss that results from adding a split point. By default, LightGBM sets`min\\_gain\\_to\\_split`to 0.0, which means \u201cthere is no improvement that is too small\u201d. However, in practice you might find that very small improvements in the training loss don\u2019t have a meaningful impact on the generalization error of the model. Increase`min\\_gain\\_to\\_split`to reduce training time.\n#### Increase`min\\_data\\_in\\_leaf`and`min\\_sum\\_hessian\\_in\\_leaf`[\uf0c1](#increase-min-data-in-leaf-and-min-sum-hessian-in-leaf)\nDepending on the size of the training data and the distribution of features, it\u2019s possible for LightGBM to add tree nodes that only describe a small number of observations. In the most extreme case, consider the addition of a tree node that only a single observation from the training data falls into. This is very unlikely to generalize well, and probably is a sign of overfitting.\nThis can be prevented indirectly with parameters like`max\\_depth`and`num\\_leaves`, but LightGBM also offers parameters to help you directly avoid adding these overly-specific tree nodes.\n* `min\\_data\\_in\\_leaf`: Minimum number of observations that must fall into a tree node for it to be added.\n* `min\\_sum\\_hessian\\_in\\_leaf`: Minimum sum of the Hessian (second derivative of the objective function evaluated for each observation) for observations in a leaf. For some regression objectives, this is just the minimum number of records that have to fall into each node. For classification objectives, it represents a sum over a distribution of probabilities. See[this Stack Overflow answer](https://stats.stackexchange.com/questions/317073/explanation-of-min-child-weight-in-xgboost-algorithm)for a good description of how to reason about values of this parameter.\n### Grow Less Trees[\uf0c1](#grow-less-trees)\n#### Decrease`num\\_iterations`[\uf0c1](#decrease-num-iterations)\nThe`num\\_iterations`parameter controls the number of boosting rounds that will be performed. Since LightGBM uses decision trees as the learners, this can also be thought of as \u201cnumber of trees\u201d.\nIf you try changing`num\\_iterations`, change the`learning\\_rate`as well.`learning\\_rate`will not have any impact on training time, but it will impact the training accuracy. As a general rule, if you reduce`num\\_iterations`, you should increase`learning\\_rate`.\nChoosing the right value of`num\\_iterations`and`learning\\_rate`is highly dependent on the data and objective, so these parameters are often chosen from a set of possible values through hyperparameter tuning.\nDecrease`num\\_iterations`to reduce training time.\n#### Use Early Stopping[\uf0c1](#use-early-stopping)\nIf early stopping is enabled, after each boosting round the model\u2019s training accuracy is evaluated against a validation set that contains data not available to the training process. That accuracy is then compared to the accuracy as of the previous boosting round. If the model\u2019s accuracy fails to improve for some number of consecutive rounds, LightGBM stops the training process.\nThat \u201cnumber of consecutive rounds\u201d is controlled by the parameter`early\\_stopping\\_round`. For example,`early\\_stopping\\_round=1`says \u201cthe first time accuracy on the validation set does not im...",
      "url": "https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html"
    },
    {
      "title": "python LightGBM text classicication with Tfidf",
      "text": "2024 Developer survey is here and we would like to hear from you!\n[Take the 2024 Developer Survey](https://stackoverflow.com/dev-survey/start?utm_medium=referral&utm_source=stackexchange-community&utm_campaign=dev-survey-2024&utm_content=announcement-banner)\n\n##### Collectives\u2122 on Stack Overflow\n\nFind centralized, trusted content and collaborate around the technologies you use most.\n\n[Learn more about Collectives](https://stackoverflow.com/collectives)\n\n**Teams**\n\nQ&A for work\n\nConnect and share knowledge within a single location that is structured and easy to search.\n\n[Learn more about Teams](https://stackoverflow.co/teams/)\n\nGet early access and see previews of new features.\n\n[Learn more about Labs](https://stackoverflow.co/labs/)\n\n# [python LightGBM text classicication with Tfidf](https://stackoverflow.com/questions/50250432/python-lightgbm-text-classicication-with-tfidf)\n\n[Ask Question](https://stackoverflow.com/questions/ask)\n\nAsked6 years, 1 month ago\n\nModified [4 years, 9 months ago](https://stackoverflow.com/questions/50250432/python-lightgbm-text-classicication-with-tfidf?lastactivity)\n\nViewed\n7k times\n\nPart of [NLP](https://stackoverflow.com/collectives/nlp) Collective\n\n4\n\nI'm trying to introduce LightGBM for text multiclassification.\n2 columns in pandas dataframe, where 'category' and 'contents' are set as follows.\n\n**Dataframe:**\n\n```\n    contents               category\n1   this is example1...    A\n2   this is example2...    B\n3   this is example3...    C\n\n*Actual data frame consists of approx 600 rows and 2 columns.\n\n```\n\nHereby I'm trying to classify text into 3 categories as follows.\n\n**Codes:**\n\n```\nimport pandas as pd\nimport numpy as np\n\nfrom nltk.corpus import stopwords\nstopwords1 = set(stopwords.words('english'))\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n\nimport lightgbm as lgbm\nfrom lightgbm import LGBMClassifier, LGBMRegressor\n\n#--main code--#\nX_train, X_test, Y_train, Y_test = train_test_split(df['contents'], df['category'], random_state = 0, test_size=0.3, shuffle=True)\n\ncount_vect = CountVectorizer(ngram_range=(1,2), stop_words=stopwords1)\nX_train_counts = count_vect.fit_transform(X_train)\n\ntfidf_transformer = TfidfTransformer(use_idf=True, smooth_idf=True, norm='l2', sublinear_tf=True)\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n\nlgbm_train = lgbm.Dataset(X_train_tfidf, Y_train)\nlgbm_eval = lgbm.Dataset(count_vect.transform(X_test), Y_test, reference=lgbm_train)\n\nparams = {\n    'boosting_type':'gbdt',\n    'objective':'multiclass',\n    'learning_rate': 0.02,\n    'num_class': 3,\n    'early_stopping': 100,\n    'num_iteration': 2000,\n    'num_leaves': 31,\n    'is_enable_sparse': 'true',\n    'tree_learner': 'data',\n    'max_depth': 4,\n    'n_estimators': 50\n    }\n\nclf_gbm = lgbm.train(params, valid_sets=lgbm_eval)\npredicted_LGBM = clf_gbm.predict(count_vect.transform(X_test))\n\nprint(accuracy_score(Y_test, predicted_LGBM))\n\n```\n\nThen I got an error as:\n\n```\nValueError: could not convert string to float: 'b'\n\n```\n\nI also convert 'category' column \\['a', 'b', 'c'\\] to int as \\[0, 1, 2\\] but got an error as\n\n```\nTypeError: Expected np.float32 or np.float64, met type(int64).\n\n```\n\nWhat's wrong with my code?\n\nAny advice / suggestions will be greatly appreciated.\n\nThanks in advance.\n\n- [python](https://stackoverflow.com/questions/tagged/python)\n- [tf-idf](https://stackoverflow.com/questions/tagged/tf-idf)\n- [text-classification](https://stackoverflow.com/questions/tagged/text-classification)\n- [lightgbm](https://stackoverflow.com/questions/tagged/lightgbm)\n\n[Share](https://stackoverflow.com/q/50250432)\n\n[Improve this question](https://stackoverflow.com/posts/50250432/edit)\n\nFollow\n\nasked May 9, 2018 at 9:53\n\n[![SY9's user avatar](https://lh6.googleusercontent.com/-5HAEklILSxw/AAAAAAAAAAI/AAAAAAAEnYs/Wueg0YweCHk/photo.jpg?sz=64)](https://stackoverflow.com/users/9478615/sy9)\n\n[SY9](https://stackoverflow.com/users/9478615/sy9) SY9\n\n16522 silver badges1111 bronze badges\n\n2\n\n- Curios. Why use a classifier built for categorical data when the features are sparse and non categorical??\n\n\u2013\u00a0[Isbister](https://stackoverflow.com/users/1818667/isbister)\n\nCommentedNov 27, 2018 at 23:07\n\n- @Isbister This code is for classification with the one-hot vector of extracted thousands of sentences so the data is sparse. In one-hot vector made by Scikit-learn CountVect is numerical since CV counts words in the sentence and put them to the vector. I think this is a bit classical but typical way for the text classification.\n\n\u2013\u00a0[SY9](https://stackoverflow.com/users/9478615/sy9)\n\nCommentedDec 3, 2018 at 1:52\n\n\n[Add a comment](https://stackoverflow.com/questions/50250432/python-lightgbm-text-classicication-with-tfidf)\u00a0\\|\n\n## 1 Answer 1\n\nSorted by:\n[Reset to default](https://stackoverflow.com/questions/50250432/python-lightgbm-text-classicication-with-tfidf?answertab=scoredesc#tab-top)\n\nHighest score (default)Trending (recent votes count more)Date modified (newest first)Date created (oldest first)\n\n5\n\nI managed to deal with this issue. Very simple but noted here for reference.\n\nSince LightGBM expects float32/64 for input, so 'categories' should be number, rather than str.\nAnd input data should be converted to float32/64 using .astype().\n\n**Changes1:**\n\n**added following 4 lines after** _X\\_train\\_tfidf = tfidf\\_transformer.fit\\_transform(X\\_train\\_counts)_\n\n```\n X_train_tfidf = X_train_tfidf.astype('float32')\n X_test_counts = X_test_counts.astype('float32')\n Y_train = Y_train.astype('float32')\n Y_test = Y_test.astype('float32')\n\n```\n\n**changes2:**\n\n**just convert 'category' column** from \\[A, B, C, ...\\] to \\[0.0, 1.0, 2.0, ...\\]\n\nMaybe just assigning attirbute as TfidfVecotrizer(dtype=np.float32) works in this case.\n\nAnd putting vectorized data to LGBMClassifier will be much simpler.\n\n**Update**\n\nUsing TfidfVectorizer is much simpler:\n\n```\ntfidf_vec = TfidfVectorizer(dtype=np.float32, sublinear_tf=True, use_idf=True, smooth_idf=True)\nX_data_tfidf = tfidf_vec.fit_transform(df['contents'])\nX_train_tfidf = tfidf_vec.transform(X_train)\nX_test_tfidf = tfidf_vec.transform(X_test)\n\nclf_LGBM = lgbm.LGBMClassifier(objective='multiclass', verbose=-1, learning_rate=0.5, max_depth=20, num_leaves=50, n_estimators=120, max_bin=2000,)\nclf_LGBM.fit(X_train_tfidf, Y_train, verbose=-1)\npredicted_LGBM = clf_LGBM.predict(X_test_tfidf)\n\n```\n\n[Share](https://stackoverflow.com/a/50406572)\n\n[Improve this answer](https://stackoverflow.com/posts/50406572/edit)\n\nFollow\n\n[edited Jan 26, 2019 at 1:17](https://stackoverflow.com/posts/50406572/revisions)\n\nanswered May 18, 2018 at 8:02\n\n[![SY9's user avatar](https://lh6.googleusercontent.com/-5HAEklILSxw/AAAAAAAAAAI/AAAAAAAEnYs/Wueg0YweCHk/photo.jpg?sz=64)](https://stackoverflow.com/users/9478615/sy9)\n\n[SY9](https://stackoverflow.com/users/9478615/sy9) SY9\n\n16522 silver badges1111 bronze badges\n\n3\n\n- I am still getting this error even after adding those 4 lines you suggested.\n\n\u2013\u00a0[phaigeim](https://stackoverflow.com/users/3879625/phaigeim)\n\nCommentedJan 18, 2019 at 19:18\n\n- TypeError: Expected np.float32 or np.float64, met type(int64) This is happening during \"train\" method\n\n\u2013\u00a0[phaigeim](https://stackoverflow.com/users/3879625/phaigeim)\n\nCommentedJan 22, 2019 at 8:15\n\n- 1\n\n\n\n\n\n@phaigeim Have you tried using TfidfVectorizer instead CountVectorizer + Tfidftransformer? TfidfVect support dtype option so you can convert data type. See Update in my answer above. If it doesn't resolve your issue, directly convert your dataset to float before voctorize data.\n\n\u2013\u00a0[SY9](https://stackoverflow.com/users/9478615/sy9)\n\nCommentedJan 26, 2019 at 1:21\n\n\n[Add a comment](https://stackoverflow.com/questions/50250432/python-lightgbm-text-classicication-with-tfidf)\u00a0\\|\n\n## Your Answer\n\n**Reminder:** Answers generated by artificial intelligence tools are not allowed on Stack...",
      "url": "https://stackoverflow.com/questions/50250432/python-lightgbm-text-classicication-with-tfidf"
    },
    {
      "title": "Mastering LightGBM: An In-Depth Guide to Efficient ...",
      "text": "Mastering LightGBM: An In-Depth Guide to Efficient Gradient Boosting | by M. Mohtasim Hossain | Medium\n[Sitemap](https://medium.com/sitemap/sitemap.xml)\n[Open in app](https://play.google.com/store/apps/details?id=com.medium.reader&amp;referrer=utm_source=mobileNavBar&amp;source=post_page---top_nav_layout_nav-----------------------------------------)\nSign up\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@mohtasim.hossain2000/mastering-lightgbm-an-in-depth-guide-to-efficient-gradient-boosting-8bfeff15ee17&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\n[\nWrite\n](https://medium.com/m/signin?operation=register&amp;redirect=https://medium.com/new-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n[\nSearch\n](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\nSign up\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@mohtasim.hossain2000/mastering-lightgbm-an-in-depth-guide-to-efficient-gradient-boosting-8bfeff15ee17&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n# ***Mastering LightGBM: An In-Depth Guide to Efficient Gradient Boosting***\n[\n![M. Mohtasim Hossain](https://miro.medium.com/v2/da:true/resize:fill:64:64/0*sL33fPxp0zRbF60D)\n](https://medium.com/@mohtasim.hossain2000?source=post_page---byline--8bfeff15ee17---------------------------------------)\n[M. Mohtasim Hossain](https://medium.com/@mohtasim.hossain2000?source=post_page---byline--8bfeff15ee17---------------------------------------)\n13 min read\n\u00b7Jan 8, 2024\n[\n](https://medium.com/m/signin?actionUrl=https://medium.com/_/vote/p/8bfeff15ee17&amp;operation=register&amp;redirect=https://medium.com/@mohtasim.hossain2000/mastering-lightgbm-an-in-depth-guide-to-efficient-gradient-boosting-8bfeff15ee17&amp;user=M.+Mohtasim+Hossain&amp;userId=0ad1f386ae64&amp;source=---header_actions--8bfeff15ee17---------------------clap_footer------------------)\n--\n2\n[](https://medium.com/m/signin?actionUrl=https://medium.com/_/bookmark/p/8bfeff15ee17&amp;operation=register&amp;redirect=https://medium.com/@mohtasim.hossain2000/mastering-lightgbm-an-in-depth-guide-to-efficient-gradient-boosting-8bfeff15ee17&amp;source=---header_actions--8bfeff15ee17---------------------bookmark_footer------------------)\nListen\nShare\nIna landscape rapidly transforming with technological innovations, the realm of machine learning stands as a paramount pillar, continually pushing the boundaries of what\u2019s achievable. Amidst the diverse array of algorithms and frameworks, one entity, LightGBM, has emerged as a beacon of efficiency and effectiveness in the realm of gradient boosting. While the digital sphere is awash with brief overviews, this blog diverges from the norm. It delves into the intricate mechanisms, explores real-world applications, dissects advantages and disadvantages, and intricately unwraps the manifold facets of LightGBM. Buckle up for a comprehensive journey into this dynamic gradient boosting framework, where intricacy meets practicality in an expanse of detailed exploration.\n## **Introduction to Gradient Boosting**\n### **Gradient boosting and its significance in machine learning:**\nGradient Boosting, an essential ensemble learning method, merges weak learners such as decision trees to form a robust predictive model. Its significance lies in iteratively improving model accuracy by emphasizing and rectifying misclassified instances. The algorithm sequentially builds models to minimize overall prediction errors, using gradient descent optimization to fit new models to residual errors from previous iterations. This adaptability across datasets and consistent high accuracy make gradient boosting a versatile and sought-after algorithm in machine learning.\n### **How boosting amalgamates less capable learners to form a more robust model:**\nBoosting combines simple models like decision trees sequentially to form a more accurate predictive model. Each model focuses on correcting the mistakes made by its predecessor by giving higher priority to misclassified instances, gradually improving the overall accuracy of the ensemble. This iterative process results in a stronger, more accurate predictive model by progressively addressing and rectifying errors.\n### **Other popular gradient boosting frameworks:**\nIn addition to Gradient Boosting Machine (GBM) and LightGBM, there are several other popular gradient boosting frameworks widely used in machine learning. Some prominent ones include:\n1.**XGBoost (Extreme Gradient Boosting):**It is a rapid and efficient gradient boosting library recognized for its speed and effectiveness.XGBoost optimizes distributed computing and tree boosting algorithms, providing parallel tree boosting, regularization, and a variety of objective functions.\n2.**CatBoost:**Developed by Yandex, CatBoost is a high-performance gradient boosting library that specializes in handling categorical features without requiring preprocessing. It is famed for its resilience against overfitting and its efficient handling of various data formats.\n3.**AdaBoost (Adaptive Boosting):**One of the earliest boosting algorithms, AdaBoost builds an ensemble by giving more weight to misclassified instances in each iteration. It assigns weights to classifiers and focuses on difficult-to-classify instances, continuously adjusting the weights to improve performance.\n4.**HistGradientBoosting:**Introduced in scikit-learn, HistGradientBoosting uses a histogram-based algorithm for training gradient-boosted decision trees. It excels in managing extensive datasets and showcases impressive performance without requiring extensive hyperparameter tuning.\n## **Overview of LightGBM**\n### **What is LightGBM?**\nLightGBM, an open-source gradient boosting framework known for its efficiency with large datasets, was developed by Microsoft\u2019s team led by Guolin Ke and introduced in a 2017 paper titled \u201cLightGBM: A Highly Efficient Gradient Boosting Decision Tree.\u201d It aimed to improve training speed and predictive performance in gradient boosting algorithms. Key innovations like Gradient-based One-Side Sampling (GOSS) and Exclusive Feature Bundling (EFB) focus on larger gradient instances and perform automatic feature selection, enhancing the boosting process. LightGBM accelerates training while maintaining or improving predictive accuracy, making it ideal for handling extensive tabular data in classification and regression tasks.\n### **LightGBM Model and Architecture:**\nLightGBM\u2019s model framework relies on gradient boosting, employing a collection of decision trees to form a strong predictive model. Its emphasis on efficiency is evident through a leaf-wise tree growth approach and the use of histogram-based algorithms. The leaf-wise approach builds trees by selecting the node with the maximum loss reduction, enabling deeper trees for enhanced accuracy while being susceptible to potential overfitting with smaller datasets. The histogram-based method discretized continuous features into histograms, reducing computational complexity and memory usage, particularly advantageous for handling large-scale datasets. This combination of strategies, along with parallel and distributed computing capabilities, empowers LightGBM to deliver rapid training speeds, lower memory consumption, and high scalability, making it suitable for diverse machine learning tasks.\nPress enter or click to view image in full size\n![]()\nA diagrammatic representation of the LightGBM model### **Advantages over other boosting algorithms:**\nLightGBM exhibits several advantages over other boosting algorithms, especially in terms of efficiency and s...",
      "url": "https://medium.com/@mohtasim.hossain2000/mastering-lightgbm-an-in-depth-guide-to-efficient-gradient-boosting-8bfeff15ee17"
    },
    {
      "title": "LightGBM hyperparameters - Amazon SageMaker AI",
      "text": "LightGBM hyperparameters - Amazon SageMaker AI\nLightGBM hyperparameters - Amazon SageMaker AI\n[](https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#lightgbm-hyperparameters)\n[Documentation](https://docs.aws.amazon.com/index.html)[Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/index.html)[Developer Guide](whatis.html)\n# LightGBM hyperparameters\nThe following table contains the subset of hyperparameters that are required or most\ncommonly used for the Amazon SageMaker AI LightGBM algorithm. Users set these parameters to\nfacilitate the estimation of model parameters from data. The SageMaker AI LightGBM algorithm is\nan implementation of the open-source[LightGBM](https://github.com/microsoft/LightGBM)package.\n###### Note\nThe default hyperparameters are based on example datasets in the[LightGBM sample notebooks](./lightgbm.html#lightgbm-sample-notebooks).\nBy default, the SageMaker AI LightGBM algorithm automatically chooses an evaluation metric and\nobjective function based on the type of classification problem. The LightGBM algorithm\ndetects the type of classification problem based on the number of labels in your data.\nFor regression problems, the evaluation metric is root mean squared error and the\nobjective function is L2 loss. For binary classification problems, the evaluation metric\nand objective function are both binary cross entropy. For multiclass classification\nproblems, the evaluation metric is multiclass cross entropy and the objective function\nis softmax. You can use the`metric`hyperparameter to change the default\nevaluation metric. Refer to the following table for more information on LightGBM\nhyperparameters, including descriptions, valid values, and default values.\n|Parameter Name|Description|\n`num\\_boost\\_round`|\nThe maximum number of boosting iterations.**Note:**Internally, LightGBM constructs`num\\_class \\* num\\_boost\\_round`trees for multi-class classification problems.\nValid values: integer, range: Positive integer.\nDefault value:`100`.\n|\n`early\\_stopping\\_rounds`|\nThe training will stop if one metric of one validation data point does not improve in the last`early\\_stopping\\_rounds`round. If`early\\_stopping\\_rounds`is less than or equal to zero, this hyperparameter is ignored.\nValid values: integer.\nDefault value:`10`.\n|\n`metric`|\nThe evaluation metric for validation data. If`metric`is set to the default`\"auto\"`value, then the algorithm\nautomatically chooses an evaluation metric based on the type of\nclassification problem:\n* `rmse`for regression\n* `binary\\_logloss`for binary classification\n* `multi\\_logloss`for multi-class classification\nValid values: string, any of the following: (`\"auto\"`,`\"rmse\"`,`\"l1\"`,`\"l2\"`,`\"huber\"`,`\"fair\"`,`\"binary\\_logloss\"`,`\"binary\\_error\"`,`\"auc\"`,`\"average\\_precision\"`,`\"multi\\_logloss\"`,`\"multi\\_error\"`,`\"auc\\_mu\"`, or`\"cross\\_entropy\"`).\nDefault value:`\"auto\"`.\n|\n`learning\\_rate`|\nThe rate at which the model weights are updated after working through each batch of training examples.\nValid values: float, range: (`0.0`,`1.0`).\nDefault value:`0.1`.\n|\n`num\\_leaves`|\nThe maximum number of leaves in one tree.\nValid values: integer, range: (`1`,`131072`).\nDefault value:`64`.\n|\n`feature\\_fraction`|\nA subset of features to be selected on each iteration (tree). Must be less than 1.0.\nValid values: float, range: (`0.0`,`1.0`).\nDefault value:`0.9`.\n|\n`bagging\\_fraction`|\nA subset of features similar to`feature\\_fraction`, but`bagging\\_fraction`randomly selects part of the data without resampling.\nValid values: float, range: (`0.0`,`1.0`].\nDefault value:`0.9`.\n|\n`bagging\\_freq`|\nThe frequency to perform bagging. At every`bagging\\_freq`iteration, LightGBM randomly selects a percentage of the data to use for the next`bagging\\_freq`iteration. This percentage is determined by the`bagging\\_fraction`hyperparameter. If`bagging\\_freq`is zero, then bagging is deactivated.\nValid values: integer, range: Non-negative integer.\nDefault value:`1`.\n|\n`max\\_depth`|\nThe maximum depth for a tree model. This is used to deal with overfitting when the amount of data is small. If`max\\_depth`is less than or equal to zero, this means there is no limit for maximum depth.\nValid values: integer.\nDefault value:`6`.\n|\n`min\\_data\\_in\\_leaf`|\nThe minimum amount of data in one leaf. Can be used to deal with overfitting.\nValid values: integer, range: Non-negative integer.\nDefault value:`3`.\n|\n`max\\_delta\\_step`|\nUsed to limit the max output of tree leaves. If`max\\_delta\\_step`is less than or equal to 0, then there is no constraint. The final max output of leaves is`learning\\_rate \\* max\\_delta\\_step`.\nValid values: float.\nDefault value:`0.0`.\n|\n`lambda\\_l1`|\nL1 regularization.\nValid values: float, range: Non-negative float.\nDefault value:`0.0`.\n|\n`lambda\\_l2`|\nL2 regularization.\nValid values: float, range: Non-negative float.\nDefault value:`0.0`.\n|\n`boosting`|\nBoosting type\nValid values: string, any of the following: (`\"gbdt\"`,`\"rf\"`,`\"dart\"`, or`\"goss\"`).\nDefault value:`\"gbdt\"`.\n|\n`min\\_gain\\_to\\_split`|\nThe minimum gain to perform a split. Can be used to speed up\ntraining.\nValid values: integer, float: Non-negative float.\nDefault value:`0.0`.\n|\n`scale\\_pos\\_weight`|\nThe weight of the labels with positive class. Used only for binary\nclassification tasks.`scale\\_pos\\_weight`cannot be used\nif`is\\_unbalance`is set to`\"True\"`.\nValid values: float, range: Positive float.\nDefault value:`1.0`.\n|\n`tree\\_learner`|\nTree learner type.\nValid values: string, any of the following:\n(`\"serial\"`,`\"feature\"`,`\"data\"`,\nor`\"voting\"`).\nDefault value:`\"serial\"`.\n|\n`feature\\_fraction\\_bynode`|\nSelects a subset of random features on each tree node. For\nexample, if`feature\\_fraction\\_bynode`is`0.8`, then 80% of features are selected. Can be used to\ndeal with overfitting.\nValid values: integer, range: (`0.0`,`1.0`].\nDefault value:`1.0`.\n|\n`is\\_unbalance`|\nSet to`\"True\"`if training data is unbalanced. Used\nonly for binary classification tasks.`is\\_unbalance`cannot be used with`scale\\_pos\\_weight`.\nValid values: string, either: (`\"True\"`or`\"False\"`).\nDefault value:`\"False\"`.\n|\n`max\\_bin`|\nThe maximum number of bins used to bucket feature values. A small\nnumber of bins may reduce training accuracy, but may increase\ngeneral performance. Can be used to deal with overfitting.\nValid values: integer, range: (1, \u221e).\nDefault value:`255`.\n|\n`tweedie\\_variance\\_power`|\nControls the variance of the Tweedie distribution. Set this closer\nto`2.0`to shift toward a gamma distribution. Set this\ncloser to`1.0`to shift toward a Poisson distribution.\nUsed only for regression tasks.\nValid values: float, range: [`1.0`,`2.0`).\nDefault value:`1.5`.\n|\n`num\\_threads`|\nNumber of parallel threads used to run LightGBM. Value 0 means\ndefault number of threads in OpenMP.\nValid values: integer, range: Non-negative integer.\nDefault value:`0`.\n|\n`verbosity`|\nThe verbosity of print messages. If the`verbosity`is\nless than`0`, then print messages only show fatal\nerrors. If`verbosity`is set to`0`, then\nprint messages include errors and warnings. If`verbosity`is`1`, then print messages\nshow more information. A`verbosity`greater than`1`shows the most information in print messages and\ncan be used for debugging.\nValid values: integer.\nDefault value:`1`.\n|\n[Document Conventions](https://docs.aws.amazon.com/general/latest/gr/docconventions.html)\nHow It Works\nModel Tuning\nDid this page help you? - Yes\nThanks for letting us know we're doing a good job!\nIf you've got a moment, please tell us what we did right so we can do more of it.\nDid this page help you? - No\nThanks for letting us know this page needs work. We're sorry we let you down.\nIf you've got a moment, please tell us how we can make the documentation better.",
      "url": "https://docs.aws.amazon.com/sagemaker/latest/dg/lightgbm-hyperparameters.html"
    },
    {
      "title": "LightGBM - Classification Models",
      "text": "- [Home](https://www.arthurgraus.nl/home.html)\n- [Training](https://www.arthurgraus.nl/training.html)\n  - [Power BI](https://www.arthurgraus.nl/power-bi.html)\n    - [Power BI Start](https://www.arthurgraus.nl/power-bi-start.html)\n    - [Power BI Introduction](https://www.arthurgraus.nl/power-bi-introduction.html)\n    - [Power BI Advanced](https://www.arthurgraus.nl/power-bi-advanced.html)\n    - [Masterclass DAX](https://www.arthurgraus.nl/masterclass-dax.html)\n  - [Microsoft Fabric](https://www.arthurgraus.nl/microsoft-fabric.html)\n    - [Masterclass Python for Data Engineers in Fabric](https://www.arthurgraus.nl/masterclass-python-for-data-engineers-in-fabric.html)\n    - [Azure Data Factory / Fabric Pipelines](https://www.arthurgraus.nl/azure-data-factory---fabric-pipelines.html)\n  - [T-SQL Queries](https://www.arthurgraus.nl/t-sql-queries.html)\n    - [T-SQL Queries Introduction](https://www.arthurgraus.nl/t-sql-queries-introduction.html)\n    - [T-SQL Queries Advanced](https://www.arthurgraus.nl/t-sql-queries-advanced.html)\n- [Consultancy](https://www.arthurgraus.nl/consultancy.html)\n  - [Power BI](https://www.arthurgraus.nl/power-bi2.html)\n- [Presentations](https://www.arthurgraus.nl/presentations.html)\n  - [Python in Fabric for Data Engineers](https://www.arthurgraus.nl/python-in-fabric-for-data-engineers.html)\n  - [Advanced Dimensional Modelling](https://www.arthurgraus.nl/advanced-dimensional-modelling.html)\n  - [AI / ML + Fabric + Power BI = Insights ^2](https://www.arthurgraus.nl/ai---ml---fabric---power-bi---insights--2.html)\n- [Contact](https://www.arthurgraus.nl/contact.html)\n\n# Classification Models - LightGBM\n\n### Description\n\nLightGBM is a gradient boosting framework that aims to enhance the speed and efficiency of training large-scale machine learning models. It uses a tree-based learning algorithm and focuses on handling categorical features and optimizing for an imbalanced dataset.\n\nOne key feature of LightGBM is its ability to handle large datasets and high-dimensional features by using a histogram-based algorithm for binning continuous features. This approach decreases the memory usage and speeds up training time.\n\nAnother advantage of LightGBM is its ability to handle imbalanced datasets. It provides techniques such as weighted loss functions and downsampling of the majority class, allowing for better performance on imbalanced classification tasks.\n\nMoreover, LightGBM supports parallel and GPU-based training, which further speeds up the training process. It also includes features like early stopping, custom objective functions, and various regularization techniques to prevent overfitting.\n\nOverall, LightGBM is a powerful and efficient gradient boosting framework for classification models, known for its ability to handle large-scale datasets, categorical features, imbalanced data, and parallel training, thus making it a popular choice in the field of machine learning.\n\n### History\n\nLightGBM is a gradient boosting framework developed by Microsoft that has gained popularity in machine learning for classification tasks. It was introduced in 2016 as an alternative to XGBoost, with a focus on faster computation and lower memory usage. LightGBM uses a histogram-based algorithm to split feature values, making it efficient and scalable for large datasets. Its ability to handle categorical features, parallel training, and speed optimizations have made it a reliable choice for various classification problems. LightGBM has since become a widely adopted tool in the machine learning community.\n\n### Use Cases\n\n- **Keyword: Fraud detection**: LightGBM can be used to build classification models for fraud detection in various domains such as credit card fraud, insurance fraud, or online transaction fraud.\n- **Keyword: Disease diagnosis**: LightGBM can assist in classifying various diseases based on input symptoms and medical records, enabling quicker and more accurate diagnoses.\n- **Keyword: Email spam filtering**: LightGBM can be employed to classify emails as spam or non-spam, enhancing email filtering systems by reducing the number of unwanted messages.\n- **Keyword: Customer churn prediction**: LightGBM algorithms can predict the likelihood of a customer leaving a service or subscription, helping businesses take proactive retention measures.\n- **Keyword: Sentiment analysis**: LightGBM can analyze and classify sentiments expressed in text data, aiding in understanding customer opinions, social media sentiment analysis, and brand reputation monitoring.\n- **Keyword: Credit risk assessment**: LightGBM can assess credit risk by analyzing various factors such as credit history, financial data, and borrower information, assisting institutions in making informed lending decisions.\n- **Keyword: Medical image recognition**: LightGBM can be utilized to classify medical images, such as X-rays or MRI scans, facilitating automated analysis and identification of specific conditions or abnormalities.\n- **Keyword: Recommendation systems**: LightGBM algorithms can be applied in building recommendation systems to suggest products, movies, or personalized content based on user preferences and historical data.\n- **Keyword: Intrusion detection**: LightGBM can identify and classify network intrusions or anomalies, helping secure systems by detecting and preventing potential cyber attacks or unauthorized access.\n- **Keyword: Text categorization**: LightGBM can categorize large volumes of text data into specific topics or classes automatically, assisting in content organization, news analysis, or document classification.\n\n### Pros\n\n1. \\*\\*Fast training speed\\*\\*: LightGBM is designed to handle large-scale datasets efficiently and can train models much faster than other gradient boosting methods. It utilizes exclusive features such as histogram-based algorithms and leaf-wise tree growth, enabling it to achieve high training speeds while maintaining good accuracy.\n2. \\*\\*Highly accurate\\*\\*: LightGBM uses gradient-based learning, which makes it capable of producing highly accurate models. It employs techniques like feature bundling and minimizing loss functions to improve the model's accuracy.\n3. \\*\\*Low memory usage\\*\\*: LightGBM optimizes memory usage by using a compact data structure that stores feature values only once, based on their frequency. This approach significantly reduces memory consumption, allowing for efficient handling of large datasets.\n4. \\*\\*Support for large datasets\\*\\*: LightGBM is particularly effective when working with large datasets due to its efficient algorithms and memory optimization techniques. It can handle tens of millions of instances and features, making it suitable for big data applications.\n5. \\*\\*Flexible customization\\*\\*: LightGBM provides various parameters and customization options that allow users to fine-tune the model according to their specific needs. It offers control over tree growth, boosting algorithm, regularization, and other aspects, enabling users to optimize the model's performance for diverse classification tasks.\n\n### Cons\n\n\n\n1. **Memory Consumption:** LightGBM can consume a large amount of memory, particularly when handling large datasets or complex feature engineering. This can limit its applicability on machines with limited memory resources.\n2. **Data Preprocessing:** LightGBM requires extensive data preprocessing. It may not handle missing values and categorical features directly, requiring users to convert them into numerical values or perform additional preprocessing steps.\n3. **Overfitting:** LightGBM is prone to overfitting, especially when working with small datasets or high-dimensional data. Adequate regularization techniques, like early stopping or using conservative learning rates, are necessary to mitigate this issue.\n4. **Black Box Nature:** LightGBM is often considered a black box model because it lacks interpretability compared to simpler models like decision trees. It can be challenging to explai...",
      "url": "https://www.arthurgraus.nl/lightgbm.html"
    },
    {
      "title": "How LightGBM algorithm works\u2014ArcGIS Pro | Documentation",
      "text": "How LightGBM algorithm works&mdash;ArcGIS Pro | Documentation\n[Back to Top](#)\n# How LightGBM algorithm works\n#### In this topic\n1. [Additional Resources](#ESRI_SECTION1_2BC67FBEE14B4ECCBA5171F6A8A3D83E)\nLightGBM is a gradient boosting ensemble method that is used by the[Train Using AutoML](https://pro.arcgis.com/en/pro-app/3.6/tool-reference/geoai/train-using-automl.htm)tool and is based on decision trees. As with other decision tree-based methods, LightGBM can be used for both classification and regression. LightGBM is optimized for high performance with distributed systems.\nLightGBM creates decision trees\rthat grow leaf wise, which means that given a condition, only a single leaf\ris split, depending on the gain. Leaf-wise\rtrees can sometimes overfit especially with smaller datasets.\rLimiting the tree depth can help to avoid\roverfitting.\nLightGBM uses a histogram-based\rmethod in which data is bucketed into bins using a histogram of the\rdistribution. The bins, instead of each data point, are used to\riterate, calculate the gain, and split the data. This method\rcan be optimized for a sparse dataset as well. Another\rcharacteristic of LightGBM is exclusive feature bundling in which the\ralgorithm combines exclusive features to reduce dimensionality,\rmaking it faster and more efficient.\nGradient-based One Side Sampling\r(GOSS) is used for sampling the dataset in LightGBM. GOSS weights\rdata points with larger gradients higher while\rcalculating the gain. In this method, instances that have not been\rused well for training contribute more. Data points with\rsmaller gradients are randomly removed and some are retained to\rmaintain accuracy. This method is typically better than random\rsampling given the same sampling rate.\n## Additional Resources\nKe, Guolin, Qi Meng, Thomas Finley, Taifeng\rWang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. \"Lightgbm: A\rhighly efficient gradient boosting decision tree.\" Advances in neural information processing\rsystems 30 (2017).\n[LightGBM documentation](https://lightgbm.readthedocs.io/)\n#### Related topics\n* [Train Using AutoML](https://pro.arcgis.com/en/pro-app/3.6/tool-reference/geoai/train-using-automl.htm)\n[Feedback on this topic?](https://pro.arcgis.com/feedback/)\n##### In this topic\n1. [Additional Resources](#ESRI_SECTION1_2BC67FBEE14B4ECCBA5171F6A8A3D83E)",
      "url": "https://pro.arcgis.com/en/pro-app/latest/tool-reference/geoai/how-lightgbm-works.htm"
    }
  ]
}