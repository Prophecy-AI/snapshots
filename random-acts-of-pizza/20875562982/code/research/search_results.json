{
  "query": "What specific text features and modeling approaches did top performers use in the Random Acts of Pizza Kaggle competition based on post-mortems and solution writeups?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Top\u2011scoring solutions in the Random Acts of Pizza competition all hinged on turning the Reddit request text into rich, numeric representations and then feeding those into strong classifiers.  Most winners first built classic bag\u2011of\u2011words / TF\u2011IDF vectors (using\u202f`sklearn.feature_extraction.text` utilities) and complemented them with higher\u2011level text signals such as topic\u2011model distributions (LDA) and document\u2011level statistics (e.g., length, presence of polite phrases)\u202f([notebook.community](https://notebook.community/omaraltaher/kaggle-pizza-project/Random_Acts_of_Pizza_Kaggle_Competition_Project)).  To tame the resulting high\u2011dimensional space they applied dimensionality reduction (truncated SVD / LSA) before modeling\u202f([Runze technical post](https://runze.github.io/technical-posts/random-acts-of-pizza)).\n\nFor the predictive layer, the most successful entries combined linear models with tree\u2011based ensembles.  Logistic regression on the reduced TF\u2011IDF/LDA features was a common baseline, while the winning scores were achieved with Random Forests and Gradient\u2011Boosted Trees (XGBoost) that could exploit both the dense SVD components and the sparse word\u2011level features.  Several teams also experimented with shallow neural nets on the same feature set, but the best leaderboard positions were secured by the ensemble of logistic regression, Random Forest/XGBoost, and SVD\u2011compressed text vectors\u202f([Carolina Arriaga project](https://www.caroarriaga.com/projects/raop)).",
      "url": ""
    },
    {
      "title": "| notebook.community",
      "text": "| notebook.community https://notebook.community/omaraltaher/kaggle-pizza-project/Random_Acts_of_Pizza_Kaggle_Competition_Project\n| notebook.community\nNone\n2017-01-01T00:00:00-20:17\n# W207 Summer 2017 Final Project iPython notebook\n\n### Omar Al Taher, Ted Pham, Chris SanChez\n\n\nIn\u00a0[1]:\n\n# This tells matplotlib not to try opening a new window for each plot.\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# General libraries.\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datetime\n\n# SK-learn libraries for learning.\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV #update module model_selection\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\n\n# SK-learn libraries for evaluation.\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_predict, cross_val_score\n\nfrom sklearn import preprocessing\nfrom sklearn.mixture import GMM\n\n# SK-learn libraries for feature extraction from text.\nfrom sklearn.feature_extraction.text import *\n\n\n# I. Background:\n\n#### This project aims to predict whether a reddit post asking for pizzas would get funded. Since it's a binary classification problem, we will explore several algorithms with a focus on logistic regression. In particular, we will look into details how to extract features from text.\n\n# II. Data Pre-Processing:\n\n#### The data in its raw form consists of 4040 observations of 31 features. The original columns consist of 19 integer values, 4 floats, and 8 objects (there is one boolean column which is the outcome variable). In order to extract predictive value from the dataset a good deal of pre-processing and feature engineering was required. A walkthrough of the various steps taken follows below in a narrative format:\n\n\nIn\u00a0[2]:\n\n#load json training data into pandas dataframe\ndf = pd.read_json('train.json')\ndf.info()\n\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 4040 entries, 0 to 4039\nData columns (total 32 columns):\ngiver_username_if_known 4040 non-null object\nnumber_of_downvotes_of_request_at_retrieval 4040 non-null int64\nnumber_of_upvotes_of_request_at_retrieval 4040 non-null int64\npost_was_edited 4040 non-null int64\nrequest_id 4040 non-null object\nrequest_number_of_comments_at_retrieval 4040 non-null int64\nrequest_text 4040 non-null object\nrequest_text_edit_aware 4040 non-null object\nrequest_title 4040 non-null object\nrequester_account_age_in_days_at_request 4040 non-null float64\nrequester_account_age_in_days_at_retrieval 4040 non-null float64\nrequester_days_since_first_post_on_raop_at_request 4040 non-null float64\nrequester_days_since_first_post_on_raop_at_retrieval 4040 non-null float64\nrequester_number_of_comments_at_request 4040 non-null int64\nrequester_number_of_comments_at_retrieval 4040 non-null int64\nrequester_number_of_comments_in_raop_at_request 4040 non-null int64\nrequester_number_of_comments_in_raop_at_retrieval 4040 non-null int64\nrequester_number_of_posts_at_request 4040 non-null int64\nrequester_number_of_posts_at_retrieval 4040 non-null int64\nrequester_number_of_posts_on_raop_at_request 4040 non-null int64\nrequester_number_of_posts_on_raop_at_retrieval 4040 non-null int64\nrequester_number_of_subreddits_at_request 4040 non-null int64\nrequester_received_pizza 4040 non-null bool\nrequester_subreddits_at_request 4040 non-null object\nrequester_upvotes_minus_downvotes_at_request 4040 non-null int64\nrequester_upvotes_minus_downvotes_at_retrieval 4040 non-null int64\nrequester_upvotes_plus_downvotes_at_request 4040 non-null int64\nrequester_upvotes_plus_downvotes_at_retrieval 4040 non-null int64\nrequester_user_flair 994 non-null object\nrequester_username 4040 non-null object\nunix_timestamp_of_request 4040 non-null int64\nunix_timestamp_of_request_utc 4040 non-null int64\ndtypes: bool(1), float64(4), int64(19), object(8)\nmemory usage: 1013.9+ KB\n\n\n#### We'll start by transforming the outcome variable into a binary variable.\n\n\nIn\u00a0[3]:\n\ndf['requester_received_pizza'] = np.where(df['requester_received_pizza'] == True, 1, 0)\ndf['requester_received_pizza'].value_counts()\n\n\nOut[3]:\n\n0 3046\n1 994\nName: requester_received_pizza, dtype: int64\n\n\n#### Next, we'll remove all the \"_at_retrieval\" columns from the dataset as they are not found in the test data set and therefore represent data that is not avaialable at the time of the request for pizza.\n\n\nIn\u00a0[4]:\n\ngood_indexes = []\nfor i, name in enumerate(df.columns):\n if re.findall('retrieval', name):\n pass\n else:\n good_indexes.append(i)\n\n# Remove at_retrieval fields from dataframce df\ncolumns = df.columns[good_indexes]\ndf = df.loc[:,columns]\n\n\n#### We also found that there were several other columns that were not needed for predictive power, and we therefore removed them as well.\n\n\nIn\u00a0[5]:\n\n#Drop six more columns from dataset\ndf.drop(['giver_username_if_known', 'post_was_edited', 'request_id',\n 'requester_user_flair', 'requester_username'], axis=1, inplace=True)\ndf.info()\n\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 4040 entries, 0 to 4039\nData columns (total 16 columns):\nrequest_text 4040 non-null object\nrequest_text_edit_aware 4040 non-null object\nrequest_title 4040 non-null object\nrequester_account_age_in_days_at_request 4040 non-null float64\nrequester_days_since_first_post_on_raop_at_request 4040 non-null float64\nrequester_number_of_comments_at_request 4040 non-null int64\nrequester_number_of_comments_in_raop_at_request 4040 non-null int64\nrequester_number_of_posts_at_request 4040 non-null int64\nrequester_number_of_posts_on_raop_at_request 4040 non-null int64\nrequester_number_of_subreddits_at_request 4040 non-null int64\nrequester_received_pizza 4040 non-null int64\nrequester_subreddits_at_request 4040 non-null object\nrequester_upvotes_minus_downvotes_at_request 4040 non-null int64\nrequester_upvotes_plus_downvotes_at_request 4040 non-null int64\nunix_timestamp_of_request 4040 non-null int64\nunix_timestamp_of_request_utc 4040 non-null int64\ndtypes: float64(2), int64(10), object(4)\nmemory usage: 536.6+ KB\n\n\n#### Removing the \"at_retrieval\" columns and the other six columns, reduces our dataset by 17 total features (leaving us with 14 features, not including the outcome variable ).\n\n#### During the EDA phase of this project we found that several (104 to be exact), observations had a \"request_text\" length of zero, some of these observations actually ended up being given a pizza. After looking through the data, we discovered that some people had left their request in the \"request_title\" field of the RAOP Reddit page and had left their request_text field blank. In order to clean this discrepancy up, we decided to combine these two fields together, as it is unclear if the benefactors (those who ended up giving pizzas away), were responding to the '\"request_title\" field, the \"request_text\" field, or both when they made their altruistic decision.\n\n\nIn\u00a0[6]:\n\n#Show that 104 observations have a blank \"request_text\" field\nlen(df[df['request_text'].str.len() == 0])\n\n\nOut[6]:\n\n104\n\n\nIn\u00a0[7]:\n\n#1. Combine request_text and request_title fields\n#2. Lowercase all words\n\ndf['request_text_n_title'] = (df['request_title'] + ' ' + df['request_text_edit_aware'])\ndf['request_text_n_title'] = [ text.split(\" \",1)[1].lower() for text in df['request_text_n_title']]\nprint df['request_text_n_title'].head()\n\n#3. Add a total length feature to the dataset\ndf['total_length'] =df['request_text_n_title'].apply(lambda x: len(x.split(' ')))\n\n#4. Ensure there are no zero length requests in the new feature/column\nprint 'nAfter combining request_title ...",
      "url": "https://notebook.community/omaraltaher/kaggle-pizza-project/Random_Acts_of_Pizza_Kaggle_Competition_Project"
    },
    {
      "title": "Random acts of pizza - a Kaggle competition \u00b7 What I talk about when I don't talk about me",
      "text": "- [Home](https://runze.github.io/)\n- [Technical Posts](https://runze.github.io/technical-posts/)\n- [Other Musings](https://runze.github.io/other-musings/)\n- [About](https://runze.github.io/about/)\n- [GitHub](https://github.com/Runze)\n- [LinkedIn](https://www.linkedin.com/in/runze-wang/)\n\nBuilt with\u00a0[Hugo](https://gohugo.io/)Theme\u00a0[Blackburn](https://github.com/yoshiharuyamashita/blackburn)\n\n2014-08-19\n\n[Kaggle](https://runze.github.io/tags/kaggle)\u00a0/\n[Machine learning](https://runze.github.io/tags/machine-learning)\u00a0/\n[R](https://runze.github.io/tags/r)\u00a0/\n[Text mining](https://runze.github.io/tags/text-mining)\n\nThis weekend, I participated in a Kaggle not-for-prize competition that uses data obtained from Reddit\u2019s Random Acts of Pizza [forum](http://www.reddit.com/r/Random_Acts_Of_Pizza/)\u00a0to analyze and predict the outcome of a request for pizza, and it was _heaps_ of fun (I always wanted to say that)! Compared with other Kaggle competitions I had tried before, I found this one\u00a0a bit easier because\u00a0the dataset is not very large (~5,000 records) and is hence perfect for model experimenting, and, more importantly, the competition is based on a real\u00a0[research](http://cs.stanford.edu/~althoff/raop-dataset/altruistic_requests_icwsm.pdf) done by a couple Stanford researchers, which provides me with a lot of guidelines in how to proceed. As my first shot, following the\u00a0paper, I replicated their\u00a0study by constructing\u00a0the same set of variables, and used\u00a0them to train a few predictive models. The result, .69 ROC, landed me at [No. 13](https://www.kaggle.com/c/random-acts-of-pizza/leaderboard) (out of 110)! I have put all my code on [github](https://github.com/Runze/pizza) (including the part related to topic modeling and data exploration) and here is a detailed explanation of what I did.\n\n**Topic modeling**\n\nFollowing the authors\u2019 strategy, the first thing I did was mining the requests (as it turned out, there are a fair amount of posts with blank content. Hence, I concatenated the request content\u00a0with the request title). After cleaning them up, removing stop words and keeping only nouns (using the [openNLP](http://cran.r-project.org/web/packages/openNLP/openNLP.pdf) package), I created a document-term matrix (DTM) using them and removed the very high- and low-frequency words (as they don\u2019t\u00a0help separate\u00a0topics) using the\u00a0[term frequency\u2013inverse document frequency](http://en.wikipedia.org/wiki/Tf%E2%80%93idf)\u00a0(tf-idf)\u00a0metric (per the method and code\u00a0described in this [vignette](http://cran.r-project.org/web/packages/topicmodels/vignettes/topicmodels.pdf)). Using this trimmed DTM, I applied the\u00a0[Latent Dirichlet allocation](http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) (LDA) algorithm from the topicmodels package (again per the vignette linked above) to identify topics. Note in the paper, the authors used \u201cnon-negative matrix factorization (NMF)\u201d to perform topic modeling. However, I wasn\u2019t able to find a package in R to do that. That aside, the 10 buckets of topics I got are not as clearly defined and distinguished as those found by the authors. In fact, I couldn\u2019t\u00a0see any clear-cut difference in the frequent terms used in my\u00a0topics at all.\u00a0Curious, I tried to find the optimal number of topics through a 10-fold cross-validation and evaluated the resulting split using perplexity, which, as defined in the vignette, uses the log likelihood and shares an inverse relationship with it (hence, the lower the perplexity the better the model fits).\u00a0Funnily, the results, as shown below, suggest 10 is indeed the optimal split (in the range of 2 to 10):\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/perplex.jpg)\n\nPerhaps a little hard to see, but 8 out of 10 cross-validation holdout sets picked 10 as the optimal value.\u00a0Here are the most frequent terms used in the 10\u00a0topics identified by my model:\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda10.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda9.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda8.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda7.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda6.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda5.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda4.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda3.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda2.png)\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/lda1.png)\n\nAlthough there are some patterns detected such as financial difficulties, family, parties, and so on, they are far less clear than\u00a0those identified by the paper. Besides the different algorithms\u00a0used, it may as\u00a0well\u00a0be that the authors performed more sophisticated cleaning and mining than I did. Out of curiosity, in addition to topic modeling, I also tried simple spherical k-means which, by default, restricts one document to only\u00a0one cluster and hence forces the \u201ctopic\u201d separation. As a result, my resulting 5 clusters (not shown here) are more different from each other and the patterns are closer to those found by the authors. Nevertheless, topic modeling\u00a0was _heaps_ of fun!\n\n**Create and explore variables**\n\nFollowing the authors\u2019 methodology, I created the same set of variables that\u00a0they used in their logistic regression. With regard to what these variables are, what they represent, and how they are constructed, please refer to the original paper. Here, I\u2019ll just show their relationship with the success rate of the pizza request. First, let\u2019s look at the 5 narrative buckets created using the key words suggested by the authors. They are created by matching the requests against those key words using regular expressions, counting the frequencies, dividing those by the total\u00a0length of the request (including the title), and converted them into deciles. Here are the relationships between the deciles and the success rate for each bucket (the 0 deciles shown below\u00a0represent the requests that do not have any key words for a particular bucket):\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/narrative.jpg)\n\nInterestingly, with the exception of money and craving,\u00a0these narrative categories do not exhibit a clear linear relationship with the outcome. One\u00a0of the reasons is that no other factors that may drive the outcome are\u00a0controlled yet. At least for those that do show a clear trend, the relationship is in line with what the study has found (e.g., more mentions of money troubles lead to a greater chance of success whereas more mentions of craving lead to the opposite).\n\nThe other\u00a0variables are more straightforward and their outcome is also more intuitive. Hence, I\u2019ll just show their relationship with the success rate\u00a0here. You can find the creation process in my code linked above.\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/explore.jpeg)\n\n**Training models**\n\nNow that we have all the variables, we can finally train some models! The first model I tried is the same logistic regression used by the authors. Even without the paper, I think logistic regression, or linear regression in general, should always be the first thing to try because its inference\u00a0power is very\u00a0valuable in understanding the relationship between the explanatory\u00a0variables and the outcome. Even if prediction is the sole purpose, I think it\u2019s necessary, not to mention fun, to understand what the model can tell us about the hidden relationships. Here are the coefficients and their statistical significance I got from the logit\u00a0model:\n\n![alt text](https://raw.githubusercontent.com/Runze/pizza/master/screenshot.png)\n\nComparing with the paper, I found my\u00a0results are generally in line with the\u00a0authors\u2019. Specifically, we both found that gratitude, hyperlink (e.g., image), reciprocity, request length, karma, whether...",
      "url": "https://runze.github.io/technical-posts/random-acts-of-pizza"
    },
    {
      "title": "Random Acts of Pizza",
      "text": "* * *\n**Random Acts of Pizza** is a project in which we trained multiple classification models to predict if a user gets a free pizza from the Reddit random acts of pizza community. This work was the final project of the course Applied Machine Learning. _Authors: Carolina Arriaga, Kanika Mahajan._\n**Overview**\n> We used data from the Kaggle competition Random Acts of Pizza to train multiple classifiers to predict a binary class. We used feature engineering by collecting user metadata and adding text-based features. We also applied dimensionality reduction using SVD. We explored four models: Logistic regression, Random Forests (Ada and XGB), Multilayer Neural Network, and Dense Neural Network. Finally, we proceeded with the hyperparameter tuning. We were able to predict whether a user would get a pizza or not.\n* * *\n* * *\n## Templates (for web app):\nLoading\u2026\n# Error\nSorry, an error occurred while loading .\nForwardBack[Permalink](https://www.caroarriaga.com/projects/raop/)Dark Mode",
      "url": "https://www.caroarriaga.com/projects/raop"
    },
    {
      "title": "GitHub - miketp333/Random_Acts_of_Pizza_Machine_Learning",
      "text": "[Skip to content](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[miketp333](https://github.com/miketp333)/ **[Random\\_Acts\\_of\\_Pizza\\_Machine\\_Learning](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Fmiketp333%2FRandom_Acts_of_Pizza_Machine_Learning) You must be signed in to change notification settings\n- [Fork\\\n0](https://github.com/login?return_to=%2Fmiketp333%2FRandom_Acts_of_Pizza_Machine_Learning)\n- [Star\\\n1](https://github.com/login?return_to=%2Fmiketp333%2FRandom_Acts_of_Pizza_Machine_Learning)\n\n\n[1\\\nstar](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/stargazers) [0\\\nforks](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/forks) [Branches](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/branches) [Tags](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tags) [Activity](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/activity)\n\n[Star](https://github.com/login?return_to=%2Fmiketp333%2FRandom_Acts_of_Pizza_Machine_Learning)\n\n[Notifications](https://github.com/login?return_to=%2Fmiketp333%2FRandom_Acts_of_Pizza_Machine_Learning) You must be signed in to change notification settings\n\n# miketp333/Random\\_Acts\\_of\\_Pizza\\_Machine\\_Learning\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmaster\n\n[Branches](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/branches) [Tags](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[30 Commits](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/commits/master/) |\n| [.ipynb\\_checkpoints](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tree/master/.ipynb_checkpoints) | [.ipynb\\_checkpoints](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tree/master/.ipynb_checkpoints) |  |  |\n| [Data](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tree/master/Data) | [Data](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tree/master/Data) |  |  |\n| [Old](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tree/master/Old) | [Old](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/tree/master/Old) |  |  |\n| [README.md](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/blob/master/README.md) | [README.md](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/blob/master/README.md) |  |  |\n| [final\\_project.ipynb](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/blob/master/final_project.ipynb) | [final\\_project.ipynb](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/blob/master/final_project.ipynb) |  |  |\n| View all files |\n\n## Repository files navigation\n\n## Random Acts of Pizza\n\n##### by Garber Boris, Josiah McDonald and Michael Powers\n\n##### July 2018\n\nThis dataset contains 5671 textual requests for pizza from the Reddit community Random Acts of Pizza together with their outcome (successful/unsuccessful) and meta-data. We use multiple machine learning approaches to build models that predict if a request will be successful or not. Some of our methods rely on the paper How to Ask for a Favor: A Case Study on the Success of Altruistic Requests (Althoff et al., 2014).\n\nSource Data: [https://www.kaggle.com/c/random-acts-of-pizza](https://www.kaggle.com/c/random-acts-of-pizza)\n\nSource Paper: [https://cs.stanford.edu/~althoff/raop-dataset/altruistic\\_requests\\_icwsm.pdf](https://cs.stanford.edu/~althoff/raop-dataset/altruistic_requests_icwsm.pdf)\n\n## About\n\nNo description, website, or topics provided.\n\n### Resources\n\n[Readme](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning#readme-ov-file)\n\n[Activity](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/activity)\n\n### Stars\n\n[**1**\\\nstar](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/stargazers)\n\n### Watchers\n\n[**4**\\\nwatching](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/watchers)\n\n### Forks\n\n[**0**\\\nforks](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fmiketp333%2FRandom_Acts_of_Pizza_Machine_Learning&report=miketp333+%28user%29)\n\n## [Releases](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/releases)\n\nNo releases published\n\n## [Packages\\ 0](https://github.com/users/miketp333/packages?repo_name=Random_Acts_of_Pizza_Machine_Learning)\n\nNo packages published\n\n## [Contributors\\ 3](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/graphs/contributors)\n\n## Languages\n\n- [Jupyter Notebook100.0%](https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning/search?l=jupyter-notebook)\n\nYou can\u2019t perform that action at this time.",
      "url": "https://github.com/miketp333/Random_Acts_of_Pizza_Machine_Learning"
    },
    {
      "title": "GitHub - leandroohf/raop: Random Acts of Pizza",
      "text": "[Skip to content](https://github.com/leandroohf/raop#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/leandroohf/raop) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/leandroohf/raop) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/leandroohf/raop) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[leandroohf](https://github.com/leandroohf)/ **[raop](https://github.com/leandroohf/raop)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Fleandroohf%2Fraop) You must be signed in to change notification settings\n- [Fork\\\n0](https://github.com/login?return_to=%2Fleandroohf%2Fraop)\n- [Star\\\n2](https://github.com/login?return_to=%2Fleandroohf%2Fraop)\n\n\nRandom Acts of Pizza\n\n[2\\\nstars](https://github.com/leandroohf/raop/stargazers) [0\\\nforks](https://github.com/leandroohf/raop/forks) [Branches](https://github.com/leandroohf/raop/branches) [Tags](https://github.com/leandroohf/raop/tags) [Activity](https://github.com/leandroohf/raop/activity)\n\n[Star](https://github.com/login?return_to=%2Fleandroohf%2Fraop)\n\n[Notifications](https://github.com/login?return_to=%2Fleandroohf%2Fraop) You must be signed in to change notification settings\n\n# leandroohf/raop\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmaster\n\n[Branches](https://github.com/leandroohf/raop/branches) [Tags](https://github.com/leandroohf/raop/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[151 Commits](https://github.com/leandroohf/raop/commits/master/) |\n| ### [data](https://github.com/leandroohf/raop/tree/master/data) | ### [data](https://github.com/leandroohf/raop/tree/master/data) |  |  |\n| ### [dev](https://github.com/leandroohf/raop/tree/master/dev) | ### [dev](https://github.com/leandroohf/raop/tree/master/dev) |  |  |\n| ### [dict](https://github.com/leandroohf/raop/tree/master/dict) | ### [dict](https://github.com/leandroohf/raop/tree/master/dict) |  |  |\n| ### [doc](https://github.com/leandroohf/raop/tree/master/doc) | ### [doc](https://github.com/leandroohf/raop/tree/master/doc) |  |  |\n| ### [models](https://github.com/leandroohf/raop/tree/master/models) | ### [models](https://github.com/leandroohf/raop/tree/master/models) |  |  |\n| ### [scratch](https://github.com/leandroohf/raop/tree/master/scratch) | ### [scratch](https://github.com/leandroohf/raop/tree/master/scratch) |  |  |\n| ### [tests](https://github.com/leandroohf/raop/tree/master/tests) | ### [tests](https://github.com/leandroohf/raop/tree/master/tests) |  |  |\n| ### [utils](https://github.com/leandroohf/raop/tree/master/utils) | ### [utils](https://github.com/leandroohf/raop/tree/master/utils) |  |  |\n| ### [README.md](https://github.com/leandroohf/raop/blob/master/README.md) | ### [README.md](https://github.com/leandroohf/raop/blob/master/README.md) |  |  |\n| ### [SETTINGS.json](https://github.com/leandroohf/raop/blob/master/SETTINGS.json) | ### [SETTINGS.json](https://github.com/leandroohf/raop/blob/master/SETTINGS.json) |  |  |\n| ### [data\\_wrangler.R](https://github.com/leandroohf/raop/blob/master/data_wrangler.R) | ### [data\\_wrangler.R](https://github.com/leandroohf/raop/blob/master/data_wrangler.R) |  |  |\n| ### [descriptive.R](https://github.com/leandroohf/raop/blob/master/descriptive.R) | ### [descriptive.R](https://github.com/leandroohf/raop/blob/master/descriptive.R) |  |  |\n| ### [etl.R](https://github.com/leandroohf/raop/blob/master/etl.R) | ### [etl.R](https://github.com/leandroohf/raop/blob/master/etl.R) |  |  |\n| ### [model\\_dev.R](https://github.com/leandroohf/raop/blob/master/model_dev.R) | ### [model\\_dev.R](https://github.com/leandroohf/raop/blob/master/model_dev.R) |  |  |\n| ### [pred.R](https://github.com/leandroohf/raop/blob/master/pred.R) | ### [pred.R](https://github.com/leandroohf/raop/blob/master/pred.R) |  |  |\n| ### [raop.org](https://github.com/leandroohf/raop/blob/master/raop.org) | ### [raop.org](https://github.com/leandroohf/raop/blob/master/raop.org) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Random Act of Pizza: (WIP)\n\n**This is a work in progress**\n\nIn this project data from online community Random Act of Pizza ( [RAoP](https://www.reddit.com/r/Random_Acts_Of_Pizza/))\nforum was analyzed.\nThe data is a collection of post where reddit's\nusers are requesting free pizza. Sentimental analyses were performed\nin the data and the findings were used to build a model to predict if\nthe post written by the user will be successful. The link for the\nanalysis can be found [here](https://github.com/leandroohf/raop/blob/master/raop.org) and a better explanation with\nmore detail can be found in the links below.\n\nStanford article\n[http://cs.stanford.edu/~althoff/raop-dataset/altruistic\\_requests\\_icwsm.pdf](http://cs.stanford.edu/~althoff/raop-dataset/altruistic_requests_icwsm.pdf)\n\nLink to references:\n[http://www.runzemc.com/2014/08/random-acts-of-pizza.html](http://www.runzemc.com/2014/08/random-acts-of-pizza.html)\n\nLink for data source\n[https://snap.stanford.edu/data/web-RedditPizzaRequests.html](https://snap.stanford.edu/data/web-RedditPizzaRequests.html)\n\nLink for redidt forum\n[https://www.reddit.com/r/Random\\_Acts\\_Of\\_Pizza/](https://www.reddit.com/r/Random_Acts_Of_Pizza/)\n\nLink for the anlaysis:\n[raop.org](https://github.com/leandroohf/raop/blob/master/raop.org)\n\n## Learn goals\n\n1. Get familiar with sentimental anlaysys\n2. Improve expertise in tune machine learning models\n3. Gain expertise with ensemble techniques\n4. Test new diagnostic tools Permutation test\n5. Get familiar with Ariflow ( **TODO**)\n\n## About\n\nRandom Acts of Pizza\n\n### Resources\n\n[Readme](https://github.com/leandroohf/raop#readme-ov-file)\n\n[Activity](https://github.com/leandroohf/raop/activity)\n\n### Stars\n\n[**2**\\\nstars](https://github.com/leandroohf/raop/stargazers)\n\n### Watchers\n\n[**2**\\\nwatching](https://github.com/leandroohf/raop/watchers)\n\n### Forks\n\n[**0**\\\nforks](https://github.com/leandroohf/raop/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fleandroohf%2Fraop&report=leandroohf+%28user%29)\n\n## [Releases](https://github.com/leandroohf/raop/releases)\n\nNo releases published\n\n## [Packages\\ 0](https://github.com/users/leandroohf/packages?repo_name=raop)\n\nNo packages published\n\n## Languages\n\n- [R100.0%](https://github.com/leandroohf/raop/search?l=r)\n\nYou can\u2019t perform that action at this time.",
      "url": "https://github.com/leandroohf/raop"
    },
    {
      "title": "Beat the Benchmark: Random Acts of Pizza",
      "text": "[Skip to content](https://gist.github.com/roycoding/1e24bce664cce16503b8#start-of-content)\n\nSearch Gists\n\nSearch Gists\n\n[Sign\u00a0in](https://gist.github.com/auth/github?return_to=https%3A%2F%2Fgist.github.com%2Froycoding%2F1e24bce664cce16503b8) [Sign\u00a0up](https://gist.github.com/join?return_to=https%3A%2F%2Fgist.github.com%2Froycoding%2F1e24bce664cce16503b8&source=header-gist)\n\nYou signed in with another tab or window. Reload to refresh your session.You signed out in another tab or window. Reload to refresh your session.You switched accounts on another tab or window. Reload to refresh your session.Dismiss alert\n\n{{ message }}\n\nInstantly share code, notes, and snippets.\n\n[![@roycoding](https://avatars.githubusercontent.com/u/747219?s=64&v=4)](https://gist.github.com/roycoding)\n\n# [roycoding](https://gist.github.com/roycoding)/ **[pizza-rf.md](https://gist.github.com/roycoding/1e24bce664cce16503b8)**\n\nLast active\nJune 27, 2017 18:36\n\nShow Gist options\n\n- [Download ZIP](https://gist.github.com/roycoding/1e24bce664cce16503b8/archive/75d8c43ee5b36303fffecf969d30d9328bd01c89.zip)\n\n- [Star1(1)](https://gist.github.com/login?return_to=https%3A%2F%2Fgist.github.com%2Froycoding%2F1e24bce664cce16503b8) You must be signed in to star a gist\n- [Fork0(0)](https://gist.github.com/login?return_to=https%3A%2F%2Fgist.github.com%2Froycoding%2F1e24bce664cce16503b8) You must be signed in to fork a gist\n\n- Embed\n\n\n\n\n\n\n\n- Embed\nEmbed this gist in your website.\n- Share\nCopy sharable link for this gist.\n- Clone via HTTPS\nClone using the web URL.\n- [Learn more about clone URLs](https://docs.github.com/articles/which-remote-url-should-i-use)\n\nClone this repository at &lt;script src=&quot;https://gist.github.com/roycoding/1e24bce664cce16503b8.js&quot;&gt;&lt;/script&gt;\n\n- Save roycoding/1e24bce664cce16503b8 to your computer and use it in GitHub Desktop.\n\nEmbed\n\n- Embed\nEmbed this gist in your website.\n- Share\nCopy sharable link for this gist.\n- Clone via HTTPS\nClone using the web URL.\n- [Learn more about clone URLs](https://docs.github.com/articles/which-remote-url-should-i-use)\n\nClone this repository at &lt;script src=&quot;https://gist.github.com/roycoding/1e24bce664cce16503b8.js&quot;&gt;&lt;/script&gt;\n\nSave roycoding/1e24bce664cce16503b8 to your computer and use it in GitHub Desktop.\n\n[Download ZIP](https://gist.github.com/roycoding/1e24bce664cce16503b8/archive/75d8c43ee5b36303fffecf969d30d9328bd01c89.zip)\n\nBeat the Benchmark: Random Acts of Pizza\n\n[Raw](https://gist.github.com/roycoding/1e24bce664cce16503b8/raw/75d8c43ee5b36303fffecf969d30d9328bd01c89/pizza-rf.md)\n\n[**pizza-rf.md**](https://gist.github.com/roycoding/1e24bce664cce16503b8#file-pizza-rf-md)\n\n# Beating the Random Acts of Pizza Benchmark\n\n## Day 2 of the [Beat 5 Kaggle Becnhmarks in 5 Days Challenge](https://www.kaggle.com/forums/t/10062/beat-5-kaggle-benchmarks-in-5-days-challenge).\n\nThe [Random Acts of Pizza](https://www.kaggle.com/c/random-acts-of-pizza) competition is about predicting when a request for a free pizza on the Random Acts of Pizza sub-reddit is granted. The benchmark is simply guessing that no pizzas are given (or all). This results in an AUC score of 50.\n\nTo beat the AUC = 50 benchmark with a simple model, I first looked at the training and test data to find simple features. I decided to use the word counts of the request title and comment text, as longer comments might be skipped by readers.\n\nTo build the model I first extracted only the desired fields from the original JSON files with jq and used json2csv to write out CSV.\n\n```\ncat train.json|jq -c '.[]' | json2csv -p -k=request_id,requester_received_pizza,request_title,request_text_edit_aware -d=\"|\" > train_1.csv\n\ncat test.json|jq -c '.[]' | json2csv -p -k=request_id,request_title,request_text_edit_aware -d=\"|\" > test_1.csv\n```\n\nI then built a very basic random forest model using the default settings in scikit-learn. With a 80/20 training/test split I achieved a local AUC of about 0.52 (single validation). Using the entire training set to build a random forest, I was able to score an AUC of 0.51274 on the competition leaderboard.\n\nNot great, but not bad for a very simple model.\n\n```\nimport pandas as pd\nfrom sklearn import cross_validation\nfrom sklearn import ensemble\nfrom sklearn import metrics\n\ntrain = pd.read_csv('train_1.csv',delimiter='|')\ntest = pd.read_csv('test_1.csv',delimiter='|')\n\n# Create text word count and title word count fields and binarize pizza received\ntrain.requester_received_pizza = train.requester_received_pizza.apply(lambda x: 1 if x else 0)\ntrain['title_count'] = train.request_title.apply(lambda x: len(x.split()))\ntrain['text_count'] = train.request_text_edit_aware.apply(lambda x: len(str(x).split()))\n\ntest['title_count'] = test.request_title.apply(lambda x: len(x.split()))\ntest['text_count'] = test.request_text_edit_aware.apply(lambda x: len(str(x).split()))\n\n# Create training and testing arrays as well as validation splits\ntrain_X = train.drop(['request_id', u'requester_received_pizza', u'request_title', u'request_text_edit_aware'],axis=1).values\ntrain_y = train.requester_received_pizza.values\nX,X_,y,y_ = cross_validation.train_test_split(train_X,train_y,test_size=0.2)\n\ntest_X = test.drop(['request_id','request_title','request_text_edit_aware'],axis=1).values\n\n# Train and test random forest model\nrf = ensemble.RandomForestClassifier() # Default values\nrf.fit(X,y)\ny_rf = rf.predict(X_)\nprint metrics.roc_auc_score(y_,y_rf)\n\n# Train model with full training data and predict test y's\nrf.fit(train_X,train_y)\ny_test_rf = rf.predict(test_X)\n\n# Write submission file\ntest_out = pd.DataFrame({'request_id':test.request_id.values,'requester_received_pizza':y_test_rf.astype('int')})\ntest_out.to_csv('rf1.csv',index=False)\n```\n\n[Sign up for free](https://gist.github.com/join?source=comment-gist) **to join this conversation on GitHub**.\nAlready have an account?\n[Sign in to comment](https://gist.github.com/login?return_to=https%3A%2F%2Fgist.github.com%2Froycoding%2F1e24bce664cce16503b8)\n\nYou can\u2019t perform that action at this time.",
      "url": "https://gist.github.com/roycoding/1e24bce664cce16503b8"
    },
    {
      "title": "Search code, repositories, users, issues, pull requests...",
      "text": "GitHub - Runze/pizza: Random acts of pizza - a Kaggle competition\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/Runze/pizza)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/Runze/pizza)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=Runze/pizza)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[Runze](https://github.com/Runze)/**[pizza](https://github.com/Runze/pizza)**Public\n* [Notifications](https://github.com/login?return_to=/Runze/pizza)You must be signed in to change notification settings\n* [Fork5](https://github.com/login?return_to=/Runze/pizza)\n* [Star1](https://github.com/login?return_to=/Runze/pizza)\nRandom acts of pizza - a Kaggle competition\n[1star](https://github.com/Runze/pizza/stargazers)[5forks](https://github.com/Runze/pizza/forks)[Branches](https://github.com/Runze/pizza/branches)[Tags](https://github.com/Runze/pizza/tags)[Activity](https://github.com/Runze/pizza/activity)\n[Star](https://github.com/login?return_to=/Runze/pizza)\n[Notifications](https://github.com/login?return_to=/Runze/pizza)You must be signed in to change notification settings\n# Runze/pizza\nmaster\n[Branches](https://github.com/Runze/pizza/branches)[Tags](https://github.com/Runze/pizza/tags)\n[](https://github.com/Runze/pizza/branches)[](https://github.com/Runze/pizza/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[8 Commits](https://github.com/Runze/pizza/commits/master/)\n[](https://github.com/Runze/pizza/commits/master/)\n|\n[.gitignore](https://github.com/Runze/pizza/blob/master/.gitignore)\n|\n[.gitignore](https://github.com/Runze/pizza/blob/master/.gitignore)\n|\n|\n|\n[1. topic modeling.R](https://github.com/Runze/pizza/blob/master/1.%20topic%20modeling.R)\n|\n[1. topic modeling.R](https://github.com/Runze/pizza/blob/master/1.%20topic%20modeling.R)\n|\n|\n|\n[2. create and explore variables.R](https://github.com/Runze/pizza/blob/master/2.%20create%20and%20explore%20variables.R)\n|\n[2. create and explore variables.R](https://github.com/Runze/pizza/blob/master/2.%20create%20and%20explore%20variables.R)\n|\n|\n|\n[3. train models.R](https://github.com/Runze/pizza/blob/master/3.%20train%20models.R)\n|\n[3. train models.R](https://github.com/Runze/pizza/blob/master/3.%20train%20models.R)\n|\n|\n|\n[4. apply to test.R](https://github.com/Runze/pizza/blob/master/4.%20apply%20to%20test.R)\n|\n[4. apply to test.R](https://github.com/Runze/pizza/blob/master/4.%20apply%20to%20test.R)\n|\n|\n|\n[README.md](https://github.com/Runze/pizza/blob/master/README.md)\n|\n[README.md](https://github.com/Runze/pizza/blob/master/README.md)\n|\n|\n|\n[explore.jpeg](https://github.com/Runze/pizza/blob/master/explore.jpeg)\n|\n[explore.jpeg](https://github.com/Runze/pizza/blob/master/explore.jpeg)\n|\n|\n|\n[importance.jpeg](https://github.com/Runze/pizza/blob/master/importance.jpeg)\n|\n[importance.jpeg](https://github.com/Runze/pizza/blob/master/importance.jpeg)\n|\n|\n|\n[lda1.png](https://github.com/Runze/pizza/blob/master/lda1.png)\n|\n[lda1.png](https://github.com/Runze/pizza/blob/master/lda1.png)\n|\n|\n|\n[lda10.png](https://github.com/Runze/pizza/blob/master/lda10.png)\n|\n[lda10.png](https://github.com/Runze/pizza/blob/master/lda10.png)\n|\n|\n|\n[lda2.png](https://github.com/Runze/pizza/blob/master/lda2.png)\n|\n[lda2.png](https://github.com/Runze/pizza/blob/master/lda2.png)\n|\n|\n|\n[lda3.png](https://github.com/Runze/pizza/blob/master/lda3.png)\n|\n[lda3.png](https://github.com/Runze/pizza/blob/master/lda3.png)\n|\n|\n|\n[lda4.png](https://github.com/Runze/pizza/blob/master/lda4.png)\n|\n[lda4.png](https://github.com/Runze/pizza/blob/master/lda4.png)\n|\n|\n|\n[lda5.png](https://github.com/Runze/pizza/blob/master/lda5.png)\n|\n[lda5.png](https://github.com/Runze/pizza/blob/master/lda5.png)\n|\n|\n|\n[lda6.png](https://github.com/Runze/pizza/blob/master/lda6.png)\n|\n[lda6.png](https://github.com/Runze/pizza/blob/master/lda6.png)\n|\n|\n|\n[lda7.png](https://github.com/Runze/pizza/blob/master/lda7.png)\n|\n[lda7.png](https://github.com/Runze/pizza/blob/master/lda7.png)\n|\n|\n|\n[lda8.png](https://github.com/Runze/pizza/blob/master/lda8.png)\n|\n[lda8.png](https://github.com/Runze/pizza/blob/master/lda8.png)\n|\n|\n|\n[lda9.png](https://github.com/Runze/pizza/blob/master/lda9.png)\n|\n[lda9.png](https://github.com/Runze/pizza/blob/master/lda9.png)\n|\n|\n|\n[narrative.jpg](https://github.com/Runze/pizza/blob/master/narrative.jpg)\n|\n[narrative.jpg](https://github.com/Runze/pizza/blob/master/narrative.jpg)\n|\n|\n|\n[parallel.jpeg](https://github.com/Runze/pizza/blob/master/parallel.jpeg)\n|\n[parallel.jpeg](https://github.com/Runze/pizza/blob/master/parallel.jpeg)\n|\n|\n|\n[perplex.jpg](https://github.com/Runze/pizza/blob/master/perplex.jpg)\n|\n[perplex.jpg](https://github.com/Runze/pizza/blob/master/perplex.jpg)\n|\n|\n|\n[screenshot.png](https://github.com/Runze/pizza/blob/master/screenshot.png)\n|\n[screenshot.png](https://github.com/Runze/pizza/blob/master/screenshot.png)\n|\n|\n|\n[sk1.jpeg](https://github.com/Runze/pizza/blob/master/sk1.jpeg)\n|\n[sk1.jpeg](https://github.com/Runze/pizza/blob/master/sk1.jpeg)\n|\n|\n|\n[sk2.jpeg](https://github.com/Runze/pizza/blob/master/sk2.jpeg)\n|\n[sk2.jpeg](https://github.com/Runze/pizza/blob/master/sk2.jpeg)\n|\n|\n|\n[sk3.jpeg](https://github.com/Runze/pizza/blob/master/sk3.jpeg)\n|\n[sk3.jpeg](https://github.com/Runze/pizza/blob/master/sk3.jpeg)\n|\n|\n|\n[sk4.jpeg](https://github.com/Runze/pizza/blob/master/sk4.jpeg)\n|\n[sk4.jpeg](https://github.com/Runze/pizza/blob/master/sk4.jpeg)\n|\n|\n|\n[sk5.jpeg](https://github.com/Runze/pizza/blob/master/sk5.jpeg)\n|\n[sk5.jpeg](https://github.com/Runze/pizza/blob/master/sk5.jpeg)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# Random acts of pizza - a Kaggle competition\n[](#random-acts-of-pizza---a-kaggle-competition)\nThis is the code I have used for the Kaggle not-for-prize competition[here](https://www.kaggle.com/c/random-acts-of-pizza). The code landed me at No. 13 (out of 110 currently). My methodology is explained in the blog post[here](http://www.runzemc.com/2014/08/random-acts-of-pizza.html).\nThe data are not included and can be downloaded from the competition[website](https://www.kaggle.com/c/random-acts-of-pizza/data)directly.\nNow who's going to buy me a pizza? :-)\n## About\nRandom acts of pizza - a Kaggle competition\n### Resources\n[Readme](#readme-ov-file)\n### Uh oh!\nThere was an error while loading.[Please reload this page]().\n[Activity](https://github.com/Runze/pizza/activity)\n### Stars\n[**1**star](https://github.com/Runze/pizza/stargazers)\n### Watchers\n[**0**watching](https://github.com/Runze/pizza/watchers)\n### Forks\n[**5**forks](https://github.com/Runze/pizza/forks)\n[Report repository](https://github.com/contact/report-content?content_url=https://github.com/Runze/pizza&amp;report=Runze+(user))\n## [Releases](https://github.com/Runze/p...",
      "url": "https://github.com/Runze/pizza"
    },
    {
      "title": "roycoding / pizza-rf.md",
      "text": "Beat the Benchmark: Random Acts of Pizza \u00b7GitHub\n[Skip to content](#start-of-content)\n[](https://gist.github.com/)\n</option></form>\nSearch Gists\nSearch Gists\n[](https://gist.github.com/)\n[Signin](https://gist.github.com/auth/github?return_to=https://gist.github.com/roycoding/1e24bce664cce16503b8)[Signup](https://gist.github.com/join?return_to=https://gist.github.com/roycoding/1e24bce664cce16503b8&amp;source=header-gist)\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\nInstantly share code, notes, and snippets.\n[![@roycoding](https://avatars.githubusercontent.com/u/747219?s=64&amp;v=4)](https://gist.github.com/roycoding)\n# [roycoding](https://gist.github.com/roycoding)/**[pizza-rf.md](https://gist.github.com/roycoding/1e24bce664cce16503b8)**\nLast activeJune 27, 2017 18:36\nShow Gist options\n* [Download ZIP](https://gist.github.com/roycoding/1e24bce664cce16503b8/archive/75d8c43ee5b36303fffecf969d30d9328bd01c89.zip)\n* [Star1(1)](https://gist.github.com/login?return_to=https://gist.github.com/roycoding/1e24bce664cce16503b8)You must be signed in to star a gist\n* [Fork0(0)](https://gist.github.com/login?return_to=https://gist.github.com/roycoding/1e24bce664cce16503b8)You must be signed in to fork a gist\n* Embed\n# Select an option\n* EmbedEmbed this gist in your website.\n* ShareCopy sharable link for this gist.\n* Clone via HTTPSClone using the web URL.\n## No results found\n[Learn more about clone URLs](https://docs.github.com/articles/which-remote-url-should-i-use)\nClone this repository at &amp;lt;script src=&amp;quot;https://gist.github.com/roycoding/1e24bce664cce16503b8.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;\n* Save roycoding/1e24bce664cce16503b8 to your computer and use it in GitHub Desktop.\nEmbed\n# Select an option\n* EmbedEmbed this gist in your website.\n* ShareCopy sharable link for this gist.\n* Clone via HTTPSClone using the web URL.\n## No results found\n[Learn more about clone URLs](https://docs.github.com/articles/which-remote-url-should-i-use)\nClone this repository at &amp;lt;script src=&amp;quot;https://gist.github.com/roycoding/1e24bce664cce16503b8.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;\nSave roycoding/1e24bce664cce16503b8 to your computer and use it in GitHub Desktop.\n[Download ZIP](https://gist.github.com/roycoding/1e24bce664cce16503b8/archive/75d8c43ee5b36303fffecf969d30d9328bd01c89.zip)\nBeat the Benchmark: Random Acts of Pizza\n[Raw](https://gist.github.com/roycoding/1e24bce664cce16503b8/raw/75d8c43ee5b36303fffecf969d30d9328bd01c89/pizza-rf.md)\n[**pizza-rf.md**](#file-pizza-rf-md)\n# Beating the Random Acts of Pizza Benchmark\n[](#beating-the-random-acts-of-pizza-benchmark)\n## Day 2 of the[Beat 5 Kaggle Becnhmarks in 5 Days Challenge](https://www.kaggle.com/forums/t/10062/beat-5-kaggle-benchmarks-in-5-days-challenge).\n[](#day-2-of-the-beat-5-kaggle-becnhmarks-in-5-days-challenge)\nThe[Random Acts of Pizza](https://www.kaggle.com/c/random-acts-of-pizza)competition is about predicting when a request for a free pizza on the Random Acts of Pizza sub-reddit is granted. The benchmark is simply guessing that no pizzas are given (or all). This results in an AUC score of 50.\nTo beat the AUC = 50 benchmark with a simple model, I first looked at the training and test data to find simple features. I decided to use the word counts of the request title and comment text, as longer comments might be skipped by readers.\nTo build the model I first extracted only the desired fields from the original JSON files with jq and used json2csv to write out CSV.\n```\ncat train.json|jq -c'.[]'|json2csv -p -k=request\\_id,requester\\_received\\_pizza,request\\_title,request\\_text\\_edit\\_aware -d=\"|\"&gt;train\\_1.csv\ncat test.json|jq -c'.[]'|json2csv -p -k=request\\_id,request\\_title,request\\_text\\_edit\\_aware -d=\"|\"&gt;test\\_1.csv\n```\nI then built a very basic random forest model using the default settings in scikit-learn. With a 80/20 training/test split I achieved a local AUC of about 0.52 (single validation). Using the entire training set to build a random forest, I was able to score an AUC of 0.51274 on the competition leaderboard.\nNot great, but not bad for a very simple model.\n```\nimportpandasaspdfromsklearnimportcross\\_validationfromsklearnimportensemblefromsklearnimportmetricstrain=pd.read\\_csv('train\\_1.csv',delimiter='|')test=pd.read\\_csv('test\\_1.csv',delimiter='|')# Create text word count and title word count fields and binarize pizza receivedtrain.requester\\_received\\_pizza=train.requester\\_received\\_pizza.apply(lambdax:1ifxelse0)train['title\\_count']=train.request\\_title.apply(lambdax:len(x.split()))train['text\\_count']=train.request\\_text\\_edit\\_aware.apply(lambdax:len(str(x).split()))test['title\\_count']=test.request\\_title.apply(lambdax:len(x.split()))test['text\\_count']=test.request\\_text\\_edit\\_aware.apply(lambdax:len(str(x).split()))# Create training and testing arrays as well as validation splitstrain\\_X=train.drop(['request\\_id',u'requester\\_received\\_pizza',u'request\\_title',u'request\\_text\\_edit\\_aware'],axis=1).valuestrain\\_y=train.requester\\_received\\_pizza.valuesX,X\\_,y,y\\_=cross\\_validation.train\\_test\\_split(train\\_X,train\\_y,test\\_size=0.2)test\\_X=test.drop(['request\\_id','request\\_title','request\\_text\\_edit\\_aware'],axis=1).values# Train and test random forest modelrf=ensemble.RandomForestClassifier()# Default valuesrf.fit(X,y)y\\_rf=rf.predict(X\\_)printmetrics.roc\\_auc\\_score(y\\_,y\\_rf)# Train model with full training data and predict test y'srf.fit(train\\_X,train\\_y)y\\_test\\_rf=rf.predict(test\\_X)# Write submission filetest\\_out=pd.DataFrame({'request\\_id':test.request\\_id.values,'requester\\_received\\_pizza':y\\_test\\_rf.astype('int')})test\\_out.to\\_csv('rf1.csv',index=False)\n```\n[Sign up for free](https://gist.github.com/join?source=comment-gist)**to join this conversation on GitHub**.\nAlready have an account?[Sign in to comment](https://gist.github.com/login?return_to=https://gist.github.com/roycoding/1e24bce664cce16503b8)\nYou can\u2019t perform that action at this time.\n</div>",
      "url": "https://gist.github.com/1e24bce664cce16503b8"
    }
  ]
}