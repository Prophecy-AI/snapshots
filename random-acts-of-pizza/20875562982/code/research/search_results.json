{
  "query": "What feature engineering techniques work well for Reddit post classification and social media metadata features?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Feature engineering for Reddit\u2011post classification typically starts with **text\u2011centric preprocessing** followed by the creation of **structured metadata features** that capture a post\u2019s social signals.  In most tutorials the raw title and self\u2011text are first merged into a single document, then cleaned by dropping nulls, duplicate or stickied entries, cross\u2011posts, URLs and any non\u2011alphabetic characters\u202f([medium.com](https://medium.com/data-science/reddit-post-classification-b70258d6affe)).  After this, a custom stop\u2011word list (often extended with the most frequent subreddit\u2011specific terms) and lemmatization are applied to reduce noise while preserving meaning\u202f([medium.com](https://medium.com/data-science/reddit-post-classification-b70258d6affe)).  The cleaned corpus is then turned into numerical vectors using classic bag\u2011of\u2011words or TF\u2011IDF representations, optionally enriched with n\u2011grams or pretrained word embeddings; these dense or sparse vectors feed linear models (SVM, XGBoost) or deep learners such as a single\u2011layer LSTM that has been shown to reach\u202f\u2248\u202f86\u202f% accuracy on title\u2011only classification\u202f([stanford.edu](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1174/reports/2762088.pdf)).\n\nBeyond the text itself, Reddit provides a rich set of **metadata** that can be engineered into predictive features.  Common numeric signals include up\u2011vote count, comment count, award count, author karma, and post age; these are often log\u2011scaled or normalized to reduce skewness.  Interaction features\u2014e.g., the ratio of up\u2011votes to comments, or the product of award count and author karma\u2014capture engagement intensity and have been recommended as simple yet powerful additions in competition notebooks\u202f([reddit.com](https://www.reddit.com/r/learnmachinelearning/comments/1ky8bqu/how_does_feature_engineering_work)).  Categorical fields such as subreddit name, author flair, or posting hour are one\u2011hot encoded, while temporal attributes (hour of day, day of week) can be cyclically encoded (sin\u202f/\u202fcos) to preserve periodicity.  When the feature space becomes high\u2011dimensional (e.g., thousands of TF\u2011IDF terms), dimensionality\u2011reduction techniques like truncated SVD or PCA, and feature\u2011selection based on chi\u2011square or model importance, help keep models tractable\u202f([projectpro.io](https://www.projectpro.io/article/8-feature-engineering-techniques-for-machine-learning/423)).\n\nPutting these steps together\u2014cleaned lemmatized text \u2192 TF\u2011IDF / embeddings, engineered numeric/social signals \u2192 scaling and interaction terms, categorical metadata \u2192 one\u2011hot or cyclic encodings, followed by optional dimensionality reduction\u2014provides a robust feature set that works well with both traditional classifiers (SVM, XGBoost) and neural architectures for Reddit post classification.",
      "url": ""
    },
    {
      "title": "Reddit Post Classification - by Andrew Bergman",
      "text": "<div><article><div><div><div><h2>Reddit Post Classification</h2><div><a href=\"https://medium.com/@andrew.j.bergman?source=post_page---byline--b70258d6affe---------------------------------------\"><div><p></p></div></a></div></div><p>During my data science immersive the third project I had to complete was a Reddit post classification. We had just completed data scraping and natural language processing so the project had two parts: scrape as many posts from Reddit\u2019s API as allowed &amp;then use classification models to predict the origin of the posts.</p><p>I completed the project a while ago, but I decided to revisit the project with more experience: since then I learned about two new classification models (support vector classifier and XGBoost classifier) .</p></div><div><div><h2>Data Scraping, Cleaning, And Preprocessing</h2><p>The process of scraping data from Reddit\u2019s API is fairly simple: it\u2019s just a basic request set up since they do not require a key to access the API. Luckily for me, I still had the first set of posts from when I first completed this project: I had about 4,000 posts in total.</p><p>In some respects, cleaning up text is a lot easier than having to clean up numeric data: I just had to remove nulls, filter out duplicates &amp; stickied posts, filter out cross-posts, non-letter characters, and URLs. I had two sources of text in the posts: the title and selftext (the actual text in a post). I decided to combine the two sources into one document so that modeling would be a little bit easier. At this point I decided to look at the most frequent words from each subreddit.</p></div><div><figure><figcaption>The 15 most frequent words before being lemmatized</figcaption></figure></div><div><p>Once I had an idea of what the most common words were, I was able to add them to the list of stop words I used.</p><p>The last preprocessing step I took was to lemmatize the text. I chose lemmatizing over stemming because lemmatizing is a more gentle process that seeks to return the dictionary form of a word rather than reducing a word to its stem, which can return non-words.</p></div></div><div><h2>Modeling</h2><pre><span>import nltk<br/>import pandas as pd<br/>import numpy as np<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>from nltk.corpus import stopwords<br/>from nltk.stem import WordNetLemmatizer<br/>from nltk.tokenize import RegexpTokenizer <br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.feature_extraction.text import TfidfVectorizerfrom <br/>from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import confusion_matrix <br/>from sklearn.metrics import roc_auc_score<br/>from sklearn.metrics import accuracy_score, f1_score<br/>from sklearn.metrics import balanced_accuracy_score<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn.model_selection import train_test_split<br/>from skearnn.model_selection import cross_val_score<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.svm import SVC<br/>from sklearn.tree import DecisionTreeClassifier<br/>from xgboost import XGBClassifier</span></pre><p>I approached the problem with 4 models: logistic regression, support vector classifier (SVC), and XGBoost classifier. Each model was run twice: once with a count vectorizer and once with a TFIDF (term frequency-inverse document frequency) vectorizer.</p><ul><li>Count vectorizer takes each word from each row in the data &amp; creates a column for it and counts how many times that word occurs.</li><li>TFIDF vectorizer does the same but, instead of returning a count, returns the frequency as a percentage scaled by how often it appears across all documents.</li></ul><p>I had to use a gridsearch on each model because I was tuning 2 sets of hyperparameters (parameters the algorithm cannot determine): one set for the vectorizers and one set for the actual models.</p><p>When it came to evaluation, I used three sets of metrics: metric evaluations (accuracy, sensitivity, specificity.), confusion matrices, and an ROC (receiver operating characteristic) curve and score. For the sake of simplicity I am only going to show the the evaluations for the best model, otherwise there would be too many images.</p></div><div><p>I started out with a logistic regression model because it is simple: if that model performed poorly, I would have to move on to a different model type. The logistic regression\u2019s performance was variable: it performed a lot better with the TFIDF vectorizer and was overfit.</p><p>The next model I tried was a SVC model. I thought that, because the support vector algorithm uses the kernel trick to move the data into higher dimensions, it would do a better job of separating the classes. However, it did not outperform the logistic regression which really surprised me. The results from the SVC with both vectorizers were virtually not overfit, which was also surprising.</p><p>I moved on to a random forest classifier next. Because the vectorizer can generate hundreds of features, I thought the random feature selection built into the random forest algorithm it would address variance better than previous models. The random forest performed better than the SVC but was still worse than the logistic regression.</p><p>Finally, I turned to XGBoost. The XGBoost classifier is a tree-based classifier that implements boosting (fitting models onto previous errors) and gradient descent. I was sure that this would be my best model but it was not: it still outperformed SVC and the random forest</p></div><div><div><h2>The Best Model</h2><p>My best model was a logistic regression with TFIDF vectorization. Despite it being the best model, it is far from a good model.</p></div><div><p>I chose these metrics because they represent model accuracy different ways.</p><ul><li><strong>Accuracy </strong>is overall how many predictions were correct</li><li><strong>Specificity </strong>is how many negative predictions are correct (r/AskCulinary)</li><li><strong>Sensitivity </strong>is how many positive predictions are correct (r/Cooking)</li><li><strong>ROC AUC Score </strong>essentially measures how distinct the positive and negative classes are.</li><li><strong>Matthews Corr. Coef.</strong> is a measure of how correlated the actual values and predicted values are.</li></ul><p>This model outperformed the baseline (41.89%) in terms of accuracy, but its scores are still not great. I optimized for sensitivity, meaning that I wanted to predict posts from r/Cooking, but this model had a terrible sensitivity: it was better at predicting the negative class (r/AskCulinary) because there were more instances of it. The MCC is low, but it is still positive which is a good thing.</p><figure></figure><p>The ROC curve plots the logistic regression\u2019s ability to distinguish between the two classes, i.e. r/Cooking &amp; r/AskCulinary. The curve itself shows the relationship between sensitivity and and false positives. However, more important is the AUC (area under the curve) because it shows the distinction between both classes. The lowest possible score is 0.5 and my best model\u2019s score is 0.67, which is not a good score at all: the model has a hard time distinguishing between the classes.</p></div></div><div><h2>Conclusions</h2><p>I was not able to satisfactorily classify the subreddit of origin for the posts I was working with.</p><p>The model\u2019s performance left a lot to be desired. Other models had specificity scores, but performed worse with the others. Additionally, the models were overfit, even though I tried algorithms that can help deal with overfitting.</p><p>The method of vectorization improved the performance, but not by a huge degree; this is an area that I would like to continue experimenting with.</p><p>Finally, I would like to try running a neural network because they are very good at classification problems.</p></div><div><p>I wasn\u2019t abl...",
      "url": "https://medium.com/data-science/reddit-post-classification-b70258d6affe"
    },
    {
      "title": "How does feature engineering work????",
      "text": "Reddit - The heart of the internet[Skip to main content](#main-content)\n[\nGo to learnmachinelearning](https://www.reddit.com/r/learnmachinelearning/)\n[r/learnmachinelearning](https://www.reddit.com/r/learnmachinelearning/)\u2022\n[krypto\\_gamer07](https://www.reddit.com/user/krypto_gamer07/)\n[Fran\u00e7ais](https://www.reddit.com/r/learnmachinelearning/comments/1ky8bqu/how_does_feature_engineering_work/?tl=fr)[Bahasa Melayu](https://www.reddit.com/r/learnmachinelearning/comments/1ky8bqu/how_does_feature_engineering_work/?tl=ms)\n# How does feature engineering work????\nI am a fresher in this department and I decided to participate in competitions to understand ML engineering better. Kaggle is holding the playground prediction competition in which we have to predict the Calories burnt by an individual. People can upload there notebooks as well so I decided to take some inspiration on how people are doing this and I have found that people are just creating new features using existing one. For ex, BMI, HR\\_temp which is just multiplication of HR, temp and duration of the individual..\nHOW DOES one get the idea of feature engineering? Do i just multiply different variables in hope of getting a better model with more features?\nAren&#39;t we taught things like PCA which is to REDUCE dimensionality? then why are we trying to create more features?\nRead more\nShare\n# Related Answers Section\nRelated Answers\n[\nBest methods for feature engineering in ML\n](https://www.reddit.com/answers/04de7e6d-f297-4964-a6f4-23ec6658518f/?q=Best%20methods%20for%20feature%20engineering%20in%20ML&amp;source=PDP)\n[\nTechniques for effective feature engineering\n](https://www.reddit.com/answers/bee71153-b6e0-45cf-acdb-6684e51e910c/?q=Techniques%20for%20effective%20feature%20engineering&amp;source=PDP)\n[\nDefine features in machine learning\n](https://www.reddit.com/answers/1f47eda4-1234-4dc0-acbf-cd350f12d133/?q=Define%20features%20in%20machine%20learning&amp;source=PDP)\n[\nReal-time feature engineering strategies\n](https://www.reddit.com/answers/b2a47d0c-1aaf-4925-9261-2771a07d9087/?q=Real-time%20feature%20engineering%20strategies&amp;source=PDP)\n[\nProgramming languages for machine learning\n](https://www.reddit.com/answers/f038071d-74bb-47cb-8513-30b2fa42910c/?q=Programming%20languages%20for%20machine%20learning&amp;source=PDP)\nNew to Reddit?\nCreate your account and connect with a world of communities.\nContinue with Email\nContinue With Phone Number\nBy continuing, you agree to our[User Agreement](https://www.redditinc.com/policies/user-agreement)and acknowledge that you understand the[Privacy Policy](https://www.redditinc.com/policies/privacy-policy).\nPublic\nAnyone can view, post, and comment to this community\n00\n[Reddit Rules](https://www.redditinc.com/policies/content-policy)[Privacy Policy](https://www.reddit.com/policies/privacy-policy)[User Agreement](https://www.redditinc.com/policies/user-agreement)[Accessibility](https://support.reddithelp.com/hc/sections/38303584022676-Accessibility)[Reddit, Inc. \u00a92025. All rights reserved.](https://redditinc.com)\nExpand NavigationCollapse Navigation",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1ky8bqu/how_does_feature_engineering_work"
    },
    {
      "title": "Deep Classification and Generation of Reddit Post Titles",
      "text": "Deep Classification and Generation of Reddit Post\nTitles\nTyler Chase\ntchase56@stanford.edu\nRolland He\nrhe@stanford.edu\nWilliam Qiu\nwillqiu@stanford.edu\nAbstract\nThe online news aggregation website Reddit offers a rich source of user-submitted\ncontent. In this paper, we analyze the titles of submissions on Reddit and build\ncontextual models that learn the patterns of posts from different subcommunities,\ncalled subreddits. The scope of our project is twofold. First, we use post titles\nfrom 10 hand-selected subreddits and build a single-layer LSTM classifier model\nto predict the subreddit a particular title is from. Additionally, we implement a bot\nthat is able to generate random post titles using LSTMs trained on each individual\nsubreddit. Our classification algorithm performs quite well and achieves an aver\u0002age test accuracy of 85.6%. Our post generator had mixed results, with an average\ntest perplexity of approximately 200 across the subreddits. Qualitative assessment\nof the generations demonstrate that our model outputs vaguely sensible results\non average, with posts from certain subreddits being easier to generate than oth\u0002ers. Though there is certainly room for improvement, we believe our novel results\nprovide a good baseline that can be extended upon.\n1 Introduction\nReddit is an online social news aggregation and internet forum. With over 540 million monthly\nvisitors, 70 million submissions, and 700 million comments 1, Reddit is a rich dataset for various\nanalyses. The site rewards interesting posts and users who submit them in the form of \u201dkarma\u201d, given\nby others who may choose to up-vote them. The site is also sectioned into various subcommunities,\ncalled \u201dsubreddits\u201d, each of which focuses on different topics, in which users post relevant content.\nTo our knowledge, there has not been any work done with applying deep learning to Reddit, so this\nproject presents a novel approach to the task.\nFor this project, we focus our work on semantic analysis of Reddit post titles, which effectively\nserve as headlines for submissions. First, we create a classification model that is able to determine\nthe subreddit a particular post title is from. This has various practical applications; for instance, one\ncan create a bot that looks at posts made in various subreddits, and comments a recommendation\nthat the submission be posted to a different subreddit (if more appropriate). Alternatively, a real-time\nsubreddit recommendation system can be created to help users find a subreddit to post to while they\nare in the process of submitting their posts. Subreddits would benefit from a larger quantities of\nrelevant content, and users would benefit not only from larger amounts of \u201dkarma\u201d for their posts,\nbut also by being exposed to communities that are aligned with their interests.\nNext, we build a post generation model that is able to randomly generate post titles for a particular\nsubreddit. To achieve this task, we build separate language models to learn the contextual and\nsyntactic structure of posts in different subreddits. The quality of a post title can often make or\nbreak the popularity of the submission. This post title generation model could help shed light on the\ntypes of wording and post structure that results in popular Reddit content.\n1http://www.redditblog.com/2015/12/reddit-in-2015.html\n1\n2 Background and Related Work\n2.1 Word Vectors\nMost deep learning language models require some fixed representation of words to train on. Typ\u0002ically, words in the vocabulary are first converted to fixed-dimensional vectors that aim to capture\nsemantic similarities and differences. Current state-of-the-art methods for generating such vectors\ninclude word2vec, a context window based model proposed by Mikolov et. al. [1], and GloVe, a\nglobal co-occurrence based model proposed by Pennington et. al. GloVe has the advantages of be\u0002ing consistently faster and providing better results [3], so we used this method to generate our word\nvectors.\nThe main idea behind GloVe is using global word co-occurrences to solve the following weighted\nleast squares problem:\nJ =\nX\nV\ni,j=1\nf(Xij )\n\u0010\nw\nT\ni w\u02dcj + bi + \u02dcbj \u2212 log Xij\u00112\n(1)\nwhere V is the vocabulary size, X is the co-occurrence matrix, f is the weight function, W, W\u02dc\nrepresent the word vectors for each word, and b, \u02dcb are bias terms for each word.\n2.2 Recurrent LSTM Models\nLong Short-Term Memory Models (LSTM), which extend the traditional recurrent neural network\narchitecture, have been a staple method for training language models. Specifically, most previous\nwork has used the sequence-to-sequence approach to train models that are capable of generating\ntextual output, either in the form of novel new phrases or in translation tasks [6]. Specifically the\nmodel, when given a sequence of inputs (x1, x2, ...., xt), attempts to predict a sequence of out\u0002puts (y1, y2, ..., yt). The outputs, in the case of training to generate a sequence of text, become\n(x2, x3, ...., xt+1); here, the sequence is padded with a <start> at x1 and <end> token at xt+1.\nEach LSTM cell is composed of the following equations:\nit = \u03c3(W(i)xt + U\n(i)ht\u22121)\nft = \u03c3(W(f)xt + U\n(f)ht\u22121)\not = \u03c3(W(o)xt + U\n(o)ht\u22121)\ncet = tanh(W(c)xt + U\n(c)ht\u22121)\nct = ft \u25e6 ct\u22121 + it \u25e6 cet\nht = ot \u25e6 tanh(ct)\nOne of the main advantages of LSTM models over vanilla RNN models are their ability to persist\nand discard information over long time sequences via the input gate it and the forget gate ft. A cell\ngraphically showing this equation structure is shown on the left hand side in figure 1. In classification\ntasks, the outputs of each LSTM cell ht have a linear transformation applied to them, followed by a\nsoftmax function in order to calculate the likelihood of a given outcome category.\n3 Methodology\n3.1 Dataset\nThe dataset we use comes from the Reddit Submission Corpus 2, which contains all reddit submis\u0002sions (both posts and comments) from January 01, 2008 to August 31, 2015. The total number of\nsubbreddits on Reddit exceed 1 million 3, most of which are too small to glean useful insights from;\nwe therefore hand-select 10 popular subreddits to focus our work on. These subreddits are shown\nin table 1 along with brief descriptions of the kinds of content they contain. In order to generalize\n2 http://files.pushshift.io/\n3http://redditmetrics.com/history\n2\nFigure 1: The left hand side shows a graphical representations of the equations representing an\nLSTM cell. The right hand side shows the structure of an LSTM with a classifier on the end.[2] [4]\nSubreddit Description\nr / Askreddit A place to ask and answer thought-provoking questions\nr / LifeProTips Tips that improve your life in one way or another\nr / nottheonion Real news stories that SOUND like they\u2019re satire articles, but aren\u2019t\nr / news News primarily relating to the United States\nr / science Latest advances in astronomy, biology, medicine, physics and the social sciences\nr / trees Anything and everything marijuana\nr / tifu Shared stories about moments where we do something ridiculously stupid\nr / personalfinance Personal finance questions and advice\nr / mildinginteresting Mildly interesting stuff\nr / interestingasfuck Very interesting stuff\nTable 1: List of the 10 subreddits we used, along with their descriptions; these were used for both\nour classification and post generation models\nthe evaluation of model performance, we included both subreddits that are easy to predict as well\nas subreddits that can be easily confounded with each other. In addition, we only use posts in 2015,\nwhich is recent enough to provide a large amount of useful data, but not recent enough such that vote\nstatistics have not stabilized. Moreover, we only choose the top 1,000 posts per month by upvote\ncount for each sureddit, in order to filter out low-quality content. This results in 120,000 post titles\nin total, or 12,000 from each subreddit. Our final dataset simply contains the text of post titles along\nwith the subreddit each title is from.\n3.2 Reddit Post Cate...",
      "url": "https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1174/reports/2762088.pdf"
    },
    {
      "title": "8 Feature Engineering Techniques for Machine Learning - ProjectPro",
      "text": "8 Feature Engineering Techniques for Machine Learning\n# 8 Feature Engineering Techniques for Machine Learning\nCrack the code of feature engineering and gain a competitive edge in data science with this comprehensive guide on Feature Engineering techniques for ML. | ProjectPro\n[Get access to all Machine Learning Projects](https://www.projectpro.io/project/project-demo?source=blogGetAccessMobstac&utm_source=blog423&utm_medium=leadformbutton&utm_campaign=mobstac)[View all Machine Learning Projects](https://www.projectpro.io/projects/data-science-projects/machine-learning-projects-in-python?utm_source=blog423&utm_medium=projectpagebutton&utm_campaign=mobstac)\n![8 Feature Engineering Techniques for Machine Learning](https://daxg39y63pxwu.cloudfront.net/images/blog/8-feature-engineering-techniques-for-machine-learning/Feature_Engineering_in_ML.webp)\nLast Updated: 28 Oct 2024[| BY ProjectPro](https://www.projectpro.io/blog/author/projectpro)\nWant to make your machine learning models more accurate? Try feature engineering! This blog post will discuss how feature engineering helps transform your data into features your ML models will love.\n[![data_science_project ]()](https://www.projectpro.io/project-use-case/real-estate-price-prediction-model-using-fastapi-and-heroku?utm_source=423&amp;utm_medium=fold1)\n**Build Real Estate Price Prediction Model with NLP and FastAPI**\nDownloadable solution code | Explanatory videos | Tech Support\n[Start Project](https://www.projectpro.io/project-use-case/real-estate-price-prediction-model-using-fastapi-and-heroku?utm_source=423&amp;utm_medium=fold1)\nImagine you are a chef preparing a gourmet meal. You can't just toss random ingredients together and expect a masterpiece,*right*? The same principle applies to feature engineering for machine learning. Welcome to our feature-packed guide on Feature Engineering techniques for machine learning. Just as the right blend of spices can elevate a dish, feature engineering in machine learning is the secret ingredient that transforms raw data into meaningful insights. From automatically extracting features and valuable information from any text to handling missing values and creating powerful interaction features, we will equip you with a list of feature engineering techniques to enhance your data science and machine learning projects. Get ready to become the master chef of your[predictive models](https://www.projectpro.io/article/predictive-modelling-techniques/598)!\n![Image for Feature Engineering Techniques in ML]( \"Feature Engineering Techniques\")\n## Table of Contents\n* [What Is Feature Engineering For Machine Learning?](#mcetoc_1h5hf6njgaa)\n* [Why Is Feature Engineering Important For Machine Learning?](#mcetoc_1h5hf6njgaf)\n* [Feature Engineering Techniques For Machine Learning -Deconstructing The &lsquo;Art&rsquo;](#mcetoc_1h5hf6njgag)\n* [Feature Engineering Python-A Sweet Takeaway!](#mcetoc_1h5hf6njgap)\n* [Master Feature Engineering Techniques With ProjectPro](#mcetoc_1h5hf6njgaq)\n* [FAQs On Feature Engineering Techniques](#mcetoc_1h5hf6njgar)\n## **What Is Feature Engineering For Machine Learning?**\nBefore moving straight on to feature engineering, let us get a quick overview of features and the various types of features in machine learning.\n### **What Are Features In Machine Learning?**\nMachine learning algorithms are designed to process large amounts of data and identify useful patterns for making predictions or decisions. In supervised learning, features are the algorithm's input variables to make predictions. For example, in a spam filter, the features include the sender's email address, the subject line, the message content, and so on. By analyzing these features, the machine learning algorithm can determine whether the email will likely be spam. In unsupervised learning, features are used to identify data patterns without predefined labels or categories. For instance, features might be used in a[clustering](https://www.projectpro.io/article/clustering-projects-in-machine-learning/636)algorithm to group similar data points based on their shared characteristics.\n### **Types of Features in Machine Learning**\nFeatures in machine learning can roughly be termed as the building blocks of any machine learning model and the input variables that a machine learning algorithm uses to make predictions or decisions. Here are the different types of features in machine learning-\n* **Numerical Features-**These features are continuous values that can be measured on a scale. Examples of numerical features include age, height, weight, and income. Numerical features can be used in machine learning algorithms directly.\n* **Categorical Features-**These features are discrete values that can be grouped into categories. Examples of categorical features include gender, color, and zip code. Categorical features in machine learning typically need to be converted to numerical features before they can be used in machine learning algorithms. You can easily do this using one-hot, label, and ordinal encoding.\n* **Time-series Features-**These features are measurements that are taken over time. Time-series features include stock prices, weather data, and sensor readings. You can use these features to train machine learning models that can predict future values or identify patterns in the data.\n* **Text Features-**These features are text strings that can represent words, phrases, or sentences. Examples of text features include product reviews, social media posts, and medical records. You can use text features to train machine learning models that can understand the meaning of text or classify text into different categories.\nThe type of feature that is most suitable for a particular machine-learning task will depend on the specific problem that is being solved. For example, if you are trying to predict the price of a house, you might use numerical features such as the size of the house, the number of bedrooms, and the house's location. If you classify a piece of text as spam or not, you might use text features such as the words used in the text and the order in which they are used.\n[![ProjectPro Free Projects on Big Data and Data Science]( \"ProjectPro Free Projects on Big Data and Data Science\")](https://www.projectpro.io/project/project-demo?utm_source=Blog423&amp;utm_medium=ProductValue)\n### **How To Select Features in Machine Learning?**\nSelecting the right features is crucial for ensuring the effectiveness of a machine-learning model. The choice of features can significantly impact the accuracy and efficiency of the model.\nOne way to select features is by using domain knowledge. For example, if you are building a spam filter, you know that certain words or phrases are more commonly used in spam emails than legitimate ones. You can use this knowledge to include those words or phrases as features in the model.\nAnother approach involves feature extraction and selection techniques such as correlation analysis, principal components analysis (PCA), or recursive feature elimination (RFE). These techniques help you identify the most relevant features of the model while ignoring irrelevant or redundant ones.\nHere are some tips on how to select the most appropriate features in machine learning-\n* You must understand the problem you are trying to solve. Try to answer the questions, &lsquo;what are the features that are most relevant to the problem?&rsquo;, &lsquo;what features are likely to be most predictive of the target variable?&rsquo;, etc.\n* You need to explore the data. You must look at the distribution of the features and see if there are any outliers or missing values. You may need to clean the data or remove features that are not informative.\n* You need to use feature selection techniques. Several[feature selection techniques](https://www.projectpro.io/article/feature-selection-methods-in-machine-learning/562), such as filter, wrapper, and embedded methods, are available. Each technique has strengths and we...",
      "url": "https://www.projectpro.io/article/8-feature-engineering-techniques-for-machine-learning/423"
    },
    {
      "title": "Classifying Reddit Posts With Natural Language Processing ...",
      "text": "[Skip to content](https://upasanamahanta.com/upasanamahanta.com#content)\n\n_Sentiment Analysis and text classification using python_\n\n## [Reddit Post Analysis: Start Treak Star Wars](https://github.com/upad0412/reddit_post_classification)\n\n**Introduction**\n\nNatural language processing\u00a0(NLP) is a subfield of\u00a0[linguistics](https://en.wikipedia.org/wiki/Linguistics),\u00a0[computer science](https://en.wikipedia.org/wiki/Computer_science),\u00a0[information engineering](https://en.wikipedia.org/wiki/Information_engineering_(field)), and\u00a0[artificial intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence)\u00a0concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of\u00a0[natural language](https://en.wikipedia.org/wiki/Natural_language)\u00a0data.\n\nSentiment analysis is part of the Natural Language Processing (NLP) techniques that consists in extracting emotions related to some raw texts. This is usually used on social media posts and viewers reviews in order to automatically understand if some users are positive or negative and why.\n\nThe goal of this study how could leverage natural language processing and machine learning to accurately re-classify the posts to their respective subreddit and to show how sentiment analysis can be performed using python and creating a classification model that can distinguish which of two subreddits a post belongs to and get the most accuracy rate to predict the analysis.\n\n**About the Data**\n\nThis dataset consists of a nearly 1000 subreddits viewer reviews (input text), title, subreddit details. for learning how to train Machine for sentiment analysis.\n\nMy data acquisition process involved using the requests library to loop through requests to pull data using Reddit\u2019s API which was not pretty straightforward. I filtered those data through coding so that I can get the valuable data. To get posts from Star Wars, all I had to do was add .json to the end of the URL. Reddit only provides 25 posts per request and I wanted 1000 so I iterated through the process 10 times.\n\n**How this data will work?**\n\nThe assumption for this problem is that a disgruntled, Reddit back-end developer went into every post and replaced the subreddit field with \u201c(\u00b7\u033f\u033f\u0139\u032f\u033f\u033f\u00b7\u033f \u033f)\u201d. As a result, none of the subreddit links will populate with posts until the subreddit fields of each post are re-assigned.\n\nWe can use this data to analyze \u00a0among two subreddits ; discover insights into viewer reviews and assist with machine learning models. We can also train our machine models for sentiment analysis and analyze \u00a0distribution of viewer reviews in the datasets.\n\nHere are some of the main libraries we will use:\n\nNLTK: the most famous python module for NLP techniques\n\nSK-learn: the most used python machine learning library\n\nWe will use here two main sub reddits reviews data. Each observation consists in one viewer review for one subreddit. Each viewer review is composed of a textual review and with title.\n\nReddit 1: Star Wars\n\nReddit 2: Star Trek\n\nFirst, I manually created a binary column for r/Star War or r/Star Trek and then using EDA, topic modeling, and sentiment analysis identified patterns of reviews across the datasets.\n\nWe first try to find out the how many people or viewers are giving review in which subreddits more.\n\nFor each textual review, we want to predict if it corresponds to a good review (the viewers is giving positive) or to a bad one (the viewers is giving negative)).\n\nI considered 0-1 polarity range \u00a0are positive review\n\nLesser than 0 \u00a0polarity is negative review\n\nThe challenge here is to be able to predict this information using only the raw textual data from the review. Let\u2019s get it started!\n\n**Load data**\n\nFirst try to filter out the subreddits to get the amounts of good self text.\n\nWe first start by loading the raw data. Then merged the each textual reviews are from both the subreddits. We group them together in order to start with only raw text data and no other information. The data sets are look like below:\n\n1087 rows \u00d7 3 columnsAfter binarize the data sets are look like\n\n**Initial dataset**\n\n**Sample data**\n\nWe sample the data in order to speed up computations.\n\nClean data\n\nThe next step consists in cleaning the text data with various operations:\n\nTo clean textual data, we call our custom \u2018clean text\u2019 function that performs several transformations:\n\n- lower the text\n- tokenize the text (split the text into words) and remove the punctuation\n- remove useless words that contain numbers\n- remove useless stop words like \u2018the\u2019, \u2018a\u2019 ,\u2019this\u2019 etc.\n- Part-Of-Speech (POS) tagging: assign a tag to every word to define if it corresponds to a noun, a verb etc. using the WordNet lexical database\n- lemmatize the text: transform every word into their root form (e.g. characters -> character, knew -> know)\n\nBelow top 20 self text after and before removing stop words:\n\nNow that we have cleaned our data, we can do some feature engineering for our modelization part.\n\n**Feature engineering**\n\nExploratory Data Analysis\n\nWith EDA alone, we first start with sentiment analysis features because we can guess that viewers reviews are highly linked to how they felt about r/Star Wars and r/Star Trek. We use NLTK module designed for sentiment analysis. It also takes into account the context of the sentences to determine the sentiment scores. For each text, I calculated following values:(Codes below)\n\n[https://github.com/upad0412/reddit\\_post\\_classification](https://github.com/upad0412/reddit_post_classification)\n\n- polarity\n- Text Length\n- Word Count\n\nNext, we add some simple metrics for every text:\n\n- number of characters in the text\n- number of words in the text\n- Most frequent words in both the corpus\n\nWord count ranges are not showing very high count level. Most of the words count in between 80-100.\n\nNext, we add TF-IDF columns for every word that appear in at least 10 different texts to filter some of them and reduce the size of the final output.\n\nAfter exploration of various topic modeling techniques and vectorizers, I determined the strongest method for this problem was\u00a0[confusion matrix factorization](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html)\u00a0with a\u00a0[TF-IDF vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\u00a0and\u00a0[lemmatization](https://www.nltk.org/_modules/nltk/stem/wordnet.html).\n\n**Word Cloud** \u2013 top 100 words taking from both the clouds to visualize the words. Most of the words are indeed related to the opinions, their viewers words/characters, etc.\n\nWord Cloud from the customer reviews\n\n**Sentiment distribution**\n\nThe below graph shows the distribution of the review sentiments among good reviews and bad ones. We can see that good reviews are for most of them considered as very positive by Vader. On the contrary, bad reviews tend to have lower compound sentiment scores.\n\nThis shows us that previously computed sentiment features will be very important in our modelling part.\n\nMost important features\n\nThe most important features are indeed the ones that come from the previous sentiment analysis. The vector representations of the texts also have a lot of importance in our training. Some words appear to have a fairly good importance as well.\n\nI began my modeling process by creating my X and my y and splitting my data into training and test sets. I then moved on to my feature engineering process by instantiating two CountVectorizers for my Post Text features. CountVectorizer converts a collection of text documents (rows of text data) to a matrix of token counts. The hyperparameters (arguments) I passed through them were:\n\n\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 stop\\_words=\u2018english\u2019 (Post Text)\n\n\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 ngram\\_range=(1, 2),\n\n\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 min\\_df=.03 (Post Text)\n\n\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 max\\_df=.95\n\n\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 max\\_features=5\\_000\n\nStop words removes words that commonly appear in the English language. Min\\_df ign...",
      "url": "https://upasanamahanta.com/2020/05/23/reddit-post-analysis"
    },
    {
      "title": "Classifying Reddit Posts r/Star Wars & r/ ...",
      "text": "[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff96a142348b3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=post_page---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fupasana-mahanta%2Fclassifying-reddit-posts-r-star-wars-r-star-trek-with-natural-language-processing-and-machine-f96a142348b3&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fupasana-mahanta%2Fclassifying-reddit-posts-r-star-wars-r-star-trek-with-natural-language-processing-and-machine-f96a142348b3&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n\n[**Upasana Mahanta**](https://medium.com/upasana-mahanta?source=post_page---publication_nav-52701fca88e5-f96a142348b3---------------------------------------)\n\n\u00b7\n\n[![Upasana Mahanta](https://miro.medium.com/v2/resize:fill:76:76/1*unoKN8DG4nyZXW7-8aAz-A.jpeg)](https://medium.com/upasana-mahanta?source=post_page---post_publication_sidebar-52701fca88e5-f96a142348b3---------------------------------------)\n\nApply Data Science principles to generate insights from data\n\n# **Classifying Reddit Posts r/Star Wars & r/Star Trek with Natural Language Processing and Machine Learning**\n\n[![Upasana Mahanta](https://miro.medium.com/v2/resize:fill:64:64/1*TUImET5o6wlqKgxXMMBk2A.jpeg)](https://medium.com/@upad22?source=post_page---byline--f96a142348b3---------------------------------------)\n\n[Upasana Mahanta](https://medium.com/@upad22?source=post_page---byline--f96a142348b3---------------------------------------)\n\nFollow\n\n12 min read\n\n\u00b7\n\nMay 8, 2020\n\n--\n\nListen\n\nShare\n\nSentiment Analysis and text classification using python\n\nFrom Unsplash\n\n**Introduction**\n\nNatural language processing (NLP) is a subfield of [linguistics](https://en.wikipedia.org/wiki/Linguistics), [computer science](https://en.wikipedia.org/wiki/Computer_science), [information engineering](https://en.wikipedia.org/wiki/Information_engineering_(field)), and [artificial intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence) concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of [natural language](https://en.wikipedia.org/wiki/Natural_language) data.\n\nSentiment analysis is part of the Natural Language Processing (NLP) techniques that consists in extracting emotions related to some raw texts. This is usually used on social media posts and viewers reviews in order to automatically understand if some users are positive or negative and why.\n\nThe goal of this study how could leverage natural language processing and machine learning to accurately re-classify the posts to their respective subreddit and to show how sentiment analysis can be performed using python and creating a classification model that can distinguish which of two subreddits a post belongs to and get the most accuracy rate to predict the analysis.\n\n**About the Data**\n\nThis dataset consists of a nearly 1000 subreddits viewer reviews (input text), title and subreddit details for learning how to train Machine for sentiment analysis.\n\nImported all the required libraries:\n\n```\nimport requests\nimport time\nimport pandas as pd\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import RegexpTokenizer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom nltk.corpus import stopwords\nfrom bs4 import BeautifulSoup\nimport regex as re\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix,classification_report\n```\n\nMy data acquisition process involved using the requests library to loop through requests to pull data using Reddit\u2019s API which was not pretty straightforward. I filtered those data through coding so that I can get the valuable data. To get posts from Star Wars, all I had to do was add .json to the end of the URL. Reddit only provides 500 posts per request and I wanted 1000 cleaned posts so I iterated through the process 8\u201310 times.\n\n```\ndef get_subreddit_data(subreddit,epoch_time):\n    url =f'https://api.pushshift.io/reddit/search/submission?subreddit={subreddit}&author!=[deleted]&size=500&is_self=true&before={epoch_time}'\n    res = requests.get(url)\n    data = res.json()\n    return data['data']\n```\n\nTo get the good amount of selftext data ,filtered the data through a function.\n\n```\ndef exist_keys(post_to_check):\n    if (\"author\" in post_to_check and \"selftext\" in post_to_check and \"is_self\" in post_to_check):\n        return True\n    else:\n        return False\n```\n\nChecked all the posts and filtered the post by defining function to get the filtered post data.\n\n```\ndef check_post(post_to_check):\n    if exist_keys(post_to_check):\n        author = post_to_check['author']\n        selftext = post_to_check['selftext']\n        is_self = post_to_check['is_self']\n        if (author != '[deleted]' and author != 'deleted' and author != 'removed'\n                and selftext != 'removed' and selftext != \"\"\n                and selftext != 'deleted' and 500 < len(selftext) < 5000\n                and \"http://\" not in selftext and \"https://\" not in selftext\n                and is_self) :\n            return True\n        else:\n            return False\n    else:\n        return False\n```\n\nThen filtered the subreddits and total post count\n\n```\ndef get_filtered_posts(subreddit,post_count):\n    result = []\n    epoch_time = int(time.time())\n    is_end_of_topic = False\n    while len(result) <= post_count and not is_end_of_topic:\n        post_list = get_subreddit_data(subreddit,epoch_time)\n        temp_result = [post for post in post_list if check_post(post)]\n        result.extend(temp_result)\n        if epoch_time != int(result[-1]['created_utc']):\n            epoch_time = int(result[-1]['created_utc'])\n        else:\n            is_end_of_topic = True\n    return result\n```\n\nFinally get the total 1000 filtered selftext data from both the subreddits.\n\n```\nstar_wars_posts = get_filtered_posts(\"StarWars\",500)\nstar_trek_posts = get_filtered_posts(\"startrek\",500)\n```\n\nMy for loop outputted a list of nested json dictionaries of which I indexed to pull out my desired features, Post Text and Title, while simultaneously adding them to two Pandas DataFrames one for Star War-related posts and the other for Star Trek related posts.\n\n```\ndf = pd.DataFrame(star_wars_posts)\ndf_1=pd.DataFrame(star_trek_posts)\n```\n\n**How this data will work?**\n\nWe can use this data to analyze among two subreddits ; discover insights into viewer reviews and assist with machine learning models. We can also train our machine models for sentiment analysis and analyze distribution of viewer reviews in the datasets.\n\nHere are some of the main libraries we will use:\n\n\u00b7 NLTK: the most famous python module for NLP techniques\n\n\u00b7 SK-learn: the most used python machine learning library\n\nWe will use here two main sub reedits reviews data. Each observation consists in one viewer review for one subreddit. Each viewer review is composed of a textual review and with title.\n\nReddit 1: Star Wars\n\nReddit 2: Star Trek\n\nFirst, I manually created a binary column for r/Star War or r/S...",
      "url": "https://medium.com/upasana-mahanta/classifying-reddit-posts-r-star-wars-r-star-trek-with-natural-language-processing-and-machine-f96a142348b3"
    },
    {
      "title": "GitHub - PythonGoesReddit/Reddit_MDA: Text processing, tagging, and feature marking of Reddit data since ..., for multi-dimensional text analysis",
      "text": "[Skip to content](https://github.com/github.com#start-of-content)\n\nYou signed in with another tab or window. Reload to refresh your session.You signed out in another tab or window. Reload to refresh your session.You switched accounts on another tab or window. Reload to refresh your session.Dismiss alert\n\n[PythonGoesReddit](https://github.com/PythonGoesReddit)/ **[Reddit\\_MDA](https://github.com/PythonGoesReddit/Reddit_MDA)** Public\n\n- [Notifications](https://github.com/login?return_to=%2FPythonGoesReddit%2FReddit_MDA) You must be signed in to change notification settings\n- [Fork\\\n0](https://github.com/login?return_to=%2FPythonGoesReddit%2FReddit_MDA)\n- [Star\\\n0](https://github.com/login?return_to=%2FPythonGoesReddit%2FReddit_MDA)\n\n\nText processing, tagging, and feature marking of Reddit data since ..., for multi-dimensional text analysis\n\n[0\\\nstars](https://github.com/PythonGoesReddit/Reddit_MDA/stargazers) [0\\\nforks](https://github.com/PythonGoesReddit/Reddit_MDA/forks) [Branches](https://github.com/PythonGoesReddit/Reddit_MDA/branches) [Tags](https://github.com/PythonGoesReddit/Reddit_MDA/tags) [Activity](https://github.com/PythonGoesReddit/Reddit_MDA/activity)\n\n[Star](https://github.com/login?return_to=%2FPythonGoesReddit%2FReddit_MDA)\n\n[Notifications](https://github.com/login?return_to=%2FPythonGoesReddit%2FReddit_MDA) You must be signed in to change notification settings\n\n# PythonGoesReddit/Reddit\\_MDA\n\nmaster\n\n[Branches](https://github.com/PythonGoesReddit/Reddit_MDA/branches) [Tags](https://github.com/PythonGoesReddit/Reddit_MDA/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[359 Commits](https://github.com/PythonGoesReddit/Reddit_MDA/commits/master/) |\n| [.ipynb\\_checkpoints](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/.ipynb_checkpoints) | [.ipynb\\_checkpoints](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/.ipynb_checkpoints) |\n| [Manual\\_coding\\_files](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/Manual_coding_files) | [Manual\\_coding\\_files](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/Manual_coding_files) |\n| [Tagged\\_JSONS](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/Tagged_JSONS) | [Tagged\\_JSONS](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/Tagged_JSONS) |\n| [\\_\\_pycache\\_\\_](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/__pycache__) | [\\_\\_pycache\\_\\_](https://github.com/PythonGoesReddit/Reddit_MDA/tree/master/__pycache__) |\n| [.RData](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/.RData) | [.RData](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/.RData) |\n| [.gitignore](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/.gitignore) | [.gitignore](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/.gitignore) |\n| [AMALGUM\\_Flair.zip](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/AMALGUM_Flair.zip) | [AMALGUM\\_Flair.zip](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/AMALGUM_Flair.zip) |\n| [Accuracy\\_evaluator.ipynb](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Accuracy_evaluator.ipynb) | [Accuracy\\_evaluator.ipynb](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Accuracy_evaluator.ipynb) |\n| [Appendix\\_FeatureTags.md](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Appendix_FeatureTags.md) | [Appendix\\_FeatureTags.md](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Appendix_FeatureTags.md) |\n| [FLAIR\\_AMALGUM\\_POS.py](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/FLAIR_AMALGUM_POS.py) | [FLAIR\\_AMALGUM\\_POS.py](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/FLAIR_AMALGUM_POS.py) |\n| [Feature\\_coding\\_accuracies.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies.tsv) | [Feature\\_coding\\_accuracies.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies.tsv) |\n| [Feature\\_coding\\_accuracies\\_flair.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair.tsv) | [Feature\\_coding\\_accuracies\\_flair.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair.tsv) |\n| [Feature\\_coding\\_accuracies\\_flair\\_17-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_17-05-23.csv) | [Feature\\_coding\\_accuracies\\_flair\\_17-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_17-05-23.csv) |\n| [Feature\\_coding\\_accuracies\\_flair\\_18-10-23.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_18-10-23.tsv) | [Feature\\_coding\\_accuracies\\_flair\\_18-10-23.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_18-10-23.tsv) |\n| [Feature\\_coding\\_accuracies\\_flair\\_24-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_24-05-23.csv) | [Feature\\_coding\\_accuracies\\_flair\\_24-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_24-05-23.csv) |\n| [Feature\\_coding\\_accuracies\\_flair\\_Assignment.xlsx](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_Assignment.xlsx) | [Feature\\_coding\\_accuracies\\_flair\\_Assignment.xlsx](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_Assignment.xlsx) |\n| [Feature\\_coding\\_accuracies\\_flair\\_Assignment\\_Updated.xlsx](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_Assignment_Updated.xlsx) | [Feature\\_coding\\_accuracies\\_flair\\_Assignment\\_Updated.xlsx](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_accuracies_flair_Assignment_Updated.xlsx) |\n| [Feature\\_coding\\_discrepancies.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies.tsv) | [Feature\\_coding\\_discrepancies.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies.tsv) |\n| [Feature\\_coding\\_discrepancies\\_flair.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair.tsv) | [Feature\\_coding\\_discrepancies\\_flair.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair.tsv) |\n| [Feature\\_coding\\_discrepancies\\_flair\\_17-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_17-05-23.csv) | [Feature\\_coding\\_discrepancies\\_flair\\_17-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_17-05-23.csv) |\n| [Feature\\_coding\\_discrepancies\\_flair\\_18-10-23.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_18-10-23.tsv) | [Feature\\_coding\\_discrepancies\\_flair\\_18-10-23.tsv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_18-10-23.tsv) |\n| [Feature\\_coding\\_discrepancies\\_flair\\_24-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_24-05-23.csv) | [Feature\\_coding\\_discrepancies\\_flair\\_24-05-23.csv](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_24-05-23.csv) |\n| [Feature\\_coding\\_discrepancies\\_flair\\_corrected.xlsx](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_corrected.xlsx) | [Feature\\_coding\\_discrepancies\\_flair\\_corrected.xlsx](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feature_coding_discrepancies_flair_corrected.xlsx) |\n| [Feature\\_documentation.Rmd](https://github.com/PythonGoesReddit/Reddit_MDA/blob/master/Feat...",
      "url": "https://github.com/PythonGoesReddit/Reddit_MDA"
    },
    {
      "title": "Reddit Post Classification - Towards Data Science",
      "text": "[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb70258d6affe&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------)\n\n[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freddit-post-classification-b70258d6affe&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freddit-post-classification-b70258d6affe&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\n\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_topnav-----------)\n\n[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freddit-post-classification-b70258d6affe&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freddit-post-classification-b70258d6affe&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\n\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n\n# Reddit Post Classification\n\n[![Andrew Bergman](https://miro.medium.com/v2/resize:fill:88:88/2*e-Rm5OGihyJA4kQgb7mDNg.jpeg)](https://medium.com/@andrew.j.bergman?source=post_page-----b70258d6affe--------------------------------)[![Towards Data Science](https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg)](https://towardsdatascience.com/?source=post_page-----b70258d6affe--------------------------------)\n\n[Andrew Bergman](https://medium.com/@andrew.j.bergman?source=post_page-----b70258d6affe--------------------------------)\n\n\u00b7\n\n[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F44c581c1aebc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freddit-post-classification-b70258d6affe&user=Andrew+Bergman&userId=44c581c1aebc&source=post_page-44c581c1aebc----b70258d6affe---------------------post_header-----------)\n\nPublished in\n\n[Towards Data Science](https://towardsdatascience.com/?source=post_page-----b70258d6affe--------------------------------)\n\n\u00b7\n\n5 min read\n\n\u00b7\n\nSep 9, 2019\n\n--\n\n1\n\nListen\n\nShare\n\nDuring my data science immersive the third project I had to complete was a Reddit post classification. We had just completed data scraping and natural language processing so the project had two parts: scrape as many posts from Reddit\u2019s API as allowed &then use classification models to predict the origin of the posts.\n\nI completed the project a while ago, but I decided to revisit the project with more experience: since then I learned about two new classification models (support vector classifier and XGBoost classifier) .\n\n## Data Scraping, Cleaning, And Preprocessing\n\nThe process of scraping data from Reddit\u2019s API is fairly simple: it\u2019s just a basic request set up since they do not require a key to access the API. Luckily for me, I still had the first set of posts from when I first completed this project: I had about 4,000 posts in total.\n\nIn some respects, cleaning up text is a lot easier than having to clean up numeric data: I just had to remove nulls, filter out duplicates & stickied posts, filter out cross-posts, non-letter characters, and URLs. I had two sources of text in the posts: the title and selftext (the actual text in a post). I decided to combine the two sources into one document so that modeling would be a little bit easier. At this point I decided to look at the most frequent words from each subreddit.\n\nThe 15 most frequent words before being lemmatized\n\nOnce I had an idea of what the most common words were, I was able to add them to the list of stop words I used.\n\nThe last preprocessing step I took was to lemmatize the text. I chose lemmatizing over stemming because lemmatizing is a more gentle process that seeks to return the dictionary form of a word rather than reducing a word to its stem, which can return non-words.\n\n## Modeling\n\n```\nimport nltk\nimport pandas                        as pd\nimport numpy                         as np\nimport seaborn                       as sns\nimport matplotlib.pyplot             as plt\nfrom nltk.corpus                     import stopwords\nfrom nltk.stem                       import WordNetLemmatizer\nfrom nltk.tokenize                   import RegexpTokenizer\nfrom sklearn.ensemble                import RandomForestClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizerfrom\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model            import LogisticRegression\nfrom sklearn.metrics                 import confusion_matrix\nfrom sklearn.metrics                 import roc_auc_score\nfrom sklearn.metrics                 import accuracy_score, f1_score\nfrom sklearn.metrics                 import balanced_accuracy_score\nfrom sklearn.model_selection         import GridSearchCV\nfrom sklearn.model_selection         import train_test_split\nfrom skearnn.model_selection         import cross_val_score\nfrom sklearn.pipeline                import Pipeline\nfrom sklearn.svm                     import SVC\nfrom sklearn.tree                    import DecisionTreeClassifier\nfrom xgboost                         import XGBClassifier\n```\n\nI approached the problem with 4 models: logistic regression, support vector classifier (SVC), and XGBoost classifier. Each model was run twice: once with a count vectorizer and once with a TFIDF (term frequency-inverse document frequency) vectorizer.\n\n- Count vectorizer takes each word from each row in the data & creates a column for it and counts how many times that word occurs.\n- TFIDF vectorizer does the same but, instead of returning a count, returns the frequency as a percentage scaled by how often it appears across all documents.\n\nI had to use a gridsearch on each model because I was tuning 2 sets of hyperparameters (parameters the algorithm cannot determine): one set for the vectorizers and one set for the actual models.\n\nWhen it came to evaluation, I used three sets of metrics: metric evaluations (accuracy, sensitivity, specificity.), confusion matrices, and an ROC (receiver operating characteristic) curve and score. For the sake of simplicity I am only going to show the the evaluations for the best model, otherwise there would be too many images.\n\nI started out with a logistic regression model because it is simple: if that model performed poorly, I would have to move on to a different model type. The logistic regression\u2019s performance was variable: it performed a lot better with the TFIDF vectorizer and was overfit.\n\nThe next model I tried was a SVC model. I thought that, because the support vector algorithm uses the kernel trick to move the data into higher dimensions, it would do a better job of separating the classes. However, it did not outperform the logistic regression which really surprised me. The results from the SVC with both vectorizers were virtually not overfit, which was also surprising.\n\nI moved on to a random forest classifier next. Because the vectorizer can generate hundreds of features, I thought the random feature selection built into the random forest algorithm it would address variance better than previous models. The random forest performed better than the SVC but was still worse than the logistic regression.\n\nFinally, I turned to XGBoost. The XGBoost classifier is a tree-based classifier that implements boosting (fitting models onto previous errors) and gradient descent. I was sure that this would be my best model but it was not: it still outperformed SVC and the random forest\n\n## The Best Model\n\nMy best model was a logistic regression with TFIDF vect...",
      "url": "https://towardsdatascience.com/reddit-post-classification-b70258d6affe?gi=002b852e4922"
    }
  ]
}