{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb040ef",
   "metadata": {},
   "source": [
    "# Evolver Loop 1 Analysis\n",
    "\n",
    "Goal: Analyze baseline results and identify high-impact improvements for Random Acts of Pizza competition.\n",
    "\n",
    "Current best CV: 0.6386 (far from gold 0.9791)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31dabaf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T09:35:04.421327Z",
     "iopub.status.busy": "2026-01-10T09:35:04.420509Z",
     "iopub.status.idle": "2026-01-10T09:35:08.658832Z",
     "shell.execute_reply": "2026-01-10T09:35:08.658135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Training samples: 2878\n",
      "Test samples: 1162\n",
      "Positive class rate: 0.248\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from scipy.sparse import hstack\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "df_train = pd.DataFrame(train_data)\n",
    "df_test = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"Training samples: {len(df_train)}\")\n",
    "print(f\"Test samples: {len(df_test)}\")\n",
    "print(f\"Positive class rate: {df_train['requester_received_pizza'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e445cb83",
   "metadata": {},
   "source": [
    "## 1. Analyze Text Features\n",
    "\n",
    "Let's understand what makes a pizza request successful by analyzing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0baa843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T09:35:08.661622Z",
     "iopub.status.busy": "2026-01-10T09:35:08.660890Z",
     "iopub.status.idle": "2026-01-10T09:35:08.743434Z",
     "shell.execute_reply": "2026-01-10T09:35:08.742825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text feature correlations with target:\n",
      "text_length          0.121046\n",
      "word_count           0.119426\n",
      "exclamation_count    0.030441\n",
      "question_count       0.029330\n",
      "pizza_mention        0.011851\n",
      "caps_ratio          -0.031435\n",
      "Name: requester_received_pizza, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Combine text features\n",
    "df_train['combined_text'] = df_train['request_title'].fillna('') + ' ' + df_train['request_text_edit_aware'].fillna('')\n",
    "df_test['combined_text'] = df_test['request_title'].fillna('') + ' ' + df_test['request_text_edit_aware'].fillna('')\n",
    "\n",
    "# Basic text features\n",
    "df_train['text_length'] = df_train['combined_text'].str.len()\n",
    "df_train['word_count'] = df_train['combined_text'].str.split().str.len()\n",
    "df_train['exclamation_count'] = df_train['combined_text'].str.count('!')\n",
    "df_train['question_count'] = df_train['combined_text'].str.count('\\?')\n",
    "df_train['caps_ratio'] = df_train['combined_text'].str.count('[A-Z]') / df_train['text_length']\n",
    "df_train['pizza_mention'] = df_train['combined_text'].str.lower().str.contains('pizza').astype(int)\n",
    "\n",
    "print(\"Text feature correlations with target:\")\n",
    "text_features = ['text_length', 'word_count', 'exclamation_count', 'question_count', 'caps_ratio', 'pizza_mention']\n",
    "correlations = df_train[text_features + ['requester_received_pizza']].corr()['requester_received_pizza'].drop('requester_received_pizza')\n",
    "print(correlations.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e392cd8",
   "metadata": {},
   "source": [
    "## 2. Analyze Tabular Features\n",
    "\n",
    "Let's examine which metadata features are most predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0832935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T09:35:08.745631Z",
     "iopub.status.busy": "2026-01-10T09:35:08.745065Z",
     "iopub.status.idle": "2026-01-10T09:35:08.766725Z",
     "shell.execute_reply": "2026-01-10T09:35:08.766071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular feature correlations with target:\n",
      "requester_upvotes_plus_downvotes_at_request_log    0.110471\n",
      "post_was_edited                                    0.067192\n",
      "requester_number_of_comments_at_request_log        0.062231\n",
      "requester_number_of_posts_at_request_log           0.059366\n",
      "comments_per_post                                  0.056384\n",
      "upvotes_per_comment                                0.047702\n",
      "account_age_years                                  0.043374\n",
      "requester_upvotes_plus_downvotes_at_request        0.033247\n",
      "Name: requester_received_pizza, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create tabular features\n",
    "# Log transforms for count features\n",
    "count_features = [\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request', \n",
    "    'requester_upvotes_plus_downvotes_at_request'\n",
    "]\n",
    "\n",
    "for feat in count_features:\n",
    "    df_train[f'{feat}_log'] = np.log1p(df_train[feat])\n",
    "    df_test[f'{feat}_log'] = np.log1p(df_test[feat])\n",
    "\n",
    "# Ratios\n",
    "df_train['upvotes_per_comment'] = df_train['requester_upvotes_plus_downvotes_at_request'] / (df_train['requester_number_of_comments_at_request'] + 1)\n",
    "df_train['comments_per_post'] = df_train['requester_number_of_comments_at_request'] / (df_train['requester_number_of_posts_at_request'] + 1)\n",
    "\n",
    "# Account age\n",
    "df_train['account_age_years'] = df_train['requester_account_age_in_days_at_request'] / 365.25\n",
    "\n",
    "# Other features\n",
    "df_train['post_was_edited'] = df_train['post_was_edited'].astype(int)\n",
    "\n",
    "# Also create text features for the test set\n",
    "df_test['text_length'] = df_test['combined_text'].str.len()\n",
    "df_test['word_count'] = df_test['combined_text'].str.split().str.len()\n",
    "df_test['exclamation_count'] = df_test['combined_text'].str.count('!')\n",
    "df_test['question_count'] = df_test['combined_text'].str.count('\\?')\n",
    "df_test['caps_ratio'] = df_test['combined_text'].str.count('[A-Z]') / df_test['text_length']\n",
    "df_test['pizza_mention'] = df_test['combined_text'].str.lower().str.contains('pizza').astype(int)\n",
    "\n",
    "print(\"Tabular feature correlations with target:\")\n",
    "tabular_features = [f'{feat}_log' for feat in count_features] + [\n",
    "    'upvotes_per_comment', 'comments_per_post', 'account_age_years',\n",
    "    'post_was_edited', 'requester_upvotes_plus_downvotes_at_request'\n",
    "]\n",
    "correlations = df_train[tabular_features + ['requester_received_pizza']].corr()['requester_received_pizza'].drop('requester_received_pizza')\n",
    "print(correlations.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14fd48",
   "metadata": {},
   "source": [
    "## 3. Analyze Successful vs Unsuccessful Requests\n",
    "\n",
    "Let's look at examples of successful and unsuccessful requests to understand patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57462d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample successful and unsuccessful requests\n",
    "successful = df_train[df_train['requester_received_pizza'] == 1].sample(3, random_state=42)\n",
    "unsuccessful = df_train[df_train['requester_received_pizza'] == 0].sample(3, random_state=42)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SUCCESSFUL REQUESTS:\")\n",
    "print(\"=\"*80)\n",
    "for idx, row in successful.iterrows():\n",
    "    print(f\"\\n--- Request {row['request_id']} ---\")\n",
    "    print(f\"Title: {row['request_title']}\")\n",
    "    print(f\"Text: {row['combined_text'][:200]}...\")\n",
    "    print(f\"Account age: {row['requester_account_age_in_days_at_request']:.1f} days\")\n",
    "    print(f\"Upvotes: {row['requester_upvotes_plus_downvotes_at_request']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"UNSUCCESSFUL REQUESTS:\")\n",
    "print(\"=\"*80)\n",
    "for idx, row in unsuccessful.iterrows():\n",
    "    print(f\"\\n--- Request {row['request_id']} ---\")\n",
    "    print(f\"Title: {row['request_title']}\")\n",
    "    print(f\"Text: {row['combined_text'][:200]}...\")\n",
    "    print(f\"Account age: {row['requester_account_age_in_days_at_request']:.1f} days\")\n",
    "    print(f\"Upvotes: {row['requester_upvotes_plus_downvotes_at_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14120691",
   "metadata": {},
   "source": [
    "## 4. Feature Importance from Baseline Model\n",
    "\n",
    "Let's train the baseline model and extract feature importance to understand what's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for baseline model\n",
    "y = df_train['requester_received_pizza'].values\n",
    "\n",
    "# Text features\n",
    "text_features = df_train['combined_text'].values\n",
    "test_text_features = df_test['combined_text'].values\n",
    "\n",
    "# Numeric features (exclude flair which doesn't exist in test)\n",
    "numeric_features = [f'{feat}_log' for feat in count_features] + [\n",
    "    'upvotes_per_comment', 'comments_per_post', 'account_age_years',\n",
    "    'text_length', 'word_count', 'exclamation_count', 'question_count',\n",
    "    'caps_ratio', 'pizza_mention', 'post_was_edited'\n",
    "]\n",
    "\n",
    "train_numeric = df_train[numeric_features].fillna(0).values\n",
    "test_numeric = df_test[numeric_features].fillna(0).values\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "# Single fold to get feature importance\n",
    "train_text_tfidf = tfidf.fit_transform(text_features)\n",
    "test_text_tfidf = tfidf.transform(test_text_features)\n",
    "\n",
    "train_combined = hstack([train_text_tfidf, train_numeric])\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(train_combined, y)\n",
    "\n",
    "# Get feature importance\n",
    "feature_names = list(tfidf.get_feature_names_out()) + numeric_features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': np.abs(model.coef_[0])\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 most important features:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78f185",
   "metadata": {},
   "source": [
    "## 5. Analyze Prediction Errors\n",
    "\n",
    "Let's see what the model gets wrong to identify improvement opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc44c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on training data\n",
    "train_pred = model.predict_proba(train_combined)[:, 1]\n",
    "\n",
    "# Add predictions to dataframe\n",
    "df_train['predicted_prob'] = train_pred\n",
    "\n",
    "# Find false positives and false negatives (using 0.5 threshold)\n",
    "threshold = 0.5\n",
    "false_positives = df_train[(df_train['requester_received_pizza'] == 0) & (df_train['predicted_prob'] > threshold)]\n",
    "false_negatives = df_train[(df_train['requester_received_pizza'] == 1) & (df_train['predicted_prob'] < threshold)]\n",
    "\n",
    "print(f\"False positives: {len(false_positives)}\")\n",
    "print(f\"False negatives: {len(false_negatives)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE FALSE POSITIVES (predicted success, actually failed):\")\n",
    "print(\"=\"*80)\n",
    "for idx, row in false_positives.sample(min(2, len(false_positives)), random_state=42).iterrows():\n",
    "    print(f\"\\n--- Request {row['request_id']} (prob: {row['predicted_prob']:.3f}) ---\")\n",
    "    print(f\"Title: {row['request_title']}\")\n",
    "    print(f\"Text: {row['combined_text'][:150]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE FALSE NEGATIVES (predicted failure, actually succeeded):\")\n",
    "print(\"=\"*80)\n",
    "for idx, row in false_negatives.sample(min(2, len(false_negatives)), random_state=42).iterrows():\n",
    "    print(f\"\\n--- Request {row['request_id']} (prob: {row['predicted_prob']:.3f}) ---\")\n",
    "    print(f\"Title: {row['request_title']}\")\n",
    "    print(f\"Text: {row['combined_text'][:150]}...\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
