## Problem Type
Binary classification combining text features (request title, text) with tabular metadata (Reddit activity metrics, user flair, timestamps).

## Reference Notebooks for Data Characteristics
- `exploration/eda.ipynb` - Contains full EDA: 2,878 training samples, 24.8% positive class (class imbalance), text length distributions, feature types (16 int, 9 object, 6 float, 1 bool), missing values in requester_user_flair (75% missing)

## Data Understanding
**Class Imbalance**: ~25% positive class requires special handling. See eda.ipynb for exact distribution.
**Text Features**: request_text (avg 402 chars), request_title (avg 72 chars) - both need preprocessing
**Categorical Features**: requester_user_flair with high cardinality (3 categories but 75% missing)
**Temporal Features**: Unix timestamps available for feature engineering

## Models
For text + tabular classification problems, winning Kaggle solutions typically use:
- **Gradient Boosting (Primary)**: XGBoost, LightGBM, or CatBoost trained on combined text embeddings + tabular features
- **Neural Networks (Secondary)**: BERT/RoBERTa for text encoding combined with tabular features in downstream classifier
- **Ensemble Size**: 3-5 diverse models (mix of tree-based and neural approaches)

## Text Feature Engineering
**Preprocessing**:
- Clean text: remove URLs, special characters, normalize whitespace
- Combine request_title and request_text into single document
- Apply lemmatization/stemming
- Create custom stopword list for Reddit-specific language

**Feature Extraction**:
- TF-IDF vectors (unigrams + bigrams) for gradient boosting models
- Sentence embeddings (BERT, RoBERTa) for neural approaches
- Text length features: char count, word count, avg word length
- Sentiment analysis scores
- Named entity recognition features

## Tabular Feature Engineering
**Metadata Features**:
- Log transforms for count features (upvotes, comments, posts) to reduce skewness
- Ratios: upvotes/comments, comments/posts, karma metrics
- Differences between request time and retrieval time metrics
- User activity rates: comments per day, posts per day
- Subreddit diversity metrics from requester_subreddits_at_request

**Categorical Encoding**:
- Target encoding for requester_user_flair (handle 75% missing values carefully)
- One-hot encoding for low-cardinality categorical features
- Frequency encoding for high-cardinality features

**Temporal Features**:
- Extract hour of day, day of week from timestamps
- Cyclical encoding for time features (sin/cos transforms)
- Time since account creation normalized by request time

## Handling Class Imbalance
**Critical for this dataset (24.8% positive class)**:
- Use AUC-ROC as evaluation metric (provided in competition)
- Apply scale_pos_weight in XGBoost/LightGBM (calculate as negative/positive ratio â‰ˆ 3.0)
- Consider class_weight='balanced' in scikit-learn models
- Optional: Try SMOTE oversampling on minority class
- Focus on PR-AUC during validation for imbalanced metrics

## Validation Strategy
- Stratified K-Fold (k=5) to preserve class distribution
- Time-based splits if temporal leakage is a concern
- Use early stopping on validation AUC-ROC
- Monitor both AUC-ROC and PR-AUC for imbalanced performance

## Ensembling
**Stacking Approach**:
- Level 1: Diverse models (XGBoost on TF-IDF, LightGBM on embeddings, CatBoost on combined)
- Level 2: Logistic regression or simple averaging
- Use out-of-fold predictions for meta-features

**Blending**:
- Weighted average based on validation performance
- Rank averaging for robustness
- Geometric mean for probability calibration

## Optimization
**Hyperparameter Tuning**:
- Bayesian optimization (Optuna) for efficient search
- Focus on: learning_rate, max_depth, min_child_samples, subsample
- Use early stopping to prevent overfitting

**Feature Selection**:
- SHAP values for feature importance interpretation
- Recursive feature elimination based on validation score
- Correlation analysis to remove redundant features