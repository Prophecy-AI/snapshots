{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e184e7f",
   "metadata": {},
   "source": [
    "# Evolver Loop 4 Analysis: LightGBM with Fixed Leakage Results\n",
    "\n",
    "Analyze exp_004 results to understand what's working and identify next optimization opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a45dcf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T12:32:42.475013Z",
     "iopub.status.busy": "2026-01-10T12:32:42.474717Z",
     "iopub.status.idle": "2026-01-10T12:32:44.041986Z",
     "shell.execute_reply": "2026-01-10T12:32:44.041235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Training samples: 2878\n",
      "Positive class rate: 0.248\n",
      "\n",
      "Loading exp_004 results...\n",
      "OOF predictions not found, using logged score\n",
      "\n",
      "Feature importance not available\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "print(\"Loading training data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "df_train = pd.DataFrame(train_data)\n",
    "y = df_train['requester_received_pizza'].values\n",
    "\n",
    "print(f\"Training samples: {len(df_train)}\")\n",
    "print(f\"Positive class rate: {y.mean():.3f}\")\n",
    "print()\n",
    "\n",
    "# Load exp_004 results\n",
    "print(\"Loading exp_004 results...\")\n",
    "exp_004_path = '/home/code/experiments/004_lightgbm_fixed_leakage'\n",
    "\n",
    "# Try to load OOF predictions if available\n",
    "import os\n",
    "if os.path.exists(f'{exp_004_path}/oof_predictions.npy'):\n",
    "    oof_predictions = np.load(f'{exp_004_path}/oof_predictions.npy')\n",
    "    print(f\"Loaded OOF predictions: {len(oof_predictions)} samples\")\n",
    "    \n",
    "    # Calculate overall CV score\n",
    "    cv_score = roc_auc_score(y, oof_predictions)\n",
    "    print(f\"Overall CV AUC: {cv_score:.4f}\")\n",
    "else:\n",
    "    print(\"OOF predictions not found, using logged score\")\n",
    "    cv_score = 0.6660\n",
    "    \n",
    "print()\n",
    "\n",
    "# Analyze feature importance if available\n",
    "if os.path.exists(f'{exp_004_path}/feature_importance.csv'):\n",
    "    feature_importance = pd.read_csv(f'{exp_004_path}/feature_importance.csv')\n",
    "    print(\"Feature importance loaded\")\n",
    "    print(feature_importance.head(10))\n",
    "else:\n",
    "    print(\"Feature importance not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b3c34",
   "metadata": {},
   "source": [
    "## Analysis of exp_004 Results\n",
    "\n",
    "Key metrics from exp_004:\n",
    "- CV AUC: 0.6660 Â± 0.0184\n",
    "- Improvement over exp_003: +0.0215\n",
    "- Individual folds: [0.6561, 0.6345, 0.6791, 0.6839, 0.6763]\n",
    "\n",
    "This shows:\n",
    "1. LightGBM is indeed better than logistic regression\n",
    "2. Fixing leakage helped (though modestly)\n",
    "3. Reduced dimensionality (82 features) works well\n",
    "4. Still far from gold (0.9791)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35941b57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T12:32:44.044602Z",
     "iopub.status.busy": "2026-01-10T12:32:44.043991Z",
     "iopub.status.idle": "2026-01-10T12:32:44.050214Z",
     "shell.execute_reply": "2026-01-10T12:32:44.049626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Performance Analysis:\n",
      "Mean: 0.6660\n",
      "Std: 0.0184\n",
      "Min: 0.6345\n",
      "Max: 0.6839\n",
      "Range: 0.0494\n",
      "\n",
      "Potential issues:\n",
      "\n",
      "Overall assessment: Model is reasonably stable but needs improvement\n"
     ]
    }
   ],
   "source": [
    "# Analyze fold performance\n",
    "fold_scores = [0.6561, 0.6345, 0.6791, 0.6839, 0.6763]\n",
    "print(\"Fold Performance Analysis:\")\n",
    "print(f\"Mean: {np.mean(fold_scores):.4f}\")\n",
    "print(f\"Std: {np.std(fold_scores):.4f}\")\n",
    "print(f\"Min: {np.min(fold_scores):.4f}\")\n",
    "print(f\"Max: {np.max(fold_scores):.4f}\")\n",
    "print(f\"Range: {np.max(fold_scores) - np.min(fold_scores):.4f}\")\n",
    "print()\n",
    "\n",
    "# Check for overfitting patterns\n",
    "print(\"Potential issues:\")\n",
    "if np.std(fold_scores) > 0.02:\n",
    "    print(\"- High variance across folds (>0.02) suggests potential overfitting or instability\")\n",
    "if np.max(fold_scores) - np.min(fold_scores) > 0.05:\n",
    "    print(\"- Large fold range (>0.05) suggests some folds are much harder/easier\")\n",
    "    \n",
    "print()\n",
    "print(\"Overall assessment: Model is reasonably stable but needs improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073629a2",
   "metadata": {},
   "source": [
    "## Gap Analysis: Why Are We Still Far From Gold?\n",
    "\n",
    "Current score: 0.666\n",
    "Gold threshold: 0.9791\n",
    "Gap: 0.3131 points\n",
    "\n",
    "This is a massive gap. Let me analyze what might be missing:\n",
    "\n",
    "1. **Feature Quality**: Current features are basic. Competition winners used much more sophisticated features\n",
    "2. **Model Capacity**: Single LightGBM might not be enough\n",
    "3. **Ensemble**: No ensembling yet\n",
    "4. **Advanced Techniques**: No stacking, no blending, no model diversity\n",
    "\n",
    "Let me research what winning solutions actually did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4bd60d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T12:32:44.052222Z",
     "iopub.status.busy": "2026-01-10T12:32:44.052003Z",
     "iopub.status.idle": "2026-01-10T12:32:44.061152Z",
     "shell.execute_reply": "2026-01-10T12:32:44.060469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments completed:\n",
      "- Baseline TF-IDF + Logistic Regression: 0.6386\n",
      "- Linguistic Features (Need/Gratitude/Evidential): 0.6118\n",
      "- Enhanced Text Representation (TF-IDF + SVD + Char Ngrams): 0.6445\n",
      "- exp_004_lightgbm_fixed_leakage: 0.6660\n",
      "\n",
      "Key findings from data_findings:\n",
      "- Data leakage in current approach: TF-IDF vectorizers and SVD transformers are fitted on full trainin...\n",
      "- Feature scale mismatch: TF-IDF features (0-1 range) combined with numeric features having vastly dif...\n",
      "- Dimensionality reduction optimization: SVD(50) explains 13.4% variance, SVD(75) explains 17.8%, SVD(...\n",
      "\n",
      "Gap to gold: 0.3131 points\n",
      "We need ~47% relative improvement from current score\n"
     ]
    }
   ],
   "source": [
    "# Load session state to see what we've tried\n",
    "import json\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    session_state = json.load(f)\n",
    "\n",
    "print(\"Experiments completed:\")\n",
    "for exp in session_state['experiments']:\n",
    "    print(f\"- {exp['name']}: {exp['score']:.4f}\")\n",
    "\n",
    "print()\n",
    "print(\"Key findings from data_findings:\")\n",
    "for finding in session_state['data_findings'][-3:]:\n",
    "    print(f\"- {finding['finding'][:100]}...\")\n",
    "    \n",
    "print()\n",
    "print(\"Gap to gold: 0.3131 points\")\n",
    "print(\"We need ~47% relative improvement from current score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecd0566",
   "metadata": {},
   "source": [
    "## Research Needed\n",
    "\n",
    "Given the massive gap (0.313 points), I need to research:\n",
    "\n",
    "1. **What did actual competition winners do?** - Look for post-mortems and winning solutions\n",
    "2. **What features are we missing?** - Advanced text features, user behavior patterns, temporal features\n",
    "3. **What modeling approaches work best?** - Ensembling strategies, stacking, model diversity\n",
    "4. **Are there data leaks or special patterns?** - Sometimes competitions have hidden patterns\n",
    "\n",
    "Let me search for competition-winning strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research queries to run:\n",
    "queries = [\n",
    "    \"What were the winning solutions for the Random Acts of Pizza Kaggle competition?\",\n",
    "    \"What specific features and techniques did top performers use in the Random Acts of Pizza competition?\",\n",
    "    \"How do Kaggle winners ensemble models for text classification competitions with tabular data?\",\n",
    "    \"What are the most effective stacking strategies for multimodal text + tabular classification?\",\n",
    "    \"Are there any known data leaks or special patterns in the Random Acts of Pizza dataset?\"\n",
    "]\n",
    "\n",
    "print(\"Research questions to answer:\")\n",
    "for i, q in enumerate(queries, 1):\n",
    "    print(f\"{i}. {q}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
