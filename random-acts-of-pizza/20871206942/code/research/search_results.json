{
  "query": "How do Kaggle winners handle class imbalance in binary text classification competitions?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Based on the techniques described by top Kaggle participants in binary text\u2011classification contests, winners typically tackle class imbalance with a short, repeatable workflow\u202f([Neptune blog](https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions);\u202f[Kaggle notebook on weighted BCE](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy);\u202f[AIcrowd notebook](https://www.aicrowd.com/showcase/dealing-with-class-imbalance)):\n\n1. **Add a class\u2011weighted loss** \u2013 replace the standard binary cross\u2011entropy with a weighted version that multiplies the loss of the minority class by a factor proportional to the inverse class frequency. This directly forces the model to pay more attention to the scarce examples\u202f([Weighted BCE notebook](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy)).\n\n2. **Supply sample weights during training** \u2013 most libraries (e.g.,\u202f`fit(..., sample_weight=\u2026)` in\u202fscikit\u2011learn, CatBoost, or PyTorch) accept a per\u2011sample weight vector. Setting higher weights for minority\u2011class rows further balances the gradient contributions\u202f([AIcrowd notebook](https://www.aicrowd.com/showcase/dealing-with-class-imbalance)).\n\n3. **Resample the training set** \u2013 apply oversampling (e.g., SMOTE) or random under\u2011sampling to create a more balanced label distribution before feeding data to the model. Studies show SMOTE and other oversampling methods improve text\u2011classification scores on imbalanced corpora\u202f([AIcrowd notebook](https://www.aicrowd.com/showcase/dealing-with-class-imbalance);\u202f[Comprehensive oversampling study](https://www.nature.com/articles/s41598-025-05791-7)).\n\n4. **Choose an imbalance\u2011aware metric** \u2013 use AUC\u2011ROC, macro\u2011averaged F1, or precision\u2011recall AUC rather than plain accuracy or log\u2011loss. Winners often tune the decision threshold on validation data to maximise the chosen metric\u202f([Jigsaw toxic\u2011comment challenge discussion](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/48639)).\n\n5. **Validate with stratified folds and blend models** \u2013 ensure each cross\u2011validation split preserves the minority\u2011class proportion, then blend several strong models (e.g., transformer\u2011based, linear, and tree\u2011based) to reduce variance while keeping the balanced signal\u202f([Neptune competition recap](https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions);\u202f[public kernel blends in Jigsaw challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52574)).\n\nFollowing these five steps\u2014weighted loss, sample weighting, careful resampling, appropriate metrics, and stratified\u2011fold blending\u2014captures the core tactics that Kaggle winners repeatedly employ to overcome severe class imbalance in binary text\u2011classification competitions.",
      "url": ""
    },
    {
      "title": "Text Classification: All Tips and Tricks from 5 Kaggle Competitions",
      "text": "In this article, I will discuss some great tips and tricks to [improve the performance](https://neptune.ai/blog/improving-machine-learning-deep-learning-models) of your text classification model. These tricks are obtained from solutions of some of Kaggle\u2019s top NLP competitions.\n\nNamely, I\u2019ve gone through:\n\n- [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification) \u2013 $65,000\n- [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/) \u2013 $35,000\n- [Quora Insincere Questions Classification](http://kaggle.com/c/quora-insincere-questions-classification) \u2013 $25,000\n- [Google QUEST Q&A Labeling](https://www.kaggle.com/c/google-quest-challenge) \u2013 $25,000\n- [TensorFlow 2.0 Question Answering](https://www.kaggle.com/c/tensorflow2-question-answering) \u2013 $50,000\n\nand found a ton of great ideas.\n\nWithout much lag, let\u2019s begin.\n\n## Dealing with larger datasets\n\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for Kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\n\n- Optimize the memory by [reducing the size of some attributes](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\n- Use open-source libraries such as [Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space\n- Use [cudf](https://github.com/rapidsai/cudf)\n- Convert data to [parquet](https://arrow.apache.org/docs/python/parquet.html) format\n- Convert data to [feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03) format\n\n## Small datasets and external data\n\nBut, what can one do if the dataset is small? Let\u2019s see some techniques to tackle this situation.\n\nOne way to increase the performance of any machine learning model is to use some external data frame that contains some variables that influence the predicate variable.\n\nLet\u2019s see some of the external datasets.\n\n- Use of [squad](https://rajpurkar.github.io/SQuAD-explorer/) data for Question Answering tasks\n- Other [datasets](http://nlpprogress.com/english/question_answering.html) for QA tasks\n- Wikitext long term dependency language modeling [dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\n- [Stackexchange data](https://archive.org/download/stackexchange)\n- Prepare a dictionary of commonly misspelled words and corrected words.\n- Use of [helper datasets](https://www.kaggle.com/kyakovlev/jigsaw-general-helper-public) for cleaning\n- [Pseudo labeling](https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969/) is the process of adding confidently predicted test data to your training data\n- Use different data [sampling methods](https://www.kaggle.com/shahules/tackling-class-imbalance)\n- Text augmentation by [Exchanging words with synonym](https://arxiv.org/pdf/1502.01710.pdf) [s](https://arxiv.org/pdf/1502.01710.pdf)\n- Text augmentation by [noising in RNN](https://arxiv.org/pdf/1703.02573.pdf)\n- Text augmentation by [translation to other languages and back](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/48038)\n\n## Data exploration and gaining insights\n\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\n\n- Twitter data [exploration methods](https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda)\n- Simple [EDA for tweets](https://www.kaggle.com/nz0722/simple-eda-text-preprocessing-jigsaw)\n- [EDA](https://www.kaggle.com/tunguz/just-some-simple-eda) for Quora data\n- [EDA](https://www.kaggle.com/kailex/r-eda-for-q-gru) in \u00a0R for Quora data\n- Complete [EDA](https://www.kaggle.com/codename007/start-from-here-quest-complete-eda-fe) with stack exchange data\n- My previous article on [EDA for natural language processing](https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools)\n\n## Data cleaning\n\nData cleaning is one of the important and integral parts of any NLP problem. Text data always needs some preprocessing and cleaning before we can represent it in a suitable form.\n\n- Use this [notebook](https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing) to clean social media data\n- [Data cleaning](https://www.kaggle.com/kyakovlev/preprocessing-bert-public) for BERT\n- Use [textblob](https://textblob.readthedocs.io/en/dev/quickstart.html) to correct misspellings\n- [Cleaning](https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing) for pre-trained embeddings\n- [Language detection and translation](https://www.pythonprogramming.in/language-detection-and-translation-using-textblob.html) for multilingual tasks\n- Preprocessing for Glove [part 1](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part1-eda) and [part 2](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part2-usage)\n- [Increasing word coverage](https://www.kaggle.com/sunnymarkliu/more-text-cleaning-to-increase-word-coverage) to get more from pre-trained word embeddings\n\n## Text representations\n\nBefore we feed our text data to the Neural network or ML model, the text input needs to be represented in a suitable format. These representations determine the performance of the model to a large extent.\n\n- Pretrained [Glove](https://nlp.stanford.edu/projects/glove/) vectors\n- Pretrained [fasttext](https://fasttext.cc/docs/en/english-vectors.html) vectors\n- Pretrained [word2vec](https://radimrehurek.com/gensim/models/word2vec.html) vectors\n- My previous article on these [3 embeddings](https://neptune.ai/blog/document-classification-small-datasets)\n- Combining [pre-trained vectors](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778/). This can help in better representation of text and decreasing OOV words\n- [Paragram](https://cogcomp.seas.upenn.edu/page/resource_view/106) embeddings\n- [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/1)\n- Use USE to generate [sentence-level features](https://www.kaggle.com/abhishek/distilbert-use-features-oof)\n- 3 methods to [combine embeddings](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778)\n\nContextual embeddings models\n\n- [BERT](https://github.com/google-research/bert) Bidirectional Encoder Representations from Transformers\n- [GPT](https://github.com/openai/finetune-transformer-lm)\n- [Roberta](https://github.com/pytorch/fairseq/tree/master/examples/roberta) a Robustly Optimized BERT\n- [Albert](https://github.com/google-research/ALBERT) a Lite BERT for Self-supervised Learning of Language Representations\n- [Distilbert](https://github.com/huggingface/transformers/tree/master/examples/distillation) a lighter version of BERT\n- [XLNET](https://github.com/zihangdai/xlnet/)\n\n## Modeling\n\n### Model architecture\n\nChoosing the right architecture is important to develop a proper machine learning model, sequence to sequence models like LSTMs, GRUs perform well in NLP problems and is always worth trying. Stacking 2 layers of LSTM/GRU networks is a common approach.\n\n- [Stacking Bidirectional CuDNNLSTM](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644/)\n- [Stacking LSTM networks](https://www.kaggle.com/sakami/google-quest-single-lstm/)\n- [LSTM and 5 fold Attention](https://www.kaggle.com/christofhenkel/keras-baseline-lstm-attention-5-fold/)\n- [Bi...",
      "url": "https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions"
    },
    {
      "title": "AIcrowd | Dealing with Class Imbalance | Posts",
      "text": "Loading\n\n#### [ADDI Alzheimers Detection Challenge](https://www.aicrowd.com/challenges/addi-alzheimers-detection-challenge)\n\n# Dealing with Class Imbalance\n\nLooking at different ways to address class imbalance in this dataset\n\nJohnowhitaker7 May 2021\n\n[20](https://www.aicrowd.com/participants/sign_in) [Open in Colab](https://colab.research.google.com/gist/aicrowd-bot/d9ed51a8b9be2026f0ff96c2b5cad9c2)\n\nIn this notebook I take a close look at some different ways we can address the difference in class balance between train and validation (and presumably test)\n\nWe look at changing sample weights, over\u00a0and under-sampling, SMOTE and some other tips and tricks.\n\nI hope you find it helpful :)\n\n# Introduction [\u00b6](https://www.aicrowd.com/www.aicrowd.com\\#Introduction)\n\nSo you've made your first model for this challenge and it's getting a log loss of ~0.9 - a ways behind the leaders on 0.6X. You're starting to think about feature engineering, adding more models to your ensemble, maybe trying one of those tabular deep learning models the cool kids are talking about. **STOP!** Before any of that, there is one BIG issue we need to deal with: class (im)balance.\n\nThe validation set (and presumably the test set) has a different class distribution to the training data. In this notebook we will look at many different ways we can correct for this class imbalance - picking one of these will boost your score tremendously (we're taking ~0.66 with a single simple random forest model). So, let's dive in.\n\n# Setup [\u00b6](https://www.aicrowd.com/www.aicrowd.com\\#Setup)\n\nImporting the libraries we'll be using, loading the data and getting ready to run our experiments.\n\nIn\u00a0\\[1\\]:\n\n```\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import f1_score, log_loss\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\n```\n\nIn\u00a0\\[2\\]:\n\n```\n#The training data\ndf = pd.read_csv('ds_shared_drive/train.csv')\nprint(df.shape)\ndf.head(2)\n```\n\n```\n(32777, 122)\n\n```\n\nOut\\[2\\]:\n\n| row\\_id | number\\_of\\_digits | missing\\_digit\\_1 | missing\\_digit\\_2 | missing\\_digit\\_3 | missing\\_digit\\_4 | missing\\_digit\\_5 | missing\\_digit\\_6 | missing\\_digit\\_7 | missing\\_digit\\_8 | ... | bottom\\_area\\_perc | left\\_area\\_perc | right\\_area\\_perc | hor\\_count | vert\\_count | eleven\\_ten\\_error | other\\_error | time\\_diff | centre\\_dot\\_detect | diagnosis |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | S0CIXBKIUEOUBNURP | 12.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.52617 | 0.524975 | 0.474667 | 0 | 0 | 0 | 1 | -105.0 | 0.0 | normal |\n| 1 | IW1Z4Z3H720OPW8LL | 12.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.00081 | 0.516212 | 0.483330 | 0 | 1 | 0 | 1 | NaN | NaN | normal |\n\n2 rows \u00d7 122 columns\n\nIn\u00a0\\[3\\]:\n\n```\n# The validation data (we merge in the labels for convenience)\nval = pd.read_csv('ds_shared_drive/validation.csv')\nval = pd.merge(val, pd.read_csv('ds_shared_drive/validation_ground_truth.csv'),\n               how='left', on='row_id')\nprint(val.shape)\nval.head()\n```\n\n```\n(362, 122)\n\n```\n\nOut\\[3\\]:\n\n| row\\_id | number\\_of\\_digits | missing\\_digit\\_1 | missing\\_digit\\_2 | missing\\_digit\\_3 | missing\\_digit\\_4 | missing\\_digit\\_5 | missing\\_digit\\_6 | missing\\_digit\\_7 | missing\\_digit\\_8 | ... | bottom\\_area\\_perc | left\\_area\\_perc | right\\_area\\_perc | hor\\_count | vert\\_count | eleven\\_ten\\_error | other\\_error | time\\_diff | centre\\_dot\\_detect | diagnosis |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | LA9JQ1JZMJ9D2MBZV | 11.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.499368 | 0.553194 | 0.446447 | 0 | 0 | 0 | 1 | NaN | NaN | post\\_alzheimer |\n| 1 | PSSRCWAPTAG72A1NT | 6.0 | 1.0 | 1.0 | 0.0 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | ... | 0.427196 | 0.496352 | 0.503273 | 0 | 1 | 0 | 1 | NaN | NaN | normal |\n| 2 | GCTODIZJB42VCBZRZ | 11.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | ... | 0.505583 | 0.503047 | 0.496615 | 1 | 0 | 0 | 0 | 0.0 | 0.0 | normal |\n| 3 | 7YMVQGV1CDB1WZFNE | 3.0 | 1.0 | 0.0 | 1.0 | 0.0 | 1.0 | 1.0 | 1.0 | 1.0 | ... | 0.444633 | 0.580023 | 0.419575 | 0 | 1 | 0 | 1 | NaN | NaN | post\\_alzheimer |\n| 4 | PHEQC6DV3LTFJYIJU | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 0.0 | ... | 0.395976 | 0.494990 | 0.504604 | 0 | 0 | 0 | 1 | 150.0 | 0.0 | normal |\n\n5 rows \u00d7 122 columns\n\nIn\u00a0\\[4\\]:\n\n```\n# We'll keep track of how different approaches perform\nresults = []\n```\n\n# Baseline \\#1 - Training on all data [\u00b6](https://www.aicrowd.com/www.aicrowd.com\\#Baseline-%231---Training-on-all-data)\n\nThis is a case where we don't do any correction for the class imbalance. Some models will do better than others - tree-based models like CatBoost will be less sensitive than some other model types, but they will still over-estimate the probability that a given sample will fall into the majority class when making predicitons on the validation set (since the 'normal' class is so much more common in the training data).\n\nIn\u00a0\\[5\\]:\n\n```\n# Prep the data\nX = df.drop(['row_id', 'diagnosis'], axis=1).fillna(0)\ny = df['diagnosis']\nX_val = val.drop(['row_id', 'diagnosis'], axis=1).fillna(0)\ny_val = val['diagnosis']\n\n# Train the model\nmodel = CatBoostClassifier(verbose=False, cat_features=['intersection_pos_rel_centre'])\n\n# Evaluate on val set\nmodel.fit(X, y, eval_set = (X_val, y_val), early_stopping_rounds = 30)\n\n# Store results\nr = {'Approach':'No modifications',\n     'Log Loss':log_loss(y_val, model.predict_proba(X_val)),\n     'F1':f1_score(y_val, model.predict(X_val), average='macro')\n    }\nresults.append(r)\n\nprint(r) # Show results\n```\n\n```\n{'Approach': 'No modifications', 'Log Loss': 0.6745549053231596, 'F1': 0.2848101265822785}\n\n```\n\nA log loss of 0.67 on the validation set isn't terrible. We are using the validation set for early stopping - without that in place we get a log loss of 0.78 on our validation set and 0.8X on the leaderboard. So in a way, by using the validation set for early stopping we are already starting to combat our class balance problem... but we can do much better!\n\n# Adjusting Sample Weights [\u00b6](https://www.aicrowd.com/www.aicrowd.com\\#Adjusting-Sample-Weights)\n\nModels like CatBoost allow us to assign more weight to specific samples. In this case, we use this to place less weight on samples in the over-represented classes, combating the bias introduced by the imbalance:\n\nIn\u00a0\\[6\\]:\n\n```\n# Prep the data\nX = df.drop(['row_id', 'diagnosis'], axis=1).fillna(0)\ny = df['diagnosis']\nX_val = val.drop(['row_id', 'diagnosis'], axis=1).fillna(0)\ny_val = val['diagnosis']\n\n#Our class weights\nweights = {\n    'normal':9/74, # Chosen based on some quick mental maths comparing the distribution of train vs val\n    'post_alzheimer':0.85,\n    'pre_alzheimer':1\n}\n\n# Applying these weights as sample weights by using Pool to wrap our training data\ntrain_data = Pool(\n    data = X,\n    label = y,\n    weight = y.map(weights), # << The important bit\n    cat_features = [list(X.columns).index('intersection_pos_rel_centre')]\n)\n\neval_data = Pool(\n    data = X_val,\n    label = y_val,\n    weight = y_val.map(lambda x: 1.0), # all validation samples get a weight of 1\n    cat_features = [list(X.columns).index('intersection_pos_rel_centre')]\n)\n\n# Train the model\nmodel = CatBoostClassifier(verbose=False)\n\n# Evaluate on val set\nmodel.fit(train_data, eval_set = eval_data, early_stopping_rounds = 30)\n\n# Store results\nr = {'Approach':'Modifying Sample Weights',\n     'Log Loss':log_loss(y_val, model.predict_proba(X_val)),\n     'F1':f1_score(y_val, model.predict(X_val), average='macro')\n    }\nresults.append(r)\n\nprint(r) # Show results\n```\n\n```\n{'Approach': 'Modifying Sample Weights', 'Log Loss': 0.5593949556085255, 'F1': 0.4727603953181...",
      "url": "https://www.aicrowd.com/showcase/dealing-with-class-imbalance"
    },
    {
      "title": "[Class Imbalance]->Weighted Binary Cross Entropy",
      "text": "menu\n\n[Skip to\\\n\\\ncontent](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy#site-content)\n\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\n\nCreate\n\nsearch\u200b\n\n- [explore\\\n\\\nHome](https://www.kaggle.com/)\n\n- [emoji\\_events\\\n\\\nCompetitions](https://www.kaggle.com/competitions)\n\n- [table\\_chart\\\n\\\nDatasets](https://www.kaggle.com/datasets)\n\n- [tenancy\\\n\\\nModels](https://www.kaggle.com/models)\n\n- [code\\\n\\\nCode](https://www.kaggle.com/code)\n\n- [comment\\\n\\\nDiscussions](https://www.kaggle.com/discussions)\n\n- [school\\\n\\\nLearn](https://www.kaggle.com/learn)\n\n\n- [expand\\_more\\\n\\\nMore](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy)\n\n\nauto\\_awesome\\_motion\n\nView Active Events\n\nmenu\n\n[Skip to\\\n\\\ncontent](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy#site-content)\n\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\n\nsearch\u200b\n\n[Sign In](https://www.kaggle.com/account/login?phase=startSignInTab&returnUrl=%2Fcode%2Fparthdhameliya77%2Fclass-imbalance-weighted-binary-cross-entropy)\n\n[Register](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2Fcode%2Fparthdhameliya77%2Fclass-imbalance-weighted-binary-cross-entropy)\n\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\n\n[Learn more](https://www.kaggle.com/cookies)\n\nOK, Got it.\n\nParth Dhameliya \u00b7 4y ago \u00b7 5,978 views\n\narrow\\_drop\\_up14\n\nCopy & Edit16\n\n![bronze medal](https://www.kaggle.com/static/images/medals/notebooks/bronzel@1x.png)\n\nmore\\_vert\n\n# \\[Class Imbalance\\]->Weighted Binary Cross Entropy\n\n## \\[Class Imbalance\\]->Weighted Binary Cross Entropy\n\n[Notebook](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy/notebook) [Input](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy/input) [Output](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy/output) [Logs](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy/log) [Comments (1)](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy/comments)\n\nhistoryVersion 3 of 3chevron\\_right\n\n## Runtime\n\nplay\\_arrow\n\n17s\n\n## Input\n\nCOMPETITIONS\n\n![](https://www.kaggle.com/competitions/23652/images/thumbnail)\n\nSETI Breakthrough Listen - E.T. Signal Search\n\n## Tags\n\n[NumPy](https://www.kaggle.com/code?tagIds=16609-NumPy) [pandas](https://www.kaggle.com/code?tagIds=16611-pandas) [Seaborn](https://www.kaggle.com/code?tagIds=16623-Seaborn)\n\n## Language\n\nPython\n\n## Table of Contents\n\n[Compute positive and negative frequencies](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy#Compute-positive-and-negative-frequencies) [Weighted Binary Cross Entropy](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy#Weighted-Binary-Cross-Entropy)\n\n![Profile picture for undefined](https://storage.googleapis.com/kaggle-competitions/kaggle/23652/logos/thumb76_76.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1739586279&Signature=FApxFEdXfKKyyTLqHdfAQvbBQeVnBI9q1i%2FcXvABXe5%2B0R3jrjE5g%2Be4FsMOZH2UKtzDeig%2F2IU6gUAyAoHYQcWfLpgkPoYELdgiKBm5oj7bOGL%2FUloUqKsP%2FxuTtqzKCSjngWgVnQFKba%2F9Lo778jI9v7AeVxJ7HaWSiwJNamLgbdVuzo14hDQJsfN2DcHLuxS9fgtwNls5%2BuAeh0Hoo9Z8jTylds%2BMj%2FB524rN5SYWM%2FfclED7v8%2BUWWGjKcW6uQ5nYQm8ZnzFSd8OYzPu6hngnfWww6JmimmEzK6Zs0Q9UcUHNHqZT4blG9bozCOiiOQ8xrjHL7WelvBcEL3NPg%3D%3D)\n\nCompetition Notebook\n\n[SETI Breakthrough Listen - E.T. Signal Search](https://www.kaggle.com/competitions/seti-breakthrough-listen)\n\n[iframe](https://www.kaggleusercontent.com/kf/62732875/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..MXZW1-_rS9Df7ODZWH3kVQ.MCLNxRmsbqUNdoV1lroPjVkG2iGA0vTYa91gU7SIqTTTgnVAcgd-a5wwDNmxl9WRqbgus1YurDuaW33u-FcFSq0qdPxvbHznm3SyyAz0oc1_wq3OfZOxN0Foh9NEb2DnZUE4sfelNCYK7ZS5rGv44hOnvZCDtf_Zj9rGdqbhFjRWlZSCQlknHSpbZYkMNETEn5ojRU51J6dNkWolOVVlUdZ_NdwwqlwIJ7eccxm_cEbIyxErrc3KQgElrrcsWrESQWnI6gwW0A7a3FEvH8EJV-t-XVS9ZqQEPF-hzPg5vOUv2zAw2yvesr6PvuaW3_CVEyZDhuNWx5fBxtfMZl_B8oQBqj8oB0waDI9_AQoSRPSp39S5nfRqoLtJSOsxMML55wXmCBHg-MtPypPx8aGMpHz2rZ2UVHxz-aCPT8Ku1YkQbfXj2PeTK6_X7Re0YqqGoJdz5SvHT6az3zYpNRKrwHnvAl_u4Sp83wHApdYM4GYaIkX5KtAX6kmHLzEUhfeVYID2HpNcgtl0rBkvNBa2tXsDiBZswKOfzUj9HQ2wmxdeC9jWpHSbF-fX49m-a61UObXhSasACwXhi9rVtsGLBdUQ1YuhSHb4c6DyZX0v-PXfkQgpo4BfViPKh6sXEfqC79cKyoB0c2oHy6q3lUI0PrcMVOExiuRxMhZo4MfK-NMfCP1DPMt53wi2Fea-8bxm.O5L0Myiw0b4rIyeHg0cEAQ/__results__.html?sharingControls=true)\n\n## License\n\nThis Notebook has been released under the [Apache 2.0](http://www.apache.org/licenses/LICENSE-2.0) open source license.\n\n## Continue exploring\n\n- ![](https://www.kaggle.com/static/images/kernel/viewer/input_light.svg)\n\n\n\n\n\n\n\nInput\n\n1 file\n\n\n\n\narrow\\_right\\_alt\n\n- ![](https://www.kaggle.com/static/images/kernel/viewer/output_light.svg)\n\n\n\n\n\n\n\nOutput\n\n0 files\n\n\n\n\narrow\\_right\\_alt\n\n- ![](https://www.kaggle.com/static/images/kernel/viewer/logs_light.svg)\n\n\n\n\n\n\n\nLogs\n\n16.9 second run - successful\n\n\n\n\narrow\\_right\\_alt\n\n- ![](https://www.kaggle.com/static/images/kernel/viewer/comments_light.svg)\n\n\n\n\n\n\n\nComments\n\n1 comment\n\n\n\n\narrow\\_right\\_alt",
      "url": "https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy"
    },
    {
      "title": "A comprehensive evaluation of oversampling techniques for enhancing text classification performance",
      "text": "A comprehensive evaluation of oversampling techniques for enhancing text classification performance | Scientific Reports\n[Skip to main content](#content)\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\nthe best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\nInternet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\nand JavaScript.\nAdvertisement\n[![Scientific Reports](https://media.springernature.com/full/nature-cms/uploads/product/srep/header-d3c533c187c710c1bedbd8e293815d5f.svg)](https://www.nature.com/srep)\n* [View all journals](https://www.nature.com/siteindex)\n* [Search](#search-menu)\n* [Log in](https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41598-025-05791-7?error=cookies_not_supported&code=03e2ec5c-c011-4bec-9529-d28b11a510d0)\n* [ContentExplore content](#explore)\n* [Aboutthe journal](#about-the-journal)\n* [Publishwith us](#publish-with-us)\n* [Sign up for alerts](https://journal-alerts.springernature.com/subscribe?journal_id&#x3D;41598)\n* [RSS feed](https://www.nature.com/srep.rss)\nA comprehensive evaluation of oversampling techniques for enhancing text classification performance\n[Download PDF](https://www.nature.com/articles/s41598-025-05791-7.pdf)\n[Download PDF](https://www.nature.com/articles/s41598-025-05791-7.pdf)\n* Article\n* [Open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)\n* Published:01 July 2025# A comprehensive evaluation of oversampling techniques for enhancing text classification performance\n* [Salimkan Fatma Taskiran](#auth-Salimkan_Fatma-Taskiran-Aff1)[1](#Aff1),\n* [Bahaeddin Turkoglu](#auth-Bahaeddin-Turkoglu-Aff2)[2](#Aff2),\n* [Ersin Kaya](#auth-Ersin-Kaya-Aff1)[1](#Aff1)&amp;\n* \u2026* [Tunc Asuroglu](#auth-Tunc-Asuroglu-Aff3-Aff4)[3](#Aff3),[4](#Aff4)Show authors\n[*Scientific Reports*](https://www.nature.com/srep)**volume15**, Article\u00a0number:21631(2025)[Cite this article](#citeas)\n* 3628Accesses\n* 4Citations\n* [Metricsdetails](https://www.nature.com/articles/s41598-025-05791-7/metrics)\n### Subjects\n* [Computational science](https://www.nature.com/subjects/computational-science)\n* [Computer science](https://www.nature.com/subjects/computer-science)\n## Abstract\nClass imbalance is a common and critical challenge in text classification tasks, where the underrepresentation of certain classes often impairs the ability of classifiers to learn minority class patterns effectively. According to the \u201cgarbage in, garbage out\u201d principle, even high-performing models may fail when trained on skewed distributions. To address this issue, this study investigates the impact of oversampling techniques, specifically the Synthetic Minority Over-sampling Technique (SMOTE) and thirty of its variants, on two benchmark text classification datasets: TREC and Emotions. Each dataset was vectorized using the MiniLMv2 transformer model to obtain semantically rich representations, and classification was performed using six machine learning algorithms. The balanced and imbalanced scenarios were compared in terms of F1-Score and Balanced Accuracy. This work constitutes, to the best of our knowledge, the first large-scale, systematic benchmarking of SMOTE-based oversampling methods in the context of transformer-embedded text classification. Furthermore, statistical significance of the observed performance differences was validated using the Friedman test. The results provide practical insights into the selection of oversampling techniques tailored to dataset characteristics and classifier sensitivity, supporting more robust and fair learning in imbalanced natural language processing tasks.\n### Similar content being viewed by others\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-025-01031-0/MediaObjects/41598_2025_1031_Fig1_HTML.png)\n### [Mitigating class imbalance in churn prediction with ensemble methods and SMOTE](https://www.nature.com/articles/s41598-025-01031-0?fromPaywallRec=false)\nArticleOpen access09 May 2025\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-025-05122-w/MediaObjects/41598_2025_5122_Fig1_HTML.png)\n### [Smart adaptive ensemble model for multiclass imbalanced nonstationary data streams](https://www.nature.com/articles/s41598-025-05122-w?fromPaywallRec=false)\nArticleOpen access01 July 2025\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-025-13929-w/MediaObjects/41598_2025_13929_Fig1_HTML.png)\n### [Improving learning from the complex multi-class imbalanced and overlapped data by mapping into higher dimension using SVM++](https://www.nature.com/articles/s41598-025-13929-w?fromPaywallRec=false)\nArticleOpen access25 August 2025\n## Introduction\nImbalanced datasets represent a significant challenge commonly encountered in real-world problems. In the field of classification problems, imbalanced datasets arise when the numbers of samples representing different classes varies substantially[1](https://www.nature.com/articles/s41598-025-05791-7#ref-CR1). Such datasets can adversely impact the training process of classifier models. As the model tends to focus on the majority class during training, it may fail to adequately learn the minority classes. This issue becomes particularly pronounced in problems where certain classes have very few instances. Consequently, although the overall accuracy of the model may appear high, its performance in correctly classifying the minority class remains insufficient.\nClassification models typically operate under the assumption that each class within a dataset contains an equal number of instances. However, this assumption becomes inadequate when the minority class holds greater importance than others. Developing highly effective classifiers for such imbalanced datasets remains a significant challenge. As the imbalance in the dataset increases, the model tends to overfit the majority class, impairing its ability to achieve the desired performance on minority classes and leading to biased outcomes. Hence, the reliability of the model in real-world applications deteriorates, resulting in failures in critical scenarios where the accurate detection of minority classes is essential[2](https://www.nature.com/articles/s41598-025-05791-7#ref-CR2). The classification of text data frequently encounters severe class imbalance challenges in critical real-world applications, including hate speech detection, cyberbullying identification, fraud detection in communication systems, and sentiment analysis of underrepresented viewpoints[3](#ref-CR3),[4](#ref-CR4),[5](#ref-CR5),[6](#ref-CR6),[7](#ref-CR7),[8](#ref-CR8),[9](https://www.nature.com/articles/s41598-025-05791-7#ref-CR9). In these domains, failure to accurately detect minority classes can result in serious ethical, legal, and operational consequences. By systematically evaluating a broad range of SMOTE-based oversampling methods, this study offers a practical framework for enhancing classifier robustness and promoting fairness in imbalanced natural language processing tasks.\nImbalanced datasets constitute a prevalent challenge across various domains, irrespective of data type. In text classification, this imbalance often stems from the natural dominance of certain topics or sentiments over less frequent ones[10](https://www.nature.com/articles/s41598-025-05791-7#ref-CR10). For instance, in major natural language processing tasks such as sentiment analysis, positive reviews may substantially outnumber negative ones, resulting in an imbalanced dataset[11](https://www.nature.com/articles/s41598-025-05791-7#ref-CR11). This situation may cause models to preferentially learn majority classes while neglecting the minority ones. Several strategies have been developed to achieve successful outc...",
      "url": "https://www.nature.com/articles/s41598-025-05791-7"
    },
    {
      "title": "Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions",
      "text": "Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions[\n**\ud83d\udce3 BIG NEWS:****Neptune is joining OpenAI!**\u2192 Read the message from our CEO \ud83d\udce3![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\nWhat do you want to find?\nSearch\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\nSearch in Blog...\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\nSearch in Blog...\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\n[Neptune Blog](https://neptune.ai/blog)# Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Shahul-Es-new-scaled.jpeg?fit=2560%2C1920&ssl=1)\n[Shahul ES](https://neptune.ai/blog/author/shahules)\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)3 min\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)1st September, 2023\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)[Tabular Data](https://neptune.ai/blog/category/tabular-data)\nIn this article, I will discuss some great tips and tricks to improve the performance of your structured data binary classification model. These tricks are obtained from solutions of some of Kaggle\u2019s top tabular data competitions. Without much lag, let\u2019s begin.\nThese are the five competitions that I have gone through to create this article:\n* [**Home credit default risk**](https://www.kaggle.com/c/home-credit-default-risk/)\n* [**Santander Customer Transaction Prediction**](https://www.kaggle.com/c/santander-customer-transaction-prediction/notebooks)\n* [**VSB Power Line Fault Detection**](https://www.kaggle.com/c/vsb-power-line-fault-detection/overview/evaluation)\n* [**Microsoft Malware Prediction**](https://www.kaggle.com/c/microsoft-malware-prediction/overview)\n* [**IEEE-CIS Fraud Detection**](https://www.kaggle.com/c/ieee-fraud-detection/overview/evaluation/)## Dealing with larger datasets\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\n* Faster[data loading with pandas.](https://www.kaggle.com/c/home-credit-default-risk/discussion/59575)\n* Data compression techniques to[reduce the size of data by 70%](https://www.kaggle.com/nickycan/compress-70-of-dataset).\n* Optimize the memory by r[educing the size of some attributes.](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\n* Use open-source libraries such as[Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space.\n* Use[cudf](https://github.com/rapidsai/cudf).\n* Convert data to[parquet](https://arrow.apache.org/docs/python/parquet.html)format.\n* Converting data to[feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03)format.\n* Reducing memory usage for[optimizing RAM](https://www.kaggle.com/mjbahmani/reducing-memory-size-for-ieee).## Data exploration\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\n* EDA for microsoft[malware detection.](https://www.kaggle.com/youhanlee/my-eda-i-want-to-see-all)\n* Time Series[EDA for malware detection.](https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68)\n* Complete[EDA for home credit loan prediction](https://www.kaggle.com/codename007/home-credit-complete-eda-feature-importance).\n* Complete[EDA for Santader prediction.](https://www.kaggle.com/gpreda/santander-eda-and-prediction)\n* EDA for[VSB Power Line Fault Detection.](https://www.kaggle.com/go1dfish/basic-eda)## Data preparation\nAfter data exploration, the first thing to do is to use those insights to prepare the data. To tackle issues like class imbalance, encoding categorical data, etc. Let\u2019s see the methods used to do it.\n* Methods to t[ackle class imbalance](https://www.kaggle.com/shahules/tackling-class-imbalance).\n* Data augmentation by[Synthetic Minority Oversampling Technique](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/).\n* Fast inplace[shuffle for augmentation](https://www.kaggle.com/jiweiliu/fast-inplace-shuffle-for-augmentation).\n* Finding[synthetic samples in the dataset.](https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split)\n* [Signal denoising](https://www.kaggle.com/jackvial/dwt-signal-denoising)used in signal processing competitions.\n* Finding[patterns of missing data](https://www.kaggle.com/jpmiller/patterns-of-missing-data).\n* Methods to handle[missing data](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779).\n* An overview of various[encoding techniques for categorical data.](https://www.kaggle.com/shahules/an-overview-of-encoding-techniques)\n* Building[model to predict missing values.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64598)\n* Random[shuffling of data](https://www.kaggle.com/brandenkmurray/randomly-shuffled-data-also-works)to create new synthetic training set.## Feature engineering\nNext, you can check the most popular feature and feature engineering techniques used in these top kaggle competitions. The feature engineering part varies from problem to problem depending on the domain.\n* Target[encoding cross validation](https://medium.com/@pouryaayria/k-fold-target-encoding-dfe9a594874b/)for better encoding.\n* Entity embedding to[handle categories](https://www.kaggle.com/abhishek/entity-embeddings-to-handle-categories).\n* Encoding c[yclic features for deep learning.](https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning)\n* Manual[feature engineering methods](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering).\n* Automated feature engineering techniques[using featuretools](https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics).\n* Top hard crafted features used in[microsoft malware detection](https://www.kaggle.com/sanderf/7th-place-solution-microsoft-malware-prediction).\n* Denoising NN for[feature extraction](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798).\n* Feature engineering[using RAPIDS framework.](https://www.kaggle.com/cdeotte/rapids-feature-engineering-fraud-0-96/)\n* Things to remember while processing f[eatures using LGBM.](https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575)\n* [Lag features and moving averages.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64593)\n* [Principal component analysis](https://medium.com/machine-learning-researcher/dimensionality-reduction-pca-and-lda-6be91734f567)for...",
      "url": "https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions"
    },
    {
      "title": "GitHub - siamak1399/Kaggle-Imbalanced-Binary-Classification: This is a binary classification for severely Imbalanced Kaggle dataset to predict Insurance renewal based on 11 features with missing values. The repository including two notebooks composed of EDA, tricks in data preprocessing, modeling with classic methods and presenting an innovative ML algorithm.",
      "text": "<div><div><article><p></p><h2>Kaggle-Imbalanced-Binary-Classification</h2><a href=\"#kaggle-imbalanced-binary-classification\"></a><p></p>\n<p>The main goal of this work is not stick to that special dataset but to review Important concepts such as generalizability of models, data preprocessing, feature extraction, modeling and evaluation. ML models such as logistic regression, random forest, support vector machine with different kernels, Gaussian Naive Bayes, AdaBoost classifier and Neural networks will be applied to predict class label of Kaggle dataset. This project inspired me to develop a new ML algorithm that is very powerful for cases that meet the required conditions.</p>\n<p>In Part I, the importance of choosing special evaluating metrics for imbalanced datasets and some innovative tricks on scaling, transforming and target encoding will be explained. Also, new features will be extracted via PCA, ICA, LDA and polynomial feature extraction methods. Feature selection section will be omitted since, a great innovative feature selection method presented in my previous notebook on car price prediction. Exploratory data analysis and plots are available at appendix in chapter 15.</p>\n<p>In part II, the theory behind innovative approach that called PMG, Parallel Modeling of Groups, for data are derived from multiple sources or from the one source with different modes is presented and two shallow version, PMG-clustered and PMG-boosted are applied to traindata_sia_train.csv and traindata_sia_test.csv datasets that are extracted in Part I. Finally, shallow and deep ML versions of the powerful innovative hybrid of PMG with bagging and boosting are described.</p>\n</article></div></div>",
      "url": "https://github.com/siamak1399/kaggle-imbalanced-binary-classification"
    },
    {
      "title": "Search code, repositories, users, issues, pull requests...",
      "text": "GitHub - sabamadadi/multi-strategy-ensemble-binary-classification: Robust binary data classification using a multi-strategy ensemble learning approach.\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=sabamadadi/multi-strategy-ensemble-binary-classification)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[sabamadadi](https://github.com/sabamadadi)/**[multi-strategy-ensemble-binary-classification](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification)**Public\n* [Notifications](https://github.com/login?return_to=/sabamadadi/multi-strategy-ensemble-binary-classification)You must be signed in to change notification settings\n* [Fork0](https://github.com/login?return_to=/sabamadadi/multi-strategy-ensemble-binary-classification)\n* [Star1](https://github.com/login?return_to=/sabamadadi/multi-strategy-ensemble-binary-classification)\nRobust binary data classification using a multi-strategy ensemble learning approach.\n[1star](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/stargazers)[0forks](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/forks)[Branches](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/branches)[Tags](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/tags)[Activity](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/activity)\n[Star](https://github.com/login?return_to=/sabamadadi/multi-strategy-ensemble-binary-classification)\n[Notifications](https://github.com/login?return_to=/sabamadadi/multi-strategy-ensemble-binary-classification)You must be signed in to change notification settings\n# sabamadadi/multi-strategy-ensemble-binary-classification\nmain\n[Branches](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/branches)[Tags](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/tags)\n[](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/branches)[](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[4 Commits](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/commits/main/)\n[](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/commits/main/)\n|\n[README.md](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/blob/main/README.md)\n|\n[README.md](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/blob/main/README.md)\n|\n|\n|\n[c\\_report.pdf](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/blob/main/c_report.pdf)\n|\n[c\\_report.pdf](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/blob/main/c_report.pdf)\n|\n|\n|\n[classification.ipynb](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/blob/main/classification.ipynb)\n|\n[classification.ipynb](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/blob/main/classification.ipynb)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# Multi-Strategy Ensemble Learning for Binary Data Classification\n[](#multi-strategy-ensemble-learning-for-binary-data-classification)\n[Full Report](https://drive.google.com/file/d/1Cf21G0ubgu8sm_Y_j2p2E1bngO8KpD2U/view?usp=sharing)\n[Kaggle Competition Leaderboard](https://www.kaggle.com/competitions/datascience-4-competition/leaderboard)First Score (0.41791)\nThis project develops a robust classification pipeline for high-dimensional binary datasets. The dataset contained 64 binary features and a categorical target, with class imbalance handled using SMOTE, producing a balanced training set of 792 samples.\nFeatures were scaled using StandardScaler to ensure consistency across training and testing. Hyperparameters were optimized using Optuna with stratified k-fold cross-validation (k=3 for ensemble, k=5 for individual models).\nThe final model is a soft-voting ensemble integrating multiple Bernoulli Naive Bayes classifiers, Logistic Regression, XGBoost, Balanced Random Forest, and three standard Random Forest classifiers. Ensemble hyperparameters were specifically tuned to maximize cross-validated accuracy (\\~0.437).\nExploratory methods like CTGAN, MLP-based feature extraction, and Random Forest-based feature selection were investigated but not included in the final pipeline.\nCritical attention was given to preprocessing consistency: the test set was scaled using the training scaler to prevent distribution mismatch.\nThe ensemble approach balances diverse algorithmic strengths, improves robustness, and handles class imbalance effectively. Future directions include exploring advanced feature selection, stacking ensembles, alternative imbalance techniques, and probability calibration.\nKey takeaways: multi-strategy ensembles are effective for high-dimensional binary data, SMOTE improves minority class performance, and consistent preprocessing is crucial for valid inference.\n## About\nRobust binary data classification using a multi-strategy ensemble learning approach.\n### Topics\n[classification](https://github.com/topics/classification)\n### Resources\n[Readme](#readme-ov-file)\n### Uh oh!\nThere was an error while loading.[Please reload this page]().\n[Activity](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/activity)\n### Stars\n[**1**star](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/stargazers)\n### Watchers\n[**0**watching](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/watchers)\n### Forks\n[**0**forks](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/forks)\n[Report repository](https://github.com/contact/report-content?content_url=https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification&amp;report=sabamadadi+(user))\n## [Releases](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/releases)\nNo releases published\n## [Packages0](https://github.com/users/sabamadadi/packages?repo_name=multi-strategy-ensemble-binary-classification)\nNo packages published\n## Languages\n* [Jupyter Notebook100.0%](https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification/search?l=jupyter-notebook)\nYou can\u2019t perform that action at this time.",
      "url": "https://github.com/sabamadadi/multi-strategy-ensemble-binary-classification"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2409.19751] Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2409.19751\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2409.19751**(cs)\n[Submitted on 29 Sep 2024]\n# Title:Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification\nAuthors:[Mohamed Abdelhamid](https://arxiv.org/search/cs?searchtype=author&amp;query=Abdelhamid,+M),[Abhyuday Desai](https://arxiv.org/search/cs?searchtype=author&amp;query=Desai,+A)\nView a PDF of the paper titled Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification, by Mohamed Abdelhamid and Abhyuday Desai\n[View PDF](https://arxiv.org/pdf/2409.19751)[HTML (experimental)](https://arxiv.org/html/2409.19751v1)> > Abstract:\n> Class imbalance in binary classification tasks remains a significant challenge in machine learning, often resulting in poor performance on minority classes. This study comprehensively evaluates three widely-used strategies for handling class imbalance: Synthetic Minority Over-sampling Technique (SMOTE), Class Weights tuning, and Decision Threshold Calibration. We compare these methods against a baseline scenario of no-intervention across 15 diverse machine learning models and 30 datasets from various domains, conducting a total of 9,000 experiments. Performance was primarily assessed using the F1-score, although our study also tracked results on additional 9 metrics including F2-score, precision, recall, Brier-score, PR-AUC, and AUC. Our results indicate that all three strategies generally outperform the baseline, with Decision Threshold Calibration emerging as the most consistently effective technique. However, we observed substantial variability in the best-performing method across datasets, highlighting the importance of testing multiple approaches for specific problems. This study provides valuable insights for practitioners dealing with imbalanced datasets and emphasizes the need for dataset-specific analysis in evaluating class imbalance handling techniques. Comments:|13 pages including appendix, 4 tables|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)|\nACMclasses:|I.2.6; I.5.1; I.5.2; I.2.m|\nCite as:|[arXiv:2409.19751](https://arxiv.org/abs/2409.19751)[cs.LG]|\n|(or[arXiv:2409.19751v1](https://arxiv.org/abs/2409.19751v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2409.19751](https://doi.org/10.48550/arXiv.2409.19751)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Abhyuday Desai [[view email](https://arxiv.org/show-email/43e3e529/2409.19751)]\n**[v1]**Sun, 29 Sep 2024 16:02:32 UTC (18 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification, by Mohamed Abdelhamid and Abhyuday Desai\n* [View PDF](https://arxiv.org/pdf/2409.19751)\n* [HTML (experimental)](https://arxiv.org/html/2409.19751v1)\n* [TeX Source](https://arxiv.org/src/2409.19751)\n[![license icon](https://arxiv.org/icons/licenses/by-sa-4.0.png)view license](http://creativecommons.org/licenses/by-sa/4.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2409.19751&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2409.19751&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2024-09](https://arxiv.org/list/cs.LG/2024-09)\nChange to browse by:\n[cs](https://arxiv.org/abs/2409.19751?context=cs)\n[cs.AI](https://arxiv.org/abs/2409.19751?context=cs.AI)\n[stat](https://arxiv.org/abs/2409.19751?context=stat)\n[stat.ML](https://arxiv.org/abs/2409.19751?context=stat.ML)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2409.19751)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2409.19751)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2409.19751)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2409.19751&amp;description=Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2409.19751&amp;title=Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to th...",
      "url": "https://arxiv.org/abs/2409.19751"
    }
  ]
}