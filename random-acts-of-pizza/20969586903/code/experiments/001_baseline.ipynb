{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9180662",
   "metadata": {},
   "source": [
    "# Baseline Experiment: LightGBM with Simple Features\n",
    "\n",
    "This notebook creates a baseline model using LightGBM with simple features extracted from both text and tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df3028d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:14:05.856495Z",
     "iopub.status.busy": "2026-01-13T21:14:05.855539Z",
     "iopub.status.idle": "2026-01-13T21:14:07.032476Z",
     "shell.execute_reply": "2026-01-13T21:14:07.031869Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249a89e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:14:07.035071Z",
     "iopub.status.busy": "2026-01-13T21:14:07.034377Z",
     "iopub.status.idle": "2026-01-13T21:14:07.151398Z",
     "shell.execute_reply": "2026-01-13T21:14:07.150788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train shape: (2878, 32)\n",
      "Test shape: (1162, 17)\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    0.751564\n",
      "True     0.248436\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Target distribution:\")\n",
    "print(train_df['requester_received_pizza'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b15348",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96185258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:14:07.153597Z",
     "iopub.status.busy": "2026-01-13T21:14:07.153348Z",
     "iopub.status.idle": "2026-01-13T21:14:07.164224Z",
     "shell.execute_reply": "2026-01-13T21:14:07.163611Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_text_features(text):\n",
    "    \"\"\"Extract simple features from text\"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return {\n",
    "            'text_length': 0,\n",
    "            'word_count': 0,\n",
    "            'sentence_count': 0,\n",
    "            'exclamation_count': 0,\n",
    "            'question_count': 0,\n",
    "            'caps_ratio': 0,\n",
    "            'has_please': 0,\n",
    "            'has_thank': 0,\n",
    "            'has_sorry': 0,\n",
    "            'has_because': 0,\n",
    "            'has_family': 0,\n",
    "            'has_kids': 0,\n",
    "            'has_work': 0,\n",
    "            'has_money': 0,\n",
    "            'has_pay': 0,\n",
    "            'has_hungry': 0,\n",
    "            'has_food': 0,\n",
    "            'has_help': 0,\n",
    "            'has_emergency': 0\n",
    "        }\n",
    "    \n",
    "    # Basic text stats\n",
    "    text_length = len(text)\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    sentence_count = len([s for s in sentences if s.strip()])\n",
    "    \n",
    "    # Punctuation\n",
    "    exclamation_count = text.count('!')\n",
    "    question_count = text.count('?')\n",
    "    caps_ratio = sum(1 for c in text if c.isupper()) / len(text) if len(text) > 0 else 0\n",
    "    \n",
    "    # Keywords (lowercase for matching)\n",
    "    text_lower = text.lower()\n",
    "    has_please = int('please' in text_lower)\n",
    "    has_thank = int(any(word in text_lower for word in ['thank', 'thanks', 'thx']))\n",
    "    has_sorry = int('sorry' in text_lower)\n",
    "    has_because = int('because' in text_lower)\n",
    "    has_family = int(any(word in text_lower for word in ['family', 'fam', 'parent', 'mother', 'father']))\n",
    "    has_kids = int(any(word in text_lower for word in ['kid', 'kids', 'child', 'children', 'baby', 'babies']))\n",
    "    has_work = int(any(word in text_lower for word in ['work', 'job', 'employ', 'money']))\n",
    "    has_money = int(any(word in text_lower for word in ['money', 'cash', 'dollar', 'bucks']))\n",
    "    has_pay = int(any(word in text_lower for word in ['pay', 'payment', 'bills', 'rent']))\n",
    "    has_hungry = int(any(word in text_lower for word in ['hungry', 'starving', 'hunger']))\n",
    "    has_food = int(any(word in text_lower for word in ['food', 'pizza', 'eat', 'meal']))\n",
    "    has_help = int('help' in text_lower)\n",
    "    has_emergency = int(any(word in text_lower for word in ['emergency', 'urgent', 'desperate', 'crisis']))\n",
    "    \n",
    "    return {\n",
    "        'text_length': text_length,\n",
    "        'word_count': word_count,\n",
    "        'sentence_count': sentence_count,\n",
    "        'exclamation_count': exclamation_count,\n",
    "        'question_count': question_count,\n",
    "        'caps_ratio': caps_ratio,\n",
    "        'has_please': has_please,\n",
    "        'has_thank': has_thank,\n",
    "        'has_sorry': has_sorry,\n",
    "        'has_because': has_because,\n",
    "        'has_family': has_family,\n",
    "        'has_kids': has_kids,\n",
    "        'has_work': has_work,\n",
    "        'has_money': has_money,\n",
    "        'has_pay': has_pay,\n",
    "        'has_hungry': has_hungry,\n",
    "        'has_food': has_food,\n",
    "        'has_help': has_help,\n",
    "        'has_emergency': has_emergency\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1439182e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:14:07.166650Z",
     "iopub.status.busy": "2026-01-13T21:14:07.166030Z",
     "iopub.status.idle": "2026-01-13T21:14:07.383862Z",
     "shell.execute_reply": "2026-01-13T21:14:07.383104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text features from request_text_edit_aware...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text edit features shape: (2878, 19)\n"
     ]
    }
   ],
   "source": [
    "# Extract text features from request_text_edit_aware only (test data doesn't have request_text)\n",
    "print(\"Extracting text features from request_text_edit_aware...\")\n",
    "text_edit_features_train = pd.DataFrame([extract_text_features(text) for text in train_df['request_text_edit_aware']])\n",
    "text_edit_features_test = pd.DataFrame([extract_text_features(text) for text in test_df['request_text_edit_aware']])\n",
    "\n",
    "# Rename columns\n",
    "text_edit_features_train.columns = [f\"text_edit_{col}\" for col in text_edit_features_train.columns]\n",
    "text_edit_features_test.columns = [f\"text_edit_{col}\" for col in text_edit_features_test.columns]\n",
    "\n",
    "print(f\"Text edit features shape: {text_edit_features_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ff3091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:14:07.386275Z",
     "iopub.status.busy": "2026-01-13T21:14:07.385664Z",
     "iopub.status.idle": "2026-01-13T21:14:07.468091Z",
     "shell.execute_reply": "2026-01-13T21:14:07.467396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common tabular features: 15\n",
      "Categorical columns to encode: ['giver_username_if_known', 'request_title', 'requester_subreddits_at_request', 'requester_username']\n",
      "Final training features shape: (2878, 34)\n",
      "Final test features shape: (1162, 34)\n",
      "Feature types: int64      29\n",
      "float64     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract tabular features (excluding text fields, target, and ID)\n",
    "train_features = [col for col in train_df.columns if col not in ['request_text', 'request_text_edit_aware', 'requester_received_pizza', 'request_id']]\n",
    "test_features = [col for col in test_df.columns if col not in ['request_text_edit_aware', 'request_id']]\n",
    "\n",
    "# Only use features that exist in both train and test\n",
    "common_features = [col for col in train_features if col in test_features]\n",
    "print(f\"Common tabular features: {len(common_features)}\")\n",
    "\n",
    "# Prepare feature matrices\n",
    "X_train = pd.concat([\n",
    "    train_df[common_features].reset_index(drop=True),\n",
    "    text_edit_features_train.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "X_test = pd.concat([\n",
    "    test_df[common_features].reset_index(drop=True),\n",
    "    text_edit_features_test.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "y_train = train_df['requester_received_pizza'].astype(int)\n",
    "\n",
    "# Handle categorical features\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical columns to encode: {categorical_cols}\")\n",
    "\n",
    "# Simple label encoding for categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on combined data to handle unseen categories\n",
    "    combined = pd.concat([X_train[col], X_test[col]], axis=0).astype(str)\n",
    "    le.fit(combined)\n",
    "    X_train[col] = le.transform(X_train[col].astype(str))\n",
    "    X_test[col] = le.transform(X_test[col].astype(str))\n",
    "\n",
    "print(f\"Final training features shape: {X_train.shape}\")\n",
    "print(f\"Final test features shape: {X_test.shape}\")\n",
    "print(f\"Feature types: {X_train.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c36375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:14:07.469973Z",
     "iopub.status.busy": "2026-01-13T21:14:07.469769Z",
     "iopub.status.idle": "2026-01-13T21:14:08.868002Z",
     "shell.execute_reply": "2026-01-13T21:14:08.867102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM model with 5-fold CV...\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid's auc: 0.791752\n",
      "Fold 1 validation log loss: 0.4565\n",
      "Fold 2/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tvalid's auc: 0.788288\n",
      "Fold 2 validation log loss: 0.4107\n",
      "Fold 3/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid's auc: 0.814596\n",
      "Fold 3 validation log loss: 0.4163\n",
      "Fold 4/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tvalid's auc: 0.746746\n",
      "Fold 4 validation log loss: 0.4714\n",
      "Fold 5/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.783338\n",
      "Fold 5 validation log loss: 0.4857\n",
      "\n",
      "Overall CV log loss: 0.4481\n",
      "Mean CV log loss: 0.4481 ± 0.0298\n"
     ]
    }
   ],
   "source": [
    "# Define cross-validation strategy\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# Store predictions\n",
    "train_predictions = np.zeros(len(X_train))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "print(f\"Training LightGBM model with {n_folds}-fold CV...\")\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(f\"Fold {fold + 1}/{n_folds}\")\n",
    "    \n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    valid_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Define parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': RANDOM_SEED\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_data],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(50),\n",
    "            lgb.log_evaluation(100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    train_predictions[valid_idx] = val_pred\n",
    "    \n",
    "    # Calculate validation score (log loss since metric direction is false)\n",
    "    val_score = log_loss(y_val, val_pred)\n",
    "    cv_scores.append(val_score)\n",
    "    print(f\"Fold {fold + 1} validation log loss: {val_score:.4f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    test_predictions += test_pred / n_folds\n",
    "\n",
    "# Calculate overall CV score\n",
    "overall_cv_score = log_loss(y_train, train_predictions)\n",
    "print(f\"\\nOverall CV log loss: {overall_cv_score:.4f}\")\n",
    "print(f\"Mean CV log loss: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477488e",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50307eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:14:51.638198Z",
     "iopub.status.busy": "2026-01-13T21:14:51.637436Z",
     "iopub.status.idle": "2026-01-13T21:14:51.696943Z",
     "shell.execute_reply": "2026-01-13T21:14:51.696342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission preview:\n",
      "  request_id  requester_received_pizza\n",
      "0  t3_1aw5zf                  0.216166\n",
      "1   t3_roiuw                  0.175791\n",
      "2   t3_mjnbq                  0.215276\n",
      "3   t3_t8wd1                  0.153092\n",
      "4  t3_1m4zxu                  0.174804\n",
      "\n",
      "Submission shape: (1162, 2)\n",
      "Prediction distribution:\n",
      "count    1162.000000\n",
      "mean        0.244243\n",
      "std         0.141949\n",
      "min         0.116029\n",
      "25%         0.157514\n",
      "50%         0.193724\n",
      "75%         0.269959\n",
      "max         0.715983\n",
      "Name: requester_received_pizza, dtype: float64\n",
      "\n",
      "Submission saved to: /home/submission/submission.csv\n",
      "\n",
      "Sample submission columns: ['request_id', 'requester_received_pizza']\n",
      "Our submission columns: ['request_id', 'requester_received_pizza']\n",
      "Columns match: True\n"
     ]
    }
   ],
   "source": [
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "# Ensure the predictions are in the correct format (0-1 range)\n",
    "submission['requester_received_pizza'] = submission['requester_received_pizza'].clip(0, 1)\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"Prediction distribution:\")\n",
    "print(submission['requester_received_pizza'].describe())\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")\n",
    "\n",
    "# Verify submission format matches sample\n",
    "sample_submission = pd.read_csv('/home/data/sampleSubmission.csv')\n",
    "print(f\"\\nSample submission columns: {sample_submission.columns.tolist()}\")\n",
    "print(f\"Our submission columns: {submission.columns.tolist()}\")\n",
    "print(f\"Columns match: {list(submission.columns) == list(sample_submission.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5826bc70",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d29289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average feature importance across all folds\n",
    "# For simplicity, we'll use the last fold's importance as a proxy\n",
    "final_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns.tolist(),\n",
    "    'importance': model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 most important features:\")\n",
    "print(final_importance.head(20))\n",
    "\n",
    "# Save feature importance\n",
    "final_importance.to_csv('/home/code/experiments/001_feature_importance.csv', index=False)\n",
    "print(\"\\nFeature importance saved to: /home/code/experiments/001_feature_importance.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
