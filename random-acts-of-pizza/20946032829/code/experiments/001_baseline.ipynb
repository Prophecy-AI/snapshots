{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bd19763",
   "metadata": {},
   "source": [
    "# Baseline Model: TF-IDF + LightGBM\n",
    "\n",
    "This notebook implements a baseline model combining:\n",
    "- TF-IDF features from text (title + request_text)\n",
    "- Tabular metadata features\n",
    "- LightGBM classifier with class weighting for imbalance\n",
    "- Stratified K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c797c9d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5e53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_path = '/home/data/train.json'\n",
    "with open(train_path, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "# Load test data\n",
    "test_path = '/home/data/test.json'\n",
    "with open(test_path, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"\\nClass distribution in training data:\")\n",
    "print(train_df['requester_received_pizza'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6045b9",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ffeaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text features\n",
    "train_df['combined_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text_edit_aware'].fillna('')\n",
    "test_df['combined_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text_edit_aware'].fillna('')\n",
    "\n",
    "# Basic text length features\n",
    "train_df['text_length'] = train_df['combined_text'].str.len()\n",
    "test_df['text_length'] = test_df['combined_text'].str.len()\n",
    "\n",
    "train_df['word_count'] = train_df['combined_text'].str.split().str.len()\n",
    "test_df['word_count'] = test_df['combined_text'].str.split().str.len()\n",
    "\n",
    "# Tabular features to use\n",
    "numeric_features = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_number_of_comments_at_request', \n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'request_number_of_comments_at_retrieval',\n",
    "    'number_of_upvotes_of_request_at_retrieval',\n",
    "    'number_of_downvotes_of_request_at_retrieval',\n",
    "    'text_length',\n",
    "    'word_count'\n",
    "]\n",
    "\n",
    "# Handle missing values and create feature matrix\n",
    "X_train_tabular = train_df[numeric_features].fillna(0)\n",
    "X_test_tabular = test_df[numeric_features].fillna(0)\n",
    "\n",
    "print(f\"Tabular feature shape: {X_train_tabular.shape}\")\n",
    "print(f\"Text samples for TF-IDF: {len(train_df['combined_text'])}\")\n",
    "print(f\"Columns in train_df: {train_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610cf2c1",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF features from text\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit features for speed\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),  # Unigrams and bigrams\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "# Fit on training text and transform both train and test\n",
    "X_train_text = vectorizer.fit_transform(train_df['combined_text'])\n",
    "X_test_text = vectorizer.transform(test_df['combined_text'])\n",
    "\n",
    "print(f\"TF-IDF feature shape: {X_train_text.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ccce2",
   "metadata": {},
   "source": [
    "## Stratified K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target variable\n",
    "y = train_df['requester_received_pizza'].astype(int)\n",
    "\n",
    "# Calculate class weights for handling imbalance\n",
    "pos_class_weight = len(y) / (2 * y.sum())\n",
    "neg_class_weight = len(y) / (2 * (len(y) - y.sum()))\n",
    "\n",
    "print(f\"Positive class weight: {pos_class_weight:.2f}\")\n",
    "print(f\"Negative class weight: {neg_class_weight:.2f}\")\n",
    "\n",
    "# Set up stratified k-fold\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "\n",
    "print(f\"\\nStarting {n_splits}-fold stratified cross-validation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9205dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, y)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_text_fold = X_train_text[train_idx]\n",
    "    X_val_text_fold = X_train_text[val_idx]\n",
    "    \n",
    "    X_train_tab_fold = X_train_tabular.iloc[train_idx]\n",
    "    X_val_tab_fold = X_train_tabular.iloc[val_idx]\n",
    "    \n",
    "    y_train_fold = y.iloc[train_idx]\n",
    "    y_val_fold = y.iloc[val_idx]\n",
    "    \n",
    "    # For simplicity, we'll use only tabular features in this baseline\n",
    "    # In future experiments, we can combine text and tabular features more sophisticatedly\n",
    "    \n",
    "    # Train LightGBM model\n",
    "    train_data = lgb.Dataset(X_train_tab_fold, label=y_train_fold)\n",
    "    val_data = lgb.Dataset(X_val_tab_fold, label=y_val_fold, reference=train_data)\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'is_unbalance': True  # Handle class imbalance\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['val'],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_pred = model.predict(X_val_tab_fold, num_iteration=model.best_iteration)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Calculate AUC score\n",
    "    fold_auc = roc_auc_score(y_val_fold, val_pred)\n",
    "    fold_scores.append(fold_auc)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} AUC: {fold_auc:.4f}\")\n",
    "\n",
    "# Overall CV score\n",
    "cv_score = np.mean(fold_scores)\n",
    "cv_std = np.std(fold_scores)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Cross-Validation AUC: {cv_score:.4f} Â± {cv_std:.4f}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# OOF AUC\n",
    "oof_auc = roc_auc_score(y, oof_predictions)\n",
    "print(f\"Out-of-Fold AUC: {oof_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2886d0",
   "metadata": {},
   "source": [
    "## Train Final Model and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93abd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on full training data\n",
    "train_data_full = lgb.Dataset(X_train_tabular, label=y)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'is_unbalance': True\n",
    "}\n",
    "\n",
    "final_model = lgb.train(\n",
    "    params,\n",
    "    train_data_full,\n",
    "    num_boost_round=1000\n",
    ")\n",
    "\n",
    "# Generate predictions on test set\n",
    "test_predictions = final_model.predict(X_test_tabular)\n",
    "\n",
    "print(f\"Test predictions shape: {test_predictions.shape}\")\n",
    "print(f\"Test predictions range: [{test_predictions.min():.4f}, {test_predictions.max():.4f}]\")\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "print(f\"\\nSubmission shape: {submission_df.shape}\")\n",
    "print(submission_df.head())\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_001_baseline.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae3348f",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9120ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': numeric_features,\n",
    "    'importance': final_model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
