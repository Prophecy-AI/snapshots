{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa104cd",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza - Baseline Model\n",
    "\n",
    "This notebook creates a baseline model for predicting pizza request success.\n",
    "\n",
    "## Approach\n",
    "1. Load and explore the data\n",
    "2. Extract numerical features\n",
    "3. Extract text features from title and text using TF-IDF\n",
    "4. Train a LightGBM model with cross-validation\n",
    "5. Generate predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0c34e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T06:07:58.126759Z",
     "iopub.status.busy": "2026-01-13T06:07:58.126213Z",
     "iopub.status.idle": "2026-01-13T06:07:59.787271Z",
     "shell.execute_reply": "2026-01-13T06:07:59.786511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n",
      "Train samples: 2878\n",
      "Test samples: 1162\n",
      "\n",
      "Train columns: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n",
      "\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    2163\n",
      "True      715\n",
      "Name: count, dtype: int64\n",
      "Success rate: 0.248\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "print(\"Loading training data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"Train samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(\"\\nTrain columns:\", train_df.columns.tolist())\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train_df['requester_received_pizza'].value_counts())\n",
    "print(f\"Success rate: {train_df['requester_received_pizza'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f900919",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Extract numerical features and text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf79329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical features to use\n",
    "numerical_features = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request',\n",
    "    'number_of_upvotes_of_request_at_retrieval',\n",
    "    'number_of_downvotes_of_request_at_retrieval',\n",
    "    'request_number_of_comments_at_retrieval'\n",
    "]\n",
    "\n",
    "# Check which features exist\n",
    "available_num_features = [f for f in numerical_features if f in train_df.columns]\n",
    "print(f\"Using {len(available_num_features)} numerical features:\")\n",
    "for f in available_num_features:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Extract numerical features\n",
    "X_num_train = train_df[available_num_features].fillna(0)\n",
    "X_num_test = test_df[available_num_features].fillna(0)\n",
    "\n",
    "print(f\"\\nNumerical features shape: {X_num_train.shape}\")\n",
    "\n",
    "# Extract text features\n",
    "print(\"\\nExtracting text features...\")\n",
    "text_features = ['request_title', 'request_text_edit_aware']\n",
    "\n",
    "# Combine title and text for TF-IDF\n",
    "train_text = train_df[text_features[0]].fillna('') + ' ' + train_df[text_features[1]].fillna('')\n",
    "test_text = test_df[text_features[0]].fillna('') + ' ' + test_df[text_features[1]].fillna('')\n",
    "\n",
    "# TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "print(\"Fitting TF-IDF on training text...\")\n",
    "X_text_train = vectorizer.fit_transform(train_text)\n",
    "X_text_test = vectorizer.transform(test_text)\n",
    "\n",
    "print(f\"Text features shape: {X_text_train.shape}\")\n",
    "\n",
    "# Combine features\n",
    "from scipy.sparse import hstack\n",
    "X_train = hstack([X_text_train, X_num_train.values])\n",
    "X_test = hstack([X_text_test, X_num_test.values])\n",
    "\n",
    "y_train = train_df['requester_received_pizza'].values\n",
    "\n",
    "print(f\"\\nFinal training shape: {X_train.shape}\")\n",
    "print(f\"Final test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1704b",
   "metadata": {},
   "source": [
    "## Model Training with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d0fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Model parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "cv_scores = []\n",
    "predictions = np.zeros(len(test_df))\n",
    "\n",
    "print(\"Training with 5-fold CV...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "    \n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    valid_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predict on validation\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    score = roc_auc_score(y_val, val_pred)\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} AUC: {score:.4f}\")\n",
    "    \n",
    "    # Predict on test\n",
    "    predictions += model.predict(X_test, num_iteration=model.best_iteration) / 5\n",
    "\n",
    "print(f\"\\nCV Scores: {cv_scores}\")\n",
    "print(f\"Mean AUC: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d4a9b",
   "metadata": {},
   "source": [
    "## Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87238172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': predictions\n",
    "})\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"\\nSubmission saved to /home/submission/submission.csv\")\n",
    "print(f\"Shape: {submission.shape}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
