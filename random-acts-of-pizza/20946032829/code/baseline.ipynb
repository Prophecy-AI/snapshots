{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "283462dc",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza - Baseline Model\n",
    "\n",
    "This notebook creates a baseline model for predicting pizza request success.\n",
    "\n",
    "## Approach\n",
    "1. Load and explore the data\n",
    "2. Extract numerical features (only those available at request time)\n",
    "3. Extract text features from title and text using TF-IDF\n",
    "4. Train a LightGBM model with cross-validation\n",
    "5. Generate predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e66af53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T06:17:47.406033Z",
     "iopub.status.busy": "2026-01-13T06:17:47.405309Z",
     "iopub.status.idle": "2026-01-13T06:17:48.671906Z",
     "shell.execute_reply": "2026-01-13T06:17:48.671103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n",
      "Train samples: 2878\n",
      "Test samples: 1162\n",
      "\n",
      "Train columns: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n",
      "\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    2163\n",
      "True      715\n",
      "Name: count, dtype: int64\n",
      "Success rate: 0.248\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "print(\"Loading training data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"Train samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(\"\\nTrain columns:\", train_df.columns.tolist())\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train_df['requester_received_pizza'].value_counts())\n",
    "print(f\"Success rate: {train_df['requester_received_pizza'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bccc2c",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Extract numerical features and text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff7ecafe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T06:20:40.928373Z",
     "iopub.status.busy": "2026-01-13T06:20:40.927779Z",
     "iopub.status.idle": "2026-01-13T06:20:41.528125Z",
     "shell.execute_reply": "2026-01-13T06:20:41.527528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 9 numerical features:\n",
      "  - requester_account_age_in_days_at_request\n",
      "  - requester_number_of_comments_at_request\n",
      "  - requester_number_of_posts_at_request\n",
      "  - requester_upvotes_minus_downvotes_at_request\n",
      "  - requester_upvotes_plus_downvotes_at_request\n",
      "  - requester_number_of_subreddits_at_request\n",
      "  - requester_number_of_comments_in_raop_at_request\n",
      "  - requester_number_of_posts_on_raop_at_request\n",
      "  - requester_days_since_first_post_on_raop_at_request\n",
      "\n",
      "Numerical features shape: (2878, 9)\n",
      "\n",
      "Extracting text features...\n",
      "Fitting TF-IDF on training text...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text features shape: (2878, 5000)\n",
      "\n",
      "Final training shape: (2878, 5009)\n",
      "Final test shape: (1162, 5009)\n"
     ]
    }
   ],
   "source": [
    "# Define numerical features to use - only features available at request time\n",
    "numerical_features = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request'\n",
    "]\n",
    "\n",
    "# Check which features exist in both train and test\n",
    "available_num_features = [f for f in numerical_features if f in train_df.columns and f in test_df.columns]\n",
    "print(f\"Using {len(available_num_features)} numerical features:\")\n",
    "for f in available_num_features:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Extract numerical features\n",
    "X_num_train = train_df[available_num_features].fillna(0)\n",
    "X_num_test = test_df[available_num_features].fillna(0)\n",
    "\n",
    "print(f\"\\nNumerical features shape: {X_num_train.shape}\")\n",
    "\n",
    "# Extract text features\n",
    "print(\"\\nExtracting text features...\")\n",
    "text_features = ['request_title', 'request_text_edit_aware']\n",
    "\n",
    "# Combine title and text for TF-IDF\n",
    "train_text = train_df[text_features[0]].fillna('') + ' ' + train_df[text_features[1]].fillna('')\n",
    "test_text = test_df[text_features[0]].fillna('') + ' ' + test_df[text_features[1]].fillna('')\n",
    "\n",
    "# TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "print(\"Fitting TF-IDF on training text...\")\n",
    "X_text_train = vectorizer.fit_transform(train_text)\n",
    "X_text_test = vectorizer.transform(test_text)\n",
    "\n",
    "print(f\"Text features shape: {X_text_train.shape}\")\n",
    "\n",
    "# Combine features and convert to CSR for indexing support\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "X_train = hstack([X_text_train, X_num_train.values])\n",
    "X_test = hstack([X_text_test, X_num_test.values])\n",
    "\n",
    "# Convert to CSR format to support indexing\n",
    "X_train = csr_matrix(X_train)\n",
    "X_test = csr_matrix(X_test)\n",
    "\n",
    "y_train = train_df['requester_received_pizza'].values\n",
    "\n",
    "print(f\"\\nFinal training shape: {X_train.shape}\")\n",
    "print(f\"Final test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422fc7f8",
   "metadata": {},
   "source": [
    "## Model Training with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f698133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T06:21:22.858650Z",
     "iopub.status.busy": "2026-01-13T06:21:22.858091Z",
     "iopub.status.idle": "2026-01-13T06:21:25.127183Z",
     "shell.execute_reply": "2026-01-13T06:21:25.126232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 5-fold CV...\n",
      "\n",
      "Fold 1/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.638189\n",
      "Fold 1 AUC: 0.6382\n",
      "\n",
      "Fold 2/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.625139\n",
      "Fold 2 AUC: 0.6251\n",
      "\n",
      "Fold 3/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.683797\n",
      "Fold 3 AUC: 0.6838\n",
      "\n",
      "Fold 4/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.597805\n",
      "Fold 4 AUC: 0.5978\n",
      "\n",
      "Fold 5/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.680701\n",
      "Fold 5 AUC: 0.6807\n",
      "\n",
      "CV Scores: [0.6381886012371001, 0.6251392948852533, 0.6837965729420694, 0.5978049728049728, 0.6807012432012433]\n",
      "Mean AUC: 0.6451 ± 0.0330\n"
     ]
    }
   ],
   "source": [
    "# Setup cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Model parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "cv_scores = []\n",
    "predictions = np.zeros(len(test_df))\n",
    "\n",
    "print(\"Training with 5-fold CV...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "    \n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    valid_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predict on validation\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    score = roc_auc_score(y_val, val_pred)\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} AUC: {score:.4f}\")\n",
    "    \n",
    "    # Predict on test\n",
    "    predictions += model.predict(X_test, num_iteration=model.best_iteration) / 5\n",
    "\n",
    "print(f\"\\nCV Scores: {cv_scores}\")\n",
    "print(f\"Mean AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e4bb5",
   "metadata": {},
   "source": [
    "## Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dc6d0b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T06:22:04.968317Z",
     "iopub.status.busy": "2026-01-13T06:22:04.968013Z",
     "iopub.status.idle": "2026-01-13T06:22:04.982247Z",
     "shell.execute_reply": "2026-01-13T06:22:04.981643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission preview:\n",
      "  request_id  requester_received_pizza\n",
      "0  t3_1aw5zf                  0.229269\n",
      "1   t3_roiuw                  0.164773\n",
      "2   t3_mjnbq                  0.213965\n",
      "3   t3_t8wd1                  0.314275\n",
      "4  t3_1m4zxu                  0.150681\n",
      "\n",
      "Submission saved to /home/submission/submission.csv\n",
      "Shape: (1162, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': predictions\n",
    "})\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"\\nSubmission saved to /home/submission/submission.csv\")\n",
    "print(f\"Shape: {submission.shape}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
