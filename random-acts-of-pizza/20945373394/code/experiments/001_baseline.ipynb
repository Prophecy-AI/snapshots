{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65bb1017",
   "metadata": {},
   "source": [
    "# Baseline Model: LightGBM with Text and Metadata Features\n",
    "\n",
    "This notebook creates a baseline model for the Random Acts of Pizza competition using LightGBM with both text and metadata features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e34c09",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d25228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text features - combine title and text (use edit_aware version since test only has that)\n",
    "train_df['combined_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text_edit_aware'].fillna('')\n",
    "test_df['combined_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text_edit_aware'].fillna('')\n",
    "\n",
    "# Basic text statistics\n",
    "def extract_text_features(df):\n",
    "    df['text_length'] = df['combined_text'].str.len()\n",
    "    df['word_count'] = df['combined_text'].str.split().str.len()\n",
    "    df['exclamation_count'] = df['combined_text'].str.count('!')\n",
    "    df['question_count'] = df['combined_text'].str.count('\\?')\n",
    "    df['caps_count'] = df['combined_text'].str.count('[A-Z]')\n",
    "    df['caps_ratio'] = df['caps_count'] / (df['text_length'] + 1)\n",
    "    return df\n",
    "\n",
    "train_df = extract_text_features(train_df)\n",
    "test_df = extract_text_features(test_df)\n",
    "\n",
    "print(\"Text features extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7cf850",
   "metadata": {},
   "source": [
    "# Metadata features - select relevant numeric features (only those available at request time)\n",
    "numeric_features = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request'\n",
    "]\n",
    "\n",
    "# Handle missing values\n",
    "for col in numeric_features:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = pd.to_numeric(train_df[col], errors='coerce')\n",
    "        test_df[col] = pd.to_numeric(test_df[col], errors='coerce')\n",
    "        \n",
    "        # Fill missing values with median\n",
    "        median_val = train_df[col].median()\n",
    "        train_df[col] = train_df[col].fillna(median_val)\n",
    "        test_df[col] = test_df[col].fillna(median_val)\n",
    "    else:\n",
    "        print(f\"Warning: {col} not found in data\")\n",
    "        numeric_features.remove(col)\n",
    "\n",
    "print(f\"Numeric features processed: {len(numeric_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features (only those available in test set)\n",
    "categorical_features = []\n",
    "\n",
    "# Check which categorical features are available\n",
    "available_categorical = []\n",
    "for col in ['requester_user_flair', 'post_was_edited']:\n",
    "    if col in train_df.columns and col in test_df.columns:\n",
    "        available_categorical.append(col)\n",
    "\n",
    "if available_categorical:\n",
    "    for col in available_categorical:\n",
    "        train_df[col] = train_df[col].fillna('missing')\n",
    "        test_df[col] = test_df[col].fillna('missing')\n",
    "        \n",
    "        # Simple label encoding\n",
    "        combined = pd.concat([train_df[col], test_df[col]])\n",
    "        mapping = {val: idx for idx, val in enumerate(combined.unique())}\n",
    "        train_df[col + '_encoded'] = train_df[col].map(mapping)\n",
    "        test_df[col + '_encoded'] = test_df[col].map(mapping)\n",
    "    \n",
    "    categorical_features = [col + '_encoded' for col in available_categorical]\n",
    "\n",
    "print(f\"Categorical features encoded: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc256e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata features - select relevant numeric features\n",
    "numeric_features = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request',\n",
    "    'number_of_upvotes_of_request_at_retrieval',\n",
    "    'number_of_downvotes_of_request_at_retrieval',\n",
    "    'request_number_of_comments_at_retrieval'\n",
    "]\n",
    "\n",
    "# Handle missing values\n",
    "for col in numeric_features:\n",
    "    train_df[col] = pd.to_numeric(train_df[col], errors='coerce')\n",
    "    test_df[col] = pd.to_numeric(test_df[col], errors='coerce')\n",
    "    \n",
    "    # Fill missing values with median\n",
    "    median_val = train_df[col].median()\n",
    "    train_df[col] = train_df[col].fillna(median_val)\n",
    "    test_df[col] = test_df[col].fillna(median_val)\n",
    "\n",
    "print(\"Numeric features processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c6bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features\n",
    "feature_cols = numeric_features + categorical_features + \\\n",
    "               ['text_length', 'word_count', 'exclamation_count', 'question_count', 'caps_count', 'caps_ratio']\n",
    "\n",
    "X_train = pd.concat([train_df[feature_cols].reset_index(drop=True), tfidf_train_df], axis=1)\n",
    "X_test = pd.concat([test_df[feature_cols].reset_index(drop=True), tfidf_test_df], axis=1)\n",
    "\n",
    "y_train = train_df['requester_received_pizza'].astype(int)\n",
    "\n",
    "print(f\"Final training shape: {X_train.shape}\")\n",
    "print(f\"Final test shape: {X_test.shape}\")\n",
    "print(f\"Feature columns: {len(feature_cols)} + {tfidf_train_df.shape[1]} TF-IDF features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553193bd",
   "metadata": {},
   "source": [
    "## TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba114544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF features for text\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "# Fit on training text\n",
    "tfidf_train = vectorizer.fit_transform(train_df['combined_text'])\n",
    "tfidf_test = vectorizer.transform(test_df['combined_text'])\n",
    "\n",
    "print(f\"TF-IDF features shape: {tfidf_train.shape}\")\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "tfidf_train_df = pd.DataFrame(\n",
    "    tfidf_train.toarray(),\n",
    "    columns=[f'tfidf_{i}' for i in range(tfidf_train.shape[1])]\n",
    ")\n",
    "\n",
    "tfidf_test_df = pd.DataFrame(\n",
    "    tfidf_test.toarray(),\n",
    "    columns=[f'tfidf_{i}' for i in range(tfidf_test.shape[1])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910b48d",
   "metadata": {},
   "source": [
    "## Prepare Final Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features\n",
    "feature_cols = numeric_features + [col + '_encoded' for col in categorical_features if col in train_df.columns] + \\\n",
    "               ['text_length', 'word_count', 'exclamation_count', 'question_count', 'caps_count', 'caps_ratio']\n",
    "\n",
    "X_train = pd.concat([train_df[feature_cols].reset_index(drop=True), tfidf_train_df], axis=1)\n",
    "X_test = pd.concat([test_df[feature_cols].reset_index(drop=True), tfidf_test_df], axis=1)\n",
    "\n",
    "y_train = train_df['requester_received_pizza'].astype(int)\n",
    "\n",
    "print(f\"Final training shape: {X_train.shape}\")\n",
    "print(f\"Final test shape: {X_test.shape}\")\n",
    "print(f\"Feature columns: {len(feature_cols)} + {tfidf_train_df.shape[1]} TF-IDF features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50bc07c",
   "metadata": {},
   "source": [
    "## Model Training with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold CV\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "cv_scores = []\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "test_predictions = np.zeros(len(test_df))\n",
    "\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "    \n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "    \n",
    "    # LightGBM dataset\n",
    "    train_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    valid_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': SEED\n",
    "    }\n",
    "    \n",
    "    # Handle class imbalance\n",
    "    scale_pos_weight = (y_tr == 0).sum() / (y_tr == 1).sum()\n",
    "    params['scale_pos_weight'] = scale_pos_weight\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    \n",
    "    # Store results\n",
    "    oof_predictions[valid_idx] = val_pred\n",
    "    test_predictions += test_pred / 5\n",
    "    \n",
    "    # Calculate fold score\n",
    "    fold_score = roc_auc_score(y_val, val_pred)\n",
    "    cv_scores.append(fold_score)\n",
    "    print(f\"Fold {fold + 1} AUC: {fold_score:.4f}\")\n",
    "\n",
    "# Overall CV score\n",
    "overall_score = roc_auc_score(y_train, oof_predictions)\n",
    "print(f\"\\nOverall CV AUC: {overall_score:.4f}\")\n",
    "print(f\"Mean CV AUC: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c4f875",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8703b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 most important features:\")\n",
    "print(importance_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9175dc54",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6969dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "# Ensure proper format\n",
    "submission['requester_received_pizza'] = submission['requester_received_pizza'].astype(float)\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"Prediction distribution:\")\n",
    "print(submission['requester_received_pizza'].describe())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
