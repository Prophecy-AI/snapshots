{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d5fd21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T08:35:39.892427Z",
     "iopub.status.busy": "2026-01-10T08:35:39.891683Z",
     "iopub.status.idle": "2026-01-10T08:35:40.142407Z",
     "shell.execute_reply": "2026-01-10T08:35:40.141696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2878, 32)\n",
      "Columns: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>giver_username_if_known</th>\n",
       "      <th>number_of_downvotes_of_request_at_retrieval</th>\n",
       "      <th>number_of_upvotes_of_request_at_retrieval</th>\n",
       "      <th>post_was_edited</th>\n",
       "      <th>request_id</th>\n",
       "      <th>request_number_of_comments_at_retrieval</th>\n",
       "      <th>request_text</th>\n",
       "      <th>request_text_edit_aware</th>\n",
       "      <th>request_title</th>\n",
       "      <th>requester_account_age_in_days_at_request</th>\n",
       "      <th>...</th>\n",
       "      <th>requester_received_pizza</th>\n",
       "      <th>requester_subreddits_at_request</th>\n",
       "      <th>requester_upvotes_minus_downvotes_at_request</th>\n",
       "      <th>requester_upvotes_minus_downvotes_at_retrieval</th>\n",
       "      <th>requester_upvotes_plus_downvotes_at_request</th>\n",
       "      <th>requester_upvotes_plus_downvotes_at_retrieval</th>\n",
       "      <th>requester_user_flair</th>\n",
       "      <th>requester_username</th>\n",
       "      <th>unix_timestamp_of_request</th>\n",
       "      <th>unix_timestamp_of_request_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N/A</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_q8ycf</td>\n",
       "      <td>0</td>\n",
       "      <td>I will soon be going on a long deployment whic...</td>\n",
       "      <td>I will soon be going on a long deployment whic...</td>\n",
       "      <td>[REQUEST] Oceanside, Ca. USA-  US Marine getti...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Random_Acts_Of_Pizza]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>SDMarine</td>\n",
       "      <td>1.330391e+09</td>\n",
       "      <td>1.330391e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N/A</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_ixnia</td>\n",
       "      <td>20</td>\n",
       "      <td>We would all really appreciate it, and would e...</td>\n",
       "      <td>We would all really appreciate it, and would e...</td>\n",
       "      <td>[REQUEST] Three (verified) medical students in...</td>\n",
       "      <td>99.526863</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[AskReddit, IAmA, TwoXChromosomes, circlejerk,...</td>\n",
       "      <td>491</td>\n",
       "      <td>883</td>\n",
       "      <td>1459</td>\n",
       "      <td>2187</td>\n",
       "      <td>None</td>\n",
       "      <td>TheycallmeFoxJohnson</td>\n",
       "      <td>1.311434e+09</td>\n",
       "      <td>1.311430e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_ndy6g</td>\n",
       "      <td>0</td>\n",
       "      <td>It took a lot of courage to make this post, an...</td>\n",
       "      <td>It took a lot of courage to make this post, an...</td>\n",
       "      <td>(REQUEST) not home 4 the holidays &amp;amp; would ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Random_Acts_Of_Pizza]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>riverfrontmom</td>\n",
       "      <td>1.323968e+09</td>\n",
       "      <td>1.323968e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1363315140.0</td>\n",
       "      <td>t3_1abbu1</td>\n",
       "      <td>32</td>\n",
       "      <td>I will go ahead and say that I got a pizza mea...</td>\n",
       "      <td>I will go ahead and say that I got a pizza mea...</td>\n",
       "      <td>[REQUEST] Not much food until tomorrow.</td>\n",
       "      <td>491.088264</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Entroductions, RandomActsOfChristmas, RandomK...</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>165</td>\n",
       "      <td>195</td>\n",
       "      <td>shroom</td>\n",
       "      <td>Joeramos</td>\n",
       "      <td>1.363305e+09</td>\n",
       "      <td>1.363301e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N/A</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_kseg4</td>\n",
       "      <td>3</td>\n",
       "      <td>My '99 Jeep Cherokee I've had for 10 years now...</td>\n",
       "      <td>My '99 Jeep Cherokee I've had for 10 years now...</td>\n",
       "      <td>[Request] Had my car stolen today</td>\n",
       "      <td>369.417558</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[DetroitRedWings, DoesAnybodyElse, FoodPorn, K...</td>\n",
       "      <td>942</td>\n",
       "      <td>2043</td>\n",
       "      <td>1906</td>\n",
       "      <td>3483</td>\n",
       "      <td>None</td>\n",
       "      <td>m4ngo</td>\n",
       "      <td>1.317088e+09</td>\n",
       "      <td>1.317084e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  giver_username_if_known  number_of_downvotes_of_request_at_retrieval  \\\n",
       "0                     N/A                                            2   \n",
       "1                     N/A                                            2   \n",
       "2                     N/A                                            1   \n",
       "3                     N/A                                            1   \n",
       "4                     N/A                                            3   \n",
       "\n",
       "   number_of_upvotes_of_request_at_retrieval post_was_edited request_id  \\\n",
       "0                                          5           False   t3_q8ycf   \n",
       "1                                          4           False   t3_ixnia   \n",
       "2                                          2            True   t3_ndy6g   \n",
       "3                                          1    1363315140.0  t3_1abbu1   \n",
       "4                                         14           False   t3_kseg4   \n",
       "\n",
       "   request_number_of_comments_at_retrieval  \\\n",
       "0                                        0   \n",
       "1                                       20   \n",
       "2                                        0   \n",
       "3                                       32   \n",
       "4                                        3   \n",
       "\n",
       "                                        request_text  \\\n",
       "0  I will soon be going on a long deployment whic...   \n",
       "1  We would all really appreciate it, and would e...   \n",
       "2  It took a lot of courage to make this post, an...   \n",
       "3  I will go ahead and say that I got a pizza mea...   \n",
       "4  My '99 Jeep Cherokee I've had for 10 years now...   \n",
       "\n",
       "                             request_text_edit_aware  \\\n",
       "0  I will soon be going on a long deployment whic...   \n",
       "1  We would all really appreciate it, and would e...   \n",
       "2  It took a lot of courage to make this post, an...   \n",
       "3  I will go ahead and say that I got a pizza mea...   \n",
       "4  My '99 Jeep Cherokee I've had for 10 years now...   \n",
       "\n",
       "                                       request_title  \\\n",
       "0  [REQUEST] Oceanside, Ca. USA-  US Marine getti...   \n",
       "1  [REQUEST] Three (verified) medical students in...   \n",
       "2  (REQUEST) not home 4 the holidays &amp; would ...   \n",
       "3            [REQUEST] Not much food until tomorrow.   \n",
       "4                  [Request] Had my car stolen today   \n",
       "\n",
       "   requester_account_age_in_days_at_request  ...  requester_received_pizza  \\\n",
       "0                                  0.000000  ...                     False   \n",
       "1                                 99.526863  ...                     False   \n",
       "2                                  0.000000  ...                     False   \n",
       "3                                491.088264  ...                      True   \n",
       "4                                369.417558  ...                     False   \n",
       "\n",
       "                     requester_subreddits_at_request  \\\n",
       "0                             [Random_Acts_Of_Pizza]   \n",
       "1  [AskReddit, IAmA, TwoXChromosomes, circlejerk,...   \n",
       "2                             [Random_Acts_Of_Pizza]   \n",
       "3  [Entroductions, RandomActsOfChristmas, RandomK...   \n",
       "4  [DetroitRedWings, DoesAnybodyElse, FoodPorn, K...   \n",
       "\n",
       "   requester_upvotes_minus_downvotes_at_request  \\\n",
       "0                                             3   \n",
       "1                                           491   \n",
       "2                                             1   \n",
       "3                                            25   \n",
       "4                                           942   \n",
       "\n",
       "   requester_upvotes_minus_downvotes_at_retrieval  \\\n",
       "0                                               3   \n",
       "1                                             883   \n",
       "2                                               1   \n",
       "3                                              21   \n",
       "4                                            2043   \n",
       "\n",
       "   requester_upvotes_plus_downvotes_at_request  \\\n",
       "0                                            7   \n",
       "1                                         1459   \n",
       "2                                            3   \n",
       "3                                          165   \n",
       "4                                         1906   \n",
       "\n",
       "   requester_upvotes_plus_downvotes_at_retrieval  requester_user_flair  \\\n",
       "0                                              7                  None   \n",
       "1                                           2187                  None   \n",
       "2                                              3                  None   \n",
       "3                                            195                shroom   \n",
       "4                                           3483                  None   \n",
       "\n",
       "     requester_username  unix_timestamp_of_request  \\\n",
       "0              SDMarine               1.330391e+09   \n",
       "1  TheycallmeFoxJohnson               1.311434e+09   \n",
       "2         riverfrontmom               1.323968e+09   \n",
       "3              Joeramos               1.363305e+09   \n",
       "4                 m4ngo               1.317088e+09   \n",
       "\n",
       "   unix_timestamp_of_request_utc  \n",
       "0                   1.330391e+09  \n",
       "1                   1.311430e+09  \n",
       "2                   1.323968e+09  \n",
       "3                   1.363301e+09  \n",
       "4                   1.317084e+09  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Problem Type\n",
    "Binary classification combining text features (request title, text) with tabular metadata (Reddit activity metrics, user flair, timestamps).\n",
    "\n",
    "## Reference Notebooks for Data Characteristics\n",
    "- `exploration/eda.ipynb` - Contains full EDA: 2,878 training samples, 24.8% positive class (class imbalance), text length distributions, feature types (16 int, 9 object, 6 float, 1 bool), missing values in requester_user_flair (75% missing)\n",
    "\n",
    "## Data Understanding\n",
    "**Class Imbalance**: ~25% positive class requires special handling. See eda.ipynb for exact distribution.\n",
    "**Text Features**: request_text (avg 402 chars), request_title (avg 72 chars) - both need preprocessing\n",
    "**Categorical Features**: requester_user_flair with high cardinality (3 categories but 75% missing)\n",
    "**Temporal Features**: Unix timestamps available for feature engineering\n",
    "\n",
    "## Models\n",
    "For text + tabular classification problems, winning Kaggle solutions typically use:\n",
    "- **Gradient Boosting (Primary)**: XGBoost, LightGBM, or CatBoost trained on combined text embeddings + tabular features\n",
    "- **Neural Networks (Secondary)**: BERT/RoBERTa for text encoding combined with tabular features in downstream classifier\n",
    "- **Ensemble Size**: 3-5 diverse models (mix of tree-based and neural approaches)\n",
    "\n",
    "## Text Feature Engineering\n",
    "**Preprocessing** (Critical for Reddit/social media language):\n",
    "- Preserve informal cues: DON'T remove all punctuation (can indicate sentiment/sarcasm)\n",
    "- Normalize elongated words: \"soooo\" → \"so\"\n",
    "- Handle Reddit-specific artifacts: strip/normalize URLs, user mentions (/u/username), subreddit tags (/r/subreddit)\n",
    "- Clean markdown formatting while preserving emoji for sentiment\n",
    "- Apply lemmatization (preferred over stemming for social media)\n",
    "- Create custom stopword list including Reddit-specific terms\n",
    "- Combine request_title and request_text into single document\n",
    "\n",
    "**Feature Extraction**:\n",
    "- TF-IDF vectors (unigrams + bigrams) for gradient boosting models\n",
    "- Sentence embeddings (BERT, RoBERTa) for neural approaches\n",
    "- Text length features: char count, word count, avg word length\n",
    "- Sentiment analysis scores\n",
    "- Named entity recognition features\n",
    "- Punctuation density and patterns\n",
    "- Capitalization patterns (ALL CAPS words count)\n",
    "\n",
    "## Tabular Feature Engineering\n",
    "**Metadata Features**:\n",
    "- Log transforms for count features (upvotes, comments, posts) to reduce skewness\n",
    "- Ratios: upvotes/comments, comments/posts, karma metrics\n",
    "- Differences between request time and retrieval time metrics\n",
    "- User activity rates: comments per day, posts per day\n",
    "- Subreddit diversity metrics from requester_subreddits_at_request\n",
    "- Account age normalized by activity (comments per day of account age)\n",
    "\n",
    "**Categorical Encoding**:\n",
    "- **requester_user_flair**: Create explicit \"Missing\" category for 75% missing values, then apply target encoding\n",
    "- One-hot encoding for low-cardinality categorical features\n",
    "- Frequency encoding for high-cardinality features\n",
    "- Target encoding with careful cross-validation to avoid leakage\n",
    "\n",
    "**Temporal Features**:\n",
    "- Extract hour of day, day of week from timestamps\n",
    "- Cyclical encoding for time features (sin/cos transforms)\n",
    "- Time since account creation normalized by request time\n",
    "- Posting time relative to peak Reddit hours\n",
    "\n",
    "## Handling Class Imbalance\n",
    "**Critical for this dataset (24.8% positive class)**:\n",
    "- Use AUC-ROC as evaluation metric (provided in competition)\n",
    "- Apply scale_pos_weight in XGBoost/LightGBM (calculate as negative/positive ratio ≈ 3.0)\n",
    "- Consider class_weight='balanced' in scikit-learn models\n",
    "- Optional: Try SMOTE oversampling on minority class\n",
    "- Focus on PR-AUC during validation for imbalanced metrics\n",
    "- Use stratified sampling throughout to preserve class distribution\n",
    "\n",
    "## Validation Strategy\n",
    "- Stratified K-Fold (k=5) to preserve class distribution\n",
    "- Time-based splits if temporal leakage is a concern\n",
    "- Use early stopping on validation AUC-ROC\n",
    "- Monitor both AUC-ROC and PR-AUC for imbalanced performance\n",
    "- Create separate validation sets for text-based and tabular-based models\n",
    "\n",
    "## Ensembling\n",
    "**Stacking Approach**:\n",
    "- Level 1: Diverse models (XGBoost on TF-IDF, LightGBM on embeddings, CatBoost on combined)\n",
    "- Level 2: Logistic regression or simple averaging\n",
    "- Use out-of-fold predictions for meta-features\n",
    "- Include both text-heavy and metadata-heavy models for diversity\n",
    "\n",
    "**Blending**:\n",
    "- Weighted average based on validation performance\n",
    "- Rank averaging for robustness\n",
    "- Geometric mean for probability calibration\n",
    "\n",
    "## Optimization\n",
    "**Hyperparameter Tuning**:\n",
    "- Bayesian optimization (Optuna) for efficient search\n",
    "- Focus on: learning_rate, max_depth, min_child_samples, subsample\n",
    "- Use early stopping to prevent overfitting\n",
    "- Tune scale_pos_weight carefully for class imbalance\n",
    "\n",
    "**Feature Selection**:\n",
    "- SHAP values for feature importance interpretation\n",
    "- Recursive feature elimination based on validation score\n",
    "- Correlation analysis to remove redundant features\n",
    "- Focus on features that work well across multiple model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515dfa3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T08:36:02.876515Z",
     "iopub.status.busy": "2026-01-10T08:36:02.875822Z",
     "iopub.status.idle": "2026-01-10T08:36:02.888487Z",
     "shell.execute_reply": "2026-01-10T08:36:02.887809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    2163\n",
      "True      715\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Success rate: 0.248\n",
      "\n",
      "Missing values per column:\n",
      "requester_user_flair    2163\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "int64      16\n",
      "object      9\n",
      "float64     6\n",
      "bool        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore target distribution\n",
    "print(\"Target distribution:\")\n",
    "print(df_train['requester_received_pizza'].value_counts())\n",
    "print(f\"\\nSuccess rate: {df_train['requester_received_pizza'].mean():.3f}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values per column:\")\n",
    "missing = df_train.isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "\n",
    "# Check data types\n",
    "print(f\"\\nData types:\")\n",
    "print(df_train.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644ee377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T08:36:26.702066Z",
     "iopub.status.busy": "2026-01-10T08:36:26.701099Z",
     "iopub.status.idle": "2026-01-10T08:36:26.723488Z",
     "shell.execute_reply": "2026-01-10T08:36:26.722531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text feature examples:\n",
      "\n",
      "Request title examples:\n",
      "['[REQUEST] Oceanside, Ca. USA-  US Marine getting ready to deploy.', \"[REQUEST] Three (verified) medical students in Pittsburgh this summer doing research.  And we're almost out of loan money.\", '(REQUEST) not home 4 the holidays &amp; would really like some pizza for my family!!!']\n",
      "\n",
      "Request text length statistics:\n",
      "count    2878.000000\n",
      "mean      402.521543\n",
      "std       362.393727\n",
      "min         0.000000\n",
      "25%       182.000000\n",
      "50%       308.000000\n",
      "75%       503.750000\n",
      "max      4460.000000\n",
      "Name: request_text_length, dtype: float64\n",
      "\n",
      "Request title length statistics:\n",
      "count    2878.000000\n",
      "mean       71.572967\n",
      "std        36.233487\n",
      "min         7.000000\n",
      "25%        46.000000\n",
      "50%        64.000000\n",
      "75%        90.000000\n",
      "max       272.000000\n",
      "Name: request_title_length, dtype: float64\n",
      "\n",
      "Requester user flair distribution:\n",
      "requester_user_flair\n",
      "None      2163\n",
      "shroom     677\n",
      "PIF         38\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore text features\n",
    "print(\"Text feature examples:\")\n",
    "print(\"\\nRequest title examples:\")\n",
    "print(df_train['request_title'].head(3).tolist())\n",
    "\n",
    "print(\"\\nRequest text length statistics:\")\n",
    "df_train['request_text_length'] = df_train['request_text'].str.len()\n",
    "print(df_train['request_text_length'].describe())\n",
    "\n",
    "print(\"\\nRequest title length statistics:\")\n",
    "df_train['request_title_length'] = df_train['request_title'].str.len()\n",
    "print(df_train['request_title_length'].describe())\n",
    "\n",
    "# Explore categorical features\n",
    "print(\"\\nRequester user flair distribution:\")\n",
    "print(df_train['requester_user_flair'].value_counts(dropna=False))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
