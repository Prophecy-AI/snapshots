## Data Understanding
**Reference notebooks for data characteristics:**
- `exploration/eda.ipynb` - Contains full EDA: feature distributions, missing values, target balance (24.8% positive rate), text length statistics, correlations, and CRITICAL data leakage analysis
- **CRITICAL FINDING**: Test data only contains "at_request" features, NOT "at_retrieval" features
- **CRITICAL FINDING**: User flair is NOT available in test data (data leakage if used)
- Use findings from these notebooks when implementing features

## Problem Type
Binary text classification with meta-data features. Evaluation metric: AUC-ROC.

## CRITICAL: Data Leakage Warning

### Features to EXCLUDE (not available in test data)
- **User flair** (`requester_user_flair`) - NOT in test data
- **All "at_retrieval" features** - Test data only has "at_request" versions:
  - `requester_account_age_in_days_at_retrieval` → use `at_request` version
  - `requester_number_of_comments_at_retrieval` → use `at_request` version
  - `requester_number_of_comments_in_raop_at_retrieval` → use `at_request` version
  - `requester_number_of_posts_at_retrieval` → use `at_request` version
  - `requester_number_of_posts_on_raop_at_retrieval` → use `at_request` version
  - `requester_upvotes_minus_downvotes_at_retrieval` → use `at_request` version
  - `requester_upvotes_plus_downvotes_at_retrieval` → use `at_request` version
  - `requester_days_since_first_post_on_raop_at_retrieval` → use `at_request` version
  - `number_of_upvotes_of_request_at_retrieval` → exclude (request votes at retrieval)
  - `number_of_downvotes_of_request_at_retrieval` → exclude (request votes at retrieval)
  - `request_number_of_comments_at_retrieval` → exclude (request comments at retrieval)

### Features to USE (available in test data)
All features ending with `_at_request` plus:
- `request_text`, `request_title`, `request_text_edit_aware`
- `requester_subreddits_at_request`
- `requester_username` (for encoding)
- `unix_timestamp_of_request`, `unix_timestamp_of_request_utc`
- `post_was_edited`
- `giver_username_if_known` (likely always "N/A" at request time)

## Core Modeling Strategy

### Text Encoding Approaches
For text classification with meta-data, winning Kaggle solutions typically use:

1. **Transformer-based models** (BERT, RoBERTa, DeBERTa)
   - Fine-tune pretrained transformers on request text + title
   - Concatenate meta-data features before final classification layer
   - Use embedding tables for high-cardinality categorical features (e.g., subreddits)
   - Social media-pretrained models (BERT-base-Twitter) work well for Reddit text
   - **Important**: Only use features available at request time

2. **Traditional NLP features** (as baseline/ensemble)
   - TF-IDF vectors for request text and title
   - N-gram features (unigrams, bigrams)
   - POS tagging and sentiment features
   - Text length, word count, readability scores
   - **Text length is highly predictive** (see EDA: longer texts have higher success rates)

### Meta-Data Modeling
1. **Gradient Boosting on meta-features alone**
   - LightGBM/XGBoost on user activity features (posts, comments, votes)
   - Focus on RAOP-specific activity (strongest correlation with target)
   - Use `at_request` versions only
   - CatBoost for categorical features (subreddits, username)
   - Stack predictions with text model

2. **Feature engineering for meta-data**
   - RAOP-specific activity is highly predictive (posts/comments on RAOP)
   - Account age, karma scores, posting patterns (all at request time)
   - Time-based features from timestamps (hour, day of week)
   - Subreddit diversity and specific subreddit indicators

## Handling Class Imbalance (24.8% positive rate)

### Training Strategies
- Use `class_weight='balanced'` or `scale_pos_weight` in gradient boosting
- Stratified K-fold validation (k=5) to preserve class distribution
- Consider oversampling minority class or undersampling majority
- Monitor AUC-ROC, F1-score, Precision-Recall curves (not accuracy)
- **Text length correlates with success**: consider stratifying by text length

### Threshold Optimization
- Tune decision threshold after training to optimize F1 or business metric
- Calibrate probabilities if needed

## Ensembling Strategies

### Model Diversity
- Combine transformer model with gradient boosting on meta-features
- Use different text encoders (BERT, RoBERTa, DeBERTa)
- Vary preprocessing (with/without text cleaning, different tokenization)
- **Critical**: Ensure all models use only non-leaky features

### Stacking Approach
- Level-1: Multiple diverse models (3-5 models)
- Level-2: Linear model or weighted average on out-of-fold predictions
- Use stratified splits to avoid leakage
- Validate on holdout set that mimics test data feature availability

## Preprocessing

### Text Preprocessing
- Use edit-aware version of text (`request_text_edit_aware`) to remove success indicators
- Handle missing/empty text (min length is 0)
- Consider Reddit-specific preprocessing (username mentions, subreddit links)
- **Preserve text length**: don't over-trim as length is predictive

### Meta-Data Preprocessing
- Use only `_at_request` versions of features
- Normalize vote counts and karma scores
- Extract features from subreddit lists (count, diversity, specific subreddits)
- Create interaction features between user activity metrics
- Encode categorical features carefully (username, subreddits)

## Validation Strategy
- Stratified K-Fold (k=5) is standard
- **CRITICAL**: Validate using only features available in test data
- Remove all "at_retrieval" features before validation
- Early stopping on validation AUC-ROC
- Use out-of-fold predictions for ensembling
- Consider time-based splits if temporal patterns exist

## Key Features to Engineer (based on EDA)
- **RAOP activity features** (strongest correlation with target)
- **Text length features** (highly predictive, see EDA)
- Subreddit diversity and specific subreddit indicators
- Time-based features (hour of day, day of week)
- Interaction between user karma and activity
- Account age normalized by activity level
- **DO NOT USE**: User flair, any "at_retrieval" features

## Implementation Checklist
- [ ] Remove all "at_retrieval" features from training data
- [ ] Remove user flair from training data
- [ ] Verify feature availability matches test data
- [ ] Engineer text length features
- [ ] Focus on RAOP-specific activity features
- [ ] Use stratified validation preserving class distribution
- [ ] Monitor for data leakage throughout pipeline