{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f00ff14",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza - Baseline Model\n",
    "\n",
    "This notebook creates a baseline model for predicting pizza request success using both text and metadata features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efdc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b70c1",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281fffff",
   "metadata": {},
   "source": [
    "## Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text features - combine title and text\n",
    "train_df['combined_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text_edit_aware'].fillna('')\n",
    "test_df['combined_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text_edit_aware'].fillna('')\n",
    "\n",
    "# Basic metadata features\n",
    "def extract_metadata_features(df, is_train=True):\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Account age features\n",
    "    features['account_age_days'] = df['requester_account_age_in_days_at_request']\n",
    "    features['account_age_days'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Activity features\n",
    "    features['num_comments'] = df['requester_number_of_comments_at_request']\n",
    "    features['num_posts'] = df['requester_number_of_posts_at_request']\n",
    "    features['num_subreddits'] = df['requester_number_of_subreddits_at_request']\n",
    "    \n",
    "    # RAOP-specific activity\n",
    "    features['num_raop_comments'] = df['requester_number_of_comments_in_raop_at_request']\n",
    "    features['num_raop_posts'] = df['requester_number_of_posts_on_raop_at_request']\n",
    "    \n",
    "    # Vote features\n",
    "    features['upvotes_minus_downvotes'] = df['requester_upvotes_minus_downvotes_at_request']\n",
    "    features['upvotes_plus_downvotes'] = df['requester_upvotes_plus_downvotes_at_request']\n",
    "    \n",
    "    # Request features (only available in training data)\n",
    "    if is_train:\n",
    "        features['request_comments'] = df['request_number_of_comments_at_retrieval']\n",
    "        features['request_upvotes'] = df['number_of_upvotes_of_request_at_retrieval']\n",
    "        features['request_downvotes'] = df['number_of_downvotes_of_request_at_retrieval']\n",
    "    else:\n",
    "        # For test data, we'll use zeros or NaN for these features\n",
    "        features['request_comments'] = 0\n",
    "        features['request_upvotes'] = 0\n",
    "        features['request_downvotes'] = 0\n",
    "    \n",
    "    # Time features\n",
    "    features['unix_timestamp'] = df['unix_timestamp_of_request']\n",
    "    \n",
    "    # User flair (categorical)\n",
    "    features['user_flair'] = df['requester_user_flair'].fillna('None')\n",
    "    \n",
    "    # Post edited (only available in training data)\n",
    "    if is_train:\n",
    "        features['post_edited'] = df['post_was_edited'].astype(int)\n",
    "    else:\n",
    "        features['post_edited'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "train_meta = extract_metadata_features(train_df, is_train=True)\n",
    "test_meta = extract_metadata_features(test_df, is_train=False)\n",
    "\n",
    "print(\"Metadata features shape:\", train_meta.shape)\n",
    "print(\"Test metadata features shape:\", test_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d9e947",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafdb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text features - combine title and text\n",
    "train_df['combined_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text_edit_aware'].fillna('')\n",
    "test_df['combined_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text_edit_aware'].fillna('')\n",
    "\n",
    "# Basic metadata features\n",
    "def extract_metadata_features(df):\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Account age features\n",
    "    features['account_age_days'] = df['requester_account_age_in_days_at_request']\n",
    "    features['account_age_days'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Activity features\n",
    "    features['num_comments'] = df['requester_number_of_comments_at_request']\n",
    "    features['num_posts'] = df['requester_number_of_posts_at_request']\n",
    "    features['num_subreddits'] = df['requester_number_of_subreddits_at_request']\n",
    "    \n",
    "    # RAOP-specific activity\n",
    "    features['num_raop_comments'] = df['requester_number_of_comments_in_raop_at_request']\n",
    "    features['num_raop_posts'] = df['requester_number_of_posts_on_raop_at_request']\n",
    "    \n",
    "    # Vote features\n",
    "    features['upvotes_minus_downvotes'] = df['requester_upvotes_minus_downvotes_at_request']\n",
    "    features['upvotes_plus_downvotes'] = df['requester_upvotes_plus_downvotes_at_request']\n",
    "    \n",
    "    # Request features\n",
    "    features['request_comments'] = df['request_number_of_comments_at_retrieval']\n",
    "    features['request_upvotes'] = df['number_of_upvotes_of_request_at_retrieval']\n",
    "    features['request_downvotes'] = df['number_of_downvotes_of_request_at_retrieval']\n",
    "    \n",
    "    # Time features\n",
    "    features['unix_timestamp'] = df['unix_timestamp_of_request']\n",
    "    \n",
    "    # User flair (categorical)\n",
    "    features['user_flair'] = df['requester_user_flair'].fillna('None')\n",
    "    \n",
    "    # Post edited\n",
    "    features['post_edited'] = df['post_was_edited'].astype(int)\n",
    "    \n",
    "    return features\n",
    "\n",
    "train_meta = extract_metadata_features(train_df)\n",
    "test_meta = extract_metadata_features(test_df)\n",
    "\n",
    "print(\"Metadata features shape:\", train_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efaaf0",
   "metadata": {},
   "source": [
    "## Handle Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6beb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode user flair\n",
    "train_meta = pd.get_dummies(train_meta, columns=['user_flair'], prefix='flair')\n",
    "test_meta = pd.get_dummies(test_meta, columns=['user_flair'], prefix='flair')\n",
    "\n",
    "# Ensure same columns in both train and test\n",
    "missing_cols = set(train_meta.columns) - set(test_meta.columns)\n",
    "for col in missing_cols:\n",
    "    test_meta[col] = 0\n",
    "\n",
    "test_meta = test_meta[train_meta.columns]\n",
    "\n",
    "print(\"After one-hot encoding:\", train_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14512d87",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize text using TF-IDF\n",
    "print(\"Vectorizing text...\")\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit features for speed\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "# Fit on training text and transform both train and test\n",
    "train_text_features = tfidf.fit_transform(train_df['combined_text'])\n",
    "test_text_features = tfidf.transform(test_df['combined_text'])\n",
    "\n",
    "print(\"Text features shape:\", train_text_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c8286",
   "metadata": {},
   "source": [
    "## Scale Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c7c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale metadata features\n",
    "scaler = StandardScaler()\n",
    "train_meta_scaled = scaler.fit_transform(train_meta)\n",
    "test_meta_scaled = scaler.transform(test_meta)\n",
    "\n",
    "# Convert to sparse matrix for compatibility with text features\n",
    "train_meta_sparse = csr_matrix(train_meta_scaled)\n",
    "test_meta_sparse = csr_matrix(test_meta_scaled)\n",
    "\n",
    "print(\"Scaled metadata shape:\", train_meta_sparse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b5fb0d",
   "metadata": {},
   "source": [
    "## Combine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e468977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text and metadata features\n",
    "X_train = hstack([train_text_features, train_meta_sparse])\n",
    "X_test = hstack([test_text_features, test_meta_sparse])\n",
    "\n",
    "print(\"Final training features shape:\", X_train.shape)\n",
    "print(\"Final test features shape:\", X_test.shape)\n",
    "\n",
    "# Target variable\n",
    "y_train = train_df['requester_received_pizza'].astype(int).values\n",
    "print(\"Target shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b7e980",
   "metadata": {},
   "source": [
    "## Cross-Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd572691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Model - Logistic Regression as baseline\n",
    "model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "\n",
    "print(f\"Running {n_splits}-fold cross-validation...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b562adf",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e37a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Predict\n",
    "    val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calculate ROC AUC\n",
    "    auc_score = roc_auc_score(y_val, val_pred)\n",
    "    cv_scores.append(auc_score)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} ROC AUC: {auc_score:.4f}\")\n",
    "\n",
    "print(f\"\\nCV ROC AUC: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b672930",
   "metadata": {},
   "source": [
    "## Train on Full Data and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on full training data\n",
    "print(\"Training on full dataset...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "test_predictions = model.predict_proba(X_test)[:, 1]\n",
    "print(\"Test predictions shape:\", test_predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7730a65",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b7c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(\"Submission file created:\", submission_path)\n",
    "print(\"\\nSubmission preview:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Check submission format\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"Prediction range: [{test_predictions.min():.4f}, {test_predictions.max():.4f}]\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
