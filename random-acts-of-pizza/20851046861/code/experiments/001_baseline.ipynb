{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35edcc9",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza - Baseline Model\n",
    "\n",
    "This notebook creates a baseline model for predicting pizza request success using both text and metadata features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b04d0c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:25:56.179885Z",
     "iopub.status.busy": "2026-01-09T12:25:56.179646Z",
     "iopub.status.idle": "2026-01-09T12:25:56.939891Z",
     "shell.execute_reply": "2026-01-09T12:25:56.939439Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c195736",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e10ec70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:25:56.941097Z",
     "iopub.status.busy": "2026-01-09T12:25:56.940936Z",
     "iopub.status.idle": "2026-01-09T12:25:56.990100Z",
     "shell.execute_reply": "2026-01-09T12:25:56.989691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n",
      "Training samples: 2878\n",
      "Test samples: 1162\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527b2265",
   "metadata": {},
   "source": [
    "## Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1524ec3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:25:56.991146Z",
     "iopub.status.busy": "2026-01-09T12:25:56.990848Z",
     "iopub.status.idle": "2026-01-09T12:25:57.008038Z",
     "shell.execute_reply": "2026-01-09T12:25:57.007660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataFrame shape: (2878, 32)\n",
      "Test DataFrame shape: (1162, 17)\n",
      "\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    2163\n",
      "True      715\n",
      "Name: count, dtype: int64\n",
      "Success rate: 0.248\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrames for easier manipulation\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(\"Training DataFrame shape:\", train_df.shape)\n",
    "print(\"Test DataFrame shape:\", test_df.shape)\n",
    "\n",
    "# Check target distribution\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train_df['requester_received_pizza'].value_counts())\n",
    "print(f\"Success rate: {train_df['requester_received_pizza'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ebc0f",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2766727b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:25:57.009004Z",
     "iopub.status.busy": "2026-01-09T12:25:57.008782Z",
     "iopub.status.idle": "2026-01-09T12:25:57.022992Z",
     "shell.execute_reply": "2026-01-09T12:25:57.022640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata features shape: (2878, 14)\n",
      "Test metadata features shape: (1162, 14)\n"
     ]
    }
   ],
   "source": [
    "# Text features - combine title and text\n",
    "train_df['combined_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text_edit_aware'].fillna('')\n",
    "test_df['combined_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text_edit_aware'].fillna('')\n",
    "\n",
    "# Basic metadata features\n",
    "def extract_metadata_features(df, is_train=True):\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Account age features\n",
    "    features['account_age_days'] = df['requester_account_age_in_days_at_request']\n",
    "    features['account_age_days'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Activity features\n",
    "    features['num_comments'] = df['requester_number_of_comments_at_request']\n",
    "    features['num_posts'] = df['requester_number_of_posts_at_request']\n",
    "    features['num_subreddits'] = df['requester_number_of_subreddits_at_request']\n",
    "    \n",
    "    # RAOP-specific activity\n",
    "    features['num_raop_comments'] = df['requester_number_of_comments_in_raop_at_request']\n",
    "    features['num_raop_posts'] = df['requester_number_of_posts_on_raop_at_request']\n",
    "    \n",
    "    # Vote features\n",
    "    features['upvotes_minus_downvotes'] = df['requester_upvotes_minus_downvotes_at_request']\n",
    "    features['upvotes_plus_downvotes'] = df['requester_upvotes_plus_downvotes_at_request']\n",
    "    \n",
    "    # Request features (only available in training data)\n",
    "    if is_train:\n",
    "        # Check if these columns exist\n",
    "        if 'request_number_of_comments_at_retrieval' in df.columns:\n",
    "            features['request_comments'] = df['request_number_of_comments_at_retrieval']\n",
    "        else:\n",
    "            features['request_comments'] = 0\n",
    "            \n",
    "        if 'number_of_upvotes_of_request_at_retrieval' in df.columns:\n",
    "            features['request_upvotes'] = df['number_of_upvotes_of_request_at_retrieval']\n",
    "        else:\n",
    "            features['request_upvotes'] = 0\n",
    "            \n",
    "        if 'number_of_downvotes_of_request_at_retrieval' in df.columns:\n",
    "            features['request_downvotes'] = df['number_of_downvotes_of_request_at_retrieval']\n",
    "        else:\n",
    "            features['request_downvotes'] = 0\n",
    "    else:\n",
    "        # For test data, we'll use zeros for these features\n",
    "        features['request_comments'] = 0\n",
    "        features['request_upvotes'] = 0\n",
    "        features['request_downvotes'] = 0\n",
    "    \n",
    "    # Time features\n",
    "    features['unix_timestamp'] = df['unix_timestamp_of_request']\n",
    "    \n",
    "    # User flair (categorical) - only in training data\n",
    "    if is_train:\n",
    "        if 'requester_user_flair' in df.columns:\n",
    "            features['user_flair'] = df['requester_user_flair'].fillna('None')\n",
    "        else:\n",
    "            features['user_flair'] = 'None'\n",
    "    else:\n",
    "        features['user_flair'] = 'None'  # Default for test data\n",
    "    \n",
    "    # Post edited (only available in training data)\n",
    "    if is_train:\n",
    "        if 'post_was_edited' in df.columns:\n",
    "            features['post_edited'] = df['post_was_edited'].astype(int)\n",
    "        else:\n",
    "            features['post_edited'] = 0\n",
    "    else:\n",
    "        features['post_edited'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "train_meta = extract_metadata_features(train_df, is_train=True)\n",
    "test_meta = extract_metadata_features(test_df, is_train=False)\n",
    "\n",
    "print(\"Metadata features shape:\", train_meta.shape)\n",
    "print(\"Test metadata features shape:\", test_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f10a5",
   "metadata": {},
   "source": [
    "## Handle Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab574d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:25:57.023808Z",
     "iopub.status.busy": "2026-01-09T12:25:57.023707Z",
     "iopub.status.idle": "2026-01-09T12:25:57.030930Z",
     "shell.execute_reply": "2026-01-09T12:25:57.030567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After one-hot encoding: (2878, 16)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode user flair\n",
    "train_meta = pd.get_dummies(train_meta, columns=['user_flair'], prefix='flair')\n",
    "test_meta = pd.get_dummies(test_meta, columns=['user_flair'], prefix='flair')\n",
    "\n",
    "# Ensure same columns in both train and test\n",
    "missing_cols = set(train_meta.columns) - set(test_meta.columns)\n",
    "for col in missing_cols:\n",
    "    test_meta[col] = 0\n",
    "\n",
    "test_meta = test_meta[train_meta.columns]\n",
    "\n",
    "print(\"After one-hot encoding:\", train_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd8417",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2b343d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:25:57.031921Z",
     "iopub.status.busy": "2026-01-09T12:25:57.031654Z",
     "iopub.status.idle": "2026-01-09T12:25:57.356487Z",
     "shell.execute_reply": "2026-01-09T12:25:57.356045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text features shape: (2878, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize text using TF-IDF\n",
    "print(\"Vectorizing text...\")\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit features for speed\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "# Fit on training text and transform both train and test\n",
    "train_text_features = tfidf.fit_transform(train_df['combined_text'])\n",
    "test_text_features = tfidf.transform(test_df['combined_text'])\n",
    "\n",
    "print(\"Text features shape:\", train_text_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a3287",
   "metadata": {},
   "source": [
    "## Scale Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b56e912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:25:57.357458Z",
     "iopub.status.busy": "2026-01-09T12:25:57.357299Z",
     "iopub.status.idle": "2026-01-09T12:25:57.366240Z",
     "shell.execute_reply": "2026-01-09T12:25:57.365889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled metadata shape: (2878, 16)\n"
     ]
    }
   ],
   "source": [
    "# Scale metadata features\n",
    "scaler = StandardScaler()\n",
    "train_meta_scaled = scaler.fit_transform(train_meta)\n",
    "test_meta_scaled = scaler.transform(test_meta)\n",
    "\n",
    "# Convert to sparse matrix for compatibility with text features\n",
    "train_meta_sparse = csr_matrix(train_meta_scaled)\n",
    "test_meta_sparse = csr_matrix(test_meta_scaled)\n",
    "\n",
    "print(\"Scaled metadata shape:\", train_meta_sparse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca192a0",
   "metadata": {},
   "source": [
    "## Combine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd0eb85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:25:57.367165Z",
     "iopub.status.busy": "2026-01-09T12:25:57.366902Z",
     "iopub.status.idle": "2026-01-09T12:25:57.371082Z",
     "shell.execute_reply": "2026-01-09T12:25:57.370743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training features shape: (2878, 5016)\n",
      "Final test features shape: (1162, 5016)\n",
      "Target shape: (2878,)\n"
     ]
    }
   ],
   "source": [
    "# Combine text and metadata features\n",
    "X_train = hstack([train_text_features, train_meta_sparse])\n",
    "X_test = hstack([test_text_features, test_meta_sparse])\n",
    "\n",
    "print(\"Final training features shape:\", X_train.shape)\n",
    "print(\"Final test features shape:\", X_test.shape)\n",
    "\n",
    "# Target variable\n",
    "y_train = train_df['requester_received_pizza'].astype(int).values\n",
    "print(\"Target shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25871777",
   "metadata": {},
   "source": [
    "## Cross-Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3164f5a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:26:05.922274Z",
     "iopub.status.busy": "2026-01-09T12:26:05.922056Z",
     "iopub.status.idle": "2026-01-09T12:26:05.925414Z",
     "shell.execute_reply": "2026-01-09T12:26:05.925018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-fold cross-validation...\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation setup\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Model - Logistic Regression as baseline\n",
    "model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "\n",
    "print(f\"Running {n_splits}-fold cross-validation...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979554c9",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b5fb06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:26:05.926527Z",
     "iopub.status.busy": "2026-01-09T12:26:05.926274Z",
     "iopub.status.idle": "2026-01-09T12:26:05.985535Z",
     "shell.execute_reply": "2026-01-09T12:26:05.985155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ROC AUC: 1.0000\n",
      "Fold 2 ROC AUC: 1.0000\n",
      "Fold 3 ROC AUC: 1.0000\n",
      "Fold 4 ROC AUC: 1.0000\n",
      "Fold 5 ROC AUC: 1.0000\n",
      "\n",
      "CV ROC AUC: 1.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Predict\n",
    "    val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calculate ROC AUC\n",
    "    auc_score = roc_auc_score(y_val, val_pred)\n",
    "    cv_scores.append(auc_score)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} ROC AUC: {auc_score:.4f}\")\n",
    "\n",
    "print(f\"\\nCV ROC AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1295ed",
   "metadata": {},
   "source": [
    "## Train on Full Data and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2795827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:26:05.986582Z",
     "iopub.status.busy": "2026-01-09T12:26:05.986298Z",
     "iopub.status.idle": "2026-01-09T12:26:05.999369Z",
     "shell.execute_reply": "2026-01-09T12:26:05.999024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on full dataset...\n",
      "Test predictions shape: (1162,)\n"
     ]
    }
   ],
   "source": [
    "# Train on full training data\n",
    "print(\"Training on full dataset...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "test_predictions = model.predict_proba(X_test)[:, 1]\n",
    "print(\"Test predictions shape:\", test_predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047a9d8d",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f63f592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T12:26:06.000320Z",
     "iopub.status.busy": "2026-01-09T12:26:06.000069Z",
     "iopub.status.idle": "2026-01-09T12:26:06.008101Z",
     "shell.execute_reply": "2026-01-09T12:26:06.007765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: /home/submission/submission.csv\n",
      "\n",
      "Submission preview:\n",
      "  request_id  requester_received_pizza\n",
      "0  t3_1aw5zf                  0.000704\n",
      "1   t3_roiuw                  0.000976\n",
      "2   t3_mjnbq                  0.000965\n",
      "3   t3_t8wd1                  0.000865\n",
      "4  t3_1m4zxu                  0.000696\n",
      "\n",
      "Submission shape: (1162, 2)\n",
      "Prediction range: [0.0006, 0.0044]\n"
     ]
    }
   ],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(\"Submission file created:\", submission_path)\n",
    "print(\"\\nSubmission preview:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Check submission format\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"Prediction range: [{test_predictions.min():.4f}, {test_predictions.max():.4f}]\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
