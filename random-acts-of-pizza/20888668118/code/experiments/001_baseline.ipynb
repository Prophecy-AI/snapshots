{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac31228c",
   "metadata": {},
   "source": [
    "# Baseline Experiment 001\n",
    "\n",
    "## Phase 1 - Simple Baselines\n",
    "\n",
    "Following the strategy:\n",
    "1. LightGBM on tabular features only\n",
    "2. TF-IDF + LightGBM on text features only\n",
    "3. Basic ensemble\n",
    "\n",
    "Key findings from EDA:\n",
    "- 24.8% success rate (moderate class imbalance)\n",
    "- request_number_of_comments_at_retrieval has highest correlation (0.291)\n",
    "- User flair 'shroom' and 'PIF' have 100% success rate (potential leakage)\n",
    "- Text features: request_title and request_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target\n",
    "y = train_df['requester_received_pizza'].astype(int)\n",
    "\n",
    "# Identify key features from EDA\n",
    "# Tabular features (numeric and categorical) - ONLY use features available at request time\n",
    "# (features with \"at_retrieval\" are not available in test data)\n",
    "tabular_features = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request'\n",
    "]\n",
    "\n",
    "# Handle user flair (highly predictive but potential leakage)\n",
    "# Create binary features instead of using raw flair\n",
    "# Note: test data doesn't have this feature, so we need to handle it carefully\n",
    "if 'requester_user_flair' in train_df.columns:\n",
    "    train_df['has_shroom_flair'] = (train_df['requester_user_flair'] == 'shroom').astype(int)\n",
    "    train_df['has_pif_flair'] = (train_df['requester_user_flair'] == 'PIF').astype(int)\n",
    "    # For test data, set these to 0 since we don't have flair information\n",
    "    test_df['has_shroom_flair'] = 0\n",
    "    test_df['has_pif_flair'] = 0\n",
    "    # Add flair features to tabular features\n",
    "    tabular_features.extend(['has_shroom_flair', 'has_pif_flair'])\n",
    "    print(\"User flair features added (note: test data has no flair info)\")\n",
    "else:\n",
    "    print(\"User flair not available in training data\")\n",
    "\n",
    "# Create text features - use request_text_edit_aware for test (cleaned version)\n",
    "# For train, we can use either request_text or request_text_edit_aware\n",
    "# Let's use request_text_edit_aware for consistency\n",
    "train_df['full_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text_edit_aware'].fillna('')\n",
    "test_df['full_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text_edit_aware'].fillna('')\n",
    "\n",
    "print(\"Features prepared:\")\n",
    "print(f\"Tabular features: {len(tabular_features)}\")\n",
    "print(f\"Text feature: full_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6b0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target\n",
    "y = train_df['requester_received_pizza'].astype(int)\n",
    "\n",
    "# Identify key features from EDA\n",
    "# Tabular features (numeric and categorical)\n",
    "tabular_features = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'request_number_of_comments_at_retrieval',\n",
    "    'number_of_upvotes_of_request_at_retrieval',\n",
    "    'number_of_downvotes_of_request_at_retrieval',\n",
    "    'requester_days_since_first_post_on_raop_at_request'\n",
    "]\n",
    "\n",
    "# Handle user flair (highly predictive but potential leakage)\n",
    "# Create binary features instead of using raw flair\n",
    "# Note: test data doesn't have this feature, so we need to handle it carefully\n",
    "if 'requester_user_flair' in train_df.columns:\n",
    "    train_df['has_shroom_flair'] = (train_df['requester_user_flair'] == 'shroom').astype(int)\n",
    "    train_df['has_pif_flair'] = (train_df['requester_user_flair'] == 'PIF').astype(int)\n",
    "    # For test data, set these to 0 since we don't have flair information\n",
    "    test_df['has_shroom_flair'] = 0\n",
    "    test_df['has_pif_flair'] = 0\n",
    "    # Add flair features to tabular features\n",
    "    tabular_features.extend(['has_shroom_flair', 'has_pif_flair'])\n",
    "    print(\"User flair features added (note: test data has no flair info)\")\n",
    "else:\n",
    "    print(\"User flair not available in training data\")\n",
    "\n",
    "# Create text features - use request_text_edit_aware for test (cleaned version)\n",
    "# For train, we can use either request_text or request_text_edit_aware\n",
    "# Let's use request_text_edit_aware for consistency\n",
    "train_df['full_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text_edit_aware'].fillna('')\n",
    "test_df['full_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text_edit_aware'].fillna('')\n",
    "\n",
    "print(\"Features prepared:\")\n",
    "print(f\"Tabular features: {len(tabular_features)}\")\n",
    "print(f\"Text feature: full_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tabular data\n",
    "X_tabular = train_df[tabular_features].copy()\n",
    "X_test_tabular = test_df[tabular_features].copy()\n",
    "\n",
    "# Handle missing values\n",
    "X_tabular = X_tabular.fillna(0)\n",
    "X_test_tabular = X_test_tabular.fillna(0)\n",
    "\n",
    "print(\"Tabular data prepared\")\n",
    "print(f\"Shape: {X_tabular.shape}\")\n",
    "print(f\"Test shape: {X_test_tabular.shape}\")\n",
    "\n",
    "# Check for any missing columns in test data\n",
    "missing_in_test = [col for col in tabular_features if col not in test_df.columns]\n",
    "if missing_in_test:\n",
    "    print(f\"Warning: These features missing in test data: {missing_in_test}\")\n",
    "    # Remove them from tabular features\n",
    "    for col in missing_in_test:\n",
    "        tabular_features.remove(col)\n",
    "    # Re-prepare data\n",
    "    X_tabular = train_df[tabular_features].copy()\n",
    "    X_test_tabular = test_df[tabular_features].copy()\n",
    "    X_tabular = X_tabular.fillna(0)\n",
    "    X_test_tabular = X_test_tabular.fillna(0)\n",
    "    print(f\"Updated tabular features: {len(tabular_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: LightGBM on tabular features only\n",
    "print(\"=\"*50)\n",
    "print(\"Model 1: LightGBM on tabular features only\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "tabular_scores = []\n",
    "tabular_predictions = np.zeros(len(test_df))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_tabular, y)):\n",
    "    X_train, X_val = X_tabular.iloc[train_idx], X_tabular.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'is_unbalance': True  # Handle class imbalance\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['val'],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict(X_val)\n",
    "    score = roc_auc_score(y_val, val_pred)\n",
    "    tabular_scores.append(score)\n",
    "    \n",
    "    # Test predictions\n",
    "    fold_pred = model.predict(X_test_tabular)\n",
    "    tabular_predictions += fold_pred / 5\n",
    "    \n",
    "    print(f\"Fold {fold+1} AUC: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(tabular_scores):.4f} ± {np.std(tabular_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: TF-IDF + LightGBM on text features only\n",
    "print(\"=\"*50)\n",
    "print(\"Model 2: TF-IDF + LightGBM on text features only\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "X_text = vectorizer.fit_transform(train_df['full_text'])\n",
    "X_test_text = vectorizer.transform(test_df['full_text'])\n",
    "\n",
    "print(f\"TF-IDF shape: {X_text.shape}\")\n",
    "\n",
    "text_scores = []\n",
    "text_predictions = np.zeros(len(test_df))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_text, y)):\n",
    "    X_train = X_text[train_idx]\n",
    "    X_val = X_text[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val = y.iloc[val_idx]\n",
    "    \n",
    "    # Convert to dense for LightGBM (sample for efficiency)\n",
    "    # For large sparse matrices, we'll use a subset of features\n",
    "    if fold == 0:\n",
    "        # On first fold, select top features by chi-square\n",
    "        from sklearn.feature_selection import SelectKBest, chi2\n",
    "        selector = SelectKBest(chi2, k=2000)\n",
    "        X_train_dense = selector.fit_transform(X_train, y_train)\n",
    "        X_val_dense = selector.transform(X_val)\n",
    "        X_test_text_dense = selector.transform(X_test_text)\n",
    "        \n",
    "        # Store selector for reuse\n",
    "        text_selector = selector\n",
    "    else:\n",
    "        X_train_dense = text_selector.transform(X_train)\n",
    "        X_val_dense = text_selector.transform(X_val)\n",
    "        X_test_text_dense = text_selector.transform(X_test_text)\n",
    "    \n",
    "    # LightGBM parameters for text\n",
    "    params_text = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'is_unbalance': True\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train_dense, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val_dense, label=y_val)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params_text,\n",
    "        train_data,\n",
    "        num_boost_round=500,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['val'],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict(X_val_dense)\n",
    "    score = roc_auc_score(y_val, val_pred)\n",
    "    text_scores.append(score)\n",
    "    \n",
    "    # Test predictions\n",
    "    fold_pred = model.predict(X_test_text_dense)\n",
    "    text_predictions += fold_pred / 5\n",
    "    \n",
    "    print(f\"Fold {fold+1} AUC: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(text_scores):.4f} ± {np.std(text_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c71a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Simple ensemble (average of predictions)\n",
    "print(\"=\"*50)\n",
    "print(\"Model 3: Simple Ensemble (Average)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Average predictions\n",
    "ensemble_predictions = (tabular_predictions + text_predictions) / 2\n",
    "\n",
    "# For validation, we can approximate ensemble score by averaging fold predictions\n",
    "# (This is an approximation - true ensemble would require retraining)\n",
    "ensemble_scores = [(t1 + t2) / 2 for t1, t2 in zip(tabular_scores, text_scores)]\n",
    "print(f\"Ensemble AUC (approx): {np.mean(ensemble_scores):.4f} ± {np.std(ensemble_scores):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Tabular-only Model:  {np.mean(tabular_scores):.4f} ± {np.std(tabular_scores):.4f}\")\n",
    "print(f\"Text-only Model:     {np.mean(text_scores):.4f} ± {np.std(text_scores):.4f}\")\n",
    "print(f\"Ensemble Model:      {np.mean(ensemble_scores):.4f} ± {np.std(ensemble_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': ensemble_predictions\n",
    "})\n",
    "\n",
    "# Ensure proper format\n",
    "submission['requester_received_pizza'] = submission['requester_received_pizza'].astype(float)\n",
    "submission = submission.sort_values('request_id')\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission_001_baseline.csv', index=False)\n",
    "print(\"\\nSubmission saved to: /home/submission/submission_001_baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9826b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T03:55:16.372772Z",
     "iopub.status.busy": "2026-01-11T03:55:16.372141Z",
     "iopub.status.idle": "2026-01-11T03:55:16.378004Z",
     "shell.execute_reply": "2026-01-11T03:55:16.377396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available features in test data:\n",
      "['giver_username_if_known', 'request_id', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_days_since_first_post_on_raop_at_request', 'requester_number_of_comments_at_request', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_posts_at_request', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_request', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc', 'has_shroom_flair', 'has_pif_flair', 'full_text']\n",
      "\n",
      "Total test columns: 20\n",
      "\n",
      "Checking tabular features availability:\n",
      "  ✓ requester_account_age_in_days_at_request\n",
      "  ✓ requester_number_of_comments_at_request\n",
      "  ✓ requester_number_of_posts_at_request\n",
      "  ✓ requester_number_of_subreddits_at_request\n",
      "  ✓ requester_upvotes_minus_downvotes_at_request\n",
      "  ✓ requester_upvotes_plus_downvotes_at_request\n",
      "  ✗ request_number_of_comments_at_retrieval - MISSING\n",
      "  ✗ number_of_upvotes_of_request_at_retrieval - MISSING\n",
      "  ✗ number_of_downvotes_of_request_at_retrieval - MISSING\n",
      "  ✓ requester_days_since_first_post_on_raop_at_request\n",
      "  ✓ has_shroom_flair\n",
      "  ✓ has_pif_flair\n",
      "\n",
      "Available features: 9\n",
      "['requester_account_age_in_days_at_request', 'requester_number_of_comments_at_request', 'requester_number_of_posts_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_request', 'requester_days_since_first_post_on_raop_at_request', 'has_shroom_flair', 'has_pif_flair']\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check which features are available in test data\n",
    "print(\"Available features in test data:\")\n",
    "print(test_df.columns.tolist())\n",
    "print(f\"\\nTotal test columns: {len(test_df.columns)}\")\n",
    "\n",
    "print(\"\\nChecking tabular features availability:\")\n",
    "for feature in tabular_features:\n",
    "    if feature in test_df.columns:\n",
    "        print(f\"  ✓ {feature}\")\n",
    "    else:\n",
    "        print(f\"  ✗ {feature} - MISSING\")\n",
    "\n",
    "# Let's use only features that are available in both train and test\n",
    "available_features = [col for col in tabular_features if col in test_df.columns]\n",
    "print(f\"\\nAvailable features: {len(available_features)}\")\n",
    "print(available_features)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
