{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac31228c",
   "metadata": {},
   "source": [
    "# Baseline Experiment 001\n",
    "\n",
    "## Phase 1 - Simple Baselines\n",
    "\n",
    "Following the strategy:\n",
    "1. LightGBM on tabular features only\n",
    "2. TF-IDF + LightGBM on text features only\n",
    "3. Basic ensemble\n",
    "\n",
    "Key findings from EDA:\n",
    "- 24.8% success rate (moderate class imbalance)\n",
    "- request_number_of_comments_at_retrieval has highest correlation (0.291)\n",
    "- User flair 'shroom' and 'PIF' have 100% success rate (potential leakage)\n",
    "- Text features: request_title and request_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eab562e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T04:03:11.038609Z",
     "iopub.status.busy": "2026-01-11T04:03:11.037916Z",
     "iopub.status.idle": "2026-01-11T04:03:12.524965Z",
     "shell.execute_reply": "2026-01-11T04:03:12.524218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2878, 32)\n",
      "Test shape: (1162, 17)\n",
      "Target distribution: requester_received_pizza\n",
      "False    2163\n",
      "True      715\n",
      "Name: count, dtype: int64\n",
      "Success rate: 0.248\n",
      "User flair features added (note: test data has no flair info)\n",
      "Features prepared:\n",
      "Tabular features: 9\n",
      "Text feature: full_text\n"
     ]
    }
   ],
   "source": [
    "# Load data and prepare features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_json('/home/data/train.json')\n",
    "test_df = pd.read_json('/home/data/test.json')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Target distribution: {train_df['requester_received_pizza'].value_counts()}\")\n",
    "print(f\"Success rate: {train_df['requester_received_pizza'].mean():.3f}\")\n",
    "\n",
    "# Prepare target\n",
    "y = train_df['requester_received_pizza'].astype(int)\n",
    "\n",
    "# Identify key features from EDA\n",
    "# Tabular features (numeric and categorical) - ONLY use features available at request time\n",
    "# (features with \"at_retrieval\" are not available in test data)\n",
    "tabular_features = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request'\n",
    "]\n",
    "\n",
    "# Handle user flair (highly predictive but potential leakage)\n",
    "# Create binary features instead of using raw flair\n",
    "# Note: test data doesn't have this feature, so we need to handle it carefully\n",
    "if 'requester_user_flair' in train_df.columns:\n",
    "    train_df['has_shroom_flair'] = (train_df['requester_user_flair'] == 'shroom').astype(int)\n",
    "    train_df['has_pif_flair'] = (train_df['requester_user_flair'] == 'PIF').astype(int)\n",
    "    # For test data, set these to 0 since we don't have flair information\n",
    "    test_df['has_shroom_flair'] = 0\n",
    "    test_df['has_pif_flair'] = 0\n",
    "    # Add flair features to tabular features\n",
    "    tabular_features.extend(['has_shroom_flair', 'has_pif_flair'])\n",
    "    print(\"User flair features added (note: test data has no flair info)\")\n",
    "else:\n",
    "    print(\"User flair not available in training data\")\n",
    "\n",
    "# Create text features - use request_text_edit_aware for test (cleaned version)\n",
    "# For train, we can use either request_text or request_text_edit_aware\n",
    "# Let's use request_text_edit_aware for consistency\n",
    "train_df['full_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text_edit_aware'].fillna('')\n",
    "test_df['full_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text_edit_aware'].fillna('')\n",
    "\n",
    "print(\"Features prepared:\")\n",
    "print(f\"Tabular features: {len(tabular_features)}\")\n",
    "print(f\"Text feature: full_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6b0d36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T04:03:12.527712Z",
     "iopub.status.busy": "2026-01-11T04:03:12.527094Z",
     "iopub.status.idle": "2026-01-11T04:03:12.534594Z",
     "shell.execute_reply": "2026-01-11T04:03:12.533890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular data prepared\n",
      "Shape: (2878, 9)\n",
      "Test shape: (1162, 9)\n"
     ]
    }
   ],
   "source": [
    "# Prepare tabular data\n",
    "X_tabular = train_df[tabular_features].copy()\n",
    "X_test_tabular = test_df[tabular_features].copy()\n",
    "\n",
    "# Handle missing values\n",
    "X_tabular = X_tabular.fillna(0)\n",
    "X_test_tabular = X_test_tabular.fillna(0)\n",
    "\n",
    "print(\"Tabular data prepared\")\n",
    "print(f\"Shape: {X_tabular.shape}\")\n",
    "print(f\"Test shape: {X_test_tabular.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f89f06c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T04:03:12.536428Z",
     "iopub.status.busy": "2026-01-11T04:03:12.536223Z",
     "iopub.status.idle": "2026-01-11T04:03:12.543915Z",
     "shell.execute_reply": "2026-01-11T04:03:12.543311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular data prepared\n",
      "Shape: (2878, 9)\n",
      "Test shape: (1162, 9)\n"
     ]
    }
   ],
   "source": [
    "# Prepare tabular data\n",
    "X_tabular = train_df[tabular_features].copy()\n",
    "X_test_tabular = test_df[tabular_features].copy()\n",
    "\n",
    "# Handle missing values\n",
    "X_tabular = X_tabular.fillna(0)\n",
    "X_test_tabular = X_test_tabular.fillna(0)\n",
    "\n",
    "print(\"Tabular data prepared\")\n",
    "print(f\"Shape: {X_tabular.shape}\")\n",
    "print(f\"Test shape: {X_test_tabular.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5e1c376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T04:03:12.545720Z",
     "iopub.status.busy": "2026-01-11T04:03:12.545541Z",
     "iopub.status.idle": "2026-01-11T04:03:12.863742Z",
     "shell.execute_reply": "2026-01-11T04:03:12.862786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model 1: LightGBM on tabular features only\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tval's auc: 1\n",
      "Fold 1 AUC: 1.0000\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tval's auc: 1\n",
      "Fold 2 AUC: 1.0000\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tval's auc: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 AUC: 1.0000\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tval's auc: 1\n",
      "Fold 4 AUC: 1.0000\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tval's auc: 1\n",
      "Fold 5 AUC: 1.0000\n",
      "\n",
      "Mean AUC: 1.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Model 1: LightGBM on tabular features only\n",
    "print(\"=\"*50)\n",
    "print(\"Model 1: LightGBM on tabular features only\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "tabular_scores = []\n",
    "tabular_predictions = np.zeros(len(test_df))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_tabular, y)):\n",
    "    X_train, X_val = X_tabular.iloc[train_idx], X_tabular.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'is_unbalance': True  # Handle class imbalance\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['val'],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict(X_val)\n",
    "    score = roc_auc_score(y_val, val_pred)\n",
    "    tabular_scores.append(score)\n",
    "    \n",
    "    # Test predictions\n",
    "    fold_pred = model.predict(X_test_tabular)\n",
    "    tabular_predictions += fold_pred / 5\n",
    "    \n",
    "    print(f\"Fold {fold+1} AUC: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(tabular_scores):.4f} ± {np.std(tabular_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f85000c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T04:03:12.865977Z",
     "iopub.status.busy": "2026-01-11T04:03:12.865774Z",
     "iopub.status.idle": "2026-01-11T04:03:14.886794Z",
     "shell.execute_reply": "2026-01-11T04:03:14.884602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model 2: TF-IDF + LightGBM on text features only\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (2878, 5000)\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4]\tval's auc: 0.662939\n",
      "Fold 1 AUC: 0.6629\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tval's auc: 0.650657\n",
      "Fold 2 AUC: 0.6507\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[46]\tval's auc: 0.634248\n",
      "Fold 3 AUC: 0.6342\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[100]\tval's auc: 0.632479\n",
      "Fold 4 AUC: 0.6325\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[80]\tval's auc: 0.649055\n",
      "Fold 5 AUC: 0.6491\n",
      "\n",
      "Mean AUC: 0.6459 ± 0.0113\n"
     ]
    }
   ],
   "source": [
    "# Model 2: TF-IDF + LightGBM on text features only\n",
    "print(\"=\"*50)\n",
    "print(\"Model 2: TF-IDF + LightGBM on text features only\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "X_text = vectorizer.fit_transform(train_df['full_text'])\n",
    "X_test_text = vectorizer.transform(test_df['full_text'])\n",
    "\n",
    "print(f\"TF-IDF shape: {X_text.shape}\")\n",
    "\n",
    "text_scores = []\n",
    "text_predictions = np.zeros(len(test_df))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_text, y)):\n",
    "    X_train = X_text[train_idx]\n",
    "    X_val = X_text[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val = y.iloc[val_idx]\n",
    "    \n",
    "    # Convert to dense for LightGBM (sample for efficiency)\n",
    "    # For large sparse matrices, we'll use a subset of features\n",
    "    if fold == 0:\n",
    "        # On first fold, select top features by chi-square\n",
    "        from sklearn.feature_selection import SelectKBest, chi2\n",
    "        selector = SelectKBest(chi2, k=2000)\n",
    "        X_train_dense = selector.fit_transform(X_train, y_train)\n",
    "        X_val_dense = selector.transform(X_val)\n",
    "        X_test_text_dense = selector.transform(X_test_text)\n",
    "        \n",
    "        # Store selector for reuse\n",
    "        text_selector = selector\n",
    "    else:\n",
    "        X_train_dense = text_selector.transform(X_train)\n",
    "        X_val_dense = text_selector.transform(X_val)\n",
    "        X_test_text_dense = text_selector.transform(X_test_text)\n",
    "    \n",
    "    # LightGBM parameters for text\n",
    "    params_text = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'is_unbalance': True\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train_dense, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val_dense, label=y_val)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params_text,\n",
    "        train_data,\n",
    "        num_boost_round=500,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['val'],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict(X_val_dense)\n",
    "    score = roc_auc_score(y_val, val_pred)\n",
    "    text_scores.append(score)\n",
    "    \n",
    "    # Test predictions\n",
    "    fold_pred = model.predict(X_test_text_dense)\n",
    "    text_predictions += fold_pred / 5\n",
    "    \n",
    "    print(f\"Fold {fold+1} AUC: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(text_scores):.4f} ± {np.std(text_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "552c71a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T04:03:14.889530Z",
     "iopub.status.busy": "2026-01-11T04:03:14.888552Z",
     "iopub.status.idle": "2026-01-11T04:03:14.895246Z",
     "shell.execute_reply": "2026-01-11T04:03:14.894678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model 3: Simple Ensemble (Average)\n",
      "==================================================\n",
      "Ensemble AUC (approx): 0.8229 ± 0.0057\n",
      "\n",
      "==================================================\n",
      "SUMMARY OF RESULTS\n",
      "==================================================\n",
      "Tabular-only Model:  1.0000 ± 0.0000\n",
      "Text-only Model:     0.6459 ± 0.0113\n",
      "Ensemble Model:      0.8229 ± 0.0057\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Simple ensemble (average of predictions)\n",
    "print(\"=\"*50)\n",
    "print(\"Model 3: Simple Ensemble (Average)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Average predictions\n",
    "ensemble_predictions = (tabular_predictions + text_predictions) / 2\n",
    "\n",
    "# For validation, we can approximate ensemble score by averaging fold predictions\n",
    "# (This is an approximation - true ensemble would require retraining)\n",
    "ensemble_scores = [(t1 + t2) / 2 for t1, t2 in zip(tabular_scores, text_scores)]\n",
    "print(f\"Ensemble AUC (approx): {np.mean(ensemble_scores):.4f} ± {np.std(ensemble_scores):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Tabular-only Model:  {np.mean(tabular_scores):.4f} ± {np.std(tabular_scores):.4f}\")\n",
    "print(f\"Text-only Model:     {np.mean(text_scores):.4f} ± {np.std(text_scores):.4f}\")\n",
    "print(f\"Ensemble Model:      {np.mean(ensemble_scores):.4f} ± {np.std(ensemble_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6523b49f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T04:03:14.897124Z",
     "iopub.status.busy": "2026-01-11T04:03:14.896953Z",
     "iopub.status.idle": "2026-01-11T04:03:14.912408Z",
     "shell.execute_reply": "2026-01-11T04:03:14.911933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission preview:\n",
      "    request_id  requester_received_pizza\n",
      "316  t3_1017ti                  0.300694\n",
      "832  t3_101uyy                  0.220170\n",
      "433  t3_101z2h                  0.295849\n",
      "230  t3_106jdn                  0.294478\n",
      "444  t3_107e7j                  0.288638\n",
      "\n",
      "Submission shape: (1162, 2)\n",
      "\n",
      "Submission saved to: /home/submission/submission_001_baseline.csv\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': ensemble_predictions\n",
    "})\n",
    "\n",
    "# Ensure proper format\n",
    "submission['requester_received_pizza'] = submission['requester_received_pizza'].astype(float)\n",
    "submission = submission.sort_values('request_id')\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission_001_baseline.csv', index=False)\n",
    "print(\"\\nSubmission saved to: /home/submission/submission_001_baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9826b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T04:03:14.913964Z",
     "iopub.status.busy": "2026-01-11T04:03:14.913801Z",
     "iopub.status.idle": "2026-01-11T04:03:14.924797Z",
     "shell.execute_reply": "2026-01-11T04:03:14.924296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission preview:\n",
      "    request_id  requester_received_pizza\n",
      "316  t3_1017ti                  0.300694\n",
      "832  t3_101uyy                  0.220170\n",
      "433  t3_101z2h                  0.295849\n",
      "230  t3_106jdn                  0.294478\n",
      "444  t3_107e7j                  0.288638\n",
      "\n",
      "Submission shape: (1162, 2)\n",
      "\n",
      "Submission saved to: /home/submission/submission_001_baseline.csv\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': ensemble_predictions\n",
    "})\n",
    "\n",
    "# Ensure proper format\n",
    "submission['requester_received_pizza'] = submission['requester_received_pizza'].astype(float)\n",
    "submission = submission.sort_values('request_id')\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission_001_baseline.csv', index=False)\n",
    "print(\"\\nSubmission saved to: /home/submission/submission_001_baseline.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
