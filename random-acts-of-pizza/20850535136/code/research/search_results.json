{
  "query": "How do Kaggle winners handle class imbalance in binary classification with 75/25 split?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Top Kaggle winners typically tackle a 75\u202f%\u202f/\u202f25\u202f% binary\u2011class split by reshaping the training data and by using metrics and model settings that reward performance on the minority class.\u202fThey combine resampling, class\u2011weighting, and careful validation to keep the imbalance from biasing the model\u202f([Dealing with extremely imbalanced dataset \u2013 Kaggle](https://www.kaggle.com/questions-and-answers/473546);\u202f[Unbalanced data and cross\u2011validation \u2013 Kaggle](https://www.kaggle.com/discussions/questions-and-answers/27589)).\n\n**Step\u2011by\u2011step workflow**\n\n1. **Inspect the split and pick an imbalance\u2011aware metric** \u2013 report AUC\u2011ROC, PR\u2011AUC or log\u2011loss instead of plain accuracy, because these metrics reflect minority\u2011class performance\u202f([Unbalanced data and cross\u2011validation \u2013 Kaggle](https://www.kaggle.com/discussions/questions-and-answers/27589)).  \n\n2. **Apply resampling to the training folds**  \n   * *Undersample* the majority (75\u202f%) class to a manageable size, or  \n   * *Oversample* the minority (25\u202f%) class with synthetic techniques such as **SMOTE** or ADASYN. Both approaches are standard in Kaggle solutions\u202f([Dealing with extremely imbalanced dataset \u2013 Kaggle](https://www.kaggle.com/questions-and-answers/473546);\u202f[Resampling strategies for imbalanced datasets \u2013 Kaggle](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets)).  \n\n3. **Add class weights (or sample weights) to the loss function** \u2013 most libraries (e.g., XGBoost, LightGBM, sklearn) accept a `scale_pos_weight` or `class_weight` argument; setting a higher weight for the minority class forces the model to penalize its errors more heavily.  \n\n4. **Train robust models and ensembles** \u2013 gradient\u2011boosted trees, neural nets, or stacked ensembles are common; ensemble methods help smooth out variance introduced by resampling\u202f([Dealing with extremely imbalanced dataset \u2013 Kaggle](https://www.kaggle.com/questions-and-answers/473546)).  \n\n5. **Validate with stratified cross\u2011validation** \u2013 ensure each fold preserves the 75/25 ratio so that performance estimates remain realistic and that resampling/weighting decisions are not over\u2011fitted.  \n\n6. **Fine\u2011tune threshold post\u2011training** \u2013 after the model is fitted, adjust the decision threshold (e.g., using the ROC curve) to balance precision vs. recall according to the competition\u2019s cost of false positives vs. false negatives.  \n\n7. **Monitor the minority\u2011class metrics on the hold\u2011out leaderboard** \u2013 iterate on resampling ratios, class\u2011weight values, and ensemble composition until the minority\u2011class AUC/PR\u2011AUC improves.  \n\nFollowing these concise steps lets you handle a 75\u202f%\u202f/\u202f25\u202f% imbalance the way Kaggle champions do, keeping the minority class well\u2011represented in both training and evaluation.",
      "url": ""
    },
    {
      "title": "Dealing with extremely imbalanced dataset - binary classification",
      "text": "Checking your browser - reCAPTCHA\nChecking your browser before accessing www.kaggle.com ...\nClick[here](#)if you are not automatically redirected after 5 seconds.",
      "url": "https://www.kaggle.com/questions-and-answers/473546"
    },
    {
      "title": "Resampling strategies for imbalanced datasets - Kaggle",
      "text": "- _code_\n\nNew Notebook\n\n- _table\\_chart_\n\nNew Dataset\n\n- _tenancy_\n\nNew Model\n\n- _emoji\\_events_\n\nNew Competition\n\n- _corporate\\_fare_\n\nNew Organization\n\n\n## No Active Events\n\nCreate notebooks and keep track of their status here.\n\n[_add_ New Notebook](https://www.kaggle.com/code/new)\n\n- _auto\\_awesome\\_motion_\n\n\n\n\n\n\n\n\n\n0 Active Events\n\n\n\n\n\n\n_expand\\_more_\n\n\nmenu\n\n[Skip to\\\n\\\ncontent](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets#site-content)\n\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\n\nCreate\n\n_search_\n\n- [_explore_\\\n\\\nHome](https://www.kaggle.com/)\n\n- [_emoji\\_events_\\\n\\\nCompetitions](https://www.kaggle.com/competitions)\n\n- [_table\\_chart_\\\n\\\nDatasets](https://www.kaggle.com/datasets)\n\n- [_tenancy_\\\n\\\nModels](https://www.kaggle.com/models)\n\n- [_code_\\\n\\\nCode](https://www.kaggle.com/code)\n\n- [_comment_\\\n\\\nDiscussions](https://www.kaggle.com/discussions)\n\n- [_school_\\\n\\\nLearn](https://www.kaggle.com/learn)\n\n- [_expand\\_more_\\\n\\\nMore](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets)\n\n\n_auto\\_awesome\\_motion_\n\nView Active Events\n\nmenu\n\n[Skip to\\\n\\\ncontent](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets#site-content)\n\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\n\n_search_\n\n[Sign In](https://www.kaggle.com/account/login?phase=startSignInTab&returnUrl=%2Fcode%2Frafjaa%2Fresampling-strategies-for-imbalanced-datasets)\n\n[Register](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2Fcode%2Frafjaa%2Fresampling-strategies-for-imbalanced-datasets)\n\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\n\n[Learn more.](https://www.kaggle.com/cookies)\n\nOK, Got it.\n\n![Something went wrong and this page crashed!](https://www.kaggle.com/static/images/error/server-error-illo_light.svg)\n\n###### Something went wrong and this page crashed!\n\nIf the issue persists, it's likely a problem on our side.\n\n```\n\nLoading CSS chunk 5073 failed.\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 5073 failed.\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\n    at t.onerror.t.onload (https://www.kaggle.com/static/assets/runtime.js?v=e39bd89f6741bf1e27b2:1:8254)\n```\n\nRefresh",
      "url": "https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets"
    },
    {
      "title": "Unbalanced data and cross-validation | Kaggle",
      "text": "<div><div><p>There are two general ways of dealing with imbalanced data: 1) change the data; 2) leave the data alone but change the performance metric and/or the weight of individual data points.</p>\n<p>Changing the data means oversampling the under-represented class(es) with synthetic data points, or undersampling (thinning down) the over-represented class(es). There are various ways of doing both operations, and I will give you one <a href=\"https://github.com/scikit-learn-contrib/imbalanced-learn\"><strong>starting point</strong></a>.</p>\n<p>A second option is to leave the data alone and adjust how we do the training. It is crucial to pick a reliable performance metric for imbalanced data, and to know whether for your purposes it is worse to have too many false positives (FPs) or false negatives (FNs). Ideally, you wouldn't want to have either of the two, but for most applications it should be clear whether we want to avoid FPs or FNs with greater preference.</p>\n<p>To give you an example: you have 900 healthy patients (class 0) and 100 cancer patients (class 1), which is at least somewhat close to the true ratio of healthy and cancer-stricken people out there. If you predict class 0 with 100% accuracy and class 1 with 70% accuracy, your accuracy will be 97% for the whole dataset. That sounds tremendous until we realize that 30 out of 100 cancer patients (30%) will go undiagnosed, meaning that high false negative rate in this case will cost many lives. What if we could adjust our classification so that both classes are predicted with 97% accuracy? This would mean that 27 healthy people would be predicted to have cancer (27 FPs) and 3 cancer-stricken individual would be predicted to be healthy (3 FNs). Now, I wouldn't want to be a doctor who tells a healthy person that they have a cancer because many people have been known to do silly things when they think they are dying. Still, compared to our starting premise, most would agree that on balance it is much better to have 27 people who think they have cancer and later find out they don't, and only 3 patients who were told they are healthy even though they have cancer. The problem is that a simple accuracy as a performance metric for training would never get you to a balanced 97% accuracy. For imbalanced datasets, F1-score (a weighted average of precision and recall), area under curve for ROC and Matthews correlation coefficient may be better measures of classifier quality.</p>\n<p>See the links below for more info:</p>\n<p><a href=\"http://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/\"><strong>link1</strong></a></p>\n<p><a href=\"https://eva.fing.edu.uy/mod/resource/view.php?id=33977\"><strong>link2</strong></a></p>\n<p><a href=\"https://www.kaggle.com/c/bosch-production-line-performance/forums/t/24120/time-effort-and-reward?forumMessageId=138285#post138285\"><strong>link3</strong></a></p></div></div>",
      "url": "https://www.kaggle.com/discussions/questions-and-answers/27589"
    },
    {
      "title": "Understanding Class Imbalance in 1 Minute! - Kaggle",
      "text": "Checking your browser - reCAPTCHA\nChecking your browser before accessing www.kaggle.com ...\nClick[here](#)if you are not automatically redirected after 5 seconds.",
      "url": "https://www.kaggle.com/getting-started/467908"
    },
    {
      "title": "Binary classification with strongly unbalanced classes",
      "text": "**Teams**\n\nQ&A for work\n\nConnect and share knowledge within a single location that is structured and easy to search.\n\n[Learn more about Teams](https://stackoverflow.co/teams/)\n\n# [Binary classification with strongly unbalanced classes](https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes)\n\n[Ask Question](https://stats.stackexchange.com/questions/ask)\n\nAsked7 years, 9 months ago\n\nModified [3 years, 11 months ago](https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes?lastactivity)\n\nViewed\n56k times\n\n67\n\n$\\\\begingroup$\n\nI have a data set in the form of (features, binary output 0 or 1), but 1 happens pretty rarely, so just by always predicting 0, I get accuracy between 70% and 90% (depending on the particular data I look at). The ML methods give me about the same accuracy, and I feel, there should be some standard methods to apply in this situation, that would improve the accuracy over the obvious prediction rule.\n\n- [machine-learning](https://stats.stackexchange.com/questions/tagged/machine-learning)\n- [classification](https://stats.stackexchange.com/questions/tagged/classification)\n- [binary-data](https://stats.stackexchange.com/questions/tagged/binary-data)\n- [unbalanced-classes](https://stats.stackexchange.com/questions/tagged/unbalanced-classes)\n\n[Share](https://stats.stackexchange.com/q/235808)\n\nCite\n\n[Improve this question](https://stats.stackexchange.com/posts/235808/edit)\n\nFollow\n\n[edited Oct 30, 2017 at 19:47](https://stats.stackexchange.com/posts/235808/revisions)\n\nLazyCat\n\nasked Sep 19, 2016 at 18:39\n\n[![LazyCat's user avatar](https://www.gravatar.com/avatar/0de65f380a7e1cb28d4f0c9c5f93fdde?s=64&d=identicon&r=PG)](https://stats.stackexchange.com/users/30893/lazycat)\n\n[LazyCat](https://stats.stackexchange.com/users/30893/lazycat) LazyCat\n\n87211 gold badge77 silver badges1111 bronze badges\n\n$\\\\endgroup$\n\n6\n\n- 4\n\n\n\n\n\n$\\\\begingroup$I've found this article to be very helpful on the subject: [svds.com/learning-imbalanced-classes](http://www.svds.com/learning-imbalanced-classes/)$\\\\endgroup$\n\n\u2013\u00a0[J. O'Brien Antognini](https://stats.stackexchange.com/users/115448/j-obrien-antognini)\n\nCommentedSep 20, 2016 at 23:18\n\n- $\\\\begingroup$@J.O'BrienAntognini That is a really nice article!$\\\\endgroup$\n\n\u2013\u00a0[Jinhua Wang](https://stats.stackexchange.com/users/163503/jinhua-wang)\n\nCommentedJan 27, 2019 at 17:22\n\n- $\\\\begingroup$Some useful discussion here: [stats.stackexchange.com/questions/285231/\u2026](https://stats.stackexchange.com/questions/285231/what-problem-does-oversampling-undersampling-and-smote-solve?r=SearchResults&s=3|0.0000) and [stats.stackexchange.com/questions/283170/\u2026](https://stats.stackexchange.com/questions/283170/when-is-unbalanced-data-really-a-problem-in-machine-learning)$\\\\endgroup$\n\n\u2013\u00a0[Sycorax](https://stats.stackexchange.com/users/22311/sycorax) \u2666\n\nCommentedJul 15, 2020 at 13:02\n\n- $\\\\begingroup$This post [here](https://stats.stackexchange.com/questions/247871/what-is-the-root-cause-of-the-class-imbalance-problem) has a very clear answer on _why_ class imbalance causes problems.$\\\\endgroup$\n\n\u2013\u00a0[Stephen G](https://stats.stackexchange.com/users/225551/stephen-g)\n\nCommentedJul 15, 2020 at 13:57\n\n- $\\\\begingroup$@StephenG At present, the post you've linked to has three answers. Which one are you referring to?$\\\\endgroup$\n\n\u2013\u00a0[Sycorax](https://stats.stackexchange.com/users/22311/sycorax) \u2666\n\nCommentedJul 15, 2020 at 17:49\n\n\n\\|\u00a0[Show **1** more comment](https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes)\n\n## 7 Answers 7\n\nSorted by:\n[Reset to default](https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes?answertab=scoredesc#tab-top)\n\nHighest score (default)Date modified (newest first)Date created (oldest first)\n\n39\n\n$\\\\begingroup$\n\nBoth hxd1011 and Frank are right (+1).\nEssentially resampling and/or cost-sensitive learning are the two main ways of getting around the problem of imbalanced data; third is to use kernel methods that sometimes might be less effected by the class imbalance.\nLet me stress that there is no silver-bullet solution. By definition you have one class that is represented inadequately in your samples.\n\nHaving said the above I believe that you will find the algorithms [SMOTE](http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-106) and [ROSE](https://journal.r-project.org/archive/2014-1/menardi-lunardon-torelli.pdf) very helpful. SMOTE effectively uses a $k$-nearest neighbours approach to exclude members of the majority class while in a similar way creating synthetic examples of a minority class. ROSE tries to create estimates of the underlying distributions of the two classes using a smoothed bootstrap approach and sample them for synthetic examples. Both are readily available in R, SMOTE in the package [DMwR](https://cran.r-project.org/web/packages/DMwR/index.html) and ROSE in the package with the [same name](https://cran.r-project.org/web/packages/ROSE/index.html). Both SMOTE and ROSE result in a training dataset that is smaller than the original one.\n\nI would probably argue that a better (or less bad) metric for the case of imbalanced data is using [Cohen's $k$](https://en.wikipedia.org/wiki/Cohen's_kappa) and/or [Receiver operating characteristic's Area under the curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve).\nCohen's kappa directly controls for the expected accuracy, AUC as it\nis a function of sensitivity and specificity, the curve is insensitive to disparities in the class proportions. Again, notice that these are just metrics that should be used with a large grain of salt. You should ideally adapt them to your specific problem taking account of the gains and costs correct and wrong classifications convey in your case. I have found that looking at [lift-curves](https://en.wikipedia.org/wiki/Lift_%28data_mining%29) is actually rather informative for this matter.\nIrrespective of your metric you should try to use a separate test to assess the performance of your algorithm; exactly because of the class imbalanced over-fitting is even more likely so out-of-sample testing is crucial.\n\nProbably the most popular recent paper on the matter is [Learning from Imbalanced Data](http://www.ele.uri.edu/faculty/he/PDFfiles/ImbalancedLearning.pdf) by He and Garcia. It gives a very nice overview of the points raised by myself and in other answers. In addition I believe that the walk-through on [Subsampling For Class Imbalances](http://topepo.github.io/caret/subsampling-for-class-imbalances.html), presented by Max Kuhn as part of the [caret](https://cran.r-project.org/web/packages/caret/index.html) package is an excellent resource to get a structure example of how under-/over-sampling as well as synthetic data creation can measure against each other.\n\n[Share](https://stats.stackexchange.com/a/235824)\n\nCite\n\n[Improve this answer](https://stats.stackexchange.com/posts/235824/edit)\n\nFollow\n\n[edited Sep 19, 2016 at 20:12](https://stats.stackexchange.com/posts/235824/revisions)\n\nanswered Sep 19, 2016 at 19:44\n\n[![us\u03b5r11852's user avatar](https://i.sstatic.net/Y88zz.png?s=64)](https://stats.stackexchange.com/users/11852/us%ce%b5r11852)\n\n[us\u03b5r11852](https://stats.stackexchange.com/users/11852/us%ce%b5r11852) us\u03b5r11852\n\n44.7k33 gold badges101101 silver badges158158 bronze badges\n\n$\\\\endgroup$\n\n3\n\n- $\\\\begingroup$A third somewhat popular (and again not too appropriate) metric is the Area-Under-the-Curve of the Precision-Recall curve. [Davis & James, 2006](https://www.biostat.wisc.edu/~page/rocpr.pdf) paper is consider a classic on the matter; CV has a good thread [too](http://stats.stackexchange.com/questions/7207). I recently saw a paper with the somewhat hammy title \" [The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating Binary Classifiers on Imbalanced Dat...",
      "url": "https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes"
    },
    {
      "title": "Best techniques and metrics for Imbalanced Dataset - Kaggle",
      "text": "Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\n\n[Learn more](https://www.kaggle.com/cookies)\n\nOK, Got it.\n\n###### Something went wrong and this page crashed!\n\nIf the issue persists, it's likely a problem on our side.\n\n```\n\nLoading CSS chunk 8198 failed.\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 8198 failed.\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\n    at r.onerror.r.onload (https://www.kaggle.com/static/assets/runtime.js?v=805aeed0a20bb825939e:1:11032)\n```\n\nRefresh",
      "url": "https://www.kaggle.com/code/marcinrutecki/best-techniques-and-metrics-for-imbalanced-dataset"
    },
    {
      "title": "Class Imbalance Strategies \u2014 A Visual Guide with Code - Medium",
      "text": "[Sitemap](https://medium.com/sitemap/sitemap.xml)\n\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8bc8fae71e1a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdata-science%2Fclass-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\n\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n\n[Search](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdata-science%2Fclass-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n[**TDS Archive**](https://medium.com/data-science?source=post_page---publication_nav-7f60cf5620c9-8bc8fae71e1a---------------------------------------)\n\n\u00b7\n\nAn archive of data science, data analytics, data engineering, machine learning, and artificial intelligence writing from the former Towards Data Science Medium publication.\n\n# Class Imbalance Strategies \u2014 A Visual Guide with Code\n\n## Understand Random Undersampling, Oversampling, SMOTE, ADASYN, and Tomek Links\n\n[Travis Tang](https://medium.com/@travis-tang?source=post_page---byline--8bc8fae71e1a---------------------------------------)\n\n13 min read\n\n\u00b7\n\nApr 24, 2023\n\n--\n\n1\n\nListen\n\nShare\n\nClass imbalance occurs when one class in a classification problem significantly outweighs the other class. It\u2019s common in many machine learning problems. Examples include fraud detection, anomaly detection, and medical diagnosis.\n\n## The Curse of Class Imbalance\n\nA model trained on an imbalanced dataset perform poorly on the minority class. At best, this can cause loss to the business in the case of a churn analysis. At worst, it can pervade systemic bias of a face recognition system.\n\nPress enter or click to view image in full size\n\nA balanced dataset might just be the missing ingredient (Source: Elena Mozhvilo on [Unsplash](https://unsplash.com/photos/j06gLuKK0GM))\n\nThe common approach to class imbalance is resampling. These can entail oversampling the majority class, undersampling the minority class, or a combination of both.\n\nIn this post, I use vivid visuals and code to illustrate these strategies for class imbalance:\n\n1. Random oversampling\n2. Random undersampling\n3. Oversampling with SMOTE\n4. Oversampling with ADASYN\n5. Undersampling with Tomek Link\n6. Oversampling with SMOTE, then undersample with TOMEK Link (SMOTE-Tomek)\n\nI will also be using these strategies on a real-world dataset, and evaluate their impact on a machine learning model. Let\u2019s go.\n\n> All source code is here.\n\n## Using Imbalance-learn\n\nWe will use the `imbalanced-learn` package in python to solve our imbalanced class problem. It is an open-sourced library relying on scikit-learn and provides tools when dealing with classification with imbalanced classes.\n\nTo install it, use the command.\n\n```\npip install -U imbalanced-learn\n```\n\n## Dataset\n\nThe dataset that we are using is the [**Communities and Crime Data Set by UCI (CC BY 4.0)**.](https://archive.ics.uci.edu/ml/datasets/communities+and+crime) It contains 100 attributes of 1994 U.S. communities. We can use this to predict if the **crime rate is high** (defined as having **per capita violent crime** above 0.65). The data source is available in the UCI Machine Learning Repository and is created by Michael Redmond from La Salle University (Published in 2009).\n\n> The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of officers assigned to drug units.\n\nThis dataset is imbalanced. It has 12 communities with low crime rates for every 1 community of high crime rate. This is perfect to illustrate our use case.\n\n```\n>>> from imblearn.datasets import fetch_datasets>>> # Fetch dataset from imbalanced-learn library >>> # as a dictionary of numpy array>>> us_crime = fetch_datasets()['us_crime']>>> us_crime{'data': array([[0.19, 0.33, 0.02, ..., 0.26, 0.2 , 0.32],        [0.  , 0.16, 0.12, ..., 0.12, 0.45, 0.  ],        [0.  , 0.42, 0.49, ..., 0.21, 0.02, 0.  ],        ...,        [0.16, 0.37, 0.25, ..., 0.32, 0.18, 0.91],        [0.08, 0.51, 0.06, ..., 0.38, 0.33, 0.22],        [0.2 , 0.78, 0.14, ..., 0.3 , 0.05, 1.  ]]), 'target': array([-1,  1, -1, ..., -1, -1, -1]), 'DESCR': 'us_crime'}\n```\n\nWe will convert this dictionary to a Pandas dataframe, then split it into train-test splits.\n\n```\n# Convert the dictionary to a pandas dataframecrime_df = pd.concat([pd.DataFrame(us_crime['data'], columns = [f'data_{i}' for i in range(us_crime.data.shape[1])]),           pd.DataFrame(us_crime['target'], columns = ['target'])], axis = 1)# Split data into train test setfrom sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(crime_df.drop('target', axis = 1),                                                     crime_df['target'],                                                     test_size = 0.4,                                                     random_state = 42)\n```\n\nNote that we will only perform under- and over-sampling only on the train dataset. We will _not_ change the test sets with under- and over-sampling.\n\n### Preprocessing the dataset\n\nOur goal is to have a visualize an imbalanced dataset. In order to visualize the 128-dimensional dataset in a 2D graph, we do the following on the train set.\n\n- scale the dataset,\n- perform Principle Component Analysis (PCA) on the features to convert the 100 features to 2 principle components,\n- visualize the data.\n\nHere\u2019s the data, visualized in 2D.\n\nImage by author\n\nCode for the above graph:\n\n```\nfrom sklearn.preprocessing import MinMaxScalerfrom sklearn.decomposition import PCAimport matplotlib.pyplot as plt# Scale the dataset on both train and test sets.# Note that we fit MinMaxScaler on X_train only, not on the entire dataset.# This prevents data leakage from test set to train set.scaler = MinMaxScaler()scaler.fit(X_train)X_train = scaler.transform(X_train)X_test = scaler.transform(X_test)# Perform PCA Decomposition on both train and test sets# Note that we fit PCA on X_train only, not on the entire dataset.# This prevents data leakage from test set to train set.pca = PCA(n_components=2)pca.fit(X_train)X_train_pca = pca.transform(X_train)X_test_pca = pca.transform(X_test)# Function for plotting dataset def plot_data(X,y,ax,title):    ax.scatter(X[:, 0], X[:, 1], c=y, alpha=0.5, s = 30, edgecolor=(0,0,0,0.5))    ax.set_ylabel('Principle Component 1')    ax.set_xlabel('Principle Component 2')    if title is not None:        ax.set_title(title)# Plot datasetfig,ax = plt.subplots(figsize=(5, 5))plot_data(X_train_pca, y_train, ax, title='Original Dataset')\n```\n\nWith the preprocessing done, we are ready to resample our dataset.\n\n## Strategy 1. Random Oversampling\n\nRandom oversampling duplicates existing examples from the minority class with replacement. Each data point in the minority class has an equal probability of being duplicated.\n\nPress enter or click to view image in full size\n\nImage by author\n\nHere\u2019s how to we can perform oversampling on our dataset.\n\n```\nfrom imblearn.over_sampling import RandomOverSampler# Perform random oversamplingros = RandomOverSampler(random_state=0)X_train_ros, ...",
      "url": "https://medium.com/data-science/class-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a"
    },
    {
      "title": "Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions",
      "text": "Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions[\n**\ud83d\udce3 BIG NEWS:****Neptune is joining OpenAI!**\u2192 Read the message from our CEO \ud83d\udce3![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\nWhat do you want to find?\nSearch\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\nSearch in Blog...\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\nSearch in Blog...\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\n[Neptune Blog](https://neptune.ai/blog)# Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Shahul-Es-new-scaled.jpeg?fit=2560%2C1920&ssl=1)\n[Shahul ES](https://neptune.ai/blog/author/shahules)\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)3 min\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)1st September, 2023\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)[Tabular Data](https://neptune.ai/blog/category/tabular-data)\nIn this article, I will discuss some great tips and tricks to improve the performance of your structured data binary classification model. These tricks are obtained from solutions of some of Kaggle\u2019s top tabular data competitions. Without much lag, let\u2019s begin.\nThese are the five competitions that I have gone through to create this article:\n* [**Home credit default risk**](https://www.kaggle.com/c/home-credit-default-risk/)\n* [**Santander Customer Transaction Prediction**](https://www.kaggle.com/c/santander-customer-transaction-prediction/notebooks)\n* [**VSB Power Line Fault Detection**](https://www.kaggle.com/c/vsb-power-line-fault-detection/overview/evaluation)\n* [**Microsoft Malware Prediction**](https://www.kaggle.com/c/microsoft-malware-prediction/overview)\n* [**IEEE-CIS Fraud Detection**](https://www.kaggle.com/c/ieee-fraud-detection/overview/evaluation/)## Dealing with larger datasets\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\n* Faster[data loading with pandas.](https://www.kaggle.com/c/home-credit-default-risk/discussion/59575)\n* Data compression techniques to[reduce the size of data by 70%](https://www.kaggle.com/nickycan/compress-70-of-dataset).\n* Optimize the memory by r[educing the size of some attributes.](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\n* Use open-source libraries such as[Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space.\n* Use[cudf](https://github.com/rapidsai/cudf).\n* Convert data to[parquet](https://arrow.apache.org/docs/python/parquet.html)format.\n* Converting data to[feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03)format.\n* Reducing memory usage for[optimizing RAM](https://www.kaggle.com/mjbahmani/reducing-memory-size-for-ieee).## Data exploration\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\n* EDA for microsoft[malware detection.](https://www.kaggle.com/youhanlee/my-eda-i-want-to-see-all)\n* Time Series[EDA for malware detection.](https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68)\n* Complete[EDA for home credit loan prediction](https://www.kaggle.com/codename007/home-credit-complete-eda-feature-importance).\n* Complete[EDA for Santader prediction.](https://www.kaggle.com/gpreda/santander-eda-and-prediction)\n* EDA for[VSB Power Line Fault Detection.](https://www.kaggle.com/go1dfish/basic-eda)## Data preparation\nAfter data exploration, the first thing to do is to use those insights to prepare the data. To tackle issues like class imbalance, encoding categorical data, etc. Let\u2019s see the methods used to do it.\n* Methods to t[ackle class imbalance](https://www.kaggle.com/shahules/tackling-class-imbalance).\n* Data augmentation by[Synthetic Minority Oversampling Technique](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/).\n* Fast inplace[shuffle for augmentation](https://www.kaggle.com/jiweiliu/fast-inplace-shuffle-for-augmentation).\n* Finding[synthetic samples in the dataset.](https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split)\n* [Signal denoising](https://www.kaggle.com/jackvial/dwt-signal-denoising)used in signal processing competitions.\n* Finding[patterns of missing data](https://www.kaggle.com/jpmiller/patterns-of-missing-data).\n* Methods to handle[missing data](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779).\n* An overview of various[encoding techniques for categorical data.](https://www.kaggle.com/shahules/an-overview-of-encoding-techniques)\n* Building[model to predict missing values.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64598)\n* Random[shuffling of data](https://www.kaggle.com/brandenkmurray/randomly-shuffled-data-also-works)to create new synthetic training set.## Feature engineering\nNext, you can check the most popular feature and feature engineering techniques used in these top kaggle competitions. The feature engineering part varies from problem to problem depending on the domain.\n* Target[encoding cross validation](https://medium.com/@pouryaayria/k-fold-target-encoding-dfe9a594874b/)for better encoding.\n* Entity embedding to[handle categories](https://www.kaggle.com/abhishek/entity-embeddings-to-handle-categories).\n* Encoding c[yclic features for deep learning.](https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning)\n* Manual[feature engineering methods](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering).\n* Automated feature engineering techniques[using featuretools](https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics).\n* Top hard crafted features used in[microsoft malware detection](https://www.kaggle.com/sanderf/7th-place-solution-microsoft-malware-prediction).\n* Denoising NN for[feature extraction](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798).\n* Feature engineering[using RAPIDS framework.](https://www.kaggle.com/cdeotte/rapids-feature-engineering-fraud-0-96/)\n* Things to remember while processing f[eatures using LGBM.](https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575)\n* [Lag features and moving averages.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64593)\n* [Principal component analysis](https://medium.com/machine-learning-researcher/dimensionality-reduction-pca-and-lda-6be91734f567)for...",
      "url": "https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions"
    }
  ]
}