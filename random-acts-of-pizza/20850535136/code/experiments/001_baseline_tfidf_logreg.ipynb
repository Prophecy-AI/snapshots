{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82546c01",
   "metadata": {},
   "source": [
    "# Baseline: TF-IDF + Logistic Regression\n",
    "\n",
    "This notebook implements a simple baseline using TF-IDF text features and logistic regression.\n",
    "Following the Phase 1 roadmap from the strategy guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd4529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import hstack\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeeb40a",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6c0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(train_data)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Columns: {train_df.columns.tolist()}\")\n",
    "\n",
    "# Load test data\n",
    "print(\"\\nLoading test data...\")\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"\\nClass distribution in training data:\")\n",
    "print(train_df['requester_received_pizza'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba42d2",
   "metadata": {},
   "source": [
    "## Basic Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd42616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text features by combining title and text\n",
    "train_df['combined_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text'].fillna('')\n",
    "test_df['combined_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text'].fillna('')\n",
    "\n",
    "# Basic text statistics\n",
    "train_df['text_length'] = train_df['combined_text'].str.len()\n",
    "train_df['word_count'] = train_df['combined_text'].str.split().str.len()\n",
    "test_df['text_length'] = test_df['combined_text'].str.len()\n",
    "test_df['word_count'] = test_df['combined_text'].str.split().str.len()\n",
    "\n",
    "# Select numeric features for concatenation\n",
    "numeric_features = ['text_length', 'word_count', 'request_number_of_comments_at_retrieval',\n",
    "                   'requester_number_of_comments_at_retrieval', 'requester_number_of_posts_at_retrieval',\n",
    "                   'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_retrieval']\n",
    "\n",
    "# Ensure numeric features exist and fill missing values\n",
    "available_numeric_features = [f for f in numeric_features if f in train_df.columns]\n",
    "print(f\"Available numeric features: {available_numeric_features}\")\n",
    "\n",
    "for f in available_numeric_features:\n",
    "    train_df[f] = pd.to_numeric(train_df[f], errors='coerce').fillna(0)\n",
    "    test_df[f] = pd.to_numeric(test_df[f], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a4351",
   "metadata": {},
   "source": [
    "## Cross-Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup stratified cross-validation\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "X_text = train_df['combined_text'].fillna('')\n",
    "y = train_df['requester_received_pizza'].astype(int)\n",
    "\n",
    "# Store OOF predictions and test predictions\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "test_predictions = np.zeros(len(test_df))\n",
    "cv_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb09de4",
   "metadata": {},
   "source": [
    "## TF-IDF + Logistic Regression with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting cross-validation...\")\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X_text, y)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_folds}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_text = X_text.iloc[train_idx]\n",
    "    X_valid_text = X_text.iloc[valid_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_valid = y.iloc[valid_idx]\n",
    "    \n",
    "    # Create TF-IDF features\n",
    "    tfidf = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train_text)\n",
    "    X_valid_tfidf = tfidf.transform(X_valid_text)\n",
    "    \n",
    "    # Add numeric features if available\n",
    "    if available_numeric_features:\n",
    "        X_train_numeric = train_df.iloc[train_idx][available_numeric_features].values\n",
    "        X_valid_numeric = train_df.iloc[valid_idx][available_numeric_features].values\n",
    "        \n",
    "        # Normalize numeric features\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        X_train_numeric = scaler.fit_transform(X_train_numeric)\n",
    "        X_valid_numeric = scaler.transform(X_valid_numeric)\n",
    "        \n",
    "        # Combine TF-IDF and numeric features\n",
    "        X_train_combined = hstack([X_train_tfidf, X_train_numeric])\n",
    "        X_valid_combined = hstack([X_valid_tfidf, X_valid_numeric])\n",
    "    else:\n",
    "        X_train_combined = X_train_tfidf\n",
    "        X_valid_combined = X_valid_tfidf\n",
    "    \n",
    "    # Train logistic regression with class weighting to handle imbalance\n",
    "    model = LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_combined, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    valid_pred = model.predict_proba(X_valid_combined)[:, 1]\n",
    "    oof_predictions[valid_idx] = valid_pred\n",
    "    \n",
    "    # Calculate AUC for this fold\n",
    "    fold_auc = roc_auc_score(y_valid, valid_pred)\n",
    "    cv_scores.append(fold_auc)\n",
    "    print(f\"Fold {fold + 1} AUC: {fold_auc:.4f}\")\n",
    "    \n",
    "    # Predict on test set for this fold\n",
    "    X_test_text = test_df['combined_text'].fillna('')\n",
    "    X_test_tfidf = tfidf.transform(X_test_text)\n",
    "    \n",
    "    if available_numeric_features:\n",
    "        X_test_numeric = test_df[available_numeric_features].values\n",
    "        X_test_numeric = scaler.transform(X_test_numeric)\n",
    "        X_test_combined = hstack([X_test_tfidf, X_test_numeric])\n",
    "    else:\n",
    "        X_test_combined = X_test_tfidf\n",
    "    \n",
    "    test_pred = model.predict_proba(X_test_combined)[:, 1]\n",
    "    test_predictions += test_pred / n_folds\n",
    "\n",
    "# Calculate overall CV score\n",
    "overall_auc = roc_auc_score(y, oof_predictions)\n",
    "print(f\"\\nOverall CV AUC: {overall_auc:.4f}\")\n",
    "print(f\"Mean Fold AUC: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76439d90",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "# Ensure the submission has the correct format\n",
    "submission['requester_received_pizza'] = submission['requester_received_pizza'].astype(float)\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_001_baseline.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"Prediction distribution:\")\n",
    "print(submission['requester_received_pizza'].describe())\n",
    "\n",
    "# Show first few predictions\n",
    "print(\"\\nFirst 5 predictions:\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
