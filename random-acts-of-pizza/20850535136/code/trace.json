{
  "spans": [
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "88207c29476ad00c",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ListFilesTool",
      "kind": "INTERNAL",
      "start_time": 1767958491300067738,
      "end_time": 1767958491300341805,
      "duration": 0.000274067,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ListFilesTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x7f38e836acd0>\", \"input\": {\"directory_path\": \"/home/data\"}}",
        "tool.output": "{\"content\": \"/home/data:\\n[FILE] description.md (7.0KB)\\n[FILE] sampleSubmission.csv (13.0KB)\\n[FILE] test.json (2.0MB)\\n[FILE] test.zip (433.1KB)\\n[FILE] train.json (8.4MB)\\n[FILE] train.zip (1.3MB)\", \"is_error\": false}",
        "tool.duration_ms": 0.38552284240722656
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "3a4b564ac53faae5",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ReadTool",
      "kind": "INTERNAL",
      "start_time": 1767958497144497793,
      "end_time": 1767958497144822555,
      "duration": 0.000324762,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ReadTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x7f38e9db0750>\", \"input\": {\"file_path\": \"/home/data/description.md\"}}",
        "tool.output": "{\"content\": \"# Overview\\n\\n## Description\\n\\n[Get started on this competition through Kaggle Scripts](https://www.kaggle.com/c/random-acts-of-pizza/forums/t/14286/kaggle-scripts-enabled-on-random-acts-of-pizza)\\n\\nIn machine learning, it is often said¬†there are¬†[no free lunches](http://en.wikipedia.org/wiki/No_free_lunch_theorem).¬†*How wrong we were.*\\n\\nThis competition contains a dataset with 5671 textual requests for pizza from the Reddit community¬†[Random Acts of Pizza](http://www.reddit.com/r/Random_Acts_Of_Pizza/)¬†together with their outcome (successful/unsuccessful) and meta-data. Participants must create an algorithm¬†capable of predicting¬†which requests will garner a cheesy (but sincere!) act of¬†kindness.\\n\\n\\\"I'll write a poem, sing a song, do a dance, play an instrument, whatever! I just want a pizza,\\\" says one hopeful poster. What about making an algorithm?\\n\\n![Pizzas](https://storage.googleapis.com/kaggle-media/competitions/kaggle/3949/media/pizzas.png)\\n\\nKaggle is hosting this competition for the machine learning community to use for fun and practice. This¬†[data](http://cs.stanford.edu/~althoff/raop-dataset/)¬†was collected and graciously shared by¬†[Althoff](http://www.timalthoff.com/)¬†et al. (Buy them a pizza -- data collection is a thankless and tedious job!) We encourage participants to explore their¬†[accompanying paper](http://cs.stanford.edu/~althoff/raop-dataset/altruistic_requests_icwsm.pdf)¬†and ask that you cite the following reference in any publications that result from your work:\\n\\nTim Althoff, Cristian Danescu-Niculescu-Mizil, Dan Jurafsky.¬†*How to Ask for a Favor: A Case Study on the Success of Altruistic Requests*,¬†Proceedings of ICWSM, 2014.\\n\\n~*Pizza icons designed by Matthew Dera from the¬†[Noun Project](http://thenounproject.com/term/pizza/30194/)*~\\n\\n### Evaluation\\n\\nSubmissions are evaluated on¬†[area under the ROC curve](http://en.wikipedia.org/wiki/Receiver_operating_characteristic)¬†between the predicted probability that a request will get pizza and the observed outcomes.\\n\\n### Submission File\\n\\nFor each request¬†in the test set, you should predict a real-valued probability that it resulted in a pizza. The file should contain a header and have the following format:\\n\\n```\\nrequest_id,requester_received_pizza\\nt3_i8iy4,0\\nt3_1mfqi0,0\\nt3_lclka,0\\n...\\n...\\n```\\n\\n### Citation\\n\\nWill Cukierski. (2014). Random Acts of Pizza. Kaggle. https://kaggle.com/competitions/random-acts-of-pizza\\n\\n\\n# Data\\n\\n## Dataset Description\\n\\n[See, fork, and run a random forest benchmark model through Kaggle Scripts](https://www.kaggle.com/users/993/ben-hamner/random-acts-of-pizza/simple-julia-benchmark)\\n\\nThis dataset includes 5671 requests collected from the Reddit community¬†[Random Acts of Pizza](http://www.reddit.com/r/Random_Acts_Of_Pizza/)¬†between December 8, 2010 and September 29, 2013 (retrieved on September 30, 2013).¬†All requests ask for the same thing: a free pizza. The outcome of each request -- whether its author received a pizza or not -- is known.¬†Meta-data includes information such as: time of the request, activity of the requester, community-age of the requester, etc.\\n\\nEach JSON¬†entry corresponds to one request (the first and only request by the requester on Random Acts of Pizza). We have removed fields from the test set which would not be available at the time of posting.\\n\\n## Data fields\\n\\n\\\"giver_username_if_known\\\": Reddit username of giver if known, i.e. the person satisfying the request (\\\"N/A\\\" otherwise).\\n\\n\\\"number_of_downvotes_of_request_at_retrieval\\\": Number of downvotes at the time the request was collected.\\n\\n\\\"number_of_upvotes_of_request_at_retrieval\\\": Number of upvotes at the time the request was collected.\\n\\n\\\"post_was_edited\\\": Boolean indicating whether this post was edited (from Reddit).\\n\\n\\\"request_id\\\": Identifier of the post on Reddit, e.g. \\\"t3_w5491\\\".\\n\\n\\\"request_number_of_comments_at_retrieval\\\": Number of comments for the request at time of retrieval.\\n\\n\\\"request_text\\\": Full text of the request.\\n\\n\\\"request_text_edit_aware\\\": Edit aware version of \\\"request_text\\\". We use a set of rules to strip edited comments indicating the success of the request such as \\\"EDIT: Thanks /u/foo, the pizza was delicous\\\".\\n\\n\\\"request_title\\\": Title of the request.\\n\\n\\\"requester_account_age_in_days_at_request\\\": Account age of requester in days at time of request.\\n\\n\\\"requester_account_age_in_days_at_retrieval\\\": Account age of requester in days at time of retrieval.\\n\\n\\\"requester_days_since_first_post_on_raop_at_request\\\": Number of days between requesters first post on RAOP and this request (zero if requester has never posted before on RAOP).\\n\\n\\\"requester_days_since_first_post_on_raop_at_retrieval\\\": Number of days between requesters first post on RAOP and time of retrieval.\\n\\n\\\"requester_number_of_comments_at_request\\\": Total number of comments on Reddit by requester at time of request.\\n\\n\\\"requester_number_of_comments_at_retrieval\\\": Total number of comments on Reddit by requester at time of retrieval.\\n\\n\\\"requester_number_of_comments_in_raop_at_request\\\": Total number of comments in RAOP by requester at time of request.\\n\\n\\\"requester_number_of_comments_in_raop_at_retrieval\\\": Total number of comments in RAOP by requester at time of retrieval.\\n\\n\\\"requester_number_of_posts_at_request\\\": Total number of posts on Reddit by requester at time of request.\\n\\n\\\"requester_number_of_posts_at_retrieval\\\": Total number of posts on Reddit by requester at time of retrieval.\\n\\n\\\"requester_number_of_posts_on_raop_at_request\\\": Total number of posts in RAOP by requester at time of request.\\n\\n\\\"requester_number_of_posts_on_raop_at_retrieval\\\": Total number of posts in RAOP by requester at time of retrieval.\\n\\n\\\"requester_number_of_subreddits_at_request\\\": The number of subreddits in which the author had already posted in at the time of request.\\n\\n\\\"requester_received_pizza\\\": Boolean indicating the success of the request, i.e., whether the requester received pizza.\\n\\n\\\"requester_subreddits_at_request\\\": The list of subreddits in which the author had already posted in at the time of request.\\n\\n\\\"requester_upvotes_minus_downvotes_at_request\\\": Difference of total upvotes and total downvotes of requester at time of request.\\n\\n\\\"requester_upvotes_minus_downvotes_at_retrieval\\\": Difference of total upvotes and total downvotes of requester at time of retrieval.\\n\\n\\\"requester_upvotes_plus_downvotes_at_request\\\": Sum of total upvotes and total downvotes of requester at time of request.\\n\\n\\\"requester_upvotes_plus_downvotes_at_retrieval\\\": Sum of total upvotes and total downvotes of requester at time of retrieval.\\n\\n\\\"requester_user_flair\\\": Users on RAOP receive badges (Reddit calls them flairs) which is a small picture next to their username. In our data set the user flair is either None (neither given nor received pizza, N=4282), \\\"shroom\\\" (received pizza, but not given, N=1306), or \\\"PIF\\\" (pizza given after having received, N=83).\\n\\n\\\"requester_username\\\": Reddit username of requester.\\n\\n\\\"unix_timestamp_of_request\\\": Unix timestamp of request (supposedly in timezone of user, but in most cases it is equal to the UTC timestamp -- which is incorrect since most RAOP users are from the USA).\\n\\n\\\"unix_timestamp_of_request_utc\\\": Unit timestamp of request in UTC.\", \"is_error\": false}",
        "tool.duration_ms": 0.37550926208496094
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "dda57fac8cda22e0",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "CreateNotebookTool",
      "kind": "INTERNAL",
      "start_time": 1767958514875363679,
      "end_time": 1767958515852410509,
      "duration": 0.97704683,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "CreateNotebookTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.CreateNotebookTool object at 0x7f38e8369e90>\", \"input\": {\"notebook_path\": \"eda.ipynb\", \"cells\": [{\"cell_type\": \"code\", \"content\": \"import pandas as pd\\nimport numpy as np\\nimport json\\n\\n# Load the training data\\ntrain_path = \\\"/home/data/train.json\\\"\\n\\n# Read the JSON file\\ntrain_data = []\\nwith open(train_path, 'r') as f:\\n    for line in f:\\n        train_data.append(json.loads(line))\\n\\ntrain_df = pd.DataFrame(train_data)\\nprint(f\\\"Training data shape: {train_df.shape}\\\")\\nprint(f\\\"Columns: {train_df.columns.tolist()}\\\")\\nprint(\\\"\\\\nFirst few rows:\\\")\\ntrain_df.head()\"}, {\"cell_type\": \"code\", \"content\": \"# Check target distribution\\ntarget_col = 'requester_received_pizza'\\nprint(f\\\"Target distribution:\\\")\\nprint(train_df[target_col].value_counts())\\nprint(f\\\"\\\\nTarget percentages:\\\")\\nprint(train_df[target_col].value_counts(normalize=True) * 100)\\n\\n# Check for missing values\\nprint(f\\\"\\\\nMissing values:\\\")\\nprint(train_df.isnull().sum().sort_values(ascending=False).head(10))\"}]}}",
        "tool.output": "{\"content\": \"Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\", \"is_error\": false}",
        "tool.duration_ms": 977.0684242248535
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "58841cadf5d0ef0d",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767958525379646536,
      "end_time": 1767958525979002030,
      "duration": 0.599355494,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 0, \"end_cell\": 1, \"duration\": 60}}",
        "tool.output": "{\"content\": \"Error: JSONDecodeError: Expecting value: line 2 column 1 (char 2)\", \"is_error\": true}",
        "tool.duration_ms": 599.4210243225098
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "196a3648d4254e49",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "BashTool",
      "kind": "INTERNAL",
      "start_time": 1767958531446056721,
      "end_time": 1767958531448871299,
      "duration": 0.002814578,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "BashTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.BashTool object at 0x7f38e836a310>\", \"input\": {\"command\": \"head -20 /home/data/train.json\"}}",
        "tool.output": "{\"content\": \"[\\n    {\\n        \\\"giver_username_if_known\\\": \\\"N/A\\\",\\n        \\\"number_of_downvotes_of_request_at_retrieval\\\": 2,\\n        \\\"number_of_upvotes_of_request_at_retrieval\\\": 5,\\n        \\\"post_was_edited\\\": false,\\n        \\\"request_id\\\": \\\"t3_q8ycf\\\",\\n        \\\"request_number_of_comments_at_retrieval\\\": 0,\\n        \\\"request_text\\\": \\\"I will soon be going on a long deployment which I'm not aloud to discuss but willing to give some info if you ask. Just wanna eat some of the stuff America has to offer before I leave for a long time to Afganistan.\\\",\\n        \\\"request_text_edit_aware\\\": \\\"I will soon be going on a long deployment which I'm not aloud to discuss but willing to give some info if you ask. Just wanna eat some of the stuff America has to offer before I leave for a long time to Afganistan.\\\",\\n        \\\"request_title\\\": \\\"[REQUEST] Oceanside, Ca. USA-  US Marine getting ready to deploy.\\\",\\n        \\\"requester_account_age_in_days_at_request\\\": 0.0,\\n        \\\"requester_account_age_in_days_at_retrieval\\\": 647.2970601851852,\\n        \\\"requester_days_since_first_post_on_raop_at_request\\\": 0.0,\\n        \\\"requester_days_since_first_post_on_raop_at_retrieval\\\": 647.2970601851852,\\n        \\\"requester_number_of_comments_at_request\\\": 0,\\n        \\\"requester_number_of_comments_at_retrieval\\\": 0,\\n        \\\"requester_number_of_comments_in_raop_at_request\\\": 0,\\n        \\\"requester_number_of_comments_in_raop_at_retrieval\\\": 0,\\n        \\\"requester_number_of_posts_at_request\\\": 0,\\n\", \"is_error\": false}",
        "tool.duration_ms": 2.8684139251708984
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "39774f125404a8a8",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "EditNotebookCellTool",
      "kind": "INTERNAL",
      "start_time": 1767958542915354792,
      "end_time": 1767958542916492559,
      "duration": 0.001137767,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "EditNotebookCellTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.EditNotebookCellTool object at 0x7f38e836ae10>\", \"input\": {\"cell_index\": 0, \"new_content\": \"import pandas as pd\\nimport numpy as np\\nimport json\\n\\n# Load the training data\\ntrain_path = \\\"/home/data/train.json\\\"\\n\\n# Read the JSON file as a JSON array\\nwith open(train_path, 'r') as f:\\n    train_data = json.load(f)\\n\\ntrain_df = pd.DataFrame(train_data)\\nprint(f\\\"Training data shape: {train_df.shape}\\\")\\nprint(f\\\"Columns: {train_df.columns.tolist()}\\\")\\nprint(\\\"\\\\nFirst few rows:\\\")\\ntrain_df.head()\"}}",
        "tool.output": "{\"content\": \"Edited cell 0. Re-run to update kernel state.\", \"is_error\": false}",
        "tool.duration_ms": 1.2218952178955078
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "d7cb59ad85afad40",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767958548175251830,
      "end_time": 1767958548246062120,
      "duration": 0.07081029,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 0, \"end_cell\": 0, \"duration\": 60}}",
        "tool.output": "{\"content\": \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\nimport json\\n\\n# Load the training data\\ntrain_path = \\\"/home/data/train.json\\\"\\n\\n# Read the JSON file as a JSON array\\nwith open(train_path, 'r') as f:\\n    train_data = json.load(f)\\n\\ntrain_df = pd.DataFrame(train_data)\\nprint(f\\\"Training data shape: {train_df.shape}\\\")\\nprint(f\\\"Columns: {train_df.columns.tolist()}\\\")\\nprint(\\\"\\\\nFirst few rows:\\\")\\ntrain_df.head()\\n```\\nOutput:\\nTraining data shape: (2878, 32)\\nColumns: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\\n\\nFirst few rows:\\n\\n  giver_username_if_known  number_of_downvotes_of_request_at_retrieval  \\\\\\n0                     N/A                                            2   \\n1                     N/A                                            2   \\n2                     N/A                                            1   \\n3                     N/A                                            1   \\n4                     N/A                                            3   \\n\\n   number_of_upvotes_of_request_at_retrieval post_was_edited request_id  \\\\\\n0                                          5           False   t3_q8ycf   \\n1                                          4           False   t3_ixnia   \\n2                                          2            True   t3_ndy6g   \\n3                                          1    1363315140.0  t3_1abbu1   \\n4                                         14           False   t3_kseg4   \\n\\n   request_number_of_comments_at_retrieval  \\\\\\n0                                        0   \\n1                                       20   \\n2                                        0   \\n3                                       32   \\n4                                        3   \\n\\n                                        request_text  \\\\\\n0  I will soon be going on a long deployment whic...   \\n1  We would all really appreciate it, and would e...   \\n2  It took a lot of courage to make this post, an...   \\n3  I will go ahead and say that I got a pizza mea...   \\n4  My '99 Jeep Cherokee I've had for 10 years now...   \\n\\n                             request_text_edit_aware  \\\\\\n0  I will soon be going on a long deployment whic...   \\n1  We would all really appreciate it, and would e...   \\n2  It took a lot of courage to make this post, an...   \\n3  I will go ahead and say that I got a pizza mea...   \\n4  My '99 Jeep Cherokee I've had for 10 years now...   \\n\\n                                       request_title  \\\\\\n0  [REQUEST] Oceanside, Ca. USA-  US Marine getti...   \\n1  [REQUEST] Three (verified) medical students in...   \\n2  (REQUEST) not home 4 the holidays &amp; would ...   \\n3            [REQUEST] Not much food until tomorrow.   \\n4                  [Request] Had my car stolen today   \\n\\n   requester_account_age_in_days_at_request  ...  requester_received_pizza  \\\\\\n0                                  0.000000  ...                     False   \\n1                                 99.526863  ...                     False   \\n2                                  0.000000  ...                     False   \\n3                                491.088264  ...                      True   \\n4                                369.417558  ...                     False   \\n\\n                     requester_subreddits_at_request  \\\\\\n0                             [Random_Acts_Of_Pizza]   \\n1  [AskReddit, IAmA, TwoXChromosomes, circlejerk,...   \\n2                             [Random_Acts_Of_Pizza]   \\n3  [Entroductions, RandomActsOfChristmas, RandomK...   \\n4  [DetroitRedWings, DoesAnybodyElse, FoodPorn, K...   \\n\\n   requester_upvotes_minus_downvotes_at_request  \\\\\\n0                                             3   \\n1                                           491   \\n2                                             1   \\n3                                            25   \\n4                                           942   \\n\\n   requester_upvotes_minus_downvotes_at_retrieval  \\\\\\n0                                               3   \\n1                                             883   \\n2                                               1   \\n3                                              21   \\n4                                            2043   \\n\\n   requester_upvotes_plus_downvotes_at_request  \\\\\\n0                                            7   \\n1                                         1459   \\n2                                            3   \\n3                                          165   \\n4                                         1906   \\n\\n   requester_upvotes_plus_downvotes_at_retrieval  requester_user_flair  \\\\\\n0                                              7                  None   \\n1                                           2187                  None   \\n2                                              3                  None   \\n3                                            195                shroom   \\n4                                           3483                  None   \\n\\n     requester_username  unix_timestamp_of_request  \\\\\\n0              SDMarine               1.330391e+09   \\n1  TheycallmeFoxJohnson               1.311434e+09   \\n2         riverfrontmom               1.323968e+09   \\n3              Joeramos               1.363305e+09   \\n4                 m4ngo               1.317088e+09   \\n\\n   unix_timestamp_of_request_utc  \\n0                   1.330391e+09  \\n1                   1.311430e+09  \\n2                   1.323968e+09  \\n3                   1.363301e+09  \\n4                   1.317084e+09  \\n\\n[5 rows x 32 columns]\", \"is_error\": false}",
        "tool.duration_ms": 70.82653045654297
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "b7c351d9acfd4864",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "AddNotebookCellTool",
      "kind": "INTERNAL",
      "start_time": 1767958558831561013,
      "end_time": 1767958558833460886,
      "duration": 0.001899873,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "AddNotebookCellTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Check target distribution\\ntarget_col = 'requester_received_pizza'\\nprint(f\\\"Target distribution:\\\")\\nprint(train_df[target_col].value_counts())\\nprint(f\\\"\\\\nTarget percentages:\\\")\\nprint(train_df[target_col].value_counts(normalize=True) * 100)\\n\\n# Check for missing values\\nprint(f\\\"\\\\nMissing values:\\\")\\nmissing_counts = train_df.isnull().sum().sort_values(ascending=False)\\nprint(missing_counts[missing_counts > 0])\\n\\n# Check data types\\nprint(f\\\"\\\\nData types:\\\")\\nprint(train_df.dtypes.value_counts())\"}}",
        "tool.output": "{\"content\": \"Added code cell at 2\", \"is_error\": false}",
        "tool.duration_ms": 1.9538402557373047
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "ee541be96647da01",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767958563354223659,
      "end_time": 1767958563368638502,
      "duration": 0.014414843,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 2, \"end_cell\": 2, \"duration\": 30}}",
        "tool.output": "{\"content\": \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Check target distribution\\ntarget_col = 'requester_received_pizza'\\nprint(f\\\"Target distribution:\\\")\\nprint(train_df[target_col].value_counts())\\nprint(f\\\"\\\\nTarget percentages:\\\")\\nprint(train_df[target_col].value_counts(normalize=True) * 100)\\n\\n# Check for missing values\\nprint(f\\\"\\\\nMissing values:\\\")\\nmissing_counts = train_df.isnull().sum().sort_values(ascending=False)\\nprint(missing_counts[missing_counts > 0])\\n\\n# Check data types\\nprint(f\\\"\\\\nData types:\\\")\\nprint(train_df.dtypes.value_counts())\\n```\\nOutput:\\nTarget distribution:\\nrequester_received_pizza\\nFalse    2163\\nTrue      715\\nName: count, dtype: int64\\n\\nTarget percentages:\\nrequester_received_pizza\\nFalse    75.156359\\nTrue     24.843641\\nName: proportion, dtype: float64\\n\\nMissing values:\\nrequester_user_flair    2163\\ndtype: int64\\n\\nData types:\\nint64      16\\nobject      9\\nfloat64     6\\nbool        1\\nName: count, dtype: int64\\n\", \"is_error\": false}",
        "tool.duration_ms": 14.472723007202148
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "d7350ef89fd1c97a",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "AddNotebookCellTool",
      "kind": "INTERNAL",
      "start_time": 1767958579564227270,
      "end_time": 1767958579566279454,
      "duration": 0.002052184,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "AddNotebookCellTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Analyze text features\\nprint(\\\"Text feature analysis:\\\")\\nprint(f\\\"\\\\nRequest title length stats:\\\")\\ntrain_df['request_title_length'] = train_df['request_title'].str.len()\\nprint(train_df['request_title_length'].describe())\\n\\nprint(f\\\"\\\\nRequest text length stats:\\\")\\ntrain_df['request_text_length'] = train_df['request_text'].str.len()\\nprint(train_df['request_text_length'].describe())\\n\\nprint(f\\\"\\\\nRequest text edit aware length stats:\\\")\\ntrain_df['request_text_edit_aware_length'] = train_df['request_text_edit_aware'].str.len()\\nprint(train_df['request_text_edit_aware_length'].describe())\\n\\n# Check correlation with target\\nprint(f\\\"\\\\nCorrelation with target:\\\")\\nprint(f\\\"Title length correlation: {train_df['request_title_length'].corr(train_df[target_col].astype(int)):.4f}\\\")\\nprint(f\\\"Text length correlation: {train_df['request_text_length'].corr(train_df[target_col].astype(int)):.4f}\\\")\\nprint(f\\\"Text edit aware length correlation: {train_df['request_text_edit_aware_length'].corr(train_df[target_col].astype(int)):.4f}\\\")\"}}",
        "tool.output": "{\"content\": \"Added code cell at 3\", \"is_error\": false}",
        "tool.duration_ms": 2.112865447998047
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "a52950272be9d220",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767958586302608118,
      "end_time": 1767958586321461665,
      "duration": 0.018853547,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 3, \"end_cell\": 3, \"duration\": 30}}",
        "tool.output": "{\"content\": \"Executed cells 3-3\\n==================================================\\n\\nCell 3:\\n```\\n# Analyze text features\\nprint(\\\"Text feature analysis:\\\")\\nprint(f\\\"\\\\nRequest title length stats:\\\")\\ntrain_df['request_title_length'] = train_df['request_title'].str.len()\\nprint(train_df['request_title_length'].describe())\\n\\nprint(f\\\"\\\\nRequest text length stats:\\\")\\ntrain_df['request_text_length'] = train_df['request_text'].str.len()\\nprint(train_df['request_text_length'].describe())\\n\\nprint(f\\\"\\\\nRequest text edit aware length stats:\\\")\\ntrain_df['request_text_edit_aware_length'] = train_df['request_text_edit\\n```\\nOutput:\\nText feature analysis:\\n\\nRequest title length stats:\\ncount    2878.000000\\nmean       71.572967\\nstd        36.233487\\nmin         7.000000\\n25%        46.000000\\n50%        64.000000\\n75%        90.000000\\nmax       272.000000\\nName: request_title_length, dtype: float64\\n\\nRequest text length stats:\\ncount    2878.000000\\nmean      402.521543\\nstd       362.393727\\nmin         0.000000\\n25%       182.000000\\n50%       308.000000\\n75%       503.750000\\nmax      4460.000000\\nName: request_text_length, dtype: float64\\n\\nRequest text edit aware length stats:\\ncount    2878.000000\\nmean      394.567755\\nstd       351.922518\\nmin         0.000000\\n25%       180.000000\\n50%       302.000000\\n75%       498.000000\\nmax      4460.000000\\nName: request_text_edit_aware_length, dtype: float64\\n\\nCorrelation with target:\\nTitle length correlation: 0.0146\\nText length correlation: 0.1301\\nText edit aware length correlation: 0.1199\\n\", \"is_error\": false}",
        "tool.duration_ms": 18.898487091064453
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "eb4c51c8962c8ead",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "WebSearchTool",
      "kind": "INTERNAL",
      "start_time": 1767958594675568417,
      "end_time": 1767958600636939856,
      "duration": 5.961371439,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "WebSearchTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What are winning approaches for text classification with tabular features on Kaggle?\"}}",
        "tool.output": "{\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nWinning Kaggle solutions for problems that mix free‚Äëtext columns with ordinary numeric or categorical fields treat the data as **multimodal** and deliberately combine a strong NLP encoder with classic tabular learners.  In practice the most reliable recipe is a three‚Äëstep pipeline:  \\n\\n1. **Encode the raw text** with a pretrained transformer (e.g., BERT, RoBERTa) to obtain dense sentence‚Äëlevel embeddings.  AutoGluon‚Äôs‚ÄØ`TextPredictor` can do this automatically and returns embeddings that can be fed to any tabular model‚ÄØ([auto.gluon.ai](https://auto.gluon.ai/0.7.0/tutorials/tabular_prediction/tabular-multimodal-text-others.html)).  \\n2. **Merge the embeddings with the structured features** ‚Äì either by concatenating them to the numeric/categorical matrix (the ‚Äútwo‚Äëstage‚Äù approach evaluated in the multimodal AutoML benchmark‚ÄØ([datasets‚Äëbenchmarks‚Äëproceedings.neurips.cc](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/9bf31c7ff062936a96d3c8bd1f8f2ff3-Abstract-round2.html))) or by converting the auxiliary columns into a short textual description and prepending it to the original document (the ‚Äúfeatures‚Äëto‚Äëtext‚Äù trick that proved best on a 23‚ÄØk clothing‚Äëreview dataset‚ÄØ([mccormickml.com](https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert))) .  \\n3. **Train high‚Äëperforming tabular models on the combined matrix** ‚Äì LightGBM, CatBoost or Random Forest are the workhorses, and they can be stacked or blended with the original transformer model itself.  The Multimodal‚ÄëToolkit library provides a ready‚Äëto‚Äëuse wrapper that integrates Hugging‚ÄØFace tokenizers with these tabular learners, making the stacking process straightforward‚ÄØ([aclanthology.org](https://aclanthology.org/2021.maiworkshop-1.10.pdf)).\\n\\nBeyond the core pipeline, Kaggle Grandmasters repeatedly stress a few complementary tricks that turn a good baseline into a winning one:  \\n\\n* **Target‚Äëencode high‚Äëcardinality categoricals** before feeding them to the tabular model, and apply the same encoding to the text‚Äëembedding features.  \\n* **Use GPU‚Äëaccelerated training** for the transformer part (e.g., via AutoGluon or the Multimodal‚ÄëToolkit) to explore larger pretrained checkpoints without prohibitive runtime‚ÄØ([developer.nvidia.com](https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data)).  \\n* **Ensemble multiple modalities** ‚Äì blend a pure‚Äëtext model, a pure‚Äëtabular model, and a multimodal model (embeddings‚ÄØ+‚ÄØfeatures) using simple weighted averages or stacking with a meta‚Äëlearner.  This strategy consistently appears in the ‚Äútips and tricks‚Äù posts that summarize top‚Äë5 Kaggle competitions‚ÄØ([neptune.ai](https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions)).  \\n\\nIn short, the winning Kaggle playbook for text classification with tabular features is to **extract high‚Äëquality transformer embeddings, fuse them with engineered numeric/categorical columns, and train/ensemble strong gradient‚Äëboosting models** ‚Äì all while leveraging GPU‚Äëfriendly libraries (AutoGluon, Multimodal‚ÄëToolkit) and proven Kaggle‚Äëspecific preprocessing tricks.\\n\\n--- Result 2 ---\\nTitle: Combining BERT/Transformers and Classical Tabular Models ‚Äî AutoGluon Documentation 0.7.0 documentation\\nURL: https://auto.gluon.ai/0.7.0/tutorials/tabular_prediction/tabular-multimodal-text-others.html\\n\\nContent:\\n<div><div>\\n<h2>Multimodal Data Tables: Combining BERT/Transformers and Classical Tabular Models<a href=\\\"#multimodal-data-tables-combining-bert-transformers-and-classical-tabular-models\\\">¬∂</a></h2>\\n<p><strong>Tip</strong>: If your data contains images, consider also checking out\\n<a href=\\\"https://auto.gluon.ai/0.7.0/tutorials/tabular_prediction/tabular-multimodal.html#sec-tabularprediction-multimodal\\\"><span>Multimodal Data Tables: Tabular, Text, and Image</span></a> which handles images in\\naddition to text and tabular features.</p>\\n<p>Here we introduce how to use AutoGluon Tabular to deal with multimodal\\ntabular data that contains text, numeric, and categorical columns. In\\nAutoGluon, <strong>raw text data</strong> is considered as a first-class citizen of\\ndata tables. AutoGluon Tabular can help you train and combine a diverse\\nset of models including classical tabular models like\\nLightGBM/RF/CatBoost as well as our pretrained NLP model based\\nmultimodal network that is introduced in Section\\n‚Äú<span>sec_textprediction_architecture</span>‚Äù of\\n<span>sec_textprediction_multimodal</span> (used by AutoGluon‚Äôs\\n<code><span>TextPredictor</span></code>).</p>\\n<div><pre><span></span><span>%</span><span>matplotlib</span> <span>inline</span>\\n<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>\\n<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>\\n<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>\\n<span>import</span> <span>pprint</span>\\n<span>import</span> <span>random</span>\\n<span>from</span> <span>autogluon.tabular</span> <span>import</span> <span>TabularPredictor</span>\\n<span>np</span><span>.</span><span>random</span><span>.</span><span>seed</span><span>(</span><span>123</span><span>)</span>\\n<span>random</span><span>.</span><span>seed</span><span>(</span><span>123</span><span>)</span>\\n</pre></div>\\n<div>\\n<h2>Product Sentiment Analysis Dataset<a href=\\\"#product-sentiment-analysis-dataset\\\">¬∂</a></h2>\\n<p>We consider the product sentiment analysis dataset from a <a href=\\\"https://www.machinehack.com/hackathons/product_sentiment_classification_weekend_hackathon_19/leaderboard\\\">MachineHack\\nhackathon</a>.\\nThe goal is to predict a user‚Äôs sentiment towards a product given their\\nreview (raw text) and a categorical feature indicating the product‚Äôs\\ntype (e.g., Tablet, Mobile, etc.). We have already split the original\\ndataset to be 90% for training and 10% for development/testing (if\\nsubmitting your models to the hackathon, we recommend training them on\\n100% of the dataset).</p>\\n<div><pre><span></span>!mkdir -p product_sentiment_machine_hack\\n!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/train.csv -O product_sentiment_machine_hack/train.csv\\n!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/dev.csv -O product_sentiment_machine_hack/dev.csv\\n!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/test.csv -O product_sentiment_machine_hack/test.csv\\n</pre></div>\\n<div><pre><span></span>--2023-02-22 23:29:24-- https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/train.csv\\nResolving autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)... 52.217.130.97, 52.217.110.220, 52.216.137.228, ...\\nConnecting to autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)|52.217.130.97|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 689486 (673K) [text/csv]\\nSaving to: ‚Äòproduct_sentiment_machine_hack/train.csv‚Äô\\nproduct_sentiment_m 100%[===================&gt;] 673.33K --.-KB/s in 0.009s\\n2023-02-22 23:29:24 (73.9 MB/s) - ‚Äòproduct_sentiment_machine_hack/train.csv‚Äô saved [689486/689486]\\n--2023-02-22 23:29:24-- https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/dev.csv\\nResolving autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)... 52.216.10.27, 52.217.225.57, 3.5.11.212, ...\\nConnecting to autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)|52.216.10.27|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 75517 (74K) [text/csv]\\nSaving to: ‚Äòproduct_sentiment_machine_hack/dev.csv‚Äô\\nproduct_sentiment_m 100%[===================&gt;] 73.75K --.-KB/s in 0.001s\\n2023-02-22 23:29:24 (57.6 MB/s) - ‚Äòproduct_sentiment_machine_hack/dev.csv‚Äô saved [75517/75517]\\n--2023-02-22 23:29:24-- https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/test.csv\\nResolving autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)... 52.217.130.97, 52.216.10.27, 52.217.225.57, ...\\nConnecting to autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)|52.217.130.97|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 312194 (305K) [text/csv]\\nSaving to: ‚Äòproduct_sentiment_machine_hack/test.csv‚Äô\\nproduct_sentiment_m 100%[===================&gt;] 304.88K --.-KB/s in 0.002s\\n2023-02-22 23:29:24 (137 MB/s) - ‚Äòproduct_sentiment_machine_hack/test.csv‚Äô saved [312194/312194]\\n</pre></div>\\n<div><pre><span></span><span>subsample_size</span> <span>=</span> <span>2000</span> <span># for quick demo, try setting to larger values</span>\\n<span>feature_columns</span> <span>=</span> <span>[</span><span>'Product_Description'</span><span>,</span> <span>'Product_Type'</span><span>]</span>\\n<span>label</span> <span>=</span> <span>'Sentiment'</span>\\n<span>train_df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'product_sentiment_machine_hack/train.csv'</span><span>,</span> <span>index_col</span><span>=</span><span>0</span><span>)</span><span>.</span><span>sample</span><span>(</span><span>2000</span><span>,</span> <span>random_state</span><span>=</span><span>123</span><span>)</span>\\n<span>dev_df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'product_sentiment_machine_hack/dev.csv'</span><span>,</span> <span>index_col</span><span>=</span><span>0</span><span>)</span>\\n<span>test_df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'product_sentiment_machine_hack/test.csv'</span><span>,</span> <span>index_col</span><span>=</span><span>0</span><span>)</span>\\n<span>train_df</span> <span>=</span> <span>train_df</span><span>[</span><span>feature_columns</span> <span>+</span> <span>[</span><span>label</span><span>]]</span>\\n<span>dev_df</span> <span>=</span> <span>dev_df</span><span>[</span><span>feature_columns</span> <span>+</span> <span>[</span><span>label</span><span>]]</span>\\n<span>test_df</span> <span>=</span> <span>test_df</span><span>[</span><span>feature_columns</span><span>]</span>\\n<span>print</span><span>(</span><span>'Number of training samples:'</span><span>,</span> <span>len</span><span>(</span><span>train_df</span><span>))</span>\\n<span>print</span><span>(</span><span>'Number of dev samples:'</span><span>,</span> <span>len</span><span>(</span><span>dev_df</span><span>))</span>\\n<span>print</span><span>(</span><span>'Number of test samples:'</span><span>,</span> <span>len</span><span>(</span><span>test_df</span><span>))</span>\\n</pre></div>\\n<div><pre><span></span><span>Number</span> <span>of</span> <span>training</span> <span>samples</span><span>:</span> <span>2000</span>\\n<span>Number</span> <span>of</span> <span>dev</span> <span>samples</span><span>:</span> <span>637</span>\\n<span>Number</span> <span>of</span> <span>test</span> <span>samples</span><span>:</span> <span>2728</span>\\n</pre></div>\\n<p>There are two features in the dataset: the users‚Äô review of the product\\nand the product‚Äôs type, and four possible classes to predict.</p>\\n<div>\\n<table>\\n <thead>\\n <tr>\\n <th></th>\\n <th>Product_Description</th>\\n <th>Product_Type</th>\\n <th>Sentiment</th>\\n </tr>\\n </thead>\\n <tbody>\\n <tr>\\n <th>4532</th>\\n <td>they took away the lego pit but ...\\n\\n--- Result 3 ---\\nTitle: Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\\nURL: https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions\\n\\nContent:\\nTabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions[\\n**üì£ BIG NEWS:****Neptune is joining OpenAI!**‚Üí Read the message from our CEO üì£![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\\nWhat do you want to find?\\nSearch\\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Neptune Blog](https://neptune.ai/blog)# Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Shahul-Es-new-scaled.jpeg?fit=2560%2C1920&ssl=1)\\n[Shahul ES](https://neptune.ai/blog/author/shahules)\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)3 min\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)1st September, 2023\\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)[Tabular Data](https://neptune.ai/blog/category/tabular-data)\\nIn this article, I will discuss some great tips and tricks to improve the performance of your structured data binary classification model. These tricks are obtained from solutions of some of Kaggle‚Äôs top tabular data competitions. Without much lag, let‚Äôs begin.\\nThese are the five competitions that I have gone through to create this article:\\n* [**Home credit default risk**](https://www.kaggle.com/c/home-credit-default-risk/)\\n* [**Santander Customer Transaction Prediction**](https://www.kaggle.com/c/santander-customer-transaction-prediction/notebooks)\\n* [**VSB Power Line Fault Detection**](https://www.kaggle.com/c/vsb-power-line-fault-detection/overview/evaluation)\\n* [**Microsoft Malware Prediction**](https://www.kaggle.com/c/microsoft-malware-prediction/overview)\\n* [**IEEE-CIS Fraud Detection**](https://www.kaggle.com/c/ieee-fraud-detection/overview/evaluation/)## Dealing with larger datasets\\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\\n* Faster[data loading with pandas.](https://www.kaggle.com/c/home-credit-default-risk/discussion/59575)\\n* Data compression techniques to[reduce the size of data by 70%](https://www.kaggle.com/nickycan/compress-70-of-dataset).\\n* Optimize the memory by r[educing the size of some attributes.](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\\n* Use open-source libraries such as[Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space.\\n* Use[cudf](https://github.com/rapidsai/cudf).\\n* Convert data to[parquet](https://arrow.apache.org/docs/python/parquet.html)format.\\n* Converting data to[feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03)format.\\n* Reducing memory usage for[optimizing RAM](https://www.kaggle.com/mjbahmani/reducing-memory-size-for-ieee).## Data exploration\\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\\n* EDA for microsoft[malware detection.](https://www.kaggle.com/youhanlee/my-eda-i-want-to-see-all)\\n* Time Series[EDA for malware detection.](https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68)\\n* Complete[EDA for home credit loan prediction](https://www.kaggle.com/codename007/home-credit-complete-eda-feature-importance).\\n* Complete[EDA for Santader prediction.](https://www.kaggle.com/gpreda/santander-eda-and-prediction)\\n* EDA for[VSB Power Line Fault Detection.](https://www.kaggle.com/go1dfish/basic-eda)## Data preparation\\nAfter data exploration, the first thing to do is to use those insights to prepare the data. To tackle issues like class imbalance, encoding categorical data, etc. Let‚Äôs see the methods used to do it.\\n* Methods to t[ackle class imbalance](https://www.kaggle.com/shahules/tackling-class-imbalance).\\n* Data augmentation by[Synthetic Minority Oversampling Technique](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/).\\n* Fast inplace[shuffle for augmentation](https://www.kaggle.com/jiweiliu/fast-inplace-shuffle-for-augmentation).\\n* Finding[synthetic samples in the dataset.](https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split)\\n* [Signal denoising](https://www.kaggle.com/jackvial/dwt-signal-denoising)used in signal processing competitions.\\n* Finding[patterns of missing data](https://www.kaggle.com/jpmiller/patterns-of-missing-data).\\n* Methods to handle[missing data](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779).\\n* An overview of various[encoding techniques for categorical data.](https://www.kaggle.com/shahules/an-overview-of-encoding-techniques)\\n* Building[model to predict missing values.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64598)\\n* Random[shuffling of data](https://www.kaggle.com/brandenkmurray/randomly-shuffled-data-also-works)to create new synthetic training set.## Feature engineering\\nNext, you can check the most popular feature and feature engineering techniques used in these top kaggle competitions. The feature engineering part varies from problem to problem depending on the domain.\\n* Target[encoding cross validation](https://medium.com/@pouryaayria/k-fold-target-encoding-dfe9a594874b/)for better encoding.\\n* Entity embedding to[handle categories](https://www.kaggle.com/abhishek/entity-embeddings-to-handle-categories).\\n* Encoding c[yclic features for deep learning.](https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning)\\n* Manual[feature engineering methods](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering).\\n* Automated feature engineering techniques[using featuretools](https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics).\\n* Top hard crafted features used in[microsoft malware detection](https://www.kaggle.com/sanderf/7th-place-solution-microsoft-malware-prediction).\\n* Denoising NN for[feature extraction](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798).\\n* Feature engineering[using RAPIDS framework.](https://www.kaggle.com/cdeotte/rapids-feature-engineering-fraud-0-96/)\\n* Things to remember while processing f[eatures using LGBM.](https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575)\\n* [Lag features and moving averages.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64593)\\n* [Principal component analysis](https://medium.com/machine-learning-researcher/dimensionality-reduction-pca-and-lda-6be91734f567)for...\\n\\n--- Result 4 ---\\nURL: https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert\\n\\nContent:\\n# Combining Categorical and Numerical Features with Text in BERT\\n\\n29 Jun 2021\\n\\nIn this tutorial we‚Äôll look at the topic of classifying text with BERT, but where we also have additional numerical or categorical features that we want to use to improve our predictions.\\n\\nTo help motivate our discussion, we‚Äôll be working with a dataset of about 23k clothing reviews. For each review, we have the review text, but also additional information such as:\\n\\n- The age of the reviewer (numerical feature)\\n- The number of upvotes on the review (numerical feature)\\n- The department and category of the clothing item (categorical features)\\n\\nFor each review, we also have a binary label, which is whether or not the reviewer ultimately recommends the item. This is what we are trying to predict.\\n\\nThis dataset was scraped from an (un-specified) e-commerce website by Nick Brooks and made available on Kaggle [here](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews).\\n\\nIn Section 2 of this Notebook, I‚Äôve implemented four different ‚Äúbaseline‚Äù strategies which score fairly well, but which don‚Äôt incorporate all of the features together.\\n\\nThen, in Section 3, I‚Äôve implemented a simple strategy to combine _everything_ and feed it through BERT. Specifically, I make text out of the additional features, and prepend this text to the review.\\n\\nThere is a GitHub project called the [Multimodal-Toolkit](https://github.com/georgian-io/Multimodal-Toolkit) which is how I learned about this clothing review dataset. The toolkit implements a number of more complicated techniques, but their benchmarks (as well as our results below) show that this simple features-to-text strategy works best for this dataset.\\n\\nIn our weekly discussion group, I talked through this Notebook and we also met with Ken Gu, the author of the Multi-Modal Toolkit! You can watch the recording [here](https://youtu.be/XPt9pIpe1vo).\\n\\nYou can find the Colab Notebook version of this post [here](https://colab.research.google.com/drive/1YRHK4HO8RktGzlYmGjBo056kzVD4_j9o).\\n\\nBy Chris McCormick\\n\\n# Contents\\n\\n- [Contents](https://mccormickml.com/mccormickml.com#contents)\\n- [S1. Clothing Review Dataset](https://mccormickml.com/mccormickml.com#s1-clothing-review-dataset)\\n  - [1.1. Download & Parse](https://mccormickml.com/mccormickml.com#11-download--parse)\\n  - [1.2. Train-Validation-Test Split](https://mccormickml.com/mccormickml.com#12-train-validation-test-split)\\n- [S2. Baseline Strategies](https://mccormickml.com/mccormickml.com#s2-baseline-strategies)\\n  - [2.1. Always Recommend](https://mccormickml.com/mccormickml.com#21-always-recommend)\\n  - [2.2. Threshold on Rating](https://mccormickml.com/mccormickml.com#22-threshold-on-rating)\\n  - [2.3. XGBoost](https://mccormickml.com/mccormickml.com#23-xgboost)\\n  - [2.4. BERT on Review Text Only](https://mccormickml.com/mccormickml.com#24-bert-on-review-text-only)\\n- [S3. BERT with All Features](https://mccormickml.com/mccormickml.com#s3-bert-with-all-features)\\n  - [3.1. All Features to Text](https://mccormickml.com/mccormickml.com#31-all-features-to-text)\\n  - [3.2. GPU & Transformers Setup](https://mccormickml.com/mccormickml.com#32-gpu--transformers-setup)\\n  - [3.3. Training Parameters](https://mccormickml.com/mccormickml.com#33-training-parameters)\\n  - [3.3. Tokenize & Encode](https://mccormickml.com/mccormickml.com#33-tokenize--encode)\\n  - [3.4. Training](https://mccormickml.com/mccormickml.com#34-training)\\n    - [3.4.1. Setup](https://mccormickml.com/mccormickml.com#341-setup)\\n    - [3.4.2. Training Loop](https://mccormickml.com/mccormickml.com#342-training-loop)\\n    - [3.4.3. Training Results](https://mccormickml.com/mccormickml.com#343-training-results)\\n  - [3.5. Test](https://mccormickml.com/mccormickml.com#35-test)\\n- [Conclusion](https://mccormickml.com/mccormickml.com#conclusion)\\n\\n# S1. Clothing Review Dataset\\n\\n## 1.1. Download & Parse\\n\\nRetrieve the .csv file for the dataset.\\n\\n```\\nimport gdown\\n\\nprint('Downloading dataset...\\\\n')\\n\\n# Download the file.\\ngdown.download('https://drive.google.com/uc?id=1ZYdt0zN4LjWqP3cQDblNhXjeohcryY5H',\\n                'Womens Clothing E-Commerce Reviews.csv',\\n                quiet=False)\\n\\nprint('\\\\n\\\\nDONE.')\\n```\\n\\n```\\nDownloading dataset...\\n\\nDownloading...\\nFrom: https://drive.google.com/uc?id=1ZYdt0zN4LjWqP3cQDblNhXjeohcryY5H\\nTo: /content/Womens Clothing E-Commerce Reviews.csv\\n8.48MB [00:00, 48.7MB/s]\\n\\nDONE.\\n\\n```\\n\\nParse the dataset csv file into a pandas DataFrame.\\n\\n```\\nimport pandas as pd\\n\\ndata_df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv', index_col=0)\\n\\ndata_df.head()\\n```\\n\\n| Clothing ID | Age | Title | Review Text | Rating | Recommended IND | Positive Feedback Count | Division Name | Department Name | Class Name |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 767 | 33 | NaN | Absolutely wonderful - silky and sexy and comf... | 4 | 1 | 0 | Initmates | Intimate | Intimates |\\n| 1 | 1080 | 34 | NaN | Love this dress! it's sooo pretty. i happene... | 5 | 1 | 4 | General | Dresses | Dresses |\\n| 2 | 1077 | 60 | Some major design flaws | I had such high hopes for this dress and reall... | 3 | 0 | 0 | General | Dresses | Dresses |\\n| 3 | 1049 | 50 | My favorite buy! | I love, love, love this jumpsuit. it's fun, fl... | 5 | 1 | 0 | General Petite | Bottoms | Pants |\\n| 4 | 847 | 47 | Flattering shirt | This shirt is very flattering to all due to th... | 5 | 1 | 6 | General | Tops | Blouses |\\n\\n_Features_\\n\\n‚Äú **Recommended IND**‚Äù is the label we are trying to predict for this dataset. ‚Äú1‚Äù means the reviewer recommended the product and ‚Äú0‚Äù means they do not.\\n\\nThe following are _categorical_ features:\\n\\n- Division Name\\n- Department Name\\n- Class Name\\n- Clothing ID\\n\\nAnd the following are _numerical_ features:\\n\\n- Age\\n- Rating\\n- Positive Feedback Count\\n\\n_Feature Analysis_\\n\\nThere is an excellent Notebook on Kaggle [here](https://www.kaggle.com/bhaveshkumar2806/complete-eda-and-visualization-of-text-data) which does some thorough analysis on each of the features in this dataset.\\n\\nNote that, in addition to the ‚ÄúRecommended‚Äù label, there is also a ‚Äú **Rating**‚Äù column where the reviewer rates the product from 1 - 5. The analysis in the above Notebook shows that almost all items rated 3 - 5 are recommended, and almost all rated 1 - 2 are not recommended. We‚Äôll see in our second baseline classifier that you can get a very high accuracy with this feature alone. However, it _is_ still possible to do better by incorporating the other features!\\n\\n## 1.2. Train-Validation-Test Split\\n\\nI want to use the same training, validation, and test splits for all of the approaches we try so that it‚Äôs a fair comparison.\\n\\nHowever, different approaches are going to require different transformations on the data, and for simplicity I want to apply those transformations _before_ splitting the dataset.\\n\\nTo solve this, we‚Äôre going to create lists of indeces for each of the three portions. That way, for a given classification approach, we can load the whole dataset, apply our transformations, and then split it according to these pre-determined indeces.\\n\\n```\\nimport random\\nimport numpy as np\\n\\n# First, calculate the split sizes. 80% training, 10% validation, 10% test.\\ntrain_size = int(0.8 * len(data_df))\\nval_size = int(0.1 * len(data_df))\\ntest_size = len(data_df) - (train_size + val_size)\\n\\n# Sanity check the sizes.\\nassert((train_size + val_size + test_size) == len(data_df))\\n\\n# Create a list of indeces for all of the samples in the dataset.\\nindeces = np.arange(0, len(data_df))\\n\\n# Shuffle the indeces randomly.\\nrandom.shuffle(indeces)\\n\\n# Get a list of indeces for each of the splits.\\ntrain_idx = indeces[0:train_size]\\nval_idx = indeces[train_size:(train_size + val_size)]\\ntest_idx = indeces[(train_size + val_size):]\\n\\n# Sanity check\\nassert(len(train_idx) == train_size)\\nassert(len(test_idx) == test_size)\\n\\n# With these lists, we can now select the corresponding dataframe rows using,\\n# e.g., train_df = data_df.iloc[train_idx]\\n\\nprint('  Training size: {:,}'.format(train_size))\\n...\\n\\n--- Result 5 ---\\nTitle: The Kaggle Grandmasters Playbook: 7 Battle-Tested Modeling Techniques for Tabular Data\\nURL: https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data\\n\\nContent:\\nThe Kaggle Grandmasters Playbook: 7 Battle&#x2d;Tested Modeling Techniques for Tabular Data | NVIDIA Technical Blog\\n[](https://developer.nvidia.com/)[DEVELOPER](https://developer.nvidia.com/)\\n[Technical Blog](https://developer.nvidia.com/blog)\\n[Subscribe](https://developer.nvidia.com/email-signup)\\n[Related Resources**](#main-content-end)\\n[Data Science](https://developer.nvidia.com/blog/category/data-science/)\\nEnglish‰∏≠Êñá\\n# The Kaggle Grandmasters Playbook: 7 Battle-Tested Modeling Techniques for Tabular Data\\nLessons from years of competitions, made practical with GPU acceleration.\\n![](https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/Kaggle-Grandmasters-Playbook-featured-1024x576-png.webp)\\nSep 18, 2025\\nBy[Kazuki Onodera](https://developer.nvidia.com/blog/author/kazuki-onodera/),[Th√©o Viel](https://developer.nvidia.com/blog/author/tviel/),[Gilberto Titericz](https://developer.nvidia.com/blog/author/gillbertotitericz/)and[Chris Deotte](https://developer.nvidia.com/blog/author/cdeotte/)\\n**\\nLike\\n[**Discuss (1)](#entry-content-comments)\\n* [L](https://www.linkedin.com/sharing/share-offsite/?url=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/)\\n* [T](https://twitter.com/intent/tweet?text=The+Kaggle+Grandmasters+Playbook:+7+Battle-Tested+Modeling+Techniques+for+Tabular+Data+|+NVIDIA+Technical+Blog+https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/)\\n* [F](https://www.facebook.com/sharer/sharer.php?u=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/)\\n* [R](https://www.reddit.com/submit?url=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/&amp;title=The+Kaggle+Grandmasters+Playbook:+7+Battle-Tested+Modeling+Techniques+for+Tabular+Data+|+NVIDIA+Technical+Blog)\\n* [E](<mailto:?subject=I'd like to share a link with you&body=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/>)\\nAI-Generated Summary\\nLike\\nDislike\\n* The authors have developed a playbook for solving real-world tabular problems, refined through hundreds of Kaggle competitions, which emphasizes fast experimentation and careful validation.\\n* Key techniques include using GPU acceleration for dataframe operations and model training with NVIDIA cuML or GPU backends of XGBoost, LightGBM, and CatBoost to enable rapid iteration.\\n* The authors also stress the importance of techniques like k-fold cross-validation, diverse baselines, feature engineering, hill climbing, stacking, pseudo-labeling, and extra training to improve model performance and robustness.\\nAI-generated content may summarize information incompletely. Verify important information.[Learn more](https://www.nvidia.com/en-us/agreements/trustworthy-ai/terms/)\\nOver hundreds of Kaggle competitions, we&#8217;ve refined a playbook that consistently lands us near the top of the leaderboard‚Äîno matter if we‚Äôre working with millions of rows, missing values, or test sets that behave nothing like the training data. This isn‚Äôt just a collection of modeling tricks‚Äîit‚Äôs a repeatable system for solving real-world tabular problems fast.\\nBelow are seven of our most battle-tested techniques, each one made practical through GPU acceleration. Whether you‚Äôre climbing the leaderboard or deploying models in production, these strategies can give you an edge.\\nWe‚Äôve included links to example write-ups or notebooks from past competitions for each technique.\\n**Note:**Kaggle and Google Colab notebooks come with free GPUs and accelerated drop-ins like the ones you‚Äôll see below pre-installed.\\n## Core principles: the foundations of a winning workflow[**](#core_principles_the_foundations_of_a_winning_workflow)\\nBefore diving into techniques, it‚Äôs worth pausing to cover the two principles that power everything in this playbook: fast experimentation and careful validation. These aren‚Äôt optional best practices‚Äîthey‚Äôre the foundation of how we approach every tabular modeling problem.\\n### Fast experimentation[**](#fast_experimentation)\\nThe biggest lever we have in any competition or real-world project is the number of high-quality experiments we can run. The more we iterate, the more patterns we discover‚Äîand the faster we catch when a model is failing, drifting, or overfitting‚Äîso we can course-correct early and improve faster.\\nIn practice, that means we optimize our entire pipeline for speed, not just our model training step.\\n**Here‚Äôs how we make it work:**\\n* Accelerate dataframe operations using[GPU drop-in replacements](https://developer.nvidia.com/blog/7-drop-in-replacements-to-instantly-speed-up-your-python-data-science-workflows/?linkId=100000376196126)for pandas or Polars to transform and engineer features at scale.\\n* Train models with[NVIDIA cuML](https://developer.nvidia.com/topics/ai/data-science/cuda-x-data-science-libraries/cuml)or GPU backends of XGBoost, LightGBM, and CatBoost.\\nGPU acceleration isn‚Äôt just for deep learning‚Äîit&#8217;s often the only way to make advanced tabular techniques practical at scale.\\n### Local Validation[**](#local_validation)\\nIf you can‚Äôt trust your validation score, you‚Äôre flying blind. That‚Äôs why cross-validation (CV) is a cornerstone to our workflow.\\n**Our approach:**\\n* Use k-fold cross-validation, where the model trains on most of the data and tests on the part that‚Äôs held out.\\n* Rotate through folds so every part of the data is tested once.\\nThis gives a much more reliable measure of performance than a single train/validation split.\\n**Pro tip:**Match your CV strategy to how the test data is structured.\\n**For example:**\\n* Use TimeSeriesSplit for time-dependent data\\n* Use GroupKFold for grouped data (like users or patients)\\nWith those foundations in place‚Äîmoving fast and validating carefully‚Äîwe can now dive into the techniques themselves. Each one builds on these principles and shows how we turn raw data into world-class models.\\n## 1. Start with smarter EDA, not just the basics[**](#1_start_with_smarter_eda_not_just_the_basics)\\nMost practitioners know the basics: Check for missing values, outliers, correlations, and feature ranges. Those steps are important, but they‚Äôre table stakes. To build models that hold up in the real world, you need to explore the data a little deeper‚Äîa couple of quick checks that we‚Äôve found useful, but many people miss:\\n**Train vs. test distribution checks:**Spot when evaluation data differs from training, since distribution shift can cause models to validate well but fail in deployment.\\n*Figure 1. Comparing feature distributions between train (blue) and test (red) reveals a clear shift‚Äîtest data is concentrated in a higher range, with minimal overlap. This kind of distribution shift can cause models to validate well but fail in deployment.*\\n**Analyze target variable for temporal patterns:**Check for trends or seasonality, since ignoring temporal patterns can lead to models that look accurate in training but break in production.\\n*Figure 2. Analyzing the target variable over time uncovers a strong upward trend with seasonal fluctuations and accelerating growth. Ignoring temporal patterns like these can mislead models unless time-aware validation is used.*\\nThese techniques aren&#8217;t brand new‚Äîbut they‚Äôre often overlooked, and ignoring them can sink a project.\\n**Why it matters:**Skipping these checks can derail an otherwise solid workflow.\\n**In action:**In the winning solution to the Amazon KDD Cup ‚Äò23, the team uncovered both a train‚Äîtest distribution shift and temporal patterns in the target‚Äîinsights that shaped the final approach.[Read the full write-up &gt;](https://openreview.net/forum?id=J3wj55kK5t)\\n**Made practical with GPUs:**Real-world datasets are often millions of rows, which can slow to a crawl in pandas. By adding GPU acceleration with[NVIDIA cuDF](https:...\\n\\n--- Result 6 ---\\nTitle: Benchmarking Multimodal AutoML for Tabular Data with Text Fields\\nURL: https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/9bf31c7ff062936a96d3c8bd1f8f2ff3-Abstract-round2.html\\n\\nContent:\\n#### Benchmarking Multimodal AutoML for Tabular Data with Text Fields\\n\\nPart of\\n[Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1 (NeurIPS Datasets and Benchmarks 2021)](https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021) round2\\n\\n[Bibtex](https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/28-/bibtex) [Paper](https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Paper-round2.pdf) [Reviews And Public Comment ¬ª](https://openreview.net/forum?id=Q0zOIaec8HF) [Supplemental](https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Supplemental-round2.zip)\\n\\n#### Authors\\n\\n_Xingjian Shi, Jonas Mueller, Nick Erickson, Nick Erickson, Mu Li, Alexander Smola, Alexander Smola_\\n\\n#### Abstract\\n\\nWe consider the use of automated supervised learning systems for data tables that not only contain numeric/categorical columns, but one or more text fields as well. Here we assemble 18 multimodal data tables that each contain some text fields and stem from a real business application. Our publicly-available benchmark enables researchers to comprehensively evaluate their own methods for supervised learning with numeric, categorical, and text features. To ensure that any single modeling strategy which performs well over all 18 datasets will serve as a practical foundation for multimodal text/tabular AutoML, the diverse datasets in our benchmark vary greatly in: sample size, problem types (a mix of classification and regression tasks), number of features (with the number of text columns ranging from 1 to 28 between datasets), as well as how the predictive signal is decomposed between text vs. numeric/categorical features (and predictive interactions thereof). Over this benchmark, we evaluate various straightforward pipelines to model such data, including standard two-stage approaches where NLP is used to featurize the text such that AutoML for tabular data can then be applied. Compared with human data science teams, the fully automated methodology that performed best on our benchmark also manages to rank 1st place when fit to the raw text/tabular data in two MachineHack prediction competitions and 2nd place (out of 2380 teams) in Kaggle's Mercari Price Suggestion Challenge.\\n\\nDo not remove: This comment is monitored to verify that the site is working properly\\n\\n--- Result 7 ---\\nTitle: A Package for Learning on Tabular and Text Data with Transformers\\nURL: https://aclanthology.org/2021.maiworkshop-1.10.pdf\\n\\nContent:\\nProceedings of the Third Workshop on Multimodal Artificial Intelligence, pages 69‚Äì73\\nJune 6, 2021. ¬©2021 Association for Computational Linguistics\\n69\\nMultimodal-Toolkit: A Package for Learning on Tabular and\\nText Data with Transformers\\nKen Gu\\nGeorgian\\nken.gu@georgian.io\\nAkshay Budhkar\\nGeorgian\\nakshay@georgian.io\\nAbstract\\nRecent progress in natural language process\\u0002ing has led to Transformer architectures be\\u0002coming the predominant model used for nat\\u0002ural language tasks. However, in many real\\u0002world datasets, additional modalities are in\\u0002cluded which the Transformer does not di\\u0002rectly leverage. We present Multimodal\\u0002Toolkit,1\\nan open-source Python package to\\nincorporate text and tabular (categorical and\\nnumerical) data with Transformers for down\\u0002stream applications. Our toolkit integrates\\nwell with Hugging Face‚Äôs existing API such as\\ntokenization and the model hub2 which allows\\neasy download of different pre-trained models.\\n1 Introduction\\nIn recent years, Transformers (Vaswani et al.,\\n2017) have become popular for model pre-training\\n(Howard and Ruder, 2018; Peters et al., 2018; De\\u0002vlin et al., 2019) and have yielded state-of-the-art\\nresults on many natural language processing (NLP)\\ntasks. In addition, well-documented Transformer\\nlibraries such as Hugging Face Transformers (Wolf\\net al., 2020), and AllenNLP (Gardner et al., 2018)\\nhave democratized NLP, making it easier to pro\\u0002ductionize and experiment on Transformers.\\nHowever, there are not a lot of comprehensive\\ntools for Transformers to work with tabular data.\\nOften in real-world datasets, there are tabular data\\nas well as unstructured text data which can pro\\u0002vide meaningful signals for the task at hand. For\\ninstance, in the small example in Figure 1, each\\nrow is a data point. Columns Title and Review\\nText contain text features, columns Division\\nName, Class Name, and Department Name\\ncontain categorical features, and the Age column\\nis a numerical feature. To the best of our knowl\\u0002edge, no tool exists that makes it simple for Trans\\u0002formers to handle this extra modality. Therefore,\\n1Github: https://git.io/JO5a6\\n2https://huggingface.co/docs\\nFigure 1: An example of a clothing review classifica\\u0002tion dataset. Each row is a data point consisting of text,\\ncategorical features, and numerical features.\\ngiven the advances of Transformers for natural\\nlanguage tasks and the maturity of existing Trans\\u0002former libraries, we introduce Multimodal-Toolkit,\\na lightweight Python package built on top of Hug\\u0002ging Face Transformers. Our package extends ex\\u0002isting Transformers in the Hugging Face‚Äôs Trans\\u0002formers library to seamlessly handle structured tab\\u0002ular data while keeping the existing tokenization\\n(including subword segmentation), experimental\\npipeline, and pre-trained model hub functionalities\\nof Hugging Face Transformers. We show the effec\\u0002tiveness of our toolkit on three real-world datasets.\\n2 Related Work\\nThere have been several proposed Transformer\\nmodels that aim to handle text features and addi\\u0002tional features of another modality. For pre-trained\\nTransformers on images and text, models such as\\nViLBERT (Lu et al., 2019) and VLBERT (Su et al.,\\n2020) are mainly the same as the original BERT\\nmodel but treat the extra image modality as addi\\u0002tional tokens to the input. These models require\\npre-training on multimodal image and text data.\\nOn the other hand, while treating image features\\n70\\nas additional input tokens, MMBT (Kiela et al.,\\n2019) proposes to use pre-trained BERT directly\\nand fine-tune on image and text data. This is simi\\u0002lar to Multimodal-Toolkit in which no pre-training\\non text and tabular data is needed.\\nLikewise, Transformers have been adapted to\\nalign, audio, visual, and text modalities in which\\nthere is a natural ground truth alignment. MulT\\n(Tsai et al., 2019) is similar to ViLBert in which\\nco-attention is used between pairs of modalities but\\nalso includes temporal convolutions so that input to\\u0002kens are aware of their temporal neighbors. Mean\\u0002while, Rahman et al. (2020) injects cross modality\\nattention at certain Transformer layers via a gating\\nmechanism.\\nFinally, knowledge graph embeddings have also\\nbeen effectively combined with input text tokens\\nin Transformers. Ostendorff et al. (2019) com\\u0002bines knowledge graph embeddings on authors\\nwith book titles and other metadata features via\\nsimple concatenation for book genre classification.\\nOn the other hand, for more general language tasks,\\nERNIE (Zhang et al., 2019) first matches the to\\u0002kens in the input text with entities in the knowledge\\ngraph. With this matching, the model fuses these\\nembeddings to produce entity-aware text embed\\u0002dings and text-aware entity embeddings.\\nHowever, these models do not capture categor\\u0002ical and numerical data explicitly. Hugging Face\\ndoes include LXMERT (Tan and Bansal, 2019) to\\nhandle language and vision modality but this can\\nnot be easily adapted for categorical and numeri\\u0002cal data. Nevertheless, existing multimodal Trans\\u0002former models do give good insights into how to\\ncombine categorical and numerical features. ViL\\u0002BERT and VLBERT for example include image\\nmodality as input tokens which lead to one of our\\nsimple baseline of categorical and numerical fea\\u0002tures as additional token inputs to the model. Like\\u0002wise, the gating mechanism Rahman et al. (2020),\\nattention, and different weighting schemes have\\nall been shown to be useful in combining different\\nmodalities.\\n3 Design\\nThe goal of Multimodal-Toolkit is to allow users\\nto quickly adapt state-of-the-art Transformer mod\\u0002els for situations involving text and tabular data\\nwhich occur often in real-world datasets. More\\u0002over, we want to bring the benefits of Transformers\\nto more use cases while making it simple for users\\nFigure 2: The framework of Multimodal-Toolkit.\\nThere is a data processing module that outputs pro\\u0002cessed text, numerical, and categorical features that are\\nthen fed as input to our Transformer With Tabular mod\\u0002ule consisting of a Hugging Face Transformer and our\\ncombining module.\\nof Hugging Face Transformers to adopt. Therefore,\\nwe maintain the existing interface of the popular\\nHugging Face Transformers library.\\nThis design enables us to easily include more\\nTransformer models, leverage strengths of spe\\u0002cific models, use a feature-rich training pipeline,\\nand integrate the thousands of community trained\\nmodels on Hugging Face‚Äôs model hub. We sup\\u0002port a variety of Transformers (e.g. BERT, AL\\u0002BERT, RoBERTa, XLNET) for both classification\\nand regression tasks. All together, this becomes a\\nreusable Transformer With Tabular component. We\\nalso provide a data preprocessing module for cate\\u0002gorical and numerical features. An overview of the\\nsystem is shown in Figure 2. Currently, the library\\nsupports PyTorch Transformers implementations.\\n3.1 Combining Module\\nWe implement a combining module that is model\\nagnostic that takes as input, x, the text features\\noutputted from a Transformer model and prepro\\u0002cessed categorical (c) and numerical (n) features,\\nand outputs a combined multimodal representation\\nm. Although existing multimodal Transformers\\nincorporate cross-modal attention inside middle\\nTransformer layers, we choose the design in which\\nthe modality combination comes after the Trans\\u0002former because this module can be easily included\\nwithout much adaptation of the existing Hugging\\nFace Transformer interface and can be easily ex\\u0002tended to new Transformers included in the future.\\nInside the combining module, we implement var-\\n71\\nCombine Feature Method Equation\\nText only m = x\\nConcat m = x||c||n\\nIndividual MLPs on categorical and\\u0002numerical features then concat (MLP + Concat) m = x||MLP(c)||MLP(n)\\nMLP on concatenated categorical and\\nnumerical features then concat (Concat + MLP) m = x||MLP(c||n)\\nAttention on categorical and numerical\\nfeatures (Attention)\\nm = Œ±x,xWxx + Œ±x,cWcc + Œ±x,nWnn\\nŒ±i,j =\\nexp(LeakyReLU(a\\nT\\n[Wixi||Wjxj ]))\\nP\\nk‚àà{x,c,n}\\nexp(LeakyReLU(aT [Wixi||Wkxk]))\\nGating on categorical and numerical\\nfeatures and then sum (Rahman et al., 2020)\\n(Gating)\\nm = x + Œ±h\\nh = gc \\f (Wcc...\\n\\n--- Result 8 ---\\nTitle: Papers with Code - Benchmarking Multimodal AutoML for Tabular Data with Text Fields\\nURL: https://paperswithcode.com/paper/benchmarking-multimodal-automl-for-tabular\\n\\nContent:\\nnew\\n\\nGet trending papers in your email inbox once a day!\\n\\nGet trending papers in your email inbox!\\n\\n[Subscribe](https://paperswithcode.com/login?next=%2Fpapers)\\n\\n# Trending Papers\\n\\n## by [AK](https://paperswithcode.com/akhaliq) and the research community\\n\\n- Daily\\n- Weekly\\n- Monthly\\n\\nTrending Papers\\n\\nSubmitted by\\nhiyouga\\n\\n### [VeOmni: Scaling Any Modality Model Training with Model-Centric\\\\ Distributed Recipe Zoo](https://paperswithcode.com/papers/2508.02317)\\n\\nRecent advances in large language models (LLMs) have driven impressive\\nprogress in omni-modal understanding and generation. However, training\\nomni-modal LLMs remains a significant challenge due to the heterogeneous model\\narchitectures required to process diverse modalities, necessitating\\nsophisticated system design for efficient large-scale training. Existing\\nframeworks typically entangle model definition with parallel logic, incurring\\nlimited scalability and substantial engineering overhead for end-to-end\\nomni-modal training. % We present \\\\\\\\veomni, a modular and efficient training\\nframework to accelerate the development of omni-modal LLMs. \\\\\\\\veomni introduces\\nmodel-centric distributed recipes that decouples communication from\\ncomputation, enabling efficient 3D parallelism on omni-modal LLMs. \\\\\\\\veomni also\\nfeatures a flexible configuration interface supporting seamless integration of\\nnew modalities with minimal code change. % Using \\\\\\\\veomni, a omni-modal\\nmixture-of-experts (MoE) model with 30B parameters can be trained with over\\n2,800 tokens/sec/GPU throughput and scale to 160K context lengths via 3D\\nparallelism on 128 GPUs, showcasing its superior efficiency and scalability for\\ntraining large omni-modal LLMs.\\n\\n- 12 authors\\n\\n¬∑Published on Aug 4, 2025\\n\\n[Upvote\\\\\\n\\\\\\n15](https://paperswithcode.com/login?next=%2Fpapers%2F2508.02317)\\n\\n[GitHub717](https://github.com/ByteDance-Seed/VeOmni) [arXiv Page](https://arxiv.org/abs/2508.02317)\\n\\nSubmitted by\\nhiyouga\\n\\n### [VeOmni: Scaling Any Modality Model Training with Model-Centric\\\\ Distributed Recipe Zoo](https://paperswithcode.com/papers/2508.02317)\\n\\nRecent advances in large language models (LLMs) have driven impressive\\nprogress in omni-modal understanding and generation. However, training\\nomni-modal LLMs remains a significant challenge due to the heterogeneous model\\narchitectures required to process diverse modalities, necessitating\\nsophisticated system design for efficient large-scale training. Existing\\nframeworks typically entangle model definition with parallel logic, incurring\\nlimited scalability and substantial engineering overhead for end-to-end\\nomni-modal training. % We present \\\\\\\\veomni, a modular and efficient training\\nframework to accelerate the development of omni-modal LLMs. \\\\\\\\veomni introduces\\nmodel-centric distributed recipes that decouples communication from\\ncomputation, enabling efficient 3D parallelism on omni-modal LLMs. \\\\\\\\veomni also\\nfeatures a flexible configuration interface supporting seamless integration of\\nnew modalities with minimal code change. % Using \\\\\\\\veomni, a omni-modal\\nmixture-of-experts (MoE) model with 30B parameters can be trained with over\\n2,800 tokens/sec/GPU throughput and scale to 160K context lengths via 3D\\nparallelism on 128 GPUs, showcasing its superior efficiency and scalability for\\ntraining large omni-modal LLMs.\\n\\n- 12 authors\\n\\n¬∑Aug 4, 2025\\n\\n[Upvote\\\\\\n\\\\\\n15](https://paperswithcode.com/login?next=%2Fpapers%2F2508.02317)\\n\\n[GitHub717](https://github.com/ByteDance-Seed/VeOmni) [arXiv Page](https://arxiv.org/abs/2508.02317)\\n\\nSubmitted by\\nFrancisRing\\n\\n### [StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation](https://paperswithcode.com/papers/2508.08248)\\n\\nCurrent diffusion models for audio-driven avatar video generation struggle to\\nsynthesize long videos with natural audio synchronization and identity\\nconsistency. This paper presents StableAvatar, the first end-to-end video\\ndiffusion transformer that synthesizes infinite-length high-quality videos\\nwithout post-processing. Conditioned on a reference image and audio,\\nStableAvatar integrates tailored training and inference modules to enable\\ninfinite-length video generation. We observe that the main reason preventing\\nexisting models from generating long videos lies in their audio modeling. They\\ntypically rely on third-party off-the-shelf extractors to obtain audio\\nembeddings, which are then directly injected into the diffusion model via\\ncross-attention. Since current diffusion backbones lack any audio-related\\npriors, this approach causes severe latent distribution error accumulation\\nacross video clips, leading the latent distribution of subsequent segments to\\ndrift away from the optimal distribution gradually. To address this,\\nStableAvatar introduces a novel Time-step-aware Audio Adapter that prevents\\nerror accumulation via time-step-aware modulation. During inference, we propose\\na novel Audio Native Guidance Mechanism to further enhance the audio\\nsynchronization by leveraging the diffusion's own evolving joint audio-latent\\nprediction as a dynamic guidance signal. To enhance the smoothness of the\\ninfinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy\\nthat fuses latent over time. Experiments on benchmarks show the effectiveness\\nof StableAvatar both qualitatively and quantitatively.\\n\\n- 9 authors\\n\\n¬∑Published on Aug 11, 2025\\n\\n[Upvote\\\\\\n\\\\\\n14](https://paperswithcode.com/login?next=%2Fpapers%2F2508.08248)\\n\\n[GitHub262](https://github.com/Francis-Rings/StableAvatar) [arXiv Page](https://arxiv.org/abs/2508.08248)\\n\\nSubmitted by\\nFrancisRing\\n\\n### [StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation](https://paperswithcode.com/papers/2508.08248)\\n\\nCurrent diffusion models for audio-driven avatar video generation struggle to\\nsynthesize long videos with natural audio synchronization and identity\\nconsistency. This paper presents StableAvatar, the first end-to-end video\\ndiffusion transformer that synthesizes infinite-length high-quality videos\\nwithout post-processing. Conditioned on a reference image and audio,\\nStableAvatar integrates tailored training and inference modules to enable\\ninfinite-length video generation. We observe that the main reason preventing\\nexisting models from generating long videos lies in their audio modeling. They\\ntypically rely on third-party off-the-shelf extractors to obtain audio\\nembeddings, which are then directly injected into the diffusion model via\\ncross-attention. Since current diffusion backbones lack any audio-related\\npriors, this approach causes severe latent distribution error accumulation\\nacross video clips, leading the latent distribution of subsequent segments to\\ndrift away from the optimal distribution gradually. To address this,\\nStableAvatar introduces a novel Time-step-aware Audio Adapter that prevents\\nerror accumulation via time-step-aware modulation. During inference, we propose\\na novel Audio Native Guidance Mechanism to further enhance the audio\\nsynchronization by leveraging the diffusion's own evolving joint audio-latent\\nprediction as a dynamic guidance signal. To enhance the smoothness of the\\ninfinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy\\nthat fuses latent over time. Experiments on benchmarks show the effectiveness\\nof StableAvatar both qualitatively and quantitatively.\\n\\n- 9 authors\\n\\n¬∑Aug 11, 2025\\n\\n[Upvote\\\\\\n\\\\\\n14](https://paperswithcode.com/login?next=%2Fpapers%2F2508.08248)\\n\\n[GitHub262](https://github.com/Francis-Rings/StableAvatar) [arXiv Page](https://arxiv.org/abs/2508.08248)\\n\\nSubmitted by\\ncsuhan\\n\\n### [ScreenCoder: Advancing Visual-to-Code Generation for Front-End\\\\ Automation via Modular Multimodal Agents](https://paperswithcode.com/papers/2507.22827)\\n\\nAutomating the transformation of user interface (UI) designs into front-end\\ncode holds significant promise for accelerating software development and\\ndemocratizing design workflows. While recent large language models (LLMs) have\\ndemonstrated progress in text-to-code generation, many existing approaches rely\\nsolely o...\\n\\n--- Result 9 ---\\nTitle: Towards Benchmarking Foundation Models for Tabular Data With Text\\nURL: https://arxiv.org/pdf/2507.07829\\n\\nContent:\\nTowards Benchmarking Foundation Models for Tabular Data With Text\\nMartin Mraz¬¥\\n* 1 Breenda Das * 1 Anshul Gupta * 1 Lennart Purucker 1 Frank Hutter 2 3 1\\nAbstract\\nFoundation models for tabular data are rapidly\\nevolving, with increasing interest in extending\\nthem to support additional modalities such as free\\u0002text features. However, existing benchmarks for\\ntabular data rarely include textual columns, and\\nidentifying real-world tabular datasets with se\\u0002mantically rich text features is non-trivial. We\\npropose a series of simple yet effective ablation\\u0002style strategies for incorporating text into con\\u0002ventional tabular pipelines. Moreover, we bench\\u0002mark how state-of-the-art tabular foundation mod\\u0002els can handle textual data by manually curating\\na collection of real-world tabular datasets with\\nmeaningful textual features. Our study is an im\\u0002portant step towards improving benchmarking of\\nfoundation models for tabular data with text.\\n1. Introduction\\nFoundation models have begun to transform tabular learn\\u0002ing (Erickson et al., 2020b; Hollmann et al., 2025), echo\\u0002ing the trajectory of other research fields. A natural next\\nstep is mixed-modality tabular modeling, where structured\\ncolumns may also include free-text fields such as job de\\u0002scriptions, clinical notes, or product summaries. Current\\ntabular benchmarks, however, almost never contain textual\\ncolumns, cf. (Bischl et al., 2019; Liu et al., 2024; McEl\\u0002fresh et al., 2024). Moreover, locating real-world datasets\\nwith semantically rich text features is exceptionally difficult,\\nwith even exhaustive searches of OpenML and Kaggle only\\nyielding a handful of usable candidates (Shi et al., 2021).\\nConsequently, current tabular foundation models are rarely\\nevaluated for tabular data with text.\\nPipelines that can handle tabular data with text vary greatly\\n*Equal contribution 1Department of Computer Science, Uni\\u0002versity of Freiburg, Freiburg, Germany 2\\nPrior Labs, Freiburg,\\nGermany 3ELLIS Institute, Tubingen, Germany. Correspon\\u0002dence to: Martin Mraz <mrazm@informatik.uni-freiburg.de>,\\nBreenda Das <dasb@informatik.uni-freiburg.de>, Anshul Gupta\\n<guptaa@informatik.uni-freiburg.de>.\\nProceedings of the 42 nd International Conference on Machine\\nLearning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025\\nby the author(s).\\nin their implementation. AutoGluon‚Äôs AutoMLPipeline\\u0002FeatureGenerator (Erickson et al., 2020a) converts text to\\nsparse vectors; CARTE (Kim et al., 2024) applies fastText\\nsentence embeddings (Bojanowski et al., 2017). and the\\nTabPFNv2 API accepts raw text but does not disclose its\\nmethodology. These divergent choices raise a fundamental\\nquestion: Which embedding strategy works best, and under\\nwhat conditions?\\nTo answer this question, we present the first systematic\\nstudy of predictive machine learning with foundation mod\\u0002els for tabular data with text. We study the performance\\nof three representative embedding routes: fastText, Skrub‚Äôs\\nTableVectorizer, and AutoGluon‚Äôs text encoder. We show\\nqualitatively, with a simple synthetic counter-example, that\\nboth n-gram based and off-the-shelf sentence embeddings\\ncan fail to recover highly predictive semantic patterns. More\\u0002over, quantitatively, we evaluate these methods on a man\\u0002ually curated set of real-world tabular benchmark that (i)\\ncontain genuinely informative free-text columns (ii) spans\\nover a variety of domains and samples.\\nOur contributions are: (I) A qualitative study show cas\\u0002ing the limitations of standard n-gram based and generic\\nNLP-based embeddings for tabular tasks with text. (II) A\\nmanually curated set of real-world tabular datasets with se\\u0002mantically rich textual columns. (III) An empirical study of\\nthree text embedding pipelines for TabPFNv2 and XGBoost\\nwith the TabPFNv2 API and AutoGluon Tabular Predictor\\nas baselines.\\nOur study reveals the limitations of current methods and\\nunderscores the need for new methods to handle tabular data\\nwith free text.\\n2. Related Work\\nApproaches incorporating free-text in tabular learning\\nlargely follow two paradigms. First, row-as-text meth\\u0002ods serialize entire rows into prompts and delegate pre\\u0002diction to a large language model (LLM), as seen in\\nTABLLM (Hegselmann et al., 2022), TABLE-LLM (Zhang\\net al., 2024). These work well when textual fields dominate\\nor in few-shot settings. Second, per-column embedding\\nstrategies extract textual embeddings from a single or groups\\nof features, while preserving the structural nature of tabular\\n1\\narXiv:2507.07829v1 [cs.LG] 10 Jul 2025\\nTowards Benchmarking Foundation Models for Tabular Data With Text\\nFigure 1. Qualitative investigation of textual embeddings for tabular prediction tasks: TabPFN v2 accuracy across five datasets.\\nBaselines ‚ÄúNo-Text‚Äù uses original input features, ‚ÄúComplete Leak‚Äù has target leakage, therefore 100% accuracy for all. Following tests\\nembed targets into textual modality. ‚ÄúN-Gram Break‚Äù shows TF-IDF breaking under unseen synonyms, ‚ÄúSimple NLP break‚Äù shows\\nFastText underperforming under noise, ‚ÄúLLM Breaks‚Äù shows BERT variant breaking under semantic ambiguity.\\ndata. They embed each column using fastText or LLMs\\nand then concatenate the resulting embeddings to the table,\\nor replace the feature with its individual textual embed\\u0002ding, cf. (Koloski et al., 2025; Carballo et al., 2023; Kim\\net al., 2024). Grinsztajn et al. (2023) compare 30+ LLM\\nand substring-based methods for embedding string columns,\\nshowing when LLMs yield better representations.\\nIn this study, we investigate pre-column embeddings be\\u0002cause we focus on a many-shot setting (e.g., more than 32\\ntraining samples), in which LLM-based predictive methods\\ndo not perform well, cf. (Hegselmann et al., 2023) and (Ma\\net al., 2024), or require a prohibitive amount of fine-tuning\\n(Shysheya et al., 2025).\\nMost popular prior tabular benchmarks contain no free-text\\nfield, cf. (Bischl et al., 2019; Gijsbers et al., 2022; McEl\\u0002fresh et al., 2023). For tabular data with text, Shi et al.\\n(2021) curated 18 datasets with mixed modalities, but many\\nrely almost entirely on text, with only one or two tabular\\nfeatures, or features derived from the long text, e.g. # of\\nwords (Tang et al., 2024). Thus, they benchmark text-based\\nmodels rather than tabular models, focusing on text data\\nwith tabular features. In contrast, we focus on tabular mod\\u0002els extended to handle text, focusing on tabular data with\\nadditional text features. Other studies were often limited to\\nan evaluation with just one or two datasets (Carballo et al.,\\n2023; Lu et al., 2023). Overall, existing studies for tabular\\ndata with text lack a domain-agnostic benchmark where\\ntextual features complement, rather than dominate, tabular\\ndata. This motivates the new benchmark we present.\\nThe CARTE Benchmark. The latest seminal work on\\nbenchmarking for tabular data with text is the CARTE (Kim\\net al., 2024) benchmark. It includes 51 datasets for tabu\\u0002lar data with text. However, when we investigated these\\ndatasets more closely, we found that at most 11 out of the\\n51 datasets are suited to evaluate tabular data with text.\\nMoreover, our manually curated collection of datasets for\\nbenchmarking only includes 1 out of the 51 datasets.\\nWe share an extensive report of our investigation in Ap\\u0002pendix G. In short, we found that most datasets (a) do not\\nrepresent predictive machine learning tasks for tabular data\\nwith text; (b) are skewed towards text data representing\\nmany categories instead of longer free text; (c) were pre\\u0002processed manually per dataset with logic that seems to\\nfavor CARTE; (d) or were very similar datasets from the\\nsame domain, with the same features, or similar semantic\\ncontent. Thus, while CARTE was a significant step toward\\nbenchmarking and learning for tabular data with text, it falls\\nshort in several aspects. Our work complements CARTE‚Äôs\\nefforts and aims to improve benchmarking for tabular data\\nwith text further.\\n3. Qualitative Investigation\\nIn this section, we evaluate popular text embedding tech\\u0002niques: N-Grams, simple NLP models and LLMs for tabular\\npr...\\n\", \"is_error\": false, \"results\": [{\"title\": \"ANSWER\", \"text\": \"Winning Kaggle solutions for problems that mix free‚Äëtext columns with ordinary numeric or categorical fields treat the data as **multimodal** and deliberately combine a strong NLP encoder with classic tabular learners.  In practice the most reliable recipe is a three‚Äëstep pipeline:  \\n\\n1. **Encode the raw text** with a pretrained transformer (e.g., BERT, RoBERTa) to obtain dense sentence‚Äëlevel embeddings.  AutoGluon‚Äôs‚ÄØ`TextPredictor` can do this automatically and returns embeddings that can be fed to any tabular model‚ÄØ([auto.gluon.ai](https://auto.gluon.ai/0.7.0/tutorials/tabular_prediction/tabular-multimodal-text-others.html)).  \\n2. **Merge the embeddings with the structured features** ‚Äì either by concatenating them to the numeric/categorical matrix (the ‚Äútwo‚Äëstage‚Äù approach evaluated in the multimodal AutoML benchmark‚ÄØ([datasets‚Äëbenchmarks‚Äëproceedings.neurips.cc](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/9bf31c7ff062936a96d3c8bd1f8f2ff3-Abstract-round2.html))) or by converting the auxiliary columns into a short textual description and prepending it to the original document (the ‚Äúfeatures‚Äëto‚Äëtext‚Äù trick that proved best on a 23‚ÄØk clothing‚Äëreview dataset‚ÄØ([mccormickml.com](https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert))) .  \\n3. **Train high‚Äëperforming tabular models on the combined matrix** ‚Äì LightGBM, CatBoost or Random Forest are the workhorses, and they can be stacked or blended with the original transformer model itself.  The Multimodal‚ÄëToolkit library provides a ready‚Äëto‚Äëuse wrapper that integrates Hugging‚ÄØFace tokenizers with these tabular learners, making the stacking process straightforward‚ÄØ([aclanthology.org](https://aclanthology.org/2021.maiworkshop-1.10.pdf)).\\n\\nBeyond the core pipeline, Kaggle Grandmasters repeatedly stress a few complementary tricks that turn a good baseline into a winning one:  \\n\\n* **Target‚Äëencode high‚Äëcardinality categoricals** before feeding them to the tabular model, and apply the same encoding to the text‚Äëembedding features.  \\n* **Use GPU‚Äëaccelerated training** for the transformer part (e.g., via AutoGluon or the Multimodal‚ÄëToolkit) to explore larger pretrained checkpoints without prohibitive runtime‚ÄØ([developer.nvidia.com](https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data)).  \\n* **Ensemble multiple modalities** ‚Äì blend a pure‚Äëtext model, a pure‚Äëtabular model, and a multimodal model (embeddings‚ÄØ+‚ÄØfeatures) using simple weighted averages or stacking with a meta‚Äëlearner.  This strategy consistently appears in the ‚Äútips and tricks‚Äù posts that summarize top‚Äë5 Kaggle competitions‚ÄØ([neptune.ai](https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions)).  \\n\\nIn short, the winning Kaggle playbook for text classification with tabular features is to **extract high‚Äëquality transformer embeddings, fuse them with engineered numeric/categorical columns, and train/ensemble strong gradient‚Äëboosting models** ‚Äì all while leveraging GPU‚Äëfriendly libraries (AutoGluon, Multimodal‚ÄëToolkit) and proven Kaggle‚Äëspecific preprocessing tricks.\", \"url\": \"\"}, {\"title\": \"Combining BERT/Transformers and Classical Tabular Models ‚Äî AutoGluon Documentation 0.7.0 documentation\", \"text\": \"<div><div>\\n<h2>Multimodal Data Tables: Combining BERT/Transformers and Classical Tabular Models<a href=\\\"#multimodal-data-tables-combining-bert-transformers-and-classical-tabular-models\\\">¬∂</a></h2>\\n<p><strong>Tip</strong>: If your data contains images, consider also checking out\\n<a href=\\\"https://auto.gluon.ai/0.7.0/tutorials/tabular_prediction/tabular-multimodal.html#sec-tabularprediction-multimodal\\\"><span>Multimodal Data Tables: Tabular, Text, and Image</span></a> which handles images in\\naddition to text and tabular features.</p>\\n<p>Here we introduce how to use AutoGluon Tabular to deal with multimodal\\ntabular data that contains text, numeric, and categorical columns. In\\nAutoGluon, <strong>raw text data</strong> is considered as a first-class citizen of\\ndata tables. AutoGluon Tabular can help you train and combine a diverse\\nset of models including classical tabular models like\\nLightGBM/RF/CatBoost as well as our pretrained NLP model based\\nmultimodal network that is introduced in Section\\n‚Äú<span>sec_textprediction_architecture</span>‚Äù of\\n<span>sec_textprediction_multimodal</span> (used by AutoGluon‚Äôs\\n<code><span>TextPredictor</span></code>).</p>\\n<div><pre><span></span><span>%</span><span>matplotlib</span> <span>inline</span>\\n<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>\\n<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>\\n<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>\\n<span>import</span> <span>pprint</span>\\n<span>import</span> <span>random</span>\\n<span>from</span> <span>autogluon.tabular</span> <span>import</span> <span>TabularPredictor</span>\\n<span>np</span><span>.</span><span>random</span><span>.</span><span>seed</span><span>(</span><span>123</span><span>)</span>\\n<span>random</span><span>.</span><span>seed</span><span>(</span><span>123</span><span>)</span>\\n</pre></div>\\n<div>\\n<h2>Product Sentiment Analysis Dataset<a href=\\\"#product-sentiment-analysis-dataset\\\">¬∂</a></h2>\\n<p>We consider the product sentiment analysis dataset from a <a href=\\\"https://www.machinehack.com/hackathons/product_sentiment_classification_weekend_hackathon_19/leaderboard\\\">MachineHack\\nhackathon</a>.\\nThe goal is to predict a user‚Äôs sentiment towards a product given their\\nreview (raw text) and a categorical feature indicating the product‚Äôs\\ntype (e.g., Tablet, Mobile, etc.). We have already split the original\\ndataset to be 90% for training and 10% for development/testing (if\\nsubmitting your models to the hackathon, we recommend training them on\\n100% of the dataset).</p>\\n<div><pre><span></span>!mkdir -p product_sentiment_machine_hack\\n!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/train.csv -O product_sentiment_machine_hack/train.csv\\n!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/dev.csv -O product_sentiment_machine_hack/dev.csv\\n!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/test.csv -O product_sentiment_machine_hack/test.csv\\n</pre></div>\\n<div><pre><span></span>--2023-02-22 23:29:24-- https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/train.csv\\nResolving autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)... 52.217.130.97, 52.217.110.220, 52.216.137.228, ...\\nConnecting to autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)|52.217.130.97|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 689486 (673K) [text/csv]\\nSaving to: ‚Äòproduct_sentiment_machine_hack/train.csv‚Äô\\nproduct_sentiment_m 100%[===================&gt;] 673.33K --.-KB/s in 0.009s\\n2023-02-22 23:29:24 (73.9 MB/s) - ‚Äòproduct_sentiment_machine_hack/train.csv‚Äô saved [689486/689486]\\n--2023-02-22 23:29:24-- https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/dev.csv\\nResolving autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)... 52.216.10.27, 52.217.225.57, 3.5.11.212, ...\\nConnecting to autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)|52.216.10.27|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 75517 (74K) [text/csv]\\nSaving to: ‚Äòproduct_sentiment_machine_hack/dev.csv‚Äô\\nproduct_sentiment_m 100%[===================&gt;] 73.75K --.-KB/s in 0.001s\\n2023-02-22 23:29:24 (57.6 MB/s) - ‚Äòproduct_sentiment_machine_hack/dev.csv‚Äô saved [75517/75517]\\n--2023-02-22 23:29:24-- https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/test.csv\\nResolving autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)... 52.217.130.97, 52.216.10.27, 52.217.225.57, ...\\nConnecting to autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)|52.217.130.97|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 312194 (305K) [text/csv]\\nSaving to: ‚Äòproduct_sentiment_machine_hack/test.csv‚Äô\\nproduct_sentiment_m 100%[===================&gt;] 304.88K --.-KB/s in 0.002s\\n2023-02-22 23:29:24 (137 MB/s) - ‚Äòproduct_sentiment_machine_hack/test.csv‚Äô saved [312194/312194]\\n</pre></div>\\n<div><pre><span></span><span>subsample_size</span> <span>=</span> <span>2000</span> <span># for quick demo, try setting to larger values</span>\\n<span>feature_columns</span> <span>=</span> <span>[</span><span>'Product_Description'</span><span>,</span> <span>'Product_Type'</span><span>]</span>\\n<span>label</span> <span>=</span> <span>'Sentiment'</span>\\n<span>train_df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'product_sentiment_machine_hack/train.csv'</span><span>,</span> <span>index_col</span><span>=</span><span>0</span><span>)</span><span>.</span><span>sample</span><span>(</span><span>2000</span><span>,</span> <span>random_state</span><span>=</span><span>123</span><span>)</span>\\n<span>dev_df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'product_sentiment_machine_hack/dev.csv'</span><span>,</span> <span>index_col</span><span>=</span><span>0</span><span>)</span>\\n<span>test_df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'product_sentiment_machine_hack/test.csv'</span><span>,</span> <span>index_col</span><span>=</span><span>0</span><span>)</span>\\n<span>train_df</span> <span>=</span> <span>train_df</span><span>[</span><span>feature_columns</span> <span>+</span> <span>[</span><span>label</span><span>]]</span>\\n<span>dev_df</span> <span>=</span> <span>dev_df</span><span>[</span><span>feature_columns</span> <span>+</span> <span>[</span><span>label</span><span>]]</span>\\n<span>test_df</span> <span>=</span> <span>test_df</span><span>[</span><span>feature_columns</span><span>]</span>\\n<span>print</span><span>(</span><span>'Number of training samples:'</span><span>,</span> <span>len</span><span>(</span><span>train_df</span><span>))</span>\\n<span>print</span><span>(</span><span>'Number of dev samples:'</span><span>,</span> <span>len</span><span>(</span><span>dev_df</span><span>))</span>\\n<span>print</span><span>(</span><span>'Number of test samples:'</span><span>,</span> <span>len</span><span>(</span><span>test_df</span><span>))</span>\\n</pre></div>\\n<div><pre><span></span><span>Number</span> <span>of</span> <span>training</span> <span>samples</span><span>:</span> <span>2000</span>\\n<span>Number</span> <span>of</span> <span>dev</span> <span>samples</span><span>:</span> <span>637</span>\\n<span>Number</span> <span>of</span> <span>test</span> <span>samples</span><span>:</span> <span>2728</span>\\n</pre></div>\\n<p>There are two features in the dataset: the users‚Äô review of the product\\nand the product‚Äôs type, and four possible classes to predict.</p>\\n<div>\\n<table>\\n <thead>\\n <tr>\\n <th></th>\\n <th>Product_Description</th>\\n <th>Product_Type</th>\\n <th>Sentiment</th>\\n </tr>\\n </thead>\\n <tbody>\\n <tr>\\n <th>4532</th>\\n <td>they took away the lego pit but ...\", \"url\": \"https://auto.gluon.ai/0.7.0/tutorials/tabular_prediction/tabular-multimodal-text-others.html\"}, {\"title\": \"Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\", \"text\": \"Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions[\\n**üì£ BIG NEWS:****Neptune is joining OpenAI!**‚Üí Read the message from our CEO üì£![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\\nWhat do you want to find?\\nSearch\\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Neptune Blog](https://neptune.ai/blog)# Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Shahul-Es-new-scaled.jpeg?fit=2560%2C1920&ssl=1)\\n[Shahul ES](https://neptune.ai/blog/author/shahules)\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)3 min\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)1st September, 2023\\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)[Tabular Data](https://neptune.ai/blog/category/tabular-data)\\nIn this article, I will discuss some great tips and tricks to improve the performance of your structured data binary classification model. These tricks are obtained from solutions of some of Kaggle‚Äôs top tabular data competitions. Without much lag, let‚Äôs begin.\\nThese are the five competitions that I have gone through to create this article:\\n* [**Home credit default risk**](https://www.kaggle.com/c/home-credit-default-risk/)\\n* [**Santander Customer Transaction Prediction**](https://www.kaggle.com/c/santander-customer-transaction-prediction/notebooks)\\n* [**VSB Power Line Fault Detection**](https://www.kaggle.com/c/vsb-power-line-fault-detection/overview/evaluation)\\n* [**Microsoft Malware Prediction**](https://www.kaggle.com/c/microsoft-malware-prediction/overview)\\n* [**IEEE-CIS Fraud Detection**](https://www.kaggle.com/c/ieee-fraud-detection/overview/evaluation/)## Dealing with larger datasets\\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\\n* Faster[data loading with pandas.](https://www.kaggle.com/c/home-credit-default-risk/discussion/59575)\\n* Data compression techniques to[reduce the size of data by 70%](https://www.kaggle.com/nickycan/compress-70-of-dataset).\\n* Optimize the memory by r[educing the size of some attributes.](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\\n* Use open-source libraries such as[Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space.\\n* Use[cudf](https://github.com/rapidsai/cudf).\\n* Convert data to[parquet](https://arrow.apache.org/docs/python/parquet.html)format.\\n* Converting data to[feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03)format.\\n* Reducing memory usage for[optimizing RAM](https://www.kaggle.com/mjbahmani/reducing-memory-size-for-ieee).## Data exploration\\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\\n* EDA for microsoft[malware detection.](https://www.kaggle.com/youhanlee/my-eda-i-want-to-see-all)\\n* Time Series[EDA for malware detection.](https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68)\\n* Complete[EDA for home credit loan prediction](https://www.kaggle.com/codename007/home-credit-complete-eda-feature-importance).\\n* Complete[EDA for Santader prediction.](https://www.kaggle.com/gpreda/santander-eda-and-prediction)\\n* EDA for[VSB Power Line Fault Detection.](https://www.kaggle.com/go1dfish/basic-eda)## Data preparation\\nAfter data exploration, the first thing to do is to use those insights to prepare the data. To tackle issues like class imbalance, encoding categorical data, etc. Let‚Äôs see the methods used to do it.\\n* Methods to t[ackle class imbalance](https://www.kaggle.com/shahules/tackling-class-imbalance).\\n* Data augmentation by[Synthetic Minority Oversampling Technique](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/).\\n* Fast inplace[shuffle for augmentation](https://www.kaggle.com/jiweiliu/fast-inplace-shuffle-for-augmentation).\\n* Finding[synthetic samples in the dataset.](https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split)\\n* [Signal denoising](https://www.kaggle.com/jackvial/dwt-signal-denoising)used in signal processing competitions.\\n* Finding[patterns of missing data](https://www.kaggle.com/jpmiller/patterns-of-missing-data).\\n* Methods to handle[missing data](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779).\\n* An overview of various[encoding techniques for categorical data.](https://www.kaggle.com/shahules/an-overview-of-encoding-techniques)\\n* Building[model to predict missing values.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64598)\\n* Random[shuffling of data](https://www.kaggle.com/brandenkmurray/randomly-shuffled-data-also-works)to create new synthetic training set.## Feature engineering\\nNext, you can check the most popular feature and feature engineering techniques used in these top kaggle competitions. The feature engineering part varies from problem to problem depending on the domain.\\n* Target[encoding cross validation](https://medium.com/@pouryaayria/k-fold-target-encoding-dfe9a594874b/)for better encoding.\\n* Entity embedding to[handle categories](https://www.kaggle.com/abhishek/entity-embeddings-to-handle-categories).\\n* Encoding c[yclic features for deep learning.](https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning)\\n* Manual[feature engineering methods](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering).\\n* Automated feature engineering techniques[using featuretools](https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics).\\n* Top hard crafted features used in[microsoft malware detection](https://www.kaggle.com/sanderf/7th-place-solution-microsoft-malware-prediction).\\n* Denoising NN for[feature extraction](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798).\\n* Feature engineering[using RAPIDS framework.](https://www.kaggle.com/cdeotte/rapids-feature-engineering-fraud-0-96/)\\n* Things to remember while processing f[eatures using LGBM.](https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575)\\n* [Lag features and moving averages.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64593)\\n* [Principal component analysis](https://medium.com/machine-learning-researcher/dimensionality-reduction-pca-and-lda-6be91734f567)for...\", \"url\": \"https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions\"}, {\"title\": \"\", \"text\": \"# Combining Categorical and Numerical Features with Text in BERT\\n\\n29 Jun 2021\\n\\nIn this tutorial we‚Äôll look at the topic of classifying text with BERT, but where we also have additional numerical or categorical features that we want to use to improve our predictions.\\n\\nTo help motivate our discussion, we‚Äôll be working with a dataset of about 23k clothing reviews. For each review, we have the review text, but also additional information such as:\\n\\n- The age of the reviewer (numerical feature)\\n- The number of upvotes on the review (numerical feature)\\n- The department and category of the clothing item (categorical features)\\n\\nFor each review, we also have a binary label, which is whether or not the reviewer ultimately recommends the item. This is what we are trying to predict.\\n\\nThis dataset was scraped from an (un-specified) e-commerce website by Nick Brooks and made available on Kaggle [here](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews).\\n\\nIn Section 2 of this Notebook, I‚Äôve implemented four different ‚Äúbaseline‚Äù strategies which score fairly well, but which don‚Äôt incorporate all of the features together.\\n\\nThen, in Section 3, I‚Äôve implemented a simple strategy to combine _everything_ and feed it through BERT. Specifically, I make text out of the additional features, and prepend this text to the review.\\n\\nThere is a GitHub project called the [Multimodal-Toolkit](https://github.com/georgian-io/Multimodal-Toolkit) which is how I learned about this clothing review dataset. The toolkit implements a number of more complicated techniques, but their benchmarks (as well as our results below) show that this simple features-to-text strategy works best for this dataset.\\n\\nIn our weekly discussion group, I talked through this Notebook and we also met with Ken Gu, the author of the Multi-Modal Toolkit! You can watch the recording [here](https://youtu.be/XPt9pIpe1vo).\\n\\nYou can find the Colab Notebook version of this post [here](https://colab.research.google.com/drive/1YRHK4HO8RktGzlYmGjBo056kzVD4_j9o).\\n\\nBy Chris McCormick\\n\\n# Contents\\n\\n- [Contents](https://mccormickml.com/mccormickml.com#contents)\\n- [S1. Clothing Review Dataset](https://mccormickml.com/mccormickml.com#s1-clothing-review-dataset)\\n  - [1.1. Download & Parse](https://mccormickml.com/mccormickml.com#11-download--parse)\\n  - [1.2. Train-Validation-Test Split](https://mccormickml.com/mccormickml.com#12-train-validation-test-split)\\n- [S2. Baseline Strategies](https://mccormickml.com/mccormickml.com#s2-baseline-strategies)\\n  - [2.1. Always Recommend](https://mccormickml.com/mccormickml.com#21-always-recommend)\\n  - [2.2. Threshold on Rating](https://mccormickml.com/mccormickml.com#22-threshold-on-rating)\\n  - [2.3. XGBoost](https://mccormickml.com/mccormickml.com#23-xgboost)\\n  - [2.4. BERT on Review Text Only](https://mccormickml.com/mccormickml.com#24-bert-on-review-text-only)\\n- [S3. BERT with All Features](https://mccormickml.com/mccormickml.com#s3-bert-with-all-features)\\n  - [3.1. All Features to Text](https://mccormickml.com/mccormickml.com#31-all-features-to-text)\\n  - [3.2. GPU & Transformers Setup](https://mccormickml.com/mccormickml.com#32-gpu--transformers-setup)\\n  - [3.3. Training Parameters](https://mccormickml.com/mccormickml.com#33-training-parameters)\\n  - [3.3. Tokenize & Encode](https://mccormickml.com/mccormickml.com#33-tokenize--encode)\\n  - [3.4. Training](https://mccormickml.com/mccormickml.com#34-training)\\n    - [3.4.1. Setup](https://mccormickml.com/mccormickml.com#341-setup)\\n    - [3.4.2. Training Loop](https://mccormickml.com/mccormickml.com#342-training-loop)\\n    - [3.4.3. Training Results](https://mccormickml.com/mccormickml.com#343-training-results)\\n  - [3.5. Test](https://mccormickml.com/mccormickml.com#35-test)\\n- [Conclusion](https://mccormickml.com/mccormickml.com#conclusion)\\n\\n# S1. Clothing Review Dataset\\n\\n## 1.1. Download & Parse\\n\\nRetrieve the .csv file for the dataset.\\n\\n```\\nimport gdown\\n\\nprint('Downloading dataset...\\\\n')\\n\\n# Download the file.\\ngdown.download('https://drive.google.com/uc?id=1ZYdt0zN4LjWqP3cQDblNhXjeohcryY5H',\\n                'Womens Clothing E-Commerce Reviews.csv',\\n                quiet=False)\\n\\nprint('\\\\n\\\\nDONE.')\\n```\\n\\n```\\nDownloading dataset...\\n\\nDownloading...\\nFrom: https://drive.google.com/uc?id=1ZYdt0zN4LjWqP3cQDblNhXjeohcryY5H\\nTo: /content/Womens Clothing E-Commerce Reviews.csv\\n8.48MB [00:00, 48.7MB/s]\\n\\nDONE.\\n\\n```\\n\\nParse the dataset csv file into a pandas DataFrame.\\n\\n```\\nimport pandas as pd\\n\\ndata_df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv', index_col=0)\\n\\ndata_df.head()\\n```\\n\\n| Clothing ID | Age | Title | Review Text | Rating | Recommended IND | Positive Feedback Count | Division Name | Department Name | Class Name |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 767 | 33 | NaN | Absolutely wonderful - silky and sexy and comf... | 4 | 1 | 0 | Initmates | Intimate | Intimates |\\n| 1 | 1080 | 34 | NaN | Love this dress! it's sooo pretty. i happene... | 5 | 1 | 4 | General | Dresses | Dresses |\\n| 2 | 1077 | 60 | Some major design flaws | I had such high hopes for this dress and reall... | 3 | 0 | 0 | General | Dresses | Dresses |\\n| 3 | 1049 | 50 | My favorite buy! | I love, love, love this jumpsuit. it's fun, fl... | 5 | 1 | 0 | General Petite | Bottoms | Pants |\\n| 4 | 847 | 47 | Flattering shirt | This shirt is very flattering to all due to th... | 5 | 1 | 6 | General | Tops | Blouses |\\n\\n_Features_\\n\\n‚Äú **Recommended IND**‚Äù is the label we are trying to predict for this dataset. ‚Äú1‚Äù means the reviewer recommended the product and ‚Äú0‚Äù means they do not.\\n\\nThe following are _categorical_ features:\\n\\n- Division Name\\n- Department Name\\n- Class Name\\n- Clothing ID\\n\\nAnd the following are _numerical_ features:\\n\\n- Age\\n- Rating\\n- Positive Feedback Count\\n\\n_Feature Analysis_\\n\\nThere is an excellent Notebook on Kaggle [here](https://www.kaggle.com/bhaveshkumar2806/complete-eda-and-visualization-of-text-data) which does some thorough analysis on each of the features in this dataset.\\n\\nNote that, in addition to the ‚ÄúRecommended‚Äù label, there is also a ‚Äú **Rating**‚Äù column where the reviewer rates the product from 1 - 5. The analysis in the above Notebook shows that almost all items rated 3 - 5 are recommended, and almost all rated 1 - 2 are not recommended. We‚Äôll see in our second baseline classifier that you can get a very high accuracy with this feature alone. However, it _is_ still possible to do better by incorporating the other features!\\n\\n## 1.2. Train-Validation-Test Split\\n\\nI want to use the same training, validation, and test splits for all of the approaches we try so that it‚Äôs a fair comparison.\\n\\nHowever, different approaches are going to require different transformations on the data, and for simplicity I want to apply those transformations _before_ splitting the dataset.\\n\\nTo solve this, we‚Äôre going to create lists of indeces for each of the three portions. That way, for a given classification approach, we can load the whole dataset, apply our transformations, and then split it according to these pre-determined indeces.\\n\\n```\\nimport random\\nimport numpy as np\\n\\n# First, calculate the split sizes. 80% training, 10% validation, 10% test.\\ntrain_size = int(0.8 * len(data_df))\\nval_size = int(0.1 * len(data_df))\\ntest_size = len(data_df) - (train_size + val_size)\\n\\n# Sanity check the sizes.\\nassert((train_size + val_size + test_size) == len(data_df))\\n\\n# Create a list of indeces for all of the samples in the dataset.\\nindeces = np.arange(0, len(data_df))\\n\\n# Shuffle the indeces randomly.\\nrandom.shuffle(indeces)\\n\\n# Get a list of indeces for each of the splits.\\ntrain_idx = indeces[0:train_size]\\nval_idx = indeces[train_size:(train_size + val_size)]\\ntest_idx = indeces[(train_size + val_size):]\\n\\n# Sanity check\\nassert(len(train_idx) == train_size)\\nassert(len(test_idx) == test_size)\\n\\n# With these lists, we can now select the corresponding dataframe rows using,\\n# e.g., train_df = data_df.iloc[train_idx]\\n\\nprint('  Training size: {:,}'.format(train_size))\\n...\", \"url\": \"https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert\"}, {\"title\": \"The Kaggle Grandmasters Playbook: 7 Battle-Tested Modeling Techniques for Tabular Data\", \"text\": \"The Kaggle Grandmasters Playbook: 7 Battle&#x2d;Tested Modeling Techniques for Tabular Data | NVIDIA Technical Blog\\n[](https://developer.nvidia.com/)[DEVELOPER](https://developer.nvidia.com/)\\n[Technical Blog](https://developer.nvidia.com/blog)\\n[Subscribe](https://developer.nvidia.com/email-signup)\\n[Related Resources**](#main-content-end)\\n[Data Science](https://developer.nvidia.com/blog/category/data-science/)\\nEnglish‰∏≠Êñá\\n# The Kaggle Grandmasters Playbook: 7 Battle-Tested Modeling Techniques for Tabular Data\\nLessons from years of competitions, made practical with GPU acceleration.\\n![](https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/Kaggle-Grandmasters-Playbook-featured-1024x576-png.webp)\\nSep 18, 2025\\nBy[Kazuki Onodera](https://developer.nvidia.com/blog/author/kazuki-onodera/),[Th√©o Viel](https://developer.nvidia.com/blog/author/tviel/),[Gilberto Titericz](https://developer.nvidia.com/blog/author/gillbertotitericz/)and[Chris Deotte](https://developer.nvidia.com/blog/author/cdeotte/)\\n**\\nLike\\n[**Discuss (1)](#entry-content-comments)\\n* [L](https://www.linkedin.com/sharing/share-offsite/?url=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/)\\n* [T](https://twitter.com/intent/tweet?text=The+Kaggle+Grandmasters+Playbook:+7+Battle-Tested+Modeling+Techniques+for+Tabular+Data+|+NVIDIA+Technical+Blog+https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/)\\n* [F](https://www.facebook.com/sharer/sharer.php?u=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/)\\n* [R](https://www.reddit.com/submit?url=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/&amp;title=The+Kaggle+Grandmasters+Playbook:+7+Battle-Tested+Modeling+Techniques+for+Tabular+Data+|+NVIDIA+Technical+Blog)\\n* [E](<mailto:?subject=I'd like to share a link with you&body=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/>)\\nAI-Generated Summary\\nLike\\nDislike\\n* The authors have developed a playbook for solving real-world tabular problems, refined through hundreds of Kaggle competitions, which emphasizes fast experimentation and careful validation.\\n* Key techniques include using GPU acceleration for dataframe operations and model training with NVIDIA cuML or GPU backends of XGBoost, LightGBM, and CatBoost to enable rapid iteration.\\n* The authors also stress the importance of techniques like k-fold cross-validation, diverse baselines, feature engineering, hill climbing, stacking, pseudo-labeling, and extra training to improve model performance and robustness.\\nAI-generated content may summarize information incompletely. Verify important information.[Learn more](https://www.nvidia.com/en-us/agreements/trustworthy-ai/terms/)\\nOver hundreds of Kaggle competitions, we&#8217;ve refined a playbook that consistently lands us near the top of the leaderboard‚Äîno matter if we‚Äôre working with millions of rows, missing values, or test sets that behave nothing like the training data. This isn‚Äôt just a collection of modeling tricks‚Äîit‚Äôs a repeatable system for solving real-world tabular problems fast.\\nBelow are seven of our most battle-tested techniques, each one made practical through GPU acceleration. Whether you‚Äôre climbing the leaderboard or deploying models in production, these strategies can give you an edge.\\nWe‚Äôve included links to example write-ups or notebooks from past competitions for each technique.\\n**Note:**Kaggle and Google Colab notebooks come with free GPUs and accelerated drop-ins like the ones you‚Äôll see below pre-installed.\\n## Core principles: the foundations of a winning workflow[**](#core_principles_the_foundations_of_a_winning_workflow)\\nBefore diving into techniques, it‚Äôs worth pausing to cover the two principles that power everything in this playbook: fast experimentation and careful validation. These aren‚Äôt optional best practices‚Äîthey‚Äôre the foundation of how we approach every tabular modeling problem.\\n### Fast experimentation[**](#fast_experimentation)\\nThe biggest lever we have in any competition or real-world project is the number of high-quality experiments we can run. The more we iterate, the more patterns we discover‚Äîand the faster we catch when a model is failing, drifting, or overfitting‚Äîso we can course-correct early and improve faster.\\nIn practice, that means we optimize our entire pipeline for speed, not just our model training step.\\n**Here‚Äôs how we make it work:**\\n* Accelerate dataframe operations using[GPU drop-in replacements](https://developer.nvidia.com/blog/7-drop-in-replacements-to-instantly-speed-up-your-python-data-science-workflows/?linkId=100000376196126)for pandas or Polars to transform and engineer features at scale.\\n* Train models with[NVIDIA cuML](https://developer.nvidia.com/topics/ai/data-science/cuda-x-data-science-libraries/cuml)or GPU backends of XGBoost, LightGBM, and CatBoost.\\nGPU acceleration isn‚Äôt just for deep learning‚Äîit&#8217;s often the only way to make advanced tabular techniques practical at scale.\\n### Local Validation[**](#local_validation)\\nIf you can‚Äôt trust your validation score, you‚Äôre flying blind. That‚Äôs why cross-validation (CV) is a cornerstone to our workflow.\\n**Our approach:**\\n* Use k-fold cross-validation, where the model trains on most of the data and tests on the part that‚Äôs held out.\\n* Rotate through folds so every part of the data is tested once.\\nThis gives a much more reliable measure of performance than a single train/validation split.\\n**Pro tip:**Match your CV strategy to how the test data is structured.\\n**For example:**\\n* Use TimeSeriesSplit for time-dependent data\\n* Use GroupKFold for grouped data (like users or patients)\\nWith those foundations in place‚Äîmoving fast and validating carefully‚Äîwe can now dive into the techniques themselves. Each one builds on these principles and shows how we turn raw data into world-class models.\\n## 1. Start with smarter EDA, not just the basics[**](#1_start_with_smarter_eda_not_just_the_basics)\\nMost practitioners know the basics: Check for missing values, outliers, correlations, and feature ranges. Those steps are important, but they‚Äôre table stakes. To build models that hold up in the real world, you need to explore the data a little deeper‚Äîa couple of quick checks that we‚Äôve found useful, but many people miss:\\n**Train vs. test distribution checks:**Spot when evaluation data differs from training, since distribution shift can cause models to validate well but fail in deployment.\\n*Figure 1. Comparing feature distributions between train (blue) and test (red) reveals a clear shift‚Äîtest data is concentrated in a higher range, with minimal overlap. This kind of distribution shift can cause models to validate well but fail in deployment.*\\n**Analyze target variable for temporal patterns:**Check for trends or seasonality, since ignoring temporal patterns can lead to models that look accurate in training but break in production.\\n*Figure 2. Analyzing the target variable over time uncovers a strong upward trend with seasonal fluctuations and accelerating growth. Ignoring temporal patterns like these can mislead models unless time-aware validation is used.*\\nThese techniques aren&#8217;t brand new‚Äîbut they‚Äôre often overlooked, and ignoring them can sink a project.\\n**Why it matters:**Skipping these checks can derail an otherwise solid workflow.\\n**In action:**In the winning solution to the Amazon KDD Cup ‚Äò23, the team uncovered both a train‚Äîtest distribution shift and temporal patterns in the target‚Äîinsights that shaped the final approach.[Read the full write-up &gt;](https://openreview.net/forum?id=J3wj55kK5t)\\n**Made practical with GPUs:**Real-world datasets are often millions of rows, which can slow to a crawl in pandas. By adding GPU acceleration with[NVIDIA cuDF](https:...\", \"url\": \"https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data\"}, {\"title\": \"Benchmarking Multimodal AutoML for Tabular Data with Text Fields\", \"text\": \"#### Benchmarking Multimodal AutoML for Tabular Data with Text Fields\\n\\nPart of\\n[Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1 (NeurIPS Datasets and Benchmarks 2021)](https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021) round2\\n\\n[Bibtex](https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/28-/bibtex) [Paper](https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Paper-round2.pdf) [Reviews And Public Comment ¬ª](https://openreview.net/forum?id=Q0zOIaec8HF) [Supplemental](https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Supplemental-round2.zip)\\n\\n#### Authors\\n\\n_Xingjian Shi, Jonas Mueller, Nick Erickson, Nick Erickson, Mu Li, Alexander Smola, Alexander Smola_\\n\\n#### Abstract\\n\\nWe consider the use of automated supervised learning systems for data tables that not only contain numeric/categorical columns, but one or more text fields as well. Here we assemble 18 multimodal data tables that each contain some text fields and stem from a real business application. Our publicly-available benchmark enables researchers to comprehensively evaluate their own methods for supervised learning with numeric, categorical, and text features. To ensure that any single modeling strategy which performs well over all 18 datasets will serve as a practical foundation for multimodal text/tabular AutoML, the diverse datasets in our benchmark vary greatly in: sample size, problem types (a mix of classification and regression tasks), number of features (with the number of text columns ranging from 1 to 28 between datasets), as well as how the predictive signal is decomposed between text vs. numeric/categorical features (and predictive interactions thereof). Over this benchmark, we evaluate various straightforward pipelines to model such data, including standard two-stage approaches where NLP is used to featurize the text such that AutoML for tabular data can then be applied. Compared with human data science teams, the fully automated methodology that performed best on our benchmark also manages to rank 1st place when fit to the raw text/tabular data in two MachineHack prediction competitions and 2nd place (out of 2380 teams) in Kaggle's Mercari Price Suggestion Challenge.\\n\\nDo not remove: This comment is monitored to verify that the site is working properly\", \"url\": \"https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/9bf31c7ff062936a96d3c8bd1f8f2ff3-Abstract-round2.html\"}, {\"title\": \"A Package for Learning on Tabular and Text Data with Transformers\", \"text\": \"Proceedings of the Third Workshop on Multimodal Artificial Intelligence, pages 69‚Äì73\\nJune 6, 2021. ¬©2021 Association for Computational Linguistics\\n69\\nMultimodal-Toolkit: A Package for Learning on Tabular and\\nText Data with Transformers\\nKen Gu\\nGeorgian\\nken.gu@georgian.io\\nAkshay Budhkar\\nGeorgian\\nakshay@georgian.io\\nAbstract\\nRecent progress in natural language process\\u0002ing has led to Transformer architectures be\\u0002coming the predominant model used for nat\\u0002ural language tasks. However, in many real\\u0002world datasets, additional modalities are in\\u0002cluded which the Transformer does not di\\u0002rectly leverage. We present Multimodal\\u0002Toolkit,1\\nan open-source Python package to\\nincorporate text and tabular (categorical and\\nnumerical) data with Transformers for down\\u0002stream applications. Our toolkit integrates\\nwell with Hugging Face‚Äôs existing API such as\\ntokenization and the model hub2 which allows\\neasy download of different pre-trained models.\\n1 Introduction\\nIn recent years, Transformers (Vaswani et al.,\\n2017) have become popular for model pre-training\\n(Howard and Ruder, 2018; Peters et al., 2018; De\\u0002vlin et al., 2019) and have yielded state-of-the-art\\nresults on many natural language processing (NLP)\\ntasks. In addition, well-documented Transformer\\nlibraries such as Hugging Face Transformers (Wolf\\net al., 2020), and AllenNLP (Gardner et al., 2018)\\nhave democratized NLP, making it easier to pro\\u0002ductionize and experiment on Transformers.\\nHowever, there are not a lot of comprehensive\\ntools for Transformers to work with tabular data.\\nOften in real-world datasets, there are tabular data\\nas well as unstructured text data which can pro\\u0002vide meaningful signals for the task at hand. For\\ninstance, in the small example in Figure 1, each\\nrow is a data point. Columns Title and Review\\nText contain text features, columns Division\\nName, Class Name, and Department Name\\ncontain categorical features, and the Age column\\nis a numerical feature. To the best of our knowl\\u0002edge, no tool exists that makes it simple for Trans\\u0002formers to handle this extra modality. Therefore,\\n1Github: https://git.io/JO5a6\\n2https://huggingface.co/docs\\nFigure 1: An example of a clothing review classifica\\u0002tion dataset. Each row is a data point consisting of text,\\ncategorical features, and numerical features.\\ngiven the advances of Transformers for natural\\nlanguage tasks and the maturity of existing Trans\\u0002former libraries, we introduce Multimodal-Toolkit,\\na lightweight Python package built on top of Hug\\u0002ging Face Transformers. Our package extends ex\\u0002isting Transformers in the Hugging Face‚Äôs Trans\\u0002formers library to seamlessly handle structured tab\\u0002ular data while keeping the existing tokenization\\n(including subword segmentation), experimental\\npipeline, and pre-trained model hub functionalities\\nof Hugging Face Transformers. We show the effec\\u0002tiveness of our toolkit on three real-world datasets.\\n2 Related Work\\nThere have been several proposed Transformer\\nmodels that aim to handle text features and addi\\u0002tional features of another modality. For pre-trained\\nTransformers on images and text, models such as\\nViLBERT (Lu et al., 2019) and VLBERT (Su et al.,\\n2020) are mainly the same as the original BERT\\nmodel but treat the extra image modality as addi\\u0002tional tokens to the input. These models require\\npre-training on multimodal image and text data.\\nOn the other hand, while treating image features\\n70\\nas additional input tokens, MMBT (Kiela et al.,\\n2019) proposes to use pre-trained BERT directly\\nand fine-tune on image and text data. This is simi\\u0002lar to Multimodal-Toolkit in which no pre-training\\non text and tabular data is needed.\\nLikewise, Transformers have been adapted to\\nalign, audio, visual, and text modalities in which\\nthere is a natural ground truth alignment. MulT\\n(Tsai et al., 2019) is similar to ViLBert in which\\nco-attention is used between pairs of modalities but\\nalso includes temporal convolutions so that input to\\u0002kens are aware of their temporal neighbors. Mean\\u0002while, Rahman et al. (2020) injects cross modality\\nattention at certain Transformer layers via a gating\\nmechanism.\\nFinally, knowledge graph embeddings have also\\nbeen effectively combined with input text tokens\\nin Transformers. Ostendorff et al. (2019) com\\u0002bines knowledge graph embeddings on authors\\nwith book titles and other metadata features via\\nsimple concatenation for book genre classification.\\nOn the other hand, for more general language tasks,\\nERNIE (Zhang et al., 2019) first matches the to\\u0002kens in the input text with entities in the knowledge\\ngraph. With this matching, the model fuses these\\nembeddings to produce entity-aware text embed\\u0002dings and text-aware entity embeddings.\\nHowever, these models do not capture categor\\u0002ical and numerical data explicitly. Hugging Face\\ndoes include LXMERT (Tan and Bansal, 2019) to\\nhandle language and vision modality but this can\\nnot be easily adapted for categorical and numeri\\u0002cal data. Nevertheless, existing multimodal Trans\\u0002former models do give good insights into how to\\ncombine categorical and numerical features. ViL\\u0002BERT and VLBERT for example include image\\nmodality as input tokens which lead to one of our\\nsimple baseline of categorical and numerical fea\\u0002tures as additional token inputs to the model. Like\\u0002wise, the gating mechanism Rahman et al. (2020),\\nattention, and different weighting schemes have\\nall been shown to be useful in combining different\\nmodalities.\\n3 Design\\nThe goal of Multimodal-Toolkit is to allow users\\nto quickly adapt state-of-the-art Transformer mod\\u0002els for situations involving text and tabular data\\nwhich occur often in real-world datasets. More\\u0002over, we want to bring the benefits of Transformers\\nto more use cases while making it simple for users\\nFigure 2: The framework of Multimodal-Toolkit.\\nThere is a data processing module that outputs pro\\u0002cessed text, numerical, and categorical features that are\\nthen fed as input to our Transformer With Tabular mod\\u0002ule consisting of a Hugging Face Transformer and our\\ncombining module.\\nof Hugging Face Transformers to adopt. Therefore,\\nwe maintain the existing interface of the popular\\nHugging Face Transformers library.\\nThis design enables us to easily include more\\nTransformer models, leverage strengths of spe\\u0002cific models, use a feature-rich training pipeline,\\nand integrate the thousands of community trained\\nmodels on Hugging Face‚Äôs model hub. We sup\\u0002port a variety of Transformers (e.g. BERT, AL\\u0002BERT, RoBERTa, XLNET) for both classification\\nand regression tasks. All together, this becomes a\\nreusable Transformer With Tabular component. We\\nalso provide a data preprocessing module for cate\\u0002gorical and numerical features. An overview of the\\nsystem is shown in Figure 2. Currently, the library\\nsupports PyTorch Transformers implementations.\\n3.1 Combining Module\\nWe implement a combining module that is model\\nagnostic that takes as input, x, the text features\\noutputted from a Transformer model and prepro\\u0002cessed categorical (c) and numerical (n) features,\\nand outputs a combined multimodal representation\\nm. Although existing multimodal Transformers\\nincorporate cross-modal attention inside middle\\nTransformer layers, we choose the design in which\\nthe modality combination comes after the Trans\\u0002former because this module can be easily included\\nwithout much adaptation of the existing Hugging\\nFace Transformer interface and can be easily ex\\u0002tended to new Transformers included in the future.\\nInside the combining module, we implement var-\\n71\\nCombine Feature Method Equation\\nText only m = x\\nConcat m = x||c||n\\nIndividual MLPs on categorical and\\u0002numerical features then concat (MLP + Concat) m = x||MLP(c)||MLP(n)\\nMLP on concatenated categorical and\\nnumerical features then concat (Concat + MLP) m = x||MLP(c||n)\\nAttention on categorical and numerical\\nfeatures (Attention)\\nm = Œ±x,xWxx + Œ±x,cWcc + Œ±x,nWnn\\nŒ±i,j =\\nexp(LeakyReLU(a\\nT\\n[Wixi||Wjxj ]))\\nP\\nk‚àà{x,c,n}\\nexp(LeakyReLU(aT [Wixi||Wkxk]))\\nGating on categorical and numerical\\nfeatures and then sum (Rahman et al., 2020)\\n(Gating)\\nm = x + Œ±h\\nh = gc \\f (Wcc...\", \"url\": \"https://aclanthology.org/2021.maiworkshop-1.10.pdf\"}, {\"title\": \"Papers with Code - Benchmarking Multimodal AutoML for Tabular Data with Text Fields\", \"text\": \"new\\n\\nGet trending papers in your email inbox once a day!\\n\\nGet trending papers in your email inbox!\\n\\n[Subscribe](https://paperswithcode.com/login?next=%2Fpapers)\\n\\n# Trending Papers\\n\\n## by [AK](https://paperswithcode.com/akhaliq) and the research community\\n\\n- Daily\\n- Weekly\\n- Monthly\\n\\nTrending Papers\\n\\nSubmitted by\\nhiyouga\\n\\n### [VeOmni: Scaling Any Modality Model Training with Model-Centric\\\\ Distributed Recipe Zoo](https://paperswithcode.com/papers/2508.02317)\\n\\nRecent advances in large language models (LLMs) have driven impressive\\nprogress in omni-modal understanding and generation. However, training\\nomni-modal LLMs remains a significant challenge due to the heterogeneous model\\narchitectures required to process diverse modalities, necessitating\\nsophisticated system design for efficient large-scale training. Existing\\nframeworks typically entangle model definition with parallel logic, incurring\\nlimited scalability and substantial engineering overhead for end-to-end\\nomni-modal training. % We present \\\\\\\\veomni, a modular and efficient training\\nframework to accelerate the development of omni-modal LLMs. \\\\\\\\veomni introduces\\nmodel-centric distributed recipes that decouples communication from\\ncomputation, enabling efficient 3D parallelism on omni-modal LLMs. \\\\\\\\veomni also\\nfeatures a flexible configuration interface supporting seamless integration of\\nnew modalities with minimal code change. % Using \\\\\\\\veomni, a omni-modal\\nmixture-of-experts (MoE) model with 30B parameters can be trained with over\\n2,800 tokens/sec/GPU throughput and scale to 160K context lengths via 3D\\nparallelism on 128 GPUs, showcasing its superior efficiency and scalability for\\ntraining large omni-modal LLMs.\\n\\n- 12 authors\\n\\n¬∑Published on Aug 4, 2025\\n\\n[Upvote\\\\\\n\\\\\\n15](https://paperswithcode.com/login?next=%2Fpapers%2F2508.02317)\\n\\n[GitHub717](https://github.com/ByteDance-Seed/VeOmni) [arXiv Page](https://arxiv.org/abs/2508.02317)\\n\\nSubmitted by\\nhiyouga\\n\\n### [VeOmni: Scaling Any Modality Model Training with Model-Centric\\\\ Distributed Recipe Zoo](https://paperswithcode.com/papers/2508.02317)\\n\\nRecent advances in large language models (LLMs) have driven impressive\\nprogress in omni-modal understanding and generation. However, training\\nomni-modal LLMs remains a significant challenge due to the heterogeneous model\\narchitectures required to process diverse modalities, necessitating\\nsophisticated system design for efficient large-scale training. Existing\\nframeworks typically entangle model definition with parallel logic, incurring\\nlimited scalability and substantial engineering overhead for end-to-end\\nomni-modal training. % We present \\\\\\\\veomni, a modular and efficient training\\nframework to accelerate the development of omni-modal LLMs. \\\\\\\\veomni introduces\\nmodel-centric distributed recipes that decouples communication from\\ncomputation, enabling efficient 3D parallelism on omni-modal LLMs. \\\\\\\\veomni also\\nfeatures a flexible configuration interface supporting seamless integration of\\nnew modalities with minimal code change. % Using \\\\\\\\veomni, a omni-modal\\nmixture-of-experts (MoE) model with 30B parameters can be trained with over\\n2,800 tokens/sec/GPU throughput and scale to 160K context lengths via 3D\\nparallelism on 128 GPUs, showcasing its superior efficiency and scalability for\\ntraining large omni-modal LLMs.\\n\\n- 12 authors\\n\\n¬∑Aug 4, 2025\\n\\n[Upvote\\\\\\n\\\\\\n15](https://paperswithcode.com/login?next=%2Fpapers%2F2508.02317)\\n\\n[GitHub717](https://github.com/ByteDance-Seed/VeOmni) [arXiv Page](https://arxiv.org/abs/2508.02317)\\n\\nSubmitted by\\nFrancisRing\\n\\n### [StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation](https://paperswithcode.com/papers/2508.08248)\\n\\nCurrent diffusion models for audio-driven avatar video generation struggle to\\nsynthesize long videos with natural audio synchronization and identity\\nconsistency. This paper presents StableAvatar, the first end-to-end video\\ndiffusion transformer that synthesizes infinite-length high-quality videos\\nwithout post-processing. Conditioned on a reference image and audio,\\nStableAvatar integrates tailored training and inference modules to enable\\ninfinite-length video generation. We observe that the main reason preventing\\nexisting models from generating long videos lies in their audio modeling. They\\ntypically rely on third-party off-the-shelf extractors to obtain audio\\nembeddings, which are then directly injected into the diffusion model via\\ncross-attention. Since current diffusion backbones lack any audio-related\\npriors, this approach causes severe latent distribution error accumulation\\nacross video clips, leading the latent distribution of subsequent segments to\\ndrift away from the optimal distribution gradually. To address this,\\nStableAvatar introduces a novel Time-step-aware Audio Adapter that prevents\\nerror accumulation via time-step-aware modulation. During inference, we propose\\na novel Audio Native Guidance Mechanism to further enhance the audio\\nsynchronization by leveraging the diffusion's own evolving joint audio-latent\\nprediction as a dynamic guidance signal. To enhance the smoothness of the\\ninfinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy\\nthat fuses latent over time. Experiments on benchmarks show the effectiveness\\nof StableAvatar both qualitatively and quantitatively.\\n\\n- 9 authors\\n\\n¬∑Published on Aug 11, 2025\\n\\n[Upvote\\\\\\n\\\\\\n14](https://paperswithcode.com/login?next=%2Fpapers%2F2508.08248)\\n\\n[GitHub262](https://github.com/Francis-Rings/StableAvatar) [arXiv Page](https://arxiv.org/abs/2508.08248)\\n\\nSubmitted by\\nFrancisRing\\n\\n### [StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation](https://paperswithcode.com/papers/2508.08248)\\n\\nCurrent diffusion models for audio-driven avatar video generation struggle to\\nsynthesize long videos with natural audio synchronization and identity\\nconsistency. This paper presents StableAvatar, the first end-to-end video\\ndiffusion transformer that synthesizes infinite-length high-quality videos\\nwithout post-processing. Conditioned on a reference image and audio,\\nStableAvatar integrates tailored training and inference modules to enable\\ninfinite-length video generation. We observe that the main reason preventing\\nexisting models from generating long videos lies in their audio modeling. They\\ntypically rely on third-party off-the-shelf extractors to obtain audio\\nembeddings, which are then directly injected into the diffusion model via\\ncross-attention. Since current diffusion backbones lack any audio-related\\npriors, this approach causes severe latent distribution error accumulation\\nacross video clips, leading the latent distribution of subsequent segments to\\ndrift away from the optimal distribution gradually. To address this,\\nStableAvatar introduces a novel Time-step-aware Audio Adapter that prevents\\nerror accumulation via time-step-aware modulation. During inference, we propose\\na novel Audio Native Guidance Mechanism to further enhance the audio\\nsynchronization by leveraging the diffusion's own evolving joint audio-latent\\nprediction as a dynamic guidance signal. To enhance the smoothness of the\\ninfinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy\\nthat fuses latent over time. Experiments on benchmarks show the effectiveness\\nof StableAvatar both qualitatively and quantitatively.\\n\\n- 9 authors\\n\\n¬∑Aug 11, 2025\\n\\n[Upvote\\\\\\n\\\\\\n14](https://paperswithcode.com/login?next=%2Fpapers%2F2508.08248)\\n\\n[GitHub262](https://github.com/Francis-Rings/StableAvatar) [arXiv Page](https://arxiv.org/abs/2508.08248)\\n\\nSubmitted by\\ncsuhan\\n\\n### [ScreenCoder: Advancing Visual-to-Code Generation for Front-End\\\\ Automation via Modular Multimodal Agents](https://paperswithcode.com/papers/2507.22827)\\n\\nAutomating the transformation of user interface (UI) designs into front-end\\ncode holds significant promise for accelerating software development and\\ndemocratizing design workflows. While recent large language models (LLMs) have\\ndemonstrated progress in text-to-code generation, many existing approaches rely\\nsolely o...\", \"url\": \"https://paperswithcode.com/paper/benchmarking-multimodal-automl-for-tabular\"}, {\"title\": \"Towards Benchmarking Foundation Models for Tabular Data With Text\", \"text\": \"Towards Benchmarking Foundation Models for Tabular Data With Text\\nMartin Mraz¬¥\\n* 1 Breenda Das * 1 Anshul Gupta * 1 Lennart Purucker 1 Frank Hutter 2 3 1\\nAbstract\\nFoundation models for tabular data are rapidly\\nevolving, with increasing interest in extending\\nthem to support additional modalities such as free\\u0002text features. However, existing benchmarks for\\ntabular data rarely include textual columns, and\\nidentifying real-world tabular datasets with se\\u0002mantically rich text features is non-trivial. We\\npropose a series of simple yet effective ablation\\u0002style strategies for incorporating text into con\\u0002ventional tabular pipelines. Moreover, we bench\\u0002mark how state-of-the-art tabular foundation mod\\u0002els can handle textual data by manually curating\\na collection of real-world tabular datasets with\\nmeaningful textual features. Our study is an im\\u0002portant step towards improving benchmarking of\\nfoundation models for tabular data with text.\\n1. Introduction\\nFoundation models have begun to transform tabular learn\\u0002ing (Erickson et al., 2020b; Hollmann et al., 2025), echo\\u0002ing the trajectory of other research fields. A natural next\\nstep is mixed-modality tabular modeling, where structured\\ncolumns may also include free-text fields such as job de\\u0002scriptions, clinical notes, or product summaries. Current\\ntabular benchmarks, however, almost never contain textual\\ncolumns, cf. (Bischl et al., 2019; Liu et al., 2024; McEl\\u0002fresh et al., 2024). Moreover, locating real-world datasets\\nwith semantically rich text features is exceptionally difficult,\\nwith even exhaustive searches of OpenML and Kaggle only\\nyielding a handful of usable candidates (Shi et al., 2021).\\nConsequently, current tabular foundation models are rarely\\nevaluated for tabular data with text.\\nPipelines that can handle tabular data with text vary greatly\\n*Equal contribution 1Department of Computer Science, Uni\\u0002versity of Freiburg, Freiburg, Germany 2\\nPrior Labs, Freiburg,\\nGermany 3ELLIS Institute, Tubingen, Germany. Correspon\\u0002dence to: Martin Mraz <mrazm@informatik.uni-freiburg.de>,\\nBreenda Das <dasb@informatik.uni-freiburg.de>, Anshul Gupta\\n<guptaa@informatik.uni-freiburg.de>.\\nProceedings of the 42 nd International Conference on Machine\\nLearning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025\\nby the author(s).\\nin their implementation. AutoGluon‚Äôs AutoMLPipeline\\u0002FeatureGenerator (Erickson et al., 2020a) converts text to\\nsparse vectors; CARTE (Kim et al., 2024) applies fastText\\nsentence embeddings (Bojanowski et al., 2017). and the\\nTabPFNv2 API accepts raw text but does not disclose its\\nmethodology. These divergent choices raise a fundamental\\nquestion: Which embedding strategy works best, and under\\nwhat conditions?\\nTo answer this question, we present the first systematic\\nstudy of predictive machine learning with foundation mod\\u0002els for tabular data with text. We study the performance\\nof three representative embedding routes: fastText, Skrub‚Äôs\\nTableVectorizer, and AutoGluon‚Äôs text encoder. We show\\nqualitatively, with a simple synthetic counter-example, that\\nboth n-gram based and off-the-shelf sentence embeddings\\ncan fail to recover highly predictive semantic patterns. More\\u0002over, quantitatively, we evaluate these methods on a man\\u0002ually curated set of real-world tabular benchmark that (i)\\ncontain genuinely informative free-text columns (ii) spans\\nover a variety of domains and samples.\\nOur contributions are: (I) A qualitative study show cas\\u0002ing the limitations of standard n-gram based and generic\\nNLP-based embeddings for tabular tasks with text. (II) A\\nmanually curated set of real-world tabular datasets with se\\u0002mantically rich textual columns. (III) An empirical study of\\nthree text embedding pipelines for TabPFNv2 and XGBoost\\nwith the TabPFNv2 API and AutoGluon Tabular Predictor\\nas baselines.\\nOur study reveals the limitations of current methods and\\nunderscores the need for new methods to handle tabular data\\nwith free text.\\n2. Related Work\\nApproaches incorporating free-text in tabular learning\\nlargely follow two paradigms. First, row-as-text meth\\u0002ods serialize entire rows into prompts and delegate pre\\u0002diction to a large language model (LLM), as seen in\\nTABLLM (Hegselmann et al., 2022), TABLE-LLM (Zhang\\net al., 2024). These work well when textual fields dominate\\nor in few-shot settings. Second, per-column embedding\\nstrategies extract textual embeddings from a single or groups\\nof features, while preserving the structural nature of tabular\\n1\\narXiv:2507.07829v1 [cs.LG] 10 Jul 2025\\nTowards Benchmarking Foundation Models for Tabular Data With Text\\nFigure 1. Qualitative investigation of textual embeddings for tabular prediction tasks: TabPFN v2 accuracy across five datasets.\\nBaselines ‚ÄúNo-Text‚Äù uses original input features, ‚ÄúComplete Leak‚Äù has target leakage, therefore 100% accuracy for all. Following tests\\nembed targets into textual modality. ‚ÄúN-Gram Break‚Äù shows TF-IDF breaking under unseen synonyms, ‚ÄúSimple NLP break‚Äù shows\\nFastText underperforming under noise, ‚ÄúLLM Breaks‚Äù shows BERT variant breaking under semantic ambiguity.\\ndata. They embed each column using fastText or LLMs\\nand then concatenate the resulting embeddings to the table,\\nor replace the feature with its individual textual embed\\u0002ding, cf. (Koloski et al., 2025; Carballo et al., 2023; Kim\\net al., 2024). Grinsztajn et al. (2023) compare 30+ LLM\\nand substring-based methods for embedding string columns,\\nshowing when LLMs yield better representations.\\nIn this study, we investigate pre-column embeddings be\\u0002cause we focus on a many-shot setting (e.g., more than 32\\ntraining samples), in which LLM-based predictive methods\\ndo not perform well, cf. (Hegselmann et al., 2023) and (Ma\\net al., 2024), or require a prohibitive amount of fine-tuning\\n(Shysheya et al., 2025).\\nMost popular prior tabular benchmarks contain no free-text\\nfield, cf. (Bischl et al., 2019; Gijsbers et al., 2022; McEl\\u0002fresh et al., 2023). For tabular data with text, Shi et al.\\n(2021) curated 18 datasets with mixed modalities, but many\\nrely almost entirely on text, with only one or two tabular\\nfeatures, or features derived from the long text, e.g. # of\\nwords (Tang et al., 2024). Thus, they benchmark text-based\\nmodels rather than tabular models, focusing on text data\\nwith tabular features. In contrast, we focus on tabular mod\\u0002els extended to handle text, focusing on tabular data with\\nadditional text features. Other studies were often limited to\\nan evaluation with just one or two datasets (Carballo et al.,\\n2023; Lu et al., 2023). Overall, existing studies for tabular\\ndata with text lack a domain-agnostic benchmark where\\ntextual features complement, rather than dominate, tabular\\ndata. This motivates the new benchmark we present.\\nThe CARTE Benchmark. The latest seminal work on\\nbenchmarking for tabular data with text is the CARTE (Kim\\net al., 2024) benchmark. It includes 51 datasets for tabu\\u0002lar data with text. However, when we investigated these\\ndatasets more closely, we found that at most 11 out of the\\n51 datasets are suited to evaluate tabular data with text.\\nMoreover, our manually curated collection of datasets for\\nbenchmarking only includes 1 out of the 51 datasets.\\nWe share an extensive report of our investigation in Ap\\u0002pendix G. In short, we found that most datasets (a) do not\\nrepresent predictive machine learning tasks for tabular data\\nwith text; (b) are skewed towards text data representing\\nmany categories instead of longer free text; (c) were pre\\u0002processed manually per dataset with logic that seems to\\nfavor CARTE; (d) or were very similar datasets from the\\nsame domain, with the same features, or similar semantic\\ncontent. Thus, while CARTE was a significant step toward\\nbenchmarking and learning for tabular data with text, it falls\\nshort in several aspects. Our work complements CARTE‚Äôs\\nefforts and aims to improve benchmarking for tabular data\\nwith text further.\\n3. Qualitative Investigation\\nIn this section, we evaluate popular text embedding tech\\u0002niques: N-Grams, simple NLP models and LLMs for tabular\\npr...\", \"url\": \"https://arxiv.org/pdf/2507.07829\"}]}",
        "tool.duration_ms": 5960.458278656006
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "6f5c21aafaab5421",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "WebSearchTool",
      "kind": "INTERNAL",
      "start_time": 1767958612432634771,
      "end_time": 1767958616514855032,
      "duration": 4.082220261,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "WebSearchTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"How do Kaggle winners handle class imbalance in binary classification with 75/25 split?\"}}",
        "tool.output": "{\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nTop Kaggle winners typically tackle a 75‚ÄØ%‚ÄØ/‚ÄØ25‚ÄØ% binary‚Äëclass split by reshaping the training data and by using metrics and model settings that reward performance on the minority class.‚ÄØThey combine resampling, class‚Äëweighting, and careful validation to keep the imbalance from biasing the model‚ÄØ([Dealing with extremely imbalanced dataset ‚Äì Kaggle](https://www.kaggle.com/questions-and-answers/473546);‚ÄØ[Unbalanced data and cross‚Äëvalidation ‚Äì Kaggle](https://www.kaggle.com/discussions/questions-and-answers/27589)).\\n\\n**Step‚Äëby‚Äëstep workflow**\\n\\n1. **Inspect the split and pick an imbalance‚Äëaware metric** ‚Äì report AUC‚ÄëROC, PR‚ÄëAUC or log‚Äëloss instead of plain accuracy, because these metrics reflect minority‚Äëclass performance‚ÄØ([Unbalanced data and cross‚Äëvalidation ‚Äì Kaggle](https://www.kaggle.com/discussions/questions-and-answers/27589)).  \\n\\n2. **Apply resampling to the training folds**  \\n   * *Undersample* the majority (75‚ÄØ%) class to a manageable size, or  \\n   * *Oversample* the minority (25‚ÄØ%) class with synthetic techniques such as **SMOTE** or ADASYN. Both approaches are standard in Kaggle solutions‚ÄØ([Dealing with extremely imbalanced dataset ‚Äì Kaggle](https://www.kaggle.com/questions-and-answers/473546);‚ÄØ[Resampling strategies for imbalanced datasets ‚Äì Kaggle](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets)).  \\n\\n3. **Add class weights (or sample weights) to the loss function** ‚Äì most libraries (e.g., XGBoost, LightGBM, sklearn) accept a `scale_pos_weight` or `class_weight` argument; setting a higher weight for the minority class forces the model to penalize its errors more heavily.  \\n\\n4. **Train robust models and ensembles** ‚Äì gradient‚Äëboosted trees, neural nets, or stacked ensembles are common; ensemble methods help smooth out variance introduced by resampling‚ÄØ([Dealing with extremely imbalanced dataset ‚Äì Kaggle](https://www.kaggle.com/questions-and-answers/473546)).  \\n\\n5. **Validate with stratified cross‚Äëvalidation** ‚Äì ensure each fold preserves the 75/25 ratio so that performance estimates remain realistic and that resampling/weighting decisions are not over‚Äëfitted.  \\n\\n6. **Fine‚Äëtune threshold post‚Äëtraining** ‚Äì after the model is fitted, adjust the decision threshold (e.g., using the ROC curve) to balance precision vs. recall according to the competition‚Äôs cost of false positives vs. false negatives.  \\n\\n7. **Monitor the minority‚Äëclass metrics on the hold‚Äëout leaderboard** ‚Äì iterate on resampling ratios, class‚Äëweight values, and ensemble composition until the minority‚Äëclass AUC/PR‚ÄëAUC improves.  \\n\\nFollowing these concise steps lets you handle a 75‚ÄØ%‚ÄØ/‚ÄØ25‚ÄØ% imbalance the way Kaggle champions do, keeping the minority class well‚Äërepresented in both training and evaluation.\\n\\n--- Result 2 ---\\nTitle: Dealing with extremely imbalanced dataset - binary classification\\nURL: https://www.kaggle.com/questions-and-answers/473546\\n\\nContent:\\nChecking your browser - reCAPTCHA\\nChecking your browser before accessing www.kaggle.com ...\\nClick[here](#)if you are not automatically redirected after 5 seconds.\\n\\n--- Result 3 ---\\nTitle: Resampling strategies for imbalanced datasets - Kaggle\\nURL: https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets\\n\\nContent:\\n- _code_\\n\\nNew Notebook\\n\\n- _table\\\\_chart_\\n\\nNew Dataset\\n\\n- _tenancy_\\n\\nNew Model\\n\\n- _emoji\\\\_events_\\n\\nNew Competition\\n\\n- _corporate\\\\_fare_\\n\\nNew Organization\\n\\n\\n## No Active Events\\n\\nCreate notebooks and keep track of their status here.\\n\\n[_add_ New Notebook](https://www.kaggle.com/code/new)\\n\\n- _auto\\\\_awesome\\\\_motion_\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0 Active Events\\n\\n\\n\\n\\n\\n\\n_expand\\\\_more_\\n\\n\\nmenu\\n\\n[Skip to\\\\\\n\\\\\\ncontent](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets#site-content)\\n\\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\\n\\nCreate\\n\\n_search_\\n\\n- [_explore_\\\\\\n\\\\\\nHome](https://www.kaggle.com/)\\n\\n- [_emoji\\\\_events_\\\\\\n\\\\\\nCompetitions](https://www.kaggle.com/competitions)\\n\\n- [_table\\\\_chart_\\\\\\n\\\\\\nDatasets](https://www.kaggle.com/datasets)\\n\\n- [_tenancy_\\\\\\n\\\\\\nModels](https://www.kaggle.com/models)\\n\\n- [_code_\\\\\\n\\\\\\nCode](https://www.kaggle.com/code)\\n\\n- [_comment_\\\\\\n\\\\\\nDiscussions](https://www.kaggle.com/discussions)\\n\\n- [_school_\\\\\\n\\\\\\nLearn](https://www.kaggle.com/learn)\\n\\n- [_expand\\\\_more_\\\\\\n\\\\\\nMore](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets)\\n\\n\\n_auto\\\\_awesome\\\\_motion_\\n\\nView Active Events\\n\\nmenu\\n\\n[Skip to\\\\\\n\\\\\\ncontent](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets#site-content)\\n\\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\\n\\n_search_\\n\\n[Sign In](https://www.kaggle.com/account/login?phase=startSignInTab&returnUrl=%2Fcode%2Frafjaa%2Fresampling-strategies-for-imbalanced-datasets)\\n\\n[Register](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2Fcode%2Frafjaa%2Fresampling-strategies-for-imbalanced-datasets)\\n\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n\\n[Learn more.](https://www.kaggle.com/cookies)\\n\\nOK, Got it.\\n\\n![Something went wrong and this page crashed!](https://www.kaggle.com/static/images/error/server-error-illo_light.svg)\\n\\n###### Something went wrong and this page crashed!\\n\\nIf the issue persists, it's likely a problem on our side.\\n\\n```\\n\\nLoading CSS chunk 5073 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 5073 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\n    at t.onerror.t.onload (https://www.kaggle.com/static/assets/runtime.js?v=e39bd89f6741bf1e27b2:1:8254)\\n```\\n\\nRefresh\\n\\n--- Result 4 ---\\nTitle: Unbalanced data and cross-validation | Kaggle\\nURL: https://www.kaggle.com/discussions/questions-and-answers/27589\\n\\nContent:\\n<div><div><p>There are two general ways of dealing with imbalanced data: 1) change the data; 2) leave the data alone but change the performance metric and/or the weight of individual data points.</p>\\n<p>Changing the data means oversampling the under-represented class(es) with synthetic data points, or undersampling (thinning down) the over-represented class(es). There are various ways of doing both operations, and I will give you one <a href=\\\"https://github.com/scikit-learn-contrib/imbalanced-learn\\\"><strong>starting point</strong></a>.</p>\\n<p>A second option is to leave the data alone and adjust how we do the training. It is crucial to pick a reliable performance metric for imbalanced data, and to know whether for your purposes it is worse to have too many false positives (FPs) or false negatives (FNs). Ideally, you wouldn't want to have either of the two, but for most applications it should be clear whether we want to avoid FPs or FNs with greater preference.</p>\\n<p>To give you an example: you have 900 healthy patients (class 0) and 100 cancer patients (class 1), which is at least somewhat close to the true ratio of healthy and cancer-stricken people out there. If you predict class 0 with 100% accuracy and class 1 with 70% accuracy, your accuracy will be 97% for the whole dataset. That sounds tremendous until we realize that 30 out of 100 cancer patients (30%) will go undiagnosed, meaning that high false negative rate in this case will cost many lives. What if we could adjust our classification so that both classes are predicted with 97% accuracy? This would mean that 27 healthy people would be predicted to have cancer (27 FPs) and 3 cancer-stricken individual would be predicted to be healthy (3 FNs). Now, I wouldn't want to be a doctor who tells a healthy person that they have a cancer because many people have been known to do silly things when they think they are dying. Still, compared to our starting premise, most would agree that on balance it is much better to have 27 people who think they have cancer and later find out they don't, and only 3 patients who were told they are healthy even though they have cancer. The problem is that a simple accuracy as a performance metric for training would never get you to a balanced 97% accuracy. For imbalanced datasets, F1-score (a weighted average of precision and recall), area under curve for ROC and Matthews correlation coefficient may be better measures of classifier quality.</p>\\n<p>See the links below for more info:</p>\\n<p><a href=\\\"http://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/\\\"><strong>link1</strong></a></p>\\n<p><a href=\\\"https://eva.fing.edu.uy/mod/resource/view.php?id=33977\\\"><strong>link2</strong></a></p>\\n<p><a href=\\\"https://www.kaggle.com/c/bosch-production-line-performance/forums/t/24120/time-effort-and-reward?forumMessageId=138285#post138285\\\"><strong>link3</strong></a></p></div></div>\\n\\n--- Result 5 ---\\nTitle: Understanding Class Imbalance in 1 Minute! - Kaggle\\nURL: https://www.kaggle.com/getting-started/467908\\n\\nContent:\\nChecking your browser - reCAPTCHA\\nChecking your browser before accessing www.kaggle.com ...\\nClick[here](#)if you are not automatically redirected after 5 seconds.\\n\\n--- Result 6 ---\\nTitle: Binary classification with strongly unbalanced classes\\nURL: https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes\\n\\nContent:\\n**Teams**\\n\\nQ&A for work\\n\\nConnect and share knowledge within a single location that is structured and easy to search.\\n\\n[Learn more about Teams](https://stackoverflow.co/teams/)\\n\\n# [Binary classification with strongly unbalanced classes](https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes)\\n\\n[Ask Question](https://stats.stackexchange.com/questions/ask)\\n\\nAsked7 years, 9 months ago\\n\\nModified [3 years, 11 months ago](https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes?lastactivity)\\n\\nViewed\\n56k times\\n\\n67\\n\\n$\\\\\\\\begingroup$\\n\\nI have a data set in the form of (features, binary output 0 or 1), but 1 happens pretty rarely, so just by always predicting 0, I get accuracy between 70% and 90% (depending on the particular data I look at). The ML methods give me about the same accuracy, and I feel, there should be some standard methods to apply in this situation, that would improve the accuracy over the obvious prediction rule.\\n\\n- [machine-learning](https://stats.stackexchange.com/questions/tagged/machine-learning)\\n- [classification](https://stats.stackexchange.com/questions/tagged/classification)\\n- [binary-data](https://stats.stackexchange.com/questions/tagged/binary-data)\\n- [unbalanced-classes](https://stats.stackexchange.com/questions/tagged/unbalanced-classes)\\n\\n[Share](https://stats.stackexchange.com/q/235808)\\n\\nCite\\n\\n[Improve this question](https://stats.stackexchange.com/posts/235808/edit)\\n\\nFollow\\n\\n[edited Oct 30, 2017 at 19:47](https://stats.stackexchange.com/posts/235808/revisions)\\n\\nLazyCat\\n\\nasked Sep 19, 2016 at 18:39\\n\\n[![LazyCat's user avatar](https://www.gravatar.com/avatar/0de65f380a7e1cb28d4f0c9c5f93fdde?s=64&d=identicon&r=PG)](https://stats.stackexchange.com/users/30893/lazycat)\\n\\n[LazyCat](https://stats.stackexchange.com/users/30893/lazycat) LazyCat\\n\\n87211 gold badge77 silver badges1111 bronze badges\\n\\n$\\\\\\\\endgroup$\\n\\n6\\n\\n- 4\\n\\n\\n\\n\\n\\n$\\\\\\\\begingroup$I've found this article to be very helpful on the subject: [svds.com/learning-imbalanced-classes](http://www.svds.com/learning-imbalanced-classes/)$\\\\\\\\endgroup$\\n\\n‚Äì¬†[J. O'Brien Antognini](https://stats.stackexchange.com/users/115448/j-obrien-antognini)\\n\\nCommentedSep 20, 2016 at 23:18\\n\\n- $\\\\\\\\begingroup$@J.O'BrienAntognini That is a really nice article!$\\\\\\\\endgroup$\\n\\n‚Äì¬†[Jinhua Wang](https://stats.stackexchange.com/users/163503/jinhua-wang)\\n\\nCommentedJan 27, 2019 at 17:22\\n\\n- $\\\\\\\\begingroup$Some useful discussion here: [stats.stackexchange.com/questions/285231/‚Ä¶](https://stats.stackexchange.com/questions/285231/what-problem-does-oversampling-undersampling-and-smote-solve?r=SearchResults&s=3|0.0000) and [stats.stackexchange.com/questions/283170/‚Ä¶](https://stats.stackexchange.com/questions/283170/when-is-unbalanced-data-really-a-problem-in-machine-learning)$\\\\\\\\endgroup$\\n\\n‚Äì¬†[Sycorax](https://stats.stackexchange.com/users/22311/sycorax) ‚ô¶\\n\\nCommentedJul 15, 2020 at 13:02\\n\\n- $\\\\\\\\begingroup$This post [here](https://stats.stackexchange.com/questions/247871/what-is-the-root-cause-of-the-class-imbalance-problem) has a very clear answer on _why_ class imbalance causes problems.$\\\\\\\\endgroup$\\n\\n‚Äì¬†[Stephen G](https://stats.stackexchange.com/users/225551/stephen-g)\\n\\nCommentedJul 15, 2020 at 13:57\\n\\n- $\\\\\\\\begingroup$@StephenG At present, the post you've linked to has three answers. Which one are you referring to?$\\\\\\\\endgroup$\\n\\n‚Äì¬†[Sycorax](https://stats.stackexchange.com/users/22311/sycorax) ‚ô¶\\n\\nCommentedJul 15, 2020 at 17:49\\n\\n\\n\\\\|¬†[Show **1** more comment](https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes)\\n\\n## 7 Answers 7\\n\\nSorted by:\\n[Reset to default](https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes?answertab=scoredesc#tab-top)\\n\\nHighest score (default)Date modified (newest first)Date created (oldest first)\\n\\n39\\n\\n$\\\\\\\\begingroup$\\n\\nBoth hxd1011 and Frank are right (+1).\\nEssentially resampling and/or cost-sensitive learning are the two main ways of getting around the problem of imbalanced data; third is to use kernel methods that sometimes might be less effected by the class imbalance.\\nLet me stress that there is no silver-bullet solution. By definition you have one class that is represented inadequately in your samples.\\n\\nHaving said the above I believe that you will find the algorithms [SMOTE](http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-106) and [ROSE](https://journal.r-project.org/archive/2014-1/menardi-lunardon-torelli.pdf) very helpful. SMOTE effectively uses a $k$-nearest neighbours approach to exclude members of the majority class while in a similar way creating synthetic examples of a minority class. ROSE tries to create estimates of the underlying distributions of the two classes using a smoothed bootstrap approach and sample them for synthetic examples. Both are readily available in R, SMOTE in the package [DMwR](https://cran.r-project.org/web/packages/DMwR/index.html) and ROSE in the package with the [same name](https://cran.r-project.org/web/packages/ROSE/index.html). Both SMOTE and ROSE result in a training dataset that is smaller than the original one.\\n\\nI would probably argue that a better (or less bad) metric for the case of imbalanced data is using [Cohen's $k$](https://en.wikipedia.org/wiki/Cohen's_kappa) and/or [Receiver operating characteristic's Area under the curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve).\\nCohen's kappa directly controls for the expected accuracy, AUC as it\\nis a function of sensitivity and specificity, the curve is insensitive to disparities in the class proportions. Again, notice that these are just metrics that should be used with a large grain of salt. You should ideally adapt them to your specific problem taking account of the gains and costs correct and wrong classifications convey in your case. I have found that looking at [lift-curves](https://en.wikipedia.org/wiki/Lift_%28data_mining%29) is actually rather informative for this matter.\\nIrrespective of your metric you should try to use a separate test to assess the performance of your algorithm; exactly because of the class imbalanced over-fitting is even more likely so out-of-sample testing is crucial.\\n\\nProbably the most popular recent paper on the matter is [Learning from Imbalanced Data](http://www.ele.uri.edu/faculty/he/PDFfiles/ImbalancedLearning.pdf) by He and Garcia. It gives a very nice overview of the points raised by myself and in other answers. In addition I believe that the walk-through on [Subsampling For Class Imbalances](http://topepo.github.io/caret/subsampling-for-class-imbalances.html), presented by Max Kuhn as part of the [caret](https://cran.r-project.org/web/packages/caret/index.html) package is an excellent resource to get a structure example of how under-/over-sampling as well as synthetic data creation can measure against each other.\\n\\n[Share](https://stats.stackexchange.com/a/235824)\\n\\nCite\\n\\n[Improve this answer](https://stats.stackexchange.com/posts/235824/edit)\\n\\nFollow\\n\\n[edited Sep 19, 2016 at 20:12](https://stats.stackexchange.com/posts/235824/revisions)\\n\\nanswered Sep 19, 2016 at 19:44\\n\\n[![usŒµr11852's user avatar](https://i.sstatic.net/Y88zz.png?s=64)](https://stats.stackexchange.com/users/11852/us%ce%b5r11852)\\n\\n[usŒµr11852](https://stats.stackexchange.com/users/11852/us%ce%b5r11852) usŒµr11852\\n\\n44.7k33 gold badges101101 silver badges158158 bronze badges\\n\\n$\\\\\\\\endgroup$\\n\\n3\\n\\n- $\\\\\\\\begingroup$A third somewhat popular (and again not too appropriate) metric is the Area-Under-the-Curve of the Precision-Recall curve. [Davis & James, 2006](https://www.biostat.wisc.edu/~page/rocpr.pdf) paper is consider a classic on the matter; CV has a good thread [too](http://stats.stackexchange.com/questions/7207). I recently saw a paper with the somewhat hammy title \\\" [The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating Binary Classifiers on Imbalanced Dat...\\n\\n--- Result 7 ---\\nTitle: Best techniques and metrics for Imbalanced Dataset - Kaggle\\nURL: https://www.kaggle.com/code/marcinrutecki/best-techniques-and-metrics-for-imbalanced-dataset\\n\\nContent:\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n\\n[Learn more](https://www.kaggle.com/cookies)\\n\\nOK, Got it.\\n\\n###### Something went wrong and this page crashed!\\n\\nIf the issue persists, it's likely a problem on our side.\\n\\n```\\n\\nLoading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\n    at r.onerror.r.onload (https://www.kaggle.com/static/assets/runtime.js?v=805aeed0a20bb825939e:1:11032)\\n```\\n\\nRefresh\\n\\n--- Result 8 ---\\nTitle: Class Imbalance Strategies ‚Äî A Visual Guide with Code - Medium\\nURL: https://medium.com/data-science/class-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a\\n\\nContent:\\n[Sitemap](https://medium.com/sitemap/sitemap.xml)\\n\\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8bc8fae71e1a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdata-science%2Fclass-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\\n\\n[Search](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdata-science%2Fclass-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n[**TDS Archive**](https://medium.com/data-science?source=post_page---publication_nav-7f60cf5620c9-8bc8fae71e1a---------------------------------------)\\n\\n¬∑\\n\\nAn archive of data science, data analytics, data engineering, machine learning, and artificial intelligence writing from the former Towards Data Science Medium publication.\\n\\n# Class Imbalance Strategies ‚Äî A Visual Guide with Code\\n\\n## Understand Random Undersampling, Oversampling, SMOTE, ADASYN, and Tomek Links\\n\\n[Travis Tang](https://medium.com/@travis-tang?source=post_page---byline--8bc8fae71e1a---------------------------------------)\\n\\n13 min read\\n\\n¬∑\\n\\nApr 24, 2023\\n\\n--\\n\\n1\\n\\nListen\\n\\nShare\\n\\nClass imbalance occurs when one class in a classification problem significantly outweighs the other class. It‚Äôs common in many machine learning problems. Examples include fraud detection, anomaly detection, and medical diagnosis.\\n\\n## The Curse of Class Imbalance\\n\\nA model trained on an imbalanced dataset perform poorly on the minority class. At best, this can cause loss to the business in the case of a churn analysis. At worst, it can pervade systemic bias of a face recognition system.\\n\\nPress enter or click to view image in full size\\n\\nA balanced dataset might just be the missing ingredient (Source: Elena Mozhvilo on [Unsplash](https://unsplash.com/photos/j06gLuKK0GM))\\n\\nThe common approach to class imbalance is resampling. These can entail oversampling the majority class, undersampling the minority class, or a combination of both.\\n\\nIn this post, I use vivid visuals and code to illustrate these strategies for class imbalance:\\n\\n1. Random oversampling\\n2. Random undersampling\\n3. Oversampling with SMOTE\\n4. Oversampling with ADASYN\\n5. Undersampling with Tomek Link\\n6. Oversampling with SMOTE, then undersample with TOMEK Link (SMOTE-Tomek)\\n\\nI will also be using these strategies on a real-world dataset, and evaluate their impact on a machine learning model. Let‚Äôs go.\\n\\n> All source code is here.\\n\\n## Using Imbalance-learn\\n\\nWe will use the `imbalanced-learn` package in python to solve our imbalanced class problem. It is an open-sourced library relying on scikit-learn and provides tools when dealing with classification with imbalanced classes.\\n\\nTo install it, use the command.\\n\\n```\\npip install -U imbalanced-learn\\n```\\n\\n## Dataset\\n\\nThe dataset that we are using is the [**Communities and Crime Data Set by UCI (CC BY 4.0)**.](https://archive.ics.uci.edu/ml/datasets/communities+and+crime) It contains 100 attributes of 1994 U.S. communities. We can use this to predict if the **crime rate is high** (defined as having **per capita violent crime** above 0.65). The data source is available in the UCI Machine Learning Repository and is created by Michael Redmond from La Salle University (Published in 2009).\\n\\n> The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of officers assigned to drug units.\\n\\nThis dataset is imbalanced. It has 12 communities with low crime rates for every 1 community of high crime rate. This is perfect to illustrate our use case.\\n\\n```\\n>>> from imblearn.datasets import fetch_datasets>>> # Fetch dataset from imbalanced-learn library >>> # as a dictionary of numpy array>>> us_crime = fetch_datasets()['us_crime']>>> us_crime{'data': array([[0.19, 0.33, 0.02, ..., 0.26, 0.2 , 0.32],        [0.  , 0.16, 0.12, ..., 0.12, 0.45, 0.  ],        [0.  , 0.42, 0.49, ..., 0.21, 0.02, 0.  ],        ...,        [0.16, 0.37, 0.25, ..., 0.32, 0.18, 0.91],        [0.08, 0.51, 0.06, ..., 0.38, 0.33, 0.22],        [0.2 , 0.78, 0.14, ..., 0.3 , 0.05, 1.  ]]), 'target': array([-1,  1, -1, ..., -1, -1, -1]), 'DESCR': 'us_crime'}\\n```\\n\\nWe will convert this dictionary to a Pandas dataframe, then split it into train-test splits.\\n\\n```\\n# Convert the dictionary to a pandas dataframecrime_df = pd.concat([pd.DataFrame(us_crime['data'], columns = [f'data_{i}' for i in range(us_crime.data.shape[1])]),           pd.DataFrame(us_crime['target'], columns = ['target'])], axis = 1)# Split data into train test setfrom sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(crime_df.drop('target', axis = 1),                                                     crime_df['target'],                                                     test_size = 0.4,                                                     random_state = 42)\\n```\\n\\nNote that we will only perform under- and over-sampling only on the train dataset. We will _not_ change the test sets with under- and over-sampling.\\n\\n### Preprocessing the dataset\\n\\nOur goal is to have a visualize an imbalanced dataset. In order to visualize the 128-dimensional dataset in a 2D graph, we do the following on the train set.\\n\\n- scale the dataset,\\n- perform Principle Component Analysis (PCA) on the features to convert the 100 features to 2 principle components,\\n- visualize the data.\\n\\nHere‚Äôs the data, visualized in 2D.\\n\\nImage by author\\n\\nCode for the above graph:\\n\\n```\\nfrom sklearn.preprocessing import MinMaxScalerfrom sklearn.decomposition import PCAimport matplotlib.pyplot as plt# Scale the dataset on both train and test sets.# Note that we fit MinMaxScaler on X_train only, not on the entire dataset.# This prevents data leakage from test set to train set.scaler = MinMaxScaler()scaler.fit(X_train)X_train = scaler.transform(X_train)X_test = scaler.transform(X_test)# Perform PCA Decomposition on both train and test sets# Note that we fit PCA on X_train only, not on the entire dataset.# This prevents data leakage from test set to train set.pca = PCA(n_components=2)pca.fit(X_train)X_train_pca = pca.transform(X_train)X_test_pca = pca.transform(X_test)# Function for plotting dataset def plot_data(X,y,ax,title):    ax.scatter(X[:, 0], X[:, 1], c=y, alpha=0.5, s = 30, edgecolor=(0,0,0,0.5))    ax.set_ylabel('Principle Component 1')    ax.set_xlabel('Principle Component 2')    if title is not None:        ax.set_title(title)# Plot datasetfig,ax = plt.subplots(figsize=(5, 5))plot_data(X_train_pca, y_train, ax, title='Original Dataset')\\n```\\n\\nWith the preprocessing done, we are ready to resample our dataset.\\n\\n## Strategy 1. Random Oversampling\\n\\nRandom oversampling duplicates existing examples from the minority class with replacement. Each data point in the minority class has an equal probability of being duplicated.\\n\\nPress enter or click to view image in full size\\n\\nImage by author\\n\\nHere‚Äôs how to we can perform oversampling on our dataset.\\n\\n```\\nfrom imblearn.over_sampling import RandomOverSampler# Perform random oversamplingros = RandomOverSampler(random_state=0)X_train_ros, ...\\n\\n--- Result 9 ---\\nTitle: Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\\nURL: https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions\\n\\nContent:\\nTabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions[\\n**üì£ BIG NEWS:****Neptune is joining OpenAI!**‚Üí Read the message from our CEO üì£![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\\nWhat do you want to find?\\nSearch\\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Neptune Blog](https://neptune.ai/blog)# Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Shahul-Es-new-scaled.jpeg?fit=2560%2C1920&ssl=1)\\n[Shahul ES](https://neptune.ai/blog/author/shahules)\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)3 min\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)1st September, 2023\\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)[Tabular Data](https://neptune.ai/blog/category/tabular-data)\\nIn this article, I will discuss some great tips and tricks to improve the performance of your structured data binary classification model. These tricks are obtained from solutions of some of Kaggle‚Äôs top tabular data competitions. Without much lag, let‚Äôs begin.\\nThese are the five competitions that I have gone through to create this article:\\n* [**Home credit default risk**](https://www.kaggle.com/c/home-credit-default-risk/)\\n* [**Santander Customer Transaction Prediction**](https://www.kaggle.com/c/santander-customer-transaction-prediction/notebooks)\\n* [**VSB Power Line Fault Detection**](https://www.kaggle.com/c/vsb-power-line-fault-detection/overview/evaluation)\\n* [**Microsoft Malware Prediction**](https://www.kaggle.com/c/microsoft-malware-prediction/overview)\\n* [**IEEE-CIS Fraud Detection**](https://www.kaggle.com/c/ieee-fraud-detection/overview/evaluation/)## Dealing with larger datasets\\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\\n* Faster[data loading with pandas.](https://www.kaggle.com/c/home-credit-default-risk/discussion/59575)\\n* Data compression techniques to[reduce the size of data by 70%](https://www.kaggle.com/nickycan/compress-70-of-dataset).\\n* Optimize the memory by r[educing the size of some attributes.](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\\n* Use open-source libraries such as[Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space.\\n* Use[cudf](https://github.com/rapidsai/cudf).\\n* Convert data to[parquet](https://arrow.apache.org/docs/python/parquet.html)format.\\n* Converting data to[feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03)format.\\n* Reducing memory usage for[optimizing RAM](https://www.kaggle.com/mjbahmani/reducing-memory-size-for-ieee).## Data exploration\\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\\n* EDA for microsoft[malware detection.](https://www.kaggle.com/youhanlee/my-eda-i-want-to-see-all)\\n* Time Series[EDA for malware detection.](https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68)\\n* Complete[EDA for home credit loan prediction](https://www.kaggle.com/codename007/home-credit-complete-eda-feature-importance).\\n* Complete[EDA for Santader prediction.](https://www.kaggle.com/gpreda/santander-eda-and-prediction)\\n* EDA for[VSB Power Line Fault Detection.](https://www.kaggle.com/go1dfish/basic-eda)## Data preparation\\nAfter data exploration, the first thing to do is to use those insights to prepare the data. To tackle issues like class imbalance, encoding categorical data, etc. Let‚Äôs see the methods used to do it.\\n* Methods to t[ackle class imbalance](https://www.kaggle.com/shahules/tackling-class-imbalance).\\n* Data augmentation by[Synthetic Minority Oversampling Technique](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/).\\n* Fast inplace[shuffle for augmentation](https://www.kaggle.com/jiweiliu/fast-inplace-shuffle-for-augmentation).\\n* Finding[synthetic samples in the dataset.](https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split)\\n* [Signal denoising](https://www.kaggle.com/jackvial/dwt-signal-denoising)used in signal processing competitions.\\n* Finding[patterns of missing data](https://www.kaggle.com/jpmiller/patterns-of-missing-data).\\n* Methods to handle[missing data](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779).\\n* An overview of various[encoding techniques for categorical data.](https://www.kaggle.com/shahules/an-overview-of-encoding-techniques)\\n* Building[model to predict missing values.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64598)\\n* Random[shuffling of data](https://www.kaggle.com/brandenkmurray/randomly-shuffled-data-also-works)to create new synthetic training set.## Feature engineering\\nNext, you can check the most popular feature and feature engineering techniques used in these top kaggle competitions. The feature engineering part varies from problem to problem depending on the domain.\\n* Target[encoding cross validation](https://medium.com/@pouryaayria/k-fold-target-encoding-dfe9a594874b/)for better encoding.\\n* Entity embedding to[handle categories](https://www.kaggle.com/abhishek/entity-embeddings-to-handle-categories).\\n* Encoding c[yclic features for deep learning.](https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning)\\n* Manual[feature engineering methods](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering).\\n* Automated feature engineering techniques[using featuretools](https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics).\\n* Top hard crafted features used in[microsoft malware detection](https://www.kaggle.com/sanderf/7th-place-solution-microsoft-malware-prediction).\\n* Denoising NN for[feature extraction](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798).\\n* Feature engineering[using RAPIDS framework.](https://www.kaggle.com/cdeotte/rapids-feature-engineering-fraud-0-96/)\\n* Things to remember while processing f[eatures using LGBM.](https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575)\\n* [Lag features and moving averages.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64593)\\n* [Principal component analysis](https://medium.com/machine-learning-researcher/dimensionality-reduction-pca-and-lda-6be91734f567)for...\\n\", \"is_error\": false, \"results\": [{\"title\": \"ANSWER\", \"text\": \"Top Kaggle winners typically tackle a 75‚ÄØ%‚ÄØ/‚ÄØ25‚ÄØ% binary‚Äëclass split by reshaping the training data and by using metrics and model settings that reward performance on the minority class.‚ÄØThey combine resampling, class‚Äëweighting, and careful validation to keep the imbalance from biasing the model‚ÄØ([Dealing with extremely imbalanced dataset ‚Äì Kaggle](https://www.kaggle.com/questions-and-answers/473546);‚ÄØ[Unbalanced data and cross‚Äëvalidation ‚Äì Kaggle](https://www.kaggle.com/discussions/questions-and-answers/27589)).\\n\\n**Step‚Äëby‚Äëstep workflow**\\n\\n1. **Inspect the split and pick an imbalance‚Äëaware metric** ‚Äì report AUC‚ÄëROC, PR‚ÄëAUC or log‚Äëloss instead of plain accuracy, because these metrics reflect minority‚Äëclass performance‚ÄØ([Unbalanced data and cross‚Äëvalidation ‚Äì Kaggle](https://www.kaggle.com/discussions/questions-and-answers/27589)).  \\n\\n2. **Apply resampling to the training folds**  \\n   * *Undersample* the majority (75‚ÄØ%) class to a manageable size, or  \\n   * *Oversample* the minority (25‚ÄØ%) class with synthetic techniques such as **SMOTE** or ADASYN. Both approaches are standard in Kaggle solutions‚ÄØ([Dealing with extremely imbalanced dataset ‚Äì Kaggle](https://www.kaggle.com/questions-and-answers/473546);‚ÄØ[Resampling strategies for imbalanced datasets ‚Äì Kaggle](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets)).  \\n\\n3. **Add class weights (or sample weights) to the loss function** ‚Äì most libraries (e.g., XGBoost, LightGBM, sklearn) accept a `scale_pos_weight` or `class_weight` argument; setting a higher weight for the minority class forces the model to penalize its errors more heavily.  \\n\\n4. **Train robust models and ensembles** ‚Äì gradient‚Äëboosted trees, neural nets, or stacked ensembles are common; ensemble methods help smooth out variance introduced by resampling‚ÄØ([Dealing with extremely imbalanced dataset ‚Äì Kaggle](https://www.kaggle.com/questions-and-answers/473546)).  \\n\\n5. **Validate with stratified cross‚Äëvalidation** ‚Äì ensure each fold preserves the 75/25 ratio so that performance estimates remain realistic and that resampling/weighting decisions are not over‚Äëfitted.  \\n\\n6. **Fine‚Äëtune threshold post‚Äëtraining** ‚Äì after the model is fitted, adjust the decision threshold (e.g., using the ROC curve) to balance precision vs. recall according to the competition‚Äôs cost of false positives vs. false negatives.  \\n\\n7. **Monitor the minority‚Äëclass metrics on the hold‚Äëout leaderboard** ‚Äì iterate on resampling ratios, class‚Äëweight values, and ensemble composition until the minority‚Äëclass AUC/PR‚ÄëAUC improves.  \\n\\nFollowing these concise steps lets you handle a 75‚ÄØ%‚ÄØ/‚ÄØ25‚ÄØ% imbalance the way Kaggle champions do, keeping the minority class well‚Äërepresented in both training and evaluation.\", \"url\": \"\"}, {\"title\": \"Dealing with extremely imbalanced dataset - binary classification\", \"text\": \"Checking your browser - reCAPTCHA\\nChecking your browser before accessing www.kaggle.com ...\\nClick[here](#)if you are not automatically redirected after 5 seconds.\", \"url\": \"https://www.kaggle.com/questions-and-answers/473546\"}, {\"title\": \"Resampling strategies for imbalanced datasets - Kaggle\", \"text\": \"- _code_\\n\\nNew Notebook\\n\\n- _table\\\\_chart_\\n\\nNew Dataset\\n\\n- _tenancy_\\n\\nNew Model\\n\\n- _emoji\\\\_events_\\n\\nNew Competition\\n\\n- _corporate\\\\_fare_\\n\\nNew Organization\\n\\n\\n## No Active Events\\n\\nCreate notebooks and keep track of their status here.\\n\\n[_add_ New Notebook](https://www.kaggle.com/code/new)\\n\\n- _auto\\\\_awesome\\\\_motion_\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0 Active Events\\n\\n\\n\\n\\n\\n\\n_expand\\\\_more_\\n\\n\\nmenu\\n\\n[Skip to\\\\\\n\\\\\\ncontent](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets#site-content)\\n\\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\\n\\nCreate\\n\\n_search_\\n\\n- [_explore_\\\\\\n\\\\\\nHome](https://www.kaggle.com/)\\n\\n- [_emoji\\\\_events_\\\\\\n\\\\\\nCompetitions](https://www.kaggle.com/competitions)\\n\\n- [_table\\\\_chart_\\\\\\n\\\\\\nDatasets](https://www.kaggle.com/datasets)\\n\\n- [_tenancy_\\\\\\n\\\\\\nModels](https://www.kaggle.com/models)\\n\\n- [_code_\\\\\\n\\\\\\nCode](https://www.kaggle.com/code)\\n\\n- [_comment_\\\\\\n\\\\\\nDiscussions](https://www.kaggle.com/discussions)\\n\\n- [_school_\\\\\\n\\\\\\nLearn](https://www.kaggle.com/learn)\\n\\n- [_expand\\\\_more_\\\\\\n\\\\\\nMore](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets)\\n\\n\\n_auto\\\\_awesome\\\\_motion_\\n\\nView Active Events\\n\\nmenu\\n\\n[Skip to\\\\\\n\\\\\\ncontent](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets#site-content)\\n\\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\\n\\n_search_\\n\\n[Sign In](https://www.kaggle.com/account/login?phase=startSignInTab&returnUrl=%2Fcode%2Frafjaa%2Fresampling-strategies-for-imbalanced-datasets)\\n\\n[Register](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2Fcode%2Frafjaa%2Fresampling-strategies-for-imbalanced-datasets)\\n\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n\\n[Learn more.](https://www.kaggle.com/cookies)\\n\\nOK, Got it.\\n\\n![Something went wrong and this page crashed!](https://www.kaggle.com/static/images/error/server-error-illo_light.svg)\\n\\n###### Something went wrong and this page crashed!\\n\\nIf the issue persists, it's likely a problem on our side.\\n\\n```\\n\\nLoading CSS chunk 5073 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 5073 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\n    at t.onerror.t.onload (https://www.kaggle.com/static/assets/runtime.js?v=e39bd89f6741bf1e27b2:1:8254)\\n```\\n\\nRefresh\", \"url\": \"https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets\"}, {\"title\": \"Unbalanced data and cross-validation | Kaggle\", \"text\": \"<div><div><p>There are two general ways of dealing with imbalanced data: 1) change the data; 2) leave the data alone but change the performance metric and/or the weight of individual data points.</p>\\n<p>Changing the data means oversampling the under-represented class(es) with synthetic data points, or undersampling (thinning down) the over-represented class(es). There are various ways of doing both operations, and I will give you one <a href=\\\"https://github.com/scikit-learn-contrib/imbalanced-learn\\\"><strong>starting point</strong></a>.</p>\\n<p>A second option is to leave the data alone and adjust how we do the training. It is crucial to pick a reliable performance metric for imbalanced data, and to know whether for your purposes it is worse to have too many false positives (FPs) or false negatives (FNs). Ideally, you wouldn't want to have either of the two, but for most applications it should be clear whether we want to avoid FPs or FNs with greater preference.</p>\\n<p>To give you an example: you have 900 healthy patients (class 0) and 100 cancer patients (class 1), which is at least somewhat close to the true ratio of healthy and cancer-stricken people out there. If you predict class 0 with 100% accuracy and class 1 with 70% accuracy, your accuracy will be 97% for the whole dataset. That sounds tremendous until we realize that 30 out of 100 cancer patients (30%) will go undiagnosed, meaning that high false negative rate in this case will cost many lives. What if we could adjust our classification so that both classes are predicted with 97% accuracy? This would mean that 27 healthy people would be predicted to have cancer (27 FPs) and 3 cancer-stricken individual would be predicted to be healthy (3 FNs). Now, I wouldn't want to be a doctor who tells a healthy person that they have a cancer because many people have been known to do silly things when they think they are dying. Still, compared to our starting premise, most would agree that on balance it is much better to have 27 people who think they have cancer and later find out they don't, and only 3 patients who were told they are healthy even though they have cancer. The problem is that a simple accuracy as a performance metric for training would never get you to a balanced 97% accuracy. For imbalanced datasets, F1-score (a weighted average of precision and recall), area under curve for ROC and Matthews correlation coefficient may be better measures of classifier quality.</p>\\n<p>See the links below for more info:</p>\\n<p><a href=\\\"http://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/\\\"><strong>link1</strong></a></p>\\n<p><a href=\\\"https://eva.fing.edu.uy/mod/resource/view.php?id=33977\\\"><strong>link2</strong></a></p>\\n<p><a href=\\\"https://www.kaggle.com/c/bosch-production-line-performance/forums/t/24120/time-effort-and-reward?forumMessageId=138285#post138285\\\"><strong>link3</strong></a></p></div></div>\", \"url\": \"https://www.kaggle.com/discussions/questions-and-answers/27589\"}, {\"title\": \"Understanding Class Imbalance in 1 Minute! - Kaggle\", \"text\": \"Checking your browser - reCAPTCHA\\nChecking your browser before accessing www.kaggle.com ...\\nClick[here](#)if you are not automatically redirected after 5 seconds.\", \"url\": \"https://www.kaggle.com/getting-started/467908\"}, {\"title\": \"Binary classification with strongly unbalanced classes\", \"text\": \"**Teams**\\n\\nQ&A for work\\n\\nConnect and share knowledge within a single location that is structured and easy to search.\\n\\n[Learn more about Teams](https://stackoverflow.co/teams/)\\n\\n# [Binary classification with strongly unbalanced classes](https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes)\\n\\n[Ask Question](https://stats.stackexchange.com/questions/ask)\\n\\nAsked7 years, 9 months ago\\n\\nModified [3 years, 11 months ago](https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes?lastactivity)\\n\\nViewed\\n56k times\\n\\n67\\n\\n$\\\\\\\\begingroup$\\n\\nI have a data set in the form of (features, binary output 0 or 1), but 1 happens pretty rarely, so just by always predicting 0, I get accuracy between 70% and 90% (depending on the particular data I look at). The ML methods give me about the same accuracy, and I feel, there should be some standard methods to apply in this situation, that would improve the accuracy over the obvious prediction rule.\\n\\n- [machine-learning](https://stats.stackexchange.com/questions/tagged/machine-learning)\\n- [classification](https://stats.stackexchange.com/questions/tagged/classification)\\n- [binary-data](https://stats.stackexchange.com/questions/tagged/binary-data)\\n- [unbalanced-classes](https://stats.stackexchange.com/questions/tagged/unbalanced-classes)\\n\\n[Share](https://stats.stackexchange.com/q/235808)\\n\\nCite\\n\\n[Improve this question](https://stats.stackexchange.com/posts/235808/edit)\\n\\nFollow\\n\\n[edited Oct 30, 2017 at 19:47](https://stats.stackexchange.com/posts/235808/revisions)\\n\\nLazyCat\\n\\nasked Sep 19, 2016 at 18:39\\n\\n[![LazyCat's user avatar](https://www.gravatar.com/avatar/0de65f380a7e1cb28d4f0c9c5f93fdde?s=64&d=identicon&r=PG)](https://stats.stackexchange.com/users/30893/lazycat)\\n\\n[LazyCat](https://stats.stackexchange.com/users/30893/lazycat) LazyCat\\n\\n87211 gold badge77 silver badges1111 bronze badges\\n\\n$\\\\\\\\endgroup$\\n\\n6\\n\\n- 4\\n\\n\\n\\n\\n\\n$\\\\\\\\begingroup$I've found this article to be very helpful on the subject: [svds.com/learning-imbalanced-classes](http://www.svds.com/learning-imbalanced-classes/)$\\\\\\\\endgroup$\\n\\n‚Äì¬†[J. O'Brien Antognini](https://stats.stackexchange.com/users/115448/j-obrien-antognini)\\n\\nCommentedSep 20, 2016 at 23:18\\n\\n- $\\\\\\\\begingroup$@J.O'BrienAntognini That is a really nice article!$\\\\\\\\endgroup$\\n\\n‚Äì¬†[Jinhua Wang](https://stats.stackexchange.com/users/163503/jinhua-wang)\\n\\nCommentedJan 27, 2019 at 17:22\\n\\n- $\\\\\\\\begingroup$Some useful discussion here: [stats.stackexchange.com/questions/285231/‚Ä¶](https://stats.stackexchange.com/questions/285231/what-problem-does-oversampling-undersampling-and-smote-solve?r=SearchResults&s=3|0.0000) and [stats.stackexchange.com/questions/283170/‚Ä¶](https://stats.stackexchange.com/questions/283170/when-is-unbalanced-data-really-a-problem-in-machine-learning)$\\\\\\\\endgroup$\\n\\n‚Äì¬†[Sycorax](https://stats.stackexchange.com/users/22311/sycorax) ‚ô¶\\n\\nCommentedJul 15, 2020 at 13:02\\n\\n- $\\\\\\\\begingroup$This post [here](https://stats.stackexchange.com/questions/247871/what-is-the-root-cause-of-the-class-imbalance-problem) has a very clear answer on _why_ class imbalance causes problems.$\\\\\\\\endgroup$\\n\\n‚Äì¬†[Stephen G](https://stats.stackexchange.com/users/225551/stephen-g)\\n\\nCommentedJul 15, 2020 at 13:57\\n\\n- $\\\\\\\\begingroup$@StephenG At present, the post you've linked to has three answers. Which one are you referring to?$\\\\\\\\endgroup$\\n\\n‚Äì¬†[Sycorax](https://stats.stackexchange.com/users/22311/sycorax) ‚ô¶\\n\\nCommentedJul 15, 2020 at 17:49\\n\\n\\n\\\\|¬†[Show **1** more comment](https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes)\\n\\n## 7 Answers 7\\n\\nSorted by:\\n[Reset to default](https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes?answertab=scoredesc#tab-top)\\n\\nHighest score (default)Date modified (newest first)Date created (oldest first)\\n\\n39\\n\\n$\\\\\\\\begingroup$\\n\\nBoth hxd1011 and Frank are right (+1).\\nEssentially resampling and/or cost-sensitive learning are the two main ways of getting around the problem of imbalanced data; third is to use kernel methods that sometimes might be less effected by the class imbalance.\\nLet me stress that there is no silver-bullet solution. By definition you have one class that is represented inadequately in your samples.\\n\\nHaving said the above I believe that you will find the algorithms [SMOTE](http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-106) and [ROSE](https://journal.r-project.org/archive/2014-1/menardi-lunardon-torelli.pdf) very helpful. SMOTE effectively uses a $k$-nearest neighbours approach to exclude members of the majority class while in a similar way creating synthetic examples of a minority class. ROSE tries to create estimates of the underlying distributions of the two classes using a smoothed bootstrap approach and sample them for synthetic examples. Both are readily available in R, SMOTE in the package [DMwR](https://cran.r-project.org/web/packages/DMwR/index.html) and ROSE in the package with the [same name](https://cran.r-project.org/web/packages/ROSE/index.html). Both SMOTE and ROSE result in a training dataset that is smaller than the original one.\\n\\nI would probably argue that a better (or less bad) metric for the case of imbalanced data is using [Cohen's $k$](https://en.wikipedia.org/wiki/Cohen's_kappa) and/or [Receiver operating characteristic's Area under the curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve).\\nCohen's kappa directly controls for the expected accuracy, AUC as it\\nis a function of sensitivity and specificity, the curve is insensitive to disparities in the class proportions. Again, notice that these are just metrics that should be used with a large grain of salt. You should ideally adapt them to your specific problem taking account of the gains and costs correct and wrong classifications convey in your case. I have found that looking at [lift-curves](https://en.wikipedia.org/wiki/Lift_%28data_mining%29) is actually rather informative for this matter.\\nIrrespective of your metric you should try to use a separate test to assess the performance of your algorithm; exactly because of the class imbalanced over-fitting is even more likely so out-of-sample testing is crucial.\\n\\nProbably the most popular recent paper on the matter is [Learning from Imbalanced Data](http://www.ele.uri.edu/faculty/he/PDFfiles/ImbalancedLearning.pdf) by He and Garcia. It gives a very nice overview of the points raised by myself and in other answers. In addition I believe that the walk-through on [Subsampling For Class Imbalances](http://topepo.github.io/caret/subsampling-for-class-imbalances.html), presented by Max Kuhn as part of the [caret](https://cran.r-project.org/web/packages/caret/index.html) package is an excellent resource to get a structure example of how under-/over-sampling as well as synthetic data creation can measure against each other.\\n\\n[Share](https://stats.stackexchange.com/a/235824)\\n\\nCite\\n\\n[Improve this answer](https://stats.stackexchange.com/posts/235824/edit)\\n\\nFollow\\n\\n[edited Sep 19, 2016 at 20:12](https://stats.stackexchange.com/posts/235824/revisions)\\n\\nanswered Sep 19, 2016 at 19:44\\n\\n[![usŒµr11852's user avatar](https://i.sstatic.net/Y88zz.png?s=64)](https://stats.stackexchange.com/users/11852/us%ce%b5r11852)\\n\\n[usŒµr11852](https://stats.stackexchange.com/users/11852/us%ce%b5r11852) usŒµr11852\\n\\n44.7k33 gold badges101101 silver badges158158 bronze badges\\n\\n$\\\\\\\\endgroup$\\n\\n3\\n\\n- $\\\\\\\\begingroup$A third somewhat popular (and again not too appropriate) metric is the Area-Under-the-Curve of the Precision-Recall curve. [Davis & James, 2006](https://www.biostat.wisc.edu/~page/rocpr.pdf) paper is consider a classic on the matter; CV has a good thread [too](http://stats.stackexchange.com/questions/7207). I recently saw a paper with the somewhat hammy title \\\" [The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating Binary Classifiers on Imbalanced Dat...\", \"url\": \"https://stats.stackexchange.com/questions/235808/binary-classification-with-strongly-unbalanced-classes\"}, {\"title\": \"Best techniques and metrics for Imbalanced Dataset - Kaggle\", \"text\": \"Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n\\n[Learn more](https://www.kaggle.com/cookies)\\n\\nOK, Got it.\\n\\n###### Something went wrong and this page crashed!\\n\\nIf the issue persists, it's likely a problem on our side.\\n\\n```\\n\\nLoading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\n    at r.onerror.r.onload (https://www.kaggle.com/static/assets/runtime.js?v=805aeed0a20bb825939e:1:11032)\\n```\\n\\nRefresh\", \"url\": \"https://www.kaggle.com/code/marcinrutecki/best-techniques-and-metrics-for-imbalanced-dataset\"}, {\"title\": \"Class Imbalance Strategies ‚Äî A Visual Guide with Code - Medium\", \"text\": \"[Sitemap](https://medium.com/sitemap/sitemap.xml)\\n\\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8bc8fae71e1a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdata-science%2Fclass-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\\n\\n[Search](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdata-science%2Fclass-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n[**TDS Archive**](https://medium.com/data-science?source=post_page---publication_nav-7f60cf5620c9-8bc8fae71e1a---------------------------------------)\\n\\n¬∑\\n\\nAn archive of data science, data analytics, data engineering, machine learning, and artificial intelligence writing from the former Towards Data Science Medium publication.\\n\\n# Class Imbalance Strategies ‚Äî A Visual Guide with Code\\n\\n## Understand Random Undersampling, Oversampling, SMOTE, ADASYN, and Tomek Links\\n\\n[Travis Tang](https://medium.com/@travis-tang?source=post_page---byline--8bc8fae71e1a---------------------------------------)\\n\\n13 min read\\n\\n¬∑\\n\\nApr 24, 2023\\n\\n--\\n\\n1\\n\\nListen\\n\\nShare\\n\\nClass imbalance occurs when one class in a classification problem significantly outweighs the other class. It‚Äôs common in many machine learning problems. Examples include fraud detection, anomaly detection, and medical diagnosis.\\n\\n## The Curse of Class Imbalance\\n\\nA model trained on an imbalanced dataset perform poorly on the minority class. At best, this can cause loss to the business in the case of a churn analysis. At worst, it can pervade systemic bias of a face recognition system.\\n\\nPress enter or click to view image in full size\\n\\nA balanced dataset might just be the missing ingredient (Source: Elena Mozhvilo on [Unsplash](https://unsplash.com/photos/j06gLuKK0GM))\\n\\nThe common approach to class imbalance is resampling. These can entail oversampling the majority class, undersampling the minority class, or a combination of both.\\n\\nIn this post, I use vivid visuals and code to illustrate these strategies for class imbalance:\\n\\n1. Random oversampling\\n2. Random undersampling\\n3. Oversampling with SMOTE\\n4. Oversampling with ADASYN\\n5. Undersampling with Tomek Link\\n6. Oversampling with SMOTE, then undersample with TOMEK Link (SMOTE-Tomek)\\n\\nI will also be using these strategies on a real-world dataset, and evaluate their impact on a machine learning model. Let‚Äôs go.\\n\\n> All source code is here.\\n\\n## Using Imbalance-learn\\n\\nWe will use the `imbalanced-learn` package in python to solve our imbalanced class problem. It is an open-sourced library relying on scikit-learn and provides tools when dealing with classification with imbalanced classes.\\n\\nTo install it, use the command.\\n\\n```\\npip install -U imbalanced-learn\\n```\\n\\n## Dataset\\n\\nThe dataset that we are using is the [**Communities and Crime Data Set by UCI (CC BY 4.0)**.](https://archive.ics.uci.edu/ml/datasets/communities+and+crime) It contains 100 attributes of 1994 U.S. communities. We can use this to predict if the **crime rate is high** (defined as having **per capita violent crime** above 0.65). The data source is available in the UCI Machine Learning Repository and is created by Michael Redmond from La Salle University (Published in 2009).\\n\\n> The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of officers assigned to drug units.\\n\\nThis dataset is imbalanced. It has 12 communities with low crime rates for every 1 community of high crime rate. This is perfect to illustrate our use case.\\n\\n```\\n>>> from imblearn.datasets import fetch_datasets>>> # Fetch dataset from imbalanced-learn library >>> # as a dictionary of numpy array>>> us_crime = fetch_datasets()['us_crime']>>> us_crime{'data': array([[0.19, 0.33, 0.02, ..., 0.26, 0.2 , 0.32],        [0.  , 0.16, 0.12, ..., 0.12, 0.45, 0.  ],        [0.  , 0.42, 0.49, ..., 0.21, 0.02, 0.  ],        ...,        [0.16, 0.37, 0.25, ..., 0.32, 0.18, 0.91],        [0.08, 0.51, 0.06, ..., 0.38, 0.33, 0.22],        [0.2 , 0.78, 0.14, ..., 0.3 , 0.05, 1.  ]]), 'target': array([-1,  1, -1, ..., -1, -1, -1]), 'DESCR': 'us_crime'}\\n```\\n\\nWe will convert this dictionary to a Pandas dataframe, then split it into train-test splits.\\n\\n```\\n# Convert the dictionary to a pandas dataframecrime_df = pd.concat([pd.DataFrame(us_crime['data'], columns = [f'data_{i}' for i in range(us_crime.data.shape[1])]),           pd.DataFrame(us_crime['target'], columns = ['target'])], axis = 1)# Split data into train test setfrom sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(crime_df.drop('target', axis = 1),                                                     crime_df['target'],                                                     test_size = 0.4,                                                     random_state = 42)\\n```\\n\\nNote that we will only perform under- and over-sampling only on the train dataset. We will _not_ change the test sets with under- and over-sampling.\\n\\n### Preprocessing the dataset\\n\\nOur goal is to have a visualize an imbalanced dataset. In order to visualize the 128-dimensional dataset in a 2D graph, we do the following on the train set.\\n\\n- scale the dataset,\\n- perform Principle Component Analysis (PCA) on the features to convert the 100 features to 2 principle components,\\n- visualize the data.\\n\\nHere‚Äôs the data, visualized in 2D.\\n\\nImage by author\\n\\nCode for the above graph:\\n\\n```\\nfrom sklearn.preprocessing import MinMaxScalerfrom sklearn.decomposition import PCAimport matplotlib.pyplot as plt# Scale the dataset on both train and test sets.# Note that we fit MinMaxScaler on X_train only, not on the entire dataset.# This prevents data leakage from test set to train set.scaler = MinMaxScaler()scaler.fit(X_train)X_train = scaler.transform(X_train)X_test = scaler.transform(X_test)# Perform PCA Decomposition on both train and test sets# Note that we fit PCA on X_train only, not on the entire dataset.# This prevents data leakage from test set to train set.pca = PCA(n_components=2)pca.fit(X_train)X_train_pca = pca.transform(X_train)X_test_pca = pca.transform(X_test)# Function for plotting dataset def plot_data(X,y,ax,title):    ax.scatter(X[:, 0], X[:, 1], c=y, alpha=0.5, s = 30, edgecolor=(0,0,0,0.5))    ax.set_ylabel('Principle Component 1')    ax.set_xlabel('Principle Component 2')    if title is not None:        ax.set_title(title)# Plot datasetfig,ax = plt.subplots(figsize=(5, 5))plot_data(X_train_pca, y_train, ax, title='Original Dataset')\\n```\\n\\nWith the preprocessing done, we are ready to resample our dataset.\\n\\n## Strategy 1. Random Oversampling\\n\\nRandom oversampling duplicates existing examples from the minority class with replacement. Each data point in the minority class has an equal probability of being duplicated.\\n\\nPress enter or click to view image in full size\\n\\nImage by author\\n\\nHere‚Äôs how to we can perform oversampling on our dataset.\\n\\n```\\nfrom imblearn.over_sampling import RandomOverSampler# Perform random oversamplingros = RandomOverSampler(random_state=0)X_train_ros, ...\", \"url\": \"https://medium.com/data-science/class-imbalance-strategies-a-visual-guide-with-code-8bc8fae71e1a\"}, {\"title\": \"Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\", \"text\": \"Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions[\\n**üì£ BIG NEWS:****Neptune is joining OpenAI!**‚Üí Read the message from our CEO üì£![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\\nWhat do you want to find?\\nSearch\\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Neptune Blog](https://neptune.ai/blog)# Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Shahul-Es-new-scaled.jpeg?fit=2560%2C1920&ssl=1)\\n[Shahul ES](https://neptune.ai/blog/author/shahules)\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)3 min\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)1st September, 2023\\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)[Tabular Data](https://neptune.ai/blog/category/tabular-data)\\nIn this article, I will discuss some great tips and tricks to improve the performance of your structured data binary classification model. These tricks are obtained from solutions of some of Kaggle‚Äôs top tabular data competitions. Without much lag, let‚Äôs begin.\\nThese are the five competitions that I have gone through to create this article:\\n* [**Home credit default risk**](https://www.kaggle.com/c/home-credit-default-risk/)\\n* [**Santander Customer Transaction Prediction**](https://www.kaggle.com/c/santander-customer-transaction-prediction/notebooks)\\n* [**VSB Power Line Fault Detection**](https://www.kaggle.com/c/vsb-power-line-fault-detection/overview/evaluation)\\n* [**Microsoft Malware Prediction**](https://www.kaggle.com/c/microsoft-malware-prediction/overview)\\n* [**IEEE-CIS Fraud Detection**](https://www.kaggle.com/c/ieee-fraud-detection/overview/evaluation/)## Dealing with larger datasets\\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\\n* Faster[data loading with pandas.](https://www.kaggle.com/c/home-credit-default-risk/discussion/59575)\\n* Data compression techniques to[reduce the size of data by 70%](https://www.kaggle.com/nickycan/compress-70-of-dataset).\\n* Optimize the memory by r[educing the size of some attributes.](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\\n* Use open-source libraries such as[Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space.\\n* Use[cudf](https://github.com/rapidsai/cudf).\\n* Convert data to[parquet](https://arrow.apache.org/docs/python/parquet.html)format.\\n* Converting data to[feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03)format.\\n* Reducing memory usage for[optimizing RAM](https://www.kaggle.com/mjbahmani/reducing-memory-size-for-ieee).## Data exploration\\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\\n* EDA for microsoft[malware detection.](https://www.kaggle.com/youhanlee/my-eda-i-want-to-see-all)\\n* Time Series[EDA for malware detection.](https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68)\\n* Complete[EDA for home credit loan prediction](https://www.kaggle.com/codename007/home-credit-complete-eda-feature-importance).\\n* Complete[EDA for Santader prediction.](https://www.kaggle.com/gpreda/santander-eda-and-prediction)\\n* EDA for[VSB Power Line Fault Detection.](https://www.kaggle.com/go1dfish/basic-eda)## Data preparation\\nAfter data exploration, the first thing to do is to use those insights to prepare the data. To tackle issues like class imbalance, encoding categorical data, etc. Let‚Äôs see the methods used to do it.\\n* Methods to t[ackle class imbalance](https://www.kaggle.com/shahules/tackling-class-imbalance).\\n* Data augmentation by[Synthetic Minority Oversampling Technique](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/).\\n* Fast inplace[shuffle for augmentation](https://www.kaggle.com/jiweiliu/fast-inplace-shuffle-for-augmentation).\\n* Finding[synthetic samples in the dataset.](https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split)\\n* [Signal denoising](https://www.kaggle.com/jackvial/dwt-signal-denoising)used in signal processing competitions.\\n* Finding[patterns of missing data](https://www.kaggle.com/jpmiller/patterns-of-missing-data).\\n* Methods to handle[missing data](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779).\\n* An overview of various[encoding techniques for categorical data.](https://www.kaggle.com/shahules/an-overview-of-encoding-techniques)\\n* Building[model to predict missing values.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64598)\\n* Random[shuffling of data](https://www.kaggle.com/brandenkmurray/randomly-shuffled-data-also-works)to create new synthetic training set.## Feature engineering\\nNext, you can check the most popular feature and feature engineering techniques used in these top kaggle competitions. The feature engineering part varies from problem to problem depending on the domain.\\n* Target[encoding cross validation](https://medium.com/@pouryaayria/k-fold-target-encoding-dfe9a594874b/)for better encoding.\\n* Entity embedding to[handle categories](https://www.kaggle.com/abhishek/entity-embeddings-to-handle-categories).\\n* Encoding c[yclic features for deep learning.](https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning)\\n* Manual[feature engineering methods](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering).\\n* Automated feature engineering techniques[using featuretools](https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics).\\n* Top hard crafted features used in[microsoft malware detection](https://www.kaggle.com/sanderf/7th-place-solution-microsoft-malware-prediction).\\n* Denoising NN for[feature extraction](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798).\\n* Feature engineering[using RAPIDS framework.](https://www.kaggle.com/cdeotte/rapids-feature-engineering-fraud-0-96/)\\n* Things to remember while processing f[eatures using LGBM.](https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575)\\n* [Lag features and moving averages.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64593)\\n* [Principal component analysis](https://medium.com/machine-learning-researcher/dimensionality-reduction-pca-and-lda-6be91734f567)for...\", \"url\": \"https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions\"}]}",
        "tool.duration_ms": 4081.7463397979736
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "0e36acfc5df91359",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "WriteTool",
      "kind": "INTERNAL",
      "start_time": 1767958855808935416,
      "end_time": 1767958855809396574,
      "duration": 0.000461158,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "WriteTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.WriteTool object at 0x7f38e8310090>\", \"input\": {\"file_path\": \"seed_prompt.txt\", \"content\": \"## Competition Overview\\nThis is a binary classification problem combining text and tabular features. See `exploration/eda.ipynb` for detailed data characteristics including feature distributions, missing values, class balance analysis, and correlation patterns.\\n\\n## Core Modeling Strategy\\n\\n### Multimodal Approach (Text + Tabular)\\nBased on winning Kaggle solutions for similar problems, the most effective approach is a three-step pipeline:\\n\\n1. **Extract text embeddings** using pretrained transformers (BERT, RoBERTa, or DeBERTa)\\n   - Use AutoGluon Tabular's TextPredictor for automatic text encoding\\n   - Alternatively, use Hugging Face transformers to generate sentence embeddings\\n   - GPU acceleration is critical for reasonable training time\\n\\n2. **Combine embeddings with tabular features**\\n   - Concatenate text embeddings with numeric/categorical features (two-stage approach)\\n   - OR convert tabular features to text and prepend to review (features-to-text trick)\\n   - Target-encode high-cardinality categorical features before merging\\n\\n3. **Train strong tabular models on combined features**\\n   - LightGBM, CatBoost, and XGBoost are the workhorses\\n   - Neural networks can be effective for larger datasets\\n   - Use libraries like Multimodal-Toolkit for seamless integration\\n\\n### Model Architecture Options\\n- **Two-stage**: Text encoder ‚Üí embeddings ‚Üí tabular model\\n- **Features-to-text**: Convert all features to text ‚Üí single transformer\\n- **Hybrid ensemble**: Combine both approaches with different weighting\\n\\n## Handling Class Imbalance (75/25 split)\\n\\n### Resampling Strategies\\n- **Undersample majority class** to balance classes (risk: information loss)\\n- **Oversample minority class** using SMOTE or ADASYN\\n- **Combine both**: SMOTE + Tomek links for cleaning\\n- **Apply resampling only to training folds** in cross-validation\\n\\n### Alternative Approaches (No Resampling)\\n- **Class weights**: Set `scale_pos_weight` in XGBoost/LightGBM or `class_weight` in sklearn\\n- **Focal loss**: Penalize hard examples more heavily\\n- **Threshold adjustment**: Optimize decision threshold post-training using ROC/PR curves\\n\\n### Validation Considerations\\n- **Always use stratified K-fold** to preserve class ratios in each fold\\n- **Monitor minority class metrics**: AUC-ROC, PR-AUC, F1-score (not accuracy)\\n- **Check for distribution shift** between train and test sets\\n\\n## Feature Engineering\\n\\n### Text Features\\n- **Basic**: Length, word count, character count, sentence count\\n- **Sentiment**: Use VADER or TextBlob for sentiment scores\\n- **TF-IDF**: Extract top terms and their statistics\\n- **Topic modeling**: LDA or NMF for latent topics\\n- **Entity extraction**: Count mentions of products, brands, locations\\n\\n### Tabular Features\\n- **Target encoding**: For high-cardinality categoricals (use cross-validation)\\n- **Interaction features**: Polynomial features between numeric columns\\n- **Aggregation features**: Group by categorical columns and compute statistics\\n- **Missing value patterns**: Create indicator for missing data patterns\\n- **Cyclical encoding**: If any temporal features exist\\n\\n### Cross-modal Features\\n- **Text-tabular interactions**: Multiply text sentiment scores with numeric features\\n- **Feature importance alignment**: Ensure text and tabular features are on similar scales\\n\\n## Model Selection and Training\\n\\n### Primary Models (Tier 1)\\n1. **LightGBM**: Fast, handles categorical features well\\n2. **CatBoost**: Excellent for categorical data, robust to overfitting\\n3. **XGBoost**: Reliable baseline, good performance\\n\\n### Secondary Models (Tier 2)\\n1. **Neural Networks**: For capturing non-linear interactions\\n2. **Random Forest**: For diversity in ensembles\\n3. **Logistic Regression**: With polynomial features for baseline\\n\\n### Training Configuration\\n- **Use early stopping** with patience of 50-100 rounds\\n- **Set class weights**: `scale_pos_weight = (negative_samples / positive_samples) * k` where k ‚àà [0.5, 2]\\n- **Hyperparameter ranges**:\\n  - Learning rate: 0.01 - 0.1\\n  - Max depth: 3 - 10\\n  - Num leaves: 31 - 255\\n  - Subsample: 0.6 - 0.9\\n  - Colsample: 0.6 - 0.9\\n\\n## Ensembling Strategy\\n\\n### Model Diversity\\n- Combine different architectures (GBM + NN + Transformer)\\n- Use different feature sets (text-only, tabular-only, combined)\\n- Vary preprocessing pipelines (different encoding strategies)\\n\\n### Ensemble Methods\\n1. **Weighted averaging**: Weight by validation performance\\n2. **Stacking**: Train meta-learner on out-of-fold predictions\\n3. **Rank averaging**: Average predictions after converting to ranks\\n4. **Optimal blending**: Use linear regression to find optimal weights\\n\\n### Implementation Order\\n1. Build 3-5 diverse single models\\n2. Create level-1 ensemble with simple averaging\\n3. Add stacking with logistic regression or LightGBM\\n4. Fine-tune ensemble weights using validation set\\n\\n## Validation Strategy\\n\\n### Cross-Validation Setup\\n- **Stratified K-Fold**: k=5 or k=10\\n- **GroupKFold**: If there's a grouping column (e.g., user_id)\\n- **TimeSeriesSplit**: If temporal patterns exist (check eda.ipynb)\\n\\n### Evaluation Metrics\\n- **Primary**: AUC-ROC (robust to class imbalance)\\n- **Secondary**: PR-AUC, F1-score, Log Loss\\n- **Never use**: Accuracy (misleading with imbalance)\\n\\n### Validation Best Practices\\n- **Create holdout set** before cross-validation for final evaluation\\n- **Monitor OOF (out-of-fold) predictions** for consistency\\n- **Check prediction distributions** across folds\\n- **Analyze errors**: Focus on minority class misclassifications\\n\\n## Optimization and Tuning\\n\\n### Hyperparameter Search\\n- **Start with broad search**: Use Optuna or Hyperopt\\n- **Focus on key params**: Learning rate, max depth, subsample\\n- **Use successive halving**: Reduce search space iteratively\\n- **Leverage GPU**: For neural network components\\n\\n### Feature Selection\\n- **Permutation importance**: On validation set\\n- **SHAP values**: For model interpretation\\n- **Recursive feature elimination**: For dimensionality reduction\\n- **Correlation analysis**: Remove highly correlated features\\n\\n### Post-Training Optimization\\n- **Threshold tuning**: Optimize for competition metric\\n- **Calibration**: Use Platt scaling or isotonic regression\\n- **Pseudo-labeling**: If confident in predictions on test set\\n\\n## Implementation Roadmap\\n\\n### Phase 1: Baselines (Quick)\\n1. TF-IDF + Logistic Regression\\n2. Tabular-only LightGBM\\n3. Text-only BERT fine-tuning\\n\\n### Phase 2: Core Models (1-2 days)\\n1. Multimodal pipeline (text embeddings + tabular)\\n2. 3-5 diverse models with different architectures\\n3. Basic ensemble (averaging)\\n\\n### Phase 3: Refinement (2-3 days)\\n1. Advanced feature engineering\\n2. Hyperparameter optimization\\n3. Stacking ensemble\\n4. Threshold optimization\\n\\n### Phase 4: Final Push (1 day)\\n1. Error analysis and targeted improvements\\n2. Model blending and weight tuning\\n3. Validation consistency checks\\n4. Submission preparation\\n\\n## Key Libraries and Tools\\n\\n### Essential Libraries\\n- **AutoGluon**: For automatic multimodal modeling\\n- **Multimodal-Toolkit**: For transformer + tabular integration\\n- **LightGBM/CatBoost/XGBoost**: Gradient boosting\\n- **Transformers**: Hugging Face for text encoding\\n- **Optuna**: Hyperparameter optimization\\n\\n### Utility Libraries\\n- **imbalanced-learn**: For resampling techniques\\n- **category_encoders**: For target encoding\\n- **SHAP**: For model interpretation\\n- **tqdm**: For progress tracking\\n\\n## Common Pitfalls to Avoid\\n\\n1. **Data leakage**: Never use test set statistics for training\\n2. **Overfitting to validation**: Use multiple validation strategies\\n3. **Ignoring minority class**: Focus metrics and analysis on positive class\\n4. **Text preprocessing errors**: Preserve semantic meaning\\n5. **Scale mismatch**: Ensure text embeddings and tabular features compatible\\n6. **Ensemble correlation**: Ensure model diversity, not just quantity\\n\\n## Expected Performance Targets\\n\\nBased on similar competitions:\\n- **Single model**: 0.75-0.85 AUC\\n- **Simple ensemble**: 0.80-0.88 AUC\\n- **Advanced ensemble**: 0.85-0.92 AUC\\n- **Top solutions**: 0.90+ AUC (requires significant feature engineering)\\n\\n## References and Resources\\n\\n- AutoGluon multimodal tutorial: Combining BERT with tabular models\\n- Multimodal-Toolkit: GitHub repository with examples\\n- Kaggle winning solutions: Mercari Price Suggestion, Home Credit Default Risk\\n- Class imbalance handling: SMOTE, ADASYN, class weights\\n- Feature engineering: Target encoding, interaction features\"}}",
        "tool.output": "{\"content\": \"Wrote to /home/code/exploration/seed_prompt.txt\", \"is_error\": false}",
        "tool.duration_ms": 0.5407333374023438
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "f10a21038fbee89f",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ListFilesTool",
      "kind": "INTERNAL",
      "start_time": 1767958865731311087,
      "end_time": 1767958865731591838,
      "duration": 0.000280751,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ListFilesTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x7f38e836acd0>\", \"input\": {\"directory_path\": \"/home/data\"}}",
        "tool.output": "{\"content\": \"/home/data:\\n[FILE] description.md (7.0KB)\\n[FILE] sampleSubmission.csv (13.0KB)\\n[FILE] test.json (2.0MB)\\n[FILE] test.zip (433.1KB)\\n[FILE] train.json (8.4MB)\\n[FILE] train.zip (1.3MB)\", \"is_error\": false}",
        "tool.duration_ms": 0.3592967987060547
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "4ced17a24f679d8e",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ReadTool",
      "kind": "INTERNAL",
      "start_time": 1767958874352053322,
      "end_time": 1767958874352379555,
      "duration": 0.000326233,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ReadTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x7f38e9db0750>\", \"input\": {\"file_path\": \"/home/data/description.md\"}}",
        "tool.output": "{\"content\": \"# Overview\\n\\n## Description\\n\\n[Get started on this competition through Kaggle Scripts](https://www.kaggle.com/c/random-acts-of-pizza/forums/t/14286/kaggle-scripts-enabled-on-random-acts-of-pizza)\\n\\nIn machine learning, it is often said¬†there are¬†[no free lunches](http://en.wikipedia.org/wiki/No_free_lunch_theorem).¬†*How wrong we were.*\\n\\nThis competition contains a dataset with 5671 textual requests for pizza from the Reddit community¬†[Random Acts of Pizza](http://www.reddit.com/r/Random_Acts_Of_Pizza/)¬†together with their outcome (successful/unsuccessful) and meta-data. Participants must create an algorithm¬†capable of predicting¬†which requests will garner a cheesy (but sincere!) act of¬†kindness.\\n\\n\\\"I'll write a poem, sing a song, do a dance, play an instrument, whatever! I just want a pizza,\\\" says one hopeful poster. What about making an algorithm?\\n\\n![Pizzas](https://storage.googleapis.com/kaggle-media/competitions/kaggle/3949/media/pizzas.png)\\n\\nKaggle is hosting this competition for the machine learning community to use for fun and practice. This¬†[data](http://cs.stanford.edu/~althoff/raop-dataset/)¬†was collected and graciously shared by¬†[Althoff](http://www.timalthoff.com/)¬†et al. (Buy them a pizza -- data collection is a thankless and tedious job!) We encourage participants to explore their¬†[accompanying paper](http://cs.stanford.edu/~althoff/raop-dataset/altruistic_requests_icwsm.pdf)¬†and ask that you cite the following reference in any publications that result from your work:\\n\\nTim Althoff, Cristian Danescu-Niculescu-Mizil, Dan Jurafsky.¬†*How to Ask for a Favor: A Case Study on the Success of Altruistic Requests*,¬†Proceedings of ICWSM, 2014.\\n\\n~*Pizza icons designed by Matthew Dera from the¬†[Noun Project](http://thenounproject.com/term/pizza/30194/)*~\\n\\n### Evaluation\\n\\nSubmissions are evaluated on¬†[area under the ROC curve](http://en.wikipedia.org/wiki/Receiver_operating_characteristic)¬†between the predicted probability that a request will get pizza and the observed outcomes.\\n\\n### Submission File\\n\\nFor each request¬†in the test set, you should predict a real-valued probability that it resulted in a pizza. The file should contain a header and have the following format:\\n\\n```\\nrequest_id,requester_received_pizza\\nt3_i8iy4,0\\nt3_1mfqi0,0\\nt3_lclka,0\\n...\\n...\\n```\\n\\n### Citation\\n\\nWill Cukierski. (2014). Random Acts of Pizza. Kaggle. https://kaggle.com/competitions/random-acts-of-pizza\\n\\n\\n# Data\\n\\n## Dataset Description\\n\\n[See, fork, and run a random forest benchmark model through Kaggle Scripts](https://www.kaggle.com/users/993/ben-hamner/random-acts-of-pizza/simple-julia-benchmark)\\n\\nThis dataset includes 5671 requests collected from the Reddit community¬†[Random Acts of Pizza](http://www.reddit.com/r/Random_Acts_Of_Pizza/)¬†between December 8, 2010 and September 29, 2013 (retrieved on September 30, 2013).¬†All requests ask for the same thing: a free pizza. The outcome of each request -- whether its author received a pizza or not -- is known.¬†Meta-data includes information such as: time of the request, activity of the requester, community-age of the requester, etc.\\n\\nEach JSON¬†entry corresponds to one request (the first and only request by the requester on Random Acts of Pizza). We have removed fields from the test set which would not be available at the time of posting.\\n\\n## Data fields\\n\\n\\\"giver_username_if_known\\\": Reddit username of giver if known, i.e. the person satisfying the request (\\\"N/A\\\" otherwise).\\n\\n\\\"number_of_downvotes_of_request_at_retrieval\\\": Number of downvotes at the time the request was collected.\\n\\n\\\"number_of_upvotes_of_request_at_retrieval\\\": Number of upvotes at the time the request was collected.\\n\\n\\\"post_was_edited\\\": Boolean indicating whether this post was edited (from Reddit).\\n\\n\\\"request_id\\\": Identifier of the post on Reddit, e.g. \\\"t3_w5491\\\".\\n\\n\\\"request_number_of_comments_at_retrieval\\\": Number of comments for the request at time of retrieval.\\n\\n\\\"request_text\\\": Full text of the request.\\n\\n\\\"request_text_edit_aware\\\": Edit aware version of \\\"request_text\\\". We use a set of rules to strip edited comments indicating the success of the request such as \\\"EDIT: Thanks /u/foo, the pizza was delicous\\\".\\n\\n\\\"request_title\\\": Title of the request.\\n\\n\\\"requester_account_age_in_days_at_request\\\": Account age of requester in days at time of request.\\n\\n\\\"requester_account_age_in_days_at_retrieval\\\": Account age of requester in days at time of retrieval.\\n\\n\\\"requester_days_since_first_post_on_raop_at_request\\\": Number of days between requesters first post on RAOP and this request (zero if requester has never posted before on RAOP).\\n\\n\\\"requester_days_since_first_post_on_raop_at_retrieval\\\": Number of days between requesters first post on RAOP and time of retrieval.\\n\\n\\\"requester_number_of_comments_at_request\\\": Total number of comments on Reddit by requester at time of request.\\n\\n\\\"requester_number_of_comments_at_retrieval\\\": Total number of comments on Reddit by requester at time of retrieval.\\n\\n\\\"requester_number_of_comments_in_raop_at_request\\\": Total number of comments in RAOP by requester at time of request.\\n\\n\\\"requester_number_of_comments_in_raop_at_retrieval\\\": Total number of comments in RAOP by requester at time of retrieval.\\n\\n\\\"requester_number_of_posts_at_request\\\": Total number of posts on Reddit by requester at time of request.\\n\\n\\\"requester_number_of_posts_at_retrieval\\\": Total number of posts on Reddit by requester at time of retrieval.\\n\\n\\\"requester_number_of_posts_on_raop_at_request\\\": Total number of posts in RAOP by requester at time of request.\\n\\n\\\"requester_number_of_posts_on_raop_at_retrieval\\\": Total number of posts in RAOP by requester at time of retrieval.\\n\\n\\\"requester_number_of_subreddits_at_request\\\": The number of subreddits in which the author had already posted in at the time of request.\\n\\n\\\"requester_received_pizza\\\": Boolean indicating the success of the request, i.e., whether the requester received pizza.\\n\\n\\\"requester_subreddits_at_request\\\": The list of subreddits in which the author had already posted in at the time of request.\\n\\n\\\"requester_upvotes_minus_downvotes_at_request\\\": Difference of total upvotes and total downvotes of requester at time of request.\\n\\n\\\"requester_upvotes_minus_downvotes_at_retrieval\\\": Difference of total upvotes and total downvotes of requester at time of retrieval.\\n\\n\\\"requester_upvotes_plus_downvotes_at_request\\\": Sum of total upvotes and total downvotes of requester at time of request.\\n\\n\\\"requester_upvotes_plus_downvotes_at_retrieval\\\": Sum of total upvotes and total downvotes of requester at time of retrieval.\\n\\n\\\"requester_user_flair\\\": Users on RAOP receive badges (Reddit calls them flairs) which is a small picture next to their username. In our data set the user flair is either None (neither given nor received pizza, N=4282), \\\"shroom\\\" (received pizza, but not given, N=1306), or \\\"PIF\\\" (pizza given after having received, N=83).\\n\\n\\\"requester_username\\\": Reddit username of requester.\\n\\n\\\"unix_timestamp_of_request\\\": Unix timestamp of request (supposedly in timezone of user, but in most cases it is equal to the UTC timestamp -- which is incorrect since most RAOP users are from the USA).\\n\\n\\\"unix_timestamp_of_request_utc\\\": Unit timestamp of request in UTC.\", \"is_error\": false}",
        "tool.duration_ms": 0.35643577575683594
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "b89e6be667570ac4",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "CreateNotebookTool",
      "kind": "INTERNAL",
      "start_time": 1767958895692660615,
      "end_time": 1767958895692829299,
      "duration": 0.000168684,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "CreateNotebookTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.CreateNotebookTool object at 0x7f38e8369e90>\", \"input\": {\"notebook_path\": \"exploration/eda.ipynb\", \"cells\": [{\"cell_type\": \"code\", \"content\": \"import pandas as pd\\nimport numpy as np\\nimport json\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Load the training data\\ntrain_path = '/home/data/train.json'\\nwith open(train_path, 'r') as f:\\n    train_data = json.load(f)\\n\\nprint(f\\\"Number of training samples: {len(train_data)}\\\")\\nprint(f\\\"First sample keys: {list(train_data[0].keys())}\\\")\\nprint(f\\\"\\\\nFirst sample preview:\\\")\\nfor key, value in list(train_data[0].items())[:5]:\\n    print(f\\\"  {key}: {value}\\\")\"}]}}",
        "tool.output": "{\"content\": \"Error: Notebook already active: /home/code/exploration/eda.ipynb. Use CloseNotebook first.\", \"is_error\": true}",
        "tool.duration_ms": 0.2503395080566406
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "fa0b48b691ab7a03",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "CloseNotebookTool",
      "kind": "INTERNAL",
      "start_time": 1767958901302310247,
      "end_time": 1767958901414210814,
      "duration": 0.111900567,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "CloseNotebookTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.CloseNotebookTool object at 0x7f38e836aed0>\", \"input\": {}}",
        "tool.output": "{\"content\": \"Closed: /home/code/exploration/eda.ipynb\", \"is_error\": false}",
        "tool.duration_ms": 111.96470260620117
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "448a1ef2091d30db",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "CreateNotebookTool",
      "kind": "INTERNAL",
      "start_time": 1767958912027262702,
      "end_time": 1767958912602845390,
      "duration": 0.575582688,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "CreateNotebookTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.CreateNotebookTool object at 0x7f38e8369e90>\", \"input\": {\"notebook_path\": \"exploration/eda.ipynb\", \"cells\": [{\"cell_type\": \"code\", \"content\": \"import pandas as pd\\nimport numpy as np\\nimport json\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Load the training data\\ntrain_path = '/home/data/train.json'\\nwith open(train_path, 'r') as f:\\n    train_data = json.load(f)\\n\\nprint(f\\\"Number of training samples: {len(train_data)}\\\")\\nprint(f\\\"First sample keys: {list(train_data[0].keys())}\\\")\\nprint(f\\\"\\\\nFirst sample preview:\\\")\\nfor key, value in list(train_data[0].items())[:5]:\\n    print(f\\\"  {key}: {value}\\\")\"}]}}",
        "tool.output": "{\"content\": \"Created: /home/code/exploration/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\", \"is_error\": false}",
        "tool.duration_ms": 575.6580829620361
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "1e7547199dbb0ba9",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767958917274091091,
      "end_time": 1767958918465335920,
      "duration": 1.191244829,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 0, \"end_cell\": 0, \"duration\": 30}}",
        "tool.output": "{\"content\": \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\nimport json\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Load the training data\\ntrain_path = '/home/data/train.json'\\nwith open(train_path, 'r') as f:\\n    train_data = json.load(f)\\n\\nprint(f\\\"Number of training samples: {len(train_data)}\\\")\\nprint(f\\\"First sample keys: {list(train_data[0].keys())}\\\")\\nprint(f\\\"\\\\nFirst sample preview:\\\")\\nfor key, value in list(train_data[0].items())[:5]:\\n    print(f\\\"  {key}: {value}\\\")\\n```\\nOutput:\\nNumber of training samples: 2878\\nFirst sample keys: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\\n\\nFirst sample preview:\\n  giver_username_if_known: N/A\\n  number_of_downvotes_of_request_at_retrieval: 2\\n  number_of_upvotes_of_request_at_retrieval: 5\\n  post_was_edited: False\\n  request_id: t3_q8ycf\\n\", \"is_error\": false}",
        "tool.duration_ms": 1191.2727355957031
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "177b6959ac30b5b4",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "AddNotebookCellTool",
      "kind": "INTERNAL",
      "start_time": 1767958932895679376,
      "end_time": 1767958932896831776,
      "duration": 0.0011524,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "AddNotebookCellTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Convert to DataFrame for easier analysis\\ndf = pd.DataFrame(train_data)\\n\\n# Analyze target distribution\\ntarget_counts = df['requester_received_pizza'].value_counts()\\ntarget_pct = df['requester_received_pizza'].value_counts(normalize=True) * 100\\n\\nprint(\\\"Target Distribution:\\\")\\nprint(f\\\"No pizza: {target_counts[False]} ({target_pct[False]:.1f}%)\\\")\\nprint(f\\\"Pizza received: {target_counts[True]} ({target_pct[True]:.1f}%)\\\")\\nprint(f\\\"Class imbalance ratio: {target_counts[False]/target_counts[True]:.2f}:1\\\")\\n\\n# Check for missing values\\nprint(f\\\"\\\\nMissing values:\\\")\\nmissing = df.isnull().sum()\\nif missing.sum() > 0:\\n    print(missing[missing > 0])\\nelse:\\n    print(\\\"No missing values found\\\")\"}}",
        "tool.output": "{\"content\": \"Added code cell at 1\", \"is_error\": false}",
        "tool.duration_ms": 1.1920928955078125
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "f6452d44250fd4ef",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767958941312381333,
      "end_time": 1767958941336341601,
      "duration": 0.023960268,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 1, \"end_cell\": 1, \"duration\": 30}}",
        "tool.output": "{\"content\": \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Convert to DataFrame for easier analysis\\ndf = pd.DataFrame(train_data)\\n\\n# Analyze target distribution\\ntarget_counts = df['requester_received_pizza'].value_counts()\\ntarget_pct = df['requester_received_pizza'].value_counts(normalize=True) * 100\\n\\nprint(\\\"Target Distribution:\\\")\\nprint(f\\\"No pizza: {target_counts[False]} ({target_pct[False]:.1f}%)\\\")\\nprint(f\\\"Pizza received: {target_counts[True]} ({target_pct[True]:.1f}%)\\\")\\nprint(f\\\"Class imbalance ratio: {target_counts[False]/target_counts[True]:.2f}:1\\\"\\n```\\nOutput:\\nTarget Distribution:\\nNo pizza: 2163 (75.2%)\\nPizza received: 715 (24.8%)\\nClass imbalance ratio: 3.03:1\\n\\nMissing values:\\nrequester_user_flair    2163\\ndtype: int64\\n\", \"is_error\": false}",
        "tool.duration_ms": 24.023056030273438
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "eeca483d488b482e",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "AddNotebookCellTool",
      "kind": "INTERNAL",
      "start_time": 1767958958506565536,
      "end_time": 1767958958507954918,
      "duration": 0.001389382,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "AddNotebookCellTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Analyze text features\\nprint(\\\"Text Features Analysis:\\\")\\nprint(f\\\"Request title length (chars): {df['request_title'].str.len().describe()}\\\")\\nprint(f\\\"\\\\nRequest text length (chars): {df['request_text'].str.len().describe()}\\\")\\nprint(f\\\"\\\\nRequest text edit-aware length (chars): {df['request_text_edit_aware'].str.len().describe()}\\\")\\n\\n# Show some examples of successful vs unsuccessful requests\\nprint(\\\"\\\\n\\\" + \\\"=\\\"*80)\\nprint(\\\"EXAMPLE SUCCESSFUL REQUEST:\\\")\\nsuccess_example = df[df['requester_received_pizza'] == True].iloc[0]\\nprint(f\\\"Title: {success_example['request_title']}\\\")\\nprint(f\\\"Text (first 200 chars): {success_example['request_text'][:200]}...\\\")\\n\\nprint(\\\"\\\\n\\\" + \\\"=\\\"*80)\\nprint(\\\"EXAMPLE UNSUCCESSFUL REQUEST:\\\")\\nfail_example = df[df['requester_received_pizza'] == False].iloc[0]\\nprint(f\\\"Title: {fail_example['request_title']}\\\")\\nprint(f\\\"Text (first 200 chars): {fail_example['request_text'][:200]}...\\\")\"}}",
        "tool.output": "{\"content\": \"Added code cell at 2\", \"is_error\": false}",
        "tool.duration_ms": 1.4371871948242188
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "53bed68f60dced43",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767958967885305783,
      "end_time": 1767958967901128125,
      "duration": 0.015822342,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 2, \"end_cell\": 2, \"duration\": 30}}",
        "tool.output": "{\"content\": \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Analyze text features\\nprint(\\\"Text Features Analysis:\\\")\\nprint(f\\\"Request title length (chars): {df['request_title'].str.len().describe()}\\\")\\nprint(f\\\"\\\\nRequest text length (chars): {df['request_text'].str.len().describe()}\\\")\\nprint(f\\\"\\\\nRequest text edit-aware length (chars): {df['request_text_edit_aware'].str.len().describe()}\\\")\\n\\n# Show some examples of successful vs unsuccessful requests\\nprint(\\\"\\\\n\\\" + \\\"=\\\"*80)\\nprint(\\\"EXAMPLE SUCCESSFUL REQUEST:\\\")\\nsuccess_example = df[df['requester_received_pizza'] =\\n```\\nOutput:\\nText Features Analysis:\\nRequest title length (chars): count    2878.000000\\nmean       71.572967\\nstd        36.233487\\nmin         7.000000\\n25%        46.000000\\n50%        64.000000\\n75%        90.000000\\nmax       272.000000\\nName: request_title, dtype: float64\\n\\nRequest text length (chars): count    2878.000000\\nmean      402.521543\\nstd       362.393727\\nmin         0.000000\\n25%       182.000000\\n50%       308.000000\\n75%       503.750000\\nmax      4460.000000\\nName: request_text, dtype: float64\\n\\nRequest text edit-aware length (chars): count    2878.000000\\nmean      394.567755\\nstd       351.922518\\nmin         0.000000\\n25%       180.000000\\n50%       302.000000\\n75%       498.000000\\nmax      4460.000000\\nName: request_text_edit_aware, dtype: float64\\n\\n================================================================================\\nEXAMPLE SUCCESSFUL REQUEST:\\nTitle: [REQUEST] Not much food until tomorrow.\\nText (first 200 chars): I will go ahead and say that I got a pizza meal from here before as to not seem like I'm scamming anyone. I have been promised 2 well-paying jobs and one minimum wage + .40 to fill in the gaps of unem...\\n\\n================================================================================\\nEXAMPLE UNSUCCESSFUL REQUEST:\\nTitle: [REQUEST] Oceanside, Ca. USA-  US Marine getting ready to deploy.\\nText (first 200 chars): I will soon be going on a long deployment which I'm not aloud to discuss but willing to give some info if you ask. Just wanna eat some of the stuff America has to offer before I leave for a long time ...\\n\", \"is_error\": false}",
        "tool.duration_ms": 15.848159790039062
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "c5854e9097f9d4b1",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "AddNotebookCellTool",
      "kind": "INTERNAL",
      "start_time": 1767958987967452041,
      "end_time": 1767958987969172916,
      "duration": 0.001720875,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "AddNotebookCellTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Analyze numerical/meta-data features\\nnumerical_features = [\\n    'requester_account_age_in_days_at_request',\\n    'requester_number_of_comments_at_request', \\n    'requester_number_of_posts_at_request',\\n    'requester_number_of_subreddits_at_request',\\n    'requester_upvotes_minus_downvotes_at_request',\\n    'requester_upvotes_plus_downvotes_at_request',\\n    'request_number_of_comments_at_retrieval',\\n    'number_of_upvotes_of_request_at_retrieval',\\n    'number_of_downvotes_of_request_at_retrieval'\\n]\\n\\nprint(\\\"Numerical Features Summary:\\\")\\nfor feature in numerical_features:\\n    if feature in df.columns:\\n        print(f\\\"\\\\n{feature}:\\\")\\n        print(df[feature].describe())\\n\\n# Analyze user flair distribution\\nprint(\\\"\\\\n\\\" + \\\"=\\\"*80)\\nprint(\\\"User Flair Distribution:\\\")\\nflair_counts = df['requester_user_flair'].value_counts(dropna=False)\\nprint(flair_counts)\\n\\n# Cross-tabulate flair with target\\nprint(\\\"\\\\nFlair vs Target:\\\")\\nflair_target = pd.crosstab(df['requester_user_flair'], df['requester_received_pizza'], normalize='index') * 100\\nprint(flair_target.round(1))\"}}",
        "tool.output": "{\"content\": \"Added code cell at 3\", \"is_error\": false}",
        "tool.duration_ms": 1.7886161804199219
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "7a481022dcd434b4",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767958994620284349,
      "end_time": 1767958994646173665,
      "duration": 0.025889316,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 3, \"end_cell\": 3, \"duration\": 30}}",
        "tool.output": "{\"content\": \"Executed cells 3-3\\n==================================================\\n\\nCell 3:\\n```\\n# Analyze numerical/meta-data features\\nnumerical_features = [\\n    'requester_account_age_in_days_at_request',\\n    'requester_number_of_comments_at_request', \\n    'requester_number_of_posts_at_request',\\n    'requester_number_of_subreddits_at_request',\\n    'requester_upvotes_minus_downvotes_at_request',\\n    'requester_upvotes_plus_downvotes_at_request',\\n    'request_number_of_comments_at_retrieval',\\n    'number_of_upvotes_of_request_at_retrieval',\\n    'number_of_downvotes_of_request_at_retrieval'\\n\\n```\\nOutput:\\nNumerical Features Summary:\\n\\nrequester_account_age_in_days_at_request:\\ncount    2878.000000\\nmean      250.682364\\nstd       301.838771\\nmin         0.000000\\n25%         3.038877\\n50%       155.156377\\n75%       383.640090\\nmax      2809.750787\\nName: requester_account_age_in_days_at_request, dtype: float64\\n\\nrequester_number_of_comments_at_request:\\ncount    2878.000000\\nmean      112.311327\\nstd       192.017515\\nmin         0.000000\\n25%         0.000000\\n50%        22.000000\\n75%       132.000000\\nmax       981.000000\\nName: requester_number_of_comments_at_request, dtype: float64\\n\\nrequester_number_of_posts_at_request:\\ncount    2878.000000\\nmean       21.614663\\nstd        51.580719\\nmin         0.000000\\n25%         0.000000\\n50%         4.000000\\n75%        21.000000\\nmax       867.000000\\nName: requester_number_of_posts_at_request, dtype: float64\\n\\nrequester_number_of_subreddits_at_request:\\ncount    2878.000000\\nmean       17.857192\\nstd        21.784934\\nmin         0.000000\\n25%         1.000000\\n50%        11.000000\\n75%        26.000000\\nmax       186.000000\\nName: requester_number_of_subreddits_at_request, dtype: float64\\n\\nrequester_upvotes_minus_downvotes_at_request:\\ncount      2878.000000\\nmean       1184.582349\\nstd        4198.255486\\nmin         -67.000000\\n25%           3.000000\\n50%         171.000000\\n75%        1124.500000\\nmax      155010.000000\\nName: requester_upvotes_minus_downvotes_at_request, dtype: float64\\n\\nrequester_upvotes_plus_downvotes_at_request:\\ncount    2.878000e+03\\nmean     3.988570e+03\\nstd      3.012747e+04\\nmin      0.000000e+00\\n25%      8.000000e+00\\n50%      3.355000e+02\\n75%      2.251500e+03\\nmax      1.286864e+06\\nName: requester_upvotes_plus_downvotes_at_request, dtype: float64\\n\\nrequest_number_of_comments_at_retrieval:\\ncount    2878.000000\\nmean        2.858582\\nstd         4.783656\\nmin         0.000000\\n25%         0.000000\\n50%         1.000000\\n75%         4.000000\\nmax        61.000000\\nName: request_number_of_comments_at_retrieval, dtype: float64\\n\\nnumber_of_upvotes_of_request_at_retrieval:\\ncount    2878.000000\\nmean        6.090688\\nstd        10.501259\\nmin         0.000000\\n25%         2.000000\\n50%         4.000000\\n75%         7.000000\\nmax       345.000000\\nName: number_of_upvotes_of_request_at_retrieval, dtype: float64\\n\\nnumber_of_downvotes_of_request_at_retrieval:\\ncount    2878.000000\\nmean        2.428075\\nstd         3.035568\\nmin         0.000000\\n25%         1.000000\\n50%         2.000000\\n75%         3.000000\\nmax        47.000000\\nName: number_of_downvotes_of_request_at_retrieval, dtype: float64\\n\\n================================================================================\\nUser Flair Distribution:\\nrequester_user_flair\\nNone      2163\\nshroom     677\\nPIF         38\\nName: count, dtype: int64\\n\\nFlair vs Target:\\nrequester_received_pizza   True\\nrequester_user_flair           \\nPIF                       100.0\\nshroom                    100.0\\n\", \"is_error\": false}",
        "tool.duration_ms": 25.93064308166504
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "2d3ead2e0fc22836",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "WebSearchTool",
      "kind": "INTERNAL",
      "start_time": 1767959004373057825,
      "end_time": 1767959009484238615,
      "duration": 5.11118079,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "WebSearchTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What are winning approaches for text classification competitions on Kaggle that combine text and meta-data features?\"}}",
        "tool.output": "{\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nWinning solutions in Kaggle text‚Äëclassification contests usually blend strong language‚Äëmodel representations with carefully engineered meta‚Äëdata features, then stack or ensemble the resulting models.  The most successful pipelines start by extracting dense embeddings from pretrained transformers (e.g.,‚ÄØBERT, RoBERTa) or fast‚Äëtext vectors for the raw text, while simultaneously turning auxiliary information such as document length, source, author ID, timestamp or categorical tags into numeric features (one‚Äëhot, target‚Äëencoded, or simple statistics).  These meta‚Äëfeatures are concatenated with the text embeddings and fed into a gradient‚Äëboosting model (LightGBM, XGBoost) or a shallow neural net, which often outperforms a pure‚Äëtext model because the extra signals help disambiguate noisy or short inputs.  After the base models are trained, competitors typically blend several variants (different seeds, architectures, or feature sets) using weighted averaging or stacking, and they validate with stratified K‚Äëfold cross‚Äëvalidation to guard against over‚Äëfitting‚ÄØ([neptune.ai](https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions)).\\n\\nIn addition to the model architecture, practical tricks that distinguish winning entries include efficient handling of large datasets (e.g., loading data as parquet or feather, using Dask or cuDF for parallel processing) and aggressive memory optimisation, which make it feasible to train large transformer‚Äëbased encoders together with many meta‚Äëfeatures on limited hardware‚ÄØ([neptune.ai](https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions)).  Pseudo‚Äëlabeling on the test set, careful class‚Äëbalance weighting, and early‚Äëstopping based on validation scores are also common, allowing the final ensemble to capture both the nuanced language patterns and the predictive power of the side information.\\n\\n--- Result 2 ---\\nTitle: Text Classification: All Tips and Tricks from 5 Kaggle Competitions\\nURL: https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions\\n\\nContent:\\nIn this article, I will discuss some great tips and tricks to [improve the performance](https://neptune.ai/blog/improving-machine-learning-deep-learning-models) of your text classification model. These tricks are obtained from solutions of some of Kaggle‚Äôs top NLP competitions.\\n\\nNamely, I‚Äôve gone through:\\n\\n- [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification) ‚Äì $65,000\\n- [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/) ‚Äì $35,000\\n- [Quora Insincere Questions Classification](http://kaggle.com/c/quora-insincere-questions-classification) ‚Äì $25,000\\n- [Google QUEST Q&A Labeling](https://www.kaggle.com/c/google-quest-challenge) ‚Äì $25,000\\n- [TensorFlow 2.0 Question Answering](https://www.kaggle.com/c/tensorflow2-question-answering) ‚Äì $50,000\\n\\nand found a ton of great ideas.\\n\\nWithout much lag, let‚Äôs begin.\\n\\n## Dealing with larger datasets\\n\\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for Kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\\n\\n- Optimize the memory by [reducing the size of some attributes](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\\n- Use open-source libraries such as [Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space\\n- Use [cudf](https://github.com/rapidsai/cudf)\\n- Convert data to [parquet](https://arrow.apache.org/docs/python/parquet.html) format\\n- Convert data to [feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03) format\\n\\n## Small datasets and external data\\n\\nBut, what can one do if the dataset is small? Let‚Äôs see some techniques to tackle this situation.\\n\\nOne way to increase the performance of any machine learning model is to use some external data frame that contains some variables that influence the predicate variable.\\n\\nLet‚Äôs see some of the external datasets.\\n\\n- Use of [squad](https://rajpurkar.github.io/SQuAD-explorer/) data for Question Answering tasks\\n- Other [datasets](http://nlpprogress.com/english/question_answering.html) for QA tasks\\n- Wikitext long term dependency language modeling [dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\\n- [Stackexchange data](https://archive.org/download/stackexchange)\\n- Prepare a dictionary of commonly misspelled words and corrected words.\\n- Use of [helper datasets](https://www.kaggle.com/kyakovlev/jigsaw-general-helper-public) for cleaning\\n- [Pseudo labeling](https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969/) is the process of adding confidently predicted test data to your training data\\n- Use different data [sampling methods](https://www.kaggle.com/shahules/tackling-class-imbalance)\\n- Text augmentation by [Exchanging words with synonym](https://arxiv.org/pdf/1502.01710.pdf) [s](https://arxiv.org/pdf/1502.01710.pdf)\\n- Text augmentation by [noising in RNN](https://arxiv.org/pdf/1703.02573.pdf)\\n- Text augmentation by [translation to other languages and back](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/48038)\\n\\n## Data exploration and gaining insights\\n\\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\\n\\n- Twitter data [exploration methods](https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda)\\n- Simple [EDA for tweets](https://www.kaggle.com/nz0722/simple-eda-text-preprocessing-jigsaw)\\n- [EDA](https://www.kaggle.com/tunguz/just-some-simple-eda) for Quora data\\n- [EDA](https://www.kaggle.com/kailex/r-eda-for-q-gru) in ¬†R for Quora data\\n- Complete [EDA](https://www.kaggle.com/codename007/start-from-here-quest-complete-eda-fe) with stack exchange data\\n- My previous article on [EDA for natural language processing](https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools)\\n\\n## Data cleaning\\n\\nData cleaning is one of the important and integral parts of any NLP problem. Text data always needs some preprocessing and cleaning before we can represent it in a suitable form.\\n\\n- Use this [notebook](https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing) to clean social media data\\n- [Data cleaning](https://www.kaggle.com/kyakovlev/preprocessing-bert-public) for BERT\\n- Use [textblob](https://textblob.readthedocs.io/en/dev/quickstart.html) to correct misspellings\\n- [Cleaning](https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing) for pre-trained embeddings\\n- [Language detection and translation](https://www.pythonprogramming.in/language-detection-and-translation-using-textblob.html) for multilingual tasks\\n- Preprocessing for Glove [part 1](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part1-eda) and [part 2](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part2-usage)\\n- [Increasing word coverage](https://www.kaggle.com/sunnymarkliu/more-text-cleaning-to-increase-word-coverage) to get more from pre-trained word embeddings\\n\\n## Text representations\\n\\nBefore we feed our text data to the Neural network or ML model, the text input needs to be represented in a suitable format. These representations determine the performance of the model to a large extent.\\n\\n- Pretrained [Glove](https://nlp.stanford.edu/projects/glove/) vectors\\n- Pretrained [fasttext](https://fasttext.cc/docs/en/english-vectors.html) vectors\\n- Pretrained [word2vec](https://radimrehurek.com/gensim/models/word2vec.html) vectors\\n- My previous article on these [3 embeddings](https://neptune.ai/blog/document-classification-small-datasets)\\n- Combining [pre-trained vectors](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778/). This can help in better representation of text and decreasing OOV words\\n- [Paragram](https://cogcomp.seas.upenn.edu/page/resource_view/106) embeddings\\n- [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/1)\\n- Use USE to generate [sentence-level features](https://www.kaggle.com/abhishek/distilbert-use-features-oof)\\n- 3 methods to [combine embeddings](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778)\\n\\nContextual embeddings models\\n\\n- [BERT](https://github.com/google-research/bert) Bidirectional Encoder Representations from Transformers\\n- [GPT](https://github.com/openai/finetune-transformer-lm)\\n- [Roberta](https://github.com/pytorch/fairseq/tree/master/examples/roberta) a Robustly Optimized BERT\\n- [Albert](https://github.com/google-research/ALBERT) a Lite BERT for Self-supervised Learning of Language Representations\\n- [Distilbert](https://github.com/huggingface/transformers/tree/master/examples/distillation) a lighter version of BERT\\n- [XLNET](https://github.com/zihangdai/xlnet/)\\n\\n## Modeling\\n\\n### Model architecture\\n\\nChoosing the right architecture is important to develop a proper machine learning model, sequence to sequence models like LSTMs, GRUs perform well in NLP problems and is always worth trying. Stacking 2 layers of LSTM/GRU networks is a common approach.\\n\\n- [Stacking Bidirectional CuDNNLSTM](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644/)\\n- [Stacking LSTM networks](https://www.kaggle.com/sakami/google-quest-single-lstm/)\\n- [LSTM and 5 fold Attention](https://www.kaggle.com/christofhenkel/keras-baseline-lstm-attention-5-fold/)\\n- [Bi...\\n\\n--- Result 3 ---\\nTitle: Text Classification Techniques - Explained - Kaggle\\nURL: https://www.kaggle.com/code/eraikako/text-classification-techniques-explained\\n\\nContent:\\nText Classification Techniques - Explained | Kaggle\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n[\\nLearn more\\n](https://www.kaggle.com/cookies)\\nOK, Got it.\\n![Something went wrong and this page crashed!](https://www.kaggle.com/static/images/error/server-error-illo_light.svg)###### Something went wrong and this page crashed!\\nIf the issue persists, it's likely a problem on our side.\\n```\\nLoading CSS chunk 1019 failed.\\\\\\\\n(https://www.kaggle.com/static/assets/KernelViewer.21f94db0016b9074.css)\\nkeyboard\\\\_arrow\\\\_upcontent\\\\_copy\\nError: Loading CSS chunk 1019 failed.\\\\\\\\n(https://www.kaggle.com/static/assets/KernelViewer.21f94db0016b9074.css)\\nat t.onerror.t.onload (https://www.kaggle.com/static/assets/runtime.js?v=a6aef772a946d7d4:1:10006)\\n```\\nRefresh\\n\\n--- Result 4 ---\\nTitle: Advanced Techniques of Text Classification - Kaggle\\nURL: https://www.kaggle.com/code/meharshanali/advanced-techniques-of-text-classification\\n\\nContent:\\nChecking your browser - reCAPTCHA\\nChecking your browser before accessing www.kaggle.com ...\\nClick[here](#)if you are not automatically redirected after 5 seconds.\\n\\n--- Result 5 ---\\nTitle: A Beginners Guide to dealing with Text Data - Kaggle\\nURL: https://www.kaggle.com/code/prashant111/a-beginners-guide-to-dealing-with-text-data\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)</p></div>ChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\nat b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=c93cac9cb620a9ebe94a:1:10973)</pre></div></div></div></div>\\n\\n--- Result 6 ---\\nTitle: A Guide to any Classification Problem - Kaggle\\nURL: https://www.kaggle.com/code/durgancegaur/a-guide-to-any-classification-problem\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)</p></div>ChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\nat b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=85e822d649bb8c5b8715:1:11062)</pre></div></div></div></div>\\n\\n--- Result 7 ---\\nTitle: How to Categorize Large Amounts of Text Data | by Data@Urban\\nURL: https://urban-institute.medium.com/how-to-categorize-large-amounts-of-text-data-71e1fd590e2a\\n\\nContent:\\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F71e1fd590e2a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&source=---two_column_layout_nav----------------------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Furban-institute.medium.com%2Fhow-to-categorize-large-amounts-of-text-data-71e1fd590e2a&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\\n\\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_topnav-----------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Furban-institute.medium.com%2Fhow-to-categorize-large-amounts-of-text-data-71e1fd590e2a&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\\n\\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\\n\\n_Original illustration courtesy of Majcot@Shutterstock_\\n\\n# How to Categorize Large Amounts of Text Data\\n\\n[![Data@Urban](https://miro.medium.com/v2/resize:fill:88:88/1*SmPWgbgKs_B3FJ242EIJJg.png)](https://urban-institute.medium.com/?source=post_page-----71e1fd590e2a--------------------------------)\\n\\n[Data@Urban](https://urban-institute.medium.com/?source=post_page-----71e1fd590e2a--------------------------------)\\n\\n¬∑\\n\\n[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fed38af6a2b4c&operation=register&redirect=https%3A%2F%2Furban-institute.medium.com%2Fhow-to-categorize-large-amounts-of-text-data-71e1fd590e2a&user=Data%40Urban&userId=ed38af6a2b4c&source=post_page-ed38af6a2b4c----71e1fd590e2a---------------------post_header-----------)\\n\\n10 min read\\n\\n¬∑\\n\\nFeb 20, 2019\\n\\n--\\n\\nListen\\n\\nShare\\n\\nIn the Urban Institute‚Äôs [Connecting Police to Communities project](https://www.urban.org/policy-centers/justice-policy-center/projects/connecting-police-communities), we‚Äôve been working to identify best practices for law enforcement use of social media by examining tweets from police and the public that document their interactions and behavior on Twitter. We collected millions of tweets containing the words ‚Äúcop‚Äù or ‚Äúpolice‚Äù to help us determine [public sentiment toward police](https://www.urban.org/research/publication/public-perceptions-police-social-media). We also collected more than 500,000 tweets from over 300 law enforcement agencies to determine [how police use social media](https://www.urban.org/research/publication/social-media-guidebook-law-enforcement-agencies).\\n\\nOnce we collected all the tweets, we needed to categorize them by either sentiment or topic. Traditionally, senior social science researchers would assign one or more research assistants the unenviable task of manually categorizing each tweet. At the scale of tweets we collected, we quickly realized that we needed a less manual, more technologically oriented solution. We simply didn‚Äôt have the time or resources for someone to read and categorize each tweet manually, so we decided to develop supervised machine learning models to perform the same task automatically. In this post, we explain how we developed a model to classify text data, along with some troubleshooting tips and the lessons we learned.\\n\\n# What Is Machine Learning?\\n\\nThe rise of online publications, reviews, and social media has created a trove of easily accessible text data for researchers and data scientists to use to study human behavior and social phenomena.\\n\\nFor researchers used to analyzing standardized tabular data, deriving meaning from unstructured and sometimes messy text is difficult. For example, movie studios looking for early audience feedback may want to categorize the topic of tweets or the sentiment of reviews, but manually reading and sorting them would take too long and would be prohibitively expensive. Instead, analysts typically use supervised machine learning techniques to classify each piece of text data in a fraction of the time.\\n\\nIn machine learning, systems learn from and detect patterns in data without being explicitly programmed by a researcher. Despite the programming process‚Äôs similarity to traditional regression models, machine learning practitioners typically use different language than social scientists ‚Äî the biggest distinction being the use of the word ‚Äúfeatures‚Äù to describe variables in a model.\\n\\nThere are generally two types of machine learning models ‚Äî unsupervised and supervised. In unsupervised machine learning, no outcome is identified, and the model clusters observations together based on patterns, similar to a factor analysis. In supervised machine learning, the researcher specifies the outcome and uses regression or classification algorithms to predict this outcome variable using the input features. For our text classification tasks, we developed two supervised machine learning models built for classification. One model classified the sentiment of public tweets toward police, and the other classified the topic of law enforcement tweets.\\n\\n# Developing a Text Classification Model\\n\\nText classification is a multistep process, and the steps included in your final process depend on the specific problem you are trying to solve. In other words, you may not get the best possible results by simply re-creating our features and models. This is because the performance of any given model depends on its ability to detect patterns in the input text, and different collections of text typically have different patterns. The following steps formed the basis for our text analysis and provide general guidelines for any text classification process.\\n\\n**Step 1: Develop features for the model.** In machine learning, features are the independent or explanatory variables used to predict the outcome variable. The features we created for analyzing Twitter data (and the features created for similar analyses) will typically fall into one of two categories: _content_ or _metadata_.\\n\\n_Content:_ Many features in the model will be based on the words in the text, but the text often needs some processing before the words can be converted into features. Analyzing text is typically a two-step procedure:\\n\\n1\\\\. Preprocess the text data. Preprocessing standardizes your text as much as possible so that the model can more easily recognize general patterns. For example, you may want to remove ‚Äústop words,‚Äù common words that may add unnecessary noise to the data and don‚Äôt have much meaning on their own ‚Äî for example, ‚Äúand,‚Äù ‚Äúin,‚Äù ‚Äúor,‚Äù and ‚Äúthe.‚Äù Similarly, you can stem or lemmatize words to convert them to their root form (e.g., ‚Äúwalks,‚Äù ‚Äúwalked,‚Äù and ‚Äúwalking‚Äù become ‚Äúwalk‚Äù) so that the model recognizes them as the same word. Other preprocessing steps include converting the text to lowercase letters and inserting placeholders for or removing punctuation, numbers, and symbols. Rather than removing numbers, replacing them with a placeholder was helpful for categorizing police tweets by topic, because the presence of numbers helped predict certain categories (e.g., when addresses were included in crime incident updates).\\n\\n2\\\\. Create a document-term matrix. In a document-term matrix, each row in the dataset represents the unit of text (e.g., a tweet or a review), and each column represents a word used in the collection of text data. The two tweets, ‚ÄúPolice training downtown tonight‚Äù and ‚ÄúPolice out here with tasers tonight‚Äù would lead to a document-term matrix that looks like this table:\\n\\n_Metadata:_ External information about the text often improves the model‚Äôs performance as much as the text itself. When working with Twitter data, it may be helpful to include information about the time of day or day of the week the tweet was posted or the number of retweets the post received. You can also extract information from the text using advanced text analytics tools like [CoreNLP](https://stanfordnlp.github.io/CoreNLP/...\\n\\n--- Result 8 ---\\nTitle: How To Run Text Categorization: All Tips and Tricks from 5 Kaggle Competitions\\nURL: https://hackernoon.com/how-to-run-text-categorization-all-tips-and-tricks-from-5-kaggle-competitions-7e1h3uyh\\n\\nContent:\\nHow To Run Text Categorization: All Tips and Tricks from 5 Kaggle Competitions | HackerNoon\\nDiscover Anything**\\n[\\n![Hackernoon logo](https://hackernoon.imgix.net/hn-icon.png?auto=format&amp;fit=max&amp;w=128)\\nHackernoon](https://hackernoon.com/)\\nSignup[Write](https://app.hackernoon.com/new)\\n******\\n**139reads\\n# How To Run Text Categorization: All Tips and Tricks from 5 Kaggle Competitions\\nby\\n**neptune.ai Jakub Czakon**\\n[\\n![](https://cdn.hackernoon.com/images%2FL4OCiGu7n6cUBUyJKe9Rs0MX1d73-8x03wsi.jpeg?alt=media&amp;token=dc8a460d-ab44-4c8e-a72e-559d894a3fbc)\\nbyneptune.ai Jakub Czakon@neptuneAI\\\\_jakub](https://hackernoon.com/u/neptuneAI_jakub)\\nSenior data scientist building experiment tracking tools for ML projects at https://neptune.ai\\nSubscribe\\nAugust 23rd, 2020\\nTLDR**\\n![neptune.ai Jakub Czakon](https://cdn.hackernoon.com/images%2FL4OCiGu7n6cUBUyJKe9Rs0MX1d73-8x03wsi.jpeg?alt=media&amp;token=dc8a460d-ab44-4c8e-a72e-559d894a3fbc)\\nbyneptune.ai Jakub Czakon@neptuneAI\\\\_jakub\\n[\\n![](https://cdn.hackernoon.com/images%2FL4OCiGu7n6cUBUyJKe9Rs0MX1d73-8x03wsi.jpeg?alt=media&amp;token=dc8a460d-ab44-4c8e-a72e-559d894a3fbc)\\nbyneptune.ai Jakub Czakon@neptuneAI\\\\_jakub](https://hackernoon.com/u/neptuneAI_jakub)\\nSenior data scientist building experiment tracking tools for ML projects at https://neptune.ai\\nSubscribe\\n****\\n**********[**](<mailto:?subject=I'd like to share a link with you &amp;body=>)\\n[\\n![](https://cdn.hackernoon.com/images%2FL4OCiGu7n6cUBUyJKe9Rs0MX1d73-8x03wsi.jpeg?alt=media&amp;token=dc8a460d-ab44-4c8e-a72e-559d894a3fbc)\\nbyneptune.ai Jakub Czakon@neptuneAI\\\\_jakub](https://hackernoon.com/u/neptuneAI_jakub)\\nSenior data scientist building experiment tracking tools for ML projects at https://neptune.ai\\nSubscribe\\n****\\n**********[**](<mailto:?subject=I'd like to share a link with you &amp;body=>)\\n[\\n‚ÜêPrevious\\nHyperparameter Tuning on Any Python Script in 3 EasySteps [A How-To Guide]\\n](https://hackernoon.com/hyperparameter-tuning-on-any-python-script-in-3-easy-steps-a-how-to-guide-5u4g329e)\\n### About Author\\n[](https://hackernoon.com/u/neptuneAI_jakub)\\n[**neptune.ai Jakub Czakon**@neptuneAI\\\\_jakub](https://hackernoon.com/u/neptuneAI_jakub)\\nSenior data scientist building experiment tracking tools for ML projects at https://neptune.ai\\n[Read my stories](https://hackernoon.com/u/neptuneAI_jakub)[Learn More](https://hackernoon.com/about/neptuneAI_jakub)\\n#### Comments\\n#### TOPICS\\n[**machine-learning](https://hackernoon.com/c/machine-learning)[#machine-learning](https://hackernoon.com/tagged/machine-learning)[#binary-classification](https://hackernoon.com/tagged/binary-classification)[#data-science](https://hackernoon.com/tagged/data-science)[#kaggle](https://hackernoon.com/tagged/kaggle)[#tips-and-tricks](https://hackernoon.com/tagged/tips-and-tricks)[#ml](https://hackernoon.com/tagged/ml)[#kaggle-competition](https://hackernoon.com/tagged/kaggle-competition)[#tutorial](https://hackernoon.com/tagged/tutorial)\\n#### THIS ARTICLE WAS FEATURED IN\\n[\\n](https://sia.hackernoon.com/how-to-run-text-categorization-all-tips-and-tricks-from-5-kaggle-competitions-7e1h3uyh)[\\n**\\nArweave\\n](https://www.arweave.net/ithJ8kJytzNBq5ZLT_ZTN24PAqZ047UthexwscEqhQw)[\\nViewBlock\\n](https://viewblock.io/arweave/tx/ithJ8kJytzNBq5ZLT_ZTN24PAqZ047UthexwscEqhQw)[Terminal](https://terminal.hackernoon.com/how-to-run-text-categorization-all-tips-and-tricks-from-5-kaggle-competitions-7e1h3uyh?ref=hackernoon)[Lite](https://hackernoon.com/lite/how-to-run-text-categorization-all-tips-and-tricks-from-5-kaggle-competitions-7e1h3uyh?ref=hackernoon)[\\n![](https://t0.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;url=https://www.joyk.com/dig/detail/1707491664448324&amp;size=16)Joyk\\n](https://www.joyk.com/dig/detail/1707491664448324)[\\n![](https://t0.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;url=https://www.learnrepo.com/242-stories-to-learn-about-ml&amp;size=16)Learnrepo\\n](https://www.learnrepo.com/242-stories-to-learn-about-ml)[\\n![](https://t0.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;url=https://unni.io/domains/hackernoon.com/page/48760739&amp;size=16)Unni\\n](https://unni.io/domains/hackernoon.com/page/48760739)[\\n![](https://t0.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;url=https://learnrepo.hashnode.dev/833-stories-to-learn-about-tutorial&amp;size=16)Hashnode\\n](https://learnrepo.hashnode.dev/833-stories-to-learn-about-tutorial)[\\n![](https://t0.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;url=https://learnrepo.com/242-stories-to-learn-about-ml&amp;size=16)Learnrepo\\n](https://learnrepo.com/242-stories-to-learn-about-ml)[\\n![](https://t0.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;url=https://unni.io/domains/hackernoon.com/page/50536904&amp;size=16)Unni\\n](https://unni.io/domains/hackernoon.com/page/50536904)\\n#### Related Stories\\n[](https://hackernoon.com/a-completeish-guide-to-python-tools-you-can-use-to-analyse-text-data-13g53wgr)\\n[#MACHINE-LEARNING](https://hackernoon.com/tagged/machine-learning)\\n## [A Complete(ish) Guide to Python Tools You Can Use To Analyse Text Data](https://hackernoon.com/a-completeish-guide-to-python-tools-you-can-use-to-analyse-text-data-13g53wgr)\\n[neptune.ai Jakub Czakon](https://hackernoon.com/u/neptuneAI_jakub)\\nMar 23, 2020\\n[](https://hackernoon.com/beyond-recall-and-precision-rethinking-metrics-in-fraud-prevention)\\n[#METRICS](https://hackernoon.com/tagged/metrics)\\n## [Beyond Recall and Precision: Rethinking Metrics in Fraud Prevention](https://hackernoon.com/beyond-recall-and-precision-rethinking-metrics-in-fraud-prevention)\\n[Aleksei Toshchakov](https://hackernoon.com/u/toshchakov)\\nNov 11, 2023\\n[](https://hackernoon.com/binary-classification-understanding-activation-and-loss-functions-with-a-pytorch-example)\\n[#BINARY-CLASSIFICATION](https://hackernoon.com/tagged/binary-classification)\\n## [Binary Classification: Understanding Activation and Loss Functions with a PyTorch Example](https://hackernoon.com/binary-classification-understanding-activation-and-loss-functions-with-a-pytorch-example)\\n[Dmitrii Matveichev](https://hackernoon.com/u/owlgrey)\\nAug 15, 2023\\n[](https://hackernoon.com/confusion-matrix-in-machine-learning-everything-you-need-to-know)\\n[#MACHINE-LEARNING](https://hackernoon.com/tagged/machine-learning)\\n## [Confusion Matrix in Machine Learning: Everything You Need to Know](https://hackernoon.com/confusion-matrix-in-machine-learning-everything-you-need-to-know)\\n[Bala Priya C](https://hackernoon.com/u/balapriya)\\nFeb 03, 2022\\n[](https://hackernoon.com/model-calibration-in-machine-learning-an-important-but-inconspicuous-concept)\\n[#ARTIFICIAL-INTELLIGENCE](https://hackernoon.com/tagged/artificial-intelligence)\\n## [Model Calibration in Machine Learning: An Important but Inconspicuous Concept](https://hackernoon.com/model-calibration-in-machine-learning-an-important-but-inconspicuous-concept)\\n[Sanjay Kumar](https://hackernoon.com/u/sanjaykn170396)\\nJan 28, 2023\\n[](https://hackernoon.com/practical-tips-for-binary-classification-excellence-ape3w02)\\n[#MACHINE-LEARNING](https://hackernoon.com/tagged/machine-learning)\\n## [Practical Tips For Binary Classification Excellence](https://hackernoon.com/practical-tips-for-binary-classification-excellence-ape3w02)\\n[neptune.ai Patrycja Jenkner](https://hackernoon.com/u/neptuneAI_patrycja)\\nNov 09, 2020\\n[](https://hackernoon.com/a-completeish-guide-to-python-tools-you-can-use-to-analyse-text-data-13g53wgr)\\n[#MACHINE-LEARNING](https://hackernoon.com/tagged/machine-learning)\\n## [A Complete(ish) Guide to Python Tools You Can Use To Analyse Text Data](https://hackernoon.com/a-completeish-guide-to-python-tools-you-can-use-to-analyse-text-data-13g53wgr)\\n[neptune.ai Jakub Czakon](https://hackernoon.com/u/neptuneAI_jakub)\\nMar 23, 2020\\n[](https://hackernoon.com/beyond-recall-and-precision-rethinking-metrics-in-fraud-prevention)\\n[#METRICS](https://hackernoon.com/tagged/metrics)\\n## [Beyond Recall and Precision: Rethinking Metrics in Fraud Prevention](https://hackernoon.com/beyond-re...\\n\\n--- Result 9 ---\\nTitle: A Journey Through Kaggle Text Data Competitions From 2021 to 2023\\nURL: https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312\\n\\nContent:\\nA Journey Through Kaggle Text Data Competitions From 2021 to 2023 | by Salomon Marquez | Medium\\n[Sitemap](https://medium.com/sitemap/sitemap.xml)\\n[Open in app](https://play.google.com/store/apps/details?id=com.medium.reader&amp;referrer=utm_source=mobileNavBar&amp;source=post_page---top_nav_layout_nav-----------------------------------------)\\nSign up\\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\\n[\\nWrite\\n](https://medium.com/m/signin?operation=register&amp;redirect=https://medium.com/new-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\\n[\\nSearch\\n](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\\nSign up\\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\\n# A Journey Through Kaggle Text Data Competitions From 2021 to 2023\\n[\\n![Salomon Marquez](https://miro.medium.com/v2/da:true/resize:fill:64:64/0*hbSxb57OAqPdRqks)\\n](https://medium.com/@sblaizer?source=post_page---byline--631a79f96312---------------------------------------)\\n[Salomon Marquez](https://medium.com/@sblaizer?source=post_page---byline--631a79f96312---------------------------------------)\\n18 min read\\n¬∑Apr 28, 2024\\n[\\n](https://medium.com/m/signin?actionUrl=https://medium.com/_/vote/p/631a79f96312&amp;operation=register&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;user=Salomon+Marquez&amp;userId=1a60dea97a2c&amp;source=---header_actions--631a79f96312---------------------clap_footer------------------)\\n--\\n[](https://medium.com/m/signin?actionUrl=https://medium.com/_/bookmark/p/631a79f96312&amp;operation=register&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;source=---header_actions--631a79f96312---------------------bookmark_footer------------------)\\nListen\\nShare\\n*Authors:*[*Liliana Badillo*](https://www.kaggle.com/sophieb)*and*[*Salomon Marquez*](https://www.kaggle.com/sblaizer)\\n**> Note:\\n**> I created this Medium post to provide more visibility to our original report. Please refer to our [> A Journey Throuhgh Text Data Competitions\\n](https://www.kaggle.com/code/sophieb/a-journey-through-text-data-competitions)> notebook for further details.\\nN**atural Language Processing (NLP)**, the branch of artificial intelligence that enables computers to understand human language, has witnessed remarkable growth and transformative advancements in recent years. This surge has been driven by the increasing availability of vast amounts of text data and the rapid development of sophisticated machine-learning techniques.\\n*> ‚ÄúIt is estimated that 90% of the world‚Äôs data was generated in the last two years alone‚Äù\\n*> by [> Amount of Data Created Daily (2023)\\n](https://explodingtopics.com/blog/data-generated-per-day)\\n[**Kaggle**](https://www.kaggle.com/)is an online platform that hosts machine learning and data science competitions. Among these competitions, text data competitions specifically focus on tasks related to NLP and text analysis. Participants are provided with text datasets and are tasked with developing models and algorithms to solve language-related challenges such as sentiment analysis, text classification, and machine translation. These competitions are instrumental in advancing NLP techniques and provide participants with valuable experience and knowledge exchange opportunities.\\nAccessing and learning about the latest techniques employed in text data Kaggle competitions can be challenging due to their dispersion within discussions and winning solution write-ups.**Valuable information about these cutting-edge approaches tends to get buried, making it difficult to stay updated on the evolving landscape of text data techniques.**\\nIn this essay, our objective is to offer valuable insights into key lessons learned by the Kaggle community during their engagement in text data competitions spanning from 2021 to 2023. We will focus on**four pivotal topics**that have emerged as the foundation for successful solutions in recent years:**model architectures**,**pseudo labeling**,**adversarial weight perturbation**, and**mask language modeling**. By examining these four key areas, we aim to provide a comprehensive understanding of the essential elements driving winning strategies in text data competitions.\\n## Methodology\\nTo gain a better understanding of the text data landscape, we carried out the following tasks:\\n* **Analyze 27 write-ups from nine Kaggle competitions specifically related to text data**. We dove deeper into the top three solutions for text data competitions held from 2021 to 2023, see**Figure 1**. Also, we explore a range of topics, including the prevalent techniques and methodologies employed, the most effective model architectures utilized, and the challenges encountered and overcame. This analysis enabled us to gain deeper insights into the problem-solving approaches and thought processes employed by Kagglers in developing their successful solutions.\\n* **Perform a general but not exhaustive analysis of the**[**arXiv dataset**](https://www.kaggle.com/datasets/Cornell-University/arxiv). We filter out categories with the potential to include NLP papers published within the past two years. By leveraging a predefined list of keywords associated with text data, we directed our efforts towards uncovering the specific problem domains and top leading model architectures [1][2] that have garnered attention within the research community.\\nPress enter or click to view image in full size\\n![]()\\n**Figure 1.**Kaggle text data competitions held from 2021 to 2023\\n## Key Discoveries of Text Data Competitions\\nThe result of the analysis of the 27 write-ups and their most notable comments can be seen in[Table I of Appendix A](https://www.kaggle.com/code/sophieb/a-journey-through-text-data-competitions#Appendix-A)and[Table II of Appendix B](https://www.kaggle.com/code/sophieb/a-journey-through-text-data-competitions#Appendix-B), respectively.**Table I**provides information about the top three winning solutions in each Kaggle competition related to text, highlighting aspects such as model architectures, parameters like PB and LB, optimizers, ensembles, and the most innovative proposed ideas, among others. On the other hand,**Table II**presents a summary of comments from the write-ups in a question-like format. Additionally, the analysis of the arXiv dataset has allowed us to unveil, on a larger scale, how the use of certain model architectures and their application to specific text domains compares to the solutions presented in text-oriented Kaggle competitions over the past two years. For more details, please refer to[EDA Kaggle and Arxiv datasets](https://www.kaggle.com/code/sophieb/eda-kaggle-and-arxiv-datasets)notebook.\\nAs**Figure 2**shows, out of the nine competitions, five focused on text classification tasks, two aimed at information extraction tasks, while the remaining targeted text matching and question-and-answer tasks. Interestingly,**Figure 3**shows that with the frequency of the term ‚Äúquestion answering‚Äù exceeding 400 times, it can be inferred that the scientific community has placed greater importance on domains related to this field. While Kaggle competitions have only hosted one question-and-answer competition, there seems ...\\n\", \"is_error\": false, \"results\": [{\"title\": \"ANSWER\", \"text\": \"Winning solutions in Kaggle text‚Äëclassification contests usually blend strong language‚Äëmodel representations with carefully engineered meta‚Äëdata features, then stack or ensemble the resulting models.  The most successful pipelines start by extracting dense embeddings from pretrained transformers (e.g.,‚ÄØBERT, RoBERTa) or fast‚Äëtext vectors for the raw text, while simultaneously turning auxiliary information such as document length, source, author ID, timestamp or categorical tags into numeric features (one‚Äëhot, target‚Äëencoded, or simple statistics).  These meta‚Äëfeatures are concatenated with the text embeddings and fed into a gradient‚Äëboosting model (LightGBM, XGBoost) or a shallow neural net, which often outperforms a pure‚Äëtext model because the extra signals help disambiguate noisy or short inputs.  After the base models are trained, competitors typically blend several variants (different seeds, architectures, or feature sets) using weighted averaging or stacking, and they validate with stratified K‚Äëfold cross‚Äëvalidation to guard against over‚Äëfitting‚ÄØ([neptune.ai](https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions)).\\n\\nIn addition to the model architecture, practical tricks that distinguish winning entries include efficient handling of large datasets (e.g., loading data as parquet or feather, using Dask or cuDF for parallel processing) and aggressive memory optimisation, which make it feasible to train large transformer‚Äëbased encoders together with many meta‚Äëfeatures on limited hardware‚ÄØ([neptune.ai](https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions)).  Pseudo‚Äëlabeling on the test set, careful class‚Äëbalance weighting, and early‚Äëstopping based on validation scores are also common, allowing the final ensemble to capture both the nuanced language patterns and the predictive power of the side information.\", \"url\": \"\"}, {\"title\": \"Text Classification: All Tips and Tricks from 5 Kaggle Competitions\", \"text\": \"In this article, I will discuss some great tips and tricks to [improve the performance](https://neptune.ai/blog/improving-machine-learning-deep-learning-models) of your text classification model. These tricks are obtained from solutions of some of Kaggle‚Äôs top NLP competitions.\\n\\nNamely, I‚Äôve gone through:\\n\\n- [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification) ‚Äì $65,000\\n- [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/) ‚Äì $35,000\\n- [Quora Insincere Questions Classification](http://kaggle.com/c/quora-insincere-questions-classification) ‚Äì $25,000\\n- [Google QUEST Q&A Labeling](https://www.kaggle.com/c/google-quest-challenge) ‚Äì $25,000\\n- [TensorFlow 2.0 Question Answering](https://www.kaggle.com/c/tensorflow2-question-answering) ‚Äì $50,000\\n\\nand found a ton of great ideas.\\n\\nWithout much lag, let‚Äôs begin.\\n\\n## Dealing with larger datasets\\n\\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for Kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\\n\\n- Optimize the memory by [reducing the size of some attributes](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\\n- Use open-source libraries such as [Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space\\n- Use [cudf](https://github.com/rapidsai/cudf)\\n- Convert data to [parquet](https://arrow.apache.org/docs/python/parquet.html) format\\n- Convert data to [feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03) format\\n\\n## Small datasets and external data\\n\\nBut, what can one do if the dataset is small? Let‚Äôs see some techniques to tackle this situation.\\n\\nOne way to increase the performance of any machine learning model is to use some external data frame that contains some variables that influence the predicate variable.\\n\\nLet‚Äôs see some of the external datasets.\\n\\n- Use of [squad](https://rajpurkar.github.io/SQuAD-explorer/) data for Question Answering tasks\\n- Other [datasets](http://nlpprogress.com/english/question_answering.html) for QA tasks\\n- Wikitext long term dependency language modeling [dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\\n- [Stackexchange data](https://archive.org/download/stackexchange)\\n- Prepare a dictionary of commonly misspelled words and corrected words.\\n- Use of [helper datasets](https://www.kaggle.com/kyakovlev/jigsaw-general-helper-public) for cleaning\\n- [Pseudo labeling](https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969/) is the process of adding confidently predicted test data to your training data\\n- Use different data [sampling methods](https://www.kaggle.com/shahules/tackling-class-imbalance)\\n- Text augmentation by [Exchanging words with synonym](https://arxiv.org/pdf/1502.01710.pdf) [s](https://arxiv.org/pdf/1502.01710.pdf)\\n- Text augmentation by [noising in RNN](https://arxiv.org/pdf/1703.02573.pdf)\\n- Text augmentation by [translation to other languages and back](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/48038)\\n\\n## Data exploration and gaining insights\\n\\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\\n\\n- Twitter data [exploration methods](https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda)\\n- Simple [EDA for tweets](https://www.kaggle.com/nz0722/simple-eda-text-preprocessing-jigsaw)\\n- [EDA](https://www.kaggle.com/tunguz/just-some-simple-eda) for Quora data\\n- [EDA](https://www.kaggle.com/kailex/r-eda-for-q-gru) in ¬†R for Quora data\\n- Complete [EDA](https://www.kaggle.com/codename007/start-from-here-quest-complete-eda-fe) with stack exchange data\\n- My previous article on [EDA for natural language processing](https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools)\\n\\n## Data cleaning\\n\\nData cleaning is one of the important and integral parts of any NLP problem. Text data always needs some preprocessing and cleaning before we can represent it in a suitable form.\\n\\n- Use this [notebook](https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing) to clean social media data\\n- [Data cleaning](https://www.kaggle.com/kyakovlev/preprocessing-bert-public) for BERT\\n- Use [textblob](https://textblob.readthedocs.io/en/dev/quickstart.html) to correct misspellings\\n- [Cleaning](https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing) for pre-trained embeddings\\n- [Language detection and translation](https://www.pythonprogramming.in/language-detection-and-translation-using-textblob.html) for multilingual tasks\\n- Preprocessing for Glove [part 1](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part1-eda) and [part 2](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part2-usage)\\n- [Increasing word coverage](https://www.kaggle.com/sunnymarkliu/more-text-cleaning-to-increase-word-coverage) to get more from pre-trained word embeddings\\n\\n## Text representations\\n\\nBefore we feed our text data to the Neural network or ML model, the text input needs to be represented in a suitable format. These representations determine the performance of the model to a large extent.\\n\\n- Pretrained [Glove](https://nlp.stanford.edu/projects/glove/) vectors\\n- Pretrained [fasttext](https://fasttext.cc/docs/en/english-vectors.html) vectors\\n- Pretrained [word2vec](https://radimrehurek.com/gensim/models/word2vec.html) vectors\\n- My previous article on these [3 embeddings](https://neptune.ai/blog/document-classification-small-datasets)\\n- Combining [pre-trained vectors](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778/). This can help in better representation of text and decreasing OOV words\\n- [Paragram](https://cogcomp.seas.upenn.edu/page/resource_view/106) embeddings\\n- [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/1)\\n- Use USE to generate [sentence-level features](https://www.kaggle.com/abhishek/distilbert-use-features-oof)\\n- 3 methods to [combine embeddings](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778)\\n\\nContextual embeddings models\\n\\n- [BERT](https://github.com/google-research/bert) Bidirectional Encoder Representations from Transformers\\n- [GPT](https://github.com/openai/finetune-transformer-lm)\\n- [Roberta](https://github.com/pytorch/fairseq/tree/master/examples/roberta) a Robustly Optimized BERT\\n- [Albert](https://github.com/google-research/ALBERT) a Lite BERT for Self-supervised Learning of Language Representations\\n- [Distilbert](https://github.com/huggingface/transformers/tree/master/examples/distillation) a lighter version of BERT\\n- [XLNET](https://github.com/zihangdai/xlnet/)\\n\\n## Modeling\\n\\n### Model architecture\\n\\nChoosing the right architecture is important to develop a proper machine learning model, sequence to sequence models like LSTMs, GRUs perform well in NLP problems and is always worth trying. Stacking 2 layers of LSTM/GRU networks is a common approach.\\n\\n- [Stacking Bidirectional CuDNNLSTM](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644/)\\n- [Stacking LSTM networks](https://www.kaggle.com/sakami/google-quest-single-lstm/)\\n- [LSTM and 5 fold Attention](https://www.kaggle.com/christofhenkel/keras-baseline-lstm-attention-5-fold/)\\n- [Bi...\", \"url\": \"https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions\"}, {\"title\": \"Text Classification Techniques - Explained - Kaggle\", \"text\": \"Text Classification Techniques - Explained | Kaggle\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n[\\nLearn more\\n](https://www.kaggle.com/cookies)\\nOK, Got it.\\n![Something went wrong and this page crashed!](https://www.kaggle.com/static/images/error/server-error-illo_light.svg)###### Something went wrong and this page crashed!\\nIf the issue persists, it's likely a problem on our side.\\n```\\nLoading CSS chunk 1019 failed.\\\\\\\\n(https://www.kaggle.com/static/assets/KernelViewer.21f94db0016b9074.css)\\nkeyboard\\\\_arrow\\\\_upcontent\\\\_copy\\nError: Loading CSS chunk 1019 failed.\\\\\\\\n(https://www.kaggle.com/static/assets/KernelViewer.21f94db0016b9074.css)\\nat t.onerror.t.onload (https://www.kaggle.com/static/assets/runtime.js?v=a6aef772a946d7d4:1:10006)\\n```\\nRefresh\", \"url\": \"https://www.kaggle.com/code/eraikako/text-classification-techniques-explained\"}, {\"title\": \"Advanced Techniques of Text Classification - Kaggle\", \"text\": \"Checking your browser - reCAPTCHA\\nChecking your browser before accessing www.kaggle.com ...\\nClick[here](#)if you are not automatically redirected after 5 seconds.\", \"url\": \"https://www.kaggle.com/code/meharshanali/advanced-techniques-of-text-classification\"}, {\"title\": \"A Beginners Guide to dealing with Text Data - Kaggle\", \"text\": \"<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)</p></div>ChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\nat b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=c93cac9cb620a9ebe94a:1:10973)</pre></div></div></div></div>\", \"url\": \"https://www.kaggle.com/code/prashant111/a-beginners-guide-to-dealing-with-text-data\"}, {\"title\": \"A Guide to any Classification Problem - Kaggle\", \"text\": \"<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)</p></div>ChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\nat b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=85e822d649bb8c5b8715:1:11062)</pre></div></div></div></div>\", \"url\": \"https://www.kaggle.com/code/durgancegaur/a-guide-to-any-classification-problem\"}, {\"title\": \"How to Categorize Large Amounts of Text Data | by Data@Urban\", \"text\": \"[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F71e1fd590e2a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&source=---two_column_layout_nav----------------------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Furban-institute.medium.com%2Fhow-to-categorize-large-amounts-of-text-data-71e1fd590e2a&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\\n\\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_topnav-----------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Furban-institute.medium.com%2Fhow-to-categorize-large-amounts-of-text-data-71e1fd590e2a&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\\n\\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\\n\\n_Original illustration courtesy of Majcot@Shutterstock_\\n\\n# How to Categorize Large Amounts of Text Data\\n\\n[![Data@Urban](https://miro.medium.com/v2/resize:fill:88:88/1*SmPWgbgKs_B3FJ242EIJJg.png)](https://urban-institute.medium.com/?source=post_page-----71e1fd590e2a--------------------------------)\\n\\n[Data@Urban](https://urban-institute.medium.com/?source=post_page-----71e1fd590e2a--------------------------------)\\n\\n¬∑\\n\\n[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fed38af6a2b4c&operation=register&redirect=https%3A%2F%2Furban-institute.medium.com%2Fhow-to-categorize-large-amounts-of-text-data-71e1fd590e2a&user=Data%40Urban&userId=ed38af6a2b4c&source=post_page-ed38af6a2b4c----71e1fd590e2a---------------------post_header-----------)\\n\\n10 min read\\n\\n¬∑\\n\\nFeb 20, 2019\\n\\n--\\n\\nListen\\n\\nShare\\n\\nIn the Urban Institute‚Äôs [Connecting Police to Communities project](https://www.urban.org/policy-centers/justice-policy-center/projects/connecting-police-communities), we‚Äôve been working to identify best practices for law enforcement use of social media by examining tweets from police and the public that document their interactions and behavior on Twitter. We collected millions of tweets containing the words ‚Äúcop‚Äù or ‚Äúpolice‚Äù to help us determine [public sentiment toward police](https://www.urban.org/research/publication/public-perceptions-police-social-media). We also collected more than 500,000 tweets from over 300 law enforcement agencies to determine [how police use social media](https://www.urban.org/research/publication/social-media-guidebook-law-enforcement-agencies).\\n\\nOnce we collected all the tweets, we needed to categorize them by either sentiment or topic. Traditionally, senior social science researchers would assign one or more research assistants the unenviable task of manually categorizing each tweet. At the scale of tweets we collected, we quickly realized that we needed a less manual, more technologically oriented solution. We simply didn‚Äôt have the time or resources for someone to read and categorize each tweet manually, so we decided to develop supervised machine learning models to perform the same task automatically. In this post, we explain how we developed a model to classify text data, along with some troubleshooting tips and the lessons we learned.\\n\\n# What Is Machine Learning?\\n\\nThe rise of online publications, reviews, and social media has created a trove of easily accessible text data for researchers and data scientists to use to study human behavior and social phenomena.\\n\\nFor researchers used to analyzing standardized tabular data, deriving meaning from unstructured and sometimes messy text is difficult. For example, movie studios looking for early audience feedback may want to categorize the topic of tweets or the sentiment of reviews, but manually reading and sorting them would take too long and would be prohibitively expensive. Instead, analysts typically use supervised machine learning techniques to classify each piece of text data in a fraction of the time.\\n\\nIn machine learning, systems learn from and detect patterns in data without being explicitly programmed by a researcher. Despite the programming process‚Äôs similarity to traditional regression models, machine learning practitioners typically use different language than social scientists ‚Äî the biggest distinction being the use of the word ‚Äúfeatures‚Äù to describe variables in a model.\\n\\nThere are generally two types of machine learning models ‚Äî unsupervised and supervised. In unsupervised machine learning, no outcome is identified, and the model clusters observations together based on patterns, similar to a factor analysis. In supervised machine learning, the researcher specifies the outcome and uses regression or classification algorithms to predict this outcome variable using the input features. For our text classification tasks, we developed two supervised machine learning models built for classification. One model classified the sentiment of public tweets toward police, and the other classified the topic of law enforcement tweets.\\n\\n# Developing a Text Classification Model\\n\\nText classification is a multistep process, and the steps included in your final process depend on the specific problem you are trying to solve. In other words, you may not get the best possible results by simply re-creating our features and models. This is because the performance of any given model depends on its ability to detect patterns in the input text, and different collections of text typically have different patterns. The following steps formed the basis for our text analysis and provide general guidelines for any text classification process.\\n\\n**Step 1: Develop features for the model.** In machine learning, features are the independent or explanatory variables used to predict the outcome variable. The features we created for analyzing Twitter data (and the features created for similar analyses) will typically fall into one of two categories: _content_ or _metadata_.\\n\\n_Content:_ Many features in the model will be based on the words in the text, but the text often needs some processing before the words can be converted into features. Analyzing text is typically a two-step procedure:\\n\\n1\\\\. Preprocess the text data. Preprocessing standardizes your text as much as possible so that the model can more easily recognize general patterns. For example, you may want to remove ‚Äústop words,‚Äù common words that may add unnecessary noise to the data and don‚Äôt have much meaning on their own ‚Äî for example, ‚Äúand,‚Äù ‚Äúin,‚Äù ‚Äúor,‚Äù and ‚Äúthe.‚Äù Similarly, you can stem or lemmatize words to convert them to their root form (e.g., ‚Äúwalks,‚Äù ‚Äúwalked,‚Äù and ‚Äúwalking‚Äù become ‚Äúwalk‚Äù) so that the model recognizes them as the same word. Other preprocessing steps include converting the text to lowercase letters and inserting placeholders for or removing punctuation, numbers, and symbols. Rather than removing numbers, replacing them with a placeholder was helpful for categorizing police tweets by topic, because the presence of numbers helped predict certain categories (e.g., when addresses were included in crime incident updates).\\n\\n2\\\\. Create a document-term matrix. In a document-term matrix, each row in the dataset represents the unit of text (e.g., a tweet or a review), and each column represents a word used in the collection of text data. The two tweets, ‚ÄúPolice training downtown tonight‚Äù and ‚ÄúPolice out here with tasers tonight‚Äù would lead to a document-term matrix that looks like this table:\\n\\n_Metadata:_ External information about the text often improves the model‚Äôs performance as much as the text itself. When working with Twitter data, it may be helpful to include information about the time of day or day of the week the tweet was posted or the number of retweets the post received. You can also extract information from the text using advanced text analytics tools like [CoreNLP](https://stanfordnlp.github.io/CoreNLP/...\", \"url\": \"https://urban-institute.medium.com/how-to-categorize-large-amounts-of-text-data-71e1fd590e2a\"}, {\"title\": \"How To Run Text Categorization: All Tips and Tricks from 5 Kaggle Competitions\", \"text\": \"How To Run Text Categorization: All Tips and Tricks from 5 Kaggle Competitions | HackerNoon\\nDiscover Anything**\\n[\\n![Hackernoon logo](https://hackernoon.imgix.net/hn-icon.png?auto=format&amp;fit=max&amp;w=128)\\nHackernoon](https://hackernoon.com/)\\nSignup[Write](https://app.hackernoon.com/new)\\n******\\n**139reads\\n# How To Run Text Categorization: All Tips and Tricks from 5 Kaggle Competitions\\nby\\n**neptune.ai Jakub Czakon**\\n[\\n![](https://cdn.hackernoon.com/images%2FL4OCiGu7n6cUBUyJKe9Rs0MX1d73-8x03wsi.jpeg?alt=media&amp;token=dc8a460d-ab44-4c8e-a72e-559d894a3fbc)\\nbyneptune.ai Jakub Czakon@neptuneAI\\\\_jakub](https://hackernoon.com/u/neptuneAI_jakub)\\nSenior data scientist building experiment tracking tools for ML projects at https://neptune.ai\\nSubscribe\\nAugust 23rd, 2020\\nTLDR**\\n![neptune.ai Jakub Czakon](https://cdn.hackernoon.com/images%2FL4OCiGu7n6cUBUyJKe9Rs0MX1d73-8x03wsi.jpeg?alt=media&amp;token=dc8a460d-ab44-4c8e-a72e-559d894a3fbc)\\nbyneptune.ai Jakub Czakon@neptuneAI\\\\_jakub\\n[\\n![](https://cdn.hackernoon.com/images%2FL4OCiGu7n6cUBUyJKe9Rs0MX1d73-8x03wsi.jpeg?alt=media&amp;token=dc8a460d-ab44-4c8e-a72e-559d894a3fbc)\\nbyneptune.ai Jakub Czakon@neptuneAI\\\\_jakub](https://hackernoon.com/u/neptuneAI_jakub)\\nSenior data scientist building experiment tracking tools for ML projects at https://neptune.ai\\nSubscribe\\n****\\n**********[**](<mailto:?subject=I'd like to share a link with you &amp;body=>)\\n[\\n![](https://cdn.hackernoon.com/images%2FL4OCiGu7n6cUBUyJKe9Rs0MX1d73-8x03wsi.jpeg?alt=media&amp;token=dc8a460d-ab44-4c8e-a72e-559d894a3fbc)\\nbyneptune.ai Jakub Czakon@neptuneAI\\\\_jakub](https://hackernoon.com/u/neptuneAI_jakub)\\nSenior data scientist building experiment tracking tools for ML projects at https://neptune.ai\\nSubscribe\\n****\\n**********[**](<mailto:?subject=I'd like to share a link with you &amp;body=>)\\n[\\n‚ÜêPrevious\\nHyperparameter Tuning on Any Python Script in 3 EasySteps [A How-To Guide]\\n](https://hackernoon.com/hyperparameter-tuning-on-any-python-script-in-3-easy-steps-a-how-to-guide-5u4g329e)\\n### About Author\\n[](https://hackernoon.com/u/neptuneAI_jakub)\\n[**neptune.ai Jakub Czakon**@neptuneAI\\\\_jakub](https://hackernoon.com/u/neptuneAI_jakub)\\nSenior data scientist building experiment tracking tools for ML projects at https://neptune.ai\\n[Read my stories](https://hackernoon.com/u/neptuneAI_jakub)[Learn More](https://hackernoon.com/about/neptuneAI_jakub)\\n#### Comments\\n#### TOPICS\\n[**machine-learning](https://hackernoon.com/c/machine-learning)[#machine-learning](https://hackernoon.com/tagged/machine-learning)[#binary-classification](https://hackernoon.com/tagged/binary-classification)[#data-science](https://hackernoon.com/tagged/data-science)[#kaggle](https://hackernoon.com/tagged/kaggle)[#tips-and-tricks](https://hackernoon.com/tagged/tips-and-tricks)[#ml](https://hackernoon.com/tagged/ml)[#kaggle-competition](https://hackernoon.com/tagged/kaggle-competition)[#tutorial](https://hackernoon.com/tagged/tutorial)\\n#### THIS ARTICLE WAS FEATURED IN\\n[\\n](https://sia.hackernoon.com/how-to-run-text-categorization-all-tips-and-tricks-from-5-kaggle-competitions-7e1h3uyh)[\\n**\\nArweave\\n](https://www.arweave.net/ithJ8kJytzNBq5ZLT_ZTN24PAqZ047UthexwscEqhQw)[\\nViewBlock\\n](https://viewblock.io/arweave/tx/ithJ8kJytzNBq5ZLT_ZTN24PAqZ047UthexwscEqhQw)[Terminal](https://terminal.hackernoon.com/how-to-run-text-categorization-all-tips-and-tricks-from-5-kaggle-competitions-7e1h3uyh?ref=hackernoon)[Lite](https://hackernoon.com/lite/how-to-run-text-categorization-all-tips-and-tricks-from-5-kaggle-competitions-7e1h3uyh?ref=hackernoon)[\\n![](https://t0.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;url=https://www.joyk.com/dig/detail/1707491664448324&amp;size=16)Joyk\\n](https://www.joyk.com/dig/detail/1707491664448324)[\\n![](https://t0.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;url=https://www.learnrepo.com/242-stories-to-learn-about-ml&amp;size=16)Learnrepo\\n](https://www.learnrepo.com/242-stories-to-learn-about-ml)[\\n![](https://t0.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;url=https://unni.io/domains/hackernoon.com/page/48760739&amp;size=16)Unni\\n](https://unni.io/domains/hackernoon.com/page/48760739)[\\n![](https://t0.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;url=https://learnrepo.hashnode.dev/833-stories-to-learn-about-tutorial&amp;size=16)Hashnode\\n](https://learnrepo.hashnode.dev/833-stories-to-learn-about-tutorial)[\\n![](https://t0.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;url=https://learnrepo.com/242-stories-to-learn-about-ml&amp;size=16)Learnrepo\\n](https://learnrepo.com/242-stories-to-learn-about-ml)[\\n![](https://t0.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;url=https://unni.io/domains/hackernoon.com/page/50536904&amp;size=16)Unni\\n](https://unni.io/domains/hackernoon.com/page/50536904)\\n#### Related Stories\\n[](https://hackernoon.com/a-completeish-guide-to-python-tools-you-can-use-to-analyse-text-data-13g53wgr)\\n[#MACHINE-LEARNING](https://hackernoon.com/tagged/machine-learning)\\n## [A Complete(ish) Guide to Python Tools You Can Use To Analyse Text Data](https://hackernoon.com/a-completeish-guide-to-python-tools-you-can-use-to-analyse-text-data-13g53wgr)\\n[neptune.ai Jakub Czakon](https://hackernoon.com/u/neptuneAI_jakub)\\nMar 23, 2020\\n[](https://hackernoon.com/beyond-recall-and-precision-rethinking-metrics-in-fraud-prevention)\\n[#METRICS](https://hackernoon.com/tagged/metrics)\\n## [Beyond Recall and Precision: Rethinking Metrics in Fraud Prevention](https://hackernoon.com/beyond-recall-and-precision-rethinking-metrics-in-fraud-prevention)\\n[Aleksei Toshchakov](https://hackernoon.com/u/toshchakov)\\nNov 11, 2023\\n[](https://hackernoon.com/binary-classification-understanding-activation-and-loss-functions-with-a-pytorch-example)\\n[#BINARY-CLASSIFICATION](https://hackernoon.com/tagged/binary-classification)\\n## [Binary Classification: Understanding Activation and Loss Functions with a PyTorch Example](https://hackernoon.com/binary-classification-understanding-activation-and-loss-functions-with-a-pytorch-example)\\n[Dmitrii Matveichev](https://hackernoon.com/u/owlgrey)\\nAug 15, 2023\\n[](https://hackernoon.com/confusion-matrix-in-machine-learning-everything-you-need-to-know)\\n[#MACHINE-LEARNING](https://hackernoon.com/tagged/machine-learning)\\n## [Confusion Matrix in Machine Learning: Everything You Need to Know](https://hackernoon.com/confusion-matrix-in-machine-learning-everything-you-need-to-know)\\n[Bala Priya C](https://hackernoon.com/u/balapriya)\\nFeb 03, 2022\\n[](https://hackernoon.com/model-calibration-in-machine-learning-an-important-but-inconspicuous-concept)\\n[#ARTIFICIAL-INTELLIGENCE](https://hackernoon.com/tagged/artificial-intelligence)\\n## [Model Calibration in Machine Learning: An Important but Inconspicuous Concept](https://hackernoon.com/model-calibration-in-machine-learning-an-important-but-inconspicuous-concept)\\n[Sanjay Kumar](https://hackernoon.com/u/sanjaykn170396)\\nJan 28, 2023\\n[](https://hackernoon.com/practical-tips-for-binary-classification-excellence-ape3w02)\\n[#MACHINE-LEARNING](https://hackernoon.com/tagged/machine-learning)\\n## [Practical Tips For Binary Classification Excellence](https://hackernoon.com/practical-tips-for-binary-classification-excellence-ape3w02)\\n[neptune.ai Patrycja Jenkner](https://hackernoon.com/u/neptuneAI_patrycja)\\nNov 09, 2020\\n[](https://hackernoon.com/a-completeish-guide-to-python-tools-you-can-use-to-analyse-text-data-13g53wgr)\\n[#MACHINE-LEARNING](https://hackernoon.com/tagged/machine-learning)\\n## [A Complete(ish) Guide to Python Tools You Can Use To Analyse Text Data](https://hackernoon.com/a-completeish-guide-to-python-tools-you-can-use-to-analyse-text-data-13g53wgr)\\n[neptune.ai Jakub Czakon](https://hackernoon.com/u/neptuneAI_jakub)\\nMar 23, 2020\\n[](https://hackernoon.com/beyond-recall-and-precision-rethinking-metrics-in-fraud-prevention)\\n[#METRICS](https://hackernoon.com/tagged/metrics)\\n## [Beyond Recall and Precision: Rethinking Metrics in Fraud Prevention](https://hackernoon.com/beyond-re...\", \"url\": \"https://hackernoon.com/how-to-run-text-categorization-all-tips-and-tricks-from-5-kaggle-competitions-7e1h3uyh\"}, {\"title\": \"A Journey Through Kaggle Text Data Competitions From 2021 to 2023\", \"text\": \"A Journey Through Kaggle Text Data Competitions From 2021 to 2023 | by Salomon Marquez | Medium\\n[Sitemap](https://medium.com/sitemap/sitemap.xml)\\n[Open in app](https://play.google.com/store/apps/details?id=com.medium.reader&amp;referrer=utm_source=mobileNavBar&amp;source=post_page---top_nav_layout_nav-----------------------------------------)\\nSign up\\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\\n[\\nWrite\\n](https://medium.com/m/signin?operation=register&amp;redirect=https://medium.com/new-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\\n[\\nSearch\\n](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\\nSign up\\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\\n# A Journey Through Kaggle Text Data Competitions From 2021 to 2023\\n[\\n![Salomon Marquez](https://miro.medium.com/v2/da:true/resize:fill:64:64/0*hbSxb57OAqPdRqks)\\n](https://medium.com/@sblaizer?source=post_page---byline--631a79f96312---------------------------------------)\\n[Salomon Marquez](https://medium.com/@sblaizer?source=post_page---byline--631a79f96312---------------------------------------)\\n18 min read\\n¬∑Apr 28, 2024\\n[\\n](https://medium.com/m/signin?actionUrl=https://medium.com/_/vote/p/631a79f96312&amp;operation=register&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;user=Salomon+Marquez&amp;userId=1a60dea97a2c&amp;source=---header_actions--631a79f96312---------------------clap_footer------------------)\\n--\\n[](https://medium.com/m/signin?actionUrl=https://medium.com/_/bookmark/p/631a79f96312&amp;operation=register&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;source=---header_actions--631a79f96312---------------------bookmark_footer------------------)\\nListen\\nShare\\n*Authors:*[*Liliana Badillo*](https://www.kaggle.com/sophieb)*and*[*Salomon Marquez*](https://www.kaggle.com/sblaizer)\\n**> Note:\\n**> I created this Medium post to provide more visibility to our original report. Please refer to our [> A Journey Throuhgh Text Data Competitions\\n](https://www.kaggle.com/code/sophieb/a-journey-through-text-data-competitions)> notebook for further details.\\nN**atural Language Processing (NLP)**, the branch of artificial intelligence that enables computers to understand human language, has witnessed remarkable growth and transformative advancements in recent years. This surge has been driven by the increasing availability of vast amounts of text data and the rapid development of sophisticated machine-learning techniques.\\n*> ‚ÄúIt is estimated that 90% of the world‚Äôs data was generated in the last two years alone‚Äù\\n*> by [> Amount of Data Created Daily (2023)\\n](https://explodingtopics.com/blog/data-generated-per-day)\\n[**Kaggle**](https://www.kaggle.com/)is an online platform that hosts machine learning and data science competitions. Among these competitions, text data competitions specifically focus on tasks related to NLP and text analysis. Participants are provided with text datasets and are tasked with developing models and algorithms to solve language-related challenges such as sentiment analysis, text classification, and machine translation. These competitions are instrumental in advancing NLP techniques and provide participants with valuable experience and knowledge exchange opportunities.\\nAccessing and learning about the latest techniques employed in text data Kaggle competitions can be challenging due to their dispersion within discussions and winning solution write-ups.**Valuable information about these cutting-edge approaches tends to get buried, making it difficult to stay updated on the evolving landscape of text data techniques.**\\nIn this essay, our objective is to offer valuable insights into key lessons learned by the Kaggle community during their engagement in text data competitions spanning from 2021 to 2023. We will focus on**four pivotal topics**that have emerged as the foundation for successful solutions in recent years:**model architectures**,**pseudo labeling**,**adversarial weight perturbation**, and**mask language modeling**. By examining these four key areas, we aim to provide a comprehensive understanding of the essential elements driving winning strategies in text data competitions.\\n## Methodology\\nTo gain a better understanding of the text data landscape, we carried out the following tasks:\\n* **Analyze 27 write-ups from nine Kaggle competitions specifically related to text data**. We dove deeper into the top three solutions for text data competitions held from 2021 to 2023, see**Figure 1**. Also, we explore a range of topics, including the prevalent techniques and methodologies employed, the most effective model architectures utilized, and the challenges encountered and overcame. This analysis enabled us to gain deeper insights into the problem-solving approaches and thought processes employed by Kagglers in developing their successful solutions.\\n* **Perform a general but not exhaustive analysis of the**[**arXiv dataset**](https://www.kaggle.com/datasets/Cornell-University/arxiv). We filter out categories with the potential to include NLP papers published within the past two years. By leveraging a predefined list of keywords associated with text data, we directed our efforts towards uncovering the specific problem domains and top leading model architectures [1][2] that have garnered attention within the research community.\\nPress enter or click to view image in full size\\n![]()\\n**Figure 1.**Kaggle text data competitions held from 2021 to 2023\\n## Key Discoveries of Text Data Competitions\\nThe result of the analysis of the 27 write-ups and their most notable comments can be seen in[Table I of Appendix A](https://www.kaggle.com/code/sophieb/a-journey-through-text-data-competitions#Appendix-A)and[Table II of Appendix B](https://www.kaggle.com/code/sophieb/a-journey-through-text-data-competitions#Appendix-B), respectively.**Table I**provides information about the top three winning solutions in each Kaggle competition related to text, highlighting aspects such as model architectures, parameters like PB and LB, optimizers, ensembles, and the most innovative proposed ideas, among others. On the other hand,**Table II**presents a summary of comments from the write-ups in a question-like format. Additionally, the analysis of the arXiv dataset has allowed us to unveil, on a larger scale, how the use of certain model architectures and their application to specific text domains compares to the solutions presented in text-oriented Kaggle competitions over the past two years. For more details, please refer to[EDA Kaggle and Arxiv datasets](https://www.kaggle.com/code/sophieb/eda-kaggle-and-arxiv-datasets)notebook.\\nAs**Figure 2**shows, out of the nine competitions, five focused on text classification tasks, two aimed at information extraction tasks, while the remaining targeted text matching and question-and-answer tasks. Interestingly,**Figure 3**shows that with the frequency of the term ‚Äúquestion answering‚Äù exceeding 400 times, it can be inferred that the scientific community has placed greater importance on domains related to this field. While Kaggle competitions have only hosted one question-and-answer competition, there seems ...\", \"url\": \"https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312\"}]}",
        "tool.duration_ms": 5110.719442367554
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "4ba834c775b6de06",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "WebSearchTool",
      "kind": "INTERNAL",
      "start_time": 1767959018528553832,
      "end_time": 1767959022424758586,
      "duration": 3.896204754,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "WebSearchTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"How do Kaggle winners handle class imbalance in binary classification competitions with 3:1 ratio?\"}}",
        "tool.output": "{\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nKaggle winners typically tame a 3‚ÄØ:‚ÄØ1 binary‚Äëclass imbalance with a short, repeatable workflow that combines data‚Äëlevel tricks and model‚Äëlevel adjustments‚ÄØ‚Äî‚ÄØall backed by the same practices discussed in Kaggle‚Äôs own discussions and competition post‚Äëmortems‚ÄØ([Unbalanced data and cross‚Äëvalidation](https://www.kaggle.com/discussions/questions-and-answers/27589); [Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions](https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions)):\\n\\n1. **Create stratified folds** so each training/validation split preserves the 3‚ÄØ:‚ÄØ1 ratio, preventing the model from seeing a skewed distribution during CV.  \\n\\n2. **Apply a sampling strategy** to the training data:  \\n   - *Oversample* the minority class (e.g., SMOTE or simple random replication) or  \\n   - *Undersample* the majority class to a more balanced mix. The `imbalanced‚Äëlearn` library is a common starting point‚ÄØ([Unbalanced data and cross‚Äëvalidation](https://www.kaggle.com/discussions/questions-and-answers/27589)).  \\n\\n3. **Add class‚Äëweighting to the loss** (e.g., `class_weight='balanced'` in scikit‚Äëlearn, or custom weights in LightGBM/CatBoost). This tells the optimizer to penalize mistakes on the minority class more heavily without altering the raw data.  \\n\\n4. **Choose an evaluation metric that reflects imbalance**, such as AUC‚ÄëPR, weighted log‚Äëloss, or F1‚Äëscore, rather than plain accuracy. Align the metric with the competition‚Äôs leaderboard and with the business cost of false positives vs. false negatives‚ÄØ([Unbalanced data and cross‚Äëvalidation](https://www.kaggle.com/discussions/questions-and-answers/27589)).  \\n\\n5. **Tune the decision threshold** after training: scan thresholds on the validation set and pick the one that maximizes the chosen metric (often improves the leaderboard score for imbalanced problems).  \\n\\n6. **Ensemble diverse models** (e.g., tree‚Äëbased + neural nets) that were each trained with the above imbalance handling; averaging predictions tends to smooth out residual bias toward the majority class‚ÄØ([Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions](https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions)).  \\n\\n7. **Validate on a hold‚Äëout set that mirrors the test distribution** (if possible) to ensure the sampling and weighting choices generalize, then submit the final ensemble.  \\n\\nFollowing these steps lets top Kagglers turn a modest 3‚ÄØ:‚ÄØ1 skew into a well‚Äëbalanced learning problem and achieve competitive scores.\\n\\n--- Result 2 ---\\nTitle: Unbalanced data and cross-validation | Kaggle\\nURL: https://www.kaggle.com/discussions/questions-and-answers/27589\\n\\nContent:\\n<div><div><p>There are two general ways of dealing with imbalanced data: 1) change the data; 2) leave the data alone but change the performance metric and/or the weight of individual data points.</p>\\n<p>Changing the data means oversampling the under-represented class(es) with synthetic data points, or undersampling (thinning down) the over-represented class(es). There are various ways of doing both operations, and I will give you one <a href=\\\"https://github.com/scikit-learn-contrib/imbalanced-learn\\\"><strong>starting point</strong></a>.</p>\\n<p>A second option is to leave the data alone and adjust how we do the training. It is crucial to pick a reliable performance metric for imbalanced data, and to know whether for your purposes it is worse to have too many false positives (FPs) or false negatives (FNs). Ideally, you wouldn't want to have either of the two, but for most applications it should be clear whether we want to avoid FPs or FNs with greater preference.</p>\\n<p>To give you an example: you have 900 healthy patients (class 0) and 100 cancer patients (class 1), which is at least somewhat close to the true ratio of healthy and cancer-stricken people out there. If you predict class 0 with 100% accuracy and class 1 with 70% accuracy, your accuracy will be 97% for the whole dataset. That sounds tremendous until we realize that 30 out of 100 cancer patients (30%) will go undiagnosed, meaning that high false negative rate in this case will cost many lives. What if we could adjust our classification so that both classes are predicted with 97% accuracy? This would mean that 27 healthy people would be predicted to have cancer (27 FPs) and 3 cancer-stricken individual would be predicted to be healthy (3 FNs). Now, I wouldn't want to be a doctor who tells a healthy person that they have a cancer because many people have been known to do silly things when they think they are dying. Still, compared to our starting premise, most would agree that on balance it is much better to have 27 people who think they have cancer and later find out they don't, and only 3 patients who were told they are healthy even though they have cancer. The problem is that a simple accuracy as a performance metric for training would never get you to a balanced 97% accuracy. For imbalanced datasets, F1-score (a weighted average of precision and recall), area under curve for ROC and Matthews correlation coefficient may be better measures of classifier quality.</p>\\n<p>See the links below for more info:</p>\\n<p><a href=\\\"http://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/\\\"><strong>link1</strong></a></p>\\n<p><a href=\\\"https://eva.fing.edu.uy/mod/resource/view.php?id=33977\\\"><strong>link2</strong></a></p>\\n<p><a href=\\\"https://www.kaggle.com/c/bosch-production-line-performance/forums/t/24120/time-effort-and-reward?forumMessageId=138285#post138285\\\"><strong>link3</strong></a></p></div></div>\\n\\n--- Result 3 ---\\nTitle: Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\\nURL: https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions\\n\\nContent:\\nTabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions[\\n**üì£ BIG NEWS:****Neptune is joining OpenAI!**‚Üí Read the message from our CEO üì£![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\\nWhat do you want to find?\\nSearch\\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Neptune Blog](https://neptune.ai/blog)# Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Shahul-Es-new-scaled.jpeg?fit=2560%2C1920&ssl=1)\\n[Shahul ES](https://neptune.ai/blog/author/shahules)\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)3 min\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)1st September, 2023\\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)[Tabular Data](https://neptune.ai/blog/category/tabular-data)\\nIn this article, I will discuss some great tips and tricks to improve the performance of your structured data binary classification model. These tricks are obtained from solutions of some of Kaggle‚Äôs top tabular data competitions. Without much lag, let‚Äôs begin.\\nThese are the five competitions that I have gone through to create this article:\\n* [**Home credit default risk**](https://www.kaggle.com/c/home-credit-default-risk/)\\n* [**Santander Customer Transaction Prediction**](https://www.kaggle.com/c/santander-customer-transaction-prediction/notebooks)\\n* [**VSB Power Line Fault Detection**](https://www.kaggle.com/c/vsb-power-line-fault-detection/overview/evaluation)\\n* [**Microsoft Malware Prediction**](https://www.kaggle.com/c/microsoft-malware-prediction/overview)\\n* [**IEEE-CIS Fraud Detection**](https://www.kaggle.com/c/ieee-fraud-detection/overview/evaluation/)## Dealing with larger datasets\\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\\n* Faster[data loading with pandas.](https://www.kaggle.com/c/home-credit-default-risk/discussion/59575)\\n* Data compression techniques to[reduce the size of data by 70%](https://www.kaggle.com/nickycan/compress-70-of-dataset).\\n* Optimize the memory by r[educing the size of some attributes.](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\\n* Use open-source libraries such as[Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space.\\n* Use[cudf](https://github.com/rapidsai/cudf).\\n* Convert data to[parquet](https://arrow.apache.org/docs/python/parquet.html)format.\\n* Converting data to[feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03)format.\\n* Reducing memory usage for[optimizing RAM](https://www.kaggle.com/mjbahmani/reducing-memory-size-for-ieee).## Data exploration\\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\\n* EDA for microsoft[malware detection.](https://www.kaggle.com/youhanlee/my-eda-i-want-to-see-all)\\n* Time Series[EDA for malware detection.](https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68)\\n* Complete[EDA for home credit loan prediction](https://www.kaggle.com/codename007/home-credit-complete-eda-feature-importance).\\n* Complete[EDA for Santader prediction.](https://www.kaggle.com/gpreda/santander-eda-and-prediction)\\n* EDA for[VSB Power Line Fault Detection.](https://www.kaggle.com/go1dfish/basic-eda)## Data preparation\\nAfter data exploration, the first thing to do is to use those insights to prepare the data. To tackle issues like class imbalance, encoding categorical data, etc. Let‚Äôs see the methods used to do it.\\n* Methods to t[ackle class imbalance](https://www.kaggle.com/shahules/tackling-class-imbalance).\\n* Data augmentation by[Synthetic Minority Oversampling Technique](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/).\\n* Fast inplace[shuffle for augmentation](https://www.kaggle.com/jiweiliu/fast-inplace-shuffle-for-augmentation).\\n* Finding[synthetic samples in the dataset.](https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split)\\n* [Signal denoising](https://www.kaggle.com/jackvial/dwt-signal-denoising)used in signal processing competitions.\\n* Finding[patterns of missing data](https://www.kaggle.com/jpmiller/patterns-of-missing-data).\\n* Methods to handle[missing data](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779).\\n* An overview of various[encoding techniques for categorical data.](https://www.kaggle.com/shahules/an-overview-of-encoding-techniques)\\n* Building[model to predict missing values.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64598)\\n* Random[shuffling of data](https://www.kaggle.com/brandenkmurray/randomly-shuffled-data-also-works)to create new synthetic training set.## Feature engineering\\nNext, you can check the most popular feature and feature engineering techniques used in these top kaggle competitions. The feature engineering part varies from problem to problem depending on the domain.\\n* Target[encoding cross validation](https://medium.com/@pouryaayria/k-fold-target-encoding-dfe9a594874b/)for better encoding.\\n* Entity embedding to[handle categories](https://www.kaggle.com/abhishek/entity-embeddings-to-handle-categories).\\n* Encoding c[yclic features for deep learning.](https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning)\\n* Manual[feature engineering methods](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering).\\n* Automated feature engineering techniques[using featuretools](https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics).\\n* Top hard crafted features used in[microsoft malware detection](https://www.kaggle.com/sanderf/7th-place-solution-microsoft-malware-prediction).\\n* Denoising NN for[feature extraction](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798).\\n* Feature engineering[using RAPIDS framework.](https://www.kaggle.com/cdeotte/rapids-feature-engineering-fraud-0-96/)\\n* Things to remember while processing f[eatures using LGBM.](https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575)\\n* [Lag features and moving averages.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64593)\\n* [Principal component analysis](https://medium.com/machine-learning-researcher/dimensionality-reduction-pca-and-lda-6be91734f567)for...\\n\\n--- Result 4 ---\\nTitle: Methods for Dealing with Imbalanced Data\\nURL: https://www.kaggle.com/code/tboyle10/methods-for-dealing-with-imbalanced-data\\n\\nContent:\\n- _code_\\n\\nNew Notebook\\n\\n- _table\\\\_chart_\\n\\nNew Dataset\\n\\n- _tenancy_\\n\\nNew Model\\n\\n- _emoji\\\\_events_\\n\\nNew Competition\\n\\n- _corporate\\\\_fare_\\n\\nNew Organization\\n\\n\\n## No Active Events\\n\\nCreate notebooks and keep track of their status here.\\n\\n[_add_ New Notebook](https://www.kaggle.com/code/new)\\n\\n- _auto\\\\_awesome\\\\_motion_\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0 Active Events\\n\\n\\n\\n\\n\\n\\n_expand\\\\_more_\\n\\n\\nmenu\\n\\n[Skip to\\\\\\n\\\\\\ncontent](https://www.kaggle.com/code/tboyle10/methods-for-dealing-with-imbalanced-data#site-content)\\n\\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\\n\\nCreate\\n\\n_search_\\n\\n- [_explore_\\\\\\n\\\\\\nHome](https://www.kaggle.com/)\\n\\n- [_emoji\\\\_events_\\\\\\n\\\\\\nCompetitions](https://www.kaggle.com/competitions)\\n\\n- [_table\\\\_chart_\\\\\\n\\\\\\nDatasets](https://www.kaggle.com/datasets)\\n\\n- [_tenancy_\\\\\\n\\\\\\nModels](https://www.kaggle.com/models)\\n\\n- [_code_\\\\\\n\\\\\\nCode](https://www.kaggle.com/code)\\n\\n- [_comment_\\\\\\n\\\\\\nDiscussions](https://www.kaggle.com/discussions)\\n\\n- [_school_\\\\\\n\\\\\\nLearn](https://www.kaggle.com/learn)\\n\\n- [_expand\\\\_more_\\\\\\n\\\\\\nMore](https://www.kaggle.com/code/tboyle10/methods-for-dealing-with-imbalanced-data)\\n\\n\\n_auto\\\\_awesome\\\\_motion_\\n\\nView Active Events\\n\\nmenu\\n\\n[Skip to\\\\\\n\\\\\\ncontent](https://www.kaggle.com/code/tboyle10/methods-for-dealing-with-imbalanced-data#site-content)\\n\\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\\n\\n_search_\\n\\n[Sign In](https://www.kaggle.com/account/login?phase=startSignInTab&returnUrl=%2Fcode%2Ftboyle10%2Fmethods-for-dealing-with-imbalanced-data)\\n\\n[Register](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2Fcode%2Ftboyle10%2Fmethods-for-dealing-with-imbalanced-data)\\n\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n\\n[Learn more.](https://www.kaggle.com/cookies)\\n\\nOK, Got it.\\n\\n![Something went wrong and this page crashed!](https://www.kaggle.com/static/images/error/server-error-illo_light.svg)\\n\\n###### Something went wrong and this page crashed!\\n\\nIf the issue persists, it's likely a problem on our side.\\n\\n```\\n\\nLoading CSS chunk 5073 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 5073 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\n    at t.onerror.t.onload (https://www.kaggle.com/static/assets/runtime.js?v=e39bd89f6741bf1e27b2:1:8254)\\n```\\n\\nRefresh\\n\\n--- Result 5 ---\\nTitle: üëë Imbalance ratio: How to identify an imbalanced dataset? | Kaggle\\nURL: https://www.kaggle.com/discussions/questions-and-answers/372288\\n\\nContent:\\nmenu\\n\\n[Skip to\\\\\\n\\\\\\ncontent](https://www.kaggle.com/discussions/questions-and-answers/372288#site-content)\\n\\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\\n\\nCreate\\n\\nsearch‚Äã\\n\\n- [explore\\\\\\n\\\\\\nHome](https://www.kaggle.com/)\\n\\n- [emoji\\\\_events\\\\\\n\\\\\\nCompetitions](https://www.kaggle.com/competitions)\\n\\n- [table\\\\_chart\\\\\\n\\\\\\nDatasets](https://www.kaggle.com/datasets)\\n\\n- [tenancy\\\\\\n\\\\\\nModels](https://www.kaggle.com/models)\\n\\n- [code\\\\\\n\\\\\\nCode](https://www.kaggle.com/code)\\n\\n- [comment\\\\\\n\\\\\\nDiscussions](https://www.kaggle.com/discussions)\\n\\n- [school\\\\\\n\\\\\\nLearn](https://www.kaggle.com/learn)\\n\\n\\n- [expand\\\\_more\\\\\\n\\\\\\nMore](https://www.kaggle.com/discussions/questions-and-answers/372288)\\n\\n\\nauto\\\\_awesome\\\\_motion\\n\\nView Active Events\\n\\nmenu\\n\\n[Skip to\\\\\\n\\\\\\ncontent](https://www.kaggle.com/discussions/questions-and-answers/372288#site-content)\\n\\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\\n\\nsearch‚Äã\\n\\n[Sign In](https://www.kaggle.com/account/login?phase=startSignInTab&returnUrl=%2Fdiscussions%2Fquestions-and-answers%2F372288)\\n\\n[Register](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2Fdiscussions%2Fquestions-and-answers%2F372288)\\n\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n\\n[Learn more](https://www.kaggle.com/cookies)\\n\\nOK, Got it.\\n\\n[Eli≈°ka Bl√°hov√°](https://www.kaggle.com/elisthefox) ¬∑ Posted 2 years ago in [Questions & Answers](https://www.kaggle.com/discussions/questions-and-answers)\\n\\narrow\\\\_drop\\\\_up3\\n\\n![This post earned a bronze medal](https://www.kaggle.com/static/images/medals/discussion/bronzel@1x.png)more\\\\_vert\\n\\n# üëë Imbalance ratio: How to identify an imbalanced dataset?\\n\\nDear community,\\n\\nI have a question for you to which I can't find a common answer. I wonder how to be able to classify a dataset as imbalanced? Is there some rule of thumb I can use? I have found this article, where it says that highly imbalanced dataset has ratio of 10-1 [https://www.sciencedirect.com/topics/computer-science/imbalance-ratio](https://www.sciencedirect.com/topics/computer-science/imbalance-ratio).\\n\\nI would love to hear your opinion.\\n\\nThanks a lot!\\n\\n[Exploratory Data Analysis](https://www.kaggle.com/discussions?tags=13201-Exploratory+Data+Analysis) [Data Analytics](https://www.kaggle.com/discussions?tags=13215-Data+Analytics) [Data Cleaning](https://www.kaggle.com/discussions?tags=13202-Data+Cleaning)\\n\\nPlease [sign in](https://www.kaggle.com/account/login) to reply to this topic.\\n\\ncomment\\n\\n## 8 Comments\\n\\nHotness\\n\\n[**Senapati Rajesh**](https://www.kaggle.com/senapatirajesh)\\n\\nPosted 2 years ago\\n\\n![This post earned a bronze medal](https://www.kaggle.com/static/images/medals/discussion/bronzel@1x.png)\\n\\narrow\\\\_drop\\\\_up1\\n\\nmore\\\\_vert\\n\\nThank you very much all for the comments and here is my version of answer\\n\\nImbalanced dataset is relevant primarily in the context of supervised machine learning involving two or more classes.\\n\\nImbalance means that the number of data points available for different the classes is different:\\n\\nIf there are two classes, then balanced data would mean 50% points for each of the class. For most machine learning techniques, little imbalance is not a problem. So, if there are 60% points for one class and 40% for the other class, it should not cause any significant performance degradation. Only when the class imbalance is high, e.g. 90% points for one class and 10% for the other, standard optimization criteria or performance measures may not be as effective and would need modification.\\n\\nA typical example of imbalanced data is encountered in e-mail classification problem where emails are classified into ham or spam. The number of spam emails is usually lower than the number of relevant (ham) emails. So, using the original distribution of two classes leads to imbalanced dataset.\\n\\nUsing accuracy as a performace measure for highly imbalanced datasets is not a good idea. For example, if 90% points belong to the true class in a binary classification problem, a default prediction of true for all data points leads to a classifier which is 90% accurate, even though the classifier has not learnt anything about the classification problem at hand!\\n\\nImbalanced data can be handled by using below techniques:\\n\\n1.Resample the training set\\n\\n(Under sampling -This method is used when quantity of data is sufficient or\\n\\nover sampling-It tries to balance dataset by increasing the size of rare samples.)\\n\\n2.Use K-fold Cross-Validation in the Right Way\\n\\n3.Ensemble Different Resampled Datasets(This approach is simple and perfectly horizontally scalable if you have a lot of data)\\n\\n4.Resample with Different Ratios( Instead of training all models with the same ratio in the ensemble, it is worth trying to ensemble different ratios)\\n\\n5.Most importantly Choose Proper Evaluation Metric(\\n\\nex:The accuracy of a classifier is the total number of correct predictions by the classifier divided by the total number of predictions.For an imbalanced class dataset F1 score is a more appropriate metric. It is the harmonic mean of precision and recall)\\n\\n6.SMOTE is another technique to oversample the minority class.SMOTE looks into minority class instances and use k nearest neighbor to select a random nearest neighbor, and a synthetic instance is created randomly in feature space.\\n\\nThank u and Pl feel free to suggest for any modifications.\\n\\n[**Olqa\\\\_842**](https://www.kaggle.com/zvr842)\\n\\nPosted 2 years ago\\n\\n![This post earned a bronze medal](https://www.kaggle.com/static/images/medals/discussion/bronzel@1x.png)\\n\\narrow\\\\_drop\\\\_up1\\n\\nmore\\\\_vert\\n\\nPlease, could you share dataset too?\\n\\n[**Eli≈°ka Bl√°hov√°**](https://www.kaggle.com/elisthefox)\\n\\nTopic Author\\n\\nPosted 2 years ago\\n\\narrow\\\\_drop\\\\_up0\\n\\nmore\\\\_vert\\n\\nOf course, currently, I am working with this dataset: [https://www.kaggle.com/datasets/shubh0799/churn-modelling](https://www.kaggle.com/datasets/shubh0799/churn-modelling). Link to my notebook: [https://www.kaggle.com/code/elisthefox/churn-analytics-should-i-stay-or-should-i-go](https://www.kaggle.com/code/elisthefox/churn-analytics-should-i-stay-or-should-i-go)\\n\\n[**Carl McBride Ellis**](https://www.kaggle.com/carlmcbrideellis)\\n\\nPosted 2 years ago\\n\\n![This post earned a bronze medal](https://www.kaggle.com/static/images/medals/discussion/bronzel@1x.png)\\n\\narrow\\\\_drop\\\\_up2\\n\\nmore\\\\_vert\\n\\nDear [@elisthefox](https://www.kaggle.com/elisthefox)\\n\\nYou may perhaps find this short notebook of some interest: [Classification: How imbalanced is \\\"imbalanced\\\"?\\\"](https://www.kaggle.com/code/carlmcbrideellis/classification-how-imbalanced-is-imbalanced).\\n\\nAll the best,\\n\\ncarl\\n\\n[**Eli≈°ka Bl√°hov√°**](https://www.kaggle.com/elisthefox)\\n\\nTopic Author\\n\\nPosted 2 years ago\\n\\n![This post earned a bronze medal](https://www.kaggle.com/static/images/medals/discussion/bronzel@1x.png)\\n\\narrow\\\\_drop\\\\_up1\\n\\nmore\\\\_vert\\n\\nThanks a lot for letting me know about this great notebook, If I understood correctly, the metric balanced accuracy helps to determine the ratio for imbalanced dataset, hence if its results are equal to 0.85, then dataset consisting of 10K rows with 8500 rows with target variable 1 and 1500 rows with target variable 0 is considered as a balanced target variable?\\n\\n[**Carl McBride Ellis**](https://www.kaggle.com/carlmcbrideellis)\\n\\nPosted 2 years ago\\n\\n![This post earned a bronze medal](https://www.kaggle.com/static/images/medals/discussion/bronzel@1x.png)\\n\\narrow\\\\_drop\\\\_up2\\n\\nmore\\\\_vert\\n\\nDear [@elisthefox](https://www.kaggle.com/elisthefox)\\n\\nStrictly speaking a dataset is balanced if there are an equal number of rows associated with each class (or label) in the training data. One can perform a quick check with something like:\\n\\n```\\ndf['labels'].value_counts().to_frame().T\\n\\ncontent_copy\\n```\\n\\nIn the notebook I suggest that most metrics work well up to an imbalance of 85:15 after which one should exercise caution. Note however as far as most estimators are concerned, they work pretty well irrespective of whether ...\\n\\n--- Result 6 ---\\nTitle: Dealing with extremely imbalanced dataset - binary classification | Kaggle\\nURL: https://www.kaggle.com/discussions/questions-and-answers/473546\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 4787 failed.\\n(error: https://www.kaggle.com/static/assets/4787.f5129f48620a03126642.css)</p></div>ChunkLoadError: Loading CSS chunk 4787 failed.\\n(error: https://www.kaggle.com/static/assets/4787.f5129f48620a03126642.css)\\nat f.onerror.f.onload (https://www.kaggle.com/static/assets/runtime.js?v=42762aa12f6df4b246e8:1:11101)</pre></div></div></div></div>\\n\\n--- Result 7 ---\\nTitle: Best techniques and metrics for Imbalanced Dataset\\nURL: https://www.kaggle.com/code/marcinrutecki/best-techniques-and-metrics-for-imbalanced-dataset\\n\\nContent:\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n\\n[Learn more](https://www.kaggle.com/cookies)\\n\\nOK, Got it.\\n\\n###### Something went wrong and this page crashed!\\n\\nIf the issue persists, it's likely a problem on our side.\\n\\n```\\n\\nLoading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\n    at r.onerror.r.onload (https://www.kaggle.com/static/assets/runtime.js?v=805aeed0a20bb825939e:1:11032)\\n```\\n\\nRefresh\\n\\n--- Result 8 ---\\nTitle: Classification on imbalanced data \\n\\n    \\n    \\n       \\n    \\n\\n     \\n      \\n      Stay organized with collections\\n     \\n     \\n      \\n      Save and categorize content based on your preferences.\\nURL: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\\n\\nContent:\\nClassification on imbalanced data | TensorFlow Core[Skip to main content](#main-content)\\n[![TensorFlow](https://www.gstatic.com/devrel-devsite/prod/ve08add287a6b4bdf8961ab8a1be50bf551be3816cdd70b7cc934114ff3ad5f10/tensorflow/images/lockup.svg)](https://www.tensorflow.org/)\\n* /\\n* English\\n* Espa√±ol ‚ÄìAm√©rica Latina\\n* Fran√ßais\\n* Indonesia\\n* Italiano\\n* Polski\\n* Portugu√™s ‚ÄìBrasil\\n* Ti√™ÃÅng Vi√™Ã£t\\n* T√ºrk√ße\\n* –†—É—Å—Å–∫–∏–π* ◊¢◊ë◊®◊ô◊™* ÿßŸÑÿπÿ±ÿ®ŸäŸëÿ©* ŸÅÿßÿ±ÿ≥€å* ‡§π‡§ø‡§Ç‡§¶‡•Ä* ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ* ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢* ‰∏≠Êñá‚ÄìÁÆÄ‰Ωì* Êó•Êú¨Ë™û* ÌïúÍµ≠Ïñ¥[GitHub](https://github.com/tensorflow)Sign in\\n* [TensorFlow Core](https://www.tensorflow.org/tutorials)\\n* [TensorFlow](https://www.tensorflow.org/)\\n* [Learn](https://www.tensorflow.org/learn)\\n* [TensorFlow Core](https://www.tensorflow.org/tutorials)\\n# Classification on imbalanced dataStay organized with collectionsSave and categorize content based on your preferences.\\n[![](https://www.tensorflow.org/images/tf_logo_32px.png)View on TensorFlow.org](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data)|[![](https://www.tensorflow.org/images/colab_logo_32px.png)Run in Google Colab](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb)|[![](https://www.tensorflow.org/images/GitHub-Mark-32px.png)View source on GitHub](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb)|[![](https://www.tensorflow.org/images/download_logo_32px.png)Download notebook](https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/imbalanced_data.ipynb)|\\nThis tutorial demonstrates how to classify a highly imbalanced dataset in which the number of examples in one class greatly outnumbers the examples in another. You will work with the[Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)dataset hosted on Kaggle. The aim is to detect a mere 492 fraudulent transactions from 284,807 transactions in total. You will use[Keras](https://www.tensorflow.org/guide/keras/overview)to define the model and[class weights](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model)to help the model learn from the imbalanced data. .\\nThis tutorial contains complete code to:\\n* Load a CSV file using Pandas.\\n* Create train, validation, and test sets.\\n* Define and train a model using Keras (including setting class weights).\\n* Evaluate the model using various metrics (including precision and recall).\\n* Select a threshold for a probabilistic classifier to get a deterministic classifier.\\n* Try and compare with class weighted modelling and oversampling.## Setup\\n```\\n`importtensorflowastffromtensorflowimportkerasimportosimporttempfileimportmatplotlibasmplimportmatplotlib.pyplotaspltimportnumpyasnpimportpandasaspdimportseabornassnsimportsklearnfromsklearn.metricsimportconfusion\\\\_matrixfromsklearn.model\\\\_selectionimporttrain\\\\_test\\\\_splitfromsklearn.preprocessingimportStandardScaler`\\n```\\n```\\n2024-08-20 01:23:52.305388: E external/local\\\\_xla/xla/stream\\\\_executor/cuda/cuda\\\\_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\\n2024-08-20 01:23:52.326935: E external/local\\\\_xla/xla/stream\\\\_executor/cuda/cuda\\\\_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\\n2024-08-20 01:23:52.333533: E external/local\\\\_xla/xla/stream\\\\_executor/cuda/cuda\\\\_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\\n```\\n```\\n`mpl.rcParams['figure.figsize']=(12,10)colors=plt.rcParams['axes.prop\\\\_cycle'].by\\\\_key()['color']`\\n```\\n## Data processing and exploration\\n### Download the Kaggle Credit Card Fraud data set\\nPandas is a Python library with many helpful utilities for loading and working with structured data. It can be used to download CSVs into a Pandas[DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame).\\n**Note:**This dataset has been collected and analysed during a research collaboration of Worldline and the[Machine Learning Group](http://mlg.ulb.ac.be)of ULB (Universit√© Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available[here](https://www.researchgate.net/project/Fraud-detection-5)and the page of the[DefeatFraud](https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/)project\\n```\\n`file=tf.keras.utilsraw\\\\_df=pd.read\\\\_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')raw\\\\_df.head()`\\n```\\n```\\n`raw\\\\_df[['Time','V1','V2','V3','V4','V5','V26','V27','V28','Amount','Class']].describe()`\\n```\\n### Examine the class label imbalance\\nLet's look at the dataset imbalance:\\n```\\n`neg,pos=np.bincount(raw\\\\_df['Class'])total=neg+posprint('Examples:\\\\\\\\nTotal:{}\\\\\\\\nPositive:{}({:.2f}% of total)\\\\\\\\n'.format(total,pos,100\\\\*pos/total))`\\n```\\n```\\nExamples:\\nTotal: 284807\\nPositive: 492 (0.17% of total)\\n```\\nThis shows the small fraction of positive samples.\\n### Clean, split and normalize the data\\nThe raw data has a few issues. First the`Time`and`Amount`columns are too variable to use directly. Drop the`Time`column (since it's not clear what it means) and take the log of the`Amount`column to reduce its range.\\n```\\n`cleaned\\\\_df=raw\\\\_df.copy()# You don't want the `Time` column.cleaned\\\\_df.pop('Time')# The `Amount` column covers a huge range. Convert to log-space.eps=0.001# 0 =&gt; 0.1¬¢cleaned\\\\_df['Log Amount']=np.log(cleaned\\\\_df.pop('Amount')+eps)`\\n```\\nSplit the dataset into train, validation, and test sets. The validation set is used during the model fitting to evaluate the loss and any metrics, however the model is not fit with this data. The test set is completely unused during the training phase and is only used at the end to evaluate how well the model generalizes to new data. This is especially important with imbalanced datasets where[overfitting](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting)is a significant concern from the lack of training data.\\n```\\n`# Use a utility from sklearn to split and shuffle your dataset.train\\\\_df,test\\\\_df=train\\\\_test\\\\_split(cleaned\\\\_df,test\\\\_size=0.2)train\\\\_df,val\\\\_df=train\\\\_test\\\\_split(train\\\\_df,test\\\\_size=0.2)# Form np arrays of labels and features.train\\\\_labels=np.array(train\\\\_df.pop('Class')).reshape(-1,1)bool\\\\_train\\\\_labels=train\\\\_labels[:,0]!=0val\\\\_labels=np.array(val\\\\_df.pop('Class')).reshape(-1,1)test\\\\_labels=np.array(test\\\\_df.pop('Class')).reshape(-1,1)train\\\\_features=np.array(train\\\\_df)val\\\\_features=np.array(val\\\\_df)test\\\\_features=np.array(test\\\\_df)`\\n```\\nWe check whether the distribution of the classes in the three sets is about the same or not.\\n```\\n`print(f'Average class probability in training set:{train\\\\_labels.mean():.4f}')print(f'Average class probability in validation set:{val\\\\_labels.mean():.4f}')print(f'Average class probability in test set:{test\\\\_labels.mean():.4f}')`\\n```\\n```\\nAverage class probability in training set: 0.0017\\nAverage class probability in validation set: 0.0018\\nAverage class probability in test set: 0.0018\\n```\\nGiven the small number of positive labels, this seems about right.\\nNormalize the input features using the sklearn StandardScaler.\\nThis will set the mean to 0 and standard deviation to 1.\\n**Note:**The`StandardScaler`is only fit using the`train\\\\_features`to be sure the model is not peeking at the validation or test sets.\\n```\\n`scaler=StandardScaler()train\\\\_features=scaler.fit\\\\_transform(train\\\\_features)val\\\\_features=scaler.transform(val\\\\_features)test\\\\_features=scaler.transform(test\\\\_features)train\\\\_features=np.clip(train\\\\_features,-5,5)val\\\\_features=np.clip(val\\\\_features,-5,5)test\\\\_features=np.clip(test\\\\_features,-5,5)print('Training labels shape:',train\\\\_labels.shape)print('Validation labels shape:',...\\n\\n--- Result 9 ---\\nTitle: Computer Science > Machine Learning\\nURL: https://arxiv.org/abs/2409.19751\\n\\nContent:\\n[2409.19751] Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification\\n[Skip to main content](#content)\\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\\n[](https://arxiv.org/IgnoreMe)\\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2409.19751\\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\\nSearch\\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\\nopen search\\nGO\\nopen navigation menu\\n# Computer Science \\\\> Machine Learning\\n**arXiv:2409.19751**(cs)\\n[Submitted on 29 Sep 2024]\\n# Title:Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification\\nAuthors:[Mohamed Abdelhamid](https://arxiv.org/search/cs?searchtype=author&amp;query=Abdelhamid,+M),[Abhyuday Desai](https://arxiv.org/search/cs?searchtype=author&amp;query=Desai,+A)\\nView a PDF of the paper titled Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification, by Mohamed Abdelhamid and Abhyuday Desai\\n[View PDF](https://arxiv.org/pdf/2409.19751)[HTML (experimental)](https://arxiv.org/html/2409.19751v1)> > Abstract:\\n> Class imbalance in binary classification tasks remains a significant challenge in machine learning, often resulting in poor performance on minority classes. This study comprehensively evaluates three widely-used strategies for handling class imbalance: Synthetic Minority Over-sampling Technique (SMOTE), Class Weights tuning, and Decision Threshold Calibration. We compare these methods against a baseline scenario of no-intervention across 15 diverse machine learning models and 30 datasets from various domains, conducting a total of 9,000 experiments. Performance was primarily assessed using the F1-score, although our study also tracked results on additional 9 metrics including F2-score, precision, recall, Brier-score, PR-AUC, and AUC. Our results indicate that all three strategies generally outperform the baseline, with Decision Threshold Calibration emerging as the most consistently effective technique. However, we observed substantial variability in the best-performing method across datasets, highlighting the importance of testing multiple approaches for specific problems. This study provides valuable insights for practitioners dealing with imbalanced datasets and emphasizes the need for dataset-specific analysis in evaluating class imbalance handling techniques. Comments:|13 pages including appendix, 4 tables|\\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)|\\nACMclasses:|I.2.6; I.5.1; I.5.2; I.2.m|\\nCite as:|[arXiv:2409.19751](https://arxiv.org/abs/2409.19751)[cs.LG]|\\n|(or[arXiv:2409.19751v1](https://arxiv.org/abs/2409.19751v1)[cs.LG]for this version)|\\n|[https://doi.org/10.48550/arXiv.2409.19751](https://doi.org/10.48550/arXiv.2409.19751)\\nFocus to learn more\\narXiv-issued DOI via DataCite\\n|\\n## Submission history\\nFrom: Abhyuday Desai [[view email](https://arxiv.org/show-email/43e3e529/2409.19751)]\\n**[v1]**Sun, 29 Sep 2024 16:02:32 UTC (18 KB)\\nFull-text links:## Access Paper:\\nView a PDF of the paper titled Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification, by Mohamed Abdelhamid and Abhyuday Desai\\n* [View PDF](https://arxiv.org/pdf/2409.19751)\\n* [HTML (experimental)](https://arxiv.org/html/2409.19751v1)\\n* [TeX Source](https://arxiv.org/src/2409.19751)\\n[![license icon](https://arxiv.org/icons/licenses/by-sa-4.0.png)view license](http://creativecommons.org/licenses/by-sa/4.0/)\\nCurrent browse context:\\ncs.LG\\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2409.19751&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2409.19751&amp;function=next&amp;context=cs.LG)\\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2024-09](https://arxiv.org/list/cs.LG/2024-09)\\nChange to browse by:\\n[cs](https://arxiv.org/abs/2409.19751?context=cs)\\n[cs.AI](https://arxiv.org/abs/2409.19751?context=cs.AI)\\n[stat](https://arxiv.org/abs/2409.19751?context=stat)\\n[stat.ML](https://arxiv.org/abs/2409.19751?context=stat.ML)\\n### References &amp; Citations\\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2409.19751)\\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2409.19751)\\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2409.19751)\\nexport BibTeX citationLoading...\\n## BibTeX formatted citation\\n&times;\\nloading...\\nData provided by:\\n### Bookmark\\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2409.19751&amp;description=Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2409.19751&amp;title=Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification>)\\nBibliographic Tools\\n# Bibliographic and Citation Tools\\nBibliographic Explorer Toggle\\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\\nConnected Papers Toggle\\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\\nLitmaps Toggle\\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\\nscite.ai Toggle\\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\\nCode, Data, Media\\n# Code, Data and Media Associated with this Article\\nalphaXiv Toggle\\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\\nLinks to Code Toggle\\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\\nDagsHub Toggle\\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\\nGotitPub Toggle\\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\\nHuggingface Toggle\\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\\nLinks to Code Toggle\\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\\nScienceCast Toggle\\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\\nDemos\\n# Demos\\nReplicate Toggle\\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\\nSpaces Toggle\\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\\nSpaces Toggle\\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\\nRelated Papers\\n# Recommenders and Search Tools\\nLink to Influence Flower\\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\\nCore recommender toggle\\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\\nIArxiv recommender toggle\\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\\n* Author\\n* Venue\\n* Institution\\n* Topic\\nAbout arXivLabs\\n# arXivLabs: experimental projects with community collaborators\\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to th...\\n\", \"is_error\": false, \"results\": [{\"title\": \"ANSWER\", \"text\": \"Kaggle winners typically tame a 3‚ÄØ:‚ÄØ1 binary‚Äëclass imbalance with a short, repeatable workflow that combines data‚Äëlevel tricks and model‚Äëlevel adjustments‚ÄØ‚Äî‚ÄØall backed by the same practices discussed in Kaggle‚Äôs own discussions and competition post‚Äëmortems‚ÄØ([Unbalanced data and cross‚Äëvalidation](https://www.kaggle.com/discussions/questions-and-answers/27589); [Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions](https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions)):\\n\\n1. **Create stratified folds** so each training/validation split preserves the 3‚ÄØ:‚ÄØ1 ratio, preventing the model from seeing a skewed distribution during CV.  \\n\\n2. **Apply a sampling strategy** to the training data:  \\n   - *Oversample* the minority class (e.g., SMOTE or simple random replication) or  \\n   - *Undersample* the majority class to a more balanced mix. The `imbalanced‚Äëlearn` library is a common starting point‚ÄØ([Unbalanced data and cross‚Äëvalidation](https://www.kaggle.com/discussions/questions-and-answers/27589)).  \\n\\n3. **Add class‚Äëweighting to the loss** (e.g., `class_weight='balanced'` in scikit‚Äëlearn, or custom weights in LightGBM/CatBoost). This tells the optimizer to penalize mistakes on the minority class more heavily without altering the raw data.  \\n\\n4. **Choose an evaluation metric that reflects imbalance**, such as AUC‚ÄëPR, weighted log‚Äëloss, or F1‚Äëscore, rather than plain accuracy. Align the metric with the competition‚Äôs leaderboard and with the business cost of false positives vs. false negatives‚ÄØ([Unbalanced data and cross‚Äëvalidation](https://www.kaggle.com/discussions/questions-and-answers/27589)).  \\n\\n5. **Tune the decision threshold** after training: scan thresholds on the validation set and pick the one that maximizes the chosen metric (often improves the leaderboard score for imbalanced problems).  \\n\\n6. **Ensemble diverse models** (e.g., tree‚Äëbased + neural nets) that were each trained with the above imbalance handling; averaging predictions tends to smooth out residual bias toward the majority class‚ÄØ([Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions](https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions)).  \\n\\n7. **Validate on a hold‚Äëout set that mirrors the test distribution** (if possible) to ensure the sampling and weighting choices generalize, then submit the final ensemble.  \\n\\nFollowing these steps lets top Kagglers turn a modest 3‚ÄØ:‚ÄØ1 skew into a well‚Äëbalanced learning problem and achieve competitive scores.\", \"url\": \"\"}, {\"title\": \"Unbalanced data and cross-validation | Kaggle\", \"text\": \"<div><div><p>There are two general ways of dealing with imbalanced data: 1) change the data; 2) leave the data alone but change the performance metric and/or the weight of individual data points.</p>\\n<p>Changing the data means oversampling the under-represented class(es) with synthetic data points, or undersampling (thinning down) the over-represented class(es). There are various ways of doing both operations, and I will give you one <a href=\\\"https://github.com/scikit-learn-contrib/imbalanced-learn\\\"><strong>starting point</strong></a>.</p>\\n<p>A second option is to leave the data alone and adjust how we do the training. It is crucial to pick a reliable performance metric for imbalanced data, and to know whether for your purposes it is worse to have too many false positives (FPs) or false negatives (FNs). Ideally, you wouldn't want to have either of the two, but for most applications it should be clear whether we want to avoid FPs or FNs with greater preference.</p>\\n<p>To give you an example: you have 900 healthy patients (class 0) and 100 cancer patients (class 1), which is at least somewhat close to the true ratio of healthy and cancer-stricken people out there. If you predict class 0 with 100% accuracy and class 1 with 70% accuracy, your accuracy will be 97% for the whole dataset. That sounds tremendous until we realize that 30 out of 100 cancer patients (30%) will go undiagnosed, meaning that high false negative rate in this case will cost many lives. What if we could adjust our classification so that both classes are predicted with 97% accuracy? This would mean that 27 healthy people would be predicted to have cancer (27 FPs) and 3 cancer-stricken individual would be predicted to be healthy (3 FNs). Now, I wouldn't want to be a doctor who tells a healthy person that they have a cancer because many people have been known to do silly things when they think they are dying. Still, compared to our starting premise, most would agree that on balance it is much better to have 27 people who think they have cancer and later find out they don't, and only 3 patients who were told they are healthy even though they have cancer. The problem is that a simple accuracy as a performance metric for training would never get you to a balanced 97% accuracy. For imbalanced datasets, F1-score (a weighted average of precision and recall), area under curve for ROC and Matthews correlation coefficient may be better measures of classifier quality.</p>\\n<p>See the links below for more info:</p>\\n<p><a href=\\\"http://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/\\\"><strong>link1</strong></a></p>\\n<p><a href=\\\"https://eva.fing.edu.uy/mod/resource/view.php?id=33977\\\"><strong>link2</strong></a></p>\\n<p><a href=\\\"https://www.kaggle.com/c/bosch-production-line-performance/forums/t/24120/time-effort-and-reward?forumMessageId=138285#post138285\\\"><strong>link3</strong></a></p></div></div>\", \"url\": \"https://www.kaggle.com/discussions/questions-and-answers/27589\"}, {\"title\": \"Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\", \"text\": \"Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions[\\n**üì£ BIG NEWS:****Neptune is joining OpenAI!**‚Üí Read the message from our CEO üì£![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\\nWhat do you want to find?\\nSearch\\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Neptune Blog](https://neptune.ai/blog)# Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions\\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Shahul-Es-new-scaled.jpeg?fit=2560%2C1920&ssl=1)\\n[Shahul ES](https://neptune.ai/blog/author/shahules)\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)3 min\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)1st September, 2023\\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)[Tabular Data](https://neptune.ai/blog/category/tabular-data)\\nIn this article, I will discuss some great tips and tricks to improve the performance of your structured data binary classification model. These tricks are obtained from solutions of some of Kaggle‚Äôs top tabular data competitions. Without much lag, let‚Äôs begin.\\nThese are the five competitions that I have gone through to create this article:\\n* [**Home credit default risk**](https://www.kaggle.com/c/home-credit-default-risk/)\\n* [**Santander Customer Transaction Prediction**](https://www.kaggle.com/c/santander-customer-transaction-prediction/notebooks)\\n* [**VSB Power Line Fault Detection**](https://www.kaggle.com/c/vsb-power-line-fault-detection/overview/evaluation)\\n* [**Microsoft Malware Prediction**](https://www.kaggle.com/c/microsoft-malware-prediction/overview)\\n* [**IEEE-CIS Fraud Detection**](https://www.kaggle.com/c/ieee-fraud-detection/overview/evaluation/)## Dealing with larger datasets\\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\\n* Faster[data loading with pandas.](https://www.kaggle.com/c/home-credit-default-risk/discussion/59575)\\n* Data compression techniques to[reduce the size of data by 70%](https://www.kaggle.com/nickycan/compress-70-of-dataset).\\n* Optimize the memory by r[educing the size of some attributes.](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\\n* Use open-source libraries such as[Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space.\\n* Use[cudf](https://github.com/rapidsai/cudf).\\n* Convert data to[parquet](https://arrow.apache.org/docs/python/parquet.html)format.\\n* Converting data to[feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03)format.\\n* Reducing memory usage for[optimizing RAM](https://www.kaggle.com/mjbahmani/reducing-memory-size-for-ieee).## Data exploration\\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\\n* EDA for microsoft[malware detection.](https://www.kaggle.com/youhanlee/my-eda-i-want-to-see-all)\\n* Time Series[EDA for malware detection.](https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68)\\n* Complete[EDA for home credit loan prediction](https://www.kaggle.com/codename007/home-credit-complete-eda-feature-importance).\\n* Complete[EDA for Santader prediction.](https://www.kaggle.com/gpreda/santander-eda-and-prediction)\\n* EDA for[VSB Power Line Fault Detection.](https://www.kaggle.com/go1dfish/basic-eda)## Data preparation\\nAfter data exploration, the first thing to do is to use those insights to prepare the data. To tackle issues like class imbalance, encoding categorical data, etc. Let‚Äôs see the methods used to do it.\\n* Methods to t[ackle class imbalance](https://www.kaggle.com/shahules/tackling-class-imbalance).\\n* Data augmentation by[Synthetic Minority Oversampling Technique](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/).\\n* Fast inplace[shuffle for augmentation](https://www.kaggle.com/jiweiliu/fast-inplace-shuffle-for-augmentation).\\n* Finding[synthetic samples in the dataset.](https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split)\\n* [Signal denoising](https://www.kaggle.com/jackvial/dwt-signal-denoising)used in signal processing competitions.\\n* Finding[patterns of missing data](https://www.kaggle.com/jpmiller/patterns-of-missing-data).\\n* Methods to handle[missing data](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779).\\n* An overview of various[encoding techniques for categorical data.](https://www.kaggle.com/shahules/an-overview-of-encoding-techniques)\\n* Building[model to predict missing values.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64598)\\n* Random[shuffling of data](https://www.kaggle.com/brandenkmurray/randomly-shuffled-data-also-works)to create new synthetic training set.## Feature engineering\\nNext, you can check the most popular feature and feature engineering techniques used in these top kaggle competitions. The feature engineering part varies from problem to problem depending on the domain.\\n* Target[encoding cross validation](https://medium.com/@pouryaayria/k-fold-target-encoding-dfe9a594874b/)for better encoding.\\n* Entity embedding to[handle categories](https://www.kaggle.com/abhishek/entity-embeddings-to-handle-categories).\\n* Encoding c[yclic features for deep learning.](https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning)\\n* Manual[feature engineering methods](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering).\\n* Automated feature engineering techniques[using featuretools](https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics).\\n* Top hard crafted features used in[microsoft malware detection](https://www.kaggle.com/sanderf/7th-place-solution-microsoft-malware-prediction).\\n* Denoising NN for[feature extraction](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798).\\n* Feature engineering[using RAPIDS framework.](https://www.kaggle.com/cdeotte/rapids-feature-engineering-fraud-0-96/)\\n* Things to remember while processing f[eatures using LGBM.](https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575)\\n* [Lag features and moving averages.](https://www.kaggle.com/c/home-credit-default-risk/discussion/64593)\\n* [Principal component analysis](https://medium.com/machine-learning-researcher/dimensionality-reduction-pca-and-lda-6be91734f567)for...\", \"url\": \"https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions\"}, {\"title\": \"Methods for Dealing with Imbalanced Data\", \"text\": \"- _code_\\n\\nNew Notebook\\n\\n- _table\\\\_chart_\\n\\nNew Dataset\\n\\n- _tenancy_\\n\\nNew Model\\n\\n- _emoji\\\\_events_\\n\\nNew Competition\\n\\n- _corporate\\\\_fare_\\n\\nNew Organization\\n\\n\\n## No Active Events\\n\\nCreate notebooks and keep track of their status here.\\n\\n[_add_ New Notebook](https://www.kaggle.com/code/new)\\n\\n- _auto\\\\_awesome\\\\_motion_\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0 Active Events\\n\\n\\n\\n\\n\\n\\n_expand\\\\_more_\\n\\n\\nmenu\\n\\n[Skip to\\\\\\n\\\\\\ncontent](https://www.kaggle.com/code/tboyle10/methods-for-dealing-with-imbalanced-data#site-content)\\n\\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\\n\\nCreate\\n\\n_search_\\n\\n- [_explore_\\\\\\n\\\\\\nHome](https://www.kaggle.com/)\\n\\n- [_emoji\\\\_events_\\\\\\n\\\\\\nCompetitions](https://www.kaggle.com/competitions)\\n\\n- [_table\\\\_chart_\\\\\\n\\\\\\nDatasets](https://www.kaggle.com/datasets)\\n\\n- [_tenancy_\\\\\\n\\\\\\nModels](https://www.kaggle.com/models)\\n\\n- [_code_\\\\\\n\\\\\\nCode](https://www.kaggle.com/code)\\n\\n- [_comment_\\\\\\n\\\\\\nDiscussions](https://www.kaggle.com/discussions)\\n\\n- [_school_\\\\\\n\\\\\\nLearn](https://www.kaggle.com/learn)\\n\\n- [_expand\\\\_more_\\\\\\n\\\\\\nMore](https://www.kaggle.com/code/tboyle10/methods-for-dealing-with-imbalanced-data)\\n\\n\\n_auto\\\\_awesome\\\\_motion_\\n\\nView Active Events\\n\\nmenu\\n\\n[Skip to\\\\\\n\\\\\\ncontent](https://www.kaggle.com/code/tboyle10/methods-for-dealing-with-imbalanced-data#site-content)\\n\\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\\n\\n_search_\\n\\n[Sign In](https://www.kaggle.com/account/login?phase=startSignInTab&returnUrl=%2Fcode%2Ftboyle10%2Fmethods-for-dealing-with-imbalanced-data)\\n\\n[Register](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2Fcode%2Ftboyle10%2Fmethods-for-dealing-with-imbalanced-data)\\n\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n\\n[Learn more.](https://www.kaggle.com/cookies)\\n\\nOK, Got it.\\n\\n![Something went wrong and this page crashed!](https://www.kaggle.com/static/images/error/server-error-illo_light.svg)\\n\\n###### Something went wrong and this page crashed!\\n\\nIf the issue persists, it's likely a problem on our side.\\n\\n```\\n\\nLoading CSS chunk 5073 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 5073 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\n    at t.onerror.t.onload (https://www.kaggle.com/static/assets/runtime.js?v=e39bd89f6741bf1e27b2:1:8254)\\n```\\n\\nRefresh\", \"url\": \"https://www.kaggle.com/code/tboyle10/methods-for-dealing-with-imbalanced-data\"}, {\"title\": \"üëë Imbalance ratio: How to identify an imbalanced dataset? | Kaggle\", \"text\": \"menu\\n\\n[Skip to\\\\\\n\\\\\\ncontent](https://www.kaggle.com/discussions/questions-and-answers/372288#site-content)\\n\\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\\n\\nCreate\\n\\nsearch‚Äã\\n\\n- [explore\\\\\\n\\\\\\nHome](https://www.kaggle.com/)\\n\\n- [emoji\\\\_events\\\\\\n\\\\\\nCompetitions](https://www.kaggle.com/competitions)\\n\\n- [table\\\\_chart\\\\\\n\\\\\\nDatasets](https://www.kaggle.com/datasets)\\n\\n- [tenancy\\\\\\n\\\\\\nModels](https://www.kaggle.com/models)\\n\\n- [code\\\\\\n\\\\\\nCode](https://www.kaggle.com/code)\\n\\n- [comment\\\\\\n\\\\\\nDiscussions](https://www.kaggle.com/discussions)\\n\\n- [school\\\\\\n\\\\\\nLearn](https://www.kaggle.com/learn)\\n\\n\\n- [expand\\\\_more\\\\\\n\\\\\\nMore](https://www.kaggle.com/discussions/questions-and-answers/372288)\\n\\n\\nauto\\\\_awesome\\\\_motion\\n\\nView Active Events\\n\\nmenu\\n\\n[Skip to\\\\\\n\\\\\\ncontent](https://www.kaggle.com/discussions/questions-and-answers/372288#site-content)\\n\\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\\n\\nsearch‚Äã\\n\\n[Sign In](https://www.kaggle.com/account/login?phase=startSignInTab&returnUrl=%2Fdiscussions%2Fquestions-and-answers%2F372288)\\n\\n[Register](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2Fdiscussions%2Fquestions-and-answers%2F372288)\\n\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n\\n[Learn more](https://www.kaggle.com/cookies)\\n\\nOK, Got it.\\n\\n[Eli≈°ka Bl√°hov√°](https://www.kaggle.com/elisthefox) ¬∑ Posted 2 years ago in [Questions & Answers](https://www.kaggle.com/discussions/questions-and-answers)\\n\\narrow\\\\_drop\\\\_up3\\n\\n![This post earned a bronze medal](https://www.kaggle.com/static/images/medals/discussion/bronzel@1x.png)more\\\\_vert\\n\\n# üëë Imbalance ratio: How to identify an imbalanced dataset?\\n\\nDear community,\\n\\nI have a question for you to which I can't find a common answer. I wonder how to be able to classify a dataset as imbalanced? Is there some rule of thumb I can use? I have found this article, where it says that highly imbalanced dataset has ratio of 10-1 [https://www.sciencedirect.com/topics/computer-science/imbalance-ratio](https://www.sciencedirect.com/topics/computer-science/imbalance-ratio).\\n\\nI would love to hear your opinion.\\n\\nThanks a lot!\\n\\n[Exploratory Data Analysis](https://www.kaggle.com/discussions?tags=13201-Exploratory+Data+Analysis) [Data Analytics](https://www.kaggle.com/discussions?tags=13215-Data+Analytics) [Data Cleaning](https://www.kaggle.com/discussions?tags=13202-Data+Cleaning)\\n\\nPlease [sign in](https://www.kaggle.com/account/login) to reply to this topic.\\n\\ncomment\\n\\n## 8 Comments\\n\\nHotness\\n\\n[**Senapati Rajesh**](https://www.kaggle.com/senapatirajesh)\\n\\nPosted 2 years ago\\n\\n![This post earned a bronze medal](https://www.kaggle.com/static/images/medals/discussion/bronzel@1x.png)\\n\\narrow\\\\_drop\\\\_up1\\n\\nmore\\\\_vert\\n\\nThank you very much all for the comments and here is my version of answer\\n\\nImbalanced dataset is relevant primarily in the context of supervised machine learning involving two or more classes.\\n\\nImbalance means that the number of data points available for different the classes is different:\\n\\nIf there are two classes, then balanced data would mean 50% points for each of the class. For most machine learning techniques, little imbalance is not a problem. So, if there are 60% points for one class and 40% for the other class, it should not cause any significant performance degradation. Only when the class imbalance is high, e.g. 90% points for one class and 10% for the other, standard optimization criteria or performance measures may not be as effective and would need modification.\\n\\nA typical example of imbalanced data is encountered in e-mail classification problem where emails are classified into ham or spam. The number of spam emails is usually lower than the number of relevant (ham) emails. So, using the original distribution of two classes leads to imbalanced dataset.\\n\\nUsing accuracy as a performace measure for highly imbalanced datasets is not a good idea. For example, if 90% points belong to the true class in a binary classification problem, a default prediction of true for all data points leads to a classifier which is 90% accurate, even though the classifier has not learnt anything about the classification problem at hand!\\n\\nImbalanced data can be handled by using below techniques:\\n\\n1.Resample the training set\\n\\n(Under sampling -This method is used when quantity of data is sufficient or\\n\\nover sampling-It tries to balance dataset by increasing the size of rare samples.)\\n\\n2.Use K-fold Cross-Validation in the Right Way\\n\\n3.Ensemble Different Resampled Datasets(This approach is simple and perfectly horizontally scalable if you have a lot of data)\\n\\n4.Resample with Different Ratios( Instead of training all models with the same ratio in the ensemble, it is worth trying to ensemble different ratios)\\n\\n5.Most importantly Choose Proper Evaluation Metric(\\n\\nex:The accuracy of a classifier is the total number of correct predictions by the classifier divided by the total number of predictions.For an imbalanced class dataset F1 score is a more appropriate metric. It is the harmonic mean of precision and recall)\\n\\n6.SMOTE is another technique to oversample the minority class.SMOTE looks into minority class instances and use k nearest neighbor to select a random nearest neighbor, and a synthetic instance is created randomly in feature space.\\n\\nThank u and Pl feel free to suggest for any modifications.\\n\\n[**Olqa\\\\_842**](https://www.kaggle.com/zvr842)\\n\\nPosted 2 years ago\\n\\n![This post earned a bronze medal](https://www.kaggle.com/static/images/medals/discussion/bronzel@1x.png)\\n\\narrow\\\\_drop\\\\_up1\\n\\nmore\\\\_vert\\n\\nPlease, could you share dataset too?\\n\\n[**Eli≈°ka Bl√°hov√°**](https://www.kaggle.com/elisthefox)\\n\\nTopic Author\\n\\nPosted 2 years ago\\n\\narrow\\\\_drop\\\\_up0\\n\\nmore\\\\_vert\\n\\nOf course, currently, I am working with this dataset: [https://www.kaggle.com/datasets/shubh0799/churn-modelling](https://www.kaggle.com/datasets/shubh0799/churn-modelling). Link to my notebook: [https://www.kaggle.com/code/elisthefox/churn-analytics-should-i-stay-or-should-i-go](https://www.kaggle.com/code/elisthefox/churn-analytics-should-i-stay-or-should-i-go)\\n\\n[**Carl McBride Ellis**](https://www.kaggle.com/carlmcbrideellis)\\n\\nPosted 2 years ago\\n\\n![This post earned a bronze medal](https://www.kaggle.com/static/images/medals/discussion/bronzel@1x.png)\\n\\narrow\\\\_drop\\\\_up2\\n\\nmore\\\\_vert\\n\\nDear [@elisthefox](https://www.kaggle.com/elisthefox)\\n\\nYou may perhaps find this short notebook of some interest: [Classification: How imbalanced is \\\"imbalanced\\\"?\\\"](https://www.kaggle.com/code/carlmcbrideellis/classification-how-imbalanced-is-imbalanced).\\n\\nAll the best,\\n\\ncarl\\n\\n[**Eli≈°ka Bl√°hov√°**](https://www.kaggle.com/elisthefox)\\n\\nTopic Author\\n\\nPosted 2 years ago\\n\\n![This post earned a bronze medal](https://www.kaggle.com/static/images/medals/discussion/bronzel@1x.png)\\n\\narrow\\\\_drop\\\\_up1\\n\\nmore\\\\_vert\\n\\nThanks a lot for letting me know about this great notebook, If I understood correctly, the metric balanced accuracy helps to determine the ratio for imbalanced dataset, hence if its results are equal to 0.85, then dataset consisting of 10K rows with 8500 rows with target variable 1 and 1500 rows with target variable 0 is considered as a balanced target variable?\\n\\n[**Carl McBride Ellis**](https://www.kaggle.com/carlmcbrideellis)\\n\\nPosted 2 years ago\\n\\n![This post earned a bronze medal](https://www.kaggle.com/static/images/medals/discussion/bronzel@1x.png)\\n\\narrow\\\\_drop\\\\_up2\\n\\nmore\\\\_vert\\n\\nDear [@elisthefox](https://www.kaggle.com/elisthefox)\\n\\nStrictly speaking a dataset is balanced if there are an equal number of rows associated with each class (or label) in the training data. One can perform a quick check with something like:\\n\\n```\\ndf['labels'].value_counts().to_frame().T\\n\\ncontent_copy\\n```\\n\\nIn the notebook I suggest that most metrics work well up to an imbalance of 85:15 after which one should exercise caution. Note however as far as most estimators are concerned, they work pretty well irrespective of whether ...\", \"url\": \"https://www.kaggle.com/discussions/questions-and-answers/372288\"}, {\"title\": \"Dealing with extremely imbalanced dataset - binary classification | Kaggle\", \"text\": \"<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 4787 failed.\\n(error: https://www.kaggle.com/static/assets/4787.f5129f48620a03126642.css)</p></div>ChunkLoadError: Loading CSS chunk 4787 failed.\\n(error: https://www.kaggle.com/static/assets/4787.f5129f48620a03126642.css)\\nat f.onerror.f.onload (https://www.kaggle.com/static/assets/runtime.js?v=42762aa12f6df4b246e8:1:11101)</pre></div></div></div></div>\", \"url\": \"https://www.kaggle.com/discussions/questions-and-answers/473546\"}, {\"title\": \"Best techniques and metrics for Imbalanced Dataset\", \"text\": \"Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n\\n[Learn more](https://www.kaggle.com/cookies)\\n\\nOK, Got it.\\n\\n###### Something went wrong and this page crashed!\\n\\nIf the issue persists, it's likely a problem on our side.\\n\\n```\\n\\nLoading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\n    at r.onerror.r.onload (https://www.kaggle.com/static/assets/runtime.js?v=805aeed0a20bb825939e:1:11032)\\n```\\n\\nRefresh\", \"url\": \"https://www.kaggle.com/code/marcinrutecki/best-techniques-and-metrics-for-imbalanced-dataset\"}, {\"title\": \"Classification on imbalanced data \\n\\n    \\n    \\n       \\n    \\n\\n     \\n      \\n      Stay organized with collections\\n     \\n     \\n      \\n      Save and categorize content based on your preferences.\", \"text\": \"Classification on imbalanced data | TensorFlow Core[Skip to main content](#main-content)\\n[![TensorFlow](https://www.gstatic.com/devrel-devsite/prod/ve08add287a6b4bdf8961ab8a1be50bf551be3816cdd70b7cc934114ff3ad5f10/tensorflow/images/lockup.svg)](https://www.tensorflow.org/)\\n* /\\n* English\\n* Espa√±ol ‚ÄìAm√©rica Latina\\n* Fran√ßais\\n* Indonesia\\n* Italiano\\n* Polski\\n* Portugu√™s ‚ÄìBrasil\\n* Ti√™ÃÅng Vi√™Ã£t\\n* T√ºrk√ße\\n* –†—É—Å—Å–∫–∏–π* ◊¢◊ë◊®◊ô◊™* ÿßŸÑÿπÿ±ÿ®ŸäŸëÿ©* ŸÅÿßÿ±ÿ≥€å* ‡§π‡§ø‡§Ç‡§¶‡•Ä* ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ* ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢* ‰∏≠Êñá‚ÄìÁÆÄ‰Ωì* Êó•Êú¨Ë™û* ÌïúÍµ≠Ïñ¥[GitHub](https://github.com/tensorflow)Sign in\\n* [TensorFlow Core](https://www.tensorflow.org/tutorials)\\n* [TensorFlow](https://www.tensorflow.org/)\\n* [Learn](https://www.tensorflow.org/learn)\\n* [TensorFlow Core](https://www.tensorflow.org/tutorials)\\n# Classification on imbalanced dataStay organized with collectionsSave and categorize content based on your preferences.\\n[![](https://www.tensorflow.org/images/tf_logo_32px.png)View on TensorFlow.org](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data)|[![](https://www.tensorflow.org/images/colab_logo_32px.png)Run in Google Colab](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb)|[![](https://www.tensorflow.org/images/GitHub-Mark-32px.png)View source on GitHub](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb)|[![](https://www.tensorflow.org/images/download_logo_32px.png)Download notebook](https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/imbalanced_data.ipynb)|\\nThis tutorial demonstrates how to classify a highly imbalanced dataset in which the number of examples in one class greatly outnumbers the examples in another. You will work with the[Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)dataset hosted on Kaggle. The aim is to detect a mere 492 fraudulent transactions from 284,807 transactions in total. You will use[Keras](https://www.tensorflow.org/guide/keras/overview)to define the model and[class weights](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model)to help the model learn from the imbalanced data. .\\nThis tutorial contains complete code to:\\n* Load a CSV file using Pandas.\\n* Create train, validation, and test sets.\\n* Define and train a model using Keras (including setting class weights).\\n* Evaluate the model using various metrics (including precision and recall).\\n* Select a threshold for a probabilistic classifier to get a deterministic classifier.\\n* Try and compare with class weighted modelling and oversampling.## Setup\\n```\\n`importtensorflowastffromtensorflowimportkerasimportosimporttempfileimportmatplotlibasmplimportmatplotlib.pyplotaspltimportnumpyasnpimportpandasaspdimportseabornassnsimportsklearnfromsklearn.metricsimportconfusion\\\\_matrixfromsklearn.model\\\\_selectionimporttrain\\\\_test\\\\_splitfromsklearn.preprocessingimportStandardScaler`\\n```\\n```\\n2024-08-20 01:23:52.305388: E external/local\\\\_xla/xla/stream\\\\_executor/cuda/cuda\\\\_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\\n2024-08-20 01:23:52.326935: E external/local\\\\_xla/xla/stream\\\\_executor/cuda/cuda\\\\_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\\n2024-08-20 01:23:52.333533: E external/local\\\\_xla/xla/stream\\\\_executor/cuda/cuda\\\\_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\\n```\\n```\\n`mpl.rcParams['figure.figsize']=(12,10)colors=plt.rcParams['axes.prop\\\\_cycle'].by\\\\_key()['color']`\\n```\\n## Data processing and exploration\\n### Download the Kaggle Credit Card Fraud data set\\nPandas is a Python library with many helpful utilities for loading and working with structured data. It can be used to download CSVs into a Pandas[DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame).\\n**Note:**This dataset has been collected and analysed during a research collaboration of Worldline and the[Machine Learning Group](http://mlg.ulb.ac.be)of ULB (Universit√© Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available[here](https://www.researchgate.net/project/Fraud-detection-5)and the page of the[DefeatFraud](https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/)project\\n```\\n`file=tf.keras.utilsraw\\\\_df=pd.read\\\\_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')raw\\\\_df.head()`\\n```\\n```\\n`raw\\\\_df[['Time','V1','V2','V3','V4','V5','V26','V27','V28','Amount','Class']].describe()`\\n```\\n### Examine the class label imbalance\\nLet's look at the dataset imbalance:\\n```\\n`neg,pos=np.bincount(raw\\\\_df['Class'])total=neg+posprint('Examples:\\\\\\\\nTotal:{}\\\\\\\\nPositive:{}({:.2f}% of total)\\\\\\\\n'.format(total,pos,100\\\\*pos/total))`\\n```\\n```\\nExamples:\\nTotal: 284807\\nPositive: 492 (0.17% of total)\\n```\\nThis shows the small fraction of positive samples.\\n### Clean, split and normalize the data\\nThe raw data has a few issues. First the`Time`and`Amount`columns are too variable to use directly. Drop the`Time`column (since it's not clear what it means) and take the log of the`Amount`column to reduce its range.\\n```\\n`cleaned\\\\_df=raw\\\\_df.copy()# You don't want the `Time` column.cleaned\\\\_df.pop('Time')# The `Amount` column covers a huge range. Convert to log-space.eps=0.001# 0 =&gt; 0.1¬¢cleaned\\\\_df['Log Amount']=np.log(cleaned\\\\_df.pop('Amount')+eps)`\\n```\\nSplit the dataset into train, validation, and test sets. The validation set is used during the model fitting to evaluate the loss and any metrics, however the model is not fit with this data. The test set is completely unused during the training phase and is only used at the end to evaluate how well the model generalizes to new data. This is especially important with imbalanced datasets where[overfitting](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting)is a significant concern from the lack of training data.\\n```\\n`# Use a utility from sklearn to split and shuffle your dataset.train\\\\_df,test\\\\_df=train\\\\_test\\\\_split(cleaned\\\\_df,test\\\\_size=0.2)train\\\\_df,val\\\\_df=train\\\\_test\\\\_split(train\\\\_df,test\\\\_size=0.2)# Form np arrays of labels and features.train\\\\_labels=np.array(train\\\\_df.pop('Class')).reshape(-1,1)bool\\\\_train\\\\_labels=train\\\\_labels[:,0]!=0val\\\\_labels=np.array(val\\\\_df.pop('Class')).reshape(-1,1)test\\\\_labels=np.array(test\\\\_df.pop('Class')).reshape(-1,1)train\\\\_features=np.array(train\\\\_df)val\\\\_features=np.array(val\\\\_df)test\\\\_features=np.array(test\\\\_df)`\\n```\\nWe check whether the distribution of the classes in the three sets is about the same or not.\\n```\\n`print(f'Average class probability in training set:{train\\\\_labels.mean():.4f}')print(f'Average class probability in validation set:{val\\\\_labels.mean():.4f}')print(f'Average class probability in test set:{test\\\\_labels.mean():.4f}')`\\n```\\n```\\nAverage class probability in training set: 0.0017\\nAverage class probability in validation set: 0.0018\\nAverage class probability in test set: 0.0018\\n```\\nGiven the small number of positive labels, this seems about right.\\nNormalize the input features using the sklearn StandardScaler.\\nThis will set the mean to 0 and standard deviation to 1.\\n**Note:**The`StandardScaler`is only fit using the`train\\\\_features`to be sure the model is not peeking at the validation or test sets.\\n```\\n`scaler=StandardScaler()train\\\\_features=scaler.fit\\\\_transform(train\\\\_features)val\\\\_features=scaler.transform(val\\\\_features)test\\\\_features=scaler.transform(test\\\\_features)train\\\\_features=np.clip(train\\\\_features,-5,5)val\\\\_features=np.clip(val\\\\_features,-5,5)test\\\\_features=np.clip(test\\\\_features,-5,5)print('Training labels shape:',train\\\\_labels.shape)print('Validation labels shape:',...\", \"url\": \"https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\"}, {\"title\": \"Computer Science > Machine Learning\", \"text\": \"[2409.19751] Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification\\n[Skip to main content](#content)\\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\\n[](https://arxiv.org/IgnoreMe)\\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2409.19751\\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\\nSearch\\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\\nopen search\\nGO\\nopen navigation menu\\n# Computer Science \\\\> Machine Learning\\n**arXiv:2409.19751**(cs)\\n[Submitted on 29 Sep 2024]\\n# Title:Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification\\nAuthors:[Mohamed Abdelhamid](https://arxiv.org/search/cs?searchtype=author&amp;query=Abdelhamid,+M),[Abhyuday Desai](https://arxiv.org/search/cs?searchtype=author&amp;query=Desai,+A)\\nView a PDF of the paper titled Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification, by Mohamed Abdelhamid and Abhyuday Desai\\n[View PDF](https://arxiv.org/pdf/2409.19751)[HTML (experimental)](https://arxiv.org/html/2409.19751v1)> > Abstract:\\n> Class imbalance in binary classification tasks remains a significant challenge in machine learning, often resulting in poor performance on minority classes. This study comprehensively evaluates three widely-used strategies for handling class imbalance: Synthetic Minority Over-sampling Technique (SMOTE), Class Weights tuning, and Decision Threshold Calibration. We compare these methods against a baseline scenario of no-intervention across 15 diverse machine learning models and 30 datasets from various domains, conducting a total of 9,000 experiments. Performance was primarily assessed using the F1-score, although our study also tracked results on additional 9 metrics including F2-score, precision, recall, Brier-score, PR-AUC, and AUC. Our results indicate that all three strategies generally outperform the baseline, with Decision Threshold Calibration emerging as the most consistently effective technique. However, we observed substantial variability in the best-performing method across datasets, highlighting the importance of testing multiple approaches for specific problems. This study provides valuable insights for practitioners dealing with imbalanced datasets and emphasizes the need for dataset-specific analysis in evaluating class imbalance handling techniques. Comments:|13 pages including appendix, 4 tables|\\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)|\\nACMclasses:|I.2.6; I.5.1; I.5.2; I.2.m|\\nCite as:|[arXiv:2409.19751](https://arxiv.org/abs/2409.19751)[cs.LG]|\\n|(or[arXiv:2409.19751v1](https://arxiv.org/abs/2409.19751v1)[cs.LG]for this version)|\\n|[https://doi.org/10.48550/arXiv.2409.19751](https://doi.org/10.48550/arXiv.2409.19751)\\nFocus to learn more\\narXiv-issued DOI via DataCite\\n|\\n## Submission history\\nFrom: Abhyuday Desai [[view email](https://arxiv.org/show-email/43e3e529/2409.19751)]\\n**[v1]**Sun, 29 Sep 2024 16:02:32 UTC (18 KB)\\nFull-text links:## Access Paper:\\nView a PDF of the paper titled Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification, by Mohamed Abdelhamid and Abhyuday Desai\\n* [View PDF](https://arxiv.org/pdf/2409.19751)\\n* [HTML (experimental)](https://arxiv.org/html/2409.19751v1)\\n* [TeX Source](https://arxiv.org/src/2409.19751)\\n[![license icon](https://arxiv.org/icons/licenses/by-sa-4.0.png)view license](http://creativecommons.org/licenses/by-sa/4.0/)\\nCurrent browse context:\\ncs.LG\\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2409.19751&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2409.19751&amp;function=next&amp;context=cs.LG)\\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2024-09](https://arxiv.org/list/cs.LG/2024-09)\\nChange to browse by:\\n[cs](https://arxiv.org/abs/2409.19751?context=cs)\\n[cs.AI](https://arxiv.org/abs/2409.19751?context=cs.AI)\\n[stat](https://arxiv.org/abs/2409.19751?context=stat)\\n[stat.ML](https://arxiv.org/abs/2409.19751?context=stat.ML)\\n### References &amp; Citations\\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2409.19751)\\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2409.19751)\\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2409.19751)\\nexport BibTeX citationLoading...\\n## BibTeX formatted citation\\n&times;\\nloading...\\nData provided by:\\n### Bookmark\\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2409.19751&amp;description=Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2409.19751&amp;title=Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification>)\\nBibliographic Tools\\n# Bibliographic and Citation Tools\\nBibliographic Explorer Toggle\\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\\nConnected Papers Toggle\\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\\nLitmaps Toggle\\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\\nscite.ai Toggle\\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\\nCode, Data, Media\\n# Code, Data and Media Associated with this Article\\nalphaXiv Toggle\\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\\nLinks to Code Toggle\\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\\nDagsHub Toggle\\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\\nGotitPub Toggle\\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\\nHuggingface Toggle\\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\\nLinks to Code Toggle\\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\\nScienceCast Toggle\\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\\nDemos\\n# Demos\\nReplicate Toggle\\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\\nSpaces Toggle\\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\\nSpaces Toggle\\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\\nRelated Papers\\n# Recommenders and Search Tools\\nLink to Influence Flower\\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\\nCore recommender toggle\\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\\nIArxiv recommender toggle\\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\\n* Author\\n* Venue\\n* Institution\\n* Topic\\nAbout arXivLabs\\n# arXivLabs: experimental projects with community collaborators\\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to th...\", \"url\": \"https://arxiv.org/abs/2409.19751\"}]}",
        "tool.duration_ms": 3895.60866355896
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "99709f8cedb35a27",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "WebSearchTool",
      "kind": "INTERNAL",
      "start_time": 1767959034473848520,
      "end_time": 1767959038037959926,
      "duration": 3.564111406,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "WebSearchTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What feature engineering techniques work best for combining text and categorical meta-data features in Kaggle competitions?\"}}",
        "tool.output": "{\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nCombining free‚Äëform text with categorical meta‚Äëdata in Kaggle contests is most often tackled by turning the non‚Äëtext fields into a textual representation that a transformer can ingest directly.  A simple and surprisingly effective recipe is to join the raw text, numeric values and categorical labels into one string separated by a special token (e.g.,‚ÄØ`[SEP]`).  In FreeAgent‚Äôs bank‚Äëtransaction classifier the transaction description, amount and industry were concatenated as‚ÄØ`Plastic pipes [SEP] -7.99 [SEP] Plumbing`, allowing a single fine‚Äëtuned transformer to learn from all modalities at once‚ÄØ([engineering.freeagent.com](https://engineering.freeagent.com/2024/05/17/combining-text-with-numerical-and-categorical-features-for-classification)).  An even more natural variant is to prepend the categorical information to the review text, treating it as additional ‚Äúwords‚Äù.  In a Kaggle‚Äëstyle clothing‚Äëreview dataset this ‚Äúfeatures‚Äëto‚Äëtext‚Äù strategy consistently outperformed more elaborate baselines, showing that a straightforward textual conversion of meta‚Äëdata can be the strongest baseline for multimodal tabular‚Äëtext problems‚ÄØ([mccormickml.com](https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert)).\\n\\nA second, slightly richer approach keeps the modalities separate: the text is encoded with a pre‚Äëtrained transformer (or a TF‚ÄëIDF / hashing vectorizer) while categorical columns are transformed with embeddings, target‚Äëencoding, or one‚Äëhot vectors, and the resulting vectors are concatenated before feeding a downstream classifier (e.g., a shallow MLP or gradient‚Äëboosted tree).  FreeAgent‚Äôs experiments showed that this ‚Äúextract‚Äëtext‚Äëembedding‚ÄØ+‚ÄØconcatenate‚Äëother‚Äëfeatures‚Äù pipeline matches or exceeds the pure‚Äëstring method on a wine‚Äëreview classification task, indicating that preserving the numeric nature of fields can give the model clearer signals‚ÄØ([engineering.freeagent.com](https://engineering.freeagent.com/2024/05/17/combining-text-with-numerical-and-categorical-features-for-classification)).  In practice, Kaggle winners often start with the easy text‚Äëconcatenation trick to get a strong baseline, then iterate toward a hybrid pipeline that encodes categorical data more explicitly for the final performance boost.\\n\\n--- Result 2 ---\\nTitle: Combining text with numerical and categorical features for classification\\nURL: https://engineering.freeagent.com/2024/05/17/combining-text-with-numerical-and-categorical-features-for-classification\\n\\nContent:\\n[Skip to content](https://engineering.freeagent.com/engineering.freeagent.com#content)\\n\\n# Classification with transformer models\\n\\nA common approach for classification tasks with text data is to fine-tune a pre-trained transformer model on domain-specific data. At FreeAgent we apply this approach to [automatically categorise bank transactions](https://www.freeagent.com/blog/how-freeagent-uses-ai/), using raw inputs that are a mixture of text, numerical and categorical data types.\\n\\nThe current approach is to concatenate the input features for each transaction into a single string before passing to the model.\\n\\nFor example a transaction with the following set of features:\\n\\n|     |     |     |\\n| --- | --- | --- |\\n| **Description** | **Amount** | **Industry** |\\n| Plastic pipes | ¬£-7.99 | Plumbing |\\n\\ncould be represented by the string:¬† `Plastic pipes [SEP] -7.99 [SEP] Plumbing` with `[SEP]` being a special token indicating the boundaries between sentences, which is used to separate the features. This is a simple way to combine features that have yielded positive performance. We‚Äôve even noticed that the model exhibits unexpectedly good interpretations of the amount feature.\\n\\nThis approach however doesn‚Äôt feel like the most natural way to represent the information contained in a numerical feature like the transaction amount. An alternative approach is to use the transformer model to extract a vector representation of the text features, concatenate this with features extracted from non-text data types and pass the combination to a classifier.\\n\\nIn this post we compare the performance of these two approaches using a dataset of wine reviews to classify wines into 3 classes (neutral, good and excellent). Diagrams 1 and 2 below give an overview of the process for getting from input features to output categories in the two approaches.\\n\\nDiagram 1: Concatenating all inputs into a single string to fine-tune a base transformer model.\\n\\nDiagram 2: Preprocessing numerical and categorical features independently from the text, extracting the description vector representation and train a lightGBM classifier.\\n\\n# Public wine reviews dataset\\n\\nWe use the [Kaggle wine reviews dataset](https://www.kaggle.com/datasets/zynicide/wine-reviews) for this experiment, which contains a variety of descriptive features for just under 130,000 wines, including a wine score. The wine score is a number between 1-100, with 100 being the best, although this dataset only includes reviews for wines that score over 80. For the purpose of this blog post, we created the wine rating from the scores ‚Äì wines between 80 and 86 (incl) were flagged as ‚Äúneutral‚Äù, between 87 and 93 as ‚Äúgood‚Äù and greater than 94 as ‚Äúexcellent‚Äù.\\n\\nTo keep things simple we will use just the wine description, price and variety to attempt to classify the wines into these 3 ratings.\\n\\nWe loaded the data and created a target variable `rating` to split the wine scores into the 3 target categories (neutral, good, excellent).\\n\\n```\\nimport pandas as pd\\n\\nwine_df = pd.read_csv(\\\"data/wine_data.csv\\\")\\nbins = [0, 87, 94, np.inf]\\nnames = [\\\"neutral\\\", \\\"good\\\", \\\"excellent\\\"]\\n\\nwine_df[\\\"rating\\\"] = pd.cut(wine_df[\\\"points\\\"], bins, labels=names)\\n\\n```\\n\\nWe can then keep a DataFrame of the features and target. For the purpose of putting together this example we have limited the model input features to the wine variety (the type of grapes used to make the wine), the price (cost for a bottle of wine) and the wine description.\\n\\n```\\nNUMERICAL_FEATURE = \\\"price\\\"\\nCATEGORICAL_FEATURE = \\\"variety\\\"\\nTEXT_FEATURE = \\\"description\\\"\\nTARGET = \\\"rating\\\"\\nFEATURES = [TEXT_FEATURE, NUMERICAL_FEATURE, CATEGORICAL_FEATURE]\\n\\nwine_df = wine_df[FEATURES + [TARGET]]\\n\\n```\\n\\nWe then split our wine dataframe into an 80:20 training:evaluation split.\\n\\n```\\nfrom sklearn.model_selection import train_test_split\\n\\ntrain_df, test_df = train_test_split(wine_df, test_size=0.2)\\n\\n```\\n\\n## LightGBM classifier approach\\n\\n### Preprocessing\\n\\n#### Preprocessing numerical and categorical features\\n\\nIn a first step we will preprocess the numerical and categorical features using SKLearn‚Äôs ColumnTransformer.¬† For the numerical features (price) we decided to fill missing values using the median wine price and scale them using a StandardScaler.\\n\\nWe preprocessed the categorical features by filling missing values with ‚Äúother‚Äù and OneHot encoded them.\\n\\nWe saved the output of the ColumnTransformer as a pandas DataFrame to concatenate it later with the vector representation of the text.\\n\\n```\\nimport numpy as np\\n\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.pipeline import make_pipeline\\nfrom sklearn.preprocessing import (\\n    OneHotEncoder,\\n    StandardScaler,\\n)\\n\\ndef preprocess_number():\\n    return make_pipeline(\\n        SimpleImputer(strategy=\\\"median\\\"),\\n        StandardScaler(),\\n    )\\n\\ndef preprocess_categories():\\n    return make_pipeline(\\n       SimpleImputer(strategy=\\\"constant\\\", fill_value=\\\"other\\\", missing_values=np.nan),\\n       OneHotEncoder(handle_unknown=\\\"ignore\\\", sparse_output=False),\\n    )\\n\\ndef create_preprocessor():\\n\\n    transformers = [\\n        (\\\"num_preprocessor\\\", preprocess_number(), [NUMERICAL_FEATURE]),\\n        (\\\"cat_preprocessor\\\", preprocess_categories(), [CATEGORICAL_FEATURE]),\\n    ]\\n\\n    return ColumnTransformer(transformers=transformers, remainder=\\\"drop\\\")\\n\\ncolumn_transformer = create_preprocessor()\\ncolumn_transformer.set_output(transform=\\\"pandas\\\")\\npreprocessed_num_cat_features_df = column_transformer.fit_transform(\\n    train_df[[NUMERICAL_FEATURE, CATEGORICAL_FEATURE]]\\n)\\n\\n```\\n\\n#### Extracting text vector representation with a transformer model\\n\\nWe then moved on to the preprocessing of the text features. We decided to use `distilbert-base-uncased` as the base transformer model to extract the vector representation of the wine description.\\n\\nBERT-type models use stacks of [transformer encoder layers](https://arxiv.org/pdf/1706.03762.pdf). Each of these blocks processes the tokenized text through a multi-headed self-attention step and a feed-forward neural network, before passing outputs to the next layer. The hidden state is the output of a given layer. The \\\\[CLS\\\\] token (short for classification) is a special token that represents an entire text sequence. We choose the hidden state of the \\\\[CLS\\\\] token in the final layer as the vector representation of our wine descriptions.\\n\\nIn order to extract the \\\\[CLS\\\\] representations, we first transform the text inputs into a Dataset of tokenized PyTorch tensors.\\n\\nFor this step we tokenized batches of 128 wine descriptions padded to a fixed length of 120 suitable for our wine descriptions of ~40 words. The max\\\\_length is one of the parameters which should be adjusted depending on the length of the text feature to prevent truncating longer inputs. The padding is necessary to ensure we will process fixed-shape inputs with the transformer model. The tokenizer returns a dictionary of input\\\\_ids, attention\\\\_mask and token\\\\_type\\\\_ids. Only the input\\\\_ids (the indices of each token in the wine description) and the attention mask (binary tensor indicating the position of the padded indice) are required inputs to the model.\\n\\nThe code for the tokenization is shown below:\\n\\n```\\nfrom datasets import Dataset\\nfrom transformers import AutoTokenizer\\n\\nMODEL_NAME = \\\"distilbert-base-uncased\\\"\\n\\ndef tokenized_pytorch_tensors(\\n        df: pd.DataFrame,\\n        column_list: list\\n    ) -> Dataset:\\n\\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\\n    transformers_dataset = Dataset.from_pandas(df)\\n\\n    def tokenize(model_inputs_batch: Dataset) -> Dataset:\\n        return tokenizer(\\n            model_inputs_batch[TEXT_FEATURE],\\n            padding=True,\\n            max_length=120,\\n            truncation=True,\\n        )\\n\\n    tokenized_dataset = transformers_dataset.map(\\n        tokenize,\\n        batched=True,\\n        batch_size=128\\n    )\\n\\n    tokenized_dataset.set_format(\\n        \\\"torch\\\",\\n        columns=column_list\\n    )\\n\\n    columns_t...\\n\\n--- Result 3 ---\\nURL: https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert\\n\\nContent:\\n# Combining Categorical and Numerical Features with Text in BERT\\n\\n29 Jun 2021\\n\\nIn this tutorial we‚Äôll look at the topic of classifying text with BERT, but where we also have additional numerical or categorical features that we want to use to improve our predictions.\\n\\nTo help motivate our discussion, we‚Äôll be working with a dataset of about 23k clothing reviews. For each review, we have the review text, but also additional information such as:\\n\\n- The age of the reviewer (numerical feature)\\n- The number of upvotes on the review (numerical feature)\\n- The department and category of the clothing item (categorical features)\\n\\nFor each review, we also have a binary label, which is whether or not the reviewer ultimately recommends the item. This is what we are trying to predict.\\n\\nThis dataset was scraped from an (un-specified) e-commerce website by Nick Brooks and made available on Kaggle [here](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews).\\n\\nIn Section 2 of this Notebook, I‚Äôve implemented four different ‚Äúbaseline‚Äù strategies which score fairly well, but which don‚Äôt incorporate all of the features together.\\n\\nThen, in Section 3, I‚Äôve implemented a simple strategy to combine _everything_ and feed it through BERT. Specifically, I make text out of the additional features, and prepend this text to the review.\\n\\nThere is a GitHub project called the [Multimodal-Toolkit](https://github.com/georgian-io/Multimodal-Toolkit) which is how I learned about this clothing review dataset. The toolkit implements a number of more complicated techniques, but their benchmarks (as well as our results below) show that this simple features-to-text strategy works best for this dataset.\\n\\nIn our weekly discussion group, I talked through this Notebook and we also met with Ken Gu, the author of the Multi-Modal Toolkit! You can watch the recording [here](https://youtu.be/XPt9pIpe1vo).\\n\\nYou can find the Colab Notebook version of this post [here](https://colab.research.google.com/drive/1YRHK4HO8RktGzlYmGjBo056kzVD4_j9o).\\n\\nBy Chris McCormick\\n\\n# Contents\\n\\n- [Contents](https://mccormickml.com/mccormickml.com#contents)\\n- [S1. Clothing Review Dataset](https://mccormickml.com/mccormickml.com#s1-clothing-review-dataset)\\n  - [1.1. Download & Parse](https://mccormickml.com/mccormickml.com#11-download--parse)\\n  - [1.2. Train-Validation-Test Split](https://mccormickml.com/mccormickml.com#12-train-validation-test-split)\\n- [S2. Baseline Strategies](https://mccormickml.com/mccormickml.com#s2-baseline-strategies)\\n  - [2.1. Always Recommend](https://mccormickml.com/mccormickml.com#21-always-recommend)\\n  - [2.2. Threshold on Rating](https://mccormickml.com/mccormickml.com#22-threshold-on-rating)\\n  - [2.3. XGBoost](https://mccormickml.com/mccormickml.com#23-xgboost)\\n  - [2.4. BERT on Review Text Only](https://mccormickml.com/mccormickml.com#24-bert-on-review-text-only)\\n- [S3. BERT with All Features](https://mccormickml.com/mccormickml.com#s3-bert-with-all-features)\\n  - [3.1. All Features to Text](https://mccormickml.com/mccormickml.com#31-all-features-to-text)\\n  - [3.2. GPU & Transformers Setup](https://mccormickml.com/mccormickml.com#32-gpu--transformers-setup)\\n  - [3.3. Training Parameters](https://mccormickml.com/mccormickml.com#33-training-parameters)\\n  - [3.3. Tokenize & Encode](https://mccormickml.com/mccormickml.com#33-tokenize--encode)\\n  - [3.4. Training](https://mccormickml.com/mccormickml.com#34-training)\\n    - [3.4.1. Setup](https://mccormickml.com/mccormickml.com#341-setup)\\n    - [3.4.2. Training Loop](https://mccormickml.com/mccormickml.com#342-training-loop)\\n    - [3.4.3. Training Results](https://mccormickml.com/mccormickml.com#343-training-results)\\n  - [3.5. Test](https://mccormickml.com/mccormickml.com#35-test)\\n- [Conclusion](https://mccormickml.com/mccormickml.com#conclusion)\\n\\n# S1. Clothing Review Dataset\\n\\n## 1.1. Download & Parse\\n\\nRetrieve the .csv file for the dataset.\\n\\n```\\nimport gdown\\n\\nprint('Downloading dataset...\\\\n')\\n\\n# Download the file.\\ngdown.download('https://drive.google.com/uc?id=1ZYdt0zN4LjWqP3cQDblNhXjeohcryY5H',\\n                'Womens Clothing E-Commerce Reviews.csv',\\n                quiet=False)\\n\\nprint('\\\\n\\\\nDONE.')\\n```\\n\\n```\\nDownloading dataset...\\n\\nDownloading...\\nFrom: https://drive.google.com/uc?id=1ZYdt0zN4LjWqP3cQDblNhXjeohcryY5H\\nTo: /content/Womens Clothing E-Commerce Reviews.csv\\n8.48MB [00:00, 48.7MB/s]\\n\\nDONE.\\n\\n```\\n\\nParse the dataset csv file into a pandas DataFrame.\\n\\n```\\nimport pandas as pd\\n\\ndata_df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv', index_col=0)\\n\\ndata_df.head()\\n```\\n\\n| Clothing ID | Age | Title | Review Text | Rating | Recommended IND | Positive Feedback Count | Division Name | Department Name | Class Name |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 767 | 33 | NaN | Absolutely wonderful - silky and sexy and comf... | 4 | 1 | 0 | Initmates | Intimate | Intimates |\\n| 1 | 1080 | 34 | NaN | Love this dress! it's sooo pretty. i happene... | 5 | 1 | 4 | General | Dresses | Dresses |\\n| 2 | 1077 | 60 | Some major design flaws | I had such high hopes for this dress and reall... | 3 | 0 | 0 | General | Dresses | Dresses |\\n| 3 | 1049 | 50 | My favorite buy! | I love, love, love this jumpsuit. it's fun, fl... | 5 | 1 | 0 | General Petite | Bottoms | Pants |\\n| 4 | 847 | 47 | Flattering shirt | This shirt is very flattering to all due to th... | 5 | 1 | 6 | General | Tops | Blouses |\\n\\n_Features_\\n\\n‚Äú **Recommended IND**‚Äù is the label we are trying to predict for this dataset. ‚Äú1‚Äù means the reviewer recommended the product and ‚Äú0‚Äù means they do not.\\n\\nThe following are _categorical_ features:\\n\\n- Division Name\\n- Department Name\\n- Class Name\\n- Clothing ID\\n\\nAnd the following are _numerical_ features:\\n\\n- Age\\n- Rating\\n- Positive Feedback Count\\n\\n_Feature Analysis_\\n\\nThere is an excellent Notebook on Kaggle [here](https://www.kaggle.com/bhaveshkumar2806/complete-eda-and-visualization-of-text-data) which does some thorough analysis on each of the features in this dataset.\\n\\nNote that, in addition to the ‚ÄúRecommended‚Äù label, there is also a ‚Äú **Rating**‚Äù column where the reviewer rates the product from 1 - 5. The analysis in the above Notebook shows that almost all items rated 3 - 5 are recommended, and almost all rated 1 - 2 are not recommended. We‚Äôll see in our second baseline classifier that you can get a very high accuracy with this feature alone. However, it _is_ still possible to do better by incorporating the other features!\\n\\n## 1.2. Train-Validation-Test Split\\n\\nI want to use the same training, validation, and test splits for all of the approaches we try so that it‚Äôs a fair comparison.\\n\\nHowever, different approaches are going to require different transformations on the data, and for simplicity I want to apply those transformations _before_ splitting the dataset.\\n\\nTo solve this, we‚Äôre going to create lists of indeces for each of the three portions. That way, for a given classification approach, we can load the whole dataset, apply our transformations, and then split it according to these pre-determined indeces.\\n\\n```\\nimport random\\nimport numpy as np\\n\\n# First, calculate the split sizes. 80% training, 10% validation, 10% test.\\ntrain_size = int(0.8 * len(data_df))\\nval_size = int(0.1 * len(data_df))\\ntest_size = len(data_df) - (train_size + val_size)\\n\\n# Sanity check the sizes.\\nassert((train_size + val_size + test_size) == len(data_df))\\n\\n# Create a list of indeces for all of the samples in the dataset.\\nindeces = np.arange(0, len(data_df))\\n\\n# Shuffle the indeces randomly.\\nrandom.shuffle(indeces)\\n\\n# Get a list of indeces for each of the splits.\\ntrain_idx = indeces[0:train_size]\\nval_idx = indeces[train_size:(train_size + val_size)]\\ntest_idx = indeces[(train_size + val_size):]\\n\\n# Sanity check\\nassert(len(train_idx) == train_size)\\nassert(len(test_idx) == test_size)\\n\\n# With these lists, we can now select the corresponding dataframe rows using,\\n# e.g., train_df = data_df.iloc[train_idx]\\n\\nprint('  Training size: {:,}'.format(train_size))\\n...\\n\\n--- Result 4 ---\\nTitle: A Reference Guide to Feature Engineering Methods | Kaggle\\nURL: https://www.kaggle.com/code/prashant111/a-reference-guide-to-feature-engineering-methods\\n\\nContent:\\nA Reference Guide to Feature Engineering Methods | Kaggle\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n[\\nLearn more\\n](https://www.kaggle.com/cookies)\\nOK, Got it.\\n![Something went wrong and this page crashed!](https://www.kaggle.com/static/images/error/server-error-illo_light.svg)###### Something went wrong and this page crashed!\\nIf the issue persists, it's likely a problem on our side.\\n```\\nLoading CSS chunk 1019 failed.\\\\\\\\n(https://www.kaggle.com/static/assets/KernelViewer.21f94db0016b9074.css)\\nkeyboard\\\\_arrow\\\\_upcontent\\\\_copy\\nError: Loading CSS chunk 1019 failed.\\\\\\\\n(https://www.kaggle.com/static/assets/KernelViewer.21f94db0016b9074.css)\\nat t.onerror.t.onload (https://www.kaggle.com/static/assets/runtime.js?v=a6aef772a946d7d4:1:10006)\\n```\\nRefresh\\n\\n--- Result 5 ---\\nTitle: Grandmaster Pro Tip: Winning First Place in Kaggle Competition with Feature Engineering Using cuDF pandas\\nURL: https://developer.nvidia.com/blog/grandmaster-pro-tip-winning-first-place-in-kaggle-competition-with-feature-engineering-using-nvidia-cudf-pandas\\n\\nContent:\\nGrandmaster Pro Tip: Winning First Place in Kaggle Competition with Feature Engineering Using cuDF pandas | NVIDIA Technical Blog\\n[](https://developer.nvidia.com/)[DEVELOPER](https://developer.nvidia.com/)\\n[Technical Blog](https://developer.nvidia.com/blog)\\n[Subscribe](https://developer.nvidia.com/email-signup)\\n[Related Resources**](#main-content-end)\\n[Data Science](https://developer.nvidia.com/blog/category/data-science/)\\nEnglish‰∏≠Êñá\\n# Grandmaster Pro Tip: Winning First Place in Kaggle Competition with Feature Engineering Using cuDF pandas\\n![](https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/NVIDIA-feature-engineering-kaggle-blog-1024x576.jpg)\\nApr 17, 2025\\nBy[Chris Deotte](https://developer.nvidia.com/blog/author/cdeotte/)\\n**\\nLike\\n[**Discuss (1)](#entry-content-comments)\\n* [L](https://www.linkedin.com/sharing/share-offsite/?url=https://developer.nvidia.com/blog/grandmaster-pro-tip-winning-first-place-in-kaggle-competition-with-feature-engineering-using-nvidia-cudf-pandas/)\\n* [T](https://twitter.com/intent/tweet?text=Grandmaster+Pro+Tip:+Winning+First+Place+in+Kaggle+Competition+with+Feature+Engineering+Using+cuDF+pandas+|+NVIDIA+Technical+Blog+https://developer.nvidia.com/blog/grandmaster-pro-tip-winning-first-place-in-kaggle-competition-with-feature-engineering-using-nvidia-cudf-pandas/)\\n* [F](https://www.facebook.com/sharer/sharer.php?u=https://developer.nvidia.com/blog/grandmaster-pro-tip-winning-first-place-in-kaggle-competition-with-feature-engineering-using-nvidia-cudf-pandas/)\\n* [R](https://www.reddit.com/submit?url=https://developer.nvidia.com/blog/grandmaster-pro-tip-winning-first-place-in-kaggle-competition-with-feature-engineering-using-nvidia-cudf-pandas/&amp;title=Grandmaster+Pro+Tip:+Winning+First+Place+in+Kaggle+Competition+with+Feature+Engineering+Using+cuDF+pandas+|+NVIDIA+Technical+Blog)\\n* [E](<mailto:?subject=I'd like to share a link with you&body=https://developer.nvidia.com/blog/grandmaster-pro-tip-winning-first-place-in-kaggle-competition-with-feature-engineering-using-nvidia-cudf-pandas/>)\\nAI-Generated Summary\\nLike\\nDislike\\n* Using NVIDIA cuDF-pandas to accelerate pandas operations on GPUs allowed for the rapid generation and testing of over 10,000 engineered features for a Kaggle competition, significantly boosting the accuracy of an XGBoost model.\\n* The most effective feature engineering techniques included groupby aggregations, such as computing statistics (e.g., mean, std, count) and quantiles, as well as creating new columns from NaNs and binning numerical columns.\\n* Techniques like extracting digits from float32 values and combining categorical columns also proved useful, and leveraging the original dataset that the synthetic data was created from provided additional predictive power.\\nAI-generated content may summarize information incompletely. Verify important information.[Learn more](https://www.nvidia.com/en-us/agreements/trustworthy-ai/terms/)\\nFeature engineering remains one of the most effective ways to improve model accuracy when working with tabular data. Unlike domains such as NLP and computer vision, where neural networks can extract rich patterns from raw inputs, the best-performing tabular models‚Äîparticularly gradient-boosted decision trees‚Äîstill gain a significant advantage from well-crafted features. However, the sheer potential number of useful features means that exploring them thoroughly is often computationally prohibitive. Trying to generate and validate hundreds or thousands of feature ideas using standard pandas on a CPU is simply too slow to be practical.\\nThis is where GPU acceleration changes the game. Using NVIDIA cuDF-pandas, which accelerates pandas operations on GPUs with zero code changes, allowed me to rapidly generate and test over 10,000 engineered features for Kaggle‚Äôs February playground competition. This accelerated discovery process was the key differentiator. In a drastically reduced timeframe &#8211; days instead of potential months &#8211;¬†the best 500 discovered features significantly boosted the accuracy of my XGBoost model, securing 1st place in the competition predicting backpack prices. Below, I share the core feature engineering techniques, accelerated by cuDF-pandas, that led to this result.\\n## Groupby(COL1)[COL2].agg(STAT)[**](#groupbycol1col2aggstat)\\nThe most powerful feature engineering technique is groupby aggregations. Namely, we execute the code`groupby(COL1)[COL2].agg(STAT)`. This is where we group by`COL1`column and aggregate (i.e. compute) a statistic`STAT`over another column`COL2`. We use the speed of NVIDIA cuDF-Pandas to explore thousands of`COL1`,`COL2`,`STAT`combinations. We try statistics (`STAT`) like &#8220;mean&#8221;, &#8220;std&#8221;, &#8220;count&#8221;, &#8220;min&#8221;, &#8220;max&#8221;, &#8220;nunique&#8221;, &#8220;skew&#8221; etc etc. We choose`COL1`and`COL2`from our tabular data‚Äôs existing columns. When`COL2`is the target column, then we use nested cross-validation to avoid leakage in our validation computation. When`COL2`is the target, this operation is called Target Encoding.\\n## Groupby(COL1)[&#8216;Price&#8217;].agg(HISTOGRAM BINS)[**](#groupbycol1&#8216;price&#8217;agghistogram_bins)\\nWhen we`groupby(COL1)[COL2]`we have a distribution (set) of numbers for each group. Instead of computing a single statistic (and making one new column), we can compute any collection of numbers that describe this distribution of numbers and make many new columns together.\\nBelow we display a histogram for the group`Weight Capacity = 21.067673`. We can count the number of elements in each (equally spaced) bucket and create a new engineered feature for each bucket count to return to the groupby operation! Below we display seven buckets, but we can treat the number of buckets as a hyperparameter.\\n```\\nresult = X\\\\_train2.groupby(&quot;&quot;WC&quot;&quot;)&#x5B;&#x5B;&quot;&quot;Price&quot;&quot;].apply(make\\\\_histogram)\\nX\\\\_valid2 = X\\\\_valid2.merge(result, on=&quot;&quot;WC&quot;&quot;, how=&quot;&quot;left&quot;&quot;)\\n```\\n*Figure 1. Histogram of price values when weight capacity equals 21.067673*\\n## Groupby(COL1)[&#8216;Price&#8217;].agg(QUANTILES)[**](#groupbycol1&#8216;price&#8217;aggquantiles)\\nWe can groupby and compute the quantiles for`QUANTILES = [5,10,40,45,55,60,90,95]`and return the eight values to create eight new columns.\\n```\\nfor k in QUANTILES:\\nresult = X\\\\_train2.groupby(&#039;&#039;Weight Capacity (kg)&#039;&#039;).\\\\\\\\\\nagg({&#039;&#039;Price&#039;&#039;: lambda x: x.quantile(k/100)})\\n```\\n## All NANs as Single Base-2 Column[**](#all_nans_as_single_base-2_column)\\nWe can create a new column from all the NANs over multiple columns. This is a powerful column which we can subsequently use for groupby aggregations or combinations with other columns.\\n```\\ntrain&#x5B;&#x5B;&quot;&quot;NaNs&quot;&quot;] = np.float32(0)\\nfor i,c in enumerate(CATS):\\ntrain&#x5B;&#x5B;&quot;&quot;NaNs&quot;&quot;] += train&#x5B;&#x5B;c].isna()\\\\*2\\\\*\\\\*i\\n```\\n## Put Numerical Column into Bins[**](#put_numerical_column_into_bins)\\nThe most powerful (predictive) column in this competition is Weight Capacity. We can create more powerful columns based on this column by binning this column with rounding.\\n```\\nfor k in range(7,10):\\nn = f&quot;round{k}&quot;\\ntrain&#x5B;n] = train&#x5B;&quot;Weight Capacity (kg)&quot;].round(k)\\n```\\n## Extract Float32 as Digits[**](#extract_float32_as_digits)\\nThe most powerful (predictive) column in this competition is Weight Capacity. We can create more powerful columns based on this column by extracting digits. This technique seems weird, but it is often used to extract info from a product ID where individual digits within a product ID convey info about a product such as brand, color, etc.\\n```\\nfor k in range(1,10):\\ntrain&#x5B;&#x5B;f&#039;&#039;digit{k}&#039;&#039;] = ((train&#x5B;&#x5B;&#039;&#039;Weight Capacity (kg)&#039;&#039;] \\\\* 10\\\\*\\\\*k) % 10).fillna(-1).astype(&quot;&quot;int8&quot;&quot;)\\n```\\n## Combination of Categorical Columns[**](#combination_of_...\\n\\n--- Result 6 ---\\nTitle: Feature Engineering with Kaggle Tutorial\\nURL: https://www.datacamp.com/tutorial/feature-engineering-kaggle\\n\\nContent:\\n[![Data and AI Literacy 2024 ](https://images.datacamp.com/Marketing/Oneoffs/data-literacy-2024/lockup-banner-data-ai-literacy.png)\\\\\\n\\\\\\n**The State of Data & AI Literacy 2024** \\\\\\n\\\\\\nDownload Now](https://www.datacamp.com/report/data-ai-literacy-report-2024)\\n\\n[Skip to main content](https://www.datacamp.com/tutorial/feature-engineering-kaggle#main)\\n\\nIn the two previous Kaggle tutorials, you learned all about how to get your data in a form to build your first machine learning model, using [Exploratory Data Analysis and baseline machine learning models](https://www.datacamp.com/tutorial/kaggle-machine-learning-eda). Next, you successfully managed to [build your first machine learning model](https://www.datacamp.com/tutorial/kaggle-tutorial-machine-learning), a decision tree classifier. You submitted all these models to Kaggle and interpreted their accuracy.\\n\\nIn this third tutorial, you'll learn more about feature engineering, a process where you use domain knowledge of your data to create additional relevant features that increase the predictive power of the learning algorithm and make your machine learning models perform even better!\\n\\nMore specifically,\\n\\n- You'll first [get started](https://www.datacamp.com/tutorial/feature-engineering-kaggle#getting-started!) by doing all necessary imports and getting the data in your workspace;\\n- Then, you'll see some reasons why you should do [feature engineering](https://www.datacamp.com/tutorial/feature-engineering-kaggle#why-feature-engineer-at-all?) and start working on engineering your own new features for your data set! You'll create new columns, transform variables into numerical ones, handle missing values, and much more.\\n- Lastly, you'll [build a new machine learning model](https://www.datacamp.com/tutorial/feature-engineering-kaggle#building-models-with-your-new-data-set!) with your new data set and submit it to Kaggle.\\n\\n## Getting Started!\\n\\nBefore you can start off, you're going to do all the imports, just like you did in the previous tutorial, use some IPython magic to make sure the figures are generated inline in the Jupyter Notebook and set the visualization style. Next, you can import your data and make sure that you store the target variable of the training data in a safe place. Afterwards, you merge the train and test data sets (with exception of the `'Survived'` column of `df_train`) and store the result in `data`.\\n\\n**Remember** that you do this because you want to make sure that any preprocessing that you do on the data is reflected in both the train and test sets!\\n\\nLastly, you use the `.info()` method to take a look at your data:\\n\\n```\\n\\n# Imports\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport re\\nimport numpy as np\\nfrom sklearn import tree\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Figures inline and set visualization style\\n%matplotlib inline\\nsns.set()\\n\\n# Import data\\ndf_train = pd.read_csv('data/train.csv')\\ndf_test = pd.read_csv('data/test.csv')\\n\\n# Store target variable of training data in a safe place\\nsurvived_train = df_train.Survived\\n\\n# Concatenate training and test sets\\ndata = pd.concat([df_train.drop(['Survived'], axis=1), df_test])\\n\\n# View head\\ndata.info()\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\n```\\n\\n<class 'pandas.core.frame.DataFrame'>\\nInt64Index: 1309 entries, 0 to 417\\nData columns (total 11 columns):\\nPassengerId    1309 non-null int64\\nPclass         1309 non-null int64\\nName           1309 non-null object\\nSex            1309 non-null object\\nAge            1046 non-null float64\\nSibSp          1309 non-null int64\\nParch          1309 non-null int64\\nTicket         1309 non-null object\\nFare           1308 non-null float64\\nCabin          295 non-null object\\nEmbarked       1307 non-null object\\ndtypes: float64(2), int64(4), object(5)\\nmemory usage: 122.7+ KB\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\n## Why Feature Engineer at all?\\n\\nYou perform feature engineering to extract more information from your data, so that you can up your game when building models.\\n\\n### Titanic's Passenger Titles\\n\\nLet's check out what this is all about by looking at an example. Let's check out the `'Name'` column with the help of the `.tail()` method, which helps you to see the last five rows of your data:\\n\\n```\\n\\n# View head of 'Name' column\\ndata.Name.tail()\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\n```\\n\\n413              Spector, Mr. Woolf\\n414    Oliva y Ocana, Dona. Fermina\\n415    Saether, Mr. Simon Sivertsen\\n416             Ware, Mr. Frederick\\n417        Peter, Master. Michael J\\nName: Name, dtype: object\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\nSuddenly, you see different titles emerging! In other words, this column contains strings or text that contain titles, such as 'Mr', 'Master' and 'Dona'.\\n\\nThese titles of course give you information on social status, profession, etc., which in the end could tell you something more about survival.\\n\\nAt first sight, it might seem like a difficult task to separate the names from the titles, but don't panic! Remember, you can easily use regular expressions to extract the title and store it in a new column `'Title'`:\\n\\n```\\n\\n# Extract Title from Name, store in column and plot barplot\\ndata['Title'] = data.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\\\.', x).group(1))\\nsns.countplot(x='Title', data=data);\\nplt.xticks(rotation=45);\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\n![bar chart](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1515151833/output_5_0_d77zb9.png)\\n\\n**Note** that this new column `'Title'` is actually a new feature for your data set!\\n\\n**Tip**: to learn more about regular expressions, check out my write up of our last [FB Live code along event](https://www.datacamp.com/tutorial/web-scraping-python-nlp) or check out DataCamp's [Python Regular Expressions Tutorial](https://www.datacamp.com/tutorial/python-regular-expression-tutorial).\\n\\nYou can see that there are several titles in the above plot and there are many that don't occur so often. So, it makes sense to put them in fewer buckets.\\n\\nFor example, you probably want to replace `'Mlle'` and `'Ms'` with `'Miss'` and `'Mme'` by `'Mrs'`, as these are French titles and ideally, you want all your data to be in one language. Next, you also take a bunch of titles that you can't immediately categorize and put them in a bucket called `'Special'`.\\n\\n**Tip**: play around with this to see how your algorithm performs as a function of it!\\n\\nNext, you view a barplot of the result with the help of the `.countplot()` method:\\n\\n```\\n\\ndata['Title'] = data['Title'].replace({'Mlle':'Miss', 'Mme':'Mrs', 'Ms':'Miss'})\\ndata['Title'] = data['Title'].replace(['Don', 'Dona', 'Rev', 'Dr',\\n                                            'Major', 'Lady', 'Sir', 'Col', 'Capt', 'Countess', 'Jonkheer'],'Special')\\nsns.countplot(x='Title', data=data);\\nplt.xticks(rotation=45);\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\n![bar chart](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1515151833/output_7_0_vdtvcz.png)\\n\\nThis is what your newly engineered feature `'Title'` looks like!\\n\\nNow, make sure that you have a `'Title'` column and check out your data again with the `.tail()` method:\\n\\n```\\n\\n# View head of data\\ndata.tail()\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\n|  | PassengerId | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked | Title |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 413 | 1305 | 3 | Spector, Mr. Woolf | male | NaN | 0 | 0 | A.5. 3236 | 8.0500 | NaN | S | Mr |\\n| 414 | 1306 | 1 | Oliva y Ocana, Dona. Fermina | female | 39.0 | 0 | 0 | PC 17758 | 108.9000 | C105 | C | Special |\\n| 415 | 1307 | 3 | Saether, Mr. Simon Sivertsen | male | 38.5 | 0 | 0 | SOTON/O.Q. 3101262 | 7.2500 | NaN | S | Mr |\\n| 416 | 1308 | 3 | Ware, Mr. Frederick | male | NaN | 0 | 0 | 359309 | 8.0500 | NaN | S | Mr |\\n| 417 | 1309 | 3 | Peter, Master. Michael J | male | NaN | 1 | 1 | 2668 | 22.3583 | NaN | C | Master |\\n\\n### Passenger's Cabins\\n\\nWhen you loaded in the ...\\n\\n--- Result 7 ---\\nTitle: Search code, repositories, users, issues, pull requests...\\nURL: https://github.com/bangdasun/kaggle_learn\\n\\nContent:\\nGitHub - bangdasun/kaggle\\\\_learn: Functions used in kaggle competitions: data preprocessing/feature engineering/model training etc. Many of these functions are collected from kaggle community, credits are belong to the authors :)\\n[Skip to content](#start-of-content)\\n## Navigation Menu\\nToggle navigation\\n[](https://github.com/)\\n[Sign in](https://github.com/login?return_to=https://github.com/bangdasun/kaggle_learn)\\nAppearance settings\\nSearch or jump to...\\n# Search code, repositories, users, issues, pull requests...\\n</option></form>\\nSearch\\nClear\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n# Provide feedback\\n</option></form>\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancelSubmit feedback\\n# Saved searches\\n## Use saved searches to filter your results more quickly\\n</option></form>\\nName\\nQuery\\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\nCancelCreate saved search\\n[Sign in](https://github.com/login?return_to=https://github.com/bangdasun/kaggle_learn)\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=bangdasun/kaggle_learn)\\nAppearance settings\\nResetting focus\\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\\n{{ message }}\\n[bangdasun](https://github.com/bangdasun)/**[kaggle\\\\_learn](https://github.com/bangdasun/kaggle_learn)**Public\\n* [Notifications](https://github.com/login?return_to=/bangdasun/kaggle_learn)You must be signed in to change notification settings\\n* [Fork15](https://github.com/login?return_to=/bangdasun/kaggle_learn)\\n* [Star11](https://github.com/login?return_to=/bangdasun/kaggle_learn)\\nFunctions used in kaggle competitions: data preprocessing/feature engineering/model training etc. Many of these functions are collected from kaggle community, credits are belong to the authors :)\\n### License\\n[MIT license](https://github.com/bangdasun/kaggle_learn/blob/develop/LICENSE)\\n[11stars](https://github.com/bangdasun/kaggle_learn/stargazers)[15forks](https://github.com/bangdasun/kaggle_learn/forks)[Branches](https://github.com/bangdasun/kaggle_learn/branches)[Tags](https://github.com/bangdasun/kaggle_learn/tags)[Activity](https://github.com/bangdasun/kaggle_learn/activity)\\n[Star](https://github.com/login?return_to=/bangdasun/kaggle_learn)\\n[Notifications](https://github.com/login?return_to=/bangdasun/kaggle_learn)You must be signed in to change notification settings\\n# bangdasun/kaggle\\\\_learn\\ndevelop\\n[Branches](https://github.com/bangdasun/kaggle_learn/branches)[Tags](https://github.com/bangdasun/kaggle_learn/tags)\\n[](https://github.com/bangdasun/kaggle_learn/branches)[](https://github.com/bangdasun/kaggle_learn/tags)\\nGo to file\\nCode\\nOpen more actions menu\\n## Folders and files\\n|Name|Name|\\nLast commit message\\n|\\nLast commit date\\n|\\n## Latest commit\\n## History\\n[66 Commits](https://github.com/bangdasun/kaggle_learn/commits/develop/)\\n[](https://github.com/bangdasun/kaggle_learn/commits/develop/)\\n|\\n[feature\\\\_engineering](https://github.com/bangdasun/kaggle_learn/tree/develop/feature_engineering)\\n|\\n[feature\\\\_engineering](https://github.com/bangdasun/kaggle_learn/tree/develop/feature_engineering)\\n|\\n|\\n|\\n[feature\\\\_importance](https://github.com/bangdasun/kaggle_learn/tree/develop/feature_importance)\\n|\\n[feature\\\\_importance](https://github.com/bangdasun/kaggle_learn/tree/develop/feature_importance)\\n|\\n|\\n|\\n[metrics](https://github.com/bangdasun/kaggle_learn/tree/develop/metrics)\\n|\\n[metrics](https://github.com/bangdasun/kaggle_learn/tree/develop/metrics)\\n|\\n|\\n|\\n[model](https://github.com/bangdasun/kaggle_learn/tree/develop/model)\\n|\\n[model](https://github.com/bangdasun/kaggle_learn/tree/develop/model)\\n|\\n|\\n|\\n[model\\\\_runner](https://github.com/bangdasun/kaggle_learn/tree/develop/model_runner)\\n|\\n[model\\\\_runner](https://github.com/bangdasun/kaggle_learn/tree/develop/model_runner)\\n|\\n|\\n|\\n[preprocessing](https://github.com/bangdasun/kaggle_learn/tree/develop/preprocessing)\\n|\\n[preprocessing](https://github.com/bangdasun/kaggle_learn/tree/develop/preprocessing)\\n|\\n|\\n|\\n[LICENSE](https://github.com/bangdasun/kaggle_learn/blob/develop/LICENSE)\\n|\\n[LICENSE](https://github.com/bangdasun/kaggle_learn/blob/develop/LICENSE)\\n|\\n|\\n|\\n[README.md](https://github.com/bangdasun/kaggle_learn/blob/develop/README.md)\\n|\\n[README.md](https://github.com/bangdasun/kaggle_learn/blob/develop/README.md)\\n|\\n|\\n|\\n[\\\\_\\\\_init\\\\_\\\\_.py](https://github.com/bangdasun/kaggle_learn/blob/develop/__init__.py)\\n|\\n[\\\\_\\\\_init\\\\_\\\\_.py](https://github.com/bangdasun/kaggle_learn/blob/develop/__init__.py)\\n|\\n|\\n|\\n[setup.py](https://github.com/bangdasun/kaggle_learn/blob/develop/setup.py)\\n|\\n[setup.py](https://github.com/bangdasun/kaggle_learn/blob/develop/setup.py)\\n|\\n|\\n|\\n[standard\\\\_env.yaml](https://github.com/bangdasun/kaggle_learn/blob/develop/standard_env.yaml)\\n|\\n[standard\\\\_env.yaml](https://github.com/bangdasun/kaggle_learn/blob/develop/standard_env.yaml)\\n|\\n|\\n|\\n[utils.py](https://github.com/bangdasun/kaggle_learn/blob/develop/utils.py)\\n|\\n[utils.py](https://github.com/bangdasun/kaggle_learn/blob/develop/utils.py)\\n|\\n|\\n|\\nView all files\\n|\\n## Repository files navigation\\n## kaggle\\\\_learn\\n[](#kaggle_learn)\\nThis module is a collection for useful code in kaggle (or more data science general), includes general utility functions, feature engineering functions, model training / cross-validation / model stacking helper functions.\\n### Modules\\n[](#modules)\\n#### Preprocessing\\n[](#preprocessing)\\nNumerical / categorical (tabular data) and text data preprocessing.\\n#### Feature Engineering\\n[](#feature-engineering)\\nSome commonly used feature engineering methods used in kaggle competitions:\\n* group by on one / multiple categorical features and get the summary statistics of numerical features\\n* text meta features\\n* text similarity features\\n* time meta features\\n* ...\\n#### Models\\n[](#models)\\nModels not implemented in`sklearn`:\\n* NB-LR (Logistic Regression with Naive Bayes features)\\nNeural network templates for different tasks:\\n* text classification (RNN / CNN based)\\n#### Model Runner\\n[](#model-runner)\\nFunctions / classes that takes data and run specified models (with cross validation).\\n#### Feature Importance\\n[](#feature-importance)\\n* Permutation feature importance\\n#### Metrics\\n[](#metrics)\\n* customized`keras`callbacks\\n#### Utilities\\n[](#utilities)\\nUtility functions:\\n* reduce`pandas`dataframe memory\\n* timer / logger\\n* ...\\n### Usage\\n[](#usage)\\nClone this repository:\\n```\\n`git clone https://github.com/bangdasun/kaggle\\\\_learn.git`\\n```\\nCreate environment to install required packages:\\n```\\n`cd kaggle\\\\_learn\\nconda env create -f standard\\\\_env.yaml`\\n```\\n## About\\nFunctions used in kaggle competitions: data preprocessing/feature engineering/model training etc. Many of these functions are collected from kaggle community, credits are belong to the authors :)\\n### Resources\\n[Readme](#readme-ov-file)\\n### License\\n[MIT license](#MIT-1-ov-file)\\n### Uh oh!\\nThere was an error while loading.[Please reload this page]().\\n[Activity](https://github.com/bangdasun/kaggle_learn/activity)\\n### Stars\\n[**11**stars](https://github.com/bangdasun/kaggle_learn/stargazers)\\n### Watchers\\n[**0**watching](https://github.com/bangdasun/kaggle_learn/watchers)\\n### Forks\\n[**15**forks](https://github.com/bangdasun/kaggle_learn/forks)\\n[Report repository](https://github.com/contact/report-content?content_url=https://github.com/bangdasun/kaggle_learn&amp;report=bangdasun+(user))\\n## [Releases](https://github.com/bangdasun/kaggle_learn/releases)\\nNo releases published\\n## [Packages0](https://github.com/users/bangdasun/packages?repo_name=kaggle_learn)\\nNo packages...\\n\\n--- Result 8 ---\\nTitle: The Kaggle Grandmasters Playbook: 7 Battle-Tested Modeling Techniques for Tabular Data\\nURL: https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data\\n\\nContent:\\nThe Kaggle Grandmasters Playbook: 7 Battle&#x2d;Tested Modeling Techniques for Tabular Data | NVIDIA Technical Blog\\n[](https://developer.nvidia.com/)[DEVELOPER](https://developer.nvidia.com/)\\n[Technical Blog](https://developer.nvidia.com/blog)\\n[Subscribe](https://developer.nvidia.com/email-signup)\\n[Related Resources**](#main-content-end)\\n[Data Science](https://developer.nvidia.com/blog/category/data-science/)\\nEnglish‰∏≠Êñá\\n# The Kaggle Grandmasters Playbook: 7 Battle-Tested Modeling Techniques for Tabular Data\\nLessons from years of competitions, made practical with GPU acceleration.\\n![](https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/Kaggle-Grandmasters-Playbook-featured-1024x576-png.webp)\\nSep 18, 2025\\nBy[Kazuki Onodera](https://developer.nvidia.com/blog/author/kazuki-onodera/),[Th√©o Viel](https://developer.nvidia.com/blog/author/tviel/),[Gilberto Titericz](https://developer.nvidia.com/blog/author/gillbertotitericz/)and[Chris Deotte](https://developer.nvidia.com/blog/author/cdeotte/)\\n**\\nLike\\n[**Discuss (1)](#entry-content-comments)\\n* [L](https://www.linkedin.com/sharing/share-offsite/?url=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/)\\n* [T](https://twitter.com/intent/tweet?text=The+Kaggle+Grandmasters+Playbook:+7+Battle-Tested+Modeling+Techniques+for+Tabular+Data+|+NVIDIA+Technical+Blog+https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/)\\n* [F](https://www.facebook.com/sharer/sharer.php?u=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/)\\n* [R](https://www.reddit.com/submit?url=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/&amp;title=The+Kaggle+Grandmasters+Playbook:+7+Battle-Tested+Modeling+Techniques+for+Tabular+Data+|+NVIDIA+Technical+Blog)\\n* [E](<mailto:?subject=I'd like to share a link with you&body=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/>)\\nAI-Generated Summary\\nLike\\nDislike\\n* The authors have developed a playbook for solving real-world tabular problems, refined through hundreds of Kaggle competitions, which emphasizes fast experimentation and careful validation.\\n* Key techniques include using GPU acceleration for dataframe operations and model training with NVIDIA cuML or GPU backends of XGBoost, LightGBM, and CatBoost to enable rapid iteration.\\n* The authors also stress the importance of techniques like k-fold cross-validation, diverse baselines, feature engineering, hill climbing, stacking, pseudo-labeling, and extra training to improve model performance and robustness.\\nAI-generated content may summarize information incompletely. Verify important information.[Learn more](https://www.nvidia.com/en-us/agreements/trustworthy-ai/terms/)\\nOver hundreds of Kaggle competitions, we&#8217;ve refined a playbook that consistently lands us near the top of the leaderboard‚Äîno matter if we‚Äôre working with millions of rows, missing values, or test sets that behave nothing like the training data. This isn‚Äôt just a collection of modeling tricks‚Äîit‚Äôs a repeatable system for solving real-world tabular problems fast.\\nBelow are seven of our most battle-tested techniques, each one made practical through GPU acceleration. Whether you‚Äôre climbing the leaderboard or deploying models in production, these strategies can give you an edge.\\nWe‚Äôve included links to example write-ups or notebooks from past competitions for each technique.\\n**Note:**Kaggle and Google Colab notebooks come with free GPUs and accelerated drop-ins like the ones you‚Äôll see below pre-installed.\\n## Core principles: the foundations of a winning workflow[**](#core_principles_the_foundations_of_a_winning_workflow)\\nBefore diving into techniques, it‚Äôs worth pausing to cover the two principles that power everything in this playbook: fast experimentation and careful validation. These aren‚Äôt optional best practices‚Äîthey‚Äôre the foundation of how we approach every tabular modeling problem.\\n### Fast experimentation[**](#fast_experimentation)\\nThe biggest lever we have in any competition or real-world project is the number of high-quality experiments we can run. The more we iterate, the more patterns we discover‚Äîand the faster we catch when a model is failing, drifting, or overfitting‚Äîso we can course-correct early and improve faster.\\nIn practice, that means we optimize our entire pipeline for speed, not just our model training step.\\n**Here‚Äôs how we make it work:**\\n* Accelerate dataframe operations using[GPU drop-in replacements](https://developer.nvidia.com/blog/7-drop-in-replacements-to-instantly-speed-up-your-python-data-science-workflows/?linkId=100000376196126)for pandas or Polars to transform and engineer features at scale.\\n* Train models with[NVIDIA cuML](https://developer.nvidia.com/topics/ai/data-science/cuda-x-data-science-libraries/cuml)or GPU backends of XGBoost, LightGBM, and CatBoost.\\nGPU acceleration isn‚Äôt just for deep learning‚Äîit&#8217;s often the only way to make advanced tabular techniques practical at scale.\\n### Local Validation[**](#local_validation)\\nIf you can‚Äôt trust your validation score, you‚Äôre flying blind. That‚Äôs why cross-validation (CV) is a cornerstone to our workflow.\\n**Our approach:**\\n* Use k-fold cross-validation, where the model trains on most of the data and tests on the part that‚Äôs held out.\\n* Rotate through folds so every part of the data is tested once.\\nThis gives a much more reliable measure of performance than a single train/validation split.\\n**Pro tip:**Match your CV strategy to how the test data is structured.\\n**For example:**\\n* Use TimeSeriesSplit for time-dependent data\\n* Use GroupKFold for grouped data (like users or patients)\\nWith those foundations in place‚Äîmoving fast and validating carefully‚Äîwe can now dive into the techniques themselves. Each one builds on these principles and shows how we turn raw data into world-class models.\\n## 1. Start with smarter EDA, not just the basics[**](#1_start_with_smarter_eda_not_just_the_basics)\\nMost practitioners know the basics: Check for missing values, outliers, correlations, and feature ranges. Those steps are important, but they‚Äôre table stakes. To build models that hold up in the real world, you need to explore the data a little deeper‚Äîa couple of quick checks that we‚Äôve found useful, but many people miss:\\n**Train vs. test distribution checks:**Spot when evaluation data differs from training, since distribution shift can cause models to validate well but fail in deployment.\\n*Figure 1. Comparing feature distributions between train (blue) and test (red) reveals a clear shift‚Äîtest data is concentrated in a higher range, with minimal overlap. This kind of distribution shift can cause models to validate well but fail in deployment.*\\n**Analyze target variable for temporal patterns:**Check for trends or seasonality, since ignoring temporal patterns can lead to models that look accurate in training but break in production.\\n*Figure 2. Analyzing the target variable over time uncovers a strong upward trend with seasonal fluctuations and accelerating growth. Ignoring temporal patterns like these can mislead models unless time-aware validation is used.*\\nThese techniques aren&#8217;t brand new‚Äîbut they‚Äôre often overlooked, and ignoring them can sink a project.\\n**Why it matters:**Skipping these checks can derail an otherwise solid workflow.\\n**In action:**In the winning solution to the Amazon KDD Cup ‚Äò23, the team uncovered both a train‚Äîtest distribution shift and temporal patterns in the target‚Äîinsights that shaped the final approach.[Read the full write-up &gt;](https://openreview.net/forum?id=J3wj55kK5t)\\n**Made practical with GPUs:**Real-world datasets are often millions of rows, which can slow to a crawl in pandas. By adding GPU acceleration with[NVIDIA cuDF](https:...\\n\\n--- Result 9 ---\\nTitle: Home Depot Product Search Relevance, Winners‚Äô Interview: 2nd Place | Thomas, Sean, Qingchen, & Nima\\nURL: https://medium.com/kaggle-blog/home-depot-product-search-relevance-winners-interview-2nd-place-thomas-sean-qingchen-nima-68068f9f9ffd\\n\\nContent:\\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F68068f9f9ffd&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fkaggle-blog%2Fhome-depot-product-search-relevance-winners-interview-2nd-place-thomas-sean-qingchen-nima-68068f9f9ffd&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fkaggle-blog%2Fhome-depot-product-search-relevance-winners-interview-2nd-place-thomas-sean-qingchen-nima-68068f9f9ffd&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\\n\\n[**Kaggle Blog**](https://medium.com/kaggle-blog?source=post_page---publication_nav-4b0982ce16a3-68068f9f9ffd---------------------------------------)\\n\\n¬∑\\n\\n[![Kaggle Blog](https://miro.medium.com/v2/resize:fill:76:76/1*9izrRVNdAJa9bFaqBwSH4w.png)](https://medium.com/kaggle-blog?source=post_page---post_publication_sidebar-4b0982ce16a3-68068f9f9ffd---------------------------------------)\\n\\nOfficial Kaggle Blog!\\n\\n# Home Depot Product Search Relevance, Winners‚Äô Interview: 2nd Place \\\\| Thomas, Sean, Qingchen, & Nima\\n\\n[![Kaggle Team](https://miro.medium.com/v2/resize:fill:64:64/1*XK0PjUK1iXscB6_0QGvXmQ.png)](https://medium.com/@kaggleteam?source=post_page---byline--68068f9f9ffd---------------------------------------)\\n\\n[Kaggle Team](https://medium.com/@kaggleteam?source=post_page---byline--68068f9f9ffd---------------------------------------)\\n\\nFollow\\n\\n5 min read\\n\\n¬∑\\n\\nJun 15, 2016\\n\\n--\\n\\nListen\\n\\nShare\\n\\nThe [Home Depot Product Search Relevance](https://web.archive.org/web/20161028171539/https://www.kaggle.com/c/home-depot-product-search-relevance) competition challenged Kagglers to predict the relevance of product search results. Over 2000 teams with 2553 players flexed their natural language processing skills in attempts to feature engineer a path to the top of the leaderboard. In this interview, the second place winners, Thomas (Justfor), Sean (sjv), Qingchen, and Nima, describe their approach and how diversity in features brought incremental improvements to their solution.\\n\\n# The basics\\n\\n# What was your background prior to entering this challenge?\\n\\n**Thomas** is a pharmacist, with his PhD in Informatics and Pharmaceutical Analytics and works in Quality in the pharmaceutical industry. At Kaggle he joined earlier competitions and got the Script of the Week award.\\n\\n**Sean** is an undergraduate student in computer science and mathematics at the Massachusetts Institute of Technology (MIT).\\n\\n**Qingchen** is a data scientist at ORTEC Consulting and a PhD researcher at the Amsterdam Business School. He has experience competing on Kaggle but this was the first time with a competition related to natural language processing.\\n\\n**Nima** is a PhD candidate at the Lassonde School of Engineering at York University focusing on research in data mining and machine learning. He has also experience competing on Kaggle but up to now focused on other types of competitions.\\n\\nBetween the four of us, we have quite a bit of experience with Kaggle competitions and machine learning, but minor experience in natural language processing.\\n\\n# What made you decide to enter this competition?\\n\\nFor all of us, the primary reason was that we wanted to learn more about natural language processing (NLP) and information retrieval (IR). This competition turned out to be great for that, especially in providing practical experience.\\n\\n# Do you have any prior experience or domain knowledge that helped you succeed in this competition?\\n\\nAll of us have strong theoretical experience with machine learning in general, and it naturally helps with the understanding and implementation of NLP and IR methods. However, none of us have had any real experience in this domain.\\n\\n# Let‚Äôs get technical\\n\\n# What preprocessing and supervised learning methods did you use?\\n\\nThe key to this competition was mostly preprocessing and feature engineering as the primary data is text. Our processed text features can broadly be grouped into a few categories: categorical features, counting features, co-occurrence features, semantic features, and statistical features.\\n\\n- Categorical features: Put words in categories such as colors, units, brands, core. Count the number of those words in the query/title and count number of intersection between query and title for each category.\\n- Counting features: Length of query, number of common grams between query and title, Jacquard similarity, etc.\\n- Co-occurrence features: Measures of how frequently words appear together. e.g., Latent Semantic Analysis (LSA).\\n- Semantic features: Measure how similar the meaning of two words is.\\n- Statistical features: Compare queries with unknown score to queries with known relevance score.\\n\\nIt seems that a lot of the top teams had similar types of features, but the implementation details are probably different. For our ensemble we used different variations of xgboost along with a ridge regression model.\\n\\nFor models and ensemble we started with random forest, extra trees and gbm-models. Furthermore xgboost and ridge were in our focus. Shortly prior to the end of the competition we found out, that first random forest and then extra trees did not help our ensembles anymore. So we focused on xgboost, gbm and Ridge.\\n\\nOur best single model was a xgboost-model and scored 0.43347 on the public LB. The final ensemble consists of 19 models based on xgboost, gbm and Ridge. The xgboost-models were made with different parameters including binarizing the target, objective reg:linear, and objective count:poisson. We found, that the Ridge Regression helped in nearly every case, so we included it in the final ensemble.\\n\\n# Were you surprised by any of your findings?\\n\\nA surprising finding was the large number of features which had predictive ability. In particular, when we teamed up, it was better to combine our features than to ensemble our results. This is quite unique as most of the time new features are more likely to cause overfit but not in this case. As a result, adding more members to the team was highly likely to improve score which is why the top-10 were all teams of at least 3 people.\\n\\n# Which tools did you use?\\n\\nWe used mainly Python 3 and Python 2. The decision for Python 2 is interesting as some of the used libraries are still not available for Python 3. In our processing chain we used the Python standard tools for machine learning (scikit-learn, nltk, pandas, numpy, scipy, xgboost, gensim). Nima used R for feature generation.\\n\\n# How did you spend your time on this competition?\\n\\nAfter teaming up, Sean and Nima spent most of their time on feature engineering and Thomas and Qingchen spent most of their time on model tuning.\\n\\n# What was the run time for both training and prediction of your winning solution?\\n\\nIn general, training/prediction time is very fast (minutes), but we used some xgboost parameters that took much longer to train (hours) for small performance gains. Text processing and feature engineering took a very long time (easily over 8 hours for a single feature set).\\n\\n# Words of wisdom\\n\\n# What have you taken away from this competition?\\n\\nFirst of all quite a lot of Kaggle ranking points and Thomas got his Master badge! Overall this was a very difficult competition and we learned a lot about natural language processing and information retrieval in practice. It now makes sense why Google is able to use such a large number of features in their search algorithm as m...\\n\", \"is_error\": false, \"results\": [{\"title\": \"ANSWER\", \"text\": \"Combining free‚Äëform text with categorical meta‚Äëdata in Kaggle contests is most often tackled by turning the non‚Äëtext fields into a textual representation that a transformer can ingest directly.  A simple and surprisingly effective recipe is to join the raw text, numeric values and categorical labels into one string separated by a special token (e.g.,‚ÄØ`[SEP]`).  In FreeAgent‚Äôs bank‚Äëtransaction classifier the transaction description, amount and industry were concatenated as‚ÄØ`Plastic pipes [SEP] -7.99 [SEP] Plumbing`, allowing a single fine‚Äëtuned transformer to learn from all modalities at once‚ÄØ([engineering.freeagent.com](https://engineering.freeagent.com/2024/05/17/combining-text-with-numerical-and-categorical-features-for-classification)).  An even more natural variant is to prepend the categorical information to the review text, treating it as additional ‚Äúwords‚Äù.  In a Kaggle‚Äëstyle clothing‚Äëreview dataset this ‚Äúfeatures‚Äëto‚Äëtext‚Äù strategy consistently outperformed more elaborate baselines, showing that a straightforward textual conversion of meta‚Äëdata can be the strongest baseline for multimodal tabular‚Äëtext problems‚ÄØ([mccormickml.com](https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert)).\\n\\nA second, slightly richer approach keeps the modalities separate: the text is encoded with a pre‚Äëtrained transformer (or a TF‚ÄëIDF / hashing vectorizer) while categorical columns are transformed with embeddings, target‚Äëencoding, or one‚Äëhot vectors, and the resulting vectors are concatenated before feeding a downstream classifier (e.g., a shallow MLP or gradient‚Äëboosted tree).  FreeAgent‚Äôs experiments showed that this ‚Äúextract‚Äëtext‚Äëembedding‚ÄØ+‚ÄØconcatenate‚Äëother‚Äëfeatures‚Äù pipeline matches or exceeds the pure‚Äëstring method on a wine‚Äëreview classification task, indicating that preserving the numeric nature of fields can give the model clearer signals‚ÄØ([engineering.freeagent.com](https://engineering.freeagent.com/2024/05/17/combining-text-with-numerical-and-categorical-features-for-classification)).  In practice, Kaggle winners often start with the easy text‚Äëconcatenation trick to get a strong baseline, then iterate toward a hybrid pipeline that encodes categorical data more explicitly for the final performance boost.\", \"url\": \"\"}, {\"title\": \"Combining text with numerical and categorical features for classification\", \"text\": \"[Skip to content](https://engineering.freeagent.com/engineering.freeagent.com#content)\\n\\n# Classification with transformer models\\n\\nA common approach for classification tasks with text data is to fine-tune a pre-trained transformer model on domain-specific data. At FreeAgent we apply this approach to [automatically categorise bank transactions](https://www.freeagent.com/blog/how-freeagent-uses-ai/), using raw inputs that are a mixture of text, numerical and categorical data types.\\n\\nThe current approach is to concatenate the input features for each transaction into a single string before passing to the model.\\n\\nFor example a transaction with the following set of features:\\n\\n|     |     |     |\\n| --- | --- | --- |\\n| **Description** | **Amount** | **Industry** |\\n| Plastic pipes | ¬£-7.99 | Plumbing |\\n\\ncould be represented by the string:¬† `Plastic pipes [SEP] -7.99 [SEP] Plumbing` with `[SEP]` being a special token indicating the boundaries between sentences, which is used to separate the features. This is a simple way to combine features that have yielded positive performance. We‚Äôve even noticed that the model exhibits unexpectedly good interpretations of the amount feature.\\n\\nThis approach however doesn‚Äôt feel like the most natural way to represent the information contained in a numerical feature like the transaction amount. An alternative approach is to use the transformer model to extract a vector representation of the text features, concatenate this with features extracted from non-text data types and pass the combination to a classifier.\\n\\nIn this post we compare the performance of these two approaches using a dataset of wine reviews to classify wines into 3 classes (neutral, good and excellent). Diagrams 1 and 2 below give an overview of the process for getting from input features to output categories in the two approaches.\\n\\nDiagram 1: Concatenating all inputs into a single string to fine-tune a base transformer model.\\n\\nDiagram 2: Preprocessing numerical and categorical features independently from the text, extracting the description vector representation and train a lightGBM classifier.\\n\\n# Public wine reviews dataset\\n\\nWe use the [Kaggle wine reviews dataset](https://www.kaggle.com/datasets/zynicide/wine-reviews) for this experiment, which contains a variety of descriptive features for just under 130,000 wines, including a wine score. The wine score is a number between 1-100, with 100 being the best, although this dataset only includes reviews for wines that score over 80. For the purpose of this blog post, we created the wine rating from the scores ‚Äì wines between 80 and 86 (incl) were flagged as ‚Äúneutral‚Äù, between 87 and 93 as ‚Äúgood‚Äù and greater than 94 as ‚Äúexcellent‚Äù.\\n\\nTo keep things simple we will use just the wine description, price and variety to attempt to classify the wines into these 3 ratings.\\n\\nWe loaded the data and created a target variable `rating` to split the wine scores into the 3 target categories (neutral, good, excellent).\\n\\n```\\nimport pandas as pd\\n\\nwine_df = pd.read_csv(\\\"data/wine_data.csv\\\")\\nbins = [0, 87, 94, np.inf]\\nnames = [\\\"neutral\\\", \\\"good\\\", \\\"excellent\\\"]\\n\\nwine_df[\\\"rating\\\"] = pd.cut(wine_df[\\\"points\\\"], bins, labels=names)\\n\\n```\\n\\nWe can then keep a DataFrame of the features and target. For the purpose of putting together this example we have limited the model input features to the wine variety (the type of grapes used to make the wine), the price (cost for a bottle of wine) and the wine description.\\n\\n```\\nNUMERICAL_FEATURE = \\\"price\\\"\\nCATEGORICAL_FEATURE = \\\"variety\\\"\\nTEXT_FEATURE = \\\"description\\\"\\nTARGET = \\\"rating\\\"\\nFEATURES = [TEXT_FEATURE, NUMERICAL_FEATURE, CATEGORICAL_FEATURE]\\n\\nwine_df = wine_df[FEATURES + [TARGET]]\\n\\n```\\n\\nWe then split our wine dataframe into an 80:20 training:evaluation split.\\n\\n```\\nfrom sklearn.model_selection import train_test_split\\n\\ntrain_df, test_df = train_test_split(wine_df, test_size=0.2)\\n\\n```\\n\\n## LightGBM classifier approach\\n\\n### Preprocessing\\n\\n#### Preprocessing numerical and categorical features\\n\\nIn a first step we will preprocess the numerical and categorical features using SKLearn‚Äôs ColumnTransformer.¬† For the numerical features (price) we decided to fill missing values using the median wine price and scale them using a StandardScaler.\\n\\nWe preprocessed the categorical features by filling missing values with ‚Äúother‚Äù and OneHot encoded them.\\n\\nWe saved the output of the ColumnTransformer as a pandas DataFrame to concatenate it later with the vector representation of the text.\\n\\n```\\nimport numpy as np\\n\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.pipeline import make_pipeline\\nfrom sklearn.preprocessing import (\\n    OneHotEncoder,\\n    StandardScaler,\\n)\\n\\ndef preprocess_number():\\n    return make_pipeline(\\n        SimpleImputer(strategy=\\\"median\\\"),\\n        StandardScaler(),\\n    )\\n\\ndef preprocess_categories():\\n    return make_pipeline(\\n       SimpleImputer(strategy=\\\"constant\\\", fill_value=\\\"other\\\", missing_values=np.nan),\\n       OneHotEncoder(handle_unknown=\\\"ignore\\\", sparse_output=False),\\n    )\\n\\ndef create_preprocessor():\\n\\n    transformers = [\\n        (\\\"num_preprocessor\\\", preprocess_number(), [NUMERICAL_FEATURE]),\\n        (\\\"cat_preprocessor\\\", preprocess_categories(), [CATEGORICAL_FEATURE]),\\n    ]\\n\\n    return ColumnTransformer(transformers=transformers, remainder=\\\"drop\\\")\\n\\ncolumn_transformer = create_preprocessor()\\ncolumn_transformer.set_output(transform=\\\"pandas\\\")\\npreprocessed_num_cat_features_df = column_transformer.fit_transform(\\n    train_df[[NUMERICAL_FEATURE, CATEGORICAL_FEATURE]]\\n)\\n\\n```\\n\\n#### Extracting text vector representation with a transformer model\\n\\nWe then moved on to the preprocessing of the text features. We decided to use `distilbert-base-uncased` as the base transformer model to extract the vector representation of the wine description.\\n\\nBERT-type models use stacks of [transformer encoder layers](https://arxiv.org/pdf/1706.03762.pdf). Each of these blocks processes the tokenized text through a multi-headed self-attention step and a feed-forward neural network, before passing outputs to the next layer. The hidden state is the output of a given layer. The \\\\[CLS\\\\] token (short for classification) is a special token that represents an entire text sequence. We choose the hidden state of the \\\\[CLS\\\\] token in the final layer as the vector representation of our wine descriptions.\\n\\nIn order to extract the \\\\[CLS\\\\] representations, we first transform the text inputs into a Dataset of tokenized PyTorch tensors.\\n\\nFor this step we tokenized batches of 128 wine descriptions padded to a fixed length of 120 suitable for our wine descriptions of ~40 words. The max\\\\_length is one of the parameters which should be adjusted depending on the length of the text feature to prevent truncating longer inputs. The padding is necessary to ensure we will process fixed-shape inputs with the transformer model. The tokenizer returns a dictionary of input\\\\_ids, attention\\\\_mask and token\\\\_type\\\\_ids. Only the input\\\\_ids (the indices of each token in the wine description) and the attention mask (binary tensor indicating the position of the padded indice) are required inputs to the model.\\n\\nThe code for the tokenization is shown below:\\n\\n```\\nfrom datasets import Dataset\\nfrom transformers import AutoTokenizer\\n\\nMODEL_NAME = \\\"distilbert-base-uncased\\\"\\n\\ndef tokenized_pytorch_tensors(\\n        df: pd.DataFrame,\\n        column_list: list\\n    ) -> Dataset:\\n\\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\\n    transformers_dataset = Dataset.from_pandas(df)\\n\\n    def tokenize(model_inputs_batch: Dataset) -> Dataset:\\n        return tokenizer(\\n            model_inputs_batch[TEXT_FEATURE],\\n            padding=True,\\n            max_length=120,\\n            truncation=True,\\n        )\\n\\n    tokenized_dataset = transformers_dataset.map(\\n        tokenize,\\n        batched=True,\\n        batch_size=128\\n    )\\n\\n    tokenized_dataset.set_format(\\n        \\\"torch\\\",\\n        columns=column_list\\n    )\\n\\n    columns_t...\", \"url\": \"https://engineering.freeagent.com/2024/05/17/combining-text-with-numerical-and-categorical-features-for-classification\"}, {\"title\": \"\", \"text\": \"# Combining Categorical and Numerical Features with Text in BERT\\n\\n29 Jun 2021\\n\\nIn this tutorial we‚Äôll look at the topic of classifying text with BERT, but where we also have additional numerical or categorical features that we want to use to improve our predictions.\\n\\nTo help motivate our discussion, we‚Äôll be working with a dataset of about 23k clothing reviews. For each review, we have the review text, but also additional information such as:\\n\\n- The age of the reviewer (numerical feature)\\n- The number of upvotes on the review (numerical feature)\\n- The department and category of the clothing item (categorical features)\\n\\nFor each review, we also have a binary label, which is whether or not the reviewer ultimately recommends the item. This is what we are trying to predict.\\n\\nThis dataset was scraped from an (un-specified) e-commerce website by Nick Brooks and made available on Kaggle [here](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews).\\n\\nIn Section 2 of this Notebook, I‚Äôve implemented four different ‚Äúbaseline‚Äù strategies which score fairly well, but which don‚Äôt incorporate all of the features together.\\n\\nThen, in Section 3, I‚Äôve implemented a simple strategy to combine _everything_ and feed it through BERT. Specifically, I make text out of the additional features, and prepend this text to the review.\\n\\nThere is a GitHub project called the [Multimodal-Toolkit](https://github.com/georgian-io/Multimodal-Toolkit) which is how I learned about this clothing review dataset. The toolkit implements a number of more complicated techniques, but their benchmarks (as well as our results below) show that this simple features-to-text strategy works best for this dataset.\\n\\nIn our weekly discussion group, I talked through this Notebook and we also met with Ken Gu, the author of the Multi-Modal Toolkit! You can watch the recording [here](https://youtu.be/XPt9pIpe1vo).\\n\\nYou can find the Colab Notebook version of this post [here](https://colab.research.google.com/drive/1YRHK4HO8RktGzlYmGjBo056kzVD4_j9o).\\n\\nBy Chris McCormick\\n\\n# Contents\\n\\n- [Contents](https://mccormickml.com/mccormickml.com#contents)\\n- [S1. Clothing Review Dataset](https://mccormickml.com/mccormickml.com#s1-clothing-review-dataset)\\n  - [1.1. Download & Parse](https://mccormickml.com/mccormickml.com#11-download--parse)\\n  - [1.2. Train-Validation-Test Split](https://mccormickml.com/mccormickml.com#12-train-validation-test-split)\\n- [S2. Baseline Strategies](https://mccormickml.com/mccormickml.com#s2-baseline-strategies)\\n  - [2.1. Always Recommend](https://mccormickml.com/mccormickml.com#21-always-recommend)\\n  - [2.2. Threshold on Rating](https://mccormickml.com/mccormickml.com#22-threshold-on-rating)\\n  - [2.3. XGBoost](https://mccormickml.com/mccormickml.com#23-xgboost)\\n  - [2.4. BERT on Review Text Only](https://mccormickml.com/mccormickml.com#24-bert-on-review-text-only)\\n- [S3. BERT with All Features](https://mccormickml.com/mccormickml.com#s3-bert-with-all-features)\\n  - [3.1. All Features to Text](https://mccormickml.com/mccormickml.com#31-all-features-to-text)\\n  - [3.2. GPU & Transformers Setup](https://mccormickml.com/mccormickml.com#32-gpu--transformers-setup)\\n  - [3.3. Training Parameters](https://mccormickml.com/mccormickml.com#33-training-parameters)\\n  - [3.3. Tokenize & Encode](https://mccormickml.com/mccormickml.com#33-tokenize--encode)\\n  - [3.4. Training](https://mccormickml.com/mccormickml.com#34-training)\\n    - [3.4.1. Setup](https://mccormickml.com/mccormickml.com#341-setup)\\n    - [3.4.2. Training Loop](https://mccormickml.com/mccormickml.com#342-training-loop)\\n    - [3.4.3. Training Results](https://mccormickml.com/mccormickml.com#343-training-results)\\n  - [3.5. Test](https://mccormickml.com/mccormickml.com#35-test)\\n- [Conclusion](https://mccormickml.com/mccormickml.com#conclusion)\\n\\n# S1. Clothing Review Dataset\\n\\n## 1.1. Download & Parse\\n\\nRetrieve the .csv file for the dataset.\\n\\n```\\nimport gdown\\n\\nprint('Downloading dataset...\\\\n')\\n\\n# Download the file.\\ngdown.download('https://drive.google.com/uc?id=1ZYdt0zN4LjWqP3cQDblNhXjeohcryY5H',\\n                'Womens Clothing E-Commerce Reviews.csv',\\n                quiet=False)\\n\\nprint('\\\\n\\\\nDONE.')\\n```\\n\\n```\\nDownloading dataset...\\n\\nDownloading...\\nFrom: https://drive.google.com/uc?id=1ZYdt0zN4LjWqP3cQDblNhXjeohcryY5H\\nTo: /content/Womens Clothing E-Commerce Reviews.csv\\n8.48MB [00:00, 48.7MB/s]\\n\\nDONE.\\n\\n```\\n\\nParse the dataset csv file into a pandas DataFrame.\\n\\n```\\nimport pandas as pd\\n\\ndata_df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv', index_col=0)\\n\\ndata_df.head()\\n```\\n\\n| Clothing ID | Age | Title | Review Text | Rating | Recommended IND | Positive Feedback Count | Division Name | Department Name | Class Name |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 767 | 33 | NaN | Absolutely wonderful - silky and sexy and comf... | 4 | 1 | 0 | Initmates | Intimate | Intimates |\\n| 1 | 1080 | 34 | NaN | Love this dress! it's sooo pretty. i happene... | 5 | 1 | 4 | General | Dresses | Dresses |\\n| 2 | 1077 | 60 | Some major design flaws | I had such high hopes for this dress and reall... | 3 | 0 | 0 | General | Dresses | Dresses |\\n| 3 | 1049 | 50 | My favorite buy! | I love, love, love this jumpsuit. it's fun, fl... | 5 | 1 | 0 | General Petite | Bottoms | Pants |\\n| 4 | 847 | 47 | Flattering shirt | This shirt is very flattering to all due to th... | 5 | 1 | 6 | General | Tops | Blouses |\\n\\n_Features_\\n\\n‚Äú **Recommended IND**‚Äù is the label we are trying to predict for this dataset. ‚Äú1‚Äù means the reviewer recommended the product and ‚Äú0‚Äù means they do not.\\n\\nThe following are _categorical_ features:\\n\\n- Division Name\\n- Department Name\\n- Class Name\\n- Clothing ID\\n\\nAnd the following are _numerical_ features:\\n\\n- Age\\n- Rating\\n- Positive Feedback Count\\n\\n_Feature Analysis_\\n\\nThere is an excellent Notebook on Kaggle [here](https://www.kaggle.com/bhaveshkumar2806/complete-eda-and-visualization-of-text-data) which does some thorough analysis on each of the features in this dataset.\\n\\nNote that, in addition to the ‚ÄúRecommended‚Äù label, there is also a ‚Äú **Rating**‚Äù column where the reviewer rates the product from 1 - 5. The analysis in the above Notebook shows that almost all items rated 3 - 5 are recommended, and almost all rated 1 - 2 are not recommended. We‚Äôll see in our second baseline classifier that you can get a very high accuracy with this feature alone. However, it _is_ still possible to do better by incorporating the other features!\\n\\n## 1.2. Train-Validation-Test Split\\n\\nI want to use the same training, validation, and test splits for all of the approaches we try so that it‚Äôs a fair comparison.\\n\\nHowever, different approaches are going to require different transformations on the data, and for simplicity I want to apply those transformations _before_ splitting the dataset.\\n\\nTo solve this, we‚Äôre going to create lists of indeces for each of the three portions. That way, for a given classification approach, we can load the whole dataset, apply our transformations, and then split it according to these pre-determined indeces.\\n\\n```\\nimport random\\nimport numpy as np\\n\\n# First, calculate the split sizes. 80% training, 10% validation, 10% test.\\ntrain_size = int(0.8 * len(data_df))\\nval_size = int(0.1 * len(data_df))\\ntest_size = len(data_df) - (train_size + val_size)\\n\\n# Sanity check the sizes.\\nassert((train_size + val_size + test_size) == len(data_df))\\n\\n# Create a list of indeces for all of the samples in the dataset.\\nindeces = np.arange(0, len(data_df))\\n\\n# Shuffle the indeces randomly.\\nrandom.shuffle(indeces)\\n\\n# Get a list of indeces for each of the splits.\\ntrain_idx = indeces[0:train_size]\\nval_idx = indeces[train_size:(train_size + val_size)]\\ntest_idx = indeces[(train_size + val_size):]\\n\\n# Sanity check\\nassert(len(train_idx) == train_size)\\nassert(len(test_idx) == test_size)\\n\\n# With these lists, we can now select the corresponding dataframe rows using,\\n# e.g., train_df = data_df.iloc[train_idx]\\n\\nprint('  Training size: {:,}'.format(train_size))\\n...\", \"url\": \"https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert\"}, {\"title\": \"A Reference Guide to Feature Engineering Methods | Kaggle\", \"text\": \"A Reference Guide to Feature Engineering Methods | Kaggle\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n[\\nLearn more\\n](https://www.kaggle.com/cookies)\\nOK, Got it.\\n![Something went wrong and this page crashed!](https://www.kaggle.com/static/images/error/server-error-illo_light.svg)###### Something went wrong and this page crashed!\\nIf the issue persists, it's likely a problem on our side.\\n```\\nLoading CSS chunk 1019 failed.\\\\\\\\n(https://www.kaggle.com/static/assets/KernelViewer.21f94db0016b9074.css)\\nkeyboard\\\\_arrow\\\\_upcontent\\\\_copy\\nError: Loading CSS chunk 1019 failed.\\\\\\\\n(https://www.kaggle.com/static/assets/KernelViewer.21f94db0016b9074.css)\\nat t.onerror.t.onload (https://www.kaggle.com/static/assets/runtime.js?v=a6aef772a946d7d4:1:10006)\\n```\\nRefresh\", \"url\": \"https://www.kaggle.com/code/prashant111/a-reference-guide-to-feature-engineering-methods\"}, {\"title\": \"Grandmaster Pro Tip: Winning First Place in Kaggle Competition with Feature Engineering Using cuDF pandas\", \"text\": \"Grandmaster Pro Tip: Winning First Place in Kaggle Competition with Feature Engineering Using cuDF pandas | NVIDIA Technical Blog\\n[](https://developer.nvidia.com/)[DEVELOPER](https://developer.nvidia.com/)\\n[Technical Blog](https://developer.nvidia.com/blog)\\n[Subscribe](https://developer.nvidia.com/email-signup)\\n[Related Resources**](#main-content-end)\\n[Data Science](https://developer.nvidia.com/blog/category/data-science/)\\nEnglish‰∏≠Êñá\\n# Grandmaster Pro Tip: Winning First Place in Kaggle Competition with Feature Engineering Using cuDF pandas\\n![](https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/NVIDIA-feature-engineering-kaggle-blog-1024x576.jpg)\\nApr 17, 2025\\nBy[Chris Deotte](https://developer.nvidia.com/blog/author/cdeotte/)\\n**\\nLike\\n[**Discuss (1)](#entry-content-comments)\\n* [L](https://www.linkedin.com/sharing/share-offsite/?url=https://developer.nvidia.com/blog/grandmaster-pro-tip-winning-first-place-in-kaggle-competition-with-feature-engineering-using-nvidia-cudf-pandas/)\\n* [T](https://twitter.com/intent/tweet?text=Grandmaster+Pro+Tip:+Winning+First+Place+in+Kaggle+Competition+with+Feature+Engineering+Using+cuDF+pandas+|+NVIDIA+Technical+Blog+https://developer.nvidia.com/blog/grandmaster-pro-tip-winning-first-place-in-kaggle-competition-with-feature-engineering-using-nvidia-cudf-pandas/)\\n* [F](https://www.facebook.com/sharer/sharer.php?u=https://developer.nvidia.com/blog/grandmaster-pro-tip-winning-first-place-in-kaggle-competition-with-feature-engineering-using-nvidia-cudf-pandas/)\\n* [R](https://www.reddit.com/submit?url=https://developer.nvidia.com/blog/grandmaster-pro-tip-winning-first-place-in-kaggle-competition-with-feature-engineering-using-nvidia-cudf-pandas/&amp;title=Grandmaster+Pro+Tip:+Winning+First+Place+in+Kaggle+Competition+with+Feature+Engineering+Using+cuDF+pandas+|+NVIDIA+Technical+Blog)\\n* [E](<mailto:?subject=I'd like to share a link with you&body=https://developer.nvidia.com/blog/grandmaster-pro-tip-winning-first-place-in-kaggle-competition-with-feature-engineering-using-nvidia-cudf-pandas/>)\\nAI-Generated Summary\\nLike\\nDislike\\n* Using NVIDIA cuDF-pandas to accelerate pandas operations on GPUs allowed for the rapid generation and testing of over 10,000 engineered features for a Kaggle competition, significantly boosting the accuracy of an XGBoost model.\\n* The most effective feature engineering techniques included groupby aggregations, such as computing statistics (e.g., mean, std, count) and quantiles, as well as creating new columns from NaNs and binning numerical columns.\\n* Techniques like extracting digits from float32 values and combining categorical columns also proved useful, and leveraging the original dataset that the synthetic data was created from provided additional predictive power.\\nAI-generated content may summarize information incompletely. Verify important information.[Learn more](https://www.nvidia.com/en-us/agreements/trustworthy-ai/terms/)\\nFeature engineering remains one of the most effective ways to improve model accuracy when working with tabular data. Unlike domains such as NLP and computer vision, where neural networks can extract rich patterns from raw inputs, the best-performing tabular models‚Äîparticularly gradient-boosted decision trees‚Äîstill gain a significant advantage from well-crafted features. However, the sheer potential number of useful features means that exploring them thoroughly is often computationally prohibitive. Trying to generate and validate hundreds or thousands of feature ideas using standard pandas on a CPU is simply too slow to be practical.\\nThis is where GPU acceleration changes the game. Using NVIDIA cuDF-pandas, which accelerates pandas operations on GPUs with zero code changes, allowed me to rapidly generate and test over 10,000 engineered features for Kaggle‚Äôs February playground competition. This accelerated discovery process was the key differentiator. In a drastically reduced timeframe &#8211; days instead of potential months &#8211;¬†the best 500 discovered features significantly boosted the accuracy of my XGBoost model, securing 1st place in the competition predicting backpack prices. Below, I share the core feature engineering techniques, accelerated by cuDF-pandas, that led to this result.\\n## Groupby(COL1)[COL2].agg(STAT)[**](#groupbycol1col2aggstat)\\nThe most powerful feature engineering technique is groupby aggregations. Namely, we execute the code`groupby(COL1)[COL2].agg(STAT)`. This is where we group by`COL1`column and aggregate (i.e. compute) a statistic`STAT`over another column`COL2`. We use the speed of NVIDIA cuDF-Pandas to explore thousands of`COL1`,`COL2`,`STAT`combinations. We try statistics (`STAT`) like &#8220;mean&#8221;, &#8220;std&#8221;, &#8220;count&#8221;, &#8220;min&#8221;, &#8220;max&#8221;, &#8220;nunique&#8221;, &#8220;skew&#8221; etc etc. We choose`COL1`and`COL2`from our tabular data‚Äôs existing columns. When`COL2`is the target column, then we use nested cross-validation to avoid leakage in our validation computation. When`COL2`is the target, this operation is called Target Encoding.\\n## Groupby(COL1)[&#8216;Price&#8217;].agg(HISTOGRAM BINS)[**](#groupbycol1&#8216;price&#8217;agghistogram_bins)\\nWhen we`groupby(COL1)[COL2]`we have a distribution (set) of numbers for each group. Instead of computing a single statistic (and making one new column), we can compute any collection of numbers that describe this distribution of numbers and make many new columns together.\\nBelow we display a histogram for the group`Weight Capacity = 21.067673`. We can count the number of elements in each (equally spaced) bucket and create a new engineered feature for each bucket count to return to the groupby operation! Below we display seven buckets, but we can treat the number of buckets as a hyperparameter.\\n```\\nresult = X\\\\_train2.groupby(&quot;&quot;WC&quot;&quot;)&#x5B;&#x5B;&quot;&quot;Price&quot;&quot;].apply(make\\\\_histogram)\\nX\\\\_valid2 = X\\\\_valid2.merge(result, on=&quot;&quot;WC&quot;&quot;, how=&quot;&quot;left&quot;&quot;)\\n```\\n*Figure 1. Histogram of price values when weight capacity equals 21.067673*\\n## Groupby(COL1)[&#8216;Price&#8217;].agg(QUANTILES)[**](#groupbycol1&#8216;price&#8217;aggquantiles)\\nWe can groupby and compute the quantiles for`QUANTILES = [5,10,40,45,55,60,90,95]`and return the eight values to create eight new columns.\\n```\\nfor k in QUANTILES:\\nresult = X\\\\_train2.groupby(&#039;&#039;Weight Capacity (kg)&#039;&#039;).\\\\\\\\\\nagg({&#039;&#039;Price&#039;&#039;: lambda x: x.quantile(k/100)})\\n```\\n## All NANs as Single Base-2 Column[**](#all_nans_as_single_base-2_column)\\nWe can create a new column from all the NANs over multiple columns. This is a powerful column which we can subsequently use for groupby aggregations or combinations with other columns.\\n```\\ntrain&#x5B;&#x5B;&quot;&quot;NaNs&quot;&quot;] = np.float32(0)\\nfor i,c in enumerate(CATS):\\ntrain&#x5B;&#x5B;&quot;&quot;NaNs&quot;&quot;] += train&#x5B;&#x5B;c].isna()\\\\*2\\\\*\\\\*i\\n```\\n## Put Numerical Column into Bins[**](#put_numerical_column_into_bins)\\nThe most powerful (predictive) column in this competition is Weight Capacity. We can create more powerful columns based on this column by binning this column with rounding.\\n```\\nfor k in range(7,10):\\nn = f&quot;round{k}&quot;\\ntrain&#x5B;n] = train&#x5B;&quot;Weight Capacity (kg)&quot;].round(k)\\n```\\n## Extract Float32 as Digits[**](#extract_float32_as_digits)\\nThe most powerful (predictive) column in this competition is Weight Capacity. We can create more powerful columns based on this column by extracting digits. This technique seems weird, but it is often used to extract info from a product ID where individual digits within a product ID convey info about a product such as brand, color, etc.\\n```\\nfor k in range(1,10):\\ntrain&#x5B;&#x5B;f&#039;&#039;digit{k}&#039;&#039;] = ((train&#x5B;&#x5B;&#039;&#039;Weight Capacity (kg)&#039;&#039;] \\\\* 10\\\\*\\\\*k) % 10).fillna(-1).astype(&quot;&quot;int8&quot;&quot;)\\n```\\n## Combination of Categorical Columns[**](#combination_of_...\", \"url\": \"https://developer.nvidia.com/blog/grandmaster-pro-tip-winning-first-place-in-kaggle-competition-with-feature-engineering-using-nvidia-cudf-pandas\"}, {\"title\": \"Feature Engineering with Kaggle Tutorial\", \"text\": \"[![Data and AI Literacy 2024 ](https://images.datacamp.com/Marketing/Oneoffs/data-literacy-2024/lockup-banner-data-ai-literacy.png)\\\\\\n\\\\\\n**The State of Data & AI Literacy 2024** \\\\\\n\\\\\\nDownload Now](https://www.datacamp.com/report/data-ai-literacy-report-2024)\\n\\n[Skip to main content](https://www.datacamp.com/tutorial/feature-engineering-kaggle#main)\\n\\nIn the two previous Kaggle tutorials, you learned all about how to get your data in a form to build your first machine learning model, using [Exploratory Data Analysis and baseline machine learning models](https://www.datacamp.com/tutorial/kaggle-machine-learning-eda). Next, you successfully managed to [build your first machine learning model](https://www.datacamp.com/tutorial/kaggle-tutorial-machine-learning), a decision tree classifier. You submitted all these models to Kaggle and interpreted their accuracy.\\n\\nIn this third tutorial, you'll learn more about feature engineering, a process where you use domain knowledge of your data to create additional relevant features that increase the predictive power of the learning algorithm and make your machine learning models perform even better!\\n\\nMore specifically,\\n\\n- You'll first [get started](https://www.datacamp.com/tutorial/feature-engineering-kaggle#getting-started!) by doing all necessary imports and getting the data in your workspace;\\n- Then, you'll see some reasons why you should do [feature engineering](https://www.datacamp.com/tutorial/feature-engineering-kaggle#why-feature-engineer-at-all?) and start working on engineering your own new features for your data set! You'll create new columns, transform variables into numerical ones, handle missing values, and much more.\\n- Lastly, you'll [build a new machine learning model](https://www.datacamp.com/tutorial/feature-engineering-kaggle#building-models-with-your-new-data-set!) with your new data set and submit it to Kaggle.\\n\\n## Getting Started!\\n\\nBefore you can start off, you're going to do all the imports, just like you did in the previous tutorial, use some IPython magic to make sure the figures are generated inline in the Jupyter Notebook and set the visualization style. Next, you can import your data and make sure that you store the target variable of the training data in a safe place. Afterwards, you merge the train and test data sets (with exception of the `'Survived'` column of `df_train`) and store the result in `data`.\\n\\n**Remember** that you do this because you want to make sure that any preprocessing that you do on the data is reflected in both the train and test sets!\\n\\nLastly, you use the `.info()` method to take a look at your data:\\n\\n```\\n\\n# Imports\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport re\\nimport numpy as np\\nfrom sklearn import tree\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Figures inline and set visualization style\\n%matplotlib inline\\nsns.set()\\n\\n# Import data\\ndf_train = pd.read_csv('data/train.csv')\\ndf_test = pd.read_csv('data/test.csv')\\n\\n# Store target variable of training data in a safe place\\nsurvived_train = df_train.Survived\\n\\n# Concatenate training and test sets\\ndata = pd.concat([df_train.drop(['Survived'], axis=1), df_test])\\n\\n# View head\\ndata.info()\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\n```\\n\\n<class 'pandas.core.frame.DataFrame'>\\nInt64Index: 1309 entries, 0 to 417\\nData columns (total 11 columns):\\nPassengerId    1309 non-null int64\\nPclass         1309 non-null int64\\nName           1309 non-null object\\nSex            1309 non-null object\\nAge            1046 non-null float64\\nSibSp          1309 non-null int64\\nParch          1309 non-null int64\\nTicket         1309 non-null object\\nFare           1308 non-null float64\\nCabin          295 non-null object\\nEmbarked       1307 non-null object\\ndtypes: float64(2), int64(4), object(5)\\nmemory usage: 122.7+ KB\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\n## Why Feature Engineer at all?\\n\\nYou perform feature engineering to extract more information from your data, so that you can up your game when building models.\\n\\n### Titanic's Passenger Titles\\n\\nLet's check out what this is all about by looking at an example. Let's check out the `'Name'` column with the help of the `.tail()` method, which helps you to see the last five rows of your data:\\n\\n```\\n\\n# View head of 'Name' column\\ndata.Name.tail()\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\n```\\n\\n413              Spector, Mr. Woolf\\n414    Oliva y Ocana, Dona. Fermina\\n415    Saether, Mr. Simon Sivertsen\\n416             Ware, Mr. Frederick\\n417        Peter, Master. Michael J\\nName: Name, dtype: object\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\nSuddenly, you see different titles emerging! In other words, this column contains strings or text that contain titles, such as 'Mr', 'Master' and 'Dona'.\\n\\nThese titles of course give you information on social status, profession, etc., which in the end could tell you something more about survival.\\n\\nAt first sight, it might seem like a difficult task to separate the names from the titles, but don't panic! Remember, you can easily use regular expressions to extract the title and store it in a new column `'Title'`:\\n\\n```\\n\\n# Extract Title from Name, store in column and plot barplot\\ndata['Title'] = data.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\\\.', x).group(1))\\nsns.countplot(x='Title', data=data);\\nplt.xticks(rotation=45);\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\n![bar chart](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1515151833/output_5_0_d77zb9.png)\\n\\n**Note** that this new column `'Title'` is actually a new feature for your data set!\\n\\n**Tip**: to learn more about regular expressions, check out my write up of our last [FB Live code along event](https://www.datacamp.com/tutorial/web-scraping-python-nlp) or check out DataCamp's [Python Regular Expressions Tutorial](https://www.datacamp.com/tutorial/python-regular-expression-tutorial).\\n\\nYou can see that there are several titles in the above plot and there are many that don't occur so often. So, it makes sense to put them in fewer buckets.\\n\\nFor example, you probably want to replace `'Mlle'` and `'Ms'` with `'Miss'` and `'Mme'` by `'Mrs'`, as these are French titles and ideally, you want all your data to be in one language. Next, you also take a bunch of titles that you can't immediately categorize and put them in a bucket called `'Special'`.\\n\\n**Tip**: play around with this to see how your algorithm performs as a function of it!\\n\\nNext, you view a barplot of the result with the help of the `.countplot()` method:\\n\\n```\\n\\ndata['Title'] = data['Title'].replace({'Mlle':'Miss', 'Mme':'Mrs', 'Ms':'Miss'})\\ndata['Title'] = data['Title'].replace(['Don', 'Dona', 'Rev', 'Dr',\\n                                            'Major', 'Lady', 'Sir', 'Col', 'Capt', 'Countess', 'Jonkheer'],'Special')\\nsns.countplot(x='Title', data=data);\\nplt.xticks(rotation=45);\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\n![bar chart](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1515151833/output_7_0_vdtvcz.png)\\n\\nThis is what your newly engineered feature `'Title'` looks like!\\n\\nNow, make sure that you have a `'Title'` column and check out your data again with the `.tail()` method:\\n\\n```\\n\\n# View head of data\\ndata.tail()\\n\\n OpenAI\\nWas this helpful? Yes No\\n```\\n\\n|  | PassengerId | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked | Title |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 413 | 1305 | 3 | Spector, Mr. Woolf | male | NaN | 0 | 0 | A.5. 3236 | 8.0500 | NaN | S | Mr |\\n| 414 | 1306 | 1 | Oliva y Ocana, Dona. Fermina | female | 39.0 | 0 | 0 | PC 17758 | 108.9000 | C105 | C | Special |\\n| 415 | 1307 | 3 | Saether, Mr. Simon Sivertsen | male | 38.5 | 0 | 0 | SOTON/O.Q. 3101262 | 7.2500 | NaN | S | Mr |\\n| 416 | 1308 | 3 | Ware, Mr. Frederick | male | NaN | 0 | 0 | 359309 | 8.0500 | NaN | S | Mr |\\n| 417 | 1309 | 3 | Peter, Master. Michael J | male | NaN | 1 | 1 | 2668 | 22.3583 | NaN | C | Master |\\n\\n### Passenger's Cabins\\n\\nWhen you loaded in the ...\", \"url\": \"https://www.datacamp.com/tutorial/feature-engineering-kaggle\"}, {\"title\": \"Search code, repositories, users, issues, pull requests...\", \"text\": \"GitHub - bangdasun/kaggle\\\\_learn: Functions used in kaggle competitions: data preprocessing/feature engineering/model training etc. Many of these functions are collected from kaggle community, credits are belong to the authors :)\\n[Skip to content](#start-of-content)\\n## Navigation Menu\\nToggle navigation\\n[](https://github.com/)\\n[Sign in](https://github.com/login?return_to=https://github.com/bangdasun/kaggle_learn)\\nAppearance settings\\nSearch or jump to...\\n# Search code, repositories, users, issues, pull requests...\\n</option></form>\\nSearch\\nClear\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n# Provide feedback\\n</option></form>\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancelSubmit feedback\\n# Saved searches\\n## Use saved searches to filter your results more quickly\\n</option></form>\\nName\\nQuery\\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\nCancelCreate saved search\\n[Sign in](https://github.com/login?return_to=https://github.com/bangdasun/kaggle_learn)\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=bangdasun/kaggle_learn)\\nAppearance settings\\nResetting focus\\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\\n{{ message }}\\n[bangdasun](https://github.com/bangdasun)/**[kaggle\\\\_learn](https://github.com/bangdasun/kaggle_learn)**Public\\n* [Notifications](https://github.com/login?return_to=/bangdasun/kaggle_learn)You must be signed in to change notification settings\\n* [Fork15](https://github.com/login?return_to=/bangdasun/kaggle_learn)\\n* [Star11](https://github.com/login?return_to=/bangdasun/kaggle_learn)\\nFunctions used in kaggle competitions: data preprocessing/feature engineering/model training etc. Many of these functions are collected from kaggle community, credits are belong to the authors :)\\n### License\\n[MIT license](https://github.com/bangdasun/kaggle_learn/blob/develop/LICENSE)\\n[11stars](https://github.com/bangdasun/kaggle_learn/stargazers)[15forks](https://github.com/bangdasun/kaggle_learn/forks)[Branches](https://github.com/bangdasun/kaggle_learn/branches)[Tags](https://github.com/bangdasun/kaggle_learn/tags)[Activity](https://github.com/bangdasun/kaggle_learn/activity)\\n[Star](https://github.com/login?return_to=/bangdasun/kaggle_learn)\\n[Notifications](https://github.com/login?return_to=/bangdasun/kaggle_learn)You must be signed in to change notification settings\\n# bangdasun/kaggle\\\\_learn\\ndevelop\\n[Branches](https://github.com/bangdasun/kaggle_learn/branches)[Tags](https://github.com/bangdasun/kaggle_learn/tags)\\n[](https://github.com/bangdasun/kaggle_learn/branches)[](https://github.com/bangdasun/kaggle_learn/tags)\\nGo to file\\nCode\\nOpen more actions menu\\n## Folders and files\\n|Name|Name|\\nLast commit message\\n|\\nLast commit date\\n|\\n## Latest commit\\n## History\\n[66 Commits](https://github.com/bangdasun/kaggle_learn/commits/develop/)\\n[](https://github.com/bangdasun/kaggle_learn/commits/develop/)\\n|\\n[feature\\\\_engineering](https://github.com/bangdasun/kaggle_learn/tree/develop/feature_engineering)\\n|\\n[feature\\\\_engineering](https://github.com/bangdasun/kaggle_learn/tree/develop/feature_engineering)\\n|\\n|\\n|\\n[feature\\\\_importance](https://github.com/bangdasun/kaggle_learn/tree/develop/feature_importance)\\n|\\n[feature\\\\_importance](https://github.com/bangdasun/kaggle_learn/tree/develop/feature_importance)\\n|\\n|\\n|\\n[metrics](https://github.com/bangdasun/kaggle_learn/tree/develop/metrics)\\n|\\n[metrics](https://github.com/bangdasun/kaggle_learn/tree/develop/metrics)\\n|\\n|\\n|\\n[model](https://github.com/bangdasun/kaggle_learn/tree/develop/model)\\n|\\n[model](https://github.com/bangdasun/kaggle_learn/tree/develop/model)\\n|\\n|\\n|\\n[model\\\\_runner](https://github.com/bangdasun/kaggle_learn/tree/develop/model_runner)\\n|\\n[model\\\\_runner](https://github.com/bangdasun/kaggle_learn/tree/develop/model_runner)\\n|\\n|\\n|\\n[preprocessing](https://github.com/bangdasun/kaggle_learn/tree/develop/preprocessing)\\n|\\n[preprocessing](https://github.com/bangdasun/kaggle_learn/tree/develop/preprocessing)\\n|\\n|\\n|\\n[LICENSE](https://github.com/bangdasun/kaggle_learn/blob/develop/LICENSE)\\n|\\n[LICENSE](https://github.com/bangdasun/kaggle_learn/blob/develop/LICENSE)\\n|\\n|\\n|\\n[README.md](https://github.com/bangdasun/kaggle_learn/blob/develop/README.md)\\n|\\n[README.md](https://github.com/bangdasun/kaggle_learn/blob/develop/README.md)\\n|\\n|\\n|\\n[\\\\_\\\\_init\\\\_\\\\_.py](https://github.com/bangdasun/kaggle_learn/blob/develop/__init__.py)\\n|\\n[\\\\_\\\\_init\\\\_\\\\_.py](https://github.com/bangdasun/kaggle_learn/blob/develop/__init__.py)\\n|\\n|\\n|\\n[setup.py](https://github.com/bangdasun/kaggle_learn/blob/develop/setup.py)\\n|\\n[setup.py](https://github.com/bangdasun/kaggle_learn/blob/develop/setup.py)\\n|\\n|\\n|\\n[standard\\\\_env.yaml](https://github.com/bangdasun/kaggle_learn/blob/develop/standard_env.yaml)\\n|\\n[standard\\\\_env.yaml](https://github.com/bangdasun/kaggle_learn/blob/develop/standard_env.yaml)\\n|\\n|\\n|\\n[utils.py](https://github.com/bangdasun/kaggle_learn/blob/develop/utils.py)\\n|\\n[utils.py](https://github.com/bangdasun/kaggle_learn/blob/develop/utils.py)\\n|\\n|\\n|\\nView all files\\n|\\n## Repository files navigation\\n## kaggle\\\\_learn\\n[](#kaggle_learn)\\nThis module is a collection for useful code in kaggle (or more data science general), includes general utility functions, feature engineering functions, model training / cross-validation / model stacking helper functions.\\n### Modules\\n[](#modules)\\n#### Preprocessing\\n[](#preprocessing)\\nNumerical / categorical (tabular data) and text data preprocessing.\\n#### Feature Engineering\\n[](#feature-engineering)\\nSome commonly used feature engineering methods used in kaggle competitions:\\n* group by on one / multiple categorical features and get the summary statistics of numerical features\\n* text meta features\\n* text similarity features\\n* time meta features\\n* ...\\n#### Models\\n[](#models)\\nModels not implemented in`sklearn`:\\n* NB-LR (Logistic Regression with Naive Bayes features)\\nNeural network templates for different tasks:\\n* text classification (RNN / CNN based)\\n#### Model Runner\\n[](#model-runner)\\nFunctions / classes that takes data and run specified models (with cross validation).\\n#### Feature Importance\\n[](#feature-importance)\\n* Permutation feature importance\\n#### Metrics\\n[](#metrics)\\n* customized`keras`callbacks\\n#### Utilities\\n[](#utilities)\\nUtility functions:\\n* reduce`pandas`dataframe memory\\n* timer / logger\\n* ...\\n### Usage\\n[](#usage)\\nClone this repository:\\n```\\n`git clone https://github.com/bangdasun/kaggle\\\\_learn.git`\\n```\\nCreate environment to install required packages:\\n```\\n`cd kaggle\\\\_learn\\nconda env create -f standard\\\\_env.yaml`\\n```\\n## About\\nFunctions used in kaggle competitions: data preprocessing/feature engineering/model training etc. Many of these functions are collected from kaggle community, credits are belong to the authors :)\\n### Resources\\n[Readme](#readme-ov-file)\\n### License\\n[MIT license](#MIT-1-ov-file)\\n### Uh oh!\\nThere was an error while loading.[Please reload this page]().\\n[Activity](https://github.com/bangdasun/kaggle_learn/activity)\\n### Stars\\n[**11**stars](https://github.com/bangdasun/kaggle_learn/stargazers)\\n### Watchers\\n[**0**watching](https://github.com/bangdasun/kaggle_learn/watchers)\\n### Forks\\n[**15**forks](https://github.com/bangdasun/kaggle_learn/forks)\\n[Report repository](https://github.com/contact/report-content?content_url=https://github.com/bangdasun/kaggle_learn&amp;report=bangdasun+(user))\\n## [Releases](https://github.com/bangdasun/kaggle_learn/releases)\\nNo releases published\\n## [Packages0](https://github.com/users/bangdasun/packages?repo_name=kaggle_learn)\\nNo packages...\", \"url\": \"https://github.com/bangdasun/kaggle_learn\"}, {\"title\": \"The Kaggle Grandmasters Playbook: 7 Battle-Tested Modeling Techniques for Tabular Data\", \"text\": \"The Kaggle Grandmasters Playbook: 7 Battle&#x2d;Tested Modeling Techniques for Tabular Data | NVIDIA Technical Blog\\n[](https://developer.nvidia.com/)[DEVELOPER](https://developer.nvidia.com/)\\n[Technical Blog](https://developer.nvidia.com/blog)\\n[Subscribe](https://developer.nvidia.com/email-signup)\\n[Related Resources**](#main-content-end)\\n[Data Science](https://developer.nvidia.com/blog/category/data-science/)\\nEnglish‰∏≠Êñá\\n# The Kaggle Grandmasters Playbook: 7 Battle-Tested Modeling Techniques for Tabular Data\\nLessons from years of competitions, made practical with GPU acceleration.\\n![](https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/Kaggle-Grandmasters-Playbook-featured-1024x576-png.webp)\\nSep 18, 2025\\nBy[Kazuki Onodera](https://developer.nvidia.com/blog/author/kazuki-onodera/),[Th√©o Viel](https://developer.nvidia.com/blog/author/tviel/),[Gilberto Titericz](https://developer.nvidia.com/blog/author/gillbertotitericz/)and[Chris Deotte](https://developer.nvidia.com/blog/author/cdeotte/)\\n**\\nLike\\n[**Discuss (1)](#entry-content-comments)\\n* [L](https://www.linkedin.com/sharing/share-offsite/?url=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/)\\n* [T](https://twitter.com/intent/tweet?text=The+Kaggle+Grandmasters+Playbook:+7+Battle-Tested+Modeling+Techniques+for+Tabular+Data+|+NVIDIA+Technical+Blog+https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/)\\n* [F](https://www.facebook.com/sharer/sharer.php?u=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/)\\n* [R](https://www.reddit.com/submit?url=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/&amp;title=The+Kaggle+Grandmasters+Playbook:+7+Battle-Tested+Modeling+Techniques+for+Tabular+Data+|+NVIDIA+Technical+Blog)\\n* [E](<mailto:?subject=I'd like to share a link with you&body=https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/>)\\nAI-Generated Summary\\nLike\\nDislike\\n* The authors have developed a playbook for solving real-world tabular problems, refined through hundreds of Kaggle competitions, which emphasizes fast experimentation and careful validation.\\n* Key techniques include using GPU acceleration for dataframe operations and model training with NVIDIA cuML or GPU backends of XGBoost, LightGBM, and CatBoost to enable rapid iteration.\\n* The authors also stress the importance of techniques like k-fold cross-validation, diverse baselines, feature engineering, hill climbing, stacking, pseudo-labeling, and extra training to improve model performance and robustness.\\nAI-generated content may summarize information incompletely. Verify important information.[Learn more](https://www.nvidia.com/en-us/agreements/trustworthy-ai/terms/)\\nOver hundreds of Kaggle competitions, we&#8217;ve refined a playbook that consistently lands us near the top of the leaderboard‚Äîno matter if we‚Äôre working with millions of rows, missing values, or test sets that behave nothing like the training data. This isn‚Äôt just a collection of modeling tricks‚Äîit‚Äôs a repeatable system for solving real-world tabular problems fast.\\nBelow are seven of our most battle-tested techniques, each one made practical through GPU acceleration. Whether you‚Äôre climbing the leaderboard or deploying models in production, these strategies can give you an edge.\\nWe‚Äôve included links to example write-ups or notebooks from past competitions for each technique.\\n**Note:**Kaggle and Google Colab notebooks come with free GPUs and accelerated drop-ins like the ones you‚Äôll see below pre-installed.\\n## Core principles: the foundations of a winning workflow[**](#core_principles_the_foundations_of_a_winning_workflow)\\nBefore diving into techniques, it‚Äôs worth pausing to cover the two principles that power everything in this playbook: fast experimentation and careful validation. These aren‚Äôt optional best practices‚Äîthey‚Äôre the foundation of how we approach every tabular modeling problem.\\n### Fast experimentation[**](#fast_experimentation)\\nThe biggest lever we have in any competition or real-world project is the number of high-quality experiments we can run. The more we iterate, the more patterns we discover‚Äîand the faster we catch when a model is failing, drifting, or overfitting‚Äîso we can course-correct early and improve faster.\\nIn practice, that means we optimize our entire pipeline for speed, not just our model training step.\\n**Here‚Äôs how we make it work:**\\n* Accelerate dataframe operations using[GPU drop-in replacements](https://developer.nvidia.com/blog/7-drop-in-replacements-to-instantly-speed-up-your-python-data-science-workflows/?linkId=100000376196126)for pandas or Polars to transform and engineer features at scale.\\n* Train models with[NVIDIA cuML](https://developer.nvidia.com/topics/ai/data-science/cuda-x-data-science-libraries/cuml)or GPU backends of XGBoost, LightGBM, and CatBoost.\\nGPU acceleration isn‚Äôt just for deep learning‚Äîit&#8217;s often the only way to make advanced tabular techniques practical at scale.\\n### Local Validation[**](#local_validation)\\nIf you can‚Äôt trust your validation score, you‚Äôre flying blind. That‚Äôs why cross-validation (CV) is a cornerstone to our workflow.\\n**Our approach:**\\n* Use k-fold cross-validation, where the model trains on most of the data and tests on the part that‚Äôs held out.\\n* Rotate through folds so every part of the data is tested once.\\nThis gives a much more reliable measure of performance than a single train/validation split.\\n**Pro tip:**Match your CV strategy to how the test data is structured.\\n**For example:**\\n* Use TimeSeriesSplit for time-dependent data\\n* Use GroupKFold for grouped data (like users or patients)\\nWith those foundations in place‚Äîmoving fast and validating carefully‚Äîwe can now dive into the techniques themselves. Each one builds on these principles and shows how we turn raw data into world-class models.\\n## 1. Start with smarter EDA, not just the basics[**](#1_start_with_smarter_eda_not_just_the_basics)\\nMost practitioners know the basics: Check for missing values, outliers, correlations, and feature ranges. Those steps are important, but they‚Äôre table stakes. To build models that hold up in the real world, you need to explore the data a little deeper‚Äîa couple of quick checks that we‚Äôve found useful, but many people miss:\\n**Train vs. test distribution checks:**Spot when evaluation data differs from training, since distribution shift can cause models to validate well but fail in deployment.\\n*Figure 1. Comparing feature distributions between train (blue) and test (red) reveals a clear shift‚Äîtest data is concentrated in a higher range, with minimal overlap. This kind of distribution shift can cause models to validate well but fail in deployment.*\\n**Analyze target variable for temporal patterns:**Check for trends or seasonality, since ignoring temporal patterns can lead to models that look accurate in training but break in production.\\n*Figure 2. Analyzing the target variable over time uncovers a strong upward trend with seasonal fluctuations and accelerating growth. Ignoring temporal patterns like these can mislead models unless time-aware validation is used.*\\nThese techniques aren&#8217;t brand new‚Äîbut they‚Äôre often overlooked, and ignoring them can sink a project.\\n**Why it matters:**Skipping these checks can derail an otherwise solid workflow.\\n**In action:**In the winning solution to the Amazon KDD Cup ‚Äò23, the team uncovered both a train‚Äîtest distribution shift and temporal patterns in the target‚Äîinsights that shaped the final approach.[Read the full write-up &gt;](https://openreview.net/forum?id=J3wj55kK5t)\\n**Made practical with GPUs:**Real-world datasets are often millions of rows, which can slow to a crawl in pandas. By adding GPU acceleration with[NVIDIA cuDF](https:...\", \"url\": \"https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data\"}, {\"title\": \"Home Depot Product Search Relevance, Winners‚Äô Interview: 2nd Place | Thomas, Sean, Qingchen, & Nima\", \"text\": \"[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F68068f9f9ffd&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fkaggle-blog%2Fhome-depot-product-search-relevance-winners-interview-2nd-place-thomas-sean-qingchen-nima-68068f9f9ffd&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fkaggle-blog%2Fhome-depot-product-search-relevance-winners-interview-2nd-place-thomas-sean-qingchen-nima-68068f9f9ffd&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\\n\\n[**Kaggle Blog**](https://medium.com/kaggle-blog?source=post_page---publication_nav-4b0982ce16a3-68068f9f9ffd---------------------------------------)\\n\\n¬∑\\n\\n[![Kaggle Blog](https://miro.medium.com/v2/resize:fill:76:76/1*9izrRVNdAJa9bFaqBwSH4w.png)](https://medium.com/kaggle-blog?source=post_page---post_publication_sidebar-4b0982ce16a3-68068f9f9ffd---------------------------------------)\\n\\nOfficial Kaggle Blog!\\n\\n# Home Depot Product Search Relevance, Winners‚Äô Interview: 2nd Place \\\\| Thomas, Sean, Qingchen, & Nima\\n\\n[![Kaggle Team](https://miro.medium.com/v2/resize:fill:64:64/1*XK0PjUK1iXscB6_0QGvXmQ.png)](https://medium.com/@kaggleteam?source=post_page---byline--68068f9f9ffd---------------------------------------)\\n\\n[Kaggle Team](https://medium.com/@kaggleteam?source=post_page---byline--68068f9f9ffd---------------------------------------)\\n\\nFollow\\n\\n5 min read\\n\\n¬∑\\n\\nJun 15, 2016\\n\\n--\\n\\nListen\\n\\nShare\\n\\nThe [Home Depot Product Search Relevance](https://web.archive.org/web/20161028171539/https://www.kaggle.com/c/home-depot-product-search-relevance) competition challenged Kagglers to predict the relevance of product search results. Over 2000 teams with 2553 players flexed their natural language processing skills in attempts to feature engineer a path to the top of the leaderboard. In this interview, the second place winners, Thomas (Justfor), Sean (sjv), Qingchen, and Nima, describe their approach and how diversity in features brought incremental improvements to their solution.\\n\\n# The basics\\n\\n# What was your background prior to entering this challenge?\\n\\n**Thomas** is a pharmacist, with his PhD in Informatics and Pharmaceutical Analytics and works in Quality in the pharmaceutical industry. At Kaggle he joined earlier competitions and got the Script of the Week award.\\n\\n**Sean** is an undergraduate student in computer science and mathematics at the Massachusetts Institute of Technology (MIT).\\n\\n**Qingchen** is a data scientist at ORTEC Consulting and a PhD researcher at the Amsterdam Business School. He has experience competing on Kaggle but this was the first time with a competition related to natural language processing.\\n\\n**Nima** is a PhD candidate at the Lassonde School of Engineering at York University focusing on research in data mining and machine learning. He has also experience competing on Kaggle but up to now focused on other types of competitions.\\n\\nBetween the four of us, we have quite a bit of experience with Kaggle competitions and machine learning, but minor experience in natural language processing.\\n\\n# What made you decide to enter this competition?\\n\\nFor all of us, the primary reason was that we wanted to learn more about natural language processing (NLP) and information retrieval (IR). This competition turned out to be great for that, especially in providing practical experience.\\n\\n# Do you have any prior experience or domain knowledge that helped you succeed in this competition?\\n\\nAll of us have strong theoretical experience with machine learning in general, and it naturally helps with the understanding and implementation of NLP and IR methods. However, none of us have had any real experience in this domain.\\n\\n# Let‚Äôs get technical\\n\\n# What preprocessing and supervised learning methods did you use?\\n\\nThe key to this competition was mostly preprocessing and feature engineering as the primary data is text. Our processed text features can broadly be grouped into a few categories: categorical features, counting features, co-occurrence features, semantic features, and statistical features.\\n\\n- Categorical features: Put words in categories such as colors, units, brands, core. Count the number of those words in the query/title and count number of intersection between query and title for each category.\\n- Counting features: Length of query, number of common grams between query and title, Jacquard similarity, etc.\\n- Co-occurrence features: Measures of how frequently words appear together. e.g., Latent Semantic Analysis (LSA).\\n- Semantic features: Measure how similar the meaning of two words is.\\n- Statistical features: Compare queries with unknown score to queries with known relevance score.\\n\\nIt seems that a lot of the top teams had similar types of features, but the implementation details are probably different. For our ensemble we used different variations of xgboost along with a ridge regression model.\\n\\nFor models and ensemble we started with random forest, extra trees and gbm-models. Furthermore xgboost and ridge were in our focus. Shortly prior to the end of the competition we found out, that first random forest and then extra trees did not help our ensembles anymore. So we focused on xgboost, gbm and Ridge.\\n\\nOur best single model was a xgboost-model and scored 0.43347 on the public LB. The final ensemble consists of 19 models based on xgboost, gbm and Ridge. The xgboost-models were made with different parameters including binarizing the target, objective reg:linear, and objective count:poisson. We found, that the Ridge Regression helped in nearly every case, so we included it in the final ensemble.\\n\\n# Were you surprised by any of your findings?\\n\\nA surprising finding was the large number of features which had predictive ability. In particular, when we teamed up, it was better to combine our features than to ensemble our results. This is quite unique as most of the time new features are more likely to cause overfit but not in this case. As a result, adding more members to the team was highly likely to improve score which is why the top-10 were all teams of at least 3 people.\\n\\n# Which tools did you use?\\n\\nWe used mainly Python 3 and Python 2. The decision for Python 2 is interesting as some of the used libraries are still not available for Python 3. In our processing chain we used the Python standard tools for machine learning (scikit-learn, nltk, pandas, numpy, scipy, xgboost, gensim). Nima used R for feature generation.\\n\\n# How did you spend your time on this competition?\\n\\nAfter teaming up, Sean and Nima spent most of their time on feature engineering and Thomas and Qingchen spent most of their time on model tuning.\\n\\n# What was the run time for both training and prediction of your winning solution?\\n\\nIn general, training/prediction time is very fast (minutes), but we used some xgboost parameters that took much longer to train (hours) for small performance gains. Text processing and feature engineering took a very long time (easily over 8 hours for a single feature set).\\n\\n# Words of wisdom\\n\\n# What have you taken away from this competition?\\n\\nFirst of all quite a lot of Kaggle ranking points and Thomas got his Master badge! Overall this was a very difficult competition and we learned a lot about natural language processing and information retrieval in practice. It now makes sense why Google is able to use such a large number of features in their search algorithm as m...\", \"url\": \"https://medium.com/kaggle-blog/home-depot-product-search-relevance-winners-interview-2nd-place-thomas-sean-qingchen-nima-68068f9f9ffd\"}]}",
        "tool.duration_ms": 3563.264846801758
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "d7a8d9e2367690d4",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "WebSearchTool",
      "kind": "INTERNAL",
      "start_time": 1767959046376747071,
      "end_time": 1767959050565431344,
      "duration": 4.188684273,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "WebSearchTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What ensembling strategies work best for text classification competitions on Kaggle?\"}}",
        "tool.output": "{\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nEnsembling is the de‚Äëfacto standard for winning Kaggle text‚Äëclassification contests.  The most reliable recipe combines **diverse fine‚Äëtuned language models** (e.g., BERT, RoBERTa, DeBERTa, GPT‚Äëbased classifiers) and aggregates their outputs with a **simple blending or voting step** before feeding the blended predictions into a **second‚Äëlevel meta‚Äëmodel**.  Studies that collected predictions from five large fine‚Äëtuned models across six datasets showed that even straightforward averaging or majority‚Äëvote ensembles consistently lift accuracy and give better uncertainty estimates than any single model‚ÄØ([arxiv.org/html/2410.19889v1](https://arxiv.org/html/2410.19889v1)).  For classification, using the **geometric mean of class probabilities** (instead of a plain arithmetic mean) often yields a small but steady gain‚ÄØ([campus.datacamp.com](https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/modeling?ex=8)).  When the ensemble contains many heterogeneous LLMs, a **majority‚Äërules / collective decision** aggregation can boost F1 by up to 65‚ÄØ% over the strongest single model, confirming that diversity and a principled voting scheme are crucial‚ÄØ([arxiv.org/html/2511.15714v1](https://arxiv.org/html/2511.15714v1)).\\n\\nThe next level of performance comes from **stacked generalization**: each base model‚Äôs out‚Äëof‚Äëfold predictions become features for a lightweight meta‚Äëlearner (often logistic regression, LightGBM, or CatBoost).  This ‚Äústacking‚Äù captures complementary error patterns and typically outperforms pure blending, especially when the base models are low‚Äëcorrelated (trained on different seeds, data splits, or architectures)‚ÄØ([campus.datacamp.com](https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/modeling?ex=8)).  Kaggle practitioners also enrich ensembles with **rank‚Äëbased averaging** or **error‚Äëcorrecting‚Äëcode voting** to further reduce variance‚ÄØ([cnblogs.com/medsci/articles/9160663.html](https://www.cnblogs.com/medsci/articles/9160663.html)).  In practice, the best Kaggle text‚Äëclassification pipelines therefore follow a three‚Äëstep stack: (1) train a heterogeneous set of fine‚Äëtuned transformers/LLMs, (2) blend their probabilities with a geometric mean or majority vote, and (3) train a second‚Äëlevel model on the blended predictions to produce the final submission.\\n\\n--- Result 2 ---\\nTitle: Ensembling Finetuned Language Models\\n for Text Classification\\nURL: https://arxiv.org/html/2410.19889v1\\n\\nContent:\\nEnsembling Finetuned Language Models for Text Classification\\n# Ensembling Finetuned Language Models\\nfor Text Classification\\nSebastian Pineda Arango1, Maciej Janowski111footnotemark:1, Lennart Purucker1, Arber Zela1,\\nFrank Hutter3,1,¬†Josif Grabocka2\\n1University of Freiburg,2University of Technology N√ºrnberg,3ELLIS Institute T√ºbingenEqual contribution. Corresponding author:pineda@cs.uni-freiburg.de\\n###### Abstract\\nFinetuning is a common practice widespread across different communities to adapt pretrained models to particular tasks.\\nText classification is one of these tasks for which many pretrained models are available. On the other hand, ensembles of neural networks are typically used to boost performance and provide reliable uncertainty estimates. However, ensembling pretrained models for text classification is not a well-studied avenue. In this paper, we present a metadataset with predictions from five large finetuned models on six datasets, and report results of different ensembling strategies from these predictions. Our results shed light on how ensembling can improve the performance of finetuned text classifiers and incentivize future adoption of ensembles in such tasks.\\n## 1Introduction\\nIn recent years, fine-tuning pretrained models has become a widely adopted technique for adapting general-purpose models to specific tasks> (Arango et¬†al., [> 2023\\n](https://arxiv.org/html/2410.19889v1#bib.bib2)> )\\n. This practice has gained significant traction across various communities due to its effectiveness in leveraging the vast knowledge encoded in pretrained models. Among the diverse tasks that benefit from fine-tuning, text classification stands out as one of the most prevalent. With the availability of numerous pretrained models, practitioners often find themselves with a range of powerful tools to tackle text classification challenges.\\nHowever, despite the widespread use of fine-tuning, the potential benefits of combining or ensembling these fine-tuned models remain underexplored.\\nPrevious studies have primarily concentrated on improving individual model performance through fine-tuning techniques> (Howard &amp; Ruder, [> 2018\\n](https://arxiv.org/html/2410.19889v1#bib.bib16)> )\\n, leaving the exploration of ensemble strategies largely underdeveloped in this context. This oversight is particularly significant given the well-documented advantages of model ensembling in other machine learning domains> (Erickson et¬†al., [> 2020\\n](https://arxiv.org/html/2410.19889v1#bib.bib10)> ; Lakshminarayanan et¬†al., [> 2017\\n](https://arxiv.org/html/2410.19889v1#bib.bib20)> )\\n, which has been shown to enhance robustness and generalization. In this paper, we address the aforementioned gap by introducing a novel metadataset, which we dub: Finetuning Text Classifiers (FTC) metadataset. FTC contains predictions from various fine-tuned models on text classification tasks with various number of classes. We systematically evaluate different ensembling strategies using this metadataset, aiming to uncover insights into the potential improvements that ensembling can offer. Our results provide valuable evidence on the efficacy of these strategies, demonstrating that ensembling fine-tuned models can lead to performance gains in text classification.\\n## 2Background and Related Work\\nFinetuning for Text Classification.Universal Language Model Fine-tuning for Text Classification or ULMFiT> (Howard &amp; Ruder, [> 2018\\n](https://arxiv.org/html/2410.19889v1#bib.bib16)> )\\nconsists of finetuning language models for classification in two stages: 1) a target task unsupervised finetuning and 2) target task classifier finetuning, while using a different learning rate per layer. However, the feasibility of fully fine-tuning large pretrained language models is constrained by computational limits> (Radford et¬†al., [> 2018\\n](https://arxiv.org/html/2410.19889v1#bib.bib31)> )\\n. This has spurred the adoption of Parameter-Efficient Fine-Tuning (PEFT) methods> (Han et¬†al., [> 2024\\n](https://arxiv.org/html/2410.19889v1#bib.bib13)> )\\n. Early strategies focused on minimal subsets of parameters such as sparse subnetworks> (Sung et¬†al., [> 2021\\n](https://arxiv.org/html/2410.19889v1#bib.bib37)> )\\nto improve task-specific performance efficiently. Innovations such as adapter modules> (Houlsby et¬†al., [> 2019\\n](https://arxiv.org/html/2410.19889v1#bib.bib15)> )\\n, which introduce a few parameters per transformer layer but in consequence increase inference time, prompted the development of Low-Rank Adaptation (LoRA)> (Hu et¬†al., [> 2022\\n](https://arxiv.org/html/2410.19889v1#bib.bib17)> ; Dettmers et¬†al., [> 2024\\n](https://arxiv.org/html/2410.19889v1#bib.bib7)> )\\nthat applies low-rank updates for improved downstream task performance with reduced computational overhead. Some studies have also demonstrated that finetuned language models can be ensembled to improve performance for text classification> (Abburi et¬†al., [> 2023\\n](https://arxiv.org/html/2410.19889v1#bib.bib1)> )\\n, but they do not provide clear insights about ensembling methods, hyperparameters, or metadata.\\nEnsembling Deep Learning Models.Ensembles of neural networks> (Hansen &amp; Salamon, [> 1990\\n](https://arxiv.org/html/2410.19889v1#bib.bib14)> ; Krogh &amp; Vedelsby, [> 1995\\n](https://arxiv.org/html/2410.19889v1#bib.bib19)> ; Dietterich, [> 2000\\n](https://arxiv.org/html/2410.19889v1#bib.bib9)> )\\nhave gained significant attention in deep learning research, both for their performance-boosting capabilities and their effectiveness in uncertainty estimation. Various strategies for building ensembles exist, with deep ensembles> (Lakshminarayanan et¬†al., [> 2017\\n](https://arxiv.org/html/2410.19889v1#bib.bib20)> )\\nbeing the most popular one, which involve independently training multiple initializations of the same network.\\nTheir state-of-the-art predictive uncertainty estimates have further fueled the interest in ensembles. Extensive empirical studies> (Ovadia et¬†al., [> 2019\\n](https://arxiv.org/html/2410.19889v1#bib.bib27)> ; Gustafsson et¬†al., [> 2020\\n](https://arxiv.org/html/2410.19889v1#bib.bib12)> )\\nhave shown that deep ensembles outperform other approaches for uncertainty estimation, such as Bayesian neural networks> (Blundell et¬†al., [> 2015\\n](https://arxiv.org/html/2410.19889v1#bib.bib3)> ; Gal &amp; Ghahramani, [> 2016\\n](https://arxiv.org/html/2410.19889v1#bib.bib11)> ; Welling &amp; Teh, [> 2011\\n](https://arxiv.org/html/2410.19889v1#bib.bib40)> )\\n. Similar to our work,> Seligmann et¬†al. (\\n[> 2024\\n](https://arxiv.org/html/2410.19889v1#bib.bib35)> )\\nshow that finetuning pretrained models via Bayesian methods on the WILDS dataset> (Koh et¬†al., [> 2021\\n](https://arxiv.org/html/2410.19889v1#bib.bib18)> )\\n, which contains text classification as well, can yield significant performance as compared to standard finetuning of single models.\\nPost-Hoc Ensembling (PHE).PHE uses set of fitted base models{z1,‚Ä¶,zM}subscriptùëß1‚Ä¶subscriptùëßùëÄ\\\\\\\\{z\\\\_{1},...,z\\\\_{M}\\\\\\\\}{ italic\\\\_z start\\\\_POSTSUBSCRIPT 1 end\\\\_POSTSUBSCRIPT , ‚Ä¶, italic\\\\_z start\\\\_POSTSUBSCRIPT italic\\\\_M end\\\\_POSTSUBSCRIPT }such that every model outputszm‚Å¢(x),zm:‚ÑùD‚Üí‚ÑùC:subscriptùëßùëöùë•subscriptùëßùëö‚Üísuperscript‚Ñùùê∑superscript‚Ñùùê∂z\\\\_{m}(x),z\\\\_{m}:\\\\\\\\mathbb{R}^{D}\\\\\\\\rightarrow\\\\\\\\mathbb{R}^{C}italic\\\\_z start\\\\_POSTSUBSCRIPT italic\\\\_m end\\\\_POSTSUBSCRIPT ( italic\\\\_x ) , italic\\\\_z start\\\\_POSTSUBSCRIPT italic\\\\_m end\\\\_POSTSUBSCRIPT : blackboard\\\\_R start\\\\_POSTSUPERSCRIPT italic\\\\_D end\\\\_POSTSUPERSCRIPT ‚Üíblackboard\\\\_R start\\\\_POSTSUPERSCRIPT italic\\\\_C end\\\\_POSTSUPERSCRIPT111We assume a classification tasks withCùê∂Citalic\\\\_Cclasses. For regressionC=1ùê∂1C=1italic\\\\_C = 1.. These outputs are combined by an ensemblerf‚Å¢(z1‚Å¢(x),‚Ä¶,zM‚Å¢(x);Œ∏)=f‚Å¢(z‚Å¢(x);Œ∏)ùëìsubscriptùëß1ùë•‚Ä¶subscriptùëßùëÄùë•ùúÉùëìùëßùë•ùúÉf(z\\\\_{1}(x),...,z\\\\_{M}(x);\\\\\\\\theta)=f(z(x);\\\\\\\\theta)italic\\\\_f ( italic\\\\_z start\\\\_POSTSUBSCRIPT 1 end\\\\_POSTSUBSCRIPT ( italic\\\\_x ) , ‚Ä¶, italic\\\\_z start\\\\_POSTSUBSCRIPT italic\\\\_M end\\\\_POSTSUBSCRIPT ( italic\\\\_x ) ; italic\\\\_Œ∏ ) = italic\\\\_f ( italic\\\\_z ( italic\\\\_x ) ; italic\\\\_Œ∏ ),...\\n\\n--- Result 3 ---\\nTitle: Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization\\nURL: https://arxiv.org/html/2511.15714v1\\n\\nContent:\\nMajority Rules: LLM Ensemble is a Winning Approach for Content Categorization\\n# Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization\\nAriel Kamen\\nRingCentral Inc.\\nariel.kamen@ringcentral.comYakov Kamen\\nRelevad Corporation\\nyakov@relevad.com\\n(November 1, 2025)\\n###### Abstract\\nThis study introduces an ensemble framework for unstructured text categorization using large language models (LLMs). By integrating multiple models, the ensemble large language model (eLLM) framework addresses common weaknesses of individual systems, including inconsistency, hallucination, category inflation, and misclassification. The eLLM approach yields a substantial performance improvement of up to 65% in F1-score over the strongest single model. We formalize the ensemble process through a mathematical model of collective decision-making and establish principled aggregation criteria. Using the Interactive Advertising Bureau (IAB) hierarchical taxonomy, we evaluate ten state-of-the-art LLMs under identical zero-shot conditions on a human-annotated corpus of 8,660 samples. Results show that individual models plateau in performance due to the compression of semantically rich text into sparse categorical representations, while eLLM improves both robustness and accuracy. With a diverse consortium of models, eLLM achieves near human-expert-level performance, offering a scalable and reliable solution for taxonomy-based classification that may significantly reduce dependence on human expert labeling.\\nIndex Terms‚ÄîAI, large language models, LLM, multi-LLM, LLM ensemble, collective intelligence, content categorization, collective decision-making, CDM, ensemble framework, eLLM.\\n## 1.‚ÄÉ‚ÄäIntroduction\\nText categorization (also termed text classification) is a foundational problem in natural language processing. Early systems relied on human experts to assign categories using controlled vocabularies and taxonomies. This labor-intensive workflow gradually gave way to rule-based heuristics and, later, to classical machine-learning pipelines with domain-specific training and hand-engineered features. While effective within constrained settings, these approaches required substantial manual effort and did not scale easily across heterogeneous domains.\\nLarge language models (LLMs)‚Äîincluding GPT, Gemini, Claude, Grok, LLaMA, Mistral, xAI, and DeepSeek‚Äîhave introduced strong zero-shot capabilities, motivating efforts to replace task-specific classifiers with general-purpose LLMs. Despite notable successes of LLMs in reasoning, scientific discovery, and content generation, their performance in taxonomy-based categorization has lagged. Empirically, single models exhibit instability, category inflation, and hallucination, often producing incoherent or non-existent labels.\\nThis performance gap reflects the unique nature of categorization as an information-compression task: semantically rich, unstructured inputs must be mapped into a small set of category names defined by a fixed taxonomy. Such taxonomies typically represent the real world sparsely, and individual texts may map to multiple categories with varying levels of relevance. Accurate mapping frequently requires background knowledge external to the text‚Äîsuch as domain conventions or factual context‚Äîthat distinguishes professional experts from general readers. In our experiments with ten widely used zero-shot LLMs spanning multiple families and release generations, we observe a consistent performance plateau: increasing model size or algorithmic sophistication does not yield commensurate gains once a threshold is reached> (Kamen, [> 2025\\n](https://arxiv.org/html/2511.15714v1#bib.bib15)> )\\n.\\nTo address these limitations, we developed an ensemble of LLMs (eLLM), treating each model as an independent expert and combining their predictions through a collective decision-making rule. This design is motivated by the well-established benefits of aggregation in both human and algorithmic committees, where diversity and redundancy suppress individual errors and reduce variance. By leveraging models built on diverse architectures, training paradigms, and knowledge bases, the ensemble extends the effective knowledge universe of any single LLM, enabling more comprehensive coverage of sparse taxonomies. In taxonomy classification, we find that ensembling mitigates common single-model failure modes‚Äîsuch as hallucinations and inconsistent label usage‚Äîwhile substantially improving both accuracy and stability. The results are striking: ensembles with sufficient diversity not only surpass the strongest individual models but, in some conditions, approach or exceed the consistency of human expert annotation. The principal trade-off lies in computational cost, since multiple model evaluations are required at inference time. This direction aligns with growing evidence that collaborative or multi-agent LLM strategies can overcome inherent limitations of single-model systems> (Feng et¬†al., [> 2025\\n](https://arxiv.org/html/2511.15714v1#bib.bib9)> )\\n. The eLLM‚Äôs capacity for automatic error counterbalancing represents a practical form of self-correction‚Äîan essential step toward reliable artificial intelligence.\\nThis paper makes the following contributions:\\n* ‚Ä¢We formalize an ensemble LLM framework for taxonomy-based categorization, specifying aggregation criteria within a collective decision-making model tailored to sparse hierarchical label spaces.\\n* ‚Ä¢We instantiate eLLM with multiple committee sizes (2, 3, 5, 7, and 10 models) and evaluate them under uniform zero-shot prompting on a human-annotated corpus of 8,660 samples labeled with the IAB¬†2.2 taxonomy.\\n* ‚Ä¢We provide empirical evidence of substantial improvements over the best single model, including large gains in F1-score, reduced category inflation, and lower hallucination rates, and we analyze the computational trade-offs of ensembling.\\n* ‚Ä¢We discuss conditions under which eLLM approaches human-expert performance, and the implications for scalable, reliable labeling pipelines.\\nTogether, these results suggest that ensemble-based categorization is a practical and robust alternative to single-model LLM classification, particularly when adherence to a fixed taxonomy and reliability under distributional shift are required. This work builds toward a new theory of collaborative AI, where orchestrated ensembles transform unstructured chaos into ordered, expert-level insight.\\n## 2.‚ÄÉ‚ÄäRelated Work\\nOur research on ensemble large language models (eLLM) for hierarchical text categorization builds upon and integrates advances in three major domains: (1) taxonomy-based classification, (2) zero-shot categorization with large language models, and (3) collective decision-making and ensemble learning. It directly extends the findings of> (Kamen, [> 2025\\n](https://arxiv.org/html/2511.15714v1#bib.bib15)> )\\n, which identified structural limitations in single-model LLM categorization and established the empirical foundation for ensemble-based approaches.\\n### 2.1.‚ÄÉ‚ÄäTaxonomy-Based Hierarchical Classification\\nText categorization has been a central task in natural language processing (NLP) for several decades. Early systems relied on manual annotation and rule-based heuristics, later replaced by supervised pipelines built upon feature engineering and linear classifiers> (Sebastiani, [> 2002\\n](https://arxiv.org/html/2511.15714v1#bib.bib26)> )\\n. As taxonomies expanded in depth and scope, hierarchical classification emerged as a natural extension, in which labels are organized into a tree or directed acyclic graph> (Jr. et¬†al., [> 2011\\n](https://arxiv.org/html/2511.15714v1#bib.bib14)> )\\n.\\nHierarchical classification requires predictions that respect structural dependencies, maintain parent‚Äìchild consistency, and remain valid across all levels of granularity. Various methods have been proposed to address these challenges, including structural loss functions> (Hsu et¬†al., [> 2009\\n](https://arxiv.org/html/2511.15714v1#bib.bi...\\n\\n--- Result 4 ---\\nTitle: Model ensembling | Python\\nURL: https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/modeling?ex=8\\n\\nContent:\\nModel ensembling | Python https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/modeling?ex=8\\nModel ensembling | Python\\nNone\\n2022-06-13T00:00:00Z\\n# Model ensembling\\n####. Model ensembling\\nSo far, we've been talking only about individual models. Now it's time to combine multiple models together.\\n####. Model ensembling\\nKaggle top solutions are usually not a single model, but a combination of a large number of various models. Different ways to combine models together is called model ensembling.\\nFor example, here is an ensemble design for a winning solution in the Homesite Quote Conversion challenge. We can see hundreds of models with multi-level stacking and blending. Let's learn about these 'blending' and 'stacking' terms.\\n####. Model blending\\nThe idea of ensemble learning is to build a prediction model by combining the strengths of a collection of simpler base models. The so-called blending approach is to just find an average of our multiple models predictions.\\nSay we're solving a regression problem with a continuous target variable.\\nAnd we have trained two models: A and B.\\nSo, for each test observation, there are model A and model B predictions available.\\n####. Model blending\\nTo combine models together we can just find the predictions mean, taking the sum and divide it by two. As we see, it allows us to tweak predictions, and to take into account both model A and model B opinions.\\nThat's it, such a simple ensembling method in the majority of cases will yield some improvement to our single models.\\n####. Model blending\\nArithmetic mean works for both regression and classification problems. However, for the classification, it's better to use a geometric mean of the class probabilities predicted.\\n####. Model stacking\\nThe more advanced ensembling approach is called model stacking. The idea is to train multiple single models, take their predictions and use these predictions as features in the 2nd level model.\\nSo, we need to perform the following steps:\\nSplit train data into two parts. Part 1 and Part 2.\\nTrain multiple single models on the first part.\\nMake predictions on the second part of the train data,\\nand on the test data. Now, we have models predictions for both Part 2 of the train data and for the test data.\\nIt means that we could create a new model using these predictions as features. This model is called the 2nd level model or meta-model.\\nIts predictions on the test data give us the stacking output.\\n####. Stacking example\\nLet's consider all these steps on the example.\\nSuppose we are given a binary classification problem with a bunch of numerical features: feature_1, feature_2 and so on to feature_N. For the train data, target variable is known.\\nAnd we need to make predictions on the test data with the unknown target variable.\\n####. Stacking example\\nFirst of all, we split train data into two separate parts: Part 1 and Part 2.\\n####. Stacking example\\nThen we train multiple single models only on the first part of the train data. For example, we've trained three different models denoting them as A, B and C.\\n####. Stacking example\\nHaving these 3 models we make the predictions on part 2 of the train data. The columns with the predictions are denoted as A_pred, B_pred and C_pred.\\nThen make the predictions on the test data as well.\\n####. Stacking example\\nSo, now we have models predictions for both Part 2 of the train data and for the test data.\\n####. Stacking example\\nIt's now possible to create a second level model using these predictions as features. It's trained on the Part 2 train data and is used to make predictions on the test data.\\n####. Stacking example\\nAs a result, we obtain stacking predictions for the test data. Thus, we combined individual model predictions into a single number using a 2nd level model.\\n####. Let's practice!\\nOK, having learned the theory, move on to build your own model ensembles!\\nShow Transcripts\\n### Create Your Free Account\\nor\\nEmail AddressPasswordStart Learning for FreeBy continuing, you accept our [Terms of Use](https://www.datacamp.com/terms-of-use), our [Privacy Policy](https://www.datacamp.com/privacy-policy) and that your data is stored in the USA.\\n\\n--- Result 5 ---\\nTitle: KAGGLE ENSEMBLING GUIDE\\nURL: https://www.cnblogs.com/medsci/articles/9160663.html\\n\\nContent:\\n[ÂçöÂÆ¢Âõ≠](https://www.cnblogs.com/) [È¶ñÈ°µ](https://www.cnblogs.com/medsci/) [Êñ∞ÈöèÁ¨î](https://i.cnblogs.com/EditPosts.aspx?opt=1) [ËÅîÁ≥ª](https://msg.cnblogs.com/send/medsci) [ËÆ¢ÈòÖ](javascript:void(0)) [ÁÆ°ÁêÜ](https://i.cnblogs.com/)\\n\\n# [KAGGLE ENSEMBLING GUIDE](https://www.cnblogs.com/medsci/articles/9160663.html)\\n\\nËΩ¨ËΩΩËá™¬† https://mlwave.com/kaggle-ensembling-guide/\\n\\ngithub:¬† https://github.com/MLWave/Kaggle-Ensemble-Guide\\n\\nModel ensembling is a very powerful technique to increase accuracy on a variety of ML tasks. In this article I will share my ensembling approaches for Kaggle Competitions.\\n\\nFor the first part we look at creating ensembles from submission files. The second part will look at creating ensembles through stacked generalization/blending.\\n\\nI answer why ensembling reduces the generalization error. Finally I show different methods of ensembling, together with their results and code to try it out for yourself.\\n\\n> This is how you win ML competitions: you take other peoples‚Äô work and ensemble them together.‚Äù¬†[Vitaly Kuznetsov](http://cims.nyu.edu/~vitaly/)¬†NIPS2014\\n\\n## Creating ensembles from submission files\\n\\nThe most basic and convenient way to ensemble is to ensemble Kaggle submission CSV files. You only need the predictions on the test set for these methods ‚Äî no need to retrain a model. This makes it a quick way to ensemble already existing model predictions, ideal when teaming up.\\n\\n### Voting ensembles.\\n\\nWe first take a look at a simple majority vote ensemble. Let‚Äôs see why model ensembling reduces error rate and why it works better to ensemble low-correlated model predictions.\\n\\n#### Error correcting codes\\n\\nDuring space missions it is very important that all signals are correctly relayed.\\n\\nIf we have a signal in the form of a binary string like:\\n\\n```\\n1110110011101111011111011011\\n\\n```\\n\\nand somehow this signal is corrupted (a bit is flipped) to:\\n\\n```\\n1010110011101111011111011011\\n\\n```\\n\\nthen lives could be lost.\\n\\nA¬†[coding](http://en.wikipedia.org/wiki/Coding_theory)¬†solution was found in¬†[error correcting codes](http://en.wikipedia.org/wiki/Forward_error_correction). The simplest error correcting code is a¬†[repetition-code](http://en.wikipedia.org/wiki/Repetition_code): Relay the signal multiple times in equally sized chunks and have a majority vote.\\n\\n```\\nOriginal signal:\\n1110110011\\n\\nEncoded:\\n10,3 101011001111101100111110110011\\n\\nDecoding:\\n1010110011\\n1110110011\\n1110110011\\n\\nMajority vote:\\n1110110011\\n\\n```\\n\\nSignal corruption is a very rare occurrence and often occur in small bursts. So then it figures that it is even rarer to have a corrupted majority vote.\\n\\nAs long as the corruption is not completely unpredictable (has a 50% chance of occurring) then signals can be repaired.\\n\\n#### A machine learning example\\n\\nSuppose we have a test set of 10 samples. The ground truth is all positive (‚Äú1‚Äù):\\n\\n```\\n1111111111\\n\\n```\\n\\nWe furthermore have 3 binary classifiers (A,B,C) with a 70% accuracy. You can view these classifiers for now as pseudo-random number generators which output a ‚Äú1‚Äù 70% of the time and a ‚Äú0‚Äù 30% of the time.\\n\\nWe will now show how these pseudo-classifiers are able to obtain 78% accuracy through a voting ensemble.\\n\\n##### A pinch of maths\\n\\nFor a majority vote with 3 members we can expect 4 outcomes:\\n\\n```\\nAll three are correct\\n  0.7 * 0.7 * 0.7\\n= 0.3429\\n\\nTwo are correct\\n  0.7 * 0.7 * 0.3\\n+ 0.7 * 0.3 * 0.7\\n+ 0.3 * 0.7 * 0.7\\n= 0.4409\\n\\nTwo are wrong\\n  0.3 * 0.3 * 0.7\\n+ 0.3 * 0.7 * 0.3\\n+ 0.7 * 0.3 * 0.3\\n= 0.189\\n\\nAll three are wrong\\n  0.3 * 0.3 * 0.3\\n= 0.027\\n\\n```\\n\\nWe see that most of the times (~44%) the majority vote corrects an error. This majority vote ensemble will be correct an average of ~78% (0.3429 + 0.4409 = 0.7838).\\n\\n#### Number of voters\\n\\nLike repetition codes increase in their error-correcting capability when more codes are repeated, so do ensembles usually improve when adding more ensemble members.\\n\\nUsing the same pinch of maths as above: a voting ensemble of 5 pseudo-random classifiers with 70% accuracy would be correct ~83% of the time. One or two errors are being corrected during ~66% of the majority votes. (0.36015 + 0.3087)\\n\\n#### Correlation\\n\\nWhen I first joined the team for KDD-cup 2014, Marios Michailidis ( [KazAnova](https://www.kaggle.com/kazanova)) proposed something peculiar. He calculated the¬†[Pearson correlation](http://onlinestatbook.com/2/describing_bivariate_data/pearson.html)¬†for all our submission files and gathered a few well-performing models which were less correlated.\\n\\nCreating an averaging ensemble from these diverse submissions gave us the¬†biggest 50-spot jump on the leaderboard. Uncorrelated submissions clearly do better when ensembled than correlated submissions. But why?\\n\\nTo see this, let us take 3 simple models again. The ground truth is still all 1‚Äôs:\\n\\n```\\n1111111100 = 80% accuracy\\n1111111100 = 80% accuracy\\n1011111100 = 70% accuracy.\\n\\n```\\n\\nThese models are highly correlated in their predictions. When we take a majority vote we see no improvement:\\n\\n```\\n1111111100 = 80% accuracy\\n\\n```\\n\\nNow we compare to 3 less-performing, but highly uncorrelated models:\\n\\n```\\n1111111100 = 80% accuracy\\n0111011101 = 70% accuracy\\n1000101111 = 60% accuracy\\n\\n```\\n\\nWhen we ensemble this with a majority vote we get:\\n\\n```\\n1111111101 = 90% accuracy\\n\\n```\\n\\nWhich¬†_is_¬†an improvement: A lower correlation between ensemble model members seems to result in an increase in the error-correcting capability.\\n\\n#### Use for Kaggle: Forest Cover Type prediction\\n\\nMajority votes make most sense when the evaluation metric requires hard predictions, for instance with (multiclass-) classification accuracy.\\n\\nThe¬†[forest cover type prediction](https://www.kaggle.com/c/forest-cover-type-prediction)¬†challenge uses the¬†[UCI Forest CoverType dataset](https://archive.ics.uci.edu/ml/datasets/Covertype). The dataset has¬†54 attributes and there are 6 classes.\\n\\nWe create a simple¬†[starter model](https://www.kaggle.com/triskelion/forest-cover-type-prediction/first-try-with-random-forests)¬†with a 500-tree Random Forest. We then create a few more models and pick the best performing one. For this task and our model selection an ExtraTreesClassifier works best.\\n\\n##### Weighing\\n\\nWe then use a weighted majority vote. Why weighing? Usually we want to give a better model more weight in a vote. So in our case we count the vote by the best model 3 times.¬†The other 4 models count for one vote each.\\n\\nThe reasoning is as follows: The only way for the inferior models to overrule the best model (expert) is for them to¬†collectively (and confidently) agree on an alternative.\\n\\nWe can expect this ensemble to repair a few erroneous choices by the best model, leading to a small improvement only.¬†That‚Äôs our punishment for forgoing a democracy and creating a Plato‚Äôs¬†_Republic_.\\n\\n> ‚ÄúEvery city encompasses two cities that are at war with each other.‚Äù¬†Plato in¬†The Republic\\n\\nTable 1. shows the result of training 5 models, and the resulting score when combining these with a weighted majority vote.\\n\\n| MODEL | PUBLIC ACCURACY SCORE |\\n| --- | --- |\\n| GradientBoostingMachine | 0.65057 |\\n| RandomForest Gini | 0.75107 |\\n| RandomForest Entropy | 0.75222 |\\n| ExtraTrees Entropy | 0.75524 |\\n| ExtraTrees Gini (Best) | 0.75571 |\\n| Voting Ensemble (Democracy) | 0.75337 |\\n| Voting Ensemble (3\\\\*Best vs. Rest) | 0.75667 |\\n\\n#### Use for Kaggle: CIFAR-10 Object detection in images\\n\\nCIFAR-10 is another multi-class classification challenge where accuracy matters.\\n\\nOur team leader for this challenge,¬†[Phil Culliton](https://www.kaggle.com/philculliton), first found the best setup to¬†[replicate a good model](http://blog.kaggle.com/2015/01/02/cifar-10-competition-winners-interviews-with-dr-ben-graham-phil-culliton-zygmunt-zajac/)¬†from dr. Graham.\\n\\nThen he used a voting ensemble of around 30 convnets submissions (all scoring above 90% accuracy). The best¬†single model of the ensemble scored¬†0.93170.\\n\\nA voting ensemble of 30 models scored¬†0.94120. A ~0.01 reduction in error rate, pushing the resulting score beyond the¬†[estimated human clas...\\n\\n--- Result 6 ---\\nURL: https://arxiv.org/pdf/2410.19889\\n\\nContent:\\narXiv reCAPTCHA\\n[![Cornell University](https://static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\\n[We gratefully acknowledge support from\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)\\n# [![arxiv logo](https://static.arxiv.org/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)\\n\\n--- Result 7 ---\\nTitle: Kaggle Champions: Ensemble Methods in Machine Learning | Toptal¬Æ\\nURL: https://www.toptal.com/machine-learning/ensemble-methods-kaggle-machine-learn\\n\\nContent:\\n<div><div>\\n<p>The proverb ‚ÄúTwo heads are better than one‚Äù takes on new meaning when it comes to <a href=\\\"https://www.toptal.com/machine-learning\\\">machine learning</a> ensembles. Ensemble methods are some of the most decorated ML families at Kaggle competitions, where they often win contests with their impressive results.</p>\\n<p>But it was a century before Kaggle when statistician Sir Francis Galton noticed the potency of aggregated intelligence. He happened upon a competition at a livestock fair where participants had to guess the weight of an ox. Eight hundred people submitted guesses, but their skill levels varied: Farmers and butchers guessed alongside city dwellers who had never seen an ox up close, so Galton thought the average guess would be quite wrong.</p>\\n<p>It <a href=\\\"https://projecteuclid.org/download/pdfview_1/euclid.ss/1411437521\\\">turned out</a> that the mean of the crowd‚Äôs guesses was off by less than a pound (&lt; 0.1%). However, even the best individual predictions were well off the mark.</p>\\n<p>How could that be? What made such an unexpected result possible?</p>\\n<h2>What Makes Machine Ensembles so Effective</h2>\\n<p>The event that forced Galton to question his beliefs also illustrates what makes ensembles so powerful: If you have <strong>different</strong> <strong>and independent models</strong>, trained using <strong>different parts of data</strong> for the same problem, they will work better together than individually. The reason? Each model will learn a different part of the concept. Therefore, each model will produce valid results and errors based on its ‚Äúknowledge.‚Äù</p>\\n<p>But the most interesting thing is that each true part will complement the others while the errors cancel out each other:</p>\\n<div><figure><a href=\\\"https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/750064/image-1631891397968-d95bfcfccb53db7971c25b2a53222b3f.png\\\"></a></figure></div>\\n<p>You need to train models with high variance (like decision trees) over distinct subsets of data. This added variance means that each model overfits different data, but when combined, the variance disappears, as if by magic. This creates a new, more robust model.</p>\\n<p>Just like in Galton‚Äôs case, when all data from all sources is combined, the result is ‚Äúsmarter‚Äù than isolated data points.</p>\\n<h3>A Closer Look at Ensemble Learning in Kaggle Competitions</h3>\\n<p>At the <a href=\\\"https://www.kaggle.com/c/otto-group-product-classification-challenge/overview\\\">Otto Group Product Classification Challenge</a>, participants had to build a predictive model that was able to distinguish between main product categories.</p>\\n<p>Here you can see how <a href=\\\"https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335\\\">the winning model was built</a>. It was a stacking of three layers: The first had 33 models, the second added three more (XGBoost, a neural network, and AdaBoost), and the third was the weighted mean of the previous layer outputs. It was both a very complex model and an ensemble.</p>\\n<p>Another Kaggle success is the model created by Chenglong Chen at the <a href=\\\"https://www.kaggle.com/c/crowdflower-search-relevance/overview\\\">Crowdflower Search Results Relevance competition</a>. The challenge was to create a predictor that could be used to measure the relevance of search results. You can read the complete <a href=\\\"https://github.com/ChenglongChen/kaggle-CrowdFlower\\\">explanation of his method</a>, but as our point of interest is ensembles, the critical part of the story is that the winning solution used an ensemble of 35 models, many of which were also ensembles‚Äîa meta-ensemble, so to speak.</p>\\n<h2>Ensemble Methods</h2>\\n<p>There are many ways of implementing ensemble methods in machine learning. We‚Äôll explore some of the most popular methods:</p>\\n<ul>\\n <li>\\n<strong>Bagging</strong>\\n <ul>\\n <li>Random Forest</li>\\n </ul>\\n </li>\\n <li>\\n<strong>Boosting</strong>\\n <ul>\\n <li>AdaBoost</li>\\n <li>Gradient Boosting and XGBoost</li>\\n </ul>\\n </li>\\n <li>\\n<strong>Hybrid Ensemble Methods</strong>\\n <ul>\\n <li>Voting</li>\\n <li>Stacking</li>\\n <li>Cascading</li>\\n </ul>\\n </li>\\n</ul>\\n<h2>Bagging</h2>\\n<p>As mentioned, you need to train many models over different subsets of data. In practice, this is not easy because you will need much more data for many models than you would for a single model, and sometimes it is not easy to obtain high-quality datasets. This is when bagging (bootstrap aggregating) comes in handy, as it splits the data through bootstrapping: a random sample with a replacement, resulting in different subsets that overlap.</p>\\n<p>Once you have trained your ensemble models, you construct your final prediction by aggregating each model prediction through any metric you prefer: the mean, median, mode, and so on. You can also use model prediction probabilities to make a weighted metric:</p>\\n<div><figure><a href=\\\"https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/750065/image-1631891438024-8c044ee5d973b58299ba8a7a56d1484c.png\\\"></a></figure></div>\\n<p>If we want to use <a href=\\\"https://en.wikipedia.org/wiki/Decision_tree_learning\\\">decision trees</a> as models but we have few strong predictive attributes in our data, all the trees will be similar. This is because the same attributes will tend to be in the root node, producing similar results in each branch of the tree.</p>\\n<h3>Random Forest</h3>\\n<p>One technique to address this problem is <strong>random forest</strong>. It makes a bagging ensemble using trees but each node constrains its possible attributes to a random subset. This forces the models to be different, resolving the previous problem. It also makes random forest a very good model for <a href=\\\"https://en.wikipedia.org/wiki/Feature_selection\\\">feature selection</a>.</p>\\n<p>Random forest is one of the most popular ML models because it delivers good performance with low variance and training time.</p>\\n<h2>Boosting</h2>\\n<p>Boosting also uses bootstrapping to train the models, with the main difference being that it adds weights to each instance based on model prediction errors. While bagging is a parallel process, boosting is a sequential one, in which each model has more probabilities. This allows it access to some instances of previous model predictions.</p>\\n<p>With this modification, boosting tries to increase the focus over misclassified instances to reach better global performance:</p>\\n<div><figure><a href=\\\"https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/750066/image-1631891461357-200322840b31404060220a892663aa15.png\\\"></a></figure></div>\\n<p>It adds weights to models too. Predictors with better performance at training time will have a higher weight at the predicting stage.</p>\\n<p>Let‚Äôs take a closer look at some of the most popular boosting models:</p>\\n<h3>AdaBoost</h3>\\n<p>AdaBoost was one of the first implementations of boosting. It does almost exactly what we outlined about boosting in general and uses decision trees as models. Let‚Äôs explain the training phase with some pseudo coding:</p>\\n<pre><code>For each instance i\\n Assign w[i] (weight, same for all)\\nFor each iteration t\\n Generate a subset s[t] by weighted boosting (using the w[i] weights)\\n Train model m[t] using s[t]\\n Store m[t]\\n Calculate e[t] (error rate of m[t])\\n Assign error rate e[t] to stored m[t] model\\n If (e[t] &lt;= a_threshold)\\n Exit for\\n Update weights using m[t] errors\\n</code></pre>\\n<p>At prediction time, it weights each prediction based on the error rate <code>e[t]</code> calculated for each one. Results with a high error rate will have less weight than others with better accuracy.</p>\\n<h3>Gradient Boosting and XGBoost</h3>\\n<p>One of the major problems when training so many models and making them work together is finding the best hyperparameter configuration. It is difficult to find the best configuration for a single model; finding the best configuration for <em>n</em> models increases the complexity exponentially. The ideal configuration fo...\\n\\n--- Result 8 ---\\nTitle: A Comprehensive Guide to Ensemble Learning: What Exactly Do You Need to Know\\nURL: https://neptune.ai/blog/ensemble-learning-guide\\n\\nContent:\\nA Comprehensive Guide to Ensemble Learning: What Exactly Do You Need to Know[\\n**üì£ BIG NEWS:****Neptune is joining OpenAI!**‚Üí Read the message from our CEO üì£![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\\nWhat do you want to find?\\nSearch\\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Neptune Blog](https://neptune.ai/blog)# A Comprehensive Guide to Ensemble Learning: What Exactly Do You Need to Know\\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Derrick-Mwiti.png?fit=193%2C193&ssl=1)\\n[Derrick Mwiti](https://neptune.ai/blog/author/derrickmwiti)\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)8 min\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)25th April, 2025\\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\\n[Ensemble learning techniques](https://www.toptal.com/machine-learning/ensemble-methods-machine-learning)have been proven to yield better performance on machine learning problems. We can use these techniques for regression as well as classification problems.\\nThe final prediction from these ensembling techniques is obtained by combining results from several base models. Averaging, voting and stacking are some of the ways the results are combined to obtain a final prediction.\\nIn this article, we will explore how ensemble learning can be used to come up with optimal machine learning models.\\n## What is ensemble learning?\\nEnsemble learning is a combination of several machine learning models in one problem. These models are known as weak learners. The intuition is that when you combine several weak learners, they can become strong learners.\\nEach weak learner is fitted on the training set and provides predictions obtained. The final prediction result is computed by combining the results from all the weak learners.\\n### Basic ensemble learning techniques\\nLet‚Äôs take a moment and look at simple ensemble learning techniques.\\n#### Max voting\\nIn classification, the prediction from each model is a vote. In max voting, the final prediction comes from the prediction with the most votes.\\nLet‚Äôs take an example where you have three classifiers with the following predictions:\\n* classifier 1 &#8211; class A\\n* classifier 2 &#8211; class B\\n* classifier 3 &#8211; class B\\nThe final prediction here would be class B since it has the most votes.\\n#### Averaging\\nIn averaging, the final output is an average of all predictions. This goes for regression problems. For example, in[random forest regression](https://neptune.ai/blog/random-forest-regression-when-does-it-fail-and-why), the final result is the average of the predictions from individual decision trees.\\nLet‚Äôs take an example of three regression models that predict the price of a commodity as follows:\\n* regressor 1 &#8211; 200\\n* regressor 2 &#8211;&#8211; 300\\n* regressor 3 &#8211; 400\\nThe final prediction would be the average of 200, 300, and 400.\\n#### Weighted average\\nIn weighted averaging, the base model with higher predictive power is more important. In the price prediction example, each of the regressors would be assigned a weight.\\nThe sum of the weights would equal one. Let‚Äôs say that the regressors are given weights of 0.35, 0.45, and 0.2 respectively. The final model prediction can be computed as follows:\\n0.35 \\\\* 200 + 0.45\\\\*300 + 0.2\\\\*400 = 285\\n## Advanced ensemble learning techniques\\nAbove are simple techniques, now let‚Äôs take a look at advanced techniques for ensemble learning.\\n### Stacking\\nStacking is the process of combining various estimators in order to reduce their biases. Predictions from each estimator are stacked together and used as input to a final estimator (usually called a*meta-model*) that computes the final prediction. Training of the final estimator happens via cross-validation.\\nStacking can be done for both regression and classification problems.\\n![Ensemble learning techniques](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Ensemble-learning-techniques.png?ssl=1)[*Source*](https://towardsdatascience.com/stacking-classifiers-for-higher-predictive-performance-566f963e4840)\\nStacking can be considered to happen in the following steps:\\n1. Split the data into a training and validation set,\\n2. Divide the training set into K folds, for example 10,\\n3. Train a base model (say SVM) on 9 folds and make predictions on the 10th fold,\\n4. Repeat until you have a prediction for each fold,\\n5. Fit the base model on the whole training set,\\n6. Use the model to make predictions on the test set,\\n7. Repeat step 3 &#8211; 6 for other base models (for example decision trees),\\n8. Use predictions from the test set as features to a new model &#8211;*the meta-model,*\\n9. Make final predictions on the test set using the meta model.\\nWith regression problems, the values passed to the meta-model are numeric. With classification problems, they‚Äôre probabilities or class labels.\\n### Blending\\nBlending is similar to stacking, but uses a holdout set from the training set to make predictions. So, predictions are done on the holdout set only. The predictions and holdout set are used to build a final model that makes predictions on the test set.\\nYou can think of blending as a type of stacking, where the meta-model is trained on predictions made by the base model on the hold-out validation set.\\nYou can consider the*blending*process to be:\\n* Split the data into a test and validation set,\\n* Fit base models on the validation set,\\n* Make predictions on the validation and test set,\\n* Use the validation set and its predictions to build a final model,\\n* Make final predictions using this model.\\nThe concept of blending[was made popular](https://netflixprize.com/assets/ProgressPrize2008_BellKor.pdf)by the[Netflix Prize competition](https://en.wikipedia.org/wiki/Netflix_Prize). The winning team used a blended solution to achieve a 10-fold performance improvement on Netflix‚Äôs movie recommendation algorithm.\\nAccording to this[Kaggle ensembling guide](https://mlwave.com/kaggle-ensembling-guide/):\\n> > ‚ÄúBlending is a word introduced by the Netflix winners. It‚Äôs very close to stacked generalization, but a bit simpler and less risk of an information leak. Some researchers use ‚Äústacked ensembling‚Äù and ‚Äúblending‚Äù interchangeably.\\n> > > > With blending, instead of creating out-of-fold predictions for the train set, you create a small holdout set of say 10% of the train set. The stacker model then trains on this holdout set only.‚Äù\\n> ### Blending vs stacking\\nBlending is simpler than stacking and prevents leakage of information in the model. The generalizers and the stackers use different datasets. However, blending uses less data and may lead to overfitting.\\nCross-validation is more solid on stacking than blending. It‚Äôs calculated over more folds, compared to using a small hold-out dataset in blending.\\n### Bagging\\nBagging takes random samples of data, builds learning algorithms, and uses the mean to find bagging probabilities. It‚Äôs also called*bootstrap aggregating*. Bagging aggregates the res...\\n\\n--- Result 9 ---\\nTitle: A Journey Through Kaggle Text Data Competitions From 2021 to 2023\\nURL: https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312\\n\\nContent:\\nA Journey Through Kaggle Text Data Competitions From 2021 to 2023 | by Salomon Marquez | Medium\\n[Sitemap](https://medium.com/sitemap/sitemap.xml)\\n[Open in app](https://play.google.com/store/apps/details?id=com.medium.reader&amp;referrer=utm_source=mobileNavBar&amp;source=post_page---top_nav_layout_nav-----------------------------------------)\\nSign up\\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\\n[\\nWrite\\n](https://medium.com/m/signin?operation=register&amp;redirect=https://medium.com/new-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\\n[\\nSearch\\n](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\\nSign up\\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\\n# A Journey Through Kaggle Text Data Competitions From 2021 to 2023\\n[\\n![Salomon Marquez](https://miro.medium.com/v2/da:true/resize:fill:64:64/0*hbSxb57OAqPdRqks)\\n](https://medium.com/@sblaizer?source=post_page---byline--631a79f96312---------------------------------------)\\n[Salomon Marquez](https://medium.com/@sblaizer?source=post_page---byline--631a79f96312---------------------------------------)\\n18 min read\\n¬∑Apr 28, 2024\\n[\\n](https://medium.com/m/signin?actionUrl=https://medium.com/_/vote/p/631a79f96312&amp;operation=register&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;user=Salomon+Marquez&amp;userId=1a60dea97a2c&amp;source=---header_actions--631a79f96312---------------------clap_footer------------------)\\n--\\n[](https://medium.com/m/signin?actionUrl=https://medium.com/_/bookmark/p/631a79f96312&amp;operation=register&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;source=---header_actions--631a79f96312---------------------bookmark_footer------------------)\\nListen\\nShare\\n*Authors:*[*Liliana Badillo*](https://www.kaggle.com/sophieb)*and*[*Salomon Marquez*](https://www.kaggle.com/sblaizer)\\n**> Note:\\n**> I created this Medium post to provide more visibility to our original report. Please refer to our [> A Journey Throuhgh Text Data Competitions\\n](https://www.kaggle.com/code/sophieb/a-journey-through-text-data-competitions)> notebook for further details.\\nN**atural Language Processing (NLP)**, the branch of artificial intelligence that enables computers to understand human language, has witnessed remarkable growth and transformative advancements in recent years. This surge has been driven by the increasing availability of vast amounts of text data and the rapid development of sophisticated machine-learning techniques.\\n*> ‚ÄúIt is estimated that 90% of the world‚Äôs data was generated in the last two years alone‚Äù\\n*> by [> Amount of Data Created Daily (2023)\\n](https://explodingtopics.com/blog/data-generated-per-day)\\n[**Kaggle**](https://www.kaggle.com/)is an online platform that hosts machine learning and data science competitions. Among these competitions, text data competitions specifically focus on tasks related to NLP and text analysis. Participants are provided with text datasets and are tasked with developing models and algorithms to solve language-related challenges such as sentiment analysis, text classification, and machine translation. These competitions are instrumental in advancing NLP techniques and provide participants with valuable experience and knowledge exchange opportunities.\\nAccessing and learning about the latest techniques employed in text data Kaggle competitions can be challenging due to their dispersion within discussions and winning solution write-ups.**Valuable information about these cutting-edge approaches tends to get buried, making it difficult to stay updated on the evolving landscape of text data techniques.**\\nIn this essay, our objective is to offer valuable insights into key lessons learned by the Kaggle community during their engagement in text data competitions spanning from 2021 to 2023. We will focus on**four pivotal topics**that have emerged as the foundation for successful solutions in recent years:**model architectures**,**pseudo labeling**,**adversarial weight perturbation**, and**mask language modeling**. By examining these four key areas, we aim to provide a comprehensive understanding of the essential elements driving winning strategies in text data competitions.\\n## Methodology\\nTo gain a better understanding of the text data landscape, we carried out the following tasks:\\n* **Analyze 27 write-ups from nine Kaggle competitions specifically related to text data**. We dove deeper into the top three solutions for text data competitions held from 2021 to 2023, see**Figure 1**. Also, we explore a range of topics, including the prevalent techniques and methodologies employed, the most effective model architectures utilized, and the challenges encountered and overcame. This analysis enabled us to gain deeper insights into the problem-solving approaches and thought processes employed by Kagglers in developing their successful solutions.\\n* **Perform a general but not exhaustive analysis of the**[**arXiv dataset**](https://www.kaggle.com/datasets/Cornell-University/arxiv). We filter out categories with the potential to include NLP papers published within the past two years. By leveraging a predefined list of keywords associated with text data, we directed our efforts towards uncovering the specific problem domains and top leading model architectures [1][2] that have garnered attention within the research community.\\nPress enter or click to view image in full size\\n![]()\\n**Figure 1.**Kaggle text data competitions held from 2021 to 2023\\n## Key Discoveries of Text Data Competitions\\nThe result of the analysis of the 27 write-ups and their most notable comments can be seen in[Table I of Appendix A](https://www.kaggle.com/code/sophieb/a-journey-through-text-data-competitions#Appendix-A)and[Table II of Appendix B](https://www.kaggle.com/code/sophieb/a-journey-through-text-data-competitions#Appendix-B), respectively.**Table I**provides information about the top three winning solutions in each Kaggle competition related to text, highlighting aspects such as model architectures, parameters like PB and LB, optimizers, ensembles, and the most innovative proposed ideas, among others. On the other hand,**Table II**presents a summary of comments from the write-ups in a question-like format. Additionally, the analysis of the arXiv dataset has allowed us to unveil, on a larger scale, how the use of certain model architectures and their application to specific text domains compares to the solutions presented in text-oriented Kaggle competitions over the past two years. For more details, please refer to[EDA Kaggle and Arxiv datasets](https://www.kaggle.com/code/sophieb/eda-kaggle-and-arxiv-datasets)notebook.\\nAs**Figure 2**shows, out of the nine competitions, five focused on text classification tasks, two aimed at information extraction tasks, while the remaining targeted text matching and question-and-answer tasks. Interestingly,**Figure 3**shows that with the frequency of the term ‚Äúquestion answering‚Äù exceeding 400 times, it can be inferred that the scientific community has placed greater importance on domains related to this field. While Kaggle competitions have only hosted one question-and-answer competition, there seems ...\\n\", \"is_error\": false, \"results\": [{\"title\": \"ANSWER\", \"text\": \"Ensembling is the de‚Äëfacto standard for winning Kaggle text‚Äëclassification contests.  The most reliable recipe combines **diverse fine‚Äëtuned language models** (e.g., BERT, RoBERTa, DeBERTa, GPT‚Äëbased classifiers) and aggregates their outputs with a **simple blending or voting step** before feeding the blended predictions into a **second‚Äëlevel meta‚Äëmodel**.  Studies that collected predictions from five large fine‚Äëtuned models across six datasets showed that even straightforward averaging or majority‚Äëvote ensembles consistently lift accuracy and give better uncertainty estimates than any single model‚ÄØ([arxiv.org/html/2410.19889v1](https://arxiv.org/html/2410.19889v1)).  For classification, using the **geometric mean of class probabilities** (instead of a plain arithmetic mean) often yields a small but steady gain‚ÄØ([campus.datacamp.com](https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/modeling?ex=8)).  When the ensemble contains many heterogeneous LLMs, a **majority‚Äërules / collective decision** aggregation can boost F1 by up to 65‚ÄØ% over the strongest single model, confirming that diversity and a principled voting scheme are crucial‚ÄØ([arxiv.org/html/2511.15714v1](https://arxiv.org/html/2511.15714v1)).\\n\\nThe next level of performance comes from **stacked generalization**: each base model‚Äôs out‚Äëof‚Äëfold predictions become features for a lightweight meta‚Äëlearner (often logistic regression, LightGBM, or CatBoost).  This ‚Äústacking‚Äù captures complementary error patterns and typically outperforms pure blending, especially when the base models are low‚Äëcorrelated (trained on different seeds, data splits, or architectures)‚ÄØ([campus.datacamp.com](https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/modeling?ex=8)).  Kaggle practitioners also enrich ensembles with **rank‚Äëbased averaging** or **error‚Äëcorrecting‚Äëcode voting** to further reduce variance‚ÄØ([cnblogs.com/medsci/articles/9160663.html](https://www.cnblogs.com/medsci/articles/9160663.html)).  In practice, the best Kaggle text‚Äëclassification pipelines therefore follow a three‚Äëstep stack: (1) train a heterogeneous set of fine‚Äëtuned transformers/LLMs, (2) blend their probabilities with a geometric mean or majority vote, and (3) train a second‚Äëlevel model on the blended predictions to produce the final submission.\", \"url\": \"\"}, {\"title\": \"Ensembling Finetuned Language Models\\n for Text Classification\", \"text\": \"Ensembling Finetuned Language Models for Text Classification\\n# Ensembling Finetuned Language Models\\nfor Text Classification\\nSebastian Pineda Arango1, Maciej Janowski111footnotemark:1, Lennart Purucker1, Arber Zela1,\\nFrank Hutter3,1,¬†Josif Grabocka2\\n1University of Freiburg,2University of Technology N√ºrnberg,3ELLIS Institute T√ºbingenEqual contribution. Corresponding author:pineda@cs.uni-freiburg.de\\n###### Abstract\\nFinetuning is a common practice widespread across different communities to adapt pretrained models to particular tasks.\\nText classification is one of these tasks for which many pretrained models are available. On the other hand, ensembles of neural networks are typically used to boost performance and provide reliable uncertainty estimates. However, ensembling pretrained models for text classification is not a well-studied avenue. In this paper, we present a metadataset with predictions from five large finetuned models on six datasets, and report results of different ensembling strategies from these predictions. Our results shed light on how ensembling can improve the performance of finetuned text classifiers and incentivize future adoption of ensembles in such tasks.\\n## 1Introduction\\nIn recent years, fine-tuning pretrained models has become a widely adopted technique for adapting general-purpose models to specific tasks> (Arango et¬†al., [> 2023\\n](https://arxiv.org/html/2410.19889v1#bib.bib2)> )\\n. This practice has gained significant traction across various communities due to its effectiveness in leveraging the vast knowledge encoded in pretrained models. Among the diverse tasks that benefit from fine-tuning, text classification stands out as one of the most prevalent. With the availability of numerous pretrained models, practitioners often find themselves with a range of powerful tools to tackle text classification challenges.\\nHowever, despite the widespread use of fine-tuning, the potential benefits of combining or ensembling these fine-tuned models remain underexplored.\\nPrevious studies have primarily concentrated on improving individual model performance through fine-tuning techniques> (Howard &amp; Ruder, [> 2018\\n](https://arxiv.org/html/2410.19889v1#bib.bib16)> )\\n, leaving the exploration of ensemble strategies largely underdeveloped in this context. This oversight is particularly significant given the well-documented advantages of model ensembling in other machine learning domains> (Erickson et¬†al., [> 2020\\n](https://arxiv.org/html/2410.19889v1#bib.bib10)> ; Lakshminarayanan et¬†al., [> 2017\\n](https://arxiv.org/html/2410.19889v1#bib.bib20)> )\\n, which has been shown to enhance robustness and generalization. In this paper, we address the aforementioned gap by introducing a novel metadataset, which we dub: Finetuning Text Classifiers (FTC) metadataset. FTC contains predictions from various fine-tuned models on text classification tasks with various number of classes. We systematically evaluate different ensembling strategies using this metadataset, aiming to uncover insights into the potential improvements that ensembling can offer. Our results provide valuable evidence on the efficacy of these strategies, demonstrating that ensembling fine-tuned models can lead to performance gains in text classification.\\n## 2Background and Related Work\\nFinetuning for Text Classification.Universal Language Model Fine-tuning for Text Classification or ULMFiT> (Howard &amp; Ruder, [> 2018\\n](https://arxiv.org/html/2410.19889v1#bib.bib16)> )\\nconsists of finetuning language models for classification in two stages: 1) a target task unsupervised finetuning and 2) target task classifier finetuning, while using a different learning rate per layer. However, the feasibility of fully fine-tuning large pretrained language models is constrained by computational limits> (Radford et¬†al., [> 2018\\n](https://arxiv.org/html/2410.19889v1#bib.bib31)> )\\n. This has spurred the adoption of Parameter-Efficient Fine-Tuning (PEFT) methods> (Han et¬†al., [> 2024\\n](https://arxiv.org/html/2410.19889v1#bib.bib13)> )\\n. Early strategies focused on minimal subsets of parameters such as sparse subnetworks> (Sung et¬†al., [> 2021\\n](https://arxiv.org/html/2410.19889v1#bib.bib37)> )\\nto improve task-specific performance efficiently. Innovations such as adapter modules> (Houlsby et¬†al., [> 2019\\n](https://arxiv.org/html/2410.19889v1#bib.bib15)> )\\n, which introduce a few parameters per transformer layer but in consequence increase inference time, prompted the development of Low-Rank Adaptation (LoRA)> (Hu et¬†al., [> 2022\\n](https://arxiv.org/html/2410.19889v1#bib.bib17)> ; Dettmers et¬†al., [> 2024\\n](https://arxiv.org/html/2410.19889v1#bib.bib7)> )\\nthat applies low-rank updates for improved downstream task performance with reduced computational overhead. Some studies have also demonstrated that finetuned language models can be ensembled to improve performance for text classification> (Abburi et¬†al., [> 2023\\n](https://arxiv.org/html/2410.19889v1#bib.bib1)> )\\n, but they do not provide clear insights about ensembling methods, hyperparameters, or metadata.\\nEnsembling Deep Learning Models.Ensembles of neural networks> (Hansen &amp; Salamon, [> 1990\\n](https://arxiv.org/html/2410.19889v1#bib.bib14)> ; Krogh &amp; Vedelsby, [> 1995\\n](https://arxiv.org/html/2410.19889v1#bib.bib19)> ; Dietterich, [> 2000\\n](https://arxiv.org/html/2410.19889v1#bib.bib9)> )\\nhave gained significant attention in deep learning research, both for their performance-boosting capabilities and their effectiveness in uncertainty estimation. Various strategies for building ensembles exist, with deep ensembles> (Lakshminarayanan et¬†al., [> 2017\\n](https://arxiv.org/html/2410.19889v1#bib.bib20)> )\\nbeing the most popular one, which involve independently training multiple initializations of the same network.\\nTheir state-of-the-art predictive uncertainty estimates have further fueled the interest in ensembles. Extensive empirical studies> (Ovadia et¬†al., [> 2019\\n](https://arxiv.org/html/2410.19889v1#bib.bib27)> ; Gustafsson et¬†al., [> 2020\\n](https://arxiv.org/html/2410.19889v1#bib.bib12)> )\\nhave shown that deep ensembles outperform other approaches for uncertainty estimation, such as Bayesian neural networks> (Blundell et¬†al., [> 2015\\n](https://arxiv.org/html/2410.19889v1#bib.bib3)> ; Gal &amp; Ghahramani, [> 2016\\n](https://arxiv.org/html/2410.19889v1#bib.bib11)> ; Welling &amp; Teh, [> 2011\\n](https://arxiv.org/html/2410.19889v1#bib.bib40)> )\\n. Similar to our work,> Seligmann et¬†al. (\\n[> 2024\\n](https://arxiv.org/html/2410.19889v1#bib.bib35)> )\\nshow that finetuning pretrained models via Bayesian methods on the WILDS dataset> (Koh et¬†al., [> 2021\\n](https://arxiv.org/html/2410.19889v1#bib.bib18)> )\\n, which contains text classification as well, can yield significant performance as compared to standard finetuning of single models.\\nPost-Hoc Ensembling (PHE).PHE uses set of fitted base models{z1,‚Ä¶,zM}subscriptùëß1‚Ä¶subscriptùëßùëÄ\\\\\\\\{z\\\\_{1},...,z\\\\_{M}\\\\\\\\}{ italic\\\\_z start\\\\_POSTSUBSCRIPT 1 end\\\\_POSTSUBSCRIPT , ‚Ä¶, italic\\\\_z start\\\\_POSTSUBSCRIPT italic\\\\_M end\\\\_POSTSUBSCRIPT }such that every model outputszm‚Å¢(x),zm:‚ÑùD‚Üí‚ÑùC:subscriptùëßùëöùë•subscriptùëßùëö‚Üísuperscript‚Ñùùê∑superscript‚Ñùùê∂z\\\\_{m}(x),z\\\\_{m}:\\\\\\\\mathbb{R}^{D}\\\\\\\\rightarrow\\\\\\\\mathbb{R}^{C}italic\\\\_z start\\\\_POSTSUBSCRIPT italic\\\\_m end\\\\_POSTSUBSCRIPT ( italic\\\\_x ) , italic\\\\_z start\\\\_POSTSUBSCRIPT italic\\\\_m end\\\\_POSTSUBSCRIPT : blackboard\\\\_R start\\\\_POSTSUPERSCRIPT italic\\\\_D end\\\\_POSTSUPERSCRIPT ‚Üíblackboard\\\\_R start\\\\_POSTSUPERSCRIPT italic\\\\_C end\\\\_POSTSUPERSCRIPT111We assume a classification tasks withCùê∂Citalic\\\\_Cclasses. For regressionC=1ùê∂1C=1italic\\\\_C = 1.. These outputs are combined by an ensemblerf‚Å¢(z1‚Å¢(x),‚Ä¶,zM‚Å¢(x);Œ∏)=f‚Å¢(z‚Å¢(x);Œ∏)ùëìsubscriptùëß1ùë•‚Ä¶subscriptùëßùëÄùë•ùúÉùëìùëßùë•ùúÉf(z\\\\_{1}(x),...,z\\\\_{M}(x);\\\\\\\\theta)=f(z(x);\\\\\\\\theta)italic\\\\_f ( italic\\\\_z start\\\\_POSTSUBSCRIPT 1 end\\\\_POSTSUBSCRIPT ( italic\\\\_x ) , ‚Ä¶, italic\\\\_z start\\\\_POSTSUBSCRIPT italic\\\\_M end\\\\_POSTSUBSCRIPT ( italic\\\\_x ) ; italic\\\\_Œ∏ ) = italic\\\\_f ( italic\\\\_z ( italic\\\\_x ) ; italic\\\\_Œ∏ ),...\", \"url\": \"https://arxiv.org/html/2410.19889v1\"}, {\"title\": \"Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization\", \"text\": \"Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization\\n# Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization\\nAriel Kamen\\nRingCentral Inc.\\nariel.kamen@ringcentral.comYakov Kamen\\nRelevad Corporation\\nyakov@relevad.com\\n(November 1, 2025)\\n###### Abstract\\nThis study introduces an ensemble framework for unstructured text categorization using large language models (LLMs). By integrating multiple models, the ensemble large language model (eLLM) framework addresses common weaknesses of individual systems, including inconsistency, hallucination, category inflation, and misclassification. The eLLM approach yields a substantial performance improvement of up to 65% in F1-score over the strongest single model. We formalize the ensemble process through a mathematical model of collective decision-making and establish principled aggregation criteria. Using the Interactive Advertising Bureau (IAB) hierarchical taxonomy, we evaluate ten state-of-the-art LLMs under identical zero-shot conditions on a human-annotated corpus of 8,660 samples. Results show that individual models plateau in performance due to the compression of semantically rich text into sparse categorical representations, while eLLM improves both robustness and accuracy. With a diverse consortium of models, eLLM achieves near human-expert-level performance, offering a scalable and reliable solution for taxonomy-based classification that may significantly reduce dependence on human expert labeling.\\nIndex Terms‚ÄîAI, large language models, LLM, multi-LLM, LLM ensemble, collective intelligence, content categorization, collective decision-making, CDM, ensemble framework, eLLM.\\n## 1.‚ÄÉ‚ÄäIntroduction\\nText categorization (also termed text classification) is a foundational problem in natural language processing. Early systems relied on human experts to assign categories using controlled vocabularies and taxonomies. This labor-intensive workflow gradually gave way to rule-based heuristics and, later, to classical machine-learning pipelines with domain-specific training and hand-engineered features. While effective within constrained settings, these approaches required substantial manual effort and did not scale easily across heterogeneous domains.\\nLarge language models (LLMs)‚Äîincluding GPT, Gemini, Claude, Grok, LLaMA, Mistral, xAI, and DeepSeek‚Äîhave introduced strong zero-shot capabilities, motivating efforts to replace task-specific classifiers with general-purpose LLMs. Despite notable successes of LLMs in reasoning, scientific discovery, and content generation, their performance in taxonomy-based categorization has lagged. Empirically, single models exhibit instability, category inflation, and hallucination, often producing incoherent or non-existent labels.\\nThis performance gap reflects the unique nature of categorization as an information-compression task: semantically rich, unstructured inputs must be mapped into a small set of category names defined by a fixed taxonomy. Such taxonomies typically represent the real world sparsely, and individual texts may map to multiple categories with varying levels of relevance. Accurate mapping frequently requires background knowledge external to the text‚Äîsuch as domain conventions or factual context‚Äîthat distinguishes professional experts from general readers. In our experiments with ten widely used zero-shot LLMs spanning multiple families and release generations, we observe a consistent performance plateau: increasing model size or algorithmic sophistication does not yield commensurate gains once a threshold is reached> (Kamen, [> 2025\\n](https://arxiv.org/html/2511.15714v1#bib.bib15)> )\\n.\\nTo address these limitations, we developed an ensemble of LLMs (eLLM), treating each model as an independent expert and combining their predictions through a collective decision-making rule. This design is motivated by the well-established benefits of aggregation in both human and algorithmic committees, where diversity and redundancy suppress individual errors and reduce variance. By leveraging models built on diverse architectures, training paradigms, and knowledge bases, the ensemble extends the effective knowledge universe of any single LLM, enabling more comprehensive coverage of sparse taxonomies. In taxonomy classification, we find that ensembling mitigates common single-model failure modes‚Äîsuch as hallucinations and inconsistent label usage‚Äîwhile substantially improving both accuracy and stability. The results are striking: ensembles with sufficient diversity not only surpass the strongest individual models but, in some conditions, approach or exceed the consistency of human expert annotation. The principal trade-off lies in computational cost, since multiple model evaluations are required at inference time. This direction aligns with growing evidence that collaborative or multi-agent LLM strategies can overcome inherent limitations of single-model systems> (Feng et¬†al., [> 2025\\n](https://arxiv.org/html/2511.15714v1#bib.bib9)> )\\n. The eLLM‚Äôs capacity for automatic error counterbalancing represents a practical form of self-correction‚Äîan essential step toward reliable artificial intelligence.\\nThis paper makes the following contributions:\\n* ‚Ä¢We formalize an ensemble LLM framework for taxonomy-based categorization, specifying aggregation criteria within a collective decision-making model tailored to sparse hierarchical label spaces.\\n* ‚Ä¢We instantiate eLLM with multiple committee sizes (2, 3, 5, 7, and 10 models) and evaluate them under uniform zero-shot prompting on a human-annotated corpus of 8,660 samples labeled with the IAB¬†2.2 taxonomy.\\n* ‚Ä¢We provide empirical evidence of substantial improvements over the best single model, including large gains in F1-score, reduced category inflation, and lower hallucination rates, and we analyze the computational trade-offs of ensembling.\\n* ‚Ä¢We discuss conditions under which eLLM approaches human-expert performance, and the implications for scalable, reliable labeling pipelines.\\nTogether, these results suggest that ensemble-based categorization is a practical and robust alternative to single-model LLM classification, particularly when adherence to a fixed taxonomy and reliability under distributional shift are required. This work builds toward a new theory of collaborative AI, where orchestrated ensembles transform unstructured chaos into ordered, expert-level insight.\\n## 2.‚ÄÉ‚ÄäRelated Work\\nOur research on ensemble large language models (eLLM) for hierarchical text categorization builds upon and integrates advances in three major domains: (1) taxonomy-based classification, (2) zero-shot categorization with large language models, and (3) collective decision-making and ensemble learning. It directly extends the findings of> (Kamen, [> 2025\\n](https://arxiv.org/html/2511.15714v1#bib.bib15)> )\\n, which identified structural limitations in single-model LLM categorization and established the empirical foundation for ensemble-based approaches.\\n### 2.1.‚ÄÉ‚ÄäTaxonomy-Based Hierarchical Classification\\nText categorization has been a central task in natural language processing (NLP) for several decades. Early systems relied on manual annotation and rule-based heuristics, later replaced by supervised pipelines built upon feature engineering and linear classifiers> (Sebastiani, [> 2002\\n](https://arxiv.org/html/2511.15714v1#bib.bib26)> )\\n. As taxonomies expanded in depth and scope, hierarchical classification emerged as a natural extension, in which labels are organized into a tree or directed acyclic graph> (Jr. et¬†al., [> 2011\\n](https://arxiv.org/html/2511.15714v1#bib.bib14)> )\\n.\\nHierarchical classification requires predictions that respect structural dependencies, maintain parent‚Äìchild consistency, and remain valid across all levels of granularity. Various methods have been proposed to address these challenges, including structural loss functions> (Hsu et¬†al., [> 2009\\n](https://arxiv.org/html/2511.15714v1#bib.bi...\", \"url\": \"https://arxiv.org/html/2511.15714v1\"}, {\"title\": \"Model ensembling | Python\", \"text\": \"Model ensembling | Python https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/modeling?ex=8\\nModel ensembling | Python\\nNone\\n2022-06-13T00:00:00Z\\n# Model ensembling\\n####. Model ensembling\\nSo far, we've been talking only about individual models. Now it's time to combine multiple models together.\\n####. Model ensembling\\nKaggle top solutions are usually not a single model, but a combination of a large number of various models. Different ways to combine models together is called model ensembling.\\nFor example, here is an ensemble design for a winning solution in the Homesite Quote Conversion challenge. We can see hundreds of models with multi-level stacking and blending. Let's learn about these 'blending' and 'stacking' terms.\\n####. Model blending\\nThe idea of ensemble learning is to build a prediction model by combining the strengths of a collection of simpler base models. The so-called blending approach is to just find an average of our multiple models predictions.\\nSay we're solving a regression problem with a continuous target variable.\\nAnd we have trained two models: A and B.\\nSo, for each test observation, there are model A and model B predictions available.\\n####. Model blending\\nTo combine models together we can just find the predictions mean, taking the sum and divide it by two. As we see, it allows us to tweak predictions, and to take into account both model A and model B opinions.\\nThat's it, such a simple ensembling method in the majority of cases will yield some improvement to our single models.\\n####. Model blending\\nArithmetic mean works for both regression and classification problems. However, for the classification, it's better to use a geometric mean of the class probabilities predicted.\\n####. Model stacking\\nThe more advanced ensembling approach is called model stacking. The idea is to train multiple single models, take their predictions and use these predictions as features in the 2nd level model.\\nSo, we need to perform the following steps:\\nSplit train data into two parts. Part 1 and Part 2.\\nTrain multiple single models on the first part.\\nMake predictions on the second part of the train data,\\nand on the test data. Now, we have models predictions for both Part 2 of the train data and for the test data.\\nIt means that we could create a new model using these predictions as features. This model is called the 2nd level model or meta-model.\\nIts predictions on the test data give us the stacking output.\\n####. Stacking example\\nLet's consider all these steps on the example.\\nSuppose we are given a binary classification problem with a bunch of numerical features: feature_1, feature_2 and so on to feature_N. For the train data, target variable is known.\\nAnd we need to make predictions on the test data with the unknown target variable.\\n####. Stacking example\\nFirst of all, we split train data into two separate parts: Part 1 and Part 2.\\n####. Stacking example\\nThen we train multiple single models only on the first part of the train data. For example, we've trained three different models denoting them as A, B and C.\\n####. Stacking example\\nHaving these 3 models we make the predictions on part 2 of the train data. The columns with the predictions are denoted as A_pred, B_pred and C_pred.\\nThen make the predictions on the test data as well.\\n####. Stacking example\\nSo, now we have models predictions for both Part 2 of the train data and for the test data.\\n####. Stacking example\\nIt's now possible to create a second level model using these predictions as features. It's trained on the Part 2 train data and is used to make predictions on the test data.\\n####. Stacking example\\nAs a result, we obtain stacking predictions for the test data. Thus, we combined individual model predictions into a single number using a 2nd level model.\\n####. Let's practice!\\nOK, having learned the theory, move on to build your own model ensembles!\\nShow Transcripts\\n### Create Your Free Account\\nor\\nEmail AddressPasswordStart Learning for FreeBy continuing, you accept our [Terms of Use](https://www.datacamp.com/terms-of-use), our [Privacy Policy](https://www.datacamp.com/privacy-policy) and that your data is stored in the USA.\", \"url\": \"https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/modeling?ex=8\"}, {\"title\": \"KAGGLE ENSEMBLING GUIDE\", \"text\": \"[ÂçöÂÆ¢Âõ≠](https://www.cnblogs.com/) [È¶ñÈ°µ](https://www.cnblogs.com/medsci/) [Êñ∞ÈöèÁ¨î](https://i.cnblogs.com/EditPosts.aspx?opt=1) [ËÅîÁ≥ª](https://msg.cnblogs.com/send/medsci) [ËÆ¢ÈòÖ](javascript:void(0)) [ÁÆ°ÁêÜ](https://i.cnblogs.com/)\\n\\n# [KAGGLE ENSEMBLING GUIDE](https://www.cnblogs.com/medsci/articles/9160663.html)\\n\\nËΩ¨ËΩΩËá™¬† https://mlwave.com/kaggle-ensembling-guide/\\n\\ngithub:¬† https://github.com/MLWave/Kaggle-Ensemble-Guide\\n\\nModel ensembling is a very powerful technique to increase accuracy on a variety of ML tasks. In this article I will share my ensembling approaches for Kaggle Competitions.\\n\\nFor the first part we look at creating ensembles from submission files. The second part will look at creating ensembles through stacked generalization/blending.\\n\\nI answer why ensembling reduces the generalization error. Finally I show different methods of ensembling, together with their results and code to try it out for yourself.\\n\\n> This is how you win ML competitions: you take other peoples‚Äô work and ensemble them together.‚Äù¬†[Vitaly Kuznetsov](http://cims.nyu.edu/~vitaly/)¬†NIPS2014\\n\\n## Creating ensembles from submission files\\n\\nThe most basic and convenient way to ensemble is to ensemble Kaggle submission CSV files. You only need the predictions on the test set for these methods ‚Äî no need to retrain a model. This makes it a quick way to ensemble already existing model predictions, ideal when teaming up.\\n\\n### Voting ensembles.\\n\\nWe first take a look at a simple majority vote ensemble. Let‚Äôs see why model ensembling reduces error rate and why it works better to ensemble low-correlated model predictions.\\n\\n#### Error correcting codes\\n\\nDuring space missions it is very important that all signals are correctly relayed.\\n\\nIf we have a signal in the form of a binary string like:\\n\\n```\\n1110110011101111011111011011\\n\\n```\\n\\nand somehow this signal is corrupted (a bit is flipped) to:\\n\\n```\\n1010110011101111011111011011\\n\\n```\\n\\nthen lives could be lost.\\n\\nA¬†[coding](http://en.wikipedia.org/wiki/Coding_theory)¬†solution was found in¬†[error correcting codes](http://en.wikipedia.org/wiki/Forward_error_correction). The simplest error correcting code is a¬†[repetition-code](http://en.wikipedia.org/wiki/Repetition_code): Relay the signal multiple times in equally sized chunks and have a majority vote.\\n\\n```\\nOriginal signal:\\n1110110011\\n\\nEncoded:\\n10,3 101011001111101100111110110011\\n\\nDecoding:\\n1010110011\\n1110110011\\n1110110011\\n\\nMajority vote:\\n1110110011\\n\\n```\\n\\nSignal corruption is a very rare occurrence and often occur in small bursts. So then it figures that it is even rarer to have a corrupted majority vote.\\n\\nAs long as the corruption is not completely unpredictable (has a 50% chance of occurring) then signals can be repaired.\\n\\n#### A machine learning example\\n\\nSuppose we have a test set of 10 samples. The ground truth is all positive (‚Äú1‚Äù):\\n\\n```\\n1111111111\\n\\n```\\n\\nWe furthermore have 3 binary classifiers (A,B,C) with a 70% accuracy. You can view these classifiers for now as pseudo-random number generators which output a ‚Äú1‚Äù 70% of the time and a ‚Äú0‚Äù 30% of the time.\\n\\nWe will now show how these pseudo-classifiers are able to obtain 78% accuracy through a voting ensemble.\\n\\n##### A pinch of maths\\n\\nFor a majority vote with 3 members we can expect 4 outcomes:\\n\\n```\\nAll three are correct\\n  0.7 * 0.7 * 0.7\\n= 0.3429\\n\\nTwo are correct\\n  0.7 * 0.7 * 0.3\\n+ 0.7 * 0.3 * 0.7\\n+ 0.3 * 0.7 * 0.7\\n= 0.4409\\n\\nTwo are wrong\\n  0.3 * 0.3 * 0.7\\n+ 0.3 * 0.7 * 0.3\\n+ 0.7 * 0.3 * 0.3\\n= 0.189\\n\\nAll three are wrong\\n  0.3 * 0.3 * 0.3\\n= 0.027\\n\\n```\\n\\nWe see that most of the times (~44%) the majority vote corrects an error. This majority vote ensemble will be correct an average of ~78% (0.3429 + 0.4409 = 0.7838).\\n\\n#### Number of voters\\n\\nLike repetition codes increase in their error-correcting capability when more codes are repeated, so do ensembles usually improve when adding more ensemble members.\\n\\nUsing the same pinch of maths as above: a voting ensemble of 5 pseudo-random classifiers with 70% accuracy would be correct ~83% of the time. One or two errors are being corrected during ~66% of the majority votes. (0.36015 + 0.3087)\\n\\n#### Correlation\\n\\nWhen I first joined the team for KDD-cup 2014, Marios Michailidis ( [KazAnova](https://www.kaggle.com/kazanova)) proposed something peculiar. He calculated the¬†[Pearson correlation](http://onlinestatbook.com/2/describing_bivariate_data/pearson.html)¬†for all our submission files and gathered a few well-performing models which were less correlated.\\n\\nCreating an averaging ensemble from these diverse submissions gave us the¬†biggest 50-spot jump on the leaderboard. Uncorrelated submissions clearly do better when ensembled than correlated submissions. But why?\\n\\nTo see this, let us take 3 simple models again. The ground truth is still all 1‚Äôs:\\n\\n```\\n1111111100 = 80% accuracy\\n1111111100 = 80% accuracy\\n1011111100 = 70% accuracy.\\n\\n```\\n\\nThese models are highly correlated in their predictions. When we take a majority vote we see no improvement:\\n\\n```\\n1111111100 = 80% accuracy\\n\\n```\\n\\nNow we compare to 3 less-performing, but highly uncorrelated models:\\n\\n```\\n1111111100 = 80% accuracy\\n0111011101 = 70% accuracy\\n1000101111 = 60% accuracy\\n\\n```\\n\\nWhen we ensemble this with a majority vote we get:\\n\\n```\\n1111111101 = 90% accuracy\\n\\n```\\n\\nWhich¬†_is_¬†an improvement: A lower correlation between ensemble model members seems to result in an increase in the error-correcting capability.\\n\\n#### Use for Kaggle: Forest Cover Type prediction\\n\\nMajority votes make most sense when the evaluation metric requires hard predictions, for instance with (multiclass-) classification accuracy.\\n\\nThe¬†[forest cover type prediction](https://www.kaggle.com/c/forest-cover-type-prediction)¬†challenge uses the¬†[UCI Forest CoverType dataset](https://archive.ics.uci.edu/ml/datasets/Covertype). The dataset has¬†54 attributes and there are 6 classes.\\n\\nWe create a simple¬†[starter model](https://www.kaggle.com/triskelion/forest-cover-type-prediction/first-try-with-random-forests)¬†with a 500-tree Random Forest. We then create a few more models and pick the best performing one. For this task and our model selection an ExtraTreesClassifier works best.\\n\\n##### Weighing\\n\\nWe then use a weighted majority vote. Why weighing? Usually we want to give a better model more weight in a vote. So in our case we count the vote by the best model 3 times.¬†The other 4 models count for one vote each.\\n\\nThe reasoning is as follows: The only way for the inferior models to overrule the best model (expert) is for them to¬†collectively (and confidently) agree on an alternative.\\n\\nWe can expect this ensemble to repair a few erroneous choices by the best model, leading to a small improvement only.¬†That‚Äôs our punishment for forgoing a democracy and creating a Plato‚Äôs¬†_Republic_.\\n\\n> ‚ÄúEvery city encompasses two cities that are at war with each other.‚Äù¬†Plato in¬†The Republic\\n\\nTable 1. shows the result of training 5 models, and the resulting score when combining these with a weighted majority vote.\\n\\n| MODEL | PUBLIC ACCURACY SCORE |\\n| --- | --- |\\n| GradientBoostingMachine | 0.65057 |\\n| RandomForest Gini | 0.75107 |\\n| RandomForest Entropy | 0.75222 |\\n| ExtraTrees Entropy | 0.75524 |\\n| ExtraTrees Gini (Best) | 0.75571 |\\n| Voting Ensemble (Democracy) | 0.75337 |\\n| Voting Ensemble (3\\\\*Best vs. Rest) | 0.75667 |\\n\\n#### Use for Kaggle: CIFAR-10 Object detection in images\\n\\nCIFAR-10 is another multi-class classification challenge where accuracy matters.\\n\\nOur team leader for this challenge,¬†[Phil Culliton](https://www.kaggle.com/philculliton), first found the best setup to¬†[replicate a good model](http://blog.kaggle.com/2015/01/02/cifar-10-competition-winners-interviews-with-dr-ben-graham-phil-culliton-zygmunt-zajac/)¬†from dr. Graham.\\n\\nThen he used a voting ensemble of around 30 convnets submissions (all scoring above 90% accuracy). The best¬†single model of the ensemble scored¬†0.93170.\\n\\nA voting ensemble of 30 models scored¬†0.94120. A ~0.01 reduction in error rate, pushing the resulting score beyond the¬†[estimated human clas...\", \"url\": \"https://www.cnblogs.com/medsci/articles/9160663.html\"}, {\"title\": \"\", \"text\": \"arXiv reCAPTCHA\\n[![Cornell University](https://static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\\n[We gratefully acknowledge support from\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)\\n# [![arxiv logo](https://static.arxiv.org/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)\", \"url\": \"https://arxiv.org/pdf/2410.19889\"}, {\"title\": \"Kaggle Champions: Ensemble Methods in Machine Learning | Toptal¬Æ\", \"text\": \"<div><div>\\n<p>The proverb ‚ÄúTwo heads are better than one‚Äù takes on new meaning when it comes to <a href=\\\"https://www.toptal.com/machine-learning\\\">machine learning</a> ensembles. Ensemble methods are some of the most decorated ML families at Kaggle competitions, where they often win contests with their impressive results.</p>\\n<p>But it was a century before Kaggle when statistician Sir Francis Galton noticed the potency of aggregated intelligence. He happened upon a competition at a livestock fair where participants had to guess the weight of an ox. Eight hundred people submitted guesses, but their skill levels varied: Farmers and butchers guessed alongside city dwellers who had never seen an ox up close, so Galton thought the average guess would be quite wrong.</p>\\n<p>It <a href=\\\"https://projecteuclid.org/download/pdfview_1/euclid.ss/1411437521\\\">turned out</a> that the mean of the crowd‚Äôs guesses was off by less than a pound (&lt; 0.1%). However, even the best individual predictions were well off the mark.</p>\\n<p>How could that be? What made such an unexpected result possible?</p>\\n<h2>What Makes Machine Ensembles so Effective</h2>\\n<p>The event that forced Galton to question his beliefs also illustrates what makes ensembles so powerful: If you have <strong>different</strong> <strong>and independent models</strong>, trained using <strong>different parts of data</strong> for the same problem, they will work better together than individually. The reason? Each model will learn a different part of the concept. Therefore, each model will produce valid results and errors based on its ‚Äúknowledge.‚Äù</p>\\n<p>But the most interesting thing is that each true part will complement the others while the errors cancel out each other:</p>\\n<div><figure><a href=\\\"https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/750064/image-1631891397968-d95bfcfccb53db7971c25b2a53222b3f.png\\\"></a></figure></div>\\n<p>You need to train models with high variance (like decision trees) over distinct subsets of data. This added variance means that each model overfits different data, but when combined, the variance disappears, as if by magic. This creates a new, more robust model.</p>\\n<p>Just like in Galton‚Äôs case, when all data from all sources is combined, the result is ‚Äúsmarter‚Äù than isolated data points.</p>\\n<h3>A Closer Look at Ensemble Learning in Kaggle Competitions</h3>\\n<p>At the <a href=\\\"https://www.kaggle.com/c/otto-group-product-classification-challenge/overview\\\">Otto Group Product Classification Challenge</a>, participants had to build a predictive model that was able to distinguish between main product categories.</p>\\n<p>Here you can see how <a href=\\\"https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335\\\">the winning model was built</a>. It was a stacking of three layers: The first had 33 models, the second added three more (XGBoost, a neural network, and AdaBoost), and the third was the weighted mean of the previous layer outputs. It was both a very complex model and an ensemble.</p>\\n<p>Another Kaggle success is the model created by Chenglong Chen at the <a href=\\\"https://www.kaggle.com/c/crowdflower-search-relevance/overview\\\">Crowdflower Search Results Relevance competition</a>. The challenge was to create a predictor that could be used to measure the relevance of search results. You can read the complete <a href=\\\"https://github.com/ChenglongChen/kaggle-CrowdFlower\\\">explanation of his method</a>, but as our point of interest is ensembles, the critical part of the story is that the winning solution used an ensemble of 35 models, many of which were also ensembles‚Äîa meta-ensemble, so to speak.</p>\\n<h2>Ensemble Methods</h2>\\n<p>There are many ways of implementing ensemble methods in machine learning. We‚Äôll explore some of the most popular methods:</p>\\n<ul>\\n <li>\\n<strong>Bagging</strong>\\n <ul>\\n <li>Random Forest</li>\\n </ul>\\n </li>\\n <li>\\n<strong>Boosting</strong>\\n <ul>\\n <li>AdaBoost</li>\\n <li>Gradient Boosting and XGBoost</li>\\n </ul>\\n </li>\\n <li>\\n<strong>Hybrid Ensemble Methods</strong>\\n <ul>\\n <li>Voting</li>\\n <li>Stacking</li>\\n <li>Cascading</li>\\n </ul>\\n </li>\\n</ul>\\n<h2>Bagging</h2>\\n<p>As mentioned, you need to train many models over different subsets of data. In practice, this is not easy because you will need much more data for many models than you would for a single model, and sometimes it is not easy to obtain high-quality datasets. This is when bagging (bootstrap aggregating) comes in handy, as it splits the data through bootstrapping: a random sample with a replacement, resulting in different subsets that overlap.</p>\\n<p>Once you have trained your ensemble models, you construct your final prediction by aggregating each model prediction through any metric you prefer: the mean, median, mode, and so on. You can also use model prediction probabilities to make a weighted metric:</p>\\n<div><figure><a href=\\\"https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/750065/image-1631891438024-8c044ee5d973b58299ba8a7a56d1484c.png\\\"></a></figure></div>\\n<p>If we want to use <a href=\\\"https://en.wikipedia.org/wiki/Decision_tree_learning\\\">decision trees</a> as models but we have few strong predictive attributes in our data, all the trees will be similar. This is because the same attributes will tend to be in the root node, producing similar results in each branch of the tree.</p>\\n<h3>Random Forest</h3>\\n<p>One technique to address this problem is <strong>random forest</strong>. It makes a bagging ensemble using trees but each node constrains its possible attributes to a random subset. This forces the models to be different, resolving the previous problem. It also makes random forest a very good model for <a href=\\\"https://en.wikipedia.org/wiki/Feature_selection\\\">feature selection</a>.</p>\\n<p>Random forest is one of the most popular ML models because it delivers good performance with low variance and training time.</p>\\n<h2>Boosting</h2>\\n<p>Boosting also uses bootstrapping to train the models, with the main difference being that it adds weights to each instance based on model prediction errors. While bagging is a parallel process, boosting is a sequential one, in which each model has more probabilities. This allows it access to some instances of previous model predictions.</p>\\n<p>With this modification, boosting tries to increase the focus over misclassified instances to reach better global performance:</p>\\n<div><figure><a href=\\\"https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/750066/image-1631891461357-200322840b31404060220a892663aa15.png\\\"></a></figure></div>\\n<p>It adds weights to models too. Predictors with better performance at training time will have a higher weight at the predicting stage.</p>\\n<p>Let‚Äôs take a closer look at some of the most popular boosting models:</p>\\n<h3>AdaBoost</h3>\\n<p>AdaBoost was one of the first implementations of boosting. It does almost exactly what we outlined about boosting in general and uses decision trees as models. Let‚Äôs explain the training phase with some pseudo coding:</p>\\n<pre><code>For each instance i\\n Assign w[i] (weight, same for all)\\nFor each iteration t\\n Generate a subset s[t] by weighted boosting (using the w[i] weights)\\n Train model m[t] using s[t]\\n Store m[t]\\n Calculate e[t] (error rate of m[t])\\n Assign error rate e[t] to stored m[t] model\\n If (e[t] &lt;= a_threshold)\\n Exit for\\n Update weights using m[t] errors\\n</code></pre>\\n<p>At prediction time, it weights each prediction based on the error rate <code>e[t]</code> calculated for each one. Results with a high error rate will have less weight than others with better accuracy.</p>\\n<h3>Gradient Boosting and XGBoost</h3>\\n<p>One of the major problems when training so many models and making them work together is finding the best hyperparameter configuration. It is difficult to find the best configuration for a single model; finding the best configuration for <em>n</em> models increases the complexity exponentially. The ideal configuration fo...\", \"url\": \"https://www.toptal.com/machine-learning/ensemble-methods-kaggle-machine-learn\"}, {\"title\": \"A Comprehensive Guide to Ensemble Learning: What Exactly Do You Need to Know\", \"text\": \"A Comprehensive Guide to Ensemble Learning: What Exactly Do You Need to Know[\\n**üì£ BIG NEWS:****Neptune is joining OpenAI!**‚Üí Read the message from our CEO üì£![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\\nWhat do you want to find?\\nSearch\\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Neptune Blog](https://neptune.ai/blog)# A Comprehensive Guide to Ensemble Learning: What Exactly Do You Need to Know\\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Derrick-Mwiti.png?fit=193%2C193&ssl=1)\\n[Derrick Mwiti](https://neptune.ai/blog/author/derrickmwiti)\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)8 min\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)25th April, 2025\\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\\n[Ensemble learning techniques](https://www.toptal.com/machine-learning/ensemble-methods-machine-learning)have been proven to yield better performance on machine learning problems. We can use these techniques for regression as well as classification problems.\\nThe final prediction from these ensembling techniques is obtained by combining results from several base models. Averaging, voting and stacking are some of the ways the results are combined to obtain a final prediction.\\nIn this article, we will explore how ensemble learning can be used to come up with optimal machine learning models.\\n## What is ensemble learning?\\nEnsemble learning is a combination of several machine learning models in one problem. These models are known as weak learners. The intuition is that when you combine several weak learners, they can become strong learners.\\nEach weak learner is fitted on the training set and provides predictions obtained. The final prediction result is computed by combining the results from all the weak learners.\\n### Basic ensemble learning techniques\\nLet‚Äôs take a moment and look at simple ensemble learning techniques.\\n#### Max voting\\nIn classification, the prediction from each model is a vote. In max voting, the final prediction comes from the prediction with the most votes.\\nLet‚Äôs take an example where you have three classifiers with the following predictions:\\n* classifier 1 &#8211; class A\\n* classifier 2 &#8211; class B\\n* classifier 3 &#8211; class B\\nThe final prediction here would be class B since it has the most votes.\\n#### Averaging\\nIn averaging, the final output is an average of all predictions. This goes for regression problems. For example, in[random forest regression](https://neptune.ai/blog/random-forest-regression-when-does-it-fail-and-why), the final result is the average of the predictions from individual decision trees.\\nLet‚Äôs take an example of three regression models that predict the price of a commodity as follows:\\n* regressor 1 &#8211; 200\\n* regressor 2 &#8211;&#8211; 300\\n* regressor 3 &#8211; 400\\nThe final prediction would be the average of 200, 300, and 400.\\n#### Weighted average\\nIn weighted averaging, the base model with higher predictive power is more important. In the price prediction example, each of the regressors would be assigned a weight.\\nThe sum of the weights would equal one. Let‚Äôs say that the regressors are given weights of 0.35, 0.45, and 0.2 respectively. The final model prediction can be computed as follows:\\n0.35 \\\\* 200 + 0.45\\\\*300 + 0.2\\\\*400 = 285\\n## Advanced ensemble learning techniques\\nAbove are simple techniques, now let‚Äôs take a look at advanced techniques for ensemble learning.\\n### Stacking\\nStacking is the process of combining various estimators in order to reduce their biases. Predictions from each estimator are stacked together and used as input to a final estimator (usually called a*meta-model*) that computes the final prediction. Training of the final estimator happens via cross-validation.\\nStacking can be done for both regression and classification problems.\\n![Ensemble learning techniques](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Ensemble-learning-techniques.png?ssl=1)[*Source*](https://towardsdatascience.com/stacking-classifiers-for-higher-predictive-performance-566f963e4840)\\nStacking can be considered to happen in the following steps:\\n1. Split the data into a training and validation set,\\n2. Divide the training set into K folds, for example 10,\\n3. Train a base model (say SVM) on 9 folds and make predictions on the 10th fold,\\n4. Repeat until you have a prediction for each fold,\\n5. Fit the base model on the whole training set,\\n6. Use the model to make predictions on the test set,\\n7. Repeat step 3 &#8211; 6 for other base models (for example decision trees),\\n8. Use predictions from the test set as features to a new model &#8211;*the meta-model,*\\n9. Make final predictions on the test set using the meta model.\\nWith regression problems, the values passed to the meta-model are numeric. With classification problems, they‚Äôre probabilities or class labels.\\n### Blending\\nBlending is similar to stacking, but uses a holdout set from the training set to make predictions. So, predictions are done on the holdout set only. The predictions and holdout set are used to build a final model that makes predictions on the test set.\\nYou can think of blending as a type of stacking, where the meta-model is trained on predictions made by the base model on the hold-out validation set.\\nYou can consider the*blending*process to be:\\n* Split the data into a test and validation set,\\n* Fit base models on the validation set,\\n* Make predictions on the validation and test set,\\n* Use the validation set and its predictions to build a final model,\\n* Make final predictions using this model.\\nThe concept of blending[was made popular](https://netflixprize.com/assets/ProgressPrize2008_BellKor.pdf)by the[Netflix Prize competition](https://en.wikipedia.org/wiki/Netflix_Prize). The winning team used a blended solution to achieve a 10-fold performance improvement on Netflix‚Äôs movie recommendation algorithm.\\nAccording to this[Kaggle ensembling guide](https://mlwave.com/kaggle-ensembling-guide/):\\n> > ‚ÄúBlending is a word introduced by the Netflix winners. It‚Äôs very close to stacked generalization, but a bit simpler and less risk of an information leak. Some researchers use ‚Äústacked ensembling‚Äù and ‚Äúblending‚Äù interchangeably.\\n> > > > With blending, instead of creating out-of-fold predictions for the train set, you create a small holdout set of say 10% of the train set. The stacker model then trains on this holdout set only.‚Äù\\n> ### Blending vs stacking\\nBlending is simpler than stacking and prevents leakage of information in the model. The generalizers and the stackers use different datasets. However, blending uses less data and may lead to overfitting.\\nCross-validation is more solid on stacking than blending. It‚Äôs calculated over more folds, compared to using a small hold-out dataset in blending.\\n### Bagging\\nBagging takes random samples of data, builds learning algorithms, and uses the mean to find bagging probabilities. It‚Äôs also called*bootstrap aggregating*. Bagging aggregates the res...\", \"url\": \"https://neptune.ai/blog/ensemble-learning-guide\"}, {\"title\": \"A Journey Through Kaggle Text Data Competitions From 2021 to 2023\", \"text\": \"A Journey Through Kaggle Text Data Competitions From 2021 to 2023 | by Salomon Marquez | Medium\\n[Sitemap](https://medium.com/sitemap/sitemap.xml)\\n[Open in app](https://play.google.com/store/apps/details?id=com.medium.reader&amp;referrer=utm_source=mobileNavBar&amp;source=post_page---top_nav_layout_nav-----------------------------------------)\\nSign up\\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\\n[\\nWrite\\n](https://medium.com/m/signin?operation=register&amp;redirect=https://medium.com/new-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\\n[\\nSearch\\n](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\\nSign up\\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\\n# A Journey Through Kaggle Text Data Competitions From 2021 to 2023\\n[\\n![Salomon Marquez](https://miro.medium.com/v2/da:true/resize:fill:64:64/0*hbSxb57OAqPdRqks)\\n](https://medium.com/@sblaizer?source=post_page---byline--631a79f96312---------------------------------------)\\n[Salomon Marquez](https://medium.com/@sblaizer?source=post_page---byline--631a79f96312---------------------------------------)\\n18 min read\\n¬∑Apr 28, 2024\\n[\\n](https://medium.com/m/signin?actionUrl=https://medium.com/_/vote/p/631a79f96312&amp;operation=register&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;user=Salomon+Marquez&amp;userId=1a60dea97a2c&amp;source=---header_actions--631a79f96312---------------------clap_footer------------------)\\n--\\n[](https://medium.com/m/signin?actionUrl=https://medium.com/_/bookmark/p/631a79f96312&amp;operation=register&amp;redirect=https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312&amp;source=---header_actions--631a79f96312---------------------bookmark_footer------------------)\\nListen\\nShare\\n*Authors:*[*Liliana Badillo*](https://www.kaggle.com/sophieb)*and*[*Salomon Marquez*](https://www.kaggle.com/sblaizer)\\n**> Note:\\n**> I created this Medium post to provide more visibility to our original report. Please refer to our [> A Journey Throuhgh Text Data Competitions\\n](https://www.kaggle.com/code/sophieb/a-journey-through-text-data-competitions)> notebook for further details.\\nN**atural Language Processing (NLP)**, the branch of artificial intelligence that enables computers to understand human language, has witnessed remarkable growth and transformative advancements in recent years. This surge has been driven by the increasing availability of vast amounts of text data and the rapid development of sophisticated machine-learning techniques.\\n*> ‚ÄúIt is estimated that 90% of the world‚Äôs data was generated in the last two years alone‚Äù\\n*> by [> Amount of Data Created Daily (2023)\\n](https://explodingtopics.com/blog/data-generated-per-day)\\n[**Kaggle**](https://www.kaggle.com/)is an online platform that hosts machine learning and data science competitions. Among these competitions, text data competitions specifically focus on tasks related to NLP and text analysis. Participants are provided with text datasets and are tasked with developing models and algorithms to solve language-related challenges such as sentiment analysis, text classification, and machine translation. These competitions are instrumental in advancing NLP techniques and provide participants with valuable experience and knowledge exchange opportunities.\\nAccessing and learning about the latest techniques employed in text data Kaggle competitions can be challenging due to their dispersion within discussions and winning solution write-ups.**Valuable information about these cutting-edge approaches tends to get buried, making it difficult to stay updated on the evolving landscape of text data techniques.**\\nIn this essay, our objective is to offer valuable insights into key lessons learned by the Kaggle community during their engagement in text data competitions spanning from 2021 to 2023. We will focus on**four pivotal topics**that have emerged as the foundation for successful solutions in recent years:**model architectures**,**pseudo labeling**,**adversarial weight perturbation**, and**mask language modeling**. By examining these four key areas, we aim to provide a comprehensive understanding of the essential elements driving winning strategies in text data competitions.\\n## Methodology\\nTo gain a better understanding of the text data landscape, we carried out the following tasks:\\n* **Analyze 27 write-ups from nine Kaggle competitions specifically related to text data**. We dove deeper into the top three solutions for text data competitions held from 2021 to 2023, see**Figure 1**. Also, we explore a range of topics, including the prevalent techniques and methodologies employed, the most effective model architectures utilized, and the challenges encountered and overcame. This analysis enabled us to gain deeper insights into the problem-solving approaches and thought processes employed by Kagglers in developing their successful solutions.\\n* **Perform a general but not exhaustive analysis of the**[**arXiv dataset**](https://www.kaggle.com/datasets/Cornell-University/arxiv). We filter out categories with the potential to include NLP papers published within the past two years. By leveraging a predefined list of keywords associated with text data, we directed our efforts towards uncovering the specific problem domains and top leading model architectures [1][2] that have garnered attention within the research community.\\nPress enter or click to view image in full size\\n![]()\\n**Figure 1.**Kaggle text data competitions held from 2021 to 2023\\n## Key Discoveries of Text Data Competitions\\nThe result of the analysis of the 27 write-ups and their most notable comments can be seen in[Table I of Appendix A](https://www.kaggle.com/code/sophieb/a-journey-through-text-data-competitions#Appendix-A)and[Table II of Appendix B](https://www.kaggle.com/code/sophieb/a-journey-through-text-data-competitions#Appendix-B), respectively.**Table I**provides information about the top three winning solutions in each Kaggle competition related to text, highlighting aspects such as model architectures, parameters like PB and LB, optimizers, ensembles, and the most innovative proposed ideas, among others. On the other hand,**Table II**presents a summary of comments from the write-ups in a question-like format. Additionally, the analysis of the arXiv dataset has allowed us to unveil, on a larger scale, how the use of certain model architectures and their application to specific text domains compares to the solutions presented in text-oriented Kaggle competitions over the past two years. For more details, please refer to[EDA Kaggle and Arxiv datasets](https://www.kaggle.com/code/sophieb/eda-kaggle-and-arxiv-datasets)notebook.\\nAs**Figure 2**shows, out of the nine competitions, five focused on text classification tasks, two aimed at information extraction tasks, while the remaining targeted text matching and question-and-answer tasks. Interestingly,**Figure 3**shows that with the frequency of the term ‚Äúquestion answering‚Äù exceeding 400 times, it can be inferred that the scientific community has placed greater importance on domains related to this field. While Kaggle competitions have only hosted one question-and-answer competition, there seems ...\", \"url\": \"https://medium.com/@sblaizer/a-journey-through-kaggle-text-data-competitions-from-2021-to-2023-631a79f96312\"}]}",
        "tool.duration_ms": 4187.7758502960205
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "6cd75671260f1ad1",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "WebSearchTool",
      "kind": "INTERNAL",
      "start_time": 1767959058371766312,
      "end_time": 1767959061804907890,
      "duration": 3.433141578,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "WebSearchTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What hyperparameter optimization techniques work best for text classification models in Kaggle competitions?\"}}",
        "tool.output": "{\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nAs of‚ÄØJan‚ÄØ9‚ÄØ2026, Bayesian‚Äëbased optimizers such as Optuna (or Hyperopt) paired with early‚Äëstopping and learning‚Äërate scheduling, and scalable parallel search tools like Ray‚ÄØTune, are reported to give the best results for text‚Äëclassification models in Kaggle competitions, outperforming manual grid or random search‚ÄØ([datascience.stackexchange.com](https://datascience.stackexchange.com/questions/124709/what-methods-do-top-kagglers-employ-for-score-gain),‚ÄØ[tw‚Äãdatascience.com](https://towardsdatascience.com/the-kaggle-way-to-tune-hyperparameters-with-optuna-285e59a0b95a),‚ÄØ[huggingface.co](https://huggingface.co/blog/ray-tune)).\\n\\n--- Result 2 ---\\nTitle: What methods do top Kagglers employ for score gain?\\nURL: https://datascience.stackexchange.com/questions/124709/what-methods-do-top-kagglers-employ-for-score-gain\\n\\nContent:\\n**Teams**\\n\\nQ&A for work\\n\\nConnect and share knowledge within a single location that is structured and easy to search.\\n\\n[Learn more about Teams](https://stackoverflow.co/teams/)\\n\\n# [What methods do top Kagglers employ for score gain?](https://datascience.stackexchange.com/questions/124709/what-methods-do-top-kagglers-employ-for-score-gain)\\n\\n[Ask Question](https://datascience.stackexchange.com/questions/ask)\\n\\nAsked1 year, 8 months ago\\n\\nModified [1 year, 8 months ago](https://datascience.stackexchange.com/datascience.stackexchange.com?lastactivity)\\n\\nViewed\\n424 times\\n\\n2\\n\\n$\\\\\\\\begingroup$\\n\\nI‚Äôm currently taking a course on ML and part of my final grade is my position on a Kaggle competition (private one) regarding a classification task. The majority of groups tend to have a similar public score but there are some that spike through the rest. I am left wondering what techniques data scientists employ to increase their scores.\\n\\nI am aware that a thoughtful pre-processing of the data is of chief importance as well as techniques such as grid search which help us find the best hyperparameters. This question is more about some out-of-the-box techniques that you employ when your aim is to increase your final score, for example, in the setting of a Kaggle competition.\\n\\n- [machine-learning](https://datascience.stackexchange.com/questions/tagged/machine-learning)\\n- [classification](https://datascience.stackexchange.com/questions/tagged/classification)\\n- [kaggle](https://datascience.stackexchange.com/questions/tagged/kaggle)\\n\\n[Share](https://datascience.stackexchange.com/q/124709)\\n\\n[Improve this question](https://datascience.stackexchange.com/posts/124709/edit)\\n\\nFollow\\n\\n[edited Nov 22, 2023 at 23:36](https://datascience.stackexchange.com/posts/124709/revisions)\\n\\n[Multivac](https://datascience.stackexchange.com/users/92050/multivac)\\n\\n3,25922 gold badges1010 silver badges2626 bronze badges\\n\\nasked Nov 22, 2023 at 19:32\\n\\n[Frederico Portela](https://datascience.stackexchange.com/users/155367/frederico-portela) Frederico Portela\\n\\n4122 bronze badges\\n\\n$\\\\\\\\endgroup$\\n\\n[Add a comment](https://datascience.stackexchange.com/datascience.stackexchange.com)¬†\\\\|\\n\\n## 2 Answers 2\\n\\nSorted by:\\n[Reset to default](https://datascience.stackexchange.com/questions/124709/what-methods-do-top-kagglers-employ-for-score-gain?answertab=scoredesc#tab-top)\\n\\nHighest score (default)Date modified (newest first)Date created (oldest first)\\n\\n4\\n\\n$\\\\\\\\begingroup$\\n\\nTop Kagglers often employ a combination of traditional machine learning techniques and creative, out-of-the-box strategies to gain an edge in competitions. Here are some techniques:\\n\\n**1\\\\. Ensemble Methods**\\n\\n- _Stacking/Blending:_ Combining predictions from multiple models. This involves training several models and then using another model to predict the target variable based on the predictions of the initial models.\\n\\n- _Bagging and Boosting:_ Techniques like Random Forest (bagging) and Gradient Boosting (boosting) can significantly improve performance.\\n\\n\\n**2\\\\. Feature Engineering**\\n\\n- _Creating new features:_ Deriving meaningful features from existing ones can provide valuable information to the model.\\n\\n- _Dimensionality Reduction:_ Techniques like Principal Component Analysis (PCA) or t-Distributed Stochastic Neighbor Embedding (t-SNE) can be useful.\\n\\n\\n**3\\\\. Advanced Preprocessing**\\n\\n- _Handling missing data:_ Creative ways to impute missing values.\\n\\n- _Outlier Detection and Treatment:_ Identifying and addressing outliers can improve model robustness.\\n\\n\\n**4\\\\. Model Hyperparameter Tuning**\\n\\n- _Bayesian Optimization:_ Efficiently searching hyperparameter space.\\n\\n- _Optuna, Hyperopt:_ Libraries for hyperparameter optimization.\\n\\n\\n**5\\\\. Neural Architecture Search (NAS)**\\n\\n- _Automated Model Design:_ Techniques to automatically search for the best neural network architecture.\\n\\n**6\\\\. Transfer Learning**\\n\\n- _Using pre-trained models:_ Leveraging models trained on large datasets and fine-tuning them for the specific task at hand.\\n\\n**7\\\\. Data Augmentation**\\n\\n- _Increasing Training Data:_ Applying transformations (rotations, flips, etc.) to artificially increase the size of the training dataset.\\n\\n**8\\\\. Domain-Specific Knowledge**\\n\\n- _Understanding the problem domain:_ Incorporating domain-specific knowledge can lead to better feature engineering and model performance.\\n\\n**9\\\\. Advanced Modeling Techniques**\\n\\n- _Neural Networks Architectures:_ Exploring different architectures, such as attention mechanisms, transformers, etc.\\n- _XGBoost, LightGBM, CatBoost:_ Gradient boosting libraries that are often used for tabular data.\\n\\n**10\\\\. Time Series Techniques**\\n\\n- _LSTM, GRU:_ For sequential data.\\n\\n- _Feature lagging and rolling statistics:_ Utilizing information from past time points.\\n\\n\\n**11\\\\. Post-Processing**\\n\\n- _Calibration:_ Adjusting predicted probabilities to improve the model's reliability.\\n- _Threshold tuning:_ Adjusting the classification threshold based on the specific needs of the task.\\n\\n**12\\\\. Collaboration and Knowledge Sharing**\\n\\n- _Participating in discussions:_ Sharing insights and learning from others on Kaggle forums.\\n- _Team Collaboration:_ Forming teams to combine diverse skills and perspectives.\\n\\n[Share](https://datascience.stackexchange.com/a/124714)\\n\\n[Improve this answer](https://datascience.stackexchange.com/posts/124714/edit)\\n\\nFollow\\n\\nanswered Nov 22, 2023 at 23:43\\n\\n[lvvittor](https://datascience.stackexchange.com/users/156336/lvvittor) lvvittor\\n\\n10111 bronze badge\\n\\n$\\\\\\\\endgroup$\\n\\n1\\n\\n- 1\\n\\n$\\\\\\\\begingroup$Thank you very much. There are indeed here some techniques i was not aware of.$\\\\\\\\endgroup$\\n\\n‚Äì¬†[Frederico Portela](https://datascience.stackexchange.com/users/155367/frederico-portela)\\n\\nCommentedNov 23, 2023 at 16:55\\n\\n\\n[Add a comment](https://datascience.stackexchange.com/datascience.stackexchange.com)¬†\\\\|\\n\\n4\\n\\n$\\\\\\\\begingroup$\\n\\nThere are many methods that can be employed to increase your score on a Kaggle competition. Here are a few examples:\\n\\n**Advanced classification techniques:** Using advanced classification techniques such as weighted average ensemble, stacked generalization ensemble, and power average ensemble can help improve your model's performance.\\n\\n**Data augmentation:** Techniques such as random rotation, hue adjustments, saturation adjustments, contrast adjustments, brightness adjustments, cropping, and more can help improve your model's accuracy when dealing with image data.\\n\\n**Text augmentation:** When dealing with text data, techniques such as exchanging words with synonyms, noising in RNN, and translating to other languages and back can help augment your training data and improve your model's performance.\\n\\n**External datasets:** Using external datasets that contain variables that influence the predicate variable can help increase the performance of your model pre-processing.\\n\\nI have even seen that in some cases, especially at the beginning of the site, teams took advantage of finding data leakage. For example, identifying customer's id that may potentially be linked to temporal patterns and thus model's prediction\\n\\nThis [discussion](https://www.kaggle.com/competitions/ieee-fraud-detection/discussion/111308) may give you a fine summary of most of the techniques I mentioned above.\\n\\nI hope it helps.\\n\\n[Share](https://datascience.stackexchange.com/a/124715)\\n\\n[Improve this answer](https://datascience.stackexchange.com/posts/124715/edit)\\n\\nFollow\\n\\nanswered Nov 22, 2023 at 23:44\\n\\n[Multivac](https://datascience.stackexchange.com/users/92050/multivac) Multivac\\n\\n3,25922 gold badges1010 silver badges2626 bronze badges\\n\\n$\\\\\\\\endgroup$\\n\\n1\\n\\n- $\\\\\\\\begingroup$Thank you for this. I'll take a look at the discussion.$\\\\\\\\endgroup$\\n\\n‚Äì¬†[Frederico Portela](https://datascience.stackexchange.com/users/155367/frederico-portela)\\n\\nCommentedNov 23, 2023 at 16:55\\n\\n\\n[Add a comment](https://datascience.stackexchange.com/datascience.stackexchange.com)¬†\\\\|\\n\\n## Your Answer\\n\\nDraft saved\\n\\nDraft discarded\\n\\n### Sign up or [log in](https://datascience.stackexchange.com/users/logi...\\n\\n--- Result 3 ---\\nTitle: The Kaggle Way to Tune Hyperparameters with Optuna\\nURL: https://towardsdatascience.com/the-kaggle-way-to-tune-hyperparameters-with-optuna-285e59a0b95a\\n\\nContent:\\nThe Kaggle Way to Tune Hyperparameters with Optuna | Towards Data Science\\n[![Towards Data Science](https://towardsdatascience.com/wp-content/uploads/2025/02/TDS-Vector-Logo.svg)](https://towardsdatascience.com/)\\nPublish AI, ML &amp; data-science insights to a global community of data professionals.\\nSign in\\n[Submit an Article](https://contributor.insightmediagroup.io/)\\n* [LinkedIn](https://www.linkedin.com/company/towards-data-science/?originalSubdomain=ca)\\n* [X](https://x.com/TDataScience)\\nToggle Search\\nSearch\\n[Artificial Intelligence](https://towardsdatascience.com/category/artificial-intelligence/)\\n# The Kaggle Way to Tune Hyperparameters with Optuna\\nEasily and efficiently optimize your model&#039;s hyperparameters with Optuna with a mini project\\n[Yash Prakash](https://towardsdatascience.com/author/ipom/)\\nJan 6, 2022\\n5 min read\\nShare\\n![Photo by Joshua Sortino on Unsplash](https://towardsdatascience.com/wp-content/uploads/2022/01/0AI-YmX3qqycS1Weo-scaled.jpg)Photo by[Joshua Sortino](https://unsplash.com/@sortino?utm_source=medium&amp;utm_medium=referral)on[Unsplash](https://unsplash.com?utm_source=medium&amp;utm_medium=referral)\\nA week ago, I posted one of my most popular articles, which contained a[list of Data Science tools and libraries](https://towardsdatascience.com/26-github-repositories-to-inspire-your-next-data-science-project-3023c24f4c3c)you should definitely be aware about. Today, I&#8217;m going to discuss one such great tool from the list.\\n[Optuna](https://github.com/optuna/optuna)is a lightweight and versatile tool to perform hyperparameter optimization for your ML algorithm in a convenient manner. With the latest version 3.0 release, I feel this is a good time to make you knowledgeable of the most prominent features of the library, and apply it on a real world mini project as well.\\nBut first, let&#8217;s discuss the elephant in the room.\\n## Why is Optuna so widely used?\\nHere are some of the greatest reasons for the popularity of this tool. And rightfully so, I&#8217;ll say:\\n* It is a platform independent library, meaning &#8211; you can use it with little to no changes with scikit-learn, Tensorflow/Keras, Pytorch, XGBoost and so on.\\n* Optuna enables you to use easy Python loops and conditional statements in your hyperparameter optimization pipeline.\\n* It also allows you to have concurrency in your code with little to no effort.\\n* And lastly, the in-built support for inspecting the optimization histories with a variety of plotting functions is very helpful.### **Note:**\\nI said**&quot;optimization histories&quot;:**Yes! That&#8217;s the fun part! No**`GridSearch`**implementation allows you retain all the history of all the trials that you conducted while searching for the hyperparameters. Optuna does, and such inference provide a great advantage.\\nIn this tutorial, I am going to use Optuna with XGBoost on a mini project in order to get you through all the fundamentals.\\nLet&#8217;s get started üëá## Setting up our project\\nMaking a virtual environment and installing XGBoost is the first step:\\n```\\n`pipenv shell`\\n```\\n```\\n`pipenv install xgboost\\npipenv install scikit-learn`\\n```\\nand then import the libraries we&#8217;ll be using, like so:\\n```\\n`import xgboost as xgb\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt`\\n```\\nWe will be making use of a preprocessed California Housing Dataset for building a regressor model, one that I&#8217;ve already prepared (link to the code + dataset at the end). We will first train a model the normal way and calculate the RMSE, and then optimize our model the best we can with Optuna.\\n## Training a simpleXGBoost model\\nThe preprocessed dataset can be imported simply:\\n```\\n`df = pd.read\\\\_csv(&#039;&#039;preprocessed\\\\_housing.csv&#039;&#039;)`\\n```\\n![Image by Autho - rthe preprocessed dataset](https://miro.medium.com/1*FmcC5AXcDQ-QpF4gW_FfXg.png)Image by Autho &#8211; rthe preprocessed dataset\\nFinally, we will go ahead and train a simple XGBoost model and calculate the validation RMSE:\\nThe output is like so:\\n```\\n`RMSE: 53119.69904403545`\\n```\\nHaving done that, let&#8217;s go ahead and get to the main part of this article!\\n## Making the Optuna objective function\\nThis objective is a bit different from what you may recall from Machine learning theory.\\nAn objective function in Optuna contains the following actions:\\n* It accepts a**dictionary**of different hyperparameters we want to optimize\\n* A model is**trained**within the function\\n* **Predictions**on test/validation data are made from the trained model\\n* The**accuracy**or**error**is finally**returned**from the function.\\nIn our case, we want to**minimize**our RMSE score, so we return the RMSE which we will then use in a &quot;**Study**&quot; to minimize.\\nLet&#8217;s create an objective function then!\\nn\\\\_trials represent each trial that is performed by the objective function, with the parameters given by**`suggest\\\\_int`**,**`suggest\\\\_float`**, and so on.\\nWe have the convenience of specifying the start, the end, and the step count, along with a**`log`**parameter which indicates whether our values represent logarithm bins or not. Learning rate hyperparameter uses**`log`**, as you can see.\\nNow, let&#8217;s create a**study**.\\n## Making a study and bringing it all together\\nA**study**in Optuna is entire process of optimization based on an objective function.\\nLet&#8217;s create one and start tuning our hyperparameters!\\n```\\n`# make a study`\\n```\\n```\\n`study = optuna.create\\\\_study(direction=&quot;&quot;minimize&quot;&quot;)\\nstudy.optimize(objective, n\\\\_trials=500)`\\n```\\nWe put &quot;minimize&quot; in the**`direction`**parameter because we want to use the objective function to minimize our RMSE error. If it was a classification task you&#8217;re doing, you can use**maximize**with the accuracy score you calculate!\\nYou&#8217;ll see that it takes less than two minutes for 500 trials on Google Colab! Quite a feat, isn&#8217;t it?\\nLet&#8217;s see the best scores and params and print them:\\n```\\n`print(f&quot;&quot;Optimized RMSE: {study.best\\\\_value:.4f}&quot;&quot;)`\\n```\\n```\\n`print(&quot;&quot;Best params:&quot;&quot;)\\nfor key, value in study.best\\\\_params.items():\\nprint(f&quot;&quot;t{key}: {value}&quot;&quot;)`\\n```\\nAnd finally, let&#8217;s put them all together:\\n```\\n`Output:`\\n```\\n```\\n`Optimized RMSE: 51774.6284\\nBest params: n\\\\_estimators: 1800 learning\\\\_rate: 0.2982950878173913 max\\\\_depth: 11`\\n```\\nI&#8217;ll say this looks like a very good improvement!\\n### Bonus experiment:\\nFinally, try seeing how the optimization history looks like with this snippet:\\n```\\n`from optuna.visualization.matplotlib import plot\\\\_optimization\\\\_history`\\n```\\n```\\n`plot\\\\_optimization\\\\_history(study)`\\n```\\nYour output should be something akin to this:\\n![Image by Author - optimization history plot](https://miro.medium.com/1*7cFNcQPQirwkmtqROWjNEQ.png)Image by Author &#8211; optimization history plot\\nThat&#8217;s it! Time to give yourself a pat on the back for making it all the way through!\\n## A few parting words&#8230;\\nThank you for reading.\\nI hope this quick tutorial with the mini project was helpful in recognizing the sheer advantage using Optuna provides as compared to regular hyperparameter optimization by hand. I recommend you experiment with building fresh pipelines with it with this or another dataset as next steps after going through this tutorial.\\nHappy learning! üôÇYou can find all the[code along with the preprocessed dataset here](https://github.com/yashprakash13/data-another-day/blob/main/README.md#a-data-scientists-life-hacks).\\nI hope to see you again in my next article. Until then,[follow me to not miss my next post](https://ipom.medium.com/). I do write every week!\\n### [I also recommend becoming a Medium member to never miss any of the Data Science articles I publish every week.](https://ipom.medium.com/membership/)Join here üëá[**> Join Medium with my referral link &#8211; Yash Prakash\\n**](https://ipom.medium.com/membership/)\\n**A couple other articles of mine you might be interested in:**\\n> ...\\n\\n--- Result 4 ---\\nTitle: Hyperparameter Search with Transformers and Ray Tune\\nURL: https://huggingface.co/blog/ray-tune\\n\\nContent:\\nHyperparameter Search with Transformers and Ray Tune\\n[![Hugging Face's logo](https://huggingface.co/front/assets/huggingface_logo-noborder.svg)Hugging Face](https://huggingface.co/)\\n[Back to Articles](https://huggingface.co/blog)\\n# [](#hyperparameter-search-with-transformers-and-ray-tune)Hyperparameter Search with Transformers and Ray Tune\\nPublished\\nNovember 2, 2020\\n[Update on GitHub](https://github.com/huggingface/blog/blob/main/ray-tune.md)\\n[\\nUpvote\\n4\\n](https://huggingface.co/login?next=/blog/ray-tune)\\n* [![](https://huggingface.co/avatars/a92dea7d853bbabbf60b351c207b6875.svg)](https://huggingface.co/etomoscow)\\n* [![](https://cdn-avatars.huggingface.co/v1/production/uploads/645d63c0ce72244df7b36be8/09vhYAzgv1svwvQM4eIE9.jpeg)](https://huggingface.co/Moreza009)\\n* [![](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/x8e_7GDCWVKREXUJeV6uw.png)](https://huggingface.co/AmrataYadav)\\n* [![](https://huggingface.co/avatars/4ef00e120c2f2db759bb6236dcba7d57.svg)](https://huggingface.co/Cavali)\\n* [![system's avatar](https://cdn-avatars.huggingface.co/v1/production/uploads/1646125250765-61af81e7a7205fb7cc9ec0cb.png)](https://huggingface.co/system)\\n[system\\nsystem\\nFollow\\n](https://huggingface.co/system)\\n##### [](#a-guest-blog-post-by-richard-liaw-from-the-anyscale-team)A guest blog post by Richard Liaw from the Anyscale team\\nWith cutting edge research implementations, thousands of trained models easily accessible, the Hugging Face[transformers](https://github.com/huggingface/transformers)library has become critical to the success and growth of natural language processing today.\\nFor any machine learning model to achieve good performance, users often need to implement some form of parameter tuning. Yet, nearly everyone ([1](https://medium.com/@prakashakshay90/fine-tuning-bert-model-using-pytorch-f34148d58a37),[2](https://mccormickml.com/2019/07/22/BERT-fine-tuning/#advantages-of-fine-tuning)) either ends up disregarding hyperparameter tuning or opting to do a simplistic grid search with a small search space.\\nHowever, simple experiments are able to show the benefit of using an advanced tuning technique. Below is[a recent experiment run on a BERT](https://medium.com/distributed-computing-with-ray/hyperparameter-optimization-for-transformers-a-guide-c4e32c6c989b)model from[Hugging Face transformers](https://github.com/huggingface/transformers)on the[RTE dataset](https://aclweb.org/aclwiki/Textual_Entailment_Resource_Pool). Genetic optimization techniques like[PBT](https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#population-based-training-tune-schedulers-populationbasedtraining)can provide large performance improvements compared to standard hyperparameter optimization techniques.\\n**Algorithm**|**Best Val Acc.**|**Best Test Acc.**|**Total GPU min**|**Total $ cost**|\\nGrid Search|74%|65.4%|45 min|$2.30|\\nBayesian Optimization +Early Stop|77%|66.9%|104 min|$5.30|\\nPopulation-based Training|78%|70.5%|48 min|$2.45|\\nIf you‚Äôre leveraging[Transformers](https://github.com/huggingface/transformers), you‚Äôll want to have a way to easily access powerful hyperparameter tuning solutions without giving up the customizability of the Transformers framework.\\n[![alt_text](https://huggingface.co/blog/assets/06_ray_tune/ray-hf.jpg \\\"image_tooltip\\\")](https://huggingface.co/blog/assets/06_ray_tune/ray-hf.jpg)\\nIn the Transformers 3.1 release,[Hugging Face Transformers](https://github.com/huggingface/transformers)and[Ray Tune](https://docs.ray.io/en/latest/tune/index.html)teamed up to provide a simple yet powerful integration.[Ray Tune](https://docs.ray.io/en/latest/tune/index.html)is a popular Python library for hyperparameter tuning that provides many state-of-the-art algorithms out of the box, along with integrations with the best-of-class tooling, such as[Weights and Biases](https://wandb.ai/)and tensorboard.\\nTo demonstrate this new[Hugging Face](https://github.com/huggingface/transformers)+[Ray Tune](https://docs.ray.io/en/latest/tune/index.html)integration, we leverage the[Hugging Face Datasets library](https://github.com/huggingface/datasets)to fine tune BERT on[MRPC](https://www.microsoft.com/en-us/download/details.aspx?id=52398).\\nTo run this example, please first run:\\n**`pip install \\\"ray[tune]\\\" transformers datasets scipy sklearn torch`**\\nSimply plug in one of Ray‚Äôs standard tuning algorithms by just adding a few lines of code.\\n```\\n`fromdatasetsimportload\\\\_dataset, load\\\\_metricfromtransformersimport(AutoModelForSequenceClassification, AutoTokenizer,\\nTrainer, TrainingArguments)\\ntokenizer = AutoTokenizer.from\\\\_pretrained('distilbert-base-uncased')\\ndataset = load\\\\_dataset('glue','mrpc')\\nmetric = load\\\\_metric('glue','mrpc')defencode(examples):\\noutputs = tokenizer(\\nexamples['sentence1'], examples['sentence2'], truncation=True)returnoutputs\\nencoded\\\\_dataset = dataset.map(encode, batched=True)defmodel\\\\_init():returnAutoModelForSequenceClassification.from\\\\_pretrained('distilbert-base-uncased', return\\\\_dict=True)defcompute\\\\_metrics(eval\\\\_pred):\\npredictions, labels = eval\\\\_pred\\npredictions = predictions.argmax(axis=-1)returnmetric.compute(predictions=predictions, references=labels)# Evaluate during training and a bit more often# than the default to be able to prune bad trials early.# Disabling tqdm is a matter of preference.training\\\\_args = TrainingArguments(\\\"test\\\", evaluation\\\\_strategy=\\\"steps\\\", eval\\\\_steps=500, disable\\\\_tqdm=True)\\ntrainer = Trainer(\\nargs=training\\\\_args,\\ntokenizer=tokenizer,\\ntrain\\\\_dataset=encoded\\\\_dataset[\\\"train\\\"],\\neval\\\\_dataset=encoded\\\\_dataset[\\\"validation\\\"],\\nmodel\\\\_init=model\\\\_init,\\ncompute\\\\_metrics=compute\\\\_metrics,\\n)# Default objective is the sum of all metrics# when metrics are provided, so we have to maximize it.trainer.hyperparameter\\\\_search(\\ndirection=\\\"maximize\\\", backend=\\\"ray\\\", n\\\\_trials=10# number of trials)`\\n```\\nBy default, each trial will utilize 1 CPU, and optionally 1 GPU if available.\\nYou can leverage multiple[GPUs for a parallel hyperparameter search](https://docs.ray.io/en/latest/tune/user-guide.html#resources-parallelism-gpus-distributed)by passing in a`resources\\\\_per\\\\_trial`argument.\\nYou can also easily swap different parameter tuning algorithms such as[HyperBand](https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#asha-tune-schedulers-ashascheduler),[Bayesian Optimization](https://docs.ray.io/en/latest/tune/api_docs/suggestion.html),[Population-Based Training](https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#population-based-training-tune-schedulers-populationbasedtraining):\\nTo run this example, first run:**`pip install hyperopt`**\\n```\\n`fromray.tune.suggest.hyperoptimportHyperOptSearchfromray.tune.schedulersimportASHAScheduler\\ntrainer = Trainer(\\nargs=training\\\\_args,\\ntokenizer=tokenizer,\\ntrain\\\\_dataset=encoded\\\\_dataset[\\\"train\\\"],\\neval\\\\_dataset=encoded\\\\_dataset[\\\"validation\\\"],\\nmodel\\\\_init=model\\\\_init,\\ncompute\\\\_metrics=compute\\\\_metrics,\\n)\\nbest\\\\_trial = trainer.hyperparameter\\\\_search(\\ndirection=\\\"maximize\\\",\\nbackend=\\\"ray\\\",# Choose among many libraries:# https://docs.ray.io/en/latest/tune/api\\\\_docs/suggestion.htmlsearch\\\\_alg=HyperOptSearch(metric=\\\"objective\\\", mode=\\\"max\\\"),# Choose among schedulers:# https://docs.ray.io/en/latest/tune/api\\\\_docs/schedulers.htmlscheduler=ASHAScheduler(metric=\\\"objective\\\", mode=\\\"max\\\"))`\\n```\\nIt also works with[Weights and Biases](https://wandb.ai/)out of the box!\\n[![alt_text](https://huggingface.co/blog/assets/06_ray_tune/ray-wandb.png \\\"image_tooltip\\\")](https://huggingface.co/blog/assets/06_ray_tune/ray-wandb.png)\\n### [](#try-it-out-today)Try it out today:\\n* `pip install -U ray`\\n* `pip install -U transformers datasets`\\n* Check out the[Hugging Face documentation](https://huggingface.co/transformers/)and[Discussion thread](https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10)\\n* [End-to-end example of using Hugging Face hyperparameter search for text classification](https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb)\\nIf you liked this blog...\\n\\n--- Result 5 ---\\nTitle: Titanic - Top 4% , Hyperparameter Tuning - Kaggle\\nURL: https://www.kaggle.com/code/tanmayunhale/titanic-top-4-hyperparameter-tuning\\n\\nContent:\\nChecking your browser - reCAPTCHA\\nChecking your browser before accessing www.kaggle.com ...\\nClick[here](#)if you are not automatically redirected after 5 seconds.\\n\\n--- Result 6 ---\\nTitle: XGBoost classifier and hyperparameter tuning [85%] - Kaggle\\nURL: https://www.kaggle.com/code/michalbrezk/xgboost-classifier-and-hyperparameter-tuning-85\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)</p></div>ChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\nat b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=fde7cab3d8c139f5e6ae:1:11126)</pre></div></div></div></div>\\n\\n--- Result 7 ---\\nTitle: Hyperparameter tuning in random forests - Kaggle\\nURL: https://www.kaggle.com/code/nargisbegum82/hyperparameter-tuning-in-random-forests\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)</p></div>ChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\nat f.onerror.f.onload (https://www.kaggle.com/static/assets/runtime.js?v=ed94601b1ebb8e8f5985:1:10685)</pre></div></div></div></div>\\n\\n--- Result 8 ---\\nTitle: Feature-engineering-pipeline-and-hyperparam-tuning - Kaggle\\nURL: https://www.kaggle.com/code/solegalli/feature-engineering-pipeline-and-hyperparam-tuning\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)</p></div>ChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\nat b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=b2b0a2a71e3ccb18d5a8:1:10994)</pre></div></div></div></div>\\n\\n--- Result 9 ---\\nTitle: Which text classification hyper-parameters are worth tuning?\\nURL: https://www.facebook.com/groups/1174547215919768/posts/1884000951641054\\n\\nContent:\\nFastText Users | Hey. So I&#039;m using fasttext for text classification, and the machine I&#039;m using is not strong enough to really brute force a hyper-parameter grid search...\\n\", \"is_error\": false, \"results\": [{\"title\": \"ANSWER\", \"text\": \"As of‚ÄØJan‚ÄØ9‚ÄØ2026, Bayesian‚Äëbased optimizers such as Optuna (or Hyperopt) paired with early‚Äëstopping and learning‚Äërate scheduling, and scalable parallel search tools like Ray‚ÄØTune, are reported to give the best results for text‚Äëclassification models in Kaggle competitions, outperforming manual grid or random search‚ÄØ([datascience.stackexchange.com](https://datascience.stackexchange.com/questions/124709/what-methods-do-top-kagglers-employ-for-score-gain),‚ÄØ[tw‚Äãdatascience.com](https://towardsdatascience.com/the-kaggle-way-to-tune-hyperparameters-with-optuna-285e59a0b95a),‚ÄØ[huggingface.co](https://huggingface.co/blog/ray-tune)).\", \"url\": \"\"}, {\"title\": \"What methods do top Kagglers employ for score gain?\", \"text\": \"**Teams**\\n\\nQ&A for work\\n\\nConnect and share knowledge within a single location that is structured and easy to search.\\n\\n[Learn more about Teams](https://stackoverflow.co/teams/)\\n\\n# [What methods do top Kagglers employ for score gain?](https://datascience.stackexchange.com/questions/124709/what-methods-do-top-kagglers-employ-for-score-gain)\\n\\n[Ask Question](https://datascience.stackexchange.com/questions/ask)\\n\\nAsked1 year, 8 months ago\\n\\nModified [1 year, 8 months ago](https://datascience.stackexchange.com/datascience.stackexchange.com?lastactivity)\\n\\nViewed\\n424 times\\n\\n2\\n\\n$\\\\\\\\begingroup$\\n\\nI‚Äôm currently taking a course on ML and part of my final grade is my position on a Kaggle competition (private one) regarding a classification task. The majority of groups tend to have a similar public score but there are some that spike through the rest. I am left wondering what techniques data scientists employ to increase their scores.\\n\\nI am aware that a thoughtful pre-processing of the data is of chief importance as well as techniques such as grid search which help us find the best hyperparameters. This question is more about some out-of-the-box techniques that you employ when your aim is to increase your final score, for example, in the setting of a Kaggle competition.\\n\\n- [machine-learning](https://datascience.stackexchange.com/questions/tagged/machine-learning)\\n- [classification](https://datascience.stackexchange.com/questions/tagged/classification)\\n- [kaggle](https://datascience.stackexchange.com/questions/tagged/kaggle)\\n\\n[Share](https://datascience.stackexchange.com/q/124709)\\n\\n[Improve this question](https://datascience.stackexchange.com/posts/124709/edit)\\n\\nFollow\\n\\n[edited Nov 22, 2023 at 23:36](https://datascience.stackexchange.com/posts/124709/revisions)\\n\\n[Multivac](https://datascience.stackexchange.com/users/92050/multivac)\\n\\n3,25922 gold badges1010 silver badges2626 bronze badges\\n\\nasked Nov 22, 2023 at 19:32\\n\\n[Frederico Portela](https://datascience.stackexchange.com/users/155367/frederico-portela) Frederico Portela\\n\\n4122 bronze badges\\n\\n$\\\\\\\\endgroup$\\n\\n[Add a comment](https://datascience.stackexchange.com/datascience.stackexchange.com)¬†\\\\|\\n\\n## 2 Answers 2\\n\\nSorted by:\\n[Reset to default](https://datascience.stackexchange.com/questions/124709/what-methods-do-top-kagglers-employ-for-score-gain?answertab=scoredesc#tab-top)\\n\\nHighest score (default)Date modified (newest first)Date created (oldest first)\\n\\n4\\n\\n$\\\\\\\\begingroup$\\n\\nTop Kagglers often employ a combination of traditional machine learning techniques and creative, out-of-the-box strategies to gain an edge in competitions. Here are some techniques:\\n\\n**1\\\\. Ensemble Methods**\\n\\n- _Stacking/Blending:_ Combining predictions from multiple models. This involves training several models and then using another model to predict the target variable based on the predictions of the initial models.\\n\\n- _Bagging and Boosting:_ Techniques like Random Forest (bagging) and Gradient Boosting (boosting) can significantly improve performance.\\n\\n\\n**2\\\\. Feature Engineering**\\n\\n- _Creating new features:_ Deriving meaningful features from existing ones can provide valuable information to the model.\\n\\n- _Dimensionality Reduction:_ Techniques like Principal Component Analysis (PCA) or t-Distributed Stochastic Neighbor Embedding (t-SNE) can be useful.\\n\\n\\n**3\\\\. Advanced Preprocessing**\\n\\n- _Handling missing data:_ Creative ways to impute missing values.\\n\\n- _Outlier Detection and Treatment:_ Identifying and addressing outliers can improve model robustness.\\n\\n\\n**4\\\\. Model Hyperparameter Tuning**\\n\\n- _Bayesian Optimization:_ Efficiently searching hyperparameter space.\\n\\n- _Optuna, Hyperopt:_ Libraries for hyperparameter optimization.\\n\\n\\n**5\\\\. Neural Architecture Search (NAS)**\\n\\n- _Automated Model Design:_ Techniques to automatically search for the best neural network architecture.\\n\\n**6\\\\. Transfer Learning**\\n\\n- _Using pre-trained models:_ Leveraging models trained on large datasets and fine-tuning them for the specific task at hand.\\n\\n**7\\\\. Data Augmentation**\\n\\n- _Increasing Training Data:_ Applying transformations (rotations, flips, etc.) to artificially increase the size of the training dataset.\\n\\n**8\\\\. Domain-Specific Knowledge**\\n\\n- _Understanding the problem domain:_ Incorporating domain-specific knowledge can lead to better feature engineering and model performance.\\n\\n**9\\\\. Advanced Modeling Techniques**\\n\\n- _Neural Networks Architectures:_ Exploring different architectures, such as attention mechanisms, transformers, etc.\\n- _XGBoost, LightGBM, CatBoost:_ Gradient boosting libraries that are often used for tabular data.\\n\\n**10\\\\. Time Series Techniques**\\n\\n- _LSTM, GRU:_ For sequential data.\\n\\n- _Feature lagging and rolling statistics:_ Utilizing information from past time points.\\n\\n\\n**11\\\\. Post-Processing**\\n\\n- _Calibration:_ Adjusting predicted probabilities to improve the model's reliability.\\n- _Threshold tuning:_ Adjusting the classification threshold based on the specific needs of the task.\\n\\n**12\\\\. Collaboration and Knowledge Sharing**\\n\\n- _Participating in discussions:_ Sharing insights and learning from others on Kaggle forums.\\n- _Team Collaboration:_ Forming teams to combine diverse skills and perspectives.\\n\\n[Share](https://datascience.stackexchange.com/a/124714)\\n\\n[Improve this answer](https://datascience.stackexchange.com/posts/124714/edit)\\n\\nFollow\\n\\nanswered Nov 22, 2023 at 23:43\\n\\n[lvvittor](https://datascience.stackexchange.com/users/156336/lvvittor) lvvittor\\n\\n10111 bronze badge\\n\\n$\\\\\\\\endgroup$\\n\\n1\\n\\n- 1\\n\\n$\\\\\\\\begingroup$Thank you very much. There are indeed here some techniques i was not aware of.$\\\\\\\\endgroup$\\n\\n‚Äì¬†[Frederico Portela](https://datascience.stackexchange.com/users/155367/frederico-portela)\\n\\nCommentedNov 23, 2023 at 16:55\\n\\n\\n[Add a comment](https://datascience.stackexchange.com/datascience.stackexchange.com)¬†\\\\|\\n\\n4\\n\\n$\\\\\\\\begingroup$\\n\\nThere are many methods that can be employed to increase your score on a Kaggle competition. Here are a few examples:\\n\\n**Advanced classification techniques:** Using advanced classification techniques such as weighted average ensemble, stacked generalization ensemble, and power average ensemble can help improve your model's performance.\\n\\n**Data augmentation:** Techniques such as random rotation, hue adjustments, saturation adjustments, contrast adjustments, brightness adjustments, cropping, and more can help improve your model's accuracy when dealing with image data.\\n\\n**Text augmentation:** When dealing with text data, techniques such as exchanging words with synonyms, noising in RNN, and translating to other languages and back can help augment your training data and improve your model's performance.\\n\\n**External datasets:** Using external datasets that contain variables that influence the predicate variable can help increase the performance of your model pre-processing.\\n\\nI have even seen that in some cases, especially at the beginning of the site, teams took advantage of finding data leakage. For example, identifying customer's id that may potentially be linked to temporal patterns and thus model's prediction\\n\\nThis [discussion](https://www.kaggle.com/competitions/ieee-fraud-detection/discussion/111308) may give you a fine summary of most of the techniques I mentioned above.\\n\\nI hope it helps.\\n\\n[Share](https://datascience.stackexchange.com/a/124715)\\n\\n[Improve this answer](https://datascience.stackexchange.com/posts/124715/edit)\\n\\nFollow\\n\\nanswered Nov 22, 2023 at 23:44\\n\\n[Multivac](https://datascience.stackexchange.com/users/92050/multivac) Multivac\\n\\n3,25922 gold badges1010 silver badges2626 bronze badges\\n\\n$\\\\\\\\endgroup$\\n\\n1\\n\\n- $\\\\\\\\begingroup$Thank you for this. I'll take a look at the discussion.$\\\\\\\\endgroup$\\n\\n‚Äì¬†[Frederico Portela](https://datascience.stackexchange.com/users/155367/frederico-portela)\\n\\nCommentedNov 23, 2023 at 16:55\\n\\n\\n[Add a comment](https://datascience.stackexchange.com/datascience.stackexchange.com)¬†\\\\|\\n\\n## Your Answer\\n\\nDraft saved\\n\\nDraft discarded\\n\\n### Sign up or [log in](https://datascience.stackexchange.com/users/logi...\", \"url\": \"https://datascience.stackexchange.com/questions/124709/what-methods-do-top-kagglers-employ-for-score-gain\"}, {\"title\": \"The Kaggle Way to Tune Hyperparameters with Optuna\", \"text\": \"The Kaggle Way to Tune Hyperparameters with Optuna | Towards Data Science\\n[![Towards Data Science](https://towardsdatascience.com/wp-content/uploads/2025/02/TDS-Vector-Logo.svg)](https://towardsdatascience.com/)\\nPublish AI, ML &amp; data-science insights to a global community of data professionals.\\nSign in\\n[Submit an Article](https://contributor.insightmediagroup.io/)\\n* [LinkedIn](https://www.linkedin.com/company/towards-data-science/?originalSubdomain=ca)\\n* [X](https://x.com/TDataScience)\\nToggle Search\\nSearch\\n[Artificial Intelligence](https://towardsdatascience.com/category/artificial-intelligence/)\\n# The Kaggle Way to Tune Hyperparameters with Optuna\\nEasily and efficiently optimize your model&#039;s hyperparameters with Optuna with a mini project\\n[Yash Prakash](https://towardsdatascience.com/author/ipom/)\\nJan 6, 2022\\n5 min read\\nShare\\n![Photo by Joshua Sortino on Unsplash](https://towardsdatascience.com/wp-content/uploads/2022/01/0AI-YmX3qqycS1Weo-scaled.jpg)Photo by[Joshua Sortino](https://unsplash.com/@sortino?utm_source=medium&amp;utm_medium=referral)on[Unsplash](https://unsplash.com?utm_source=medium&amp;utm_medium=referral)\\nA week ago, I posted one of my most popular articles, which contained a[list of Data Science tools and libraries](https://towardsdatascience.com/26-github-repositories-to-inspire-your-next-data-science-project-3023c24f4c3c)you should definitely be aware about. Today, I&#8217;m going to discuss one such great tool from the list.\\n[Optuna](https://github.com/optuna/optuna)is a lightweight and versatile tool to perform hyperparameter optimization for your ML algorithm in a convenient manner. With the latest version 3.0 release, I feel this is a good time to make you knowledgeable of the most prominent features of the library, and apply it on a real world mini project as well.\\nBut first, let&#8217;s discuss the elephant in the room.\\n## Why is Optuna so widely used?\\nHere are some of the greatest reasons for the popularity of this tool. And rightfully so, I&#8217;ll say:\\n* It is a platform independent library, meaning &#8211; you can use it with little to no changes with scikit-learn, Tensorflow/Keras, Pytorch, XGBoost and so on.\\n* Optuna enables you to use easy Python loops and conditional statements in your hyperparameter optimization pipeline.\\n* It also allows you to have concurrency in your code with little to no effort.\\n* And lastly, the in-built support for inspecting the optimization histories with a variety of plotting functions is very helpful.### **Note:**\\nI said**&quot;optimization histories&quot;:**Yes! That&#8217;s the fun part! No**`GridSearch`**implementation allows you retain all the history of all the trials that you conducted while searching for the hyperparameters. Optuna does, and such inference provide a great advantage.\\nIn this tutorial, I am going to use Optuna with XGBoost on a mini project in order to get you through all the fundamentals.\\nLet&#8217;s get started üëá## Setting up our project\\nMaking a virtual environment and installing XGBoost is the first step:\\n```\\n`pipenv shell`\\n```\\n```\\n`pipenv install xgboost\\npipenv install scikit-learn`\\n```\\nand then import the libraries we&#8217;ll be using, like so:\\n```\\n`import xgboost as xgb\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt`\\n```\\nWe will be making use of a preprocessed California Housing Dataset for building a regressor model, one that I&#8217;ve already prepared (link to the code + dataset at the end). We will first train a model the normal way and calculate the RMSE, and then optimize our model the best we can with Optuna.\\n## Training a simpleXGBoost model\\nThe preprocessed dataset can be imported simply:\\n```\\n`df = pd.read\\\\_csv(&#039;&#039;preprocessed\\\\_housing.csv&#039;&#039;)`\\n```\\n![Image by Autho - rthe preprocessed dataset](https://miro.medium.com/1*FmcC5AXcDQ-QpF4gW_FfXg.png)Image by Autho &#8211; rthe preprocessed dataset\\nFinally, we will go ahead and train a simple XGBoost model and calculate the validation RMSE:\\nThe output is like so:\\n```\\n`RMSE: 53119.69904403545`\\n```\\nHaving done that, let&#8217;s go ahead and get to the main part of this article!\\n## Making the Optuna objective function\\nThis objective is a bit different from what you may recall from Machine learning theory.\\nAn objective function in Optuna contains the following actions:\\n* It accepts a**dictionary**of different hyperparameters we want to optimize\\n* A model is**trained**within the function\\n* **Predictions**on test/validation data are made from the trained model\\n* The**accuracy**or**error**is finally**returned**from the function.\\nIn our case, we want to**minimize**our RMSE score, so we return the RMSE which we will then use in a &quot;**Study**&quot; to minimize.\\nLet&#8217;s create an objective function then!\\nn\\\\_trials represent each trial that is performed by the objective function, with the parameters given by**`suggest\\\\_int`**,**`suggest\\\\_float`**, and so on.\\nWe have the convenience of specifying the start, the end, and the step count, along with a**`log`**parameter which indicates whether our values represent logarithm bins or not. Learning rate hyperparameter uses**`log`**, as you can see.\\nNow, let&#8217;s create a**study**.\\n## Making a study and bringing it all together\\nA**study**in Optuna is entire process of optimization based on an objective function.\\nLet&#8217;s create one and start tuning our hyperparameters!\\n```\\n`# make a study`\\n```\\n```\\n`study = optuna.create\\\\_study(direction=&quot;&quot;minimize&quot;&quot;)\\nstudy.optimize(objective, n\\\\_trials=500)`\\n```\\nWe put &quot;minimize&quot; in the**`direction`**parameter because we want to use the objective function to minimize our RMSE error. If it was a classification task you&#8217;re doing, you can use**maximize**with the accuracy score you calculate!\\nYou&#8217;ll see that it takes less than two minutes for 500 trials on Google Colab! Quite a feat, isn&#8217;t it?\\nLet&#8217;s see the best scores and params and print them:\\n```\\n`print(f&quot;&quot;Optimized RMSE: {study.best\\\\_value:.4f}&quot;&quot;)`\\n```\\n```\\n`print(&quot;&quot;Best params:&quot;&quot;)\\nfor key, value in study.best\\\\_params.items():\\nprint(f&quot;&quot;t{key}: {value}&quot;&quot;)`\\n```\\nAnd finally, let&#8217;s put them all together:\\n```\\n`Output:`\\n```\\n```\\n`Optimized RMSE: 51774.6284\\nBest params: n\\\\_estimators: 1800 learning\\\\_rate: 0.2982950878173913 max\\\\_depth: 11`\\n```\\nI&#8217;ll say this looks like a very good improvement!\\n### Bonus experiment:\\nFinally, try seeing how the optimization history looks like with this snippet:\\n```\\n`from optuna.visualization.matplotlib import plot\\\\_optimization\\\\_history`\\n```\\n```\\n`plot\\\\_optimization\\\\_history(study)`\\n```\\nYour output should be something akin to this:\\n![Image by Author - optimization history plot](https://miro.medium.com/1*7cFNcQPQirwkmtqROWjNEQ.png)Image by Author &#8211; optimization history plot\\nThat&#8217;s it! Time to give yourself a pat on the back for making it all the way through!\\n## A few parting words&#8230;\\nThank you for reading.\\nI hope this quick tutorial with the mini project was helpful in recognizing the sheer advantage using Optuna provides as compared to regular hyperparameter optimization by hand. I recommend you experiment with building fresh pipelines with it with this or another dataset as next steps after going through this tutorial.\\nHappy learning! üôÇYou can find all the[code along with the preprocessed dataset here](https://github.com/yashprakash13/data-another-day/blob/main/README.md#a-data-scientists-life-hacks).\\nI hope to see you again in my next article. Until then,[follow me to not miss my next post](https://ipom.medium.com/). I do write every week!\\n### [I also recommend becoming a Medium member to never miss any of the Data Science articles I publish every week.](https://ipom.medium.com/membership/)Join here üëá[**> Join Medium with my referral link &#8211; Yash Prakash\\n**](https://ipom.medium.com/membership/)\\n**A couple other articles of mine you might be interested in:**\\n> ...\", \"url\": \"https://towardsdatascience.com/the-kaggle-way-to-tune-hyperparameters-with-optuna-285e59a0b95a\"}, {\"title\": \"Hyperparameter Search with Transformers and Ray Tune\", \"text\": \"Hyperparameter Search with Transformers and Ray Tune\\n[![Hugging Face's logo](https://huggingface.co/front/assets/huggingface_logo-noborder.svg)Hugging Face](https://huggingface.co/)\\n[Back to Articles](https://huggingface.co/blog)\\n# [](#hyperparameter-search-with-transformers-and-ray-tune)Hyperparameter Search with Transformers and Ray Tune\\nPublished\\nNovember 2, 2020\\n[Update on GitHub](https://github.com/huggingface/blog/blob/main/ray-tune.md)\\n[\\nUpvote\\n4\\n](https://huggingface.co/login?next=/blog/ray-tune)\\n* [![](https://huggingface.co/avatars/a92dea7d853bbabbf60b351c207b6875.svg)](https://huggingface.co/etomoscow)\\n* [![](https://cdn-avatars.huggingface.co/v1/production/uploads/645d63c0ce72244df7b36be8/09vhYAzgv1svwvQM4eIE9.jpeg)](https://huggingface.co/Moreza009)\\n* [![](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/x8e_7GDCWVKREXUJeV6uw.png)](https://huggingface.co/AmrataYadav)\\n* [![](https://huggingface.co/avatars/4ef00e120c2f2db759bb6236dcba7d57.svg)](https://huggingface.co/Cavali)\\n* [![system's avatar](https://cdn-avatars.huggingface.co/v1/production/uploads/1646125250765-61af81e7a7205fb7cc9ec0cb.png)](https://huggingface.co/system)\\n[system\\nsystem\\nFollow\\n](https://huggingface.co/system)\\n##### [](#a-guest-blog-post-by-richard-liaw-from-the-anyscale-team)A guest blog post by Richard Liaw from the Anyscale team\\nWith cutting edge research implementations, thousands of trained models easily accessible, the Hugging Face[transformers](https://github.com/huggingface/transformers)library has become critical to the success and growth of natural language processing today.\\nFor any machine learning model to achieve good performance, users often need to implement some form of parameter tuning. Yet, nearly everyone ([1](https://medium.com/@prakashakshay90/fine-tuning-bert-model-using-pytorch-f34148d58a37),[2](https://mccormickml.com/2019/07/22/BERT-fine-tuning/#advantages-of-fine-tuning)) either ends up disregarding hyperparameter tuning or opting to do a simplistic grid search with a small search space.\\nHowever, simple experiments are able to show the benefit of using an advanced tuning technique. Below is[a recent experiment run on a BERT](https://medium.com/distributed-computing-with-ray/hyperparameter-optimization-for-transformers-a-guide-c4e32c6c989b)model from[Hugging Face transformers](https://github.com/huggingface/transformers)on the[RTE dataset](https://aclweb.org/aclwiki/Textual_Entailment_Resource_Pool). Genetic optimization techniques like[PBT](https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#population-based-training-tune-schedulers-populationbasedtraining)can provide large performance improvements compared to standard hyperparameter optimization techniques.\\n**Algorithm**|**Best Val Acc.**|**Best Test Acc.**|**Total GPU min**|**Total $ cost**|\\nGrid Search|74%|65.4%|45 min|$2.30|\\nBayesian Optimization +Early Stop|77%|66.9%|104 min|$5.30|\\nPopulation-based Training|78%|70.5%|48 min|$2.45|\\nIf you‚Äôre leveraging[Transformers](https://github.com/huggingface/transformers), you‚Äôll want to have a way to easily access powerful hyperparameter tuning solutions without giving up the customizability of the Transformers framework.\\n[![alt_text](https://huggingface.co/blog/assets/06_ray_tune/ray-hf.jpg \\\"image_tooltip\\\")](https://huggingface.co/blog/assets/06_ray_tune/ray-hf.jpg)\\nIn the Transformers 3.1 release,[Hugging Face Transformers](https://github.com/huggingface/transformers)and[Ray Tune](https://docs.ray.io/en/latest/tune/index.html)teamed up to provide a simple yet powerful integration.[Ray Tune](https://docs.ray.io/en/latest/tune/index.html)is a popular Python library for hyperparameter tuning that provides many state-of-the-art algorithms out of the box, along with integrations with the best-of-class tooling, such as[Weights and Biases](https://wandb.ai/)and tensorboard.\\nTo demonstrate this new[Hugging Face](https://github.com/huggingface/transformers)+[Ray Tune](https://docs.ray.io/en/latest/tune/index.html)integration, we leverage the[Hugging Face Datasets library](https://github.com/huggingface/datasets)to fine tune BERT on[MRPC](https://www.microsoft.com/en-us/download/details.aspx?id=52398).\\nTo run this example, please first run:\\n**`pip install \\\"ray[tune]\\\" transformers datasets scipy sklearn torch`**\\nSimply plug in one of Ray‚Äôs standard tuning algorithms by just adding a few lines of code.\\n```\\n`fromdatasetsimportload\\\\_dataset, load\\\\_metricfromtransformersimport(AutoModelForSequenceClassification, AutoTokenizer,\\nTrainer, TrainingArguments)\\ntokenizer = AutoTokenizer.from\\\\_pretrained('distilbert-base-uncased')\\ndataset = load\\\\_dataset('glue','mrpc')\\nmetric = load\\\\_metric('glue','mrpc')defencode(examples):\\noutputs = tokenizer(\\nexamples['sentence1'], examples['sentence2'], truncation=True)returnoutputs\\nencoded\\\\_dataset = dataset.map(encode, batched=True)defmodel\\\\_init():returnAutoModelForSequenceClassification.from\\\\_pretrained('distilbert-base-uncased', return\\\\_dict=True)defcompute\\\\_metrics(eval\\\\_pred):\\npredictions, labels = eval\\\\_pred\\npredictions = predictions.argmax(axis=-1)returnmetric.compute(predictions=predictions, references=labels)# Evaluate during training and a bit more often# than the default to be able to prune bad trials early.# Disabling tqdm is a matter of preference.training\\\\_args = TrainingArguments(\\\"test\\\", evaluation\\\\_strategy=\\\"steps\\\", eval\\\\_steps=500, disable\\\\_tqdm=True)\\ntrainer = Trainer(\\nargs=training\\\\_args,\\ntokenizer=tokenizer,\\ntrain\\\\_dataset=encoded\\\\_dataset[\\\"train\\\"],\\neval\\\\_dataset=encoded\\\\_dataset[\\\"validation\\\"],\\nmodel\\\\_init=model\\\\_init,\\ncompute\\\\_metrics=compute\\\\_metrics,\\n)# Default objective is the sum of all metrics# when metrics are provided, so we have to maximize it.trainer.hyperparameter\\\\_search(\\ndirection=\\\"maximize\\\", backend=\\\"ray\\\", n\\\\_trials=10# number of trials)`\\n```\\nBy default, each trial will utilize 1 CPU, and optionally 1 GPU if available.\\nYou can leverage multiple[GPUs for a parallel hyperparameter search](https://docs.ray.io/en/latest/tune/user-guide.html#resources-parallelism-gpus-distributed)by passing in a`resources\\\\_per\\\\_trial`argument.\\nYou can also easily swap different parameter tuning algorithms such as[HyperBand](https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#asha-tune-schedulers-ashascheduler),[Bayesian Optimization](https://docs.ray.io/en/latest/tune/api_docs/suggestion.html),[Population-Based Training](https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#population-based-training-tune-schedulers-populationbasedtraining):\\nTo run this example, first run:**`pip install hyperopt`**\\n```\\n`fromray.tune.suggest.hyperoptimportHyperOptSearchfromray.tune.schedulersimportASHAScheduler\\ntrainer = Trainer(\\nargs=training\\\\_args,\\ntokenizer=tokenizer,\\ntrain\\\\_dataset=encoded\\\\_dataset[\\\"train\\\"],\\neval\\\\_dataset=encoded\\\\_dataset[\\\"validation\\\"],\\nmodel\\\\_init=model\\\\_init,\\ncompute\\\\_metrics=compute\\\\_metrics,\\n)\\nbest\\\\_trial = trainer.hyperparameter\\\\_search(\\ndirection=\\\"maximize\\\",\\nbackend=\\\"ray\\\",# Choose among many libraries:# https://docs.ray.io/en/latest/tune/api\\\\_docs/suggestion.htmlsearch\\\\_alg=HyperOptSearch(metric=\\\"objective\\\", mode=\\\"max\\\"),# Choose among schedulers:# https://docs.ray.io/en/latest/tune/api\\\\_docs/schedulers.htmlscheduler=ASHAScheduler(metric=\\\"objective\\\", mode=\\\"max\\\"))`\\n```\\nIt also works with[Weights and Biases](https://wandb.ai/)out of the box!\\n[![alt_text](https://huggingface.co/blog/assets/06_ray_tune/ray-wandb.png \\\"image_tooltip\\\")](https://huggingface.co/blog/assets/06_ray_tune/ray-wandb.png)\\n### [](#try-it-out-today)Try it out today:\\n* `pip install -U ray`\\n* `pip install -U transformers datasets`\\n* Check out the[Hugging Face documentation](https://huggingface.co/transformers/)and[Discussion thread](https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10)\\n* [End-to-end example of using Hugging Face hyperparameter search for text classification](https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb)\\nIf you liked this blog...\", \"url\": \"https://huggingface.co/blog/ray-tune\"}, {\"title\": \"Titanic - Top 4% , Hyperparameter Tuning - Kaggle\", \"text\": \"Checking your browser - reCAPTCHA\\nChecking your browser before accessing www.kaggle.com ...\\nClick[here](#)if you are not automatically redirected after 5 seconds.\", \"url\": \"https://www.kaggle.com/code/tanmayunhale/titanic-top-4-hyperparameter-tuning\"}, {\"title\": \"XGBoost classifier and hyperparameter tuning [85%] - Kaggle\", \"text\": \"<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)</p></div>ChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\nat b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=fde7cab3d8c139f5e6ae:1:11126)</pre></div></div></div></div>\", \"url\": \"https://www.kaggle.com/code/michalbrezk/xgboost-classifier-and-hyperparameter-tuning-85\"}, {\"title\": \"Hyperparameter tuning in random forests - Kaggle\", \"text\": \"<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)</p></div>ChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\nat f.onerror.f.onload (https://www.kaggle.com/static/assets/runtime.js?v=ed94601b1ebb8e8f5985:1:10685)</pre></div></div></div></div>\", \"url\": \"https://www.kaggle.com/code/nargisbegum82/hyperparameter-tuning-in-random-forests\"}, {\"title\": \"Feature-engineering-pipeline-and-hyperparam-tuning - Kaggle\", \"text\": \"<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)</p></div>ChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\nat b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=b2b0a2a71e3ccb18d5a8:1:10994)</pre></div></div></div></div>\", \"url\": \"https://www.kaggle.com/code/solegalli/feature-engineering-pipeline-and-hyperparam-tuning\"}, {\"title\": \"Which text classification hyper-parameters are worth tuning?\", \"text\": \"FastText Users | Hey. So I&#039;m using fasttext for text classification, and the machine I&#039;m using is not strong enough to really brute force a hyper-parameter grid search...\", \"url\": \"https://www.facebook.com/groups/1174547215919768/posts/1884000951641054\"}]}",
        "tool.duration_ms": 3432.706594467163
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "219bfd1d475ff9b1",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "WebSearchTool",
      "kind": "INTERNAL",
      "start_time": 1767959069692756902,
      "end_time": 1767959075440700099,
      "duration": 5.747943197,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "WebSearchTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What text data augmentation techniques are most effective for improving text classification model performance in Kaggle competitions?\"}}",
        "tool.output": "{\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nText data augmentation is a cornerstone of winning Kaggle text‚Äëclassification solutions because it expands limited training sets, reduces over‚Äëfitting, and mimics the linguistic variability seen in real‚Äëworld data.  The most consistently effective tricks, as reported by a Kaggle master and validated in recent research, are the **Easy Data Augmentation (EDA)** operations ‚Äì synonym replacement, random insertion, random swap, and random deletion ‚Äì which are simple to implement yet give large gains, especially on small‚Äëto‚Äëmedium datasets ([Neptune‚ÄØAI](https://neptune.ai/blog/data-augmentation-nlp),‚ÄØ2023;‚ÄØ[Wei & Zou‚ÄØ2019](https://arxiv.org/abs/1901.11196)).  Building on EDA, practitioners add **back‚Äëtranslation** (translate to another language and back) and **contextual word replacement** using pretrained language models (e.g., BERT, RoBERTa) to generate fluent paraphrases that preserve label semantics.  Word‚Äëembedding‚Äëbased synonym swaps and character‚Äëlevel noise (swap or delete characters) further diversify the corpus without breaking meaning ([DataCamp‚ÄØ2024](https://www.datacamp.com/tutorial/complete-guide-data-augmentation)).  \\n\\nBeyond these ‚Äúlightweight‚Äù methods, recent Kaggle‚Äëlevel experiments show that **strategic curriculum learning**‚Äîintroducing real examples first and then gradually mixing augmented ones‚Äîcan amplify the benefit of any augmentation technique.  The Modified Cyclical Curriculum Learning (MCCL) framework, evaluated across topic classification, sentiment analysis, and offensive‚Äëlanguage detection, consistently outperformed plain training ([ScienceDirect‚ÄØ2024](https://www.sciencedirect.com/science/article/pii/S2949719124000190)).  For larger label‚Äërich tasks, **class‚Äëconditional generative models** such as a VAE trained per class have been demonstrated to surpass other generative augmentations, delivering higher accuracy on binary classification benchmarks ([Piedboeuf‚ÄØ2022](https://aclanthology.org/2022.coling-1.305)).  \\n\\nIn practice, Kaggle winners combine these approaches: start with EDA‚Äëstyle word‚Äëlevel edits, enrich with back‚Äëtranslation or BERT‚Äëbased paraphrasing, apply a modest amount of character noise, and finally schedule the augmented data using a curriculum (or mixup) strategy.  This pipeline balances diversity and label fidelity, leading to the strongest performance gains reported across recent Kaggle text‚Äëclassification competitions ([Neptune‚ÄØ2022](https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions)).\\n\\n--- Result 2 ---\\nTitle: Data Augmentation in NLP: Best Practices From a Kaggle ...\\nURL: https://neptune.ai/blog/data-augmentation-nlp\\n\\nContent:\\nData Augmentation in NLP: Best Practices From a Kaggle Master[\\n**üì£ BIG NEWS:****Neptune is joining OpenAI!**‚Üí Read the message from our CEO üì£![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\\nWhat do you want to find?\\nSearch\\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Neptune Blog](https://neptune.ai/blog)# Data Augmentation in NLP: Best Practices From a Kaggle Master\\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Shahul-Es-new-scaled.jpeg?fit=2560%2C1920&ssl=1)\\n[Shahul ES](https://neptune.ai/blog/author/shahules)\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)5 min\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)1st September, 2023\\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)[Natural Language Processing](https://neptune.ai/blog/category/natural-language-processing)\\nThere are many tasks in NLP from text classification to question answering but whatever you do the amount of data you have to train your model impacts the model performance heavily.\\nWhat can you do to make your dataset larger?\\nSimple option -&gt; Get more data :).\\nBut acquiring and labeling additional observations can be an expensive and time-consuming process.\\nWhat you can do instead?\\nApply data augmentation to your text data.\\nData augmentation techniques are used to**generate additional, synthetic data using the data you have.**Augmentation methods are super popular in computer vision applications but they are just as powerful for NLP.\\nIn this article, we‚Äôll go through all the major data augmentation methods for NLP that you can use to increase the size of your textual dataset and improve your model performance.\\n## Data augmentation for vision vs NLP\\nIn computer vision applications data augmentations are done almost everywhere to get larger training data and make the model generalize better.\\nThe main methods used involve:\\n* cropping,\\n* flipping,\\n* zooming,\\n* rotation,\\n* noise injection,\\n* and many others.\\nIn**computer vision**, these transformations are**done on the go**using data generators. As a batch of data is fed to your neural network it is randomly transformed (augmented). You don‚Äôt need to prepare anything before training.\\nThis isn‚Äôt the case with**NLP**, where data augmentation should be done carefully due to the grammatical structure of the text. The methods discussed here are used**before training.**A new augmented dataset is generated beforehand and later fed into data loaders to train the model.\\n![](https://lh4.googleusercontent.com/nyCEre_Ywft5YHXeKTEmMR-kmSkySsTIH6x_U1jBbJ9CF_2Erbnz9oueyXFIH4PMHBxl1elzRSFIszU9xKJ7aveJ1sL489I3p_DXc5QWIOFP2W8wWWvBQ7x-QzRCT23R5XDi5Gm3)\\n## Data augmentation methods\\nIn this article, I will mainly focus on NLP data augmentation methods provided in the following projects:\\n* Back translation.\\n* [EDA (Easy Data Augmentation)](https://arxiv.org/abs/1901.11196).\\n* [NLP Albumentation.](https://github.com/albumentations-team/albumentations)\\n* [NLP Aug.](https://github.com/makcedward/nlpaug)\\nSo, let‚Äôs dive into each of them.\\n### **Back translation**\\nIn this method, we**translate the text data to some language and then translate it back to the original**language. This can help to generate textual data with different words while preserving the context of the text data.\\nLanguage translations APIs like google translate, Bing, Yandex are used to perform the translation. For example, given the sentence:\\n![](https://lh6.googleusercontent.com/x3ZAhTDLT1QVSD8gCdaBVMquM2dcYA15A-orfzXyTzhTP8m0ZKLXz_2NrJdWlTgWKRS7BimExM8RO9Ce_uVVVdRR29vGeP0VZdncDZY0GTwkctocQyYg7HK9VL5ay3QC4JhbSXBK)*Amit Chaudhary[&#8220;Back Translation for Text Augmentation with Google Sheets&#8221;](https://amitness.com/2020/02/back-translation-in-google-sheets/)*\\nYou can see that the sentences are not the same but their content remains the same after the back-translation. If you want to try this method for a dataset you can use this[notebook](https://www.kaggle.com/miklgr500/how-to-use-translators-for-comments-translation)as reference.\\n### **Easy Data Augmentation**\\nEasy data augmentation uses traditional and very simple data augmentation methods. EDA consists of**four simple operations that do a surprisingly good job**of preventing overfitting and helping train more robust models.\\n* **Synonym Replacement**\\nRandomly choose*n*words from the sentence that are not stop words. Replace each of these words with one of its synonyms chosen at random.\\nFor example, given the sentence:\\n*This**article**will focus on summarizing data augmentation**techniques**in NLP.*\\nThe method randomly selects n words (say two), the words*article*and*techniques*, and replaces them with*write-up*and*methods*respectively.\\n*This**write-up**will focus on summarizing data augmentation**methods**in NLP.*\\n* **Random Insertion**\\nFind a random synonym of a random word in the sentence that is not a stop word. Insert that synonym into a random position in the sentence. Do this*n*times.\\nFor example, given the sentence:\\n*This**article**will focus on summarizing data augmentation**techniques**in NLP.*\\nThe method randomly selects n words (say two), the words*article*and*techniques*find the synonyms as*write-up*and*methods*respectively. Then these synonyms are inserted at a random position in the sentence.\\n*This article will focus on**write-up**summarizing data augmentation techniques in NLP**methods**.*\\n* **Random Swap**\\nRandomly choose two words in the sentence and swap their positions. Do this*n*times.\\nFor example, given the sentence\\n*This**article**will focus on summarizing data augmentation**techniques**in NLP.*\\nThe method randomly selects n words (say two), the words*article*and*techniques*and swaps them to create a new sentence.\\n*This**techniques**will focus on summarizing data augmentation**article**in NLP.*\\n* **Random Deletion**\\nRandomly remove each word in the sentence with probability*p*.\\nFor example, given the sentence\\n*This**article**will focus on summarizing data augmentation**techniques**in NLP.*\\nThe method selects n words (say two), the words*will*and*techniques*, and removes them from the sentence.\\n*This****article**focus on summarizing data augmentation in NLP.*\\nYou can go to this[repository](https://github.com/jasonwei20/eda_nlp)if you want to apply these techniques to your projects.\\n### **NLP Albumentation**\\nPreviously, we talked about differences between computer vision data augmentation and NLP data augmentation. But in this section, we will see how we can apply some of the ideas used in CV data augmentation in NLP.\\nFor that, we will use the[Albumentations](https://github.com/albumentations-team/albumentations)package.\\nLet‚Äôs take a look at a couple of the techniques here.\\n* **Shuffle Sentences Transform**\\nIn this transformation, if the given text sample contains multiple sentences these sentences are shuffled to create a new sample.\\nFor example:\\n**text = &#8216;&lt;Sentence1&gt;. &lt;Sentence2&gt;. &lt;Sentence4&gt;. &lt;Sentence4&gt;. &lt;Sentence...\\n\\n--- Result 3 ---\\nTitle: Advancing NLP models with strategic text augmentation\\nURL: https://www.sciencedirect.com/science/article/pii/S2949719124000190\\n\\nContent:\\n<div><div><header></header><div><div><ul><li><a><span><span><span>View¬†<strong>PDF</strong></span></span></span></a></li><li></li></ul></div><div><article><div><p><a href=\\\"https://www.sciencedirect.com/journal/natural-language-processing-journal\\\"><span><span></span></span></a></p><p><a href=\\\"https://www.sciencedirect.com/journal/natural-language-processing-journal/vol/7/suppl/C\\\"><span><span></span></span></a></p></div><div><p><span>Under a Creative Commons </span><a href=\\\"http://creativecommons.org/licenses/by/4.0/\\\"><span><span>license</span></span></a></p><p><span></span>Open access</p></div><div><h2>Abstract</h2><div><p>This study conducts a thorough evaluation of text augmentation techniques across a variety of datasets and natural language processing (NLP) tasks to address the lack of reliable, generalized evidence for these methods. It examines the effectiveness of these techniques in augmenting training sets to improve performance in tasks such as topic classification, sentiment analysis, and offensive language detection. The research emphasizes not only the augmentation methods, but also the strategic order in which real and augmented instances are introduced during training. A major contribution is the development and evaluation of Modified Cyclical Curriculum Learning (MCCL) for augmented datasets, which represents a novel approach in the field. Results show that specific augmentation methods, especially when integrated with MCCL, significantly outperform traditional training approaches in NLP model performance. These results underscore the need for careful selection of augmentation techniques and sequencing strategies to optimize the balance between speed and quality improvement in various NLP tasks. The study concludes that the use of augmentation methods, especially in conjunction with MCCL, leads to improved results in various classification tasks, providing a foundation for future advances in text augmentation strategies in NLP.</p></div></div><ul><li></li><li></li></ul><div><h2>Keywords</h2><p><span>Text augmentation</span></p><p><span>Data augmentation</span></p><p><span>Curriculum learning</span></p><p><span>Text classification</span></p><p><span>Sample ordering</span></p></div><section><header><h2>Cited by (0)</h2></header></section><div><dl><dt><a href=\\\"#baep-article-footnote-id1\\\"><span><span><sup>‚òÜ</sup></span></span></a></dt><dd><p>This study was supported by the <span>Scientific and Technological Research Council of Turkey</span>\\n(TUBITAK) Grant No: <a href=\\\"#GS1\\\"><span><span>120E100</span></span></a>.</p></dd></dl></div><p><span>¬© 2024 The Author(s). Published by Elsevier B.V.</span></p></article></div></div></div></div>\\n\\n--- Result 4 ---\\nTitle: A Complete Guide to Data Augmentation\\nURL: https://www.datacamp.com/tutorial/complete-guide-data-augmentation\\n\\nContent:\\nA Complete Guide to Data Augmentation | DataCamp\\n[Skip to main content](#main)\\n# A Complete Guide to Data Augmentation\\nLearn about data augmentation techniques, applications, and tools with a TensorFlow and Keras tutorial.\\nListContents\\nUpdated Dec 9, 2024¬∑ 15 min read\\nContents\\n## GroupTraining more people?\\nGet your team access to the full DataCamp for business platform.\\n## What is Data Augmentation?\\nData augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data. It includes making minor changes to the dataset or using deep learning to generate new data points.\\n### Augmented vs. synthetic data\\nData augmentation and synthetic data generation are distinct yet complementary techniques in machine learning:\\n* **Augmented data**: This involves creating modified versions of existing data to increase dataset diversity. For example, in image processing, applying transformations like rotations, flips, or color adjustments to existing images can help models generalize better.\\n* **Synthetic data**: Thisrefers to artificially generated data, which allows researchers and developers to test and improve algorithms without risking the privacy or security of real-world data.\\n**Note**: augmentation techniques are not limited to images. You can augment audio, video, text, and other types of data too.\\n### Why is data augmentation important?\\nData augmentation helps machine learning models perform better by making the most of existing data. It prevents overfitting, improves accuracy, and creates diversity in training data, which is crucial when datasets are small or imbalanced. By simulating real-world variations, it makes models more robust and reliable‚Äîwithout the need for expensive data collection. In short, it‚Äôs a simple, powerful way to help models learn and generalize effectively.\\n### When should you use data augmentation?\\n1. To prevent models from overfitting.\\n2. The initial training set is too small.\\n3. To improve the model accuracy.\\n4. To Reduce the operational cost of labeling and cleaning the raw dataset.### Limitations of data augmentation\\n* The biases in the original dataset persist in the augmented data.\\n* Quality assurance for data augmentation is expensive.\\n* Research and development are required to build a system with advanced applications. For example, generating high-resolution images using GANs can be challenging.\\n* Finding an effective data augmentation approach can be challenging.\\n## Become a ML Scientist\\nMaster Python skills to become a machine learning scientist\\n[Start Learning for Free](https://www.datacamp.com/tracks/machine-learning-scientist-with-python)\\n## Data Augmentation Techniques\\nIn this section, we will learn about audio, text, image, and advanced data augmentation techniques.\\n### Audio Data Augmentation\\n1. **Noise injection**: add gaussian or random noise to the audio dataset to improve the model performance.\\n2. **Shifting**: shift audio left (fast forward) or right with random seconds.\\n3. **Changing the speed**: stretches times series by a fixed rate.\\n4. **Changing the pitch**: randomly change the pitch of the audio.### Text Data Augmentation\\n1. **Word or sentence shuffling**: randomly changing the position of a word or sentence.\\n2. **Word replacement**: replace words with synonyms.\\n3. **Syntax-tree manipulation**: paraphrase the sentence using the same word.\\n4. **Random word insertion**: inserts words at random.\\n5. **Random word deletion**: deletes words at random.### Image Augmentation\\n***Learn more about image transformation and manipulation with hands-on exercises in our[Image Processing with Python skill track](https://www.datacamp.com/tracks/image-processing).***\\n1. **Geometric transformations**: randomly flip, crop, rotate, stretch, and zoom images. You need to be careful about applying multiple transformations on the same images, as this can reduce model performance.\\n2. **Color space transformations**: randomly change RGB color channels, contrast, and brightness.\\n3. **Kernel filters**: randomly change the sharpness or blurring of the image.\\n4. **Random erasing**: delete some part of the initial image.\\n5. **Mixing images**: blending and mixing multiple images.### Advanced Techniques\\n1. **Generative adversarial networks**(GANs): used to generate new data points or images. It does not require existing data to generate synthetic data.\\n2. **Neural Style Transfer**: a series of convolutional layers trained to deconstruct images and separate context and style.## Data Augmentation Applications\\nData augmentation can apply to all machine learning applications where acquiring quality data is challenging. Furthermore, it can help improve model robustness and performance across all fields of study.\\n### Healthcare\\nAcquiring and labeling medical imaging datasets is time-consuming and expensive. You also need a subject matter expert to validate the dataset before performing data analysis. Using geometric and other transformations can help you train robust and accurate machine-learning models.\\nFor example, in the case of Pneumonia Classification, you can use random cropping, zooming, stretching, and color space transformation to improve the model performance. However, you need to be careful about certain augmentations as they can result in opposite results. For example, random rotation and reflection along the x-axis are not recommended for the X-ray imaging dataset.\\n![kaggle-COVID19-Classification.png](https://images.datacamp.com/image/upload/v1669207732/kaggle_COVID_19_Classification_10703dbe61.png)\\nImage from[ibrahimsobh.github.io](https://ibrahimsobh.github.io/kaggle-COVID19-Classification/)| kaggle-COVID19-Classification\\n### Self-Driving Cars\\nThere is limited data available on self-driving cars, and companies are using simulated environments to generate synthetic data using reinforcement learning. It can help you train and test machine learning applications where data security is an issue.\\n![Autonomous Visualization System from Uber ATG.png](https://images.datacamp.com/image/upload/v1669207732/Autonomous_Visualization_System_from_Uber_ATG_9e79d6c630.png)\\nImage by[David Silver](https://medium.com/self-driving-cars/autonomous-visualization-system-from-uber-atg-50957e7101f0)| Autonomous Visualization System from Uber ATG\\nThe possibilities of augmented data as a simulation are endless, as it can be used to generate real-world scenarios.\\n### Natural Language Processing\\nText data augmentation is generally used in situations with limited quality data, and improving the performance metric takes priority. You can apply synonym augmentation, word embedding, character swap, and random insertion and deletion. These techniques are also valuable for low-resource languages.\\n![Selective Text Augmentation with Word Roles for Low-Resource Text Classification.png](https://images.datacamp.com/image/upload/v1669207732/Selective_Text_Augmentation_with_Word_Roles_for_Low_Resource_Text_Classification_c1302878c9.png)\\nImage from[Papers With Code](https://paperswithcode.com/paper/selective-text-augmentation-with-word-roles)| Selective Text Augmentation with Word Roles for Low-Resource Text Classification.\\nResearchers use text augmentation for the language models in high error recognition scenarios, sequence-to-sequence data generation, and text classification.\\n### Automatic Speech Recognition\\nIn sound classification and speech recognition, data augmentation works wonders. It improves the model performance even on low-resource languages.\\n![Noise Injection.png](https://images.datacamp.com/image/upload/v1669207728/Noise_Injection_b3af64a578.png)\\nImage by[Edward Ma](https://medium.com/@makcedward/data-augmentation-for-audio-76912b01fdf6)| Noise Injection\\nThe random noise injection, shifting, and changing the pitch can help you produce state-of-the-art speech-to-text models. You can also use GANs to generate realistic sounds for a particular application.\\n## Ethical Implications of Data Augmentatio...\\n\\n--- Result 5 ---\\nTitle: Effective Data Augmentation for Sentence Classification ...\\nURL: https://aclanthology.org/2022.coling-1.305\\n\\nContent:\\n## [Effective Data Augmentation for Sentence Classification Using One VAE per Class](https://aclanthology.org/2022.coling-1.305.pdf)\\n[Fr√©d√©ric Piedboeuf](https://aclanthology.org/people/f/frederic-piedboeuf/),\\n[Philippe Langlais](https://aclanthology.org/people/p/philippe-langlais/)\\n* * *\\n##### Abstract\\nIn recent years, data augmentation has become an important field of machine learning. While images can use simple techniques such as cropping or rotating, textual data augmentation needs more complex manipulations to ensure that the generated examples are useful. Variational auto-encoders (VAE) and its conditional variant the Conditional-VAE (CVAE) are often used to generate new textual data, both relying on a good enough training of the generator so that it doesn‚Äôt create examples of the wrong class. In this paper, we explore a simpler way to use VAE for data augmentation: the training of one VAE per class. We show on several dataset sizes, as well as on four different binary classification tasks, that it systematically outperforms other generative data augmentation techniques.\\nAnthology ID:2022.coling-1.305Volume:[Proceedings of the 29th International Conference on Computational Linguistics](https://aclanthology.org/volumes/2022.coling-1/)Month:OctoberYear:2022Address:Gyeongju, Republic of KoreaEditors:[Nicoletta Calzolari](https://aclanthology.org/people/n/nicoletta-calzolari/),\\n[Chu-Ren Huang](https://aclanthology.org/people/c/chu-ren-huang/),\\n[Hansaem Kim](https://aclanthology.org/people/h/hansaem-kim/),\\n[James Pustejovsky](https://aclanthology.org/people/j/james-pustejovsky/),\\n[Leo Wanner](https://aclanthology.org/people/l/leo-wanner/),\\n[Key-Sun Choi](https://aclanthology.org/people/k/key-sun-choi/),\\n[Pum-Mo Ryu](https://aclanthology.org/people/p/pum-mo-ryu/),\\n[Hsin-Hsi Chen](https://aclanthology.org/people/h/hsin-hsi-chen/),\\n[Lucia Donatelli](https://aclanthology.org/people/l/lucia-donatelli/),\\n[Heng Ji](https://aclanthology.org/people/h/heng-ji/),\\n[Sadao Kurohashi](https://aclanthology.org/people/s/sadao-kurohashi/),\\n[Patrizia Paggio](https://aclanthology.org/people/p/patrizia-paggio/),\\n[Nianwen Xue](https://aclanthology.org/people/n/nianwen-xue/),\\n[Seokhwan Kim](https://aclanthology.org/people/s/seokhwan-kim/),\\n[Younggyun Hahm](https://aclanthology.org/people/y/younggyun-hahm/),\\n[Zhong He](https://aclanthology.org/people/z/zhong-he/),\\n[Tony Kyungil Lee](https://aclanthology.org/people/t/tony-kyungil-lee/),\\n[Enrico Santus](https://aclanthology.org/people/e/enrico-santus/),\\n[Francis Bond](https://aclanthology.org/people/f/francis-bond/),\\n[Seung-Hoon Na](https://aclanthology.org/people/s/seung-hoon-na/)Venue:[COLING](https://aclanthology.org/venues/coling/)SIG:Publisher:International Committee on Computational LinguisticsNote:Pages:3454‚Äì3464Language:URL:[https://aclanthology.org/2022.coling-1.305/](https://aclanthology.org/2022.coling-1.305/)DOI:Bibkey:piedboeuf-langlais-2022-effectiveCite (ACL):Fr√©d√©ric Piedboeuf and Philippe Langlais. 2022. [Effective Data Augmentation for Sentence Classification Using One VAE per Class](https://aclanthology.org/2022.coling-1.305/). In _Proceedings of the 29th International Conference on Computational Linguistics_, pages 3454‚Äì3464, Gyeongju, Republic of Korea. International Committee on Computational Linguistics.Cite (Informal):[Effective Data Augmentation for Sentence Classification Using One VAE per Class](https://aclanthology.org/2022.coling-1.305/) (Piedboeuf & Langlais, COLING 2022)Copy Citation:BibTeXMarkdownMODS XMLEndnoteMore options‚Ä¶PDF:[https://aclanthology.org/2022.coling-1.305.pdf](https://aclanthology.org/2022.coling-1.305.pdf)Data[SST](https://paperswithcode.com/dataset/sst),¬†[SST-2](https://paperswithcode.com/dataset/sst-2)\\n[PDF](https://aclanthology.org/2022.coling-1.305.pdf) [Cite](https://aclanthology.org/2022.coling-1.305/) [Search](https://www.semanticscholar.org/search?q=Effective+Data+Augmentation+for+Sentence+Classification+Using+One+VAE+per+Class) [Fix data](https://aclanthology.org/2022.coling-1.305/)\\n* * *\\n\\n--- Result 6 ---\\nTitle: EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks\\nURL: https://arxiv.org/abs/1901.11196\\n\\nContent:\\n# Computer Science > Computation and Language\\n\\n**arXiv:1901.11196** (cs)\\n\\n\\\\[Submitted on 31 Jan 2019 ( [v1](https://arxiv.org/abs/1901.11196v1)), last revised 25 Aug 2019 (this version, v2)\\\\]\\n\\n# Title:EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks\\n\\nAuthors: [Jason Wei](https://arxiv.org/search/cs?searchtype=author&query=Wei,+J), [Kai Zou](https://arxiv.org/search/cs?searchtype=author&query=Zou,+K)\\n\\nView a PDF of the paper titled EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks, by Jason Wei and Kai Zou\\n\\n[View PDF](https://arxiv.org/pdf/1901.11196)\\n\\n> Abstract:We present EDA: easy data augmentation techniques for boosting performance on text classification tasks. EDA consists of four simple but powerful operations: synonym replacement, random insertion, random swap, and random deletion. On five text classification tasks, we show that EDA improves performance for both convolutional and recurrent neural networks. EDA demonstrates particularly strong results for smaller datasets; on average, across five datasets, training with EDA while using only 50% of the available training set achieved the same accuracy as normal training with all available data. We also performed extensive ablation studies and suggest parameters for practical use.\\n\\n|     |     |\\n| --- | --- |\\n| Comments: | EMNLP-IJCNLP 2019 short paper |\\n| Subjects: | Computation and Language (cs.CL) |\\n| Cite as: | [arXiv:1901.11196](https://arxiv.org/abs/1901.11196) \\\\[cs.CL\\\\] |\\n| (or [arXiv:1901.11196v2](https://arxiv.org/abs/1901.11196v2) \\\\[cs.CL\\\\] for this version) |\\n| [https://doi.org/10.48550/arXiv.1901.11196](https://doi.org/10.48550/arXiv.1901.11196) <br>Focus to learn more<br>arXiv-issued DOI via DataCite |\\n\\n## Submission history\\n\\nFrom: Jason Wei \\\\[ [view email](https://arxiv.org/show-email/7ee5aa67/1901.11196)\\\\] **[\\\\[v1\\\\]](https://arxiv.org/abs/1901.11196v1)**\\nThu, 31 Jan 2019 03:20:52 UTC (294 KB)\\n**\\\\[v2\\\\]**\\nSun, 25 Aug 2019 23:11:07 UTC (63 KB)\\n\\nFull-text links:\\n\\n## Access Paper:\\n\\nView a PDF of the paper titled EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks, by Jason Wei and Kai Zou\\n\\n- [View PDF](https://arxiv.org/pdf/1901.11196)\\n- [TeX Source](https://arxiv.org/src/1901.11196)\\n\\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\\n\\nCurrent browse context:\\n\\ncs.CL\\n\\n[<¬†prev](https://arxiv.org/prevnext?id=1901.11196&function=prev&context=cs.CL)¬† \\\\| ¬†[next¬†>](https://arxiv.org/prevnext?id=1901.11196&function=next&context=cs.CL)\\n\\n[new](https://arxiv.org/list/cs.CL/new) \\\\| [recent](https://arxiv.org/list/cs.CL/recent) \\\\| [2019-01](https://arxiv.org/list/cs.CL/2019-01)\\n\\nChange to browse by:\\n\\n[cs](https://arxiv.org/abs/1901.11196?context=cs)\\n\\n### References & Citations\\n\\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1901.11196)\\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1901.11196)\\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:1901.11196)\\n\\n### [DBLP](https://dblp.uni-trier.de) \\\\- CS Bibliography\\n\\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1901.html#abs-1901-11196) \\\\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1901-11196)\\n\\n[Jason W. Wei](https://dblp.uni-trier.de/search/author?author=Jason%20W.%20Wei) [Kai Zou](https://dblp.uni-trier.de/search/author?author=Kai%20Zou)\\n\\nexport BibTeX citationLoading...\\n\\n## BibTeX formatted citation\\n\\n√ó\\n\\nData provided by:\\n\\n### Bookmark\\n\\nBibliographic Tools\\n\\n# Bibliographic and Citation Tools\\n\\nBibliographic Explorer Toggle\\n\\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\\n\\nConnected Papers Toggle\\n\\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\\n\\nLitmaps Toggle\\n\\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\\n\\nscite.ai Toggle\\n\\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\\n\\nCode, Data, Media\\n\\n# Code, Data and Media Associated with this Article\\n\\nalphaXiv Toggle\\n\\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\\n\\nLinks to Code Toggle\\n\\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\\n\\nDagsHub Toggle\\n\\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\\n\\nGotitPub Toggle\\n\\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\\n\\nHuggingface Toggle\\n\\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\\n\\nLinks to Code Toggle\\n\\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\\n\\nScienceCast Toggle\\n\\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\\n\\nDemos\\n\\n# Demos\\n\\nReplicate Toggle\\n\\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\\n\\nSpaces Toggle\\n\\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\\n\\nSpaces Toggle\\n\\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\\n\\nRelated Papers\\n\\n# Recommenders and Search Tools\\n\\nLink to Influence Flower\\n\\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\\n\\nCore recommender toggle\\n\\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\\n\\n- Author\\n- Venue\\n- Institution\\n- Topic\\n\\nAbout arXivLabs\\n\\n# arXivLabs: experimental projects with community collaborators\\n\\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\\n\\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\\n\\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\\n\\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1901.11196) \\\\|\\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))\\n\\n--- Result 7 ---\\nTitle: Text Classification: All Tips and Tricks from 5 Kaggle Competitions\\nURL: https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions\\n\\nContent:\\nIn this article, I will discuss some great tips and tricks to [improve the performance](https://neptune.ai/blog/improving-machine-learning-deep-learning-models) of your text classification model. These tricks are obtained from solutions of some of Kaggle‚Äôs top NLP competitions.\\n\\nNamely, I‚Äôve gone through:\\n\\n- [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification) ‚Äì $65,000\\n- [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/) ‚Äì $35,000\\n- [Quora Insincere Questions Classification](http://kaggle.com/c/quora-insincere-questions-classification) ‚Äì $25,000\\n- [Google QUEST Q&A Labeling](https://www.kaggle.com/c/google-quest-challenge) ‚Äì $25,000\\n- [TensorFlow 2.0 Question Answering](https://www.kaggle.com/c/tensorflow2-question-answering) ‚Äì $50,000\\n\\nand found a ton of great ideas.\\n\\nWithout much lag, let‚Äôs begin.\\n\\n## Dealing with larger datasets\\n\\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for Kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\\n\\n- Optimize the memory by [reducing the size of some attributes](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\\n- Use open-source libraries such as [Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space\\n- Use [cudf](https://github.com/rapidsai/cudf)\\n- Convert data to [parquet](https://arrow.apache.org/docs/python/parquet.html) format\\n- Convert data to [feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03) format\\n\\n## Small datasets and external data\\n\\nBut, what can one do if the dataset is small? Let‚Äôs see some techniques to tackle this situation.\\n\\nOne way to increase the performance of any machine learning model is to use some external data frame that contains some variables that influence the predicate variable.\\n\\nLet‚Äôs see some of the external datasets.\\n\\n- Use of [squad](https://rajpurkar.github.io/SQuAD-explorer/) data for Question Answering tasks\\n- Other [datasets](http://nlpprogress.com/english/question_answering.html) for QA tasks\\n- Wikitext long term dependency language modeling [dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\\n- [Stackexchange data](https://archive.org/download/stackexchange)\\n- Prepare a dictionary of commonly misspelled words and corrected words.\\n- Use of [helper datasets](https://www.kaggle.com/kyakovlev/jigsaw-general-helper-public) for cleaning\\n- [Pseudo labeling](https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969/) is the process of adding confidently predicted test data to your training data\\n- Use different data [sampling methods](https://www.kaggle.com/shahules/tackling-class-imbalance)\\n- Text augmentation by [Exchanging words with synonym](https://arxiv.org/pdf/1502.01710.pdf) [s](https://arxiv.org/pdf/1502.01710.pdf)\\n- Text augmentation by [noising in RNN](https://arxiv.org/pdf/1703.02573.pdf)\\n- Text augmentation by [translation to other languages and back](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/48038)\\n\\n## Data exploration and gaining insights\\n\\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\\n\\n- Twitter data [exploration methods](https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda)\\n- Simple [EDA for tweets](https://www.kaggle.com/nz0722/simple-eda-text-preprocessing-jigsaw)\\n- [EDA](https://www.kaggle.com/tunguz/just-some-simple-eda) for Quora data\\n- [EDA](https://www.kaggle.com/kailex/r-eda-for-q-gru) in ¬†R for Quora data\\n- Complete [EDA](https://www.kaggle.com/codename007/start-from-here-quest-complete-eda-fe) with stack exchange data\\n- My previous article on [EDA for natural language processing](https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools)\\n\\n## Data cleaning\\n\\nData cleaning is one of the important and integral parts of any NLP problem. Text data always needs some preprocessing and cleaning before we can represent it in a suitable form.\\n\\n- Use this [notebook](https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing) to clean social media data\\n- [Data cleaning](https://www.kaggle.com/kyakovlev/preprocessing-bert-public) for BERT\\n- Use [textblob](https://textblob.readthedocs.io/en/dev/quickstart.html) to correct misspellings\\n- [Cleaning](https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing) for pre-trained embeddings\\n- [Language detection and translation](https://www.pythonprogramming.in/language-detection-and-translation-using-textblob.html) for multilingual tasks\\n- Preprocessing for Glove [part 1](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part1-eda) and [part 2](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part2-usage)\\n- [Increasing word coverage](https://www.kaggle.com/sunnymarkliu/more-text-cleaning-to-increase-word-coverage) to get more from pre-trained word embeddings\\n\\n## Text representations\\n\\nBefore we feed our text data to the Neural network or ML model, the text input needs to be represented in a suitable format. These representations determine the performance of the model to a large extent.\\n\\n- Pretrained [Glove](https://nlp.stanford.edu/projects/glove/) vectors\\n- Pretrained [fasttext](https://fasttext.cc/docs/en/english-vectors.html) vectors\\n- Pretrained [word2vec](https://radimrehurek.com/gensim/models/word2vec.html) vectors\\n- My previous article on these [3 embeddings](https://neptune.ai/blog/document-classification-small-datasets)\\n- Combining [pre-trained vectors](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778/). This can help in better representation of text and decreasing OOV words\\n- [Paragram](https://cogcomp.seas.upenn.edu/page/resource_view/106) embeddings\\n- [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/1)\\n- Use USE to generate [sentence-level features](https://www.kaggle.com/abhishek/distilbert-use-features-oof)\\n- 3 methods to [combine embeddings](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778)\\n\\nContextual embeddings models\\n\\n- [BERT](https://github.com/google-research/bert) Bidirectional Encoder Representations from Transformers\\n- [GPT](https://github.com/openai/finetune-transformer-lm)\\n- [Roberta](https://github.com/pytorch/fairseq/tree/master/examples/roberta) a Robustly Optimized BERT\\n- [Albert](https://github.com/google-research/ALBERT) a Lite BERT for Self-supervised Learning of Language Representations\\n- [Distilbert](https://github.com/huggingface/transformers/tree/master/examples/distillation) a lighter version of BERT\\n- [XLNET](https://github.com/zihangdai/xlnet/)\\n\\n## Modeling\\n\\n### Model architecture\\n\\nChoosing the right architecture is important to develop a proper machine learning model, sequence to sequence models like LSTMs, GRUs perform well in NLP problems and is always worth trying. Stacking 2 layers of LSTM/GRU networks is a common approach.\\n\\n- [Stacking Bidirectional CuDNNLSTM](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644/)\\n- [Stacking LSTM networks](https://www.kaggle.com/sakami/google-quest-single-lstm/)\\n- [LSTM and 5 fold Attention](https://www.kaggle.com/christofhenkel/keras-baseline-lstm-attention-5-fold/)\\n- [Bi...\\n\\n--- Result 8 ---\\nTitle: Text augmentation techniques in NLP\\nURL: https://www.geeksforgeeks.org/nlp/text-augmentation-techniques-in-nlp\\n\\nContent:\\n- [NLP Tutorial](https://www.geeksforgeeks.org/nlp/natural-language-processing-nlp-tutorial/)\\n- [Libraries](https://www.geeksforgeeks.org/nlp/nlp-libraries-in-python/)\\n- [Phases](https://www.geeksforgeeks.org/machine-learning/phases-of-natural-language-processing-nlp/)\\n- [Text Preprosessing](https://www.geeksforgeeks.org/nlp/text-preprocessing-for-nlp-tasks/)\\n- [Tokenization](https://www.geeksforgeeks.org/nlp/nlp-how-tokenizing-text-sentence-words-works/)\\n- [Lemmatization](https://www.geeksforgeeks.org/python/python-lemmatization-with-nltk/)\\n- [Word Embeddings](https://www.geeksforgeeks.org/nlp/word-embeddings-in-nlp/)\\n- [Projects Ideas](https://www.geeksforgeeks.org/nlp/top-natural-language-processing-nlp-projects/)\\n- [Interview Question](https://www.geeksforgeeks.org/nlp/advanced-natural-language-processing-interview-question/)\\n- [NLP Quiz](https://www.geeksforgeeks.org/quizzes/natural-language-processing-quiz/)\\n- [NLP Pipeline](https://www.geeksforgeeks.org/nlp/natural-language-processing-nlp-pipeline/)\\n- [DL for NLP](https://www.geeksforgeeks.org/nlp/nlp-with-deep-learning/)\\n- [NLP Datasets](https://www.geeksforgeeks.org/nlp/best-nlp-datasets/)\\n- [Machine Learning](https://www.geeksforgeeks.org/machine-learning/machine-learning/)\\n\\nSign In\\n\\n‚ñ≤\\n\\n[Open In App](https://geeksforgeeksapp.page.link/?link=https://www.geeksforgeeks.org/text-augmentation-techniques-in-nlp/?type%3Darticle%26id%3D997649&apn=free.programming.programming&isi=1641848816&ibi=org.geeksforgeeks.GeeksforGeeksDev&efr=1)\\n\\n# Text augmentation techniques in NLP\\n\\nLast Updated : 23 Jul, 2025\\n\\nComments\\n\\nImprove\\n\\nSuggest changes\\n\\n7 Likes\\n\\nLike\\n\\nReport\\n\\n**Text augmentation** is an important aspect of **NLP** to generate an artificial corpus. This helps in improving the NLP-based models to generalize better over a lot of different sub-tasks like intent classification, machine translation, chatbot training, image summarization, etc.\\n\\nText augmentation is used when:\\n\\n- There is an absence of sufficient variation in the text corpus.\\n- There is a high data imbalance during intent classification tasks.\\n- The overall quantity of data is insufficient for data-hungry machine-learning models.\\n\\nTable of Content\\n\\n- [Data Augmentation in NLP](https://www.geeksforgeeks.org/www.geeksforgeeks.org#data-augmentation-in-nlp)\\n- [Easy data Augmentation](https://www.geeksforgeeks.org/www.geeksforgeeks.org#easy-data-augmentation)\\n- [Generative Models](https://www.geeksforgeeks.org/www.geeksforgeeks.org#generative-models)\\n\\n## Data Augmentation in NLP\\n\\n[Data Augmentation](https://www.geeksforgeeks.org/machine-learning/python-data-augmentation/) (DA) is a technique employed to artificially expand training datasets by creating various versions of existing data without the need for additional data collection. Its primary goal is to enhance classification task performance by altering the data while preserving class categories.\\n\\nIn fields like [Computer Vision](https://www.geeksforgeeks.org/computer-vision/computer-vision/) and [Natural Language Processing](https://www.geeksforgeeks.org/nlp/natural-language-processing-overview/) (NLP), where data scarcity and limited diversity pose challenges, data augmentation strategies play a crucial role. While generating augmented images is relatively straightforward, NLP faces complexities due to the nuanced nature of language. Unlike images, we can't replace every word with a synonym, and even if substitution is possible, maintaining context becomes a significant challenge.\\n\\nThe pivotal role of data augmentation lies in its ability to boost model performance by increasing the volume of training data. More data generally leads to improved model performance. However, it is crucial to strike a balance in the distribution of augmented data. The generated data should neither closely resemble the original data nor deviate too much from it, as either extreme may result in overfitting or poor model performance. Therefore, effective data augmentation approaches should aim for a harmonious balance in data distribution.\\n\\nThe following three stages are where data augmentation techniques are used:\\n\\n- **Word Level:** At the word level, augmentation involves the transformation or replacement of individual words within the text. This could include synonyms, word shuffling, or other word-level modifications aimed at introducing variability without compromising the overall meaning or context of the text.\\n- **Sentence Level:** [Augmentation](https://www.geeksforgeeks.org/machine-learning/text-to-text-transfer-transformer-in-data-augmentation/) at the sentence level focuses on altering the structure and composition of entire sentences. Techniques such as paraphrasing, sentence shuffling, or introducing grammatical variations are employed. The goal is to diversify the dataset by presenting the model with different formulations of ideas while maintaining the essence of the original content.\\n- **Document Level:** At the document level, augmentation extends to the entire document or piece of text. This may involve introducing substantial changes, such as inserting or removing paragraphs, reordering sections, or even changing the overall writing style. Document-level augmentation aims to provide the model with exposure to varied document structures and writing conventions.\\n\\n## Easy data Augmentation\\n\\n### Synonym Replacement\\n\\nSynonym replacement is a technique to replace a set of [token](https://www.geeksforgeeks.org/ethical-hacking/how-does-the-token-based-authentication-work/)(s) from a text/document with another set of token(s) with equal or equivalent meaning without changing the overall meaning or context of the original phrase. The sentence generated post-replacement is called a synthetic phrase.\\n\\nThe synonym replacement can occur at any or all three of a document, i.e. at the character level, word/token level, or sentence level.\\n\\n#### **Word-embedding based**\\n\\n[Word embeddings](https://www.geeksforgeeks.org/nlp/word-embeddings-in-nlp/) that have been trained, such [GloVe](https://www.geeksforgeeks.org/nlp/pre-trained-word-embedding-using-glove-in-nlp-models/), [Word2Vec](https://www.geeksforgeeks.org/python/python-word-embedding-using-word2vec/), and fastText, can find the word vector that is closest to the original text in the embedding space.\\n\\nBecause contextual bidirectional embeddings such as ELMo and [BERT](https://www.geeksforgeeks.org/nlp/explanation-of-bert-model-nlp/) have substantially richer vector representations, they are recommended for improved reliability. Bidirectional [LSTM](https://www.geeksforgeeks.org/deep-learning/deep-learning-introduction-to-long-short-term-memory/) and Transformer models are more successful since they can encode longer text sequences and show contextual knowledge of the words around them.\\n\\n#### **Lexical-based**\\n\\nToken(s) with close or exact meaning is replaced directly in the string to achieve lexical-based augmented text. [Wordnet](https://www.geeksforgeeks.org/nlp/nlp-wordnet-for-tagging/) is used to tag and find the respective synonyms, hyponyms, and meronyms for the token(s) in the text.\\n\\n- **Random Insertion**\\n\\nRandomly inserting redundant or semantically similar words/tokens that do not include [stopwords](https://www.geeksforgeeks.org/nlp/removing-stop-words-nltk-python/) increase the meaning of a sentence/embedding or keep it semantically unchanged resulting in the creation of augmented text. This step should be done carefully as the introduction of negative words in a sentence can change its sentiment completely.\\n\\n```\\noriginal text: This is a geekforgeeks example.post-random insertion text: This is a new geekforgeeks example.\\n```\\n\\n- **Random Swap**\\n\\nRandomly replacing similar words/tokens that keep the semantic meaning of the sentence/embedding unchanged results in the creation of augmented text.\\n\\n```\\noriginal text: This is a geekforgeeks example.post-random swapped text: This is a geekforgeeks illustration.\\n```\\n\\n- **Random deletion**\\n\\nRandom del...\\n\\n--- Result 9 ---\\nTitle: Text Data Augmentation for Large Language Models\\nURL: https://arxiv.org/html/2501.18845v1\\n\\nContent:\\narXiv reCAPTCHA\\n[![Cornell University](https://static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\\n[We gratefully acknowledge support from\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)\\n# [![arxiv logo](https://static.arxiv.org/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)\\n\", \"is_error\": false, \"results\": [{\"title\": \"ANSWER\", \"text\": \"Text data augmentation is a cornerstone of winning Kaggle text‚Äëclassification solutions because it expands limited training sets, reduces over‚Äëfitting, and mimics the linguistic variability seen in real‚Äëworld data.  The most consistently effective tricks, as reported by a Kaggle master and validated in recent research, are the **Easy Data Augmentation (EDA)** operations ‚Äì synonym replacement, random insertion, random swap, and random deletion ‚Äì which are simple to implement yet give large gains, especially on small‚Äëto‚Äëmedium datasets ([Neptune‚ÄØAI](https://neptune.ai/blog/data-augmentation-nlp),‚ÄØ2023;‚ÄØ[Wei & Zou‚ÄØ2019](https://arxiv.org/abs/1901.11196)).  Building on EDA, practitioners add **back‚Äëtranslation** (translate to another language and back) and **contextual word replacement** using pretrained language models (e.g., BERT, RoBERTa) to generate fluent paraphrases that preserve label semantics.  Word‚Äëembedding‚Äëbased synonym swaps and character‚Äëlevel noise (swap or delete characters) further diversify the corpus without breaking meaning ([DataCamp‚ÄØ2024](https://www.datacamp.com/tutorial/complete-guide-data-augmentation)).  \\n\\nBeyond these ‚Äúlightweight‚Äù methods, recent Kaggle‚Äëlevel experiments show that **strategic curriculum learning**‚Äîintroducing real examples first and then gradually mixing augmented ones‚Äîcan amplify the benefit of any augmentation technique.  The Modified Cyclical Curriculum Learning (MCCL) framework, evaluated across topic classification, sentiment analysis, and offensive‚Äëlanguage detection, consistently outperformed plain training ([ScienceDirect‚ÄØ2024](https://www.sciencedirect.com/science/article/pii/S2949719124000190)).  For larger label‚Äërich tasks, **class‚Äëconditional generative models** such as a VAE trained per class have been demonstrated to surpass other generative augmentations, delivering higher accuracy on binary classification benchmarks ([Piedboeuf‚ÄØ2022](https://aclanthology.org/2022.coling-1.305)).  \\n\\nIn practice, Kaggle winners combine these approaches: start with EDA‚Äëstyle word‚Äëlevel edits, enrich with back‚Äëtranslation or BERT‚Äëbased paraphrasing, apply a modest amount of character noise, and finally schedule the augmented data using a curriculum (or mixup) strategy.  This pipeline balances diversity and label fidelity, leading to the strongest performance gains reported across recent Kaggle text‚Äëclassification competitions ([Neptune‚ÄØ2022](https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions)).\", \"url\": \"\"}, {\"title\": \"Data Augmentation in NLP: Best Practices From a Kaggle ...\", \"text\": \"Data Augmentation in NLP: Best Practices From a Kaggle Master[\\n**üì£ BIG NEWS:****Neptune is joining OpenAI!**‚Üí Read the message from our CEO üì£![](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)](https://neptune.ai/blog/we-are-joining-openai)\\n[![logo](https://neptune.ai/wp-content/themes/neptune/img/logo-neptune.svg)](https://neptune.ai)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)\\nWhat do you want to find?\\nSearch\\n![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Log in](https://app.neptune.ai/login)[Contact us](https://neptune.ai/contact-us)\\n[![Home](https://neptune.ai/wp-content/themes/neptune/img/icon-breadcrumbs-home.svg)](https://neptune.ai/)&gt;[Blog](https://neptune.ai/blog)&gt;[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n![search](https://neptune.ai/wp-content/themes/neptune/img/icon-search.svg)![cancel](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\nSearch in Blog...\\n![search](https://neptune.ai/wp-content/themes/neptune/img/image-ratio-holder.svg)\\n[Neptune Blog](https://neptune.ai/blog)# Data Augmentation in NLP: Best Practices From a Kaggle Master\\n![Author image](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/Shahul-Es-new-scaled.jpeg?fit=2560%2C1920&ssl=1)\\n[Shahul ES](https://neptune.ai/blog/author/shahules)\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-time.svg)5 min\\n![](https://neptune.ai/wp-content/themes/neptune/img/icon-meta-date.svg)1st September, 2023\\n[ML Model Development](https://neptune.ai/blog/category/machine-learning-model-development)[Natural Language Processing](https://neptune.ai/blog/category/natural-language-processing)\\nThere are many tasks in NLP from text classification to question answering but whatever you do the amount of data you have to train your model impacts the model performance heavily.\\nWhat can you do to make your dataset larger?\\nSimple option -&gt; Get more data :).\\nBut acquiring and labeling additional observations can be an expensive and time-consuming process.\\nWhat you can do instead?\\nApply data augmentation to your text data.\\nData augmentation techniques are used to**generate additional, synthetic data using the data you have.**Augmentation methods are super popular in computer vision applications but they are just as powerful for NLP.\\nIn this article, we‚Äôll go through all the major data augmentation methods for NLP that you can use to increase the size of your textual dataset and improve your model performance.\\n## Data augmentation for vision vs NLP\\nIn computer vision applications data augmentations are done almost everywhere to get larger training data and make the model generalize better.\\nThe main methods used involve:\\n* cropping,\\n* flipping,\\n* zooming,\\n* rotation,\\n* noise injection,\\n* and many others.\\nIn**computer vision**, these transformations are**done on the go**using data generators. As a batch of data is fed to your neural network it is randomly transformed (augmented). You don‚Äôt need to prepare anything before training.\\nThis isn‚Äôt the case with**NLP**, where data augmentation should be done carefully due to the grammatical structure of the text. The methods discussed here are used**before training.**A new augmented dataset is generated beforehand and later fed into data loaders to train the model.\\n![](https://lh4.googleusercontent.com/nyCEre_Ywft5YHXeKTEmMR-kmSkySsTIH6x_U1jBbJ9CF_2Erbnz9oueyXFIH4PMHBxl1elzRSFIszU9xKJ7aveJ1sL489I3p_DXc5QWIOFP2W8wWWvBQ7x-QzRCT23R5XDi5Gm3)\\n## Data augmentation methods\\nIn this article, I will mainly focus on NLP data augmentation methods provided in the following projects:\\n* Back translation.\\n* [EDA (Easy Data Augmentation)](https://arxiv.org/abs/1901.11196).\\n* [NLP Albumentation.](https://github.com/albumentations-team/albumentations)\\n* [NLP Aug.](https://github.com/makcedward/nlpaug)\\nSo, let‚Äôs dive into each of them.\\n### **Back translation**\\nIn this method, we**translate the text data to some language and then translate it back to the original**language. This can help to generate textual data with different words while preserving the context of the text data.\\nLanguage translations APIs like google translate, Bing, Yandex are used to perform the translation. For example, given the sentence:\\n![](https://lh6.googleusercontent.com/x3ZAhTDLT1QVSD8gCdaBVMquM2dcYA15A-orfzXyTzhTP8m0ZKLXz_2NrJdWlTgWKRS7BimExM8RO9Ce_uVVVdRR29vGeP0VZdncDZY0GTwkctocQyYg7HK9VL5ay3QC4JhbSXBK)*Amit Chaudhary[&#8220;Back Translation for Text Augmentation with Google Sheets&#8221;](https://amitness.com/2020/02/back-translation-in-google-sheets/)*\\nYou can see that the sentences are not the same but their content remains the same after the back-translation. If you want to try this method for a dataset you can use this[notebook](https://www.kaggle.com/miklgr500/how-to-use-translators-for-comments-translation)as reference.\\n### **Easy Data Augmentation**\\nEasy data augmentation uses traditional and very simple data augmentation methods. EDA consists of**four simple operations that do a surprisingly good job**of preventing overfitting and helping train more robust models.\\n* **Synonym Replacement**\\nRandomly choose*n*words from the sentence that are not stop words. Replace each of these words with one of its synonyms chosen at random.\\nFor example, given the sentence:\\n*This**article**will focus on summarizing data augmentation**techniques**in NLP.*\\nThe method randomly selects n words (say two), the words*article*and*techniques*, and replaces them with*write-up*and*methods*respectively.\\n*This**write-up**will focus on summarizing data augmentation**methods**in NLP.*\\n* **Random Insertion**\\nFind a random synonym of a random word in the sentence that is not a stop word. Insert that synonym into a random position in the sentence. Do this*n*times.\\nFor example, given the sentence:\\n*This**article**will focus on summarizing data augmentation**techniques**in NLP.*\\nThe method randomly selects n words (say two), the words*article*and*techniques*find the synonyms as*write-up*and*methods*respectively. Then these synonyms are inserted at a random position in the sentence.\\n*This article will focus on**write-up**summarizing data augmentation techniques in NLP**methods**.*\\n* **Random Swap**\\nRandomly choose two words in the sentence and swap their positions. Do this*n*times.\\nFor example, given the sentence\\n*This**article**will focus on summarizing data augmentation**techniques**in NLP.*\\nThe method randomly selects n words (say two), the words*article*and*techniques*and swaps them to create a new sentence.\\n*This**techniques**will focus on summarizing data augmentation**article**in NLP.*\\n* **Random Deletion**\\nRandomly remove each word in the sentence with probability*p*.\\nFor example, given the sentence\\n*This**article**will focus on summarizing data augmentation**techniques**in NLP.*\\nThe method selects n words (say two), the words*will*and*techniques*, and removes them from the sentence.\\n*This****article**focus on summarizing data augmentation in NLP.*\\nYou can go to this[repository](https://github.com/jasonwei20/eda_nlp)if you want to apply these techniques to your projects.\\n### **NLP Albumentation**\\nPreviously, we talked about differences between computer vision data augmentation and NLP data augmentation. But in this section, we will see how we can apply some of the ideas used in CV data augmentation in NLP.\\nFor that, we will use the[Albumentations](https://github.com/albumentations-team/albumentations)package.\\nLet‚Äôs take a look at a couple of the techniques here.\\n* **Shuffle Sentences Transform**\\nIn this transformation, if the given text sample contains multiple sentences these sentences are shuffled to create a new sample.\\nFor example:\\n**text = &#8216;&lt;Sentence1&gt;. &lt;Sentence2&gt;. &lt;Sentence4&gt;. &lt;Sentence4&gt;. &lt;Sentence...\", \"url\": \"https://neptune.ai/blog/data-augmentation-nlp\"}, {\"title\": \"Advancing NLP models with strategic text augmentation\", \"text\": \"<div><div><header></header><div><div><ul><li><a><span><span><span>View¬†<strong>PDF</strong></span></span></span></a></li><li></li></ul></div><div><article><div><p><a href=\\\"https://www.sciencedirect.com/journal/natural-language-processing-journal\\\"><span><span></span></span></a></p><p><a href=\\\"https://www.sciencedirect.com/journal/natural-language-processing-journal/vol/7/suppl/C\\\"><span><span></span></span></a></p></div><div><p><span>Under a Creative Commons </span><a href=\\\"http://creativecommons.org/licenses/by/4.0/\\\"><span><span>license</span></span></a></p><p><span></span>Open access</p></div><div><h2>Abstract</h2><div><p>This study conducts a thorough evaluation of text augmentation techniques across a variety of datasets and natural language processing (NLP) tasks to address the lack of reliable, generalized evidence for these methods. It examines the effectiveness of these techniques in augmenting training sets to improve performance in tasks such as topic classification, sentiment analysis, and offensive language detection. The research emphasizes not only the augmentation methods, but also the strategic order in which real and augmented instances are introduced during training. A major contribution is the development and evaluation of Modified Cyclical Curriculum Learning (MCCL) for augmented datasets, which represents a novel approach in the field. Results show that specific augmentation methods, especially when integrated with MCCL, significantly outperform traditional training approaches in NLP model performance. These results underscore the need for careful selection of augmentation techniques and sequencing strategies to optimize the balance between speed and quality improvement in various NLP tasks. The study concludes that the use of augmentation methods, especially in conjunction with MCCL, leads to improved results in various classification tasks, providing a foundation for future advances in text augmentation strategies in NLP.</p></div></div><ul><li></li><li></li></ul><div><h2>Keywords</h2><p><span>Text augmentation</span></p><p><span>Data augmentation</span></p><p><span>Curriculum learning</span></p><p><span>Text classification</span></p><p><span>Sample ordering</span></p></div><section><header><h2>Cited by (0)</h2></header></section><div><dl><dt><a href=\\\"#baep-article-footnote-id1\\\"><span><span><sup>‚òÜ</sup></span></span></a></dt><dd><p>This study was supported by the <span>Scientific and Technological Research Council of Turkey</span>\\n(TUBITAK) Grant No: <a href=\\\"#GS1\\\"><span><span>120E100</span></span></a>.</p></dd></dl></div><p><span>¬© 2024 The Author(s). Published by Elsevier B.V.</span></p></article></div></div></div></div>\", \"url\": \"https://www.sciencedirect.com/science/article/pii/S2949719124000190\"}, {\"title\": \"A Complete Guide to Data Augmentation\", \"text\": \"A Complete Guide to Data Augmentation | DataCamp\\n[Skip to main content](#main)\\n# A Complete Guide to Data Augmentation\\nLearn about data augmentation techniques, applications, and tools with a TensorFlow and Keras tutorial.\\nListContents\\nUpdated Dec 9, 2024¬∑ 15 min read\\nContents\\n## GroupTraining more people?\\nGet your team access to the full DataCamp for business platform.\\n## What is Data Augmentation?\\nData augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data. It includes making minor changes to the dataset or using deep learning to generate new data points.\\n### Augmented vs. synthetic data\\nData augmentation and synthetic data generation are distinct yet complementary techniques in machine learning:\\n* **Augmented data**: This involves creating modified versions of existing data to increase dataset diversity. For example, in image processing, applying transformations like rotations, flips, or color adjustments to existing images can help models generalize better.\\n* **Synthetic data**: Thisrefers to artificially generated data, which allows researchers and developers to test and improve algorithms without risking the privacy or security of real-world data.\\n**Note**: augmentation techniques are not limited to images. You can augment audio, video, text, and other types of data too.\\n### Why is data augmentation important?\\nData augmentation helps machine learning models perform better by making the most of existing data. It prevents overfitting, improves accuracy, and creates diversity in training data, which is crucial when datasets are small or imbalanced. By simulating real-world variations, it makes models more robust and reliable‚Äîwithout the need for expensive data collection. In short, it‚Äôs a simple, powerful way to help models learn and generalize effectively.\\n### When should you use data augmentation?\\n1. To prevent models from overfitting.\\n2. The initial training set is too small.\\n3. To improve the model accuracy.\\n4. To Reduce the operational cost of labeling and cleaning the raw dataset.### Limitations of data augmentation\\n* The biases in the original dataset persist in the augmented data.\\n* Quality assurance for data augmentation is expensive.\\n* Research and development are required to build a system with advanced applications. For example, generating high-resolution images using GANs can be challenging.\\n* Finding an effective data augmentation approach can be challenging.\\n## Become a ML Scientist\\nMaster Python skills to become a machine learning scientist\\n[Start Learning for Free](https://www.datacamp.com/tracks/machine-learning-scientist-with-python)\\n## Data Augmentation Techniques\\nIn this section, we will learn about audio, text, image, and advanced data augmentation techniques.\\n### Audio Data Augmentation\\n1. **Noise injection**: add gaussian or random noise to the audio dataset to improve the model performance.\\n2. **Shifting**: shift audio left (fast forward) or right with random seconds.\\n3. **Changing the speed**: stretches times series by a fixed rate.\\n4. **Changing the pitch**: randomly change the pitch of the audio.### Text Data Augmentation\\n1. **Word or sentence shuffling**: randomly changing the position of a word or sentence.\\n2. **Word replacement**: replace words with synonyms.\\n3. **Syntax-tree manipulation**: paraphrase the sentence using the same word.\\n4. **Random word insertion**: inserts words at random.\\n5. **Random word deletion**: deletes words at random.### Image Augmentation\\n***Learn more about image transformation and manipulation with hands-on exercises in our[Image Processing with Python skill track](https://www.datacamp.com/tracks/image-processing).***\\n1. **Geometric transformations**: randomly flip, crop, rotate, stretch, and zoom images. You need to be careful about applying multiple transformations on the same images, as this can reduce model performance.\\n2. **Color space transformations**: randomly change RGB color channels, contrast, and brightness.\\n3. **Kernel filters**: randomly change the sharpness or blurring of the image.\\n4. **Random erasing**: delete some part of the initial image.\\n5. **Mixing images**: blending and mixing multiple images.### Advanced Techniques\\n1. **Generative adversarial networks**(GANs): used to generate new data points or images. It does not require existing data to generate synthetic data.\\n2. **Neural Style Transfer**: a series of convolutional layers trained to deconstruct images and separate context and style.## Data Augmentation Applications\\nData augmentation can apply to all machine learning applications where acquiring quality data is challenging. Furthermore, it can help improve model robustness and performance across all fields of study.\\n### Healthcare\\nAcquiring and labeling medical imaging datasets is time-consuming and expensive. You also need a subject matter expert to validate the dataset before performing data analysis. Using geometric and other transformations can help you train robust and accurate machine-learning models.\\nFor example, in the case of Pneumonia Classification, you can use random cropping, zooming, stretching, and color space transformation to improve the model performance. However, you need to be careful about certain augmentations as they can result in opposite results. For example, random rotation and reflection along the x-axis are not recommended for the X-ray imaging dataset.\\n![kaggle-COVID19-Classification.png](https://images.datacamp.com/image/upload/v1669207732/kaggle_COVID_19_Classification_10703dbe61.png)\\nImage from[ibrahimsobh.github.io](https://ibrahimsobh.github.io/kaggle-COVID19-Classification/)| kaggle-COVID19-Classification\\n### Self-Driving Cars\\nThere is limited data available on self-driving cars, and companies are using simulated environments to generate synthetic data using reinforcement learning. It can help you train and test machine learning applications where data security is an issue.\\n![Autonomous Visualization System from Uber ATG.png](https://images.datacamp.com/image/upload/v1669207732/Autonomous_Visualization_System_from_Uber_ATG_9e79d6c630.png)\\nImage by[David Silver](https://medium.com/self-driving-cars/autonomous-visualization-system-from-uber-atg-50957e7101f0)| Autonomous Visualization System from Uber ATG\\nThe possibilities of augmented data as a simulation are endless, as it can be used to generate real-world scenarios.\\n### Natural Language Processing\\nText data augmentation is generally used in situations with limited quality data, and improving the performance metric takes priority. You can apply synonym augmentation, word embedding, character swap, and random insertion and deletion. These techniques are also valuable for low-resource languages.\\n![Selective Text Augmentation with Word Roles for Low-Resource Text Classification.png](https://images.datacamp.com/image/upload/v1669207732/Selective_Text_Augmentation_with_Word_Roles_for_Low_Resource_Text_Classification_c1302878c9.png)\\nImage from[Papers With Code](https://paperswithcode.com/paper/selective-text-augmentation-with-word-roles)| Selective Text Augmentation with Word Roles for Low-Resource Text Classification.\\nResearchers use text augmentation for the language models in high error recognition scenarios, sequence-to-sequence data generation, and text classification.\\n### Automatic Speech Recognition\\nIn sound classification and speech recognition, data augmentation works wonders. It improves the model performance even on low-resource languages.\\n![Noise Injection.png](https://images.datacamp.com/image/upload/v1669207728/Noise_Injection_b3af64a578.png)\\nImage by[Edward Ma](https://medium.com/@makcedward/data-augmentation-for-audio-76912b01fdf6)| Noise Injection\\nThe random noise injection, shifting, and changing the pitch can help you produce state-of-the-art speech-to-text models. You can also use GANs to generate realistic sounds for a particular application.\\n## Ethical Implications of Data Augmentatio...\", \"url\": \"https://www.datacamp.com/tutorial/complete-guide-data-augmentation\"}, {\"title\": \"Effective Data Augmentation for Sentence Classification ...\", \"text\": \"## [Effective Data Augmentation for Sentence Classification Using One VAE per Class](https://aclanthology.org/2022.coling-1.305.pdf)\\n[Fr√©d√©ric Piedboeuf](https://aclanthology.org/people/f/frederic-piedboeuf/),\\n[Philippe Langlais](https://aclanthology.org/people/p/philippe-langlais/)\\n* * *\\n##### Abstract\\nIn recent years, data augmentation has become an important field of machine learning. While images can use simple techniques such as cropping or rotating, textual data augmentation needs more complex manipulations to ensure that the generated examples are useful. Variational auto-encoders (VAE) and its conditional variant the Conditional-VAE (CVAE) are often used to generate new textual data, both relying on a good enough training of the generator so that it doesn‚Äôt create examples of the wrong class. In this paper, we explore a simpler way to use VAE for data augmentation: the training of one VAE per class. We show on several dataset sizes, as well as on four different binary classification tasks, that it systematically outperforms other generative data augmentation techniques.\\nAnthology ID:2022.coling-1.305Volume:[Proceedings of the 29th International Conference on Computational Linguistics](https://aclanthology.org/volumes/2022.coling-1/)Month:OctoberYear:2022Address:Gyeongju, Republic of KoreaEditors:[Nicoletta Calzolari](https://aclanthology.org/people/n/nicoletta-calzolari/),\\n[Chu-Ren Huang](https://aclanthology.org/people/c/chu-ren-huang/),\\n[Hansaem Kim](https://aclanthology.org/people/h/hansaem-kim/),\\n[James Pustejovsky](https://aclanthology.org/people/j/james-pustejovsky/),\\n[Leo Wanner](https://aclanthology.org/people/l/leo-wanner/),\\n[Key-Sun Choi](https://aclanthology.org/people/k/key-sun-choi/),\\n[Pum-Mo Ryu](https://aclanthology.org/people/p/pum-mo-ryu/),\\n[Hsin-Hsi Chen](https://aclanthology.org/people/h/hsin-hsi-chen/),\\n[Lucia Donatelli](https://aclanthology.org/people/l/lucia-donatelli/),\\n[Heng Ji](https://aclanthology.org/people/h/heng-ji/),\\n[Sadao Kurohashi](https://aclanthology.org/people/s/sadao-kurohashi/),\\n[Patrizia Paggio](https://aclanthology.org/people/p/patrizia-paggio/),\\n[Nianwen Xue](https://aclanthology.org/people/n/nianwen-xue/),\\n[Seokhwan Kim](https://aclanthology.org/people/s/seokhwan-kim/),\\n[Younggyun Hahm](https://aclanthology.org/people/y/younggyun-hahm/),\\n[Zhong He](https://aclanthology.org/people/z/zhong-he/),\\n[Tony Kyungil Lee](https://aclanthology.org/people/t/tony-kyungil-lee/),\\n[Enrico Santus](https://aclanthology.org/people/e/enrico-santus/),\\n[Francis Bond](https://aclanthology.org/people/f/francis-bond/),\\n[Seung-Hoon Na](https://aclanthology.org/people/s/seung-hoon-na/)Venue:[COLING](https://aclanthology.org/venues/coling/)SIG:Publisher:International Committee on Computational LinguisticsNote:Pages:3454‚Äì3464Language:URL:[https://aclanthology.org/2022.coling-1.305/](https://aclanthology.org/2022.coling-1.305/)DOI:Bibkey:piedboeuf-langlais-2022-effectiveCite (ACL):Fr√©d√©ric Piedboeuf and Philippe Langlais. 2022. [Effective Data Augmentation for Sentence Classification Using One VAE per Class](https://aclanthology.org/2022.coling-1.305/). In _Proceedings of the 29th International Conference on Computational Linguistics_, pages 3454‚Äì3464, Gyeongju, Republic of Korea. International Committee on Computational Linguistics.Cite (Informal):[Effective Data Augmentation for Sentence Classification Using One VAE per Class](https://aclanthology.org/2022.coling-1.305/) (Piedboeuf & Langlais, COLING 2022)Copy Citation:BibTeXMarkdownMODS XMLEndnoteMore options‚Ä¶PDF:[https://aclanthology.org/2022.coling-1.305.pdf](https://aclanthology.org/2022.coling-1.305.pdf)Data[SST](https://paperswithcode.com/dataset/sst),¬†[SST-2](https://paperswithcode.com/dataset/sst-2)\\n[PDF](https://aclanthology.org/2022.coling-1.305.pdf) [Cite](https://aclanthology.org/2022.coling-1.305/) [Search](https://www.semanticscholar.org/search?q=Effective+Data+Augmentation+for+Sentence+Classification+Using+One+VAE+per+Class) [Fix data](https://aclanthology.org/2022.coling-1.305/)\\n* * *\", \"url\": \"https://aclanthology.org/2022.coling-1.305\"}, {\"title\": \"EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks\", \"text\": \"# Computer Science > Computation and Language\\n\\n**arXiv:1901.11196** (cs)\\n\\n\\\\[Submitted on 31 Jan 2019 ( [v1](https://arxiv.org/abs/1901.11196v1)), last revised 25 Aug 2019 (this version, v2)\\\\]\\n\\n# Title:EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks\\n\\nAuthors: [Jason Wei](https://arxiv.org/search/cs?searchtype=author&query=Wei,+J), [Kai Zou](https://arxiv.org/search/cs?searchtype=author&query=Zou,+K)\\n\\nView a PDF of the paper titled EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks, by Jason Wei and Kai Zou\\n\\n[View PDF](https://arxiv.org/pdf/1901.11196)\\n\\n> Abstract:We present EDA: easy data augmentation techniques for boosting performance on text classification tasks. EDA consists of four simple but powerful operations: synonym replacement, random insertion, random swap, and random deletion. On five text classification tasks, we show that EDA improves performance for both convolutional and recurrent neural networks. EDA demonstrates particularly strong results for smaller datasets; on average, across five datasets, training with EDA while using only 50% of the available training set achieved the same accuracy as normal training with all available data. We also performed extensive ablation studies and suggest parameters for practical use.\\n\\n|     |     |\\n| --- | --- |\\n| Comments: | EMNLP-IJCNLP 2019 short paper |\\n| Subjects: | Computation and Language (cs.CL) |\\n| Cite as: | [arXiv:1901.11196](https://arxiv.org/abs/1901.11196) \\\\[cs.CL\\\\] |\\n| (or [arXiv:1901.11196v2](https://arxiv.org/abs/1901.11196v2) \\\\[cs.CL\\\\] for this version) |\\n| [https://doi.org/10.48550/arXiv.1901.11196](https://doi.org/10.48550/arXiv.1901.11196) <br>Focus to learn more<br>arXiv-issued DOI via DataCite |\\n\\n## Submission history\\n\\nFrom: Jason Wei \\\\[ [view email](https://arxiv.org/show-email/7ee5aa67/1901.11196)\\\\] **[\\\\[v1\\\\]](https://arxiv.org/abs/1901.11196v1)**\\nThu, 31 Jan 2019 03:20:52 UTC (294 KB)\\n**\\\\[v2\\\\]**\\nSun, 25 Aug 2019 23:11:07 UTC (63 KB)\\n\\nFull-text links:\\n\\n## Access Paper:\\n\\nView a PDF of the paper titled EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks, by Jason Wei and Kai Zou\\n\\n- [View PDF](https://arxiv.org/pdf/1901.11196)\\n- [TeX Source](https://arxiv.org/src/1901.11196)\\n\\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\\n\\nCurrent browse context:\\n\\ncs.CL\\n\\n[<¬†prev](https://arxiv.org/prevnext?id=1901.11196&function=prev&context=cs.CL)¬† \\\\| ¬†[next¬†>](https://arxiv.org/prevnext?id=1901.11196&function=next&context=cs.CL)\\n\\n[new](https://arxiv.org/list/cs.CL/new) \\\\| [recent](https://arxiv.org/list/cs.CL/recent) \\\\| [2019-01](https://arxiv.org/list/cs.CL/2019-01)\\n\\nChange to browse by:\\n\\n[cs](https://arxiv.org/abs/1901.11196?context=cs)\\n\\n### References & Citations\\n\\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1901.11196)\\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1901.11196)\\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:1901.11196)\\n\\n### [DBLP](https://dblp.uni-trier.de) \\\\- CS Bibliography\\n\\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1901.html#abs-1901-11196) \\\\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1901-11196)\\n\\n[Jason W. Wei](https://dblp.uni-trier.de/search/author?author=Jason%20W.%20Wei) [Kai Zou](https://dblp.uni-trier.de/search/author?author=Kai%20Zou)\\n\\nexport BibTeX citationLoading...\\n\\n## BibTeX formatted citation\\n\\n√ó\\n\\nData provided by:\\n\\n### Bookmark\\n\\nBibliographic Tools\\n\\n# Bibliographic and Citation Tools\\n\\nBibliographic Explorer Toggle\\n\\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\\n\\nConnected Papers Toggle\\n\\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\\n\\nLitmaps Toggle\\n\\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\\n\\nscite.ai Toggle\\n\\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\\n\\nCode, Data, Media\\n\\n# Code, Data and Media Associated with this Article\\n\\nalphaXiv Toggle\\n\\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\\n\\nLinks to Code Toggle\\n\\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\\n\\nDagsHub Toggle\\n\\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\\n\\nGotitPub Toggle\\n\\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\\n\\nHuggingface Toggle\\n\\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\\n\\nLinks to Code Toggle\\n\\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\\n\\nScienceCast Toggle\\n\\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\\n\\nDemos\\n\\n# Demos\\n\\nReplicate Toggle\\n\\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\\n\\nSpaces Toggle\\n\\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\\n\\nSpaces Toggle\\n\\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\\n\\nRelated Papers\\n\\n# Recommenders and Search Tools\\n\\nLink to Influence Flower\\n\\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\\n\\nCore recommender toggle\\n\\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\\n\\n- Author\\n- Venue\\n- Institution\\n- Topic\\n\\nAbout arXivLabs\\n\\n# arXivLabs: experimental projects with community collaborators\\n\\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\\n\\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\\n\\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\\n\\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1901.11196) \\\\|\\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))\", \"url\": \"https://arxiv.org/abs/1901.11196\"}, {\"title\": \"Text Classification: All Tips and Tricks from 5 Kaggle Competitions\", \"text\": \"In this article, I will discuss some great tips and tricks to [improve the performance](https://neptune.ai/blog/improving-machine-learning-deep-learning-models) of your text classification model. These tricks are obtained from solutions of some of Kaggle‚Äôs top NLP competitions.\\n\\nNamely, I‚Äôve gone through:\\n\\n- [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification) ‚Äì $65,000\\n- [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/) ‚Äì $35,000\\n- [Quora Insincere Questions Classification](http://kaggle.com/c/quora-insincere-questions-classification) ‚Äì $25,000\\n- [Google QUEST Q&A Labeling](https://www.kaggle.com/c/google-quest-challenge) ‚Äì $25,000\\n- [TensorFlow 2.0 Question Answering](https://www.kaggle.com/c/tensorflow2-question-answering) ‚Äì $50,000\\n\\nand found a ton of great ideas.\\n\\nWithout much lag, let‚Äôs begin.\\n\\n## Dealing with larger datasets\\n\\nOne issue you might face in any machine learning competition is the size of your data set. If the size of your data is large, that is 3GB + for Kaggle kernels and more basic laptops you could find it difficult to load and process with limited resources. Here is the link to some of the articles and kernels that I have found useful in such situations.\\n\\n- Optimize the memory by [reducing the size of some attributes](https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data)\\n- Use open-source libraries such as [Dask to read and manipulate the data](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask), it performs parallel computing and saves up memory space\\n- Use [cudf](https://github.com/rapidsai/cudf)\\n- Convert data to [parquet](https://arrow.apache.org/docs/python/parquet.html) format\\n- Convert data to [feather](https://medium.com/@snehotosh.banerjee/feather-a-fast-on-disk-format-for-r-and-python-data-frames-de33d0516b03) format\\n\\n## Small datasets and external data\\n\\nBut, what can one do if the dataset is small? Let‚Äôs see some techniques to tackle this situation.\\n\\nOne way to increase the performance of any machine learning model is to use some external data frame that contains some variables that influence the predicate variable.\\n\\nLet‚Äôs see some of the external datasets.\\n\\n- Use of [squad](https://rajpurkar.github.io/SQuAD-explorer/) data for Question Answering tasks\\n- Other [datasets](http://nlpprogress.com/english/question_answering.html) for QA tasks\\n- Wikitext long term dependency language modeling [dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\\n- [Stackexchange data](https://archive.org/download/stackexchange)\\n- Prepare a dictionary of commonly misspelled words and corrected words.\\n- Use of [helper datasets](https://www.kaggle.com/kyakovlev/jigsaw-general-helper-public) for cleaning\\n- [Pseudo labeling](https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969/) is the process of adding confidently predicted test data to your training data\\n- Use different data [sampling methods](https://www.kaggle.com/shahules/tackling-class-imbalance)\\n- Text augmentation by [Exchanging words with synonym](https://arxiv.org/pdf/1502.01710.pdf) [s](https://arxiv.org/pdf/1502.01710.pdf)\\n- Text augmentation by [noising in RNN](https://arxiv.org/pdf/1703.02573.pdf)\\n- Text augmentation by [translation to other languages and back](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/48038)\\n\\n## Data exploration and gaining insights\\n\\nData exploration always helps to better understand the data and gain insights from it. Before starting to develop machine learning models, top competitors always read/do a lot of exploratory data analysis for the data. This helps in feature engineering and cleaning of the data.\\n\\n- Twitter data [exploration methods](https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda)\\n- Simple [EDA for tweets](https://www.kaggle.com/nz0722/simple-eda-text-preprocessing-jigsaw)\\n- [EDA](https://www.kaggle.com/tunguz/just-some-simple-eda) for Quora data\\n- [EDA](https://www.kaggle.com/kailex/r-eda-for-q-gru) in ¬†R for Quora data\\n- Complete [EDA](https://www.kaggle.com/codename007/start-from-here-quest-complete-eda-fe) with stack exchange data\\n- My previous article on [EDA for natural language processing](https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools)\\n\\n## Data cleaning\\n\\nData cleaning is one of the important and integral parts of any NLP problem. Text data always needs some preprocessing and cleaning before we can represent it in a suitable form.\\n\\n- Use this [notebook](https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing) to clean social media data\\n- [Data cleaning](https://www.kaggle.com/kyakovlev/preprocessing-bert-public) for BERT\\n- Use [textblob](https://textblob.readthedocs.io/en/dev/quickstart.html) to correct misspellings\\n- [Cleaning](https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing) for pre-trained embeddings\\n- [Language detection and translation](https://www.pythonprogramming.in/language-detection-and-translation-using-textblob.html) for multilingual tasks\\n- Preprocessing for Glove [part 1](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part1-eda) and [part 2](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part2-usage)\\n- [Increasing word coverage](https://www.kaggle.com/sunnymarkliu/more-text-cleaning-to-increase-word-coverage) to get more from pre-trained word embeddings\\n\\n## Text representations\\n\\nBefore we feed our text data to the Neural network or ML model, the text input needs to be represented in a suitable format. These representations determine the performance of the model to a large extent.\\n\\n- Pretrained [Glove](https://nlp.stanford.edu/projects/glove/) vectors\\n- Pretrained [fasttext](https://fasttext.cc/docs/en/english-vectors.html) vectors\\n- Pretrained [word2vec](https://radimrehurek.com/gensim/models/word2vec.html) vectors\\n- My previous article on these [3 embeddings](https://neptune.ai/blog/document-classification-small-datasets)\\n- Combining [pre-trained vectors](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778/). This can help in better representation of text and decreasing OOV words\\n- [Paragram](https://cogcomp.seas.upenn.edu/page/resource_view/106) embeddings\\n- [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/1)\\n- Use USE to generate [sentence-level features](https://www.kaggle.com/abhishek/distilbert-use-features-oof)\\n- 3 methods to [combine embeddings](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778)\\n\\nContextual embeddings models\\n\\n- [BERT](https://github.com/google-research/bert) Bidirectional Encoder Representations from Transformers\\n- [GPT](https://github.com/openai/finetune-transformer-lm)\\n- [Roberta](https://github.com/pytorch/fairseq/tree/master/examples/roberta) a Robustly Optimized BERT\\n- [Albert](https://github.com/google-research/ALBERT) a Lite BERT for Self-supervised Learning of Language Representations\\n- [Distilbert](https://github.com/huggingface/transformers/tree/master/examples/distillation) a lighter version of BERT\\n- [XLNET](https://github.com/zihangdai/xlnet/)\\n\\n## Modeling\\n\\n### Model architecture\\n\\nChoosing the right architecture is important to develop a proper machine learning model, sequence to sequence models like LSTMs, GRUs perform well in NLP problems and is always worth trying. Stacking 2 layers of LSTM/GRU networks is a common approach.\\n\\n- [Stacking Bidirectional CuDNNLSTM](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644/)\\n- [Stacking LSTM networks](https://www.kaggle.com/sakami/google-quest-single-lstm/)\\n- [LSTM and 5 fold Attention](https://www.kaggle.com/christofhenkel/keras-baseline-lstm-attention-5-fold/)\\n- [Bi...\", \"url\": \"https://neptune.ai/blog/text-classification-tips-and-tricks-kaggle-competitions\"}, {\"title\": \"Text augmentation techniques in NLP\", \"text\": \"- [NLP Tutorial](https://www.geeksforgeeks.org/nlp/natural-language-processing-nlp-tutorial/)\\n- [Libraries](https://www.geeksforgeeks.org/nlp/nlp-libraries-in-python/)\\n- [Phases](https://www.geeksforgeeks.org/machine-learning/phases-of-natural-language-processing-nlp/)\\n- [Text Preprosessing](https://www.geeksforgeeks.org/nlp/text-preprocessing-for-nlp-tasks/)\\n- [Tokenization](https://www.geeksforgeeks.org/nlp/nlp-how-tokenizing-text-sentence-words-works/)\\n- [Lemmatization](https://www.geeksforgeeks.org/python/python-lemmatization-with-nltk/)\\n- [Word Embeddings](https://www.geeksforgeeks.org/nlp/word-embeddings-in-nlp/)\\n- [Projects Ideas](https://www.geeksforgeeks.org/nlp/top-natural-language-processing-nlp-projects/)\\n- [Interview Question](https://www.geeksforgeeks.org/nlp/advanced-natural-language-processing-interview-question/)\\n- [NLP Quiz](https://www.geeksforgeeks.org/quizzes/natural-language-processing-quiz/)\\n- [NLP Pipeline](https://www.geeksforgeeks.org/nlp/natural-language-processing-nlp-pipeline/)\\n- [DL for NLP](https://www.geeksforgeeks.org/nlp/nlp-with-deep-learning/)\\n- [NLP Datasets](https://www.geeksforgeeks.org/nlp/best-nlp-datasets/)\\n- [Machine Learning](https://www.geeksforgeeks.org/machine-learning/machine-learning/)\\n\\nSign In\\n\\n‚ñ≤\\n\\n[Open In App](https://geeksforgeeksapp.page.link/?link=https://www.geeksforgeeks.org/text-augmentation-techniques-in-nlp/?type%3Darticle%26id%3D997649&apn=free.programming.programming&isi=1641848816&ibi=org.geeksforgeeks.GeeksforGeeksDev&efr=1)\\n\\n# Text augmentation techniques in NLP\\n\\nLast Updated : 23 Jul, 2025\\n\\nComments\\n\\nImprove\\n\\nSuggest changes\\n\\n7 Likes\\n\\nLike\\n\\nReport\\n\\n**Text augmentation** is an important aspect of **NLP** to generate an artificial corpus. This helps in improving the NLP-based models to generalize better over a lot of different sub-tasks like intent classification, machine translation, chatbot training, image summarization, etc.\\n\\nText augmentation is used when:\\n\\n- There is an absence of sufficient variation in the text corpus.\\n- There is a high data imbalance during intent classification tasks.\\n- The overall quantity of data is insufficient for data-hungry machine-learning models.\\n\\nTable of Content\\n\\n- [Data Augmentation in NLP](https://www.geeksforgeeks.org/www.geeksforgeeks.org#data-augmentation-in-nlp)\\n- [Easy data Augmentation](https://www.geeksforgeeks.org/www.geeksforgeeks.org#easy-data-augmentation)\\n- [Generative Models](https://www.geeksforgeeks.org/www.geeksforgeeks.org#generative-models)\\n\\n## Data Augmentation in NLP\\n\\n[Data Augmentation](https://www.geeksforgeeks.org/machine-learning/python-data-augmentation/) (DA) is a technique employed to artificially expand training datasets by creating various versions of existing data without the need for additional data collection. Its primary goal is to enhance classification task performance by altering the data while preserving class categories.\\n\\nIn fields like [Computer Vision](https://www.geeksforgeeks.org/computer-vision/computer-vision/) and [Natural Language Processing](https://www.geeksforgeeks.org/nlp/natural-language-processing-overview/) (NLP), where data scarcity and limited diversity pose challenges, data augmentation strategies play a crucial role. While generating augmented images is relatively straightforward, NLP faces complexities due to the nuanced nature of language. Unlike images, we can't replace every word with a synonym, and even if substitution is possible, maintaining context becomes a significant challenge.\\n\\nThe pivotal role of data augmentation lies in its ability to boost model performance by increasing the volume of training data. More data generally leads to improved model performance. However, it is crucial to strike a balance in the distribution of augmented data. The generated data should neither closely resemble the original data nor deviate too much from it, as either extreme may result in overfitting or poor model performance. Therefore, effective data augmentation approaches should aim for a harmonious balance in data distribution.\\n\\nThe following three stages are where data augmentation techniques are used:\\n\\n- **Word Level:** At the word level, augmentation involves the transformation or replacement of individual words within the text. This could include synonyms, word shuffling, or other word-level modifications aimed at introducing variability without compromising the overall meaning or context of the text.\\n- **Sentence Level:** [Augmentation](https://www.geeksforgeeks.org/machine-learning/text-to-text-transfer-transformer-in-data-augmentation/) at the sentence level focuses on altering the structure and composition of entire sentences. Techniques such as paraphrasing, sentence shuffling, or introducing grammatical variations are employed. The goal is to diversify the dataset by presenting the model with different formulations of ideas while maintaining the essence of the original content.\\n- **Document Level:** At the document level, augmentation extends to the entire document or piece of text. This may involve introducing substantial changes, such as inserting or removing paragraphs, reordering sections, or even changing the overall writing style. Document-level augmentation aims to provide the model with exposure to varied document structures and writing conventions.\\n\\n## Easy data Augmentation\\n\\n### Synonym Replacement\\n\\nSynonym replacement is a technique to replace a set of [token](https://www.geeksforgeeks.org/ethical-hacking/how-does-the-token-based-authentication-work/)(s) from a text/document with another set of token(s) with equal or equivalent meaning without changing the overall meaning or context of the original phrase. The sentence generated post-replacement is called a synthetic phrase.\\n\\nThe synonym replacement can occur at any or all three of a document, i.e. at the character level, word/token level, or sentence level.\\n\\n#### **Word-embedding based**\\n\\n[Word embeddings](https://www.geeksforgeeks.org/nlp/word-embeddings-in-nlp/) that have been trained, such [GloVe](https://www.geeksforgeeks.org/nlp/pre-trained-word-embedding-using-glove-in-nlp-models/), [Word2Vec](https://www.geeksforgeeks.org/python/python-word-embedding-using-word2vec/), and fastText, can find the word vector that is closest to the original text in the embedding space.\\n\\nBecause contextual bidirectional embeddings such as ELMo and [BERT](https://www.geeksforgeeks.org/nlp/explanation-of-bert-model-nlp/) have substantially richer vector representations, they are recommended for improved reliability. Bidirectional [LSTM](https://www.geeksforgeeks.org/deep-learning/deep-learning-introduction-to-long-short-term-memory/) and Transformer models are more successful since they can encode longer text sequences and show contextual knowledge of the words around them.\\n\\n#### **Lexical-based**\\n\\nToken(s) with close or exact meaning is replaced directly in the string to achieve lexical-based augmented text. [Wordnet](https://www.geeksforgeeks.org/nlp/nlp-wordnet-for-tagging/) is used to tag and find the respective synonyms, hyponyms, and meronyms for the token(s) in the text.\\n\\n- **Random Insertion**\\n\\nRandomly inserting redundant or semantically similar words/tokens that do not include [stopwords](https://www.geeksforgeeks.org/nlp/removing-stop-words-nltk-python/) increase the meaning of a sentence/embedding or keep it semantically unchanged resulting in the creation of augmented text. This step should be done carefully as the introduction of negative words in a sentence can change its sentiment completely.\\n\\n```\\noriginal text: This is a geekforgeeks example.post-random insertion text: This is a new geekforgeeks example.\\n```\\n\\n- **Random Swap**\\n\\nRandomly replacing similar words/tokens that keep the semantic meaning of the sentence/embedding unchanged results in the creation of augmented text.\\n\\n```\\noriginal text: This is a geekforgeeks example.post-random swapped text: This is a geekforgeeks illustration.\\n```\\n\\n- **Random deletion**\\n\\nRandom del...\", \"url\": \"https://www.geeksforgeeks.org/nlp/text-augmentation-techniques-in-nlp\"}, {\"title\": \"Text Data Augmentation for Large Language Models\", \"text\": \"arXiv reCAPTCHA\\n[![Cornell University](https://static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\\n[We gratefully acknowledge support from\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)\\n# [![arxiv logo](https://static.arxiv.org/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)\", \"url\": \"https://arxiv.org/html/2501.18845v1\"}]}",
        "tool.duration_ms": 5747.2498416900635
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "7ceae91c9c6c9075",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "ReadTool",
      "kind": "INTERNAL",
      "start_time": 1767959087623334782,
      "end_time": 1767959087623629466,
      "duration": 0.000294684,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ReadTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x7f38e9db0750>\", \"input\": {\"file_path\": \"/home/code/exploration/seed_prompt.txt\"}}",
        "tool.output": "{\"content\": \"## Competition Overview\\nThis is a binary classification problem combining text and tabular features. See `exploration/eda.ipynb` for detailed data characteristics including feature distributions, missing values, class balance analysis, and correlation patterns.\\n\\n## Core Modeling Strategy\\n\\n### Multimodal Approach (Text + Tabular)\\nBased on winning Kaggle solutions for similar problems, the most effective approach is a three-step pipeline:\\n\\n1. **Extract text embeddings** using pretrained transformers (BERT, RoBERTa, or DeBERTa)\\n   - Use AutoGluon Tabular's TextPredictor for automatic text encoding\\n   - Alternatively, use Hugging Face transformers to generate sentence embeddings\\n   - GPU acceleration is critical for reasonable training time\\n\\n2. **Combine embeddings with tabular features**\\n   - Concatenate text embeddings with numeric/categorical features (two-stage approach)\\n   - OR convert tabular features to text and prepend to review (features-to-text trick)\\n   - Target-encode high-cardinality categorical features before merging\\n\\n3. **Train strong tabular models on combined features**\\n   - LightGBM, CatBoost, and XGBoost are the workhorses\\n   - Neural networks can be effective for larger datasets\\n   - Use libraries like Multimodal-Toolkit for seamless integration\\n\\n### Model Architecture Options\\n- **Two-stage**: Text encoder ‚Üí embeddings ‚Üí tabular model\\n- **Features-to-text**: Convert all features to text ‚Üí single transformer\\n- **Hybrid ensemble**: Combine both approaches with different weighting\\n\\n## Handling Class Imbalance (75/25 split)\\n\\n### Resampling Strategies\\n- **Undersample majority class** to balance classes (risk: information loss)\\n- **Oversample minority class** using SMOTE or ADASYN\\n- **Combine both**: SMOTE + Tomek links for cleaning\\n- **Apply resampling only to training folds** in cross-validation\\n\\n### Alternative Approaches (No Resampling)\\n- **Class weights**: Set `scale_pos_weight` in XGBoost/LightGBM or `class_weight` in sklearn\\n- **Focal loss**: Penalize hard examples more heavily\\n- **Threshold adjustment**: Optimize decision threshold post-training using ROC/PR curves\\n\\n### Validation Considerations\\n- **Always use stratified K-fold** to preserve class ratios in each fold\\n- **Monitor minority class metrics**: AUC-ROC, PR-AUC, F1-score (not accuracy)\\n- **Check for distribution shift** between train and test sets\\n\\n## Feature Engineering\\n\\n### Text Features\\n- **Basic**: Length, word count, character count, sentence count\\n- **Sentiment**: Use VADER or TextBlob for sentiment scores\\n- **TF-IDF**: Extract top terms and their statistics\\n- **Topic modeling**: LDA or NMF for latent topics\\n- **Entity extraction**: Count mentions of products, brands, locations\\n\\n### Tabular Features\\n- **Target encoding**: For high-cardinality categoricals (use cross-validation)\\n- **Interaction features**: Polynomial features between numeric columns\\n- **Aggregation features**: Group by categorical columns and compute statistics\\n- **Missing value patterns**: Create indicator for missing data patterns\\n- **Cyclical encoding**: If any temporal features exist\\n\\n### Cross-modal Features\\n- **Text-tabular interactions**: Multiply text sentiment scores with numeric features\\n- **Feature importance alignment**: Ensure text and tabular features are on similar scales\\n\\n## Model Selection and Training\\n\\n### Primary Models (Tier 1)\\n1. **LightGBM**: Fast, handles categorical features well\\n2. **CatBoost**: Excellent for categorical data, robust to overfitting\\n3. **XGBoost**: Reliable baseline, good performance\\n\\n### Secondary Models (Tier 2)\\n1. **Neural Networks**: For capturing non-linear interactions\\n2. **Random Forest**: For diversity in ensembles\\n3. **Logistic Regression**: With polynomial features for baseline\\n\\n### Training Configuration\\n- **Use early stopping** with patience of 50-100 rounds\\n- **Set class weights**: `scale_pos_weight = (negative_samples / positive_samples) * k` where k ‚àà [0.5, 2]\\n- **Hyperparameter ranges**:\\n  - Learning rate: 0.01 - 0.1\\n  - Max depth: 3 - 10\\n  - Num leaves: 31 - 255\\n  - Subsample: 0.6 - 0.9\\n  - Colsample: 0.6 - 0.9\\n\\n## Ensembling Strategy\\n\\n### Model Diversity\\n- Combine different architectures (GBM + NN + Transformer)\\n- Use different feature sets (text-only, tabular-only, combined)\\n- Vary preprocessing pipelines (different encoding strategies)\\n\\n### Ensemble Methods\\n1. **Weighted averaging**: Weight by validation performance\\n2. **Stacking**: Train meta-learner on out-of-fold predictions\\n3. **Rank averaging**: Average predictions after converting to ranks\\n4. **Optimal blending**: Use linear regression to find optimal weights\\n\\n### Implementation Order\\n1. Build 3-5 diverse single models\\n2. Create level-1 ensemble with simple averaging\\n3. Add stacking with logistic regression or LightGBM\\n4. Fine-tune ensemble weights using validation set\\n\\n## Validation Strategy\\n\\n### Cross-Validation Setup\\n- **Stratified K-Fold**: k=5 or k=10\\n- **GroupKFold**: If there's a grouping column (e.g., user_id)\\n- **TimeSeriesSplit**: If temporal patterns exist (check eda.ipynb)\\n\\n### Evaluation Metrics\\n- **Primary**: AUC-ROC (robust to class imbalance)\\n- **Secondary**: PR-AUC, F1-score, Log Loss\\n- **Never use**: Accuracy (misleading with imbalance)\\n\\n### Validation Best Practices\\n- **Create holdout set** before cross-validation for final evaluation\\n- **Monitor OOF (out-of-fold) predictions** for consistency\\n- **Check prediction distributions** across folds\\n- **Analyze errors**: Focus on minority class misclassifications\\n\\n## Optimization and Tuning\\n\\n### Hyperparameter Search\\n- **Start with broad search**: Use Optuna or Hyperopt\\n- **Focus on key params**: Learning rate, max depth, subsample\\n- **Use successive halving**: Reduce search space iteratively\\n- **Leverage GPU**: For neural network components\\n\\n### Feature Selection\\n- **Permutation importance**: On validation set\\n- **SHAP values**: For model interpretation\\n- **Recursive feature elimination**: For dimensionality reduction\\n- **Correlation analysis**: Remove highly correlated features\\n\\n### Post-Training Optimization\\n- **Threshold tuning**: Optimize for competition metric\\n- **Calibration**: Use Platt scaling or isotonic regression\\n- **Pseudo-labeling**: If confident in predictions on test set\\n\\n## Implementation Roadmap\\n\\n### Phase 1: Baselines (Quick)\\n1. TF-IDF + Logistic Regression\\n2. Tabular-only LightGBM\\n3. Text-only BERT fine-tuning\\n\\n### Phase 2: Core Models (1-2 days)\\n1. Multimodal pipeline (text embeddings + tabular)\\n2. 3-5 diverse models with different architectures\\n3. Basic ensemble (averaging)\\n\\n### Phase 3: Refinement (2-3 days)\\n1. Advanced feature engineering\\n2. Hyperparameter optimization\\n3. Stacking ensemble\\n4. Threshold optimization\\n\\n### Phase 4: Final Push (1 day)\\n1. Error analysis and targeted improvements\\n2. Model blending and weight tuning\\n3. Validation consistency checks\\n4. Submission preparation\\n\\n## Key Libraries and Tools\\n\\n### Essential Libraries\\n- **AutoGluon**: For automatic multimodal modeling\\n- **Multimodal-Toolkit**: For transformer + tabular integration\\n- **LightGBM/CatBoost/XGBoost**: Gradient boosting\\n- **Transformers**: Hugging Face for text encoding\\n- **Optuna**: Hyperparameter optimization\\n\\n### Utility Libraries\\n- **imbalanced-learn**: For resampling techniques\\n- **category_encoders**: For target encoding\\n- **SHAP**: For model interpretation\\n- **tqdm**: For progress tracking\\n\\n## Common Pitfalls to Avoid\\n\\n1. **Data leakage**: Never use test set statistics for training\\n2. **Overfitting to validation**: Use multiple validation strategies\\n3. **Ignoring minority class**: Focus metrics and analysis on positive class\\n4. **Text preprocessing errors**: Preserve semantic meaning\\n5. **Scale mismatch**: Ensure text embeddings and tabular features compatible\\n6. **Ensemble correlation**: Ensure model diversity, not just quantity\\n\\n## Expected Performance Targets\\n\\nBased on similar competitions:\\n- **Single model**: 0.75-0.85 AUC\\n- **Simple ensemble**: 0.80-0.88 AUC\\n- **Advanced ensemble**: 0.85-0.92 AUC\\n- **Top solutions**: 0.90+ AUC (requires significant feature engineering)\\n\\n## References and Resources\\n\\n- AutoGluon multimodal tutorial: Combining BERT with tabular models\\n- Multimodal-Toolkit: GitHub repository with examples\\n- Kaggle winning solutions: Mercari Price Suggestion, Home Credit Default Risk\\n- Class imbalance handling: SMOTE, ADASYN, class weights\\n- Feature engineering: Target encoding, interaction features\", \"is_error\": false}",
        "tool.duration_ms": 0.2808570861816406
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "37c57e1c1b23f936",
      "parent_span_id": "0ba2a54e35250b4b",
      "name": "llm.openai/o1",
      "kind": "CLIENT",
      "start_time": 1767959089191362914,
      "end_time": 1767959099565684500,
      "duration": 10.374321586,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "openai/o1",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 4000,
        "llm.prompt": "user: Evaluate subagent ExplorerAgent at loop 0 for potential RL update.\n\nCompetition: random-acts-of-pizza\nMetric: higher is better\n\nCall log contains 0 LLM interactions to evaluate.\n\nCALL LOG:\n\n--- Tool Call: ListFilesTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x7f38e836acd0>\", \"input\": {\"directory_path\": \"/home/data\"}}\nOutput: {\"content\": \"/home/data:\\n[FILE] description.md (7.0KB)\\n[FILE] sampleSubmission.csv (13.0KB)\\n[FILE] test.json (2.0MB)\\n[FILE] test.zip (433.1KB)\\n[FILE] train.json (8.4MB)\\n[FILE] train.zip (1.3MB)\", \"is_error\": false}\n\n--- Tool Call: ReadTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x7f38e9db0750>\", \"input\": {\"file_path\": \"/home/data/description.md\"}}\nOutput: {\"content\": \"# Overview\\n\\n## Description\\n\\n[Get started on this competition through Kaggle Scripts](https://www.kaggle.com/c/random-acts-of-pizza/forums/t/14286/kaggle-scripts-enabled-on-random-acts-of-pizza)\\n\\nIn machine learning, it is often said¬†there are¬†[no free lunches](http://en.wikipedia....\n\n--- Tool Call: CreateNotebookTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.CreateNotebookTool object at 0x7f38e8369e90>\", \"input\": {\"notebook_path\": \"eda.ipynb\", \"cells\": [{\"cell_type\": \"code\", \"content\": \"import pandas as pd\\nimport numpy as np\\nimport json\\n\\n# Load the training data\\ntrain_path = \\\"/home/data/train.jso...\nOutput: {\"content\": \"Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\", \"is_error\": false}\n\n--- Tool Call: ExecuteCellRangeTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 0, \"end_cell\": 1, \"duration\": 60}}\nOutput: {\"content\": \"Error: JSONDecodeError: Expecting value: line 2 column 1 (char 2)\", \"is_error\": true}\n\n--- Tool Call: BashTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.file_tools.BashTool object at 0x7f38e836a310>\", \"input\": {\"command\": \"head -20 /home/data/train.json\"}}\nOutput: {\"content\": \"[\\n    {\\n        \\\"giver_username_if_known\\\": \\\"N/A\\\",\\n        \\\"number_of_downvotes_of_request_at_retrieval\\\": 2,\\n        \\\"number_of_upvotes_of_request_at_retrieval\\\": 5,\\n        \\\"post_was_edited\\\": false,\\n        \\\"request_id\\\": \\\"t3_q8ycf\\\",\\n        \\\"request_number_of_commen...\n\n--- Tool Call: EditNotebookCellTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.EditNotebookCellTool object at 0x7f38e836ae10>\", \"input\": {\"cell_index\": 0, \"new_content\": \"import pandas as pd\\nimport numpy as np\\nimport json\\n\\n# Load the training data\\ntrain_path = \\\"/home/data/train.json\\\"\\n\\n# Read the JSON file as a JSON a...\nOutput: {\"content\": \"Edited cell 0. Re-run to update kernel state.\", \"is_error\": false}\n\n--- Tool Call: ExecuteCellRangeTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 0, \"end_cell\": 0, \"duration\": 60}}\nOutput: {\"content\": \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\nimport json\\n\\n# Load the training data\\ntrain_path = \\\"/home/data/train.json\\\"\\n\\n# Read the JSON file as a JSON array\\nwith open(train_path, 'r') as f:\\n   ...\n\n--- Tool Call: AddNotebookCellTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Check target distribution\\ntarget_col = 'requester_received_pizza'\\nprint(f\\\"Target distribution:\\\")\\nprint(train_df[target_col].value_counts())\\nprint(f\\\"...\nOutput: {\"content\": \"Added code cell at 2\", \"is_error\": false}\n\n--- Tool Call: ExecuteCellRangeTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 2, \"end_cell\": 2, \"duration\": 30}}\nOutput: {\"content\": \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Check target distribution\\ntarget_col = 'requester_received_pizza'\\nprint(f\\\"Target distribution:\\\")\\nprint(train_df[target_col].value_counts())\\nprint(f\\\"\\\\nTarget percentages:\\\")\\nprint(train_df[...\n\n--- Tool Call: AddNotebookCellTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Analyze text features\\nprint(\\\"Text feature analysis:\\\")\\nprint(f\\\"\\\\nRequest title length stats:\\\")\\ntrain_df['request_title_length'] = train_df['request_...\nOutput: {\"content\": \"Added code cell at 3\", \"is_error\": false}\n\n--- Tool Call: ExecuteCellRangeTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 3, \"end_cell\": 3, \"duration\": 30}}\nOutput: {\"content\": \"Executed cells 3-3\\n==================================================\\n\\nCell 3:\\n```\\n# Analyze text features\\nprint(\\\"Text feature analysis:\\\")\\nprint(f\\\"\\\\nRequest title length stats:\\\")\\ntrain_df['request_title_length'] = train_df['request_title'].str.len()\\nprint(train_df['request...\n\n--- Tool Call: WebSearchTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What are winning approaches for text classification with tabular features on Kaggle?\"}}\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nWinning Kaggle solutions for problems that mix free‚Äëtext columns with ordinary numeric or categorical fields treat the data as **multimodal** and deliberately com...\n\n--- Tool Call: WebSearchTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"How do Kaggle winners handle class imbalance in binary classification with 75/25 split?\"}}\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nTop Kaggle winners typically tackle a 75‚ÄØ%‚ÄØ/‚ÄØ25‚ÄØ% binary‚Äëclass split by reshaping the training data and by using metrics and model settings that reward performanc...\n\n--- Tool Call: WriteTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.file_tools.WriteTool object at 0x7f38e8310090>\", \"input\": {\"file_path\": \"seed_prompt.txt\", \"content\": \"## Competition Overview\\nThis is a binary classification problem combining text and tabular features. See `exploration/eda.ipynb` for detailed data charac...\nOutput: {\"content\": \"Wrote to /home/code/exploration/seed_prompt.txt\", \"is_error\": false}\n\n--- Tool Call: ListFilesTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x7f38e836acd0>\", \"input\": {\"directory_path\": \"/home/data\"}}\nOutput: {\"content\": \"/home/data:\\n[FILE] description.md (7.0KB)\\n[FILE] sampleSubmission.csv (13.0KB)\\n[FILE] test.json (2.0MB)\\n[FILE] test.zip (433.1KB)\\n[FILE] train.json (8.4MB)\\n[FILE] train.zip (1.3MB)\", \"is_error\": false}\n\n--- Tool Call: ReadTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x7f38e9db0750>\", \"input\": {\"file_path\": \"/home/data/description.md\"}}\nOutput: {\"content\": \"# Overview\\n\\n## Description\\n\\n[Get started on this competition through Kaggle Scripts](https://www.kaggle.com/c/random-acts-of-pizza/forums/t/14286/kaggle-scripts-enabled-on-random-acts-of-pizza)\\n\\nIn machine learning, it is often said¬†there are¬†[no free lunches](http://en.wikipedia....\n\n--- Tool Call: CreateNotebookTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.CreateNotebookTool object at 0x7f38e8369e90>\", \"input\": {\"notebook_path\": \"exploration/eda.ipynb\", \"cells\": [{\"cell_type\": \"code\", \"content\": \"import pandas as pd\\nimport numpy as np\\nimport json\\nimport matplotlib.pyplot as plt\\nimport seaborn as ...\nOutput: {\"content\": \"Error: Notebook already active: /home/code/exploration/eda.ipynb. Use CloseNotebook first.\", \"is_error\": true}\n\n--- Tool Call: CloseNotebookTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.CloseNotebookTool object at 0x7f38e836aed0>\", \"input\": {}}\nOutput: {\"content\": \"Closed: /home/code/exploration/eda.ipynb\", \"is_error\": false}\n\n--- Tool Call: CreateNotebookTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.CreateNotebookTool object at 0x7f38e8369e90>\", \"input\": {\"notebook_path\": \"exploration/eda.ipynb\", \"cells\": [{\"cell_type\": \"code\", \"content\": \"import pandas as pd\\nimport numpy as np\\nimport json\\nimport matplotlib.pyplot as plt\\nimport seaborn as ...\nOutput: {\"content\": \"Created: /home/code/exploration/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\", \"is_error\": false}\n\n--- Tool Call: ExecuteCellRangeTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 0, \"end_cell\": 0, \"duration\": 30}}\nOutput: {\"content\": \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\nimport json\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Load the training data\\ntrain_path = '/home/data/train.json'\\nwith open(train_path, '...\n\n--- Tool Call: AddNotebookCellTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Convert to DataFrame for easier analysis\\ndf = pd.DataFrame(train_data)\\n\\n# Analyze target distribution\\ntarget_counts = df['requester_received_pizza'].va...\nOutput: {\"content\": \"Added code cell at 1\", \"is_error\": false}\n\n--- Tool Call: ExecuteCellRangeTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 1, \"end_cell\": 1, \"duration\": 30}}\nOutput: {\"content\": \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Convert to DataFrame for easier analysis\\ndf = pd.DataFrame(train_data)\\n\\n# Analyze target distribution\\ntarget_counts = df['requester_received_pizza'].value_counts()\\ntarget_pct = df['requester_r...\n\n--- Tool Call: AddNotebookCellTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Analyze text features\\nprint(\\\"Text Features Analysis:\\\")\\nprint(f\\\"Request title length (chars): {df['request_title'].str.len().describe()}\\\")\\nprint(f\\\"\\...\nOutput: {\"content\": \"Added code cell at 2\", \"is_error\": false}\n\n--- Tool Call: ExecuteCellRangeTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 2, \"end_cell\": 2, \"duration\": 30}}\nOutput: {\"content\": \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Analyze text features\\nprint(\\\"Text Features Analysis:\\\")\\nprint(f\\\"Request title length (chars): {df['request_title'].str.len().describe()}\\\")\\nprint(f\\\"\\\\nRequest text length (chars): {df['reques...\n\n--- Tool Call: AddNotebookCellTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Analyze numerical/meta-data features\\nnumerical_features = [\\n    'requester_account_age_in_days_at_request',\\n    'requester_number_of_comments_at_request...\nOutput: {\"content\": \"Added code cell at 3\", \"is_error\": false}\n\n--- Tool Call: ExecuteCellRangeTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 3, \"end_cell\": 3, \"duration\": 30}}\nOutput: {\"content\": \"Executed cells 3-3\\n==================================================\\n\\nCell 3:\\n```\\n# Analyze numerical/meta-data features\\nnumerical_features = [\\n    'requester_account_age_in_days_at_request',\\n    'requester_number_of_comments_at_request', \\n    'requester_number_of_posts_at_req...\n\n--- Tool Call: WebSearchTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What are winning approaches for text classification competitions on Kaggle that combine text and meta-data features?\"}}\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nWinning solutions in Kaggle text‚Äëclassification contests usually blend strong language‚Äëmodel representations with carefully engineered meta‚Äëdata features, then st...\n\n--- Tool Call: WebSearchTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"How do Kaggle winners handle class imbalance in binary classification competitions with 3:1 ratio?\"}}\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nKaggle winners typically tame a 3‚ÄØ:‚ÄØ1 binary‚Äëclass imbalance with a short, repeatable workflow that combines data‚Äëlevel tricks and model‚Äëlevel adjustments‚ÄØ‚Äî‚ÄØall b...\n\n--- Tool Call: WebSearchTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What feature engineering techniques work best for combining text and categorical meta-data features in Kaggle competitions?\"}}\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nCombining free‚Äëform text with categorical meta‚Äëdata in Kaggle contests is most often tackled by turning the non‚Äëtext fields into a textual representation that a t...\n\n--- Tool Call: WebSearchTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What ensembling strategies work best for text classification competitions on Kaggle?\"}}\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nEnsembling is the de‚Äëfacto standard for winning Kaggle text‚Äëclassification contests.  The most reliable recipe combines **diverse fine‚Äëtuned language models** (e....\n\n--- Tool Call: WebSearchTool ---\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What hyperparameter optimization techniques work best for text classification models in Kaggle competitions?\"}}\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nAs of‚ÄØJan‚ÄØ9‚ÄØ2026, Bayesian‚Äëbased optimizers such as Optuna (or Hyperopt) paired with early‚Äëstopping and learning‚Äërate scheduling, and scalable parallel search too...\n\n--- Tool Call: WebSearchTool ---\nInp\n\nUse the reward function rubric to score progress and identify failed calls.",
        "llm.messages": "[{'role': 'user', 'content': 'Evaluate subagent ExplorerAgent at loop 0 for potential RL update.\\n\\nCompetition: random-acts-of-pizza\\nMetric: higher is better\\n\\nCall log contains 0 LLM interactions to evaluate.\\n\\nCALL LOG:\\n\\n--- Tool Call: ListFilesTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x7f38e836acd0>\", \"input\": {\"directory_path\": \"/home/data\"}}\\nOutput: {\"content\": \"/home/data:\\\\n[FILE] description.md (7.0KB)\\\\n[FILE] sampleSubmission.csv (13.0KB)\\\\n[FILE] test.json (2.0MB)\\\\n[FILE] test.zip (433.1KB)\\\\n[FILE] train.json (8.4MB)\\\\n[FILE] train.zip (1.3MB)\", \"is_error\": false}\\n\\n--- Tool Call: ReadTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x7f38e9db0750>\", \"input\": {\"file_path\": \"/home/data/description.md\"}}\\nOutput: {\"content\": \"# Overview\\\\n\\\\n## Description\\\\n\\\\n[Get started on this competition through Kaggle Scripts](https://www.kaggle.com/c/random-acts-of-pizza/forums/t/14286/kaggle-scripts-enabled-on-random-acts-of-pizza)\\\\n\\\\nIn machine learning, it is often said\\xa0there are\\xa0[no free lunches](http://en.wikipedia....\\n\\n--- Tool Call: CreateNotebookTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.CreateNotebookTool object at 0x7f38e8369e90>\", \"input\": {\"notebook_path\": \"eda.ipynb\", \"cells\": [{\"cell_type\": \"code\", \"content\": \"import pandas as pd\\\\nimport numpy as np\\\\nimport json\\\\n\\\\n# Load the training data\\\\ntrain_path = \\\\\"/home/data/train.jso...\\nOutput: {\"content\": \"Created: /home/code/exploration/eda.ipynb\\\\n\\\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\", \"is_error\": false}\\n\\n--- Tool Call: ExecuteCellRangeTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 0, \"end_cell\": 1, \"duration\": 60}}\\nOutput: {\"content\": \"Error: JSONDecodeError: Expecting value: line 2 column 1 (char 2)\", \"is_error\": true}\\n\\n--- Tool Call: BashTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.file_tools.BashTool object at 0x7f38e836a310>\", \"input\": {\"command\": \"head -20 /home/data/train.json\"}}\\nOutput: {\"content\": \"[\\\\n    {\\\\n        \\\\\"giver_username_if_known\\\\\": \\\\\"N/A\\\\\",\\\\n        \\\\\"number_of_downvotes_of_request_at_retrieval\\\\\": 2,\\\\n        \\\\\"number_of_upvotes_of_request_at_retrieval\\\\\": 5,\\\\n        \\\\\"post_was_edited\\\\\": false,\\\\n        \\\\\"request_id\\\\\": \\\\\"t3_q8ycf\\\\\",\\\\n        \\\\\"request_number_of_commen...\\n\\n--- Tool Call: EditNotebookCellTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.EditNotebookCellTool object at 0x7f38e836ae10>\", \"input\": {\"cell_index\": 0, \"new_content\": \"import pandas as pd\\\\nimport numpy as np\\\\nimport json\\\\n\\\\n# Load the training data\\\\ntrain_path = \\\\\"/home/data/train.json\\\\\"\\\\n\\\\n# Read the JSON file as a JSON a...\\nOutput: {\"content\": \"Edited cell 0. Re-run to update kernel state.\", \"is_error\": false}\\n\\n--- Tool Call: ExecuteCellRangeTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 0, \"end_cell\": 0, \"duration\": 60}}\\nOutput: {\"content\": \"Executed cells 0-0\\\\n==================================================\\\\n\\\\nCell 0:\\\\n```\\\\nimport pandas as pd\\\\nimport numpy as np\\\\nimport json\\\\n\\\\n# Load the training data\\\\ntrain_path = \\\\\"/home/data/train.json\\\\\"\\\\n\\\\n# Read the JSON file as a JSON array\\\\nwith open(train_path, \\'r\\') as f:\\\\n   ...\\n\\n--- Tool Call: AddNotebookCellTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Check target distribution\\\\ntarget_col = \\'requester_received_pizza\\'\\\\nprint(f\\\\\"Target distribution:\\\\\")\\\\nprint(train_df[target_col].value_counts())\\\\nprint(f\\\\\"...\\nOutput: {\"content\": \"Added code cell at 2\", \"is_error\": false}\\n\\n--- Tool Call: ExecuteCellRangeTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 2, \"end_cell\": 2, \"duration\": 30}}\\nOutput: {\"content\": \"Executed cells 2-2\\\\n==================================================\\\\n\\\\nCell 2:\\\\n```\\\\n# Check target distribution\\\\ntarget_col = \\'requester_received_pizza\\'\\\\nprint(f\\\\\"Target distribution:\\\\\")\\\\nprint(train_df[target_col].value_counts())\\\\nprint(f\\\\\"\\\\\\\\nTarget percentages:\\\\\")\\\\nprint(train_df[...\\n\\n--- Tool Call: AddNotebookCellTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Analyze text features\\\\nprint(\\\\\"Text feature analysis:\\\\\")\\\\nprint(f\\\\\"\\\\\\\\nRequest title length stats:\\\\\")\\\\ntrain_df[\\'request_title_length\\'] = train_df[\\'request_...\\nOutput: {\"content\": \"Added code cell at 3\", \"is_error\": false}\\n\\n--- Tool Call: ExecuteCellRangeTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 3, \"end_cell\": 3, \"duration\": 30}}\\nOutput: {\"content\": \"Executed cells 3-3\\\\n==================================================\\\\n\\\\nCell 3:\\\\n```\\\\n# Analyze text features\\\\nprint(\\\\\"Text feature analysis:\\\\\")\\\\nprint(f\\\\\"\\\\\\\\nRequest title length stats:\\\\\")\\\\ntrain_df[\\'request_title_length\\'] = train_df[\\'request_title\\'].str.len()\\\\nprint(train_df[\\'request...\\n\\n--- Tool Call: WebSearchTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What are winning approaches for text classification with tabular features on Kaggle?\"}}\\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\\\n==================================================\\\\n\\\\n--- Result 1 ---\\\\nTitle: ANSWER\\\\n\\\\nContent:\\\\nWinning Kaggle solutions for problems that mix free‚Äëtext columns with ordinary numeric or categorical fields treat the data as **multimodal** and deliberately com...\\n\\n--- Tool Call: WebSearchTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"How do Kaggle winners handle class imbalance in binary classification with 75/25 split?\"}}\\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\\\n==================================================\\\\n\\\\n--- Result 1 ---\\\\nTitle: ANSWER\\\\n\\\\nContent:\\\\nTop Kaggle winners typically tackle a 75\\u202f%\\u202f/\\u202f25\\u202f% binary‚Äëclass split by reshaping the training data and by using metrics and model settings that reward performanc...\\n\\n--- Tool Call: WriteTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.file_tools.WriteTool object at 0x7f38e8310090>\", \"input\": {\"file_path\": \"seed_prompt.txt\", \"content\": \"## Competition Overview\\\\nThis is a binary classification problem combining text and tabular features. See `exploration/eda.ipynb` for detailed data charac...\\nOutput: {\"content\": \"Wrote to /home/code/exploration/seed_prompt.txt\", \"is_error\": false}\\n\\n--- Tool Call: ListFilesTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x7f38e836acd0>\", \"input\": {\"directory_path\": \"/home/data\"}}\\nOutput: {\"content\": \"/home/data:\\\\n[FILE] description.md (7.0KB)\\\\n[FILE] sampleSubmission.csv (13.0KB)\\\\n[FILE] test.json (2.0MB)\\\\n[FILE] test.zip (433.1KB)\\\\n[FILE] train.json (8.4MB)\\\\n[FILE] train.zip (1.3MB)\", \"is_error\": false}\\n\\n--- Tool Call: ReadTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x7f38e9db0750>\", \"input\": {\"file_path\": \"/home/data/description.md\"}}\\nOutput: {\"content\": \"# Overview\\\\n\\\\n## Description\\\\n\\\\n[Get started on this competition through Kaggle Scripts](https://www.kaggle.com/c/random-acts-of-pizza/forums/t/14286/kaggle-scripts-enabled-on-random-acts-of-pizza)\\\\n\\\\nIn machine learning, it is often said\\xa0there are\\xa0[no free lunches](http://en.wikipedia....\\n\\n--- Tool Call: CreateNotebookTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.CreateNotebookTool object at 0x7f38e8369e90>\", \"input\": {\"notebook_path\": \"exploration/eda.ipynb\", \"cells\": [{\"cell_type\": \"code\", \"content\": \"import pandas as pd\\\\nimport numpy as np\\\\nimport json\\\\nimport matplotlib.pyplot as plt\\\\nimport seaborn as ...\\nOutput: {\"content\": \"Error: Notebook already active: /home/code/exploration/eda.ipynb. Use CloseNotebook first.\", \"is_error\": true}\\n\\n--- Tool Call: CloseNotebookTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.CloseNotebookTool object at 0x7f38e836aed0>\", \"input\": {}}\\nOutput: {\"content\": \"Closed: /home/code/exploration/eda.ipynb\", \"is_error\": false}\\n\\n--- Tool Call: CreateNotebookTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.CreateNotebookTool object at 0x7f38e8369e90>\", \"input\": {\"notebook_path\": \"exploration/eda.ipynb\", \"cells\": [{\"cell_type\": \"code\", \"content\": \"import pandas as pd\\\\nimport numpy as np\\\\nimport json\\\\nimport matplotlib.pyplot as plt\\\\nimport seaborn as ...\\nOutput: {\"content\": \"Created: /home/code/exploration/exploration/eda.ipynb\\\\n\\\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\", \"is_error\": false}\\n\\n--- Tool Call: ExecuteCellRangeTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 0, \"end_cell\": 0, \"duration\": 30}}\\nOutput: {\"content\": \"Executed cells 0-0\\\\n==================================================\\\\n\\\\nCell 0:\\\\n```\\\\nimport pandas as pd\\\\nimport numpy as np\\\\nimport json\\\\nimport matplotlib.pyplot as plt\\\\nimport seaborn as sns\\\\n\\\\n# Load the training data\\\\ntrain_path = \\'/home/data/train.json\\'\\\\nwith open(train_path, \\'...\\n\\n--- Tool Call: AddNotebookCellTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Convert to DataFrame for easier analysis\\\\ndf = pd.DataFrame(train_data)\\\\n\\\\n# Analyze target distribution\\\\ntarget_counts = df[\\'requester_received_pizza\\'].va...\\nOutput: {\"content\": \"Added code cell at 1\", \"is_error\": false}\\n\\n--- Tool Call: ExecuteCellRangeTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 1, \"end_cell\": 1, \"duration\": 30}}\\nOutput: {\"content\": \"Executed cells 1-1\\\\n==================================================\\\\n\\\\nCell 1:\\\\n```\\\\n# Convert to DataFrame for easier analysis\\\\ndf = pd.DataFrame(train_data)\\\\n\\\\n# Analyze target distribution\\\\ntarget_counts = df[\\'requester_received_pizza\\'].value_counts()\\\\ntarget_pct = df[\\'requester_r...\\n\\n--- Tool Call: AddNotebookCellTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Analyze text features\\\\nprint(\\\\\"Text Features Analysis:\\\\\")\\\\nprint(f\\\\\"Request title length (chars): {df[\\'request_title\\'].str.len().describe()}\\\\\")\\\\nprint(f\\\\\"\\\\...\\nOutput: {\"content\": \"Added code cell at 2\", \"is_error\": false}\\n\\n--- Tool Call: ExecuteCellRangeTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 2, \"end_cell\": 2, \"duration\": 30}}\\nOutput: {\"content\": \"Executed cells 2-2\\\\n==================================================\\\\n\\\\nCell 2:\\\\n```\\\\n# Analyze text features\\\\nprint(\\\\\"Text Features Analysis:\\\\\")\\\\nprint(f\\\\\"Request title length (chars): {df[\\'request_title\\'].str.len().describe()}\\\\\")\\\\nprint(f\\\\\"\\\\\\\\nRequest text length (chars): {df[\\'reques...\\n\\n--- Tool Call: AddNotebookCellTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x7f38e836a6d0>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Analyze numerical/meta-data features\\\\nnumerical_features = [\\\\n    \\'requester_account_age_in_days_at_request\\',\\\\n    \\'requester_number_of_comments_at_request...\\nOutput: {\"content\": \"Added code cell at 3\", \"is_error\": false}\\n\\n--- Tool Call: ExecuteCellRangeTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x7f38e836a210>\", \"input\": {\"start_cell\": 3, \"end_cell\": 3, \"duration\": 30}}\\nOutput: {\"content\": \"Executed cells 3-3\\\\n==================================================\\\\n\\\\nCell 3:\\\\n```\\\\n# Analyze numerical/meta-data features\\\\nnumerical_features = [\\\\n    \\'requester_account_age_in_days_at_request\\',\\\\n    \\'requester_number_of_comments_at_request\\', \\\\n    \\'requester_number_of_posts_at_req...\\n\\n--- Tool Call: WebSearchTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What are winning approaches for text classification competitions on Kaggle that combine text and meta-data features?\"}}\\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\\\n==================================================\\\\n\\\\n--- Result 1 ---\\\\nTitle: ANSWER\\\\n\\\\nContent:\\\\nWinning solutions in Kaggle text‚Äëclassification contests usually blend strong language‚Äëmodel representations with carefully engineered meta‚Äëdata features, then st...\\n\\n--- Tool Call: WebSearchTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"How do Kaggle winners handle class imbalance in binary classification competitions with 3:1 ratio?\"}}\\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\\\n==================================================\\\\n\\\\n--- Result 1 ---\\\\nTitle: ANSWER\\\\n\\\\nContent:\\\\nKaggle winners typically tame a 3\\u202f:\\u202f1 binary‚Äëclass imbalance with a short, repeatable workflow that combines data‚Äëlevel tricks and model‚Äëlevel adjustments\\u202f‚Äî\\u202fall b...\\n\\n--- Tool Call: WebSearchTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What feature engineering techniques work best for combining text and categorical meta-data features in Kaggle competitions?\"}}\\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\\\n==================================================\\\\n\\\\n--- Result 1 ---\\\\nTitle: ANSWER\\\\n\\\\nContent:\\\\nCombining free‚Äëform text with categorical meta‚Äëdata in Kaggle contests is most often tackled by turning the non‚Äëtext fields into a textual representation that a t...\\n\\n--- Tool Call: WebSearchTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What ensembling strategies work best for text classification competitions on Kaggle?\"}}\\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\\\n==================================================\\\\n\\\\n--- Result 1 ---\\\\nTitle: ANSWER\\\\n\\\\nContent:\\\\nEnsembling is the de‚Äëfacto standard for winning Kaggle text‚Äëclassification contests.  The most reliable recipe combines **diverse fine‚Äëtuned language models** (e....\\n\\n--- Tool Call: WebSearchTool ---\\nInput: {\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x7f38e8369d50>\", \"input\": {\"query\": \"What hyperparameter optimization techniques work best for text classification models in Kaggle competitions?\"}}\\nOutput: {\"content\": \"SEARCH RESULTS (9 found)\\\\n==================================================\\\\n\\\\n--- Result 1 ---\\\\nTitle: ANSWER\\\\n\\\\nContent:\\\\nAs of\\u202fJan\\u202f9\\u202f2026, Bayesian‚Äëbased optimizers such as Optuna (or Hyperopt) paired with early‚Äëstopping and learning‚Äërate scheduling, and scalable parallel search too...\\n\\n--- Tool Call: WebSearchTool ---\\nInp\\n\\nUse the reward function rubric to score progress and identify failed calls.'}]",
        "llm.input_tokens": 7452,
        "llm.output_tokens": 961,
        "llm.total_tokens": 8413,
        "llm.latency_ms": 10374.329566955566,
        "llm.completion": "SCORE=0.6 TRIGGER=0\n{\n  \"score\": 0.6,\n  \"trigger_rl\": false,\n  \"llm_calls_to_rl\": [],\n  \"overall_failure_reason\": \"Initial EDA performed successfully; minor notebook errors overcome. No major failures or rule violations observed.\"\n}",
        "llm.cost_usd": 0.036771
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "0ba2a54e35250b4b",
      "parent_span_id": "4aaf3e79af5251e4",
      "name": "ExplorerAgent",
      "kind": "INTERNAL",
      "start_time": 1767958481631285975,
      "end_time": 1767959099566973511,
      "duration": 617.935687536,
      "status": {
        "status_code": "ERROR",
        "description": "ExplorationTimeoutException: ExplorationTimeoutException"
      },
      "attributes": {
        "cascade.span_type": "agent",
        "cascade.agent_name": "ExplorerAgent"
      },
      "events": [
        {
          "name": "exception",
          "timestamp": 1767959099566483861,
          "attributes": {
            "exception.type": "agent_v7_live.agents.explorer_agent.exceptions.ExplorationTimeoutException",
            "exception.message": "ExplorationTimeoutException",
            "exception.stacktrace": "Traceback (most recent call last):\n  File \"/opt/conda/envs/agent/lib/python3.11/site-packages/cascade/tracing.py\", line 354, in trace_agent\n    yield span\n  File \"/home/agent/agent_v7_live/main.py\", line 490, in run_explorer\n    await agent.run()\n  File \"/home/agent/agent_v7_live/agents/explorer_agent/agent.py\", line 399, in run\n    raise ExplorationTimeoutException(\nagent_v7_live.agents.explorer_agent.exceptions.ExplorationTimeoutException: ExplorationTimeoutException\n",
            "exception.escaped": "False"
          }
        },
        {
          "name": "exception",
          "timestamp": 1767959099566962283,
          "attributes": {
            "exception.type": "agent_v7_live.agents.explorer_agent.exceptions.ExplorationTimeoutException",
            "exception.message": "ExplorationTimeoutException",
            "exception.stacktrace": "Traceback (most recent call last):\n  File \"/opt/conda/envs/agent/lib/python3.11/site-packages/opentelemetry/trace/__init__.py\", line 589, in use_span\n    yield span\n  File \"/opt/conda/envs/agent/lib/python3.11/site-packages/opentelemetry/sdk/trace/__init__.py\", line 1105, in start_as_current_span\n    yield span\n  File \"/opt/conda/envs/agent/lib/python3.11/site-packages/cascade/tracing.py\", line 354, in trace_agent\n    yield span\n  File \"/home/agent/agent_v7_live/main.py\", line 490, in run_explorer\n    await agent.run()\n  File \"/home/agent/agent_v7_live/agents/explorer_agent/agent.py\", line 399, in run\n    raise ExplorationTimeoutException(\nagent_v7_live.agents.explorer_agent.exceptions.ExplorationTimeoutException: ExplorationTimeoutException\n",
            "exception.escaped": "False"
          }
        }
      ]
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "ec38b02ab9dfbf95",
      "parent_span_id": "128d4bd68955796b",
      "name": "ReadTool",
      "kind": "INTERNAL",
      "start_time": 1767959105633815030,
      "end_time": 1767959105634096711,
      "duration": 0.000281681,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ReadTool",
        "cascade.agent_name": "ExecutorAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x7f38e9db0750>\", \"input\": {\"file_path\": \"/home/code/session_state.json\"}}",
        "tool.output": "{\"content\": \"{\\n  \\\"workspace_dir\\\": \\\"/home/code\\\",\\n  \\\"competition_id\\\": \\\"random-acts-of-pizza\\\",\\n  \\\"metric_direction\\\": false,\\n  \\\"start_time\\\": \\\"2026-01-09T11:34:39.750696\\\",\\n  \\\"time_limit_minutes\\\": 1440,\\n  \\\"experiments\\\": [],\\n  \\\"candidates\\\": [],\\n  \\\"submissions\\\": [],\\n  \\\"strategy_history\\\": [],\\n  \\\"feedback_history\\\": [],\\n  \\\"data_findings\\\": [],\\n  \\\"web_research\\\": [\\n    {\\n      \\\"query\\\": \\\"What are winning approaches for text classification with tabular features on Kaggle?\\\",\\n      \\\"finding\\\": \\\"Winning Kaggle solutions for problems that mix free\\\\u2011text columns with ordinary numeric or categorical fields treat the data as **multimodal** and deliberately combine a strong NLP encoder with classic tabular learners.  In practice the most reliable recipe is a three\\\\u2011step pipeline:  \\\\n\\\\n1. **Encode the raw text** with a pretrained transformer (e.g., BERT, RoBERTa) to obtain dense sentence\\\\u2011level embeddings.  AutoGluon\\\\u2019s\\\\u202f`TextPredictor` can do this automatically and returns embeddings that can be fed to any tabular model\\\\u202f([auto.gluon.ai](https://auto.gluon.ai/0.7.0/tutorials/tabular_prediction/tabular-multimodal-text-others.html)).  \\\\n2. **Merge the embeddings with the structured features** \\\\u2013 either by concatenating them to the numeric/categorical matrix (the \\\\u201ctwo\\\\u2011stage\\\\u201d approach evaluated in the multimodal AutoML benchmark\\\\u202f([datasets\\\\u2011benchmarks\\\\u2011proceedings.neurips.cc](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/9bf31c7ff062936a96d3c8bd1f8f2ff3-Abstract-round2.html)))\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"How do Kaggle winners handle class imbalance in binary classification with 75/25 split?\\\",\\n      \\\"finding\\\": \\\"Top Kaggle winners typically tackle a 75\\\\u202f%\\\\u202f/\\\\u202f25\\\\u202f% binary\\\\u2011class split by reshaping the training data and by using metrics and model settings that reward performance on the minority class.\\\\u202fThey combine resampling, class\\\\u2011weighting, and careful validation to keep the imbalance from biasing the model\\\\u202f([Dealing with extremely imbalanced dataset \\\\u2013 Kaggle](https://www.kaggle.com/questions-and-answers/473546);\\\\u202f[Unbalanced data and cross\\\\u2011validation \\\\u2013 Kaggle](https://www.kaggle.com/discussions/questions-and-answers/27589)).\\\\n\\\\n**Step\\\\u2011by\\\\u2011step workflow**\\\\n\\\\n1. **Inspect the split and pick an imbalance\\\\u2011aware metric** \\\\u2013 report AUC\\\\u2011ROC, PR\\\\u2011AUC or log\\\\u2011loss instead of plain accuracy, because these metrics reflect minority\\\\u2011class performance\\\\u202f([Unbalanced data and cross\\\\u2011validation \\\\u2013 Kaggle](https://www.kaggle.com/discussions/questions-and-answers/27589)).  \\\\n\\\\n2. **Apply resampling to the training folds**  \\\\n   * *Undersample* the majority (75\\\\u202f%) class to a manageable size, or  \\\\n   * *Oversample* the minority (25\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"What are winning approaches for text classification competitions on Kaggle that combine text and meta-data features?\\\",\\n      \\\"finding\\\": \\\"Winning solutions in Kaggle text\\\\u2011classification contests usually blend strong language\\\\u2011model representations with carefully engineered meta\\\\u2011data features, then stack or ensemble the resulting models.  The most successful pipelines start by extracting dense embeddings from pretrained transformers (e.g.,\\\\u202fBERT, RoBERTa) or fast\\\\u2011text vectors for the raw text, while simultaneously turning auxiliary information such as document length, source, author ID, timestamp or categorical tags into numeric features (one\\\\u2011hot, target\\\\u2011encoded, or simple statistics).  These meta\\\\u2011features are concatenated with the text embeddings and fed into a gradient\\\\u2011boosting model (LightGBM, XGBoost) or a shallow neural net, which often outperforms a pure\\\\u2011text model because the extra signals help disambiguate noisy or short inputs.  After the base models are trained, competitors typically blend several variants (different seeds, architectures, or feature sets) using weighted averaging or stacking, and they validate wit\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"How do Kaggle winners handle class imbalance in binary classification competitions with 3:1 ratio?\\\",\\n      \\\"finding\\\": \\\"Kaggle winners typically tame a 3\\\\u202f:\\\\u202f1 binary\\\\u2011class imbalance with a short, repeatable workflow that combines data\\\\u2011level tricks and model\\\\u2011level adjustments\\\\u202f\\\\u2014\\\\u202fall backed by the same practices discussed in Kaggle\\\\u2019s own discussions and competition post\\\\u2011mortems\\\\u202f([Unbalanced data and cross\\\\u2011validation](https://www.kaggle.com/discussions/questions-and-answers/27589); [Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions](https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions)):\\\\n\\\\n1. **Create stratified folds** so each training/validation split preserves the 3\\\\u202f:\\\\u202f1 ratio, preventing the model from seeing a skewed distribution during CV.  \\\\n\\\\n2. **Apply a sampling strategy** to the training data:  \\\\n   - *Oversample* the minority class (e.g., SMOTE or simple random replication) or  \\\\n   - *Undersample* the majority class to a more balanced mix. The `imbalanced\\\\u2011learn` library is a common starting point\\\\u202f([Unbalanced data and cr\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"What feature engineering techniques work best for combining text and categorical meta-data features in Kaggle competitions?\\\",\\n      \\\"finding\\\": \\\"Combining free\\\\u2011form text with categorical meta\\\\u2011data in Kaggle contests is most often tackled by turning the non\\\\u2011text fields into a textual representation that a transformer can ingest directly.  A simple and surprisingly effective recipe is to join the raw text, numeric values and categorical labels into one string separated by a special token (e.g.,\\\\u202f`[SEP]`).  In FreeAgent\\\\u2019s bank\\\\u2011transaction classifier the transaction description, amount and industry were concatenated as\\\\u202f`Plastic pipes [SEP] -7.99 [SEP] Plumbing`, allowing a single fine\\\\u2011tuned transformer to learn from all modalities at once\\\\u202f([engineering.freeagent.com](https://engineering.freeagent.com/2024/05/17/combining-text-with-numerical-and-categorical-features-for-classification)).  An even more natural variant is to prepend the categorical information to the review text, treating it as additional \\\\u201cwords\\\\u201d.  In a Kaggle\\\\u2011style clothing\\\\u2011review dataset this \\\\u201cfeatures\\\\u2011to\\\\u2011text\\\\u201d strategy consistently outperformed more elaborate baseli\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"What ensembling strategies work best for text classification competitions on Kaggle?\\\",\\n      \\\"finding\\\": \\\"Ensembling is the de\\\\u2011facto standard for winning Kaggle text\\\\u2011classification contests.  The most reliable recipe combines **diverse fine\\\\u2011tuned language models** (e.g., BERT, RoBERTa, DeBERTa, GPT\\\\u2011based classifiers) and aggregates their outputs with a **simple blending or voting step** before feeding the blended predictions into a **second\\\\u2011level meta\\\\u2011model**.  Studies that collected predictions from five large fine\\\\u2011tuned models across six datasets showed that even straightforward averaging or majority\\\\u2011vote ensembles consistently lift accuracy and give better uncertainty estimates than any single model\\\\u202f([arxiv.org/html/2410.19889v1](https://arxiv.org/html/2410.19889v1)).  For classification, using the **geometric mean of class probabilities** (instead of a plain arithmetic mean) often yields a small but steady gain\\\\u202f([campus.datacamp.com](https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/modeling?ex=8)).  When the ensemble contains many heterogeneous LLMs, a **major\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"What hyperparameter optimization techniques work best for text classification models in Kaggle competitions?\\\",\\n      \\\"finding\\\": \\\"As of\\\\u202fJan\\\\u202f9\\\\u202f2026, Bayesian\\\\u2011based optimizers such as Optuna (or Hyperopt) paired with early\\\\u2011stopping and learning\\\\u2011rate scheduling, and scalable parallel search tools like Ray\\\\u202fTune, are reported to give the best results for text\\\\u2011classification models in Kaggle competitions, outperforming manual grid or random search\\\\u202f([datascience.stackexchange.com](https://datascience.stackexchange.com/questions/124709/what-methods-do-top-kagglers-employ-for-score-gain),\\\\u202f[tw\\\\u200bdatascience.com](https://towardsdatascience.com/the-kaggle-way-to-tune-hyperparameters-with-optuna-285e59a0b95a),\\\\u202f[huggingface.co](https://huggingface.co/blog/ray-tune)).\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"What text data augmentation techniques are most effective for improving text classification model performance in Kaggle competitions?\\\",\\n      \\\"finding\\\": \\\"Text data augmentation is a cornerstone of winning Kaggle text\\\\u2011classification solutions because it expands limited training sets, reduces over\\\\u2011fitting, and mimics the linguistic variability seen in real\\\\u2011world data.  The most consistently effective tricks, as reported by a Kaggle master and validated in recent research, are the **Easy Data Augmentation (EDA)** operations \\\\u2013 synonym replacement, random insertion, random swap, and random deletion \\\\u2013 which are simple to implement yet give large gains, especially on small\\\\u2011to\\\\u2011medium datasets ([Neptune\\\\u202fAI](https://neptune.ai/blog/data-augmentation-nlp),\\\\u202f2023;\\\\u202f[Wei & Zou\\\\u202f2019](https://arxiv.org/abs/1901.11196)).  Building on EDA, practitioners add **back\\\\u2011translation** (translate to another language and back) and **contextual word replacement** using pretrained language models (e.g., BERT, RoBERTa) to generate fluent paraphrases that preserve label semantics.  Word\\\\u2011embedding\\\\u2011based synonym swaps and character\\\\u2011level noise (swap or delete characters\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    }\\n  ]\\n}\", \"is_error\": false}",
        "tool.duration_ms": 0.2624988555908203
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "ab0c209229eef633",
      "parent_span_id": "128d4bd68955796b",
      "name": "ReadTool",
      "kind": "INTERNAL",
      "start_time": 1767959110837769886,
      "end_time": 1767959110838048395,
      "duration": 0.000278509,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ReadTool",
        "cascade.agent_name": "ExecutorAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x7f38e9db0750>\", \"input\": {\"file_path\": \"/home/code/session_state.json\"}}",
        "tool.output": "{\"content\": \"{\\n  \\\"workspace_dir\\\": \\\"/home/code\\\",\\n  \\\"competition_id\\\": \\\"random-acts-of-pizza\\\",\\n  \\\"metric_direction\\\": false,\\n  \\\"start_time\\\": \\\"2026-01-09T11:34:39.750696\\\",\\n  \\\"time_limit_minutes\\\": 1440,\\n  \\\"experiments\\\": [],\\n  \\\"candidates\\\": [],\\n  \\\"submissions\\\": [],\\n  \\\"strategy_history\\\": [],\\n  \\\"feedback_history\\\": [],\\n  \\\"data_findings\\\": [],\\n  \\\"web_research\\\": [\\n    {\\n      \\\"query\\\": \\\"What are winning approaches for text classification with tabular features on Kaggle?\\\",\\n      \\\"finding\\\": \\\"Winning Kaggle solutions for problems that mix free\\\\u2011text columns with ordinary numeric or categorical fields treat the data as **multimodal** and deliberately combine a strong NLP encoder with classic tabular learners.  In practice the most reliable recipe is a three\\\\u2011step pipeline:  \\\\n\\\\n1. **Encode the raw text** with a pretrained transformer (e.g., BERT, RoBERTa) to obtain dense sentence\\\\u2011level embeddings.  AutoGluon\\\\u2019s\\\\u202f`TextPredictor` can do this automatically and returns embeddings that can be fed to any tabular model\\\\u202f([auto.gluon.ai](https://auto.gluon.ai/0.7.0/tutorials/tabular_prediction/tabular-multimodal-text-others.html)).  \\\\n2. **Merge the embeddings with the structured features** \\\\u2013 either by concatenating them to the numeric/categorical matrix (the \\\\u201ctwo\\\\u2011stage\\\\u201d approach evaluated in the multimodal AutoML benchmark\\\\u202f([datasets\\\\u2011benchmarks\\\\u2011proceedings.neurips.cc](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/9bf31c7ff062936a96d3c8bd1f8f2ff3-Abstract-round2.html)))\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"How do Kaggle winners handle class imbalance in binary classification with 75/25 split?\\\",\\n      \\\"finding\\\": \\\"Top Kaggle winners typically tackle a 75\\\\u202f%\\\\u202f/\\\\u202f25\\\\u202f% binary\\\\u2011class split by reshaping the training data and by using metrics and model settings that reward performance on the minority class.\\\\u202fThey combine resampling, class\\\\u2011weighting, and careful validation to keep the imbalance from biasing the model\\\\u202f([Dealing with extremely imbalanced dataset \\\\u2013 Kaggle](https://www.kaggle.com/questions-and-answers/473546);\\\\u202f[Unbalanced data and cross\\\\u2011validation \\\\u2013 Kaggle](https://www.kaggle.com/discussions/questions-and-answers/27589)).\\\\n\\\\n**Step\\\\u2011by\\\\u2011step workflow**\\\\n\\\\n1. **Inspect the split and pick an imbalance\\\\u2011aware metric** \\\\u2013 report AUC\\\\u2011ROC, PR\\\\u2011AUC or log\\\\u2011loss instead of plain accuracy, because these metrics reflect minority\\\\u2011class performance\\\\u202f([Unbalanced data and cross\\\\u2011validation \\\\u2013 Kaggle](https://www.kaggle.com/discussions/questions-and-answers/27589)).  \\\\n\\\\n2. **Apply resampling to the training folds**  \\\\n   * *Undersample* the majority (75\\\\u202f%) class to a manageable size, or  \\\\n   * *Oversample* the minority (25\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"What are winning approaches for text classification competitions on Kaggle that combine text and meta-data features?\\\",\\n      \\\"finding\\\": \\\"Winning solutions in Kaggle text\\\\u2011classification contests usually blend strong language\\\\u2011model representations with carefully engineered meta\\\\u2011data features, then stack or ensemble the resulting models.  The most successful pipelines start by extracting dense embeddings from pretrained transformers (e.g.,\\\\u202fBERT, RoBERTa) or fast\\\\u2011text vectors for the raw text, while simultaneously turning auxiliary information such as document length, source, author ID, timestamp or categorical tags into numeric features (one\\\\u2011hot, target\\\\u2011encoded, or simple statistics).  These meta\\\\u2011features are concatenated with the text embeddings and fed into a gradient\\\\u2011boosting model (LightGBM, XGBoost) or a shallow neural net, which often outperforms a pure\\\\u2011text model because the extra signals help disambiguate noisy or short inputs.  After the base models are trained, competitors typically blend several variants (different seeds, architectures, or feature sets) using weighted averaging or stacking, and they validate wit\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"How do Kaggle winners handle class imbalance in binary classification competitions with 3:1 ratio?\\\",\\n      \\\"finding\\\": \\\"Kaggle winners typically tame a 3\\\\u202f:\\\\u202f1 binary\\\\u2011class imbalance with a short, repeatable workflow that combines data\\\\u2011level tricks and model\\\\u2011level adjustments\\\\u202f\\\\u2014\\\\u202fall backed by the same practices discussed in Kaggle\\\\u2019s own discussions and competition post\\\\u2011mortems\\\\u202f([Unbalanced data and cross\\\\u2011validation](https://www.kaggle.com/discussions/questions-and-answers/27589); [Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions](https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions)):\\\\n\\\\n1. **Create stratified folds** so each training/validation split preserves the 3\\\\u202f:\\\\u202f1 ratio, preventing the model from seeing a skewed distribution during CV.  \\\\n\\\\n2. **Apply a sampling strategy** to the training data:  \\\\n   - *Oversample* the minority class (e.g., SMOTE or simple random replication) or  \\\\n   - *Undersample* the majority class to a more balanced mix. The `imbalanced\\\\u2011learn` library is a common starting point\\\\u202f([Unbalanced data and cr\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"What feature engineering techniques work best for combining text and categorical meta-data features in Kaggle competitions?\\\",\\n      \\\"finding\\\": \\\"Combining free\\\\u2011form text with categorical meta\\\\u2011data in Kaggle contests is most often tackled by turning the non\\\\u2011text fields into a textual representation that a transformer can ingest directly.  A simple and surprisingly effective recipe is to join the raw text, numeric values and categorical labels into one string separated by a special token (e.g.,\\\\u202f`[SEP]`).  In FreeAgent\\\\u2019s bank\\\\u2011transaction classifier the transaction description, amount and industry were concatenated as\\\\u202f`Plastic pipes [SEP] -7.99 [SEP] Plumbing`, allowing a single fine\\\\u2011tuned transformer to learn from all modalities at once\\\\u202f([engineering.freeagent.com](https://engineering.freeagent.com/2024/05/17/combining-text-with-numerical-and-categorical-features-for-classification)).  An even more natural variant is to prepend the categorical information to the review text, treating it as additional \\\\u201cwords\\\\u201d.  In a Kaggle\\\\u2011style clothing\\\\u2011review dataset this \\\\u201cfeatures\\\\u2011to\\\\u2011text\\\\u201d strategy consistently outperformed more elaborate baseli\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"What ensembling strategies work best for text classification competitions on Kaggle?\\\",\\n      \\\"finding\\\": \\\"Ensembling is the de\\\\u2011facto standard for winning Kaggle text\\\\u2011classification contests.  The most reliable recipe combines **diverse fine\\\\u2011tuned language models** (e.g., BERT, RoBERTa, DeBERTa, GPT\\\\u2011based classifiers) and aggregates their outputs with a **simple blending or voting step** before feeding the blended predictions into a **second\\\\u2011level meta\\\\u2011model**.  Studies that collected predictions from five large fine\\\\u2011tuned models across six datasets showed that even straightforward averaging or majority\\\\u2011vote ensembles consistently lift accuracy and give better uncertainty estimates than any single model\\\\u202f([arxiv.org/html/2410.19889v1](https://arxiv.org/html/2410.19889v1)).  For classification, using the **geometric mean of class probabilities** (instead of a plain arithmetic mean) often yields a small but steady gain\\\\u202f([campus.datacamp.com](https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/modeling?ex=8)).  When the ensemble contains many heterogeneous LLMs, a **major\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"What hyperparameter optimization techniques work best for text classification models in Kaggle competitions?\\\",\\n      \\\"finding\\\": \\\"As of\\\\u202fJan\\\\u202f9\\\\u202f2026, Bayesian\\\\u2011based optimizers such as Optuna (or Hyperopt) paired with early\\\\u2011stopping and learning\\\\u2011rate scheduling, and scalable parallel search tools like Ray\\\\u202fTune, are reported to give the best results for text\\\\u2011classification models in Kaggle competitions, outperforming manual grid or random search\\\\u202f([datascience.stackexchange.com](https://datascience.stackexchange.com/questions/124709/what-methods-do-top-kagglers-employ-for-score-gain),\\\\u202f[tw\\\\u200bdatascience.com](https://towardsdatascience.com/the-kaggle-way-to-tune-hyperparameters-with-optuna-285e59a0b95a),\\\\u202f[huggingface.co](https://huggingface.co/blog/ray-tune)).\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    },\\n    {\\n      \\\"query\\\": \\\"What text data augmentation techniques are most effective for improving text classification model performance in Kaggle competitions?\\\",\\n      \\\"finding\\\": \\\"Text data augmentation is a cornerstone of winning Kaggle text\\\\u2011classification solutions because it expands limited training sets, reduces over\\\\u2011fitting, and mimics the linguistic variability seen in real\\\\u2011world data.  The most consistently effective tricks, as reported by a Kaggle master and validated in recent research, are the **Easy Data Augmentation (EDA)** operations \\\\u2013 synonym replacement, random insertion, random swap, and random deletion \\\\u2013 which are simple to implement yet give large gains, especially on small\\\\u2011to\\\\u2011medium datasets ([Neptune\\\\u202fAI](https://neptune.ai/blog/data-augmentation-nlp),\\\\u202f2023;\\\\u202f[Wei & Zou\\\\u202f2019](https://arxiv.org/abs/1901.11196)).  Building on EDA, practitioners add **back\\\\u2011translation** (translate to another language and back) and **contextual word replacement** using pretrained language models (e.g., BERT, RoBERTa) to generate fluent paraphrases that preserve label semantics.  Word\\\\u2011embedding\\\\u2011based synonym swaps and character\\\\u2011level noise (swap or delete characters\\\",\\n      \\\"agent\\\": \\\"explorer\\\"\\n    }\\n  ]\\n}\", \"is_error\": false}",
        "tool.duration_ms": 0.2524852752685547
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "f892bc4f70d4c359",
      "parent_span_id": "128d4bd68955796b",
      "name": "ListFilesTool",
      "kind": "INTERNAL",
      "start_time": 1767959124168880348,
      "end_time": 1767959124169099774,
      "duration": 0.000219426,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ListFilesTool",
        "cascade.agent_name": "ExecutorAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x7f3b0205a250>\", \"input\": {\"directory_path\": \"/home/data\"}}",
        "tool.output": "{\"content\": \"/home/data:\\n[FILE] description.md (7.0KB)\\n[FILE] sampleSubmission.csv (13.0KB)\\n[FILE] test.json (2.0MB)\\n[FILE] test.zip (433.1KB)\\n[FILE] train.json (8.4MB)\\n[FILE] train.zip (1.3MB)\", \"is_error\": false}",
        "tool.duration_ms": 0.2703666687011719
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "7856b8c1ded84c04",
      "parent_span_id": "128d4bd68955796b",
      "name": "ReadTool",
      "kind": "INTERNAL",
      "start_time": 1767959135191736842,
      "end_time": 1767959135192053430,
      "duration": 0.000316588,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ReadTool",
        "cascade.agent_name": "ExecutorAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x7f38e9db0750>\", \"input\": {\"file_path\": \"/home/data/description.md\"}}",
        "tool.output": "{\"content\": \"# Overview\\n\\n## Description\\n\\n[Get started on this competition through Kaggle Scripts](https://www.kaggle.com/c/random-acts-of-pizza/forums/t/14286/kaggle-scripts-enabled-on-random-acts-of-pizza)\\n\\nIn machine learning, it is often said¬†there are¬†[no free lunches](http://en.wikipedia.org/wiki/No_free_lunch_theorem).¬†*How wrong we were.*\\n\\nThis competition contains a dataset with 5671 textual requests for pizza from the Reddit community¬†[Random Acts of Pizza](http://www.reddit.com/r/Random_Acts_Of_Pizza/)¬†together with their outcome (successful/unsuccessful) and meta-data. Participants must create an algorithm¬†capable of predicting¬†which requests will garner a cheesy (but sincere!) act of¬†kindness.\\n\\n\\\"I'll write a poem, sing a song, do a dance, play an instrument, whatever! I just want a pizza,\\\" says one hopeful poster. What about making an algorithm?\\n\\n![Pizzas](https://storage.googleapis.com/kaggle-media/competitions/kaggle/3949/media/pizzas.png)\\n\\nKaggle is hosting this competition for the machine learning community to use for fun and practice. This¬†[data](http://cs.stanford.edu/~althoff/raop-dataset/)¬†was collected and graciously shared by¬†[Althoff](http://www.timalthoff.com/)¬†et al. (Buy them a pizza -- data collection is a thankless and tedious job!) We encourage participants to explore their¬†[accompanying paper](http://cs.stanford.edu/~althoff/raop-dataset/altruistic_requests_icwsm.pdf)¬†and ask that you cite the following reference in any publications that result from your work:\\n\\nTim Althoff, Cristian Danescu-Niculescu-Mizil, Dan Jurafsky.¬†*How to Ask for a Favor: A Case Study on the Success of Altruistic Requests*,¬†Proceedings of ICWSM, 2014.\\n\\n~*Pizza icons designed by Matthew Dera from the¬†[Noun Project](http://thenounproject.com/term/pizza/30194/)*~\\n\\n### Evaluation\\n\\nSubmissions are evaluated on¬†[area under the ROC curve](http://en.wikipedia.org/wiki/Receiver_operating_characteristic)¬†between the predicted probability that a request will get pizza and the observed outcomes.\\n\\n### Submission File\\n\\nFor each request¬†in the test set, you should predict a real-valued probability that it resulted in a pizza. The file should contain a header and have the following format:\\n\\n```\\nrequest_id,requester_received_pizza\\nt3_i8iy4,0\\nt3_1mfqi0,0\\nt3_lclka,0\\n...\\n...\\n```\\n\\n### Citation\\n\\nWill Cukierski. (2014). Random Acts of Pizza. Kaggle. https://kaggle.com/competitions/random-acts-of-pizza\\n\\n\\n# Data\\n\\n## Dataset Description\\n\\n[See, fork, and run a random forest benchmark model through Kaggle Scripts](https://www.kaggle.com/users/993/ben-hamner/random-acts-of-pizza/simple-julia-benchmark)\\n\\nThis dataset includes 5671 requests collected from the Reddit community¬†[Random Acts of Pizza](http://www.reddit.com/r/Random_Acts_Of_Pizza/)¬†between December 8, 2010 and September 29, 2013 (retrieved on September 30, 2013).¬†All requests ask for the same thing: a free pizza. The outcome of each request -- whether its author received a pizza or not -- is known.¬†Meta-data includes information such as: time of the request, activity of the requester, community-age of the requester, etc.\\n\\nEach JSON¬†entry corresponds to one request (the first and only request by the requester on Random Acts of Pizza). We have removed fields from the test set which would not be available at the time of posting.\\n\\n## Data fields\\n\\n\\\"giver_username_if_known\\\": Reddit username of giver if known, i.e. the person satisfying the request (\\\"N/A\\\" otherwise).\\n\\n\\\"number_of_downvotes_of_request_at_retrieval\\\": Number of downvotes at the time the request was collected.\\n\\n\\\"number_of_upvotes_of_request_at_retrieval\\\": Number of upvotes at the time the request was collected.\\n\\n\\\"post_was_edited\\\": Boolean indicating whether this post was edited (from Reddit).\\n\\n\\\"request_id\\\": Identifier of the post on Reddit, e.g. \\\"t3_w5491\\\".\\n\\n\\\"request_number_of_comments_at_retrieval\\\": Number of comments for the request at time of retrieval.\\n\\n\\\"request_text\\\": Full text of the request.\\n\\n\\\"request_text_edit_aware\\\": Edit aware version of \\\"request_text\\\". We use a set of rules to strip edited comments indicating the success of the request such as \\\"EDIT: Thanks /u/foo, the pizza was delicous\\\".\\n\\n\\\"request_title\\\": Title of the request.\\n\\n\\\"requester_account_age_in_days_at_request\\\": Account age of requester in days at time of request.\\n\\n\\\"requester_account_age_in_days_at_retrieval\\\": Account age of requester in days at time of retrieval.\\n\\n\\\"requester_days_since_first_post_on_raop_at_request\\\": Number of days between requesters first post on RAOP and this request (zero if requester has never posted before on RAOP).\\n\\n\\\"requester_days_since_first_post_on_raop_at_retrieval\\\": Number of days between requesters first post on RAOP and time of retrieval.\\n\\n\\\"requester_number_of_comments_at_request\\\": Total number of comments on Reddit by requester at time of request.\\n\\n\\\"requester_number_of_comments_at_retrieval\\\": Total number of comments on Reddit by requester at time of retrieval.\\n\\n\\\"requester_number_of_comments_in_raop_at_request\\\": Total number of comments in RAOP by requester at time of request.\\n\\n\\\"requester_number_of_comments_in_raop_at_retrieval\\\": Total number of comments in RAOP by requester at time of retrieval.\\n\\n\\\"requester_number_of_posts_at_request\\\": Total number of posts on Reddit by requester at time of request.\\n\\n\\\"requester_number_of_posts_at_retrieval\\\": Total number of posts on Reddit by requester at time of retrieval.\\n\\n\\\"requester_number_of_posts_on_raop_at_request\\\": Total number of posts in RAOP by requester at time of request.\\n\\n\\\"requester_number_of_posts_on_raop_at_retrieval\\\": Total number of posts in RAOP by requester at time of retrieval.\\n\\n\\\"requester_number_of_subreddits_at_request\\\": The number of subreddits in which the author had already posted in at the time of request.\\n\\n\\\"requester_received_pizza\\\": Boolean indicating the success of the request, i.e., whether the requester received pizza.\\n\\n\\\"requester_subreddits_at_request\\\": The list of subreddits in which the author had already posted in at the time of request.\\n\\n\\\"requester_upvotes_minus_downvotes_at_request\\\": Difference of total upvotes and total downvotes of requester at time of request.\\n\\n\\\"requester_upvotes_minus_downvotes_at_retrieval\\\": Difference of total upvotes and total downvotes of requester at time of retrieval.\\n\\n\\\"requester_upvotes_plus_downvotes_at_request\\\": Sum of total upvotes and total downvotes of requester at time of request.\\n\\n\\\"requester_upvotes_plus_downvotes_at_retrieval\\\": Sum of total upvotes and total downvotes of requester at time of retrieval.\\n\\n\\\"requester_user_flair\\\": Users on RAOP receive badges (Reddit calls them flairs) which is a small picture next to their username. In our data set the user flair is either None (neither given nor received pizza, N=4282), \\\"shroom\\\" (received pizza, but not given, N=1306), or \\\"PIF\\\" (pizza given after having received, N=83).\\n\\n\\\"requester_username\\\": Reddit username of requester.\\n\\n\\\"unix_timestamp_of_request\\\": Unix timestamp of request (supposedly in timezone of user, but in most cases it is equal to the UTC timestamp -- which is incorrect since most RAOP users are from the USA).\\n\\n\\\"unix_timestamp_of_request_utc\\\": Unit timestamp of request in UTC.\", \"is_error\": false}",
        "tool.duration_ms": 0.35190582275390625
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "ace5a8ebfae613ef",
      "parent_span_id": "128d4bd68955796b",
      "name": "ReadTool",
      "kind": "INTERNAL",
      "start_time": 1767959141676457002,
      "end_time": 1767959141676920903,
      "duration": 0.000463901,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ReadTool",
        "cascade.agent_name": "ExecutorAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x7f38e9db0750>\", \"input\": {\"file_path\": \"/home/data/sampleSubmission.csv\"}}",
        "tool.output": "{\"content\": \"request_id,requester_received_pizza\\nt3_1aw5zf,0\\nt3_roiuw,0\\nt3_mjnbq,0\\nt3_t8wd1,0\\nt3_1m4zxu,0\\nt3_1jgnj6,0\\nt3_s4o1h,0\\nt3_1dg2a4,0\\nt3_trm7n,0\\nt3_s7k0h,0\\nt3_j2cxp,0\\nt3_jka9v,0\\nt3_lzjvv,0\\nt3_1epr8n,0\\nt3_1j1w1c,0\\nt3_1mx8pz,0\\nt3_l4llm,0\\nt3_m95c2,0\\nt3_yhec5,0\\nt3_kwqew,0\\nt3_121c2k,0\\nt3_m6v9p,0\\nt3_1l8aoa,0\\nt3_pkhyy,0\\nt3_n5je7,0\\nt3_vhvq1,0\\nt3_1o8uuk,0\\nt3_qdwgl,0\\nt3_s0t6p,0\\nt3_zqq84,0\\nt3_17gtl5,0\\nt3_ui761,0\\nt3_jc1u4,0\\nt3_r16t9,0\\nt3_lzkem,0\\nt3_m812c,0\\nt3_sotbx,0\\nt3_qqqde,0\\nt3_q22la,0\\nt3_12nnks,0\\nt3_1jx6ex,0\\nt3_jz46l,0\\nt3_10ukdp,0\\nt3_meys2,0\\nt3_1bo01c,0\\nt3_1g2xtg,0\\nt3_l0zas,0\\nt3_jhqic,0\\nt3_qht9n,0\\nt3_1fttue,0\\nt3_1cflvh,0\\nt3_17ihhv,0\\nt3_1091hq,0\\nt3_khd1w,0\\nt3_j4ms5,0\\nt3_t27zl,0\\nt3_1a94mq,0\\nt3_1i3qda,0\\nt3_1fy1og,0\\nt3_1j65wv,0\\nt3_lmy9r,0\\nt3_rmof0,0\\nt3_170xyf,0\\nt3_x00as,0\\nt3_kod7s,0\\nt3_kaip7,0\\nt3_tu076,0\\nt3_woken,0\\nt3_i9cf1,0\\nt3_jrp9c,0\\nt3_v477d,0\\nt3_hlvzn,0\\nt3_10h4k4,0\\nt3_1484sj,0\\nt3_lhgee,0\\nt3_n4zpe,0\\nt3_11fmfp,0\\nt3_qwy2m,0\\nt3_187oid,0\\nt3_m0nxw,0\\nt3_1g8kf3,0\\nt3_ignyn,0\\nt3_zwf27,0\\nt3_lhi6m,0\\nt3_yte0l,0\\nt3_11hoxm,0\\nt3_t0dvv,0\\nt3_1lulit,0\\nt3_i693s,0\\nt3_19o5oe,0\\nt3_1j64hc,0\\nt3_uhfo4,0\\nt3_16gep8,0\\nt3_1laja1,0\\nt3_14yhq1,0\\nt3_1hpzqs,0\\nt3_11vgte,0\\nt3_mco6j,0\\nt3_wko45,0\\nt3_zrzdo,0\\nt3_flezd,0\\nt3_1mgesx,0\\nt3_jg1tx,0\\nt3_1nd4dt,0\\nt3_189m64,0\\nt3_1ii7cp,0\\nt3_tj0s0,0\\nt3_12p0tt,0\\nt3_13qwpa,0\\nt3_1mdson,0\\nt3_ki3f0,0\\nt3_myf58,0\\nt3_jdy60,0\\nt3_tzuki,0\\nt3_r1cak,0\\nt3_1lbper,0\\nt3_rgg9c,0\\nt3_147zyr,0\\nt3_ihe06,0\\nt3_13jcdx,0\\nt3_zpn24,0\\nt3_1mmlp7,0\\nt3_1azv0d,0\\nt3_1291w9,0\\nt3_huju7,0\\nt3_1en7mg,0\\nt3_1db1jf,0\\nt3_1djsvl,0\\nt3_ts55w,0\\nt3_i8iq7,0\\nt3_n0a4q,0\\nt3_1ihmtb,0\\nt3_1mtdc3,0\\nt3_johrr,0\\nt3_lp00f,0\\nt3_m1rph,0\\nt3_1nb10u,0\\nt3_ywjco,0\\nt3_ys2bs,0\\nt3_pq07v,0\\nt3_1cfb3h,0\\nt3_iyrge,0\\nt3_yv9x1,0\\nt3_1krjd9,0\\nt3_v259r,0\\nt3_lgixi,0\\nt3_12rb3l,0\\nt3_pkin0,0\\nt3_z7mzq,0\\nt3_1j93fd,0\\nt3_jb396,0\\nt3_v0h9r,0\\nt3_xb4nc,0\\nt3_1hpv57,0\\nt3_lyldy,0\\nt3_idwhf,0\\nt3_kfxsm,0\\nt3_1f3ehu,0\\nt3_ux4gp,0\\nt3_j680o,0\\nt3_n36b7,0\\nt3_1kbspq,0\\nt3_lfdif,0\\nt3_jibiu,0\\nt3_wez2u,0\\nt3_hicex,0\\nt3_rcb83,0\\nt3_k5jz6,0\\nt3_1ld1zr,0\\nt3_matz6,0\\nt3_13lllw,0\\nt3_mh8t5,0\\nt3_x7wp5,0\\nt3_1gooei,0\\nt3_1elntj,0\\nt3_j6xaf,0\\nt3_1295t4,0\\nt3_18pvdc,0\\nt3_kfn62,0\\nt3_1lhw18,0\\nt3_mh41r,0\\nt3_lput5,0\\nt3_uj1h7,0\\nt3_nctcy,0\\nt3_rqgfm,0\\nt3_rblfk,0\\nt3_pynup,0\\nt3_ijcon,0\\nt3_wzdfb,0\\nt3_qfcrx,0\\nt3_jkv3u,0\\nt3_t4ez0,0\\nt3_182za3,0\\nt3_k3huv,0\\nt3_jjvsg,0\\nt3_13hmch,0\\nt3_uoddl,0\\nt3_kxvhy,0\\nt3_1ippsx,0\\nt3_17k605,0\\nt3_jfe2h,0\\nt3_q70zy,0\\nt3_i3ms5,0\\nt3_ny71q,0\\nt3_iieek,0\\nt3_irsb9,0\\nt3_1dxr4r,0\\nt3_lcoa8,0\\nt3_nylck,0\\nt3_16soun,0\\nt3_kxh3z,0\\nt3_kwj17,0\\nt3_11z0f9,0\\nt3_y1r33,0\\nt3_llc55,0\\nt3_j4mle,0\\nt3_ma4bd,0\\nt3_ja0xm,0\\nt3_thomi,0\\nt3_1a42uf,0\\nt3_1f2c2c,0\\nt3_13yr6a,0\\nt3_1epzt6,0\\nt3_lkn30,0\\nt3_ma690,0\\nt3_isvki,0\\nt3_1ht64o,0\\nt3_iqne8,0\\nt3_1fmkkt,0\\nt3_158xj0,0\\nt3_106jdn,0\\nt3_jruny,0\\nt3_14sl4k,0\\nt3_1ih4cz,0\\nt3_p5o8n,0\\nt3_k9jlk,0\\nt3_1l7zot,0\\nt3_1jx6nd,0\\nt3_ucleb,0\\nt3_1na78p,0\\nt3_10i6xc,0\\nt3_1mg1x9,0\\nt3_swk1k,0\\nt3_198a81,0\\nt3_p3j6h,0\\nt3_144v2r,0\\nt3_1lrg7w,0\\nt3_1n2fv2,0\\nt3_qsar9,0\\nt3_1kla7d,0\\nt3_144qbb,0\\nt3_qe4zn,0\\nt3_ic3dt,0\\nt3_p7iuv,0\\nt3_1ii4ol,0\\nt3_xb0l7,0\\nt3_xljod,0\\nt3_xz1f7,0\\nt3_hxha3,0\\nt3_1fxzpb,0\\nt3_jray4,0\\nt3_o8zvp,0\\nt3_1j6f12,0\\nt3_kai9o,0\\nt3_11zb19,0\\nt3_mz7kn,0\\nt3_icsm3,0\\nt3_lj9bn,0\\nt3_1jtr9y,0\\nt3_wdbar,0\\nt3_1moe8s,0\\nt3_o450c,0\\nt3_nwtb9,0\\nt3_ienv4,0\\nt3_vb27s,0\\nt3_1j4lyi,0\\nt3_1c796y,0\\nt3_121puf,0\\nt3_1loan8,0\\nt3_1imqzn,0\\nt3_m22z8,0\\nt3_1izqab,0\\nt3_1b9snd,0\\nt3_icsqz,0\\nt3_u3lgo,0\\nt3_n955o,0\\nt3_loudp,0\\nt3_11um5c,0\\nt3_kemps,0\\nt3_16ni9v,0\\nt3_ny0r1,0\\nt3_1ei0nh,0\\nt3_s71nl,0\\nt3_ieg2u,0\\nt3_1j2fdd,0\\nt3_1jzxz7,0\\nt3_1ih7n3,0\\nt3_j66zi,0\\nt3_jjv8e,0\\nt3_pvpg4,0\\nt3_r3l0v,0\\nt3_v5k8z,0\\nt3_1l7avh,0\\nt3_j7tkt,0\\nt3_oe3zg,0\\nt3_u5j5m,0\\nt3_jr1lq,0\\nt3_1kk8i1,0\\nt3_vk1v9,0\\nt3_mbyo8,0\\nt3_jod1x,0\\nt3_zpqs4,0\\nt3_vc4hg,0\\nt3_u3n8x,0\\nt3_1dbt8e,0\\nt3_p1xpj,0\\nt3_1017ti,0\\nt3_id8n9,0\\nt3_m14x5,0\\nt3_1apfqa,0\\nt3_lx5xj,0\\nt3_1866ui,0\\nt3_n840z,0\\nt3_1bezf4,0\\nt3_nacny,0\\nt3_1dyffq,0\\nt3_ocy5a,0\\nt3_10ogaj,0\\nt3_iaaw6,0\\nt3_1j4f8b,0\\nt3_x88qi,0\\nt3_1fches,0\\nt3_10ny1p,0\\nt3_ilwc6,0\\nt3_krx2p,0\\nt3_119not,0\\nt3_1gu3j5,0\\nt3_1bbbuz,0\\nt3_hxe8a,0\\nt3_j5qdl,0\\nt3_1mz84n,0\\nt3_i4y7l,0\\nt3_ibsys,0\\nt3_ydmzc,0\\nt3_19xmjp,0\\nt3_1l3540,0\\nt3_ktf2k,0\\nt3_k0hn0,0\\nt3_1ek27q,0\\nt3_wyilc,0\\nt3_1kaciz,0\\nt3_lkdh6,0\\nt3_j2o4w,0\\nt3_1czbz2,0\\nt3_vrm0z,0\\nt3_1cpt0u,0\\nt3_14xb3r,0\\nt3_ig6ya,0\\nt3_k6zox,0\\nt3_icbf1,0\\nt3_jak6v,0\\nt3_ni1uh,0\\nt3_i4d2s,0\\nt3_il2qy,0\\nt3_16wajn,0\\nt3_ibx3y,0\\nt3_k4b7c,0\\nt3_1copha,0\\nt3_ktlkm,0\\nt3_qprm5,0\\nt3_iyqth,0\\nt3_yvy67,0\\nt3_ycl16,0\\nt3_1izuji,0\\nt3_jhtmr,0\\nt3_1np61k,0\\nt3_1id2hk,0\\nt3_1enxtb,0\\nt3_yzjva,0\\nt3_13d6ne,0\\nt3_s5apt,0\\nt3_mqba5,0\\nt3_1kwu2y,0\\nt3_1jgf2f,0\\nt3_1a35ag,0\\nt3_lm2ge,0\\nt3_ytyy6,0\\nt3_leh9u,0\\nt3_xoxju,0\\nt3_1mgs2z,0\\nt3_1lngx7,0\\nt3_1jggjo,0\\nt3_14avuh,0\\nt3_ugq11,0\\nt3_jocl9,0\\nt3_1hs29l,0\\nt3_152asi,0\\nt3_l3a1p,0\\nt3_sybz5,0\\nt3_x1fef,0\\nt3_1c6tno,0\\nt3_yhpux,0\\nt3_nztz2,0\\nt3_lza8c,0\\nt3_1lzcwr,0\\nt3_lwhkp,0\\nt3_1dna10,0\\nt3_119rgh,0\\nt3_iapny,0\\nt3_kfk0a,0\\nt3_ibvsg,0\\nt3_o4fyx,0\\nt3_y3g5j,0\\nt3_l6lv4,0\\nt3_1kmqat,0\\nt3_162d1a,0\\nt3_ujkj0,0\\nt3_1erbgm,0\\nt3_ooexu,0\\nt3_19t19f,0\\nt3_ja4e2,0\\nt3_kt4mf,0\\nt3_wt7zz,0\\nt3_1lfquz,0\\nt3_18sldk,0\\nt3_htd91,0\\nt3_1h4w4n,0\\nt3_p8wrm,0\\nt3_154kz8,0\\nt3_sefhh,0\\nt3_1lix8p,0\\nt3_jlxn4,0\\nt3_11wso9,0\\nt3_101z2h,0\\nt3_1j8a3x,0\\nt3_wqh5d,0\\nt3_i7pfu,0\\nt3_wnhw8,0\\nt3_l5prn,0\\nt3_11xfys,0\\nt3_od50u,0\\nt3_im02c,0\\nt3_z5hnc,0\\nt3_l3b0f,0\\nt3_107e7j,0\\nt3_kerxb,0\\nt3_qx22x,0\\nt3_1eje4d,0\\nt3_1mo8zt,0\\nt3_1f84jw,0\\nt3_1j41yg,0\\nt3_1nbc0n,0\\nt3_jp7f2,0\\nt3_15pek8,0\\nt3_id8ti,0\\nt3_1mq5l0,0\\nt3_kgmij,0\\nt3_1mzn97,0\\nt3_1mkuh8,0\\nt3_l0we8,0\\nt3_17ci8s,0\\nt3_p8lc5,0\\nt3_1hdv69,0\\nt3_1loly5,0\\nt3_12f2yv,0\\nt3_uiv13,0\\nt3_jtbys,0\\nt3_j5z5a,0\\nt3_1996pd,0\\nt3_i3p8s,0\\nt3_j61o1,0\\nt3_17ytg3,0\\nt3_qt4v3,0\\nt3_x18at,0\\nt3_li286,0\\nt3_1gzq6z,0\\nt3_18o5oe,0\\nt3_1jg8a9,0\\nt3_sdado,0\\nt3_ibybv,0\\nt3_jl3qt,0\\nt3_m71dy,0\\nt3_j5agd,0\\nt3_kpnkh,0\\nt3_stuny,0\\nt3_1ddgqj,0\\nt3_1embfn,0\\nt3_jpw8a,0\\nt3_q745h,0\\nt3_1ml5ot,0\\nt3_1czj8l,0\\nt3_1fhq21,0\\nt3_1cfm07,0\\nt3_mihxn,0\\nt3_1lbmlb,0\\nt3_1nbkb1,0\\nt3_wzo6q,0\\nt3_v0ale,0\\nt3_lm8kd,0\\nt3_leebc,0\\nt3_idka5,0\\nt3_wkmpp,0\\nt3_kvqy9,0\\nt3_16s4f9,0\\nt3_qsrgg,0\\nt3_1adibf,0\\nt3_1kkqe9,0\\nt3_1laxa0,0\\nt3_j0r6n,0\\nt3_l18ch,0\\nt3_kzxb4,0\\nt3_1c3y33,0\\nt3_1k3bp9,0\\nt3_z2w4j,0\\nt3_s332h,0\\nt3_my19f,0\\nt3_1kbjq5,0\\nt3_wst3o,0\\nt3_v77cz,0\\nt3_jb0kw,0\\nt3_sov1j,0\\nt3_m3daq,0\\nt3_hutzt,0\\nt3_rehrg,0\\nt3_iesyg,0\\nt3_it7hc,0\\nt3_lu03g,0\\nt3_xyx9c,0\\nt3_n47ak,0\\nt3_16wb5q,0\\nt3_1ejygu,0\\nt3_tneil,0\\nt3_soowc,0\\nt3_mvmij,0\\nt3_1iudib,0\\nt3_jrysw,0\\nt3_vbswl,0\\nt3_kri7t,0\\nt3_1mz7p9,0\\nt3_11ti05,0\\nt3_i8n4m,0\\nt3_j0st7,0\\nt3_1lhdz9,0\\nt3_k78hk,0\\nt3_mu4o6,0\\nt3_kppwl,0\\nt3_nj0sk,0\\nt3_1niqoy,0\\nt3_yj539,0\\nt3_xu0dn,0\\nt3_jt3mq,0\\nt3_odnwf,0\\nt3_hux4g,0\\nt3_1j8ixk,0\\nt3_1dekja,0\\nt3_l460b,0\\nt3_1m52rm,0\\nt3_1e7pw1,0\\nt3_hue7e,0\\nt3_1i06ov,0\\nt3_11v41i,0\\nt3_l65kv,0\\nt3_sp1fg,0\\nt3_lqhfe,0\\nt3_15r2ea,0\\nt3_okh6v,0\\nt3_w50hm,0\\nt3_z7xdo,0\\nt3_1mwwu5,0\\nt3_q8zng,0\\nt3_1iayg1,0\\nt3_14vtze,0\\nt3_ryku2,0\\nt3_10aewu,0\\nt3_n2h3z,0\\nt3_vurl4,0\\nt3_n03eb,0\\nt3_rrcc9,0\\nt3_zz6p5,0\\nt3_kysd6,0\\nt3_12r721,0\\nt3_1f6b9w,0\\nt3_xx4f6,0\\nt3_jrd0h,0\\nt3_ide15,0\\nt3_mupj4,0\\nt3_uubek,0\\nt3_jotm5,0\\nt3_jlluy,0\\nt3_i4fmt,0\\nt3_iwjzw,0\\nt3_zvogg,0\\nt3_18yxt1,0\\nt3_oxp5l,0\\nt3_uqp0c,0\\nt3_17nyu7,0\\nt3_hu8l7,0\\nt3_1mjky0,0\\nt3_1kmi1j,0\\nt3_14oyob,0\\nt3_kde1y,0\\nt3_ijlic,0\\nt3_mk98a,0\\nt3_txxhe,0\\nt3_n8wlx,0\\nt3_j2nbu,0\\nt3_hub23,0\\nt3_vv6uo,0\\nt3_1ahck6,0\\nt3_o2vp7,0\\nt3_so8v3,0\\nt3_16sb6h,0\\nt3_1ekg5c,0\\nt3_p4bhk,0\\nt3_10q049,0\\nt3_mmptc,0\\nt3_kmqvq,0\\nt3_kr339,0\\nt3_y87jg,0\\nt3_1ivpg0,0\\nt3_j4gtp,0\\nt3_ifzpe,0\\nt3_junbn,0\\nt3_1mqs3k,0\\nt3_1mg5fg,0\\nt3_x11f8,0\\nt3_r4box,0\\nt3_lm901,0\\nt3_1iv1fe,0\\nt3_1b3bt4,0\\nt3_1fof55,0\\nt3_xc9l0,0\\nt3_k6557,0\\nt3_iqm6n,0\\nt3_lm0l0,0\\nt3_114c6l,0\\nt3_pedfi,0\\nt3_19mdz6,0\\nt3_1211sa,0\\nt3_xeelk,0\\nt3_14ym0h,0\\nt3_ibv3g,0\\nt3_wq5xv,0\\nt3_10opse,0\\nt3_upm24,0\\nt3_1cndjm,0\\nt3_uebcn,0\\nt3_1lel1x,0\\nt3_16f9ay,0\\nt3_n01xw,0\\nt3_14t9hd,0\\nt3_x0ymn,0\\nt3_1f3xe8,0\\nt3_1lhq2y,0\\nt3_urqtw,0\\nt3_16upcl,0\\nt3_nrc9b,0\\nt3_12m4dw,0\\nt3_jbkeh,0\\nt3_1i6486,0\\nt3_1iv92l,0\\nt3_1j8boj,0\\nt3_1iw58q,0\\nt3_1j6osm,0\\nt3_xcdxo,0\\nt3_1eqkcw,0\\nt3_1i5vnp,0\\nt3_w1pfu,0\\nt3_1eeqcs,0\\nt3_rpdiz,0\\nt3_t3uat,0\\nt3_1ayjhe,0\\nt3_13jfrb,0\\nt3_l8bnw,0\\nt3_14tjdf,0\\nt3_kse6r,0\\nt3_1gtb6m,0\\nt3_1mjf8o,0\\nt3_1mh8hd,0\\nt3_1kgiqn,0\\nt3_rdzac,0\\nt3_i98md,0\\nt3_rekw2,0\\nt3_1j57s5,0\\nt3_zkvfi,0\\nt3_1jwjz1,0\\nt3_18zn0d,0\\nt3_1ktyev,0\\nt3_m5ara,0\\nt3_1aex0q,0\\nt3_1l5diu,0\\nt3_lb3k5,0\\nt3_16gdbu,0\\nt3_11lvl7,0\\nt3_ltlev,0\\nt3_1cxvc5,0\\nt3_10pz0s,0\\nt3_1kj23h,0\\nt3_pgkkz,0\\nt3_iqrcx,0\\nt3_1i6786,0\\nt3_11kxvh,0\\nt3_10rvni,0\\nt3_1cta35,0\\nt3_njyij,0\\nt3_hhgic,0\\nt3_1hkyhy,0\\nt3_15nuxv,0\\nt3_icfj2,0\\nt3_p7my1,0\\nt3_phjlw,0\\nt3_1ld5j6,0\\nt3_1is4rs,0\\nt3_10pq58,0\\nt3_w3crb,0\\nt3_nonc4,0\\nt3_1ll0sz,0\\nt3_it4h2,0\\nt3_11pen3,0\\nt3_vcn3x,0\\nt3_1e7t7h,0\\nt3_17aq8d,0\\nt3_1lr3i8,0\\nt3_10nzqp,0\\nt3_1jp4vc,0\\nt3_y0ano,0\\nt3_ifeu9,0\\nt3_l8g1b,0\\nt3_r4k7g,0\\nt3_11tivy,0\\nt3_rdkc5,0\\nt3_knh6v,0\\nt3_195gj1,0\\nt3_m1t5z,0\\nt3_p6lib,0\\nt3_13lbzi,0\\nt3_tvwmt,0\\nt3_1da9ae,0\\nt3_svw8j,0\\nt3_1iwt3k,0\\nt3_mj5ju,0\\nt3_hy0vl,0\\nt3_1cbum9,0\\nt3_qvf9b,0\\nt3_ph959,0\\nt3_ickap,0\\nt3_15g1rr,0\\nt3_i3735,0\\nt3_umiaz,0\\nt3_112ec3,0\\nt3_uyapc,0\\nt3_1hfuh7,0\\nt3_iil4h,0\\nt3_12psv7,0\\nt3_wwdjm,0\\nt3_pdxll,0\\nt3_1l33kn,0\\nt3_t7fp4,0\\nt3_l55gf,0\\nt3_1lvypa,0\\nt3_1i92ag,0\\nt3_p9dk1,0\\nt3_kutpx,0\\nt3_19vzo3,0\\nt3_1llqlm,0\\nt3_1meso5,0\\nt3_18a6wc,0\\nt3_19d7h5,0\\nt3_1n0elq,0\\nt3_nylom,0\\nt3_j1hth,0\\nt3_ivd1a,0\\nt3_1jgp51,0\\nt3_1142bk,0\\nt3_qagim,0\\nt3_t12we,0\\nt3_sorhh,0\\nt3_js36w,0\\nt3_1dqrm6,0\\nt3_xqeim,0\\nt3_1ian7f,0\\nt3_16gqmg,0\\nt3_l4hr9,0\\nt3_ljfjh,0\\nt3_1fq4v3,0\\nt3_xu9k9,0\\nt3_zqykg,0\\nt3_1eo0kr,0\\nt3_v0bne,0\\nt3_1ilc22,0\\nt3_ozqyn,0\\nt3_p4ovq,0\\nt3_nakz9,0\\nt3_1j5piq,0\\nt3_1b34e5,0\\nt3_v7j8q,0\\nt3_ikg6e,0\\nt3_px5ws,0\\nt3_owlgk,0\\nt3_la5nq,0\\nt3_18vx3q,0\\nt3_idloh,0\\nt3_185l84,0\\nt3_td0yv,0\\nt3_mc8or,0\\nt3_1jy0x7,0\\nt3_tagb8,0\\nt3_1kd6kj,0\\nt3_srvli,0\\nt3_mxsww,0\\nt3_vuunv,0\\nt3_1i7mc9,0\\nt3_1e5gew,0\\nt3_lhdt0,0\\nt3_kx5g9,0\\nt3_jm28w,0\\nt3_tl7q7,0\\nt3_ifbuc,0\\nt3_1jhwvy,0\\nt3_1eecka,0\\nt3_ip3mm,0\\nt3_mwyh8,0\\nt3_ojsi7,0\\nt3_wos8r,0\\nt3_nejwm,0\\nt3_k9deb,0\\nt3_1btika,0\\nt3_j4hdb,0\\nt3_1ixzy0,0\\nt3_nwwmb,0\\nt3_133cg3,0\\nt3_yj8a6,0\\nt3_101uyy,0\\nt3_hyf1p,0\\nt3_s1us6,0\\nt3_xkg32,0\\nt3_icw5d,0\\nt3_jsbkc,0\\nt3_t5soc,0\\nt3_15uyq3,0\\nt3_huujf,0\\nt3_14gmeb,0\\nt3_lpzmu,0\\nt3_zo7x6,0\\nt3_1bwe1z,0\\nt3_oepok,0\\nt3_1d4ncf,0\\nt3_l268t,0\\nt3_1nv8jq,0\\nt3_lit9l,0\\nt3_wivqj,0\\nt3_ux6ka,0\\nt3_18g8j0,0\\nt3_ofpdj,0\\nt3_14bkx0,0\\nt3_1b2ij2,0\\nt3_jk2h2,0\\nt3_1bvr8d,0\\nt3_o7zs6,0\\nt3_1cwnn0,0\\nt3_jbtvg,0\\nt3_w1vg8,0\\nt3_o880l,0\\nt3_18ic2n,0\\nt3_1itzpp,0\\nt3_10sfld,0\\nt3_itf9z,0\\nt3_19elkp,0\\nt3_pfky1,0\\nt3_17kpe8,0\\nt3_ngp84,0\\nt3_vjsze,0\\nt3_13331n,0\\nt3_uuwgc,0\\nt3_ys1wm,0\\nt3_17g6l7,0\\nt3_mdvgl,0\\nt3_10j2a1,0\\nt3_13btoa,0\\nt3_mwbd6,0\\nt3_1jpu8l,0\\nt3_k3mbm,0\\nt3_1o48ha,0\\nt3_1mryfn,0\\nt3_18c24q,0\\nt3_qwu55,0\\nt3_1ktwwv,0\\nt3_pukrr,0\\nt3_1jd5t9,0\\nt3_i96xd,0\\nt3_i67so,0\\nt3_17pb84,0\\nt3_qseg2,0\\nt3_xevib,0\\nt3_mdb8o,0\\nt3_nyxfh,0\\nt3_jnosh,0\\nt3_17ma70,0\\nt3_1l2skl,0\\nt3_12s9wy,0\\nt3_14fcmj,0\\nt3_icnsj,0\\nt3_j3px1,0\\nt3_p84xp,0\\nt3_1iffmt,0\\nt3_qwlzl,0\\nt3_1ifykb,0\\nt3_pf7xu,0\\nt3_w1omy,0\\nt3_ibxcx,0\\nt3_16g44g,0\\nt3_1lzgcg,0\\nt3_11v2e3,0\\nt3_whggb,0\\nt3_yyutk,0\\nt3_jawug,0\\nt3_11h5fx,0\\nt3_ksmnr,0\\nt3_xixa9,0\\nt3_129hun,0\\nt3_10w3p4,0\\nt3_1aa9he,0\\nt3_1ea7ee,0\\nt3_17ghsm,0\\nt3_o7i9r,0\\nt3_lbanx,0\\nt3_192rjt,0\\nt3_u1pjd,0\\nt3_w8ha8,0\\nt3_12p7c1,0\\nt3_j4i0t,0\\nt3_jyqjt,0\\nt3_1235kc,0\\nt3_1drofn,0\\nt3_iskfp,0\\nt3_xnbcg,0\\nt3_1ejj7t,0\\nt3_iaoil,0\\nt3_j48po,0\\nt3_17mumg,0\\nt3_1naboz,0\\nt3_1a636c,0\\nt3_rlqw0,0\\nt3_17nxn9,0\\nt3_15qs5c,0\\nt3_tbdfc,0\\nt3_1d1niu,0\\nt3_1ejldw,0\\nt3_1jyxj8,0\\nt3_r9csz,0\\nt3_im138,0\\nt3_1fvlpz,0\\nt3_kma5h,0\\nt3_nb786,0\\nt3_1iarcu,0\\nt3_x9tks,0\\nt3_r022i,0\\nt3_ry4te,0\\nt3_si6hr,0\\nt3_kpi2z,0\\nt3_1adsra,0\\nt3_17ppx1,0\\nt3_vav2k,0\\nt3_1jkuj5,0\\nt3_1lixj3,0\\nt3_p25h6,0\\nt3_s36vf,0\\nt3_1lxspb,0\\nt3_1ccwpb,0\\nt3_1kghul,0\\nt3_1785hj,0\\nt3_oijja,0\\nt3_1a4uso,0\\nt3_jf70p,0\\nt3_tbnpe,0\\nt3_1cke6u,0\\nt3_veeyw,0\\nt3_1bkxgh,0\\nt3_11hkwu,0\\nt3_od42n,0\\nt3_ixy0f,0\\nt3_vwcvk,0\\nt3_o77z6,0\\nt3_139qw1,0\\nt3_1hftkm,0\\nt3_j1u1l,0\\nt3_1lnq58,0\\nt3_183j1t,0\\nt3_1948qi,0\\nt3_14kuxr,0\\nt3_jraz4,0\\nt3_o8nap,0\\nt3_1m28mz,0\\nt3_1j33z9,0\\nt3_15r3p6,0\\nt3_penyh,0\\nt3_ks7mt,0\\nt3_10rvrc,0\\nt3_14kzth,0\\nt3_zqs0z,0\\nt3_1ks9hw,0\\nt3_tfksg,0\\nt3_1dym29,0\\nt3_1iv792,0\\nt3_k87xw,0\\nt3_j7j1a,0\\nt3_1gtku5,0\\nt3_1je0om,0\\nt3_1fydsv,0\\nt3_1923em,0\\nt3_soxzw,0\\nt3_1mwb3m,0\\nt3_j0bk0,0\\nt3_y3otl,0\\nt3_1ejbbj,0\\nt3_1ehr1g,0\\nt3_vnmor,0\\nt3_i49s7,0\\nt3_1ezo2x,0\\nt3_k3zte,0\\nt3_px0sh,0\\nt3_r65sc,0\\nt3_ko3e1,0\\nt3_1jpq2m,0\\nt3_1do7ez,0\\nt3_pvqb0,0\\nt3_msef6,0\\nt3_14i72s,0\\nt3_1kkvey,0\\nt3_wanz0,0\\nt3_iv9ox,0\\nt3_krb3m,0\\nt3_ilau5,0\\nt3_1kj6vm,0\\nt3_1l0ugy,0\\nt3_1g8r0o,0\\nt3_1le5sz,0\\nt3_j869k,0\\nt3_xtx62,0\\nt3_1ivbrp,0\\nt3_s2w1y,0\\nt3_1ivgyp,0\\nt3_pe178,0\\nt3_s58wn,0\\nt3_1i3zr6,0\\nt3_wv24t,0\\nt3_sbnbg,0\\nt3_14f8ed,0\\nt3_1mt2g2,0\\nt3_1bvqrf,0\\nt3_1d673k,0\\nt3_k3k13,0\\nt3_10usdp,0\\nt3_o0m9i,0\\nt3_1mjrmt,0\\nt3_1lajal,0\\nt3_lyd1s,0\\nt3_1dayzb,0\\nt3_z409k,0\\nt3_1ipzb6,0\\nt3_i5c8j,0\\nt3_qt3v7,0\\nt3_igo1i,0\\nt3_i3una,0\\nt3_10u70o,0\\nt3_1e95a5,0\\nt3_ivhw5,0\\nt3_liw3m,0\\nt3_ra40d,0\\nt3_1glla8,0\\nt3_wy35k,0\\nt3_1ihhx4,0\\nt3_1idsgl,0\\nt3_kfq6s,0\\nt3_rzs62,0\\nt3_lpu5j,0\\nt3_l7y4a,0\\nt3_ixx53,0\\nt3_rrrzo,0\\nt3_14tc0g,0\\nt3_r8jj3,0\\nt3_1lr307,0\\nt3_mktvg,0\\nt3_usmgq,0\\nt3_162jlp,0\\nt3_iaeax,0\\nt3_ng075,0\\nt3_11zxa9,0\\nt3_i94gr,0\\nt3_ytnaq,0\\nt3_j7uxa,0\\nt3_1da8ub,0\\nt3_ssyae,0\\nt3_kvu06,0\\nt3_18zijt,0\\nt3_16ibe1,0\\nt3_idewk,0\\nt3_jq3x6,0\\nt3_1nc07j,0\\nt3_1eemqq,0\\nt3_iaftz,0\\nt3_1nvvnk,0\\nt3_1cfduv,0\\nt3_1l59g9,0\\nt3_icnyh,0\\nt3_13ump5,0\\nt3_m1twq,0\\nt3_12mhsp,0\\nt3_144ad5,0\\nt3_13fuev,0\\nt3_1jn7fx,0\\nt3_te3za,0\\nt3_yi4kv,0\\nt3_145qyc,0\\nt3_lboww,0\\nt3_ien0r,0\\nt3_1if61u,0\\nt3_19ulmv,0\\nt3_1btsrs,0\\nt3_t0fl6,0\\nt3_11e5xk,0\\nt3_w61sg,0\\nt3_x19zb,0\\nt3_1ju5fx,0\\nt3_vnnkb,0\\nt3_193tya,0\\nt3_1iv3bw,0\\nt3_1ltm59,0\\nt3_hj6s8,0\\nt3_pypw7,0\\nt3_1fiyu3,0\\nt3_1is1ux,0\\nt3_1310xx,0\\nt3_1jnsxo,0\\nt3_va5vp,0\\nt3_usk00,0\\nt3_1mg7w7,0\\nt3_1hc7aj,0\\nt3_1aulwp,0\\nt3_1ixemj,0\\nt3_1frcip,0\\nt3_wgk03,0\\nt3_k0l9j,0\\nt3_wd8ky,0\\nt3_nwamf,0\\nt3_l1xkw,0\\nt3_1ee34s,0\\nt3_17biu9,0\\nt3_12ge8l,0\\nt3_zqtrr,0\\nt3_oqsen,0\\nt3_rlqcj,0\\nt3_lkau4,0\\nt3_iu9ym,0\\nt3_11lmex,0\\nt3_sdi2k,0\\nt3_szbjh,0\\nt3_1342ph,0\\nt3_rk5ky,0\\nt3_hz7vk,0\\nt3_121ck5,0\\nt3_10ben6,0\\n\", \"is_error\": false}",
        "tool.duration_ms": 0.4324913024902344
      }
    },
    {
      "trace_id": "0ad319796ae0544a413df0aa2fc8b5a0",
      "span_id": "60d9da52f73791ba",
      "parent_span_id": "128d4bd68955796b",
      "name": "CreateNotebookTool",
      "kind": "INTERNAL",
      "start_time": 1767959215377491649,
      "end_time": 1767959215940016916,
      "duration": 0.562525267,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "CreateNotebookTool",
        "cascade.agent_name": "ExecutorAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.CreateNotebookTool object at 0x7f3b02059f50>\", \"input\": {\"notebook_path\": \"/home/code/experiments/001_baseline_tfidf_logreg.ipynb\", \"cells\": [{\"cell_type\": \"markdown\", \"content\": \"# Baseline: TF-IDF + Logistic Regression\\n\\nThis notebook implements a simple baseline using TF-IDF text features and logistic regression.\\nFollowing the Phase 1 roadmap from the strategy guide.\"}, {\"cell_type\": \"code\", \"content\": \"import json\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.model_selection import StratifiedKFold\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import roc_auc_score\\nfrom scipy.sparse import hstack\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n\\n# Set random seed for reproducibility\\nnp.random.seed(42)\"}, {\"cell_type\": \"markdown\", \"content\": \"## Load Data\"}, {\"cell_type\": \"code\", \"content\": \"# Load training data\\nprint(\\\"Loading training data...\\\")\\nwith open('/home/data/train.json', 'r') as f:\\n    train_data = json.load(f)\\n\\n# Convert to DataFrame\\ntrain_df = pd.DataFrame(train_data)\\nprint(f\\\"Training data shape: {train_df.shape}\\\")\\nprint(f\\\"Columns: {train_df.columns.tolist()}\\\")\\n\\n# Load test data\\nprint(\\\"\\\\nLoading test data...\\\")\\nwith open('/home/data/test.json', 'r') as f:\\n    test_data = json.load(f)\\n\\ntest_df = pd.DataFrame(test_data)\\nprint(f\\\"Test data shape: {test_df.shape}\\\")\\n\\n# Check class distribution\\nprint(f\\\"\\\\nClass distribution in training data:\\\")\\nprint(train_df['requester_received_pizza'].value_counts(normalize=True))\"}, {\"cell_type\": \"markdown\", \"content\": \"## Basic Feature Engineering\"}, {\"cell_type\": \"code\", \"content\": \"# Create text features by combining title and text\\ntrain_df['combined_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text'].fillna('')\\ntest_df['combined_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text'].fillna('')\\n\\n# Basic text statistics\\ntrain_df['text_length'] = train_df['combined_text'].str.len()\\ntrain_df['word_count'] = train_df['combined_text'].str.split().str.len()\\ntest_df['text_length'] = test_df['combined_text'].str.len()\\ntest_df['word_count'] = test_df['combined_text'].str.split().str.len()\\n\\n# Select numeric features for concatenation\\nnumeric_features = ['text_length', 'word_count', 'request_number_of_comments_at_retrieval',\\n                   'requester_number_of_comments_at_retrieval', 'requester_number_of_posts_at_retrieval',\\n                   'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_retrieval']\\n\\n# Ensure numeric features exist and fill missing values\\navailable_numeric_features = [f for f in numeric_features if f in train_df.columns]\\nprint(f\\\"Available numeric features: {available_numeric_features}\\\")\\n\\nfor f in available_numeric_features:\\n    train_df[f] = pd.to_numeric(train_df[f], errors='coerce').fillna(0)\\n    test_df[f] = pd.to_numeric(test_df[f], errors='coerce').fillna(0)\"}, {\"cell_type\": \"markdown\", \"content\": \"## Cross-Validation Setup\"}, {\"cell_type\": \"code\", \"content\": \"# Setup stratified cross-validation\\nn_folds = 5\\nskf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\\n\\nX_text = train_df['combined_text'].fillna('')\\ny = train_df['requester_received_pizza'].astype(int)\\n\\n# Store OOF predictions and test predictions\\noof_predictions = np.zeros(len(train_df))\\ntest_predictions = np.zeros(len(test_df))\\ncv_scores = []\"}, {\"cell_type\": \"markdown\", \"content\": \"## TF-IDF + Logistic Regression with Cross-Validation\"}, {\"cell_type\": \"code\", \"content\": \"print(\\\"Starting cross-validation...\\\")\\n\\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(X_text, y)):\\n    print(f\\\"\\\\nFold {fold + 1}/{n_folds}\\\")\\n    \\n    # Split data\\n    X_train_text = X_text.iloc[train_idx]\\n    X_valid_text = X_text.iloc[valid_idx]\\n    y_train = y.iloc[train_idx]\\n    y_valid = y.iloc[valid_idx]\\n    \\n    # Create TF-IDF features\\n    tfidf = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))\\n    X_train_tfidf = tfidf.fit_transform(X_train_text)\\n    X_valid_tfidf = tfidf.transform(X_valid_text)\\n    \\n    # Add numeric features if available\\n    if available_numeric_features:\\n        X_train_numeric = train_df.iloc[train_idx][available_numeric_features].values\\n        X_valid_numeric = train_df.iloc[valid_idx][available_numeric_features].values\\n        \\n        # Normalize numeric features\\n        from sklearn.preprocessing import StandardScaler\\n        scaler = StandardScaler()\\n        X_train_numeric = scaler.fit_transform(X_train_numeric)\\n        X_valid_numeric = scaler.transform(X_valid_numeric)\\n        \\n        # Combine TF-IDF and numeric features\\n        X_train_combined = hstack([X_train_tfidf, X_train_numeric])\\n        X_valid_combined = hstack([X_valid_tfidf, X_valid_numeric])\\n    else:\\n        X_train_combined = X_train_tfidf\\n        X_valid_combined = X_valid_tfidf\\n    \\n    # Train logistic regression with class weighting to handle imbalance\\n    model = LogisticRegression(\\n        class_weight='balanced',\\n        max_iter=1000,\\n        random_state=42,\\n        n_jobs=-1\\n    )\\n    \\n    model.fit(X_train_combined, y_train)\\n    \\n    # Predict on validation set\\n    valid_pred = model.predict_proba(X_valid_combined)[:, 1]\\n    oof_predictions[valid_idx] = valid_pred\\n    \\n    # Calculate AUC for this fold\\n    fold_auc = roc_auc_score(y_valid, valid_pred)\\n    cv_scores.append(fold_auc)\\n    print(f\\\"Fold {fold + 1} AUC: {fold_auc:.4f}\\\")\\n    \\n    # Predict on test set for this fold\\n    X_test_text = test_df['combined_text'].fillna('')\\n    X_test_tfidf = tfidf.transform(X_test_text)\\n    \\n    if available_numeric_features:\\n        X_test_numeric = test_df[available_numeric_features].values\\n        X_test_numeric = scaler.transform(X_test_numeric)\\n        X_test_combined = hstack([X_test_tfidf, X_test_numeric])\\n    else:\\n        X_test_combined = X_test_tfidf\\n    \\n    test_pred = model.predict_proba(X_test_combined)[:, 1]\\n    test_predictions += test_pred / n_folds\\n\\n# Calculate overall CV score\\noverall_auc = roc_auc_score(y, oof_predictions)\\nprint(f\\\"\\\\nOverall CV AUC: {overall_auc:.4f}\\\")\\nprint(f\\\"Mean Fold AUC: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\\\")\"}, {\"cell_type\": \"markdown\", \"content\": \"## Create Submission\"}, {\"cell_type\": \"code\", \"content\": \"# Create submission file\\nsubmission = pd.DataFrame({\\n    'request_id': test_df['request_id'],\\n    'requester_received_pizza': test_predictions\\n})\\n\\n# Ensure the submission has the correct format\\nsubmission['requester_received_pizza'] = submission['requester_received_pizza'].astype(float)\\n\\n# Save submission\\nsubmission_path = '/home/submission/submission_001_baseline.csv'\\nsubmission.to_csv(submission_path, index=False)\\n\\nprint(f\\\"Submission saved to: {submission_path}\\\")\\nprint(f\\\"Submission shape: {submission.shape}\\\")\\nprint(f\\\"Prediction distribution:\\\")\\nprint(submission['requester_received_pizza'].describe())\\n\\n# Show first few predictions\\nprint(\\\"\\\\nFirst 5 predictions:\\\")\\nprint(submission.head())\"}]}}",
        "tool.output": "{\"content\": \"Created: /home/code/experiments/001_baseline_tfidf_logreg.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\", \"is_error\": false}",
        "tool.duration_ms": 562.6018047332764
      }
    }
  ],
  "metadata": {
    "span_count": 41,
    "last_updated": "2026-01-09T11:46:59.974519"
  }
}