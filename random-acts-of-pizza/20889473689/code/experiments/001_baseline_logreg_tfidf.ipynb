{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68dd8860",
   "metadata": {},
   "source": [
    "# Baseline Model: Logistic Regression + TF-IDF\n",
    "\n",
    "Simple baseline using TF-IDF features on combined text data with Logistic Regression.\n",
    "\n",
    "## Approach\n",
    "- Combine request_title and request_text\n",
    "- TF-IDF vectorization (unigrams and bigrams)\n",
    "- Logistic Regression with class weighting for imbalance\n",
    "- 5-fold stratified cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a017c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T05:24:11.093509Z",
     "iopub.status.busy": "2026-01-11T05:24:11.092448Z",
     "iopub.status.idle": "2026-01-11T05:24:12.477313Z",
     "shell.execute_reply": "2026-01-11T05:24:12.476694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Training data shape: (2878, 32)\n",
      "Target distribution: {False: 2163, True: 715}\n",
      "Positive rate: 0.248\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Target distribution: {train_df['requester_received_pizza'].value_counts().to_dict()}\")\n",
    "print(f\"Positive rate: {train_df['requester_received_pizza'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4785fce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T05:28:30.625546Z",
     "iopub.status.busy": "2026-01-11T05:28:30.625208Z",
     "iopub.status.idle": "2026-01-11T05:28:30.736446Z",
     "shell.execute_reply": "2026-01-11T05:28:30.735536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined text sample:\n",
      "[request] oceanside, ca. usa- us marine getting ready to deploy. i will soon be going on a long deployment which i'm not aloud to discuss but willing to give some info if you ask. just wanna eat some \n"
     ]
    }
   ],
   "source": [
    "# Combine text features - use request_text_edit_aware for both train and test\n",
    "train_df['combined_text'] = train_df['request_title'].fillna('') + ' ' + train_df['request_text_edit_aware'].fillna('')\n",
    "train_df['combined_text'] = train_df['combined_text'].str.lower()\n",
    "\n",
    "# Basic text preprocessing - remove extra whitespace\n",
    "train_df['combined_text'] = train_df['combined_text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "print(\"Combined text sample:\")\n",
    "print(train_df['combined_text'].iloc[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "789a73c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T05:28:30.739292Z",
     "iopub.status.busy": "2026-01-11T05:28:30.738997Z",
     "iopub.status.idle": "2026-01-11T05:28:30.789935Z",
     "shell.execute_reply": "2026-01-11T05:28:30.789081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature statistics:\n",
      "Text length - mean: 464.8, std: 351.3\n",
      "Word count - mean: 88.0, std: 67.8\n",
      "Has flair: 715 (0.248)\n"
     ]
    }
   ],
   "source": [
    "# Create additional simple features\n",
    "train_df['text_length'] = train_df['combined_text'].str.len()\n",
    "train_df['word_count'] = train_df['combined_text'].str.split().str.len()\n",
    "\n",
    "# Handle user flair (critical finding: perfect separation but likely leakage)\n",
    "# We'll include it but be aware it might be leakage\n",
    "train_df['user_flair'] = train_df['requester_user_flair'].fillna('None')\n",
    "train_df['has_flair'] = (train_df['user_flair'] != 'None').astype(int)\n",
    "\n",
    "print(\"Feature statistics:\")\n",
    "print(f\"Text length - mean: {train_df['text_length'].mean():.1f}, std: {train_df['text_length'].std():.1f}\")\n",
    "print(f\"Word count - mean: {train_df['word_count'].mean():.1f}, std: {train_df['word_count'].std():.1f}\")\n",
    "print(f\"Has flair: {train_df['has_flair'].sum()} ({train_df['has_flair'].mean():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84016c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T05:28:30.792696Z",
     "iopub.status.busy": "2026-01-11T05:28:30.792435Z",
     "iopub.status.idle": "2026-01-11T05:28:36.936183Z",
     "shell.execute_reply": "2026-01-11T05:28:36.935054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance - Positive rate: 0.248, scale_pos_weight: 3.025\n",
      "\n",
      "Starting 5-fold cross-validation...\n",
      "\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation AUC: 0.6372\n",
      "  Training samples: 2302, Validation samples: 576\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation AUC: 0.6128\n",
      "  Training samples: 2302, Validation samples: 576\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation AUC: 0.6053\n",
      "  Training samples: 2302, Validation samples: 576\n",
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation AUC: 0.5653\n",
      "  Training samples: 2303, Validation samples: 575\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation AUC: 0.6074\n",
      "  Training samples: 2303, Validation samples: 575\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Results:\n",
      "Mean AUC: 0.6056 ± 0.0232\n",
      "Individual folds: ['0.6372', '0.6128', '0.6053', '0.5653', '0.6074']\n",
      "OOF AUC: 0.6060\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for modeling\n",
    "X_text = train_df['combined_text']\n",
    "y = train_df['requester_received_pizza'].values\n",
    "\n",
    "# Calculate class weight for imbalance\n",
    "pos_rate = y.mean()\n",
    "neg_rate = 1 - pos_rate\n",
    "scale_pos_weight = neg_rate / pos_rate\n",
    "print(f\"Class imbalance - Positive rate: {pos_rate:.3f}, scale_pos_weight: {scale_pos_weight:.3f}\")\n",
    "\n",
    "# 5-fold stratified cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "\n",
    "print(\"\\nStarting 5-fold cross-validation...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_text, y)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X_text.iloc[train_idx], X_text.iloc[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Create pipeline with TF-IDF and Logistic Regression\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            max_features=10000,\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words='english',\n",
    "            lowercase=True,\n",
    "            min_df=2,\n",
    "            max_df=0.95\n",
    "        )),\n",
    "        ('clf', LogisticRegression(\n",
    "            class_weight='balanced',\n",
    "            max_iter=1000,\n",
    "            C=1.0,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Train model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_pred = pipeline.predict_proba(X_val)[:, 1]\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc_score = roc_auc_score(y_val, val_pred)\n",
    "    fold_scores.append(auc_score)\n",
    "    \n",
    "    print(f\"  Validation AUC: {auc_score:.4f}\")\n",
    "    print(f\"  Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")\n",
    "\n",
    "# Overall CV score\n",
    "mean_auc = np.mean(fold_scores)\n",
    "std_auc = np.std(fold_scores)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Cross-Validation Results:\")\n",
    "print(f\"Mean AUC: {mean_auc:.4f} ± {std_auc:.4f}\")\n",
    "print(f\"Individual folds: {[f'{score:.4f}' for score in fold_scores]}\")\n",
    "\n",
    "# Calculate OOF AUC\n",
    "oof_auc = roc_auc_score(y, oof_predictions)\n",
    "print(f\"OOF AUC: {oof_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d883f4b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T05:28:36.939222Z",
     "iopub.status.busy": "2026-01-11T05:28:36.938873Z",
     "iopub.status.idle": "2026-01-11T05:28:38.288885Z",
     "shell.execute_reply": "2026-01-11T05:28:38.287990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n",
      "Test data shape: (1162, 17)\n",
      "\n",
      "Training final model on full training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions shape: (1162,)\n",
      "Test predictions range: [0.1515, 0.8548]\n",
      "Test predictions mean: 0.4534\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Preprocess test data - use request_text_edit_aware\n",
    "test_df['combined_text'] = test_df['request_title'].fillna('') + ' ' + test_df['request_text_edit_aware'].fillna('')\n",
    "test_df['combined_text'] = test_df['combined_text'].str.lower()\n",
    "test_df['combined_text'] = test_df['combined_text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "# Create simple features\n",
    "test_df['text_length'] = test_df['combined_text'].str.len()\n",
    "test_df['word_count'] = test_df['combined_text'].str.split().str.len()\n",
    "test_df['user_flair'] = test_df['requester_user_flair'].fillna('None') if 'requester_user_flair' in test_df.columns else 'None'\n",
    "test_df['has_flair'] = (test_df['user_flair'] != 'None').astype(int) if 'requester_user_flair' in test_df.columns else 0\n",
    "\n",
    "X_test_text = test_df['combined_text']\n",
    "\n",
    "# Train final model on full training data\n",
    "print(\"\\nTraining final model on full training data...\")\n",
    "final_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=10000,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words='english',\n",
    "        lowercase=True,\n",
    "        min_df=2,\n",
    "        max_df=0.95\n",
    "    )),\n",
    "    ('clf', LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        max_iter=1000,\n",
    "        C=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X_text, y)\n",
    "\n",
    "# Generate predictions\n",
    "test_predictions = final_pipeline.predict_proba(X_test_text)[:, 1]\n",
    "\n",
    "print(f\"Test predictions shape: {test_predictions.shape}\")\n",
    "print(f\"Test predictions range: [{test_predictions.min():.4f}, {test_predictions.max():.4f}]\")\n",
    "print(f\"Test predictions mean: {test_predictions.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0316d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "# Ensure correct format (0/1 probabilities)\n",
    "submission_df['requester_received_pizza'] = submission_df['requester_received_pizza'].astype(float)\n",
    "\n",
    "print(\"Submission file preview:\")\n",
    "print(submission_df.head())\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_001_baseline.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")\n",
    "\n",
    "# Verify submission format matches sample\n",
    "sample_submission = pd.read_csv('/home/data/sampleSubmission.csv')\n",
    "print(f\"\\nFormat verification:\")\n",
    "print(f\"Sample columns: {sample_submission.columns.tolist()}\")\n",
    "print(f\"Our columns: {submission_df.columns.tolist()}\")\n",
    "print(f\"Sample shape: {sample_submission.shape}\")\n",
    "print(f\"Our shape: {submission_df.shape}\")\n",
    "print(f\"IDs match: {set(sample_submission['request_id']) == set(submission_df['request_id'])}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
