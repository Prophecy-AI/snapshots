{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ee515c",
   "metadata": {},
   "source": [
    "# Baseline Model: Meta Features Only\n",
    "\n",
    "This notebook implements a simple baseline using only numerical/meta features available in the test set.\n",
    "\n",
    "**Features used:**\n",
    "- User activity metrics (at_request only)\n",
    "- Vote counts (at_request only)\n",
    "- Temporal features\n",
    "- Account age features\n",
    "\n",
    "**Model:** LightGBM with class imbalance handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf498e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Target distribution: {train_df['requester_received_pizza'].value_counts().to_dict()}\")\n",
    "print(f\"Positive rate: {train_df['requester_received_pizza'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d269a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features available in test set (17 features)\n",
    "# Excluding: request_id, requester_username, giver_username_if_known, requester_subreddits_at_request (high cardinality)\n",
    "# Using only numerical features for this baseline\n",
    "\n",
    "meta_features = [\n",
    "    # User activity (at_request only)\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    \n",
    "    # Vote counts (at_request only)\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    \n",
    "    # Temporal features\n",
    "    'unix_timestamp_of_request',\n",
    "    'unix_timestamp_of_request_utc',\n",
    "    \n",
    "    # Account age\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request'\n",
    "]\n",
    "\n",
    "print(f\"Using {len(meta_features)} meta features:\")\n",
    "for feat in meta_features:\n",
    "    print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4750af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineer additional features from temporal data\n",
    "print(\"Engineering temporal features...\")\n",
    "\n",
    "train_df['request_datetime'] = pd.to_datetime(train_df['unix_timestamp_of_request_utc'], unit='s')\n",
    "test_df['request_datetime'] = pd.to_datetime(test_df['unix_timestamp_of_request_utc'], unit='s')\n",
    "\n",
    "# Extract hour and day of week\n",
    "train_df['request_hour'] = train_df['request_datetime'].dt.hour\n",
    "test_df['request_hour'] = test_df['request_datetime'].dt.hour\n",
    "\n",
    "train_df['request_dayofweek'] = train_df['request_datetime'].dt.dayofweek\n",
    "test_df['request_dayofweek'] = test_df['request_datetime'].dt.dayofweek\n",
    "\n",
    "# Add engineered features to feature list\n",
    "engineered_features = ['request_hour', 'request_dayofweek']\n",
    "all_features = meta_features + engineered_features\n",
    "\n",
    "print(f\"Total features: {len(all_features)}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in training data:\")\n",
    "print(train_df[all_features].isnull().sum().sum())\n",
    "\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(test_df[all_features].isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "X = train_df[all_features].copy()\n",
    "y = train_df['requester_received_pizza'].astype(int).values\n",
    "X_test = test_df[all_features].copy()\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# Handle any missing values (fill with median)\n",
    "for col in all_features:\n",
    "    median_val = X[col].median()\n",
    "    X[col].fillna(median_val, inplace=True)\n",
    "    X_test[col].fillna(median_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4077d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Model parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'class_weight': 'balanced'  # Handle class imbalance\n",
    "}\n",
    "\n",
    "print(f\"Training with {n_folds}-fold stratified CV...\")\n",
    "print(f\"Model parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54102a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with cross-validation\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_folds}\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['val'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(50),\n",
    "            lgb.log_evaluation(0)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    \n",
    "    # Store predictions\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    test_predictions += test_pred / n_folds\n",
    "    \n",
    "    # Calculate score\n",
    "    fold_score = roc_auc_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_score)\n",
    "    print(f\"Fold {fold + 1} ROC-AUC: {fold_score:.4f}\")\n",
    "\n",
    "# Overall CV score\n",
    "cv_score = roc_auc_score(y, oof_predictions)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Cross-Validation Results:\")\n",
    "print(f\"Mean ROC-AUC: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")\n",
    "print(f\"OOF ROC-AUC: {cv_score:.4f}\")\n",
    "print(f\"Fold scores: {fold_scores}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f4db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = model.feature_importance(importance_type='gain')\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 features by importance:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116596b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions for submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "submission_path = '/home/submission/submission_001_baseline_meta_only.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(f\"Prediction range: [{test_predictions.min():.4f}, {test_predictions.max():.4f}]\")\n",
    "print(f\"Mean prediction: {test_predictions.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
