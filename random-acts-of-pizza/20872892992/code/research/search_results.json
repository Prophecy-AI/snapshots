{
  "query": "Why would TF-IDF perform worse than meta features alone on Reddit text classification, and what are better approaches for social media text?",
  "results": [
    {
      "title": "ANSWER",
      "text": "TF\u2011IDF often under\u2011performs meta\u2011features on Reddit because it treats each post as a sparse bag\u2011of\u2011words, ignoring word order, syntax and the many informal signals that dominate social\u2011media text (misspellings, emojis, slang, abbreviations). Reddit comments are typically short and noisy, so the term\u2011frequency statistics become unreliable and the resulting vectors are highly sparse, making it difficult for a linear classifier to capture the subtle cues that indicate a target class. Meta\u2011features\u2014such as psycholinguistic scores, user activity statistics, posting time, or sentiment indicators\u2014directly encode these higher\u2011level signals and therefore provide a richer, lower\u2011dimensional representation that is often more discriminative for the task ([Extended pre\u2011processing pipeline for text classification\u2026](https://www.sciencedirect.com/science/article/abs/pii/S030645731931461X); [Meta\u2011level sentiment models for big social data analysis](https://www.sciencedirect.com/science/article/abs/pii/S0950705114002068)).\n\nMore effective approaches for social\u2011media text therefore move beyond plain TF\u2011IDF. Domain\u2011adapted pretrained language models such as SocBERT, which are trained on large Reddit and Twitter corpora, capture contextual semantics and informal language patterns better than generic BERT ([SocBERT: A Pretrained Model for Social Media Text](https://aclanthology.org/2023.insights-1.5/)). Hybrid systems that combine deep transformer embeddings with statistical term\u2011weighting also show gains; a RoBERTa\u2011TF\u2011IDF\u2011PCA model outperformed RoBERTa alone on suicide\u2011risk detection from Reddit posts ([Detection of Suicidal Risk on Social Media: A Hybrid Model](https://arxiv.org/pdf/2505.23797.pdf)). Character\u2011level encoders like Tweet2Vec further mitigate out\u2011of\u2011vocabulary problems by learning representations directly from raw characters, which is especially useful for the noisy, abbreviated language of Reddit ([Tweet2Vec: Character\u2011Based Distributed Representations for Social Media](https://arxiv.org/abs/1605.03481)). Finally, combining engineered meta\u2011features with transformer\u2011based models (e.g., BLSTM on psycholinguistic cues plus a transformer) yields state\u2011of\u2011the\u2011art performance on mental\u2011health prediction from Reddit posts ([The Best of Both Worlds: Combining Engineered Features with Transformers for Improved Mental Health Prediction from Reddit Posts](https://aclanthology.org/2022.smm4h-1.50/)). These strategies\u2014domain\u2011specific PLMs, hybrid embedding\u2011TF\u2011IDF pipelines, character\u2011level models, and the integration of meta\u2011features\u2014are currently the most successful for classifying social\u2011media text.",
      "url": ""
    },
    {
      "title": "The Best of Both Worlds: Combining Engineered Features with Transformers for Improved Mental Health Prediction from Reddit Posts",
      "text": "## [The Best of Both Worlds: Combining Engineered Features with Transformers for Improved Mental Health Prediction from Reddit Posts](https://aclanthology.org/2022.smm4h-1.50.pdf)\n\n[Sourabh Zanwar](https://aclanthology.org/people/sourabh-zanwar/),\n[Daniel Wiechmann](https://aclanthology.org/people/daniel-wiechmann/),\n[Yu Qiao](https://aclanthology.org/people/yu-qiao/),\n[Elma Kerz](https://aclanthology.org/people/elma-kerz/)\n\n##### Abstract\n\nIn recent years, there has been increasing interest in the application of natural language processing and machine learning techniques to the detection of mental health conditions (MHC) based on social media data. In this paper, we aim to improve the state-of-the-art (SoTA) detection of six MHC in Reddit posts in two ways: First, we built models leveraging Bidirectional Long Short-Term Memory (BLSTM) networks trained on in-text distributions of a comprehensive set of psycholinguistic features for more explainable MHC detection as compared to black-box solutions. Second, we combine these BLSTM models with Transformers to improve the prediction accuracy over SoTA models. In addition, we uncover nuanced patterns of linguistic markers characteristic of specific MHC.\n\nAnthology ID:2022.smm4h-1.50Volume:[Proceedings of the Seventh Workshop on Social Media Mining for Health Applications, Workshop & Shared Task](https://aclanthology.org/volumes/2022.smm4h-1/)Month:OctoberYear:2022Address:Gyeongju, Republic of KoreaEditors:[Graciela Gonzalez-Hernandez](https://aclanthology.org/people/graciela-gonzalez/),\n[Davy Weissenbacher](https://aclanthology.org/people/davy-weissenbacher/)Venue:[SMM4H](https://aclanthology.org/venues/smm4h/)SIG:Publisher:Association for Computational LinguisticsNote:Pages:197\u2013202Language:URL:[https://aclanthology.org/2022.smm4h-1.50/](https://aclanthology.org/2022.smm4h-1.50/)DOI:Bibkey:zanwar-etal-2022-bestCite (ACL):Sourabh Zanwar, Daniel Wiechmann, Yu Qiao, and Elma Kerz. 2022. [The Best of Both Worlds: Combining Engineered Features with Transformers for Improved Mental Health Prediction from Reddit Posts](https://aclanthology.org/2022.smm4h-1.50/). In _Proceedings of the Seventh Workshop on Social Media Mining for Health Applications, Workshop & Shared Task_, pages 197\u2013202, Gyeongju, Republic of Korea. Association for Computational Linguistics.Cite (Informal):[The Best of Both Worlds: Combining Engineered Features with Transformers for Improved Mental Health Prediction from Reddit Posts](https://aclanthology.org/2022.smm4h-1.50/) (Zanwar et al., SMM4H 2022)Copy Citation:BibTeXMarkdownMODS XMLEndnoteMore options\u2026PDF:[https://aclanthology.org/2022.smm4h-1.50.pdf](https://aclanthology.org/2022.smm4h-1.50.pdf)\n\n[PDF](https://aclanthology.org/2022.smm4h-1.50.pdf) [Cite](https://aclanthology.org/aclanthology.org) [Search](https://www.semanticscholar.org/search?q=The+Best+of+Both+Worlds%3A+Combining+Engineered+Features+with+Transformers+for+Improved+Mental+Health+Prediction+from+Reddit+Posts) [Fix data](https://aclanthology.org/aclanthology.org)",
      "url": "https://aclanthology.org/2022.smm4h-1.50"
    },
    {
      "title": "SocBERT: A Pretrained Model for Social Media Text",
      "text": "## [SocBERT: A Pretrained Model for Social Media Text](https://aclanthology.org/2023.insights-1.5.pdf)\n[Yuting Guo](https://aclanthology.org/people/y/yuting-guo/),\n[Abeed Sarker](https://aclanthology.org/people/a/abeed-sarker/)\n* * *\n##### Abstract\nPretrained language models (PLMs) on domain-specific data have been proven to be effective for in-domain natural language processing (NLP) tasks. Our work aimed to develop a language model which can be effective for the NLP tasks with the data from diverse social media platforms. We pretrained a language model on Twitter and Reddit posts in English consisting of 929M sequence blocks for 112K steps. We benchmarked our model and 3 transformer-based models\u2014BERT, BERTweet, and RoBERTa on 40 social media text classification tasks. The results showed that although our model did not perform the best on all of the tasks, it outperformed the baseline model\u2014BERT on most of the tasks, which illustrates the effectiveness of our model. Also, our work provides some insights of how to improve the efficiency of training PLMs.\nAnthology ID:2023.insights-1.5Volume:[Proceedings of the Fourth Workshop on Insights from Negative Results in NLP](https://aclanthology.org/volumes/2023.insights-1/)Month:MayYear:2023Address:Dubrovnik, CroatiaEditors:[Shabnam Tafreshi](https://aclanthology.org/people/s/shabnam-tafreshi/),\n[Arjun Akula](https://aclanthology.org/people/a/arjun-akula/),\n[Jo\u00e3o Sedoc](https://aclanthology.org/people/j/joao-sedoc/),\n[Aleksandr Drozd](https://aclanthology.org/people/a/aleksandr-drozd/),\n[Anna Rogers](https://aclanthology.org/people/a/anna-rogers/),\n[Anna Rumshisky](https://aclanthology.org/people/a/anna-rumshisky/)Venues:[insights](https://aclanthology.org/venues/insights/)\n\\|\n[WS](https://aclanthology.org/venues/ws/)SIG:Publisher:Association for Computational LinguisticsNote:Pages:45\u201352Language:URL:[https://aclanthology.org/2023.insights-1.5/](https://aclanthology.org/2023.insights-1.5/)DOI:[10.18653/v1/2023.insights-1.5](https://doi.org/10.18653/v1/2023.insights-1.5)Bibkey:guo-sarker-2023-socbertCite (ACL):Yuting Guo and Abeed Sarker. 2023. [SocBERT: A Pretrained Model for Social Media Text](https://aclanthology.org/2023.insights-1.5/). In _Proceedings of the Fourth Workshop on Insights from Negative Results in NLP_, pages 45\u201352, Dubrovnik, Croatia. Association for Computational Linguistics.Cite (Informal):[SocBERT: A Pretrained Model for Social Media Text](https://aclanthology.org/2023.insights-1.5/) (Guo & Sarker, insights 2023)Copy Citation:BibTeXMarkdownMODS XMLEndnoteMore options\u2026PDF:[https://aclanthology.org/2023.insights-1.5.pdf](https://aclanthology.org/2023.insights-1.5.pdf)Video:[https://aclanthology.org/2023.insights-1.5.mp4](https://aclanthology.org/2023.insights-1.5.mp4)\n[PDF](https://aclanthology.org/2023.insights-1.5.pdf) [Cite](https://aclanthology.org/2023.insights-1.5/) [Search](https://www.semanticscholar.org/search?q=SocBERT%3A+A+Pretrained+Model+for+Social+Media+Text) [Video](https://aclanthology.org/2023.insights-1.5.mp4) [Fix data](https://aclanthology.org/2023.insights-1.5/)\n* * *",
      "url": "https://aclanthology.org/2023.insights-1.5"
    },
    {
      "title": "Extended pre-processing pipeline for text classification: On the role of meta-feature representations, sparsification and selective sampling",
      "text": "[Skip to main content](https://www.sciencedirect.com/science/article/abs/pii/S030645731931461X#screen-reader-main-content) [Skip to article](https://www.sciencedirect.com/science/article/abs/pii/S030645731931461X#screen-reader-main-title)\n\n- [Access through\u00a0**your institution**](https://www.sciencedirect.com/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS030645731931461X)\n- [Purchase PDF](https://www.sciencedirect.com/getaccess/pii/S030645731931461X/purchase)\n\nSearch ScienceDirect\n\n## Article preview\n\n- [Abstract](https://www.sciencedirect.com/science/article/abs/pii/S030645731931461X#preview-section-abstract)\n- [Introduction](https://www.sciencedirect.com/science/article/abs/pii/S030645731931461X#preview-section-introduction)\n- [Section snippets](https://www.sciencedirect.com/science/article/abs/pii/S030645731931461X#preview-section-snippets)\n- [References (60)](https://www.sciencedirect.com/science/article/abs/pii/S030645731931461X#preview-section-references)\n- [Cited by (33)](https://www.sciencedirect.com/science/article/abs/pii/S030645731931461X#preview-section-cited-by)\n\n[![Elsevier](https://sdfestaticassets-us-east-1.sciencedirectassets.com/prod/558f6b3505d331efa27a89a25731aa712b0662a4/image/elsevier-non-solus.png)](https://www.sciencedirect.com/journal/information-processing-and-management)\n\n## [Information Processing & Management](https://www.sciencedirect.com/journal/information-processing-and-management)\n\n[Volume 57, Issue 4](https://www.sciencedirect.com/journal/information-processing-and-management/vol/57/issue/4), July 2020, 102263\n\n[![Information Processing & Management](https://ars.els-cdn.com/content/image/1-s2.0-S0306457319X00084-cov150h.gif)](https://www.sciencedirect.com/journal/information-processing-and-management/vol/57/issue/4)\n\n# Extended pre-processing pipeline for text classification: On the role of meta-feature representations, sparsification and selective sampling\n\nAuthor links open overlay panelWashingtonCunhaa, S\u00e9rgioCanutoa, FelipeViegasa, ThiagoSallesa, ChristianGomesa, VitorMangaravitea, ElaineResendea, ThiersonRosac, Marcos Andr\u00e9Gon\u00e7alvesa, LeonardoRochab\n\nShow more\n\nAdd to Mendeley\n\nShare\n\nCite\n\n[https://doi.org/10.1016/j.ipm.2020.102263](https://doi.org/10.1016/j.ipm.2020.102263) [Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&contentID=S030645731931461X&orderBeanReset=true)\n\n## Highlights\n\n- \u2022\nWe propose and orchestrate new pre-processing steps for text classification pipelines.\n\n- \u2022\nWe explore meta-feature representations, sparsification and selective sampling.\n\n- \u2022\nWe provide thorough evaluations of the trade-offs between costs and effectiveness.\n\n- \u2022\nOur final representations are more effective than word embeddings (up to 46%).\n\n- \u2022\nOur processes induce large reductions in computational costs and memory consumption.\n\n\n## Abstract\n\nText Classification pipelines are a sequence of tasks needed to be performed to classify documents into a set of predefined categories. The pre-processing phase (before training) of these pipelines involve different ways of transforming and manipulating the documents for the next (learning) phase. In this paper, we introduce _three_ new steps into the pre-processing phase of text classification pipelines to improve effectiveness while reducing the associated costs. The distance-based Meta-Features (MFs) generation step aims at reducing the dimensionality of the original term-document matrix while producing a potentially more informative space that explicitly exploits discriminative labeled information. The second step is a sparsification one aimed at making the MF representation less dense to reduce training costs and noise. The third step is a selective sampling (SS) aimed at removing lines (documents) of the matrix obtained in the previous step, by carefully selecting the \u201cbest\u201d documents for the learning phase. Our experiments show that the proposed extended pre-processing pipeline can achieve significant gains in effectiveness when compared to the original TF-IDF (up to 52%) and embedding-based representations (up to 46%), at a much lower cost (up to 9.7x faster in some datasets). Other main contributions of our work include a thorough and rigorous evaluation of the trade-offs between cost and effectiveness associated with the introduction of these new steps into the pipeline as well as a comprehensive comparative experimental evaluation of many alternatives in terms of representations, approaches, etc.\n\n## Access through your organization\n\nCheck access to the full text by signing in through your organization.\n\n[Access through **your institution**](https://www.sciencedirect.com/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS030645731931461X)\n\n## Introduction\n\nClassification pipelines are a sequence of tasks needed to be performed to classify digital objects (e.g., textual documents, images) into a set of predefined categories. In this paper, we are specially concerned with _pre-processing steps_ of _text classification_ pipelines.\n\nFig.\u00a01 (a) illustrates a typical text classification pipeline. From the raw textual content of documents, we usually apply some pre-processing, such as lower-casing, punctuation, stopwords removal and stemming. Then, an additional feature selection step may be performed, keeping only the most informative words. After that, a _m_\u202f\u00d7\u202f_n_ document-term matrix representation (or some latent term encoding) of the document is built. The most common representation of this matrix in text classification exploits the so-called TF-IDF paradigm. The major problems with the TF-IDF matrix representation have to do with its high dimensionality and sparseness. Other alternative representations that aim at producing a more compact space in terms of latent dimensions (e.g., distributional word embeddings) do exist\u00a0(Mikolov,\u00a0Grave, Bojanowski, Puhrsch, & Joulin, 2018a), but their unambiguous contribution to text classification tasks has not yet been fully established, as comparisons are not done with standard benchmarks following rigorous scientific procedures\u00a0(Sculley,\u00a0Snoek, Wiltschko, & Rahimi, 2018) (e.g., with multiples runs to check variability and with statistical significance tests to reject the null hypothesis of equality of results)1 Indeed, some of our experimental results demonstrate that, when compared using proper and rigorous experimental procedures, (word) embedding-based representations present no clear advantage in terms of effectiveness or cost than simpler TF-IDF representations, at least in the datasets we experimented with.\n\nIn any case, the complexity of the representation is directly associated with the costs involved in the whole classification process. This is particularly important given the development of recent techniques such as (word) embedding and deep neural networks, which require a considerable amount of data and computational power to properly work. These methods cause large increases in the cost of training, validation and actual classification of unknown (test) instances.\n\nIt used to be the case, not in a distant past, that in text classification tasks the cost of training a model would not be a dominant factor in the choice of a particular algorithm or representation, as the training process would be run just once and in a batch mode. This scenario has changed in the last few years, mainly due to the tremendous increase in the complexity of the representations (mainly those based on word embeddings), the complexity of the models (mainly those based on deep learning), the size of the datasets and the surge of new applications such real-time text stream classification\u00a0(Ren,\u00a0Peetz, Liang, van\u00a0Dolen, & de\u00a0Rijke, 2014). For instance, as we shall see next, some of the most complex models (e.g., fully connected feed-forward neural networks) when compared to SVMs with standard TF-IDF representations, are sometimes 30x - 80x slower. This can make their application somet...",
      "url": "https://www.sciencedirect.com/science/article/abs/pii/S030645731931461X"
    },
    {
      "title": "Meta-level sentiment models for big social data analysis",
      "text": "[Skip to main content](https://www.sciencedirect.com/science/article/abs/pii/S0950705114002068#screen-reader-main-content) [Skip to article](https://www.sciencedirect.com/science/article/abs/pii/S0950705114002068#screen-reader-main-title)\n\n- [Access through\u00a0**your institution**](https://www.sciencedirect.com/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0950705114002068)\n- [Purchase PDF](https://www.sciencedirect.com/getaccess/pii/S0950705114002068/purchase)\n\nSearch ScienceDirect\n\n## Article preview\n\n- [Abstract](https://www.sciencedirect.com/science/article/abs/pii/S0950705114002068#preview-section-abstract)\n- [Introduction](https://www.sciencedirect.com/science/article/abs/pii/S0950705114002068#preview-section-introduction)\n- [Section snippets](https://www.sciencedirect.com/science/article/abs/pii/S0950705114002068#preview-section-snippets)\n- [References (35)](https://www.sciencedirect.com/science/article/abs/pii/S0950705114002068#preview-section-references)\n- [Cited by (197)](https://www.sciencedirect.com/science/article/abs/pii/S0950705114002068#preview-section-cited-by)\n\n[![Elsevier](https://sdfestaticassets-us-east-1.sciencedirectassets.com/prod/558f6b3505d331efa27a89a25731aa712b0662a4/image/elsevier-non-solus.png)](https://www.sciencedirect.com/journal/knowledge-based-systems)\n\n## [Knowledge-Based Systems](https://www.sciencedirect.com/journal/knowledge-based-systems)\n\n[Volume 69](https://www.sciencedirect.com/journal/knowledge-based-systems/vol/69/suppl/C), October 2014, Pages 86-99\n\n[![Knowledge-Based Systems](https://ars.els-cdn.com/content/image/1-s2.0-S0950705114X00158-cov150h.gif)](https://www.sciencedirect.com/journal/knowledge-based-systems/vol/69/suppl/C)\n\n# Meta-level sentiment models for big social data analysis\n\nAuthor links open overlay panelFelipeBravo-Marquezab, MarceloMendozac, BarbaraPobleted\n\nShow more\n\nAdd to Mendeley\n\nShare\n\nCite\n\n[https://doi.org/10.1016/j.knosys.2014.05.016](https://doi.org/10.1016/j.knosys.2014.05.016) [Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&contentID=S0950705114002068&orderBeanReset=true)\n\n## Abstract\n\nPeople react to events, topics and entities by expressing their personal opinions and emotions. These reactions can correspond to a wide range of intensities, from very mild to strong. An adequate processing and understanding of these expressions has been the subject of research in several fields, such as business and politics. In this context, Twitter sentiment analysis, which is the task of automatically identifying and extracting subjective information from tweets, has received increasing attention from the Web mining community. Twitter provides an extremely valuable insight into human opinions, as well as new challenging _Big Data_ problems. These problems include the processing of massive volumes of streaming data, as well as the automatic identification of human expressiveness within short text messages. In that area, several methods and lexical resources have been proposed in order to extract sentiment indicators from natural language texts at both syntactic and semantic levels. These approaches address different dimensions of opinions, such as subjectivity, polarity, intensity and emotion. This article is the first study of how these resources, which are focused on different sentiment scopes, complement each other. With this purpose we identify scenarios in which some of these resources are more useful than others. Furthermore, we propose a novel approach for sentiment classification based on meta-level features. This supervised approach boosts existing sentiment classification of subjectivity and polarity detection on Twitter. Our results show that the combination of meta-level features provides significant improvements in performance. However, we observe that there are important differences that rely on the type of lexical resource, the dataset used to build the model, and the learning strategy. Experimental results indicate that manually generated lexicons are focused on emotional words, being very useful for polarity prediction. On the other hand, lexicons generated with automatic methods include neutral words, introducing noise in the detection of subjectivity. Our findings indicate that polarity and subjectivity prediction are different dimensions of the same problem, but they need to be addressed using different subspace features. Lexicon-based approaches are recommendable for polarity, and stylistic part-of-speech based approaches are meaningful for subjectivity. With this research we offer a more global insight of the resource components for the complex task of classifying human emotion and opinion.\n\n## Access through your organization\n\nCheck access to the full text by signing in through your organization.\n\n[Access through **your institution**](https://www.sciencedirect.com/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0950705114002068)\n\n## Introduction\n\nHumans naturally communicate by expressing feelings, opinions and preferences about the environment that surrounds them. Moreover, the emotional load of a message, written or verbal, is extremely important when it comes to understanding its true meaning. Therefore, opinion and sentiment comprehension are a key aspect of human interaction. For many years, emotions have been studied individually and also collectively, in order to understand human behavior. The collective or social analysis of opinions and sentiment responds to the need to measure the impact or polarization that a certain event or entity has on a group of individuals. Social sentiment has been studied in politics to understand and forecast election outcomes, and also in marketing, to predict the success of a certain product and to recommend others.\n\nBefore the rise of online social media, gathering data on opinions was expensive and usually achieved at very small scale. When users on the Web started communicating massively through this channel, social networks became overloaded with opinionated data. In that aspect, social media has opened new possibilities for human interaction. Microblogging platforms, in particular, allow real-time sharing of comments and opinions. Twitter,1 an extremely popular microblogging platform, has millions of users that share millions of personal posts on a daily basis. This rich and enormous volume of user generated data offers endless opportunities for the study of human behavior.\n\nManual classification of millions of posts for opinion mining is an unfeasible task. Therefore, several methods have been proposed to automatically infer human opinions from natural language texts. Computational sentiment analysis methods attempt to measure different opinion dimensions. A number of methods for polarity estimation have been proposed in \\[3\\], \\[12\\], \\[13\\], \\[23\\] discussed in depth in Section 2. Polarity estimation is reduced into a classification problem with three polarity classes \u2013 positive, negative and neutral \u2013 with supervised and unsupervised approaches being proposed for this task. In the case of unsupervised approaches, a number of lexicon resources with positive and negative scores for words exist. A related task is the detection of _subjectivity_, which is the specific task of separating factual from opinionated text. This problem has also been addressed with supervised approaches \\[33\\]. In addition, opinion intensities (strengths) have also become a matter of study, for example, SentiStrength \\[30\\] estimates positive and negative strength scores at sentence level. Finally, the emotion estimation problem has also been addressed with the creation of lexicons. The Plutchik wheel of emotions, proposed in \\[28\\], is composed of four pairs of opposite emotion states: _joy-trust_, _sadness-anger_, _surprise-fear_, and _anticipation-disgust_. Mohammad et al. \\[20\\] labeled a number of words according to Plutchik emotional categories, developing the NRC word-em...",
      "url": "https://www.sciencedirect.com/science/article/abs/pii/S0950705114002068"
    },
    {
      "title": "Tweet2Vec: Character-Based Distributed Representations for Social Media",
      "text": "# Computer Science > Machine Learning\n\n**arXiv:1605.03481** (cs)\n\n\\[Submitted on 11 May 2016 ( [v1](https://arxiv.org/abs/1605.03481v1)), last revised 17 May 2016 (this version, v2)\\]\n\n# Title:Tweet2Vec: Character-Based Distributed Representations for Social Media\n\nAuthors: [Bhuwan Dhingra](https://arxiv.org/search/cs?searchtype=author&query=Dhingra,+B), [Zhong Zhou](https://arxiv.org/search/cs?searchtype=author&query=Zhou,+Z), [Dylan Fitzpatrick](https://arxiv.org/search/cs?searchtype=author&query=Fitzpatrick,+D), [Michael Muehl](https://arxiv.org/search/cs?searchtype=author&query=Muehl,+M), [William W. Cohen](https://arxiv.org/search/cs?searchtype=author&query=Cohen,+W+W)\n\nView a PDF of the paper titled Tweet2Vec: Character-Based Distributed Representations for Social Media, by Bhuwan Dhingra and 4 other authors\n\n[View PDF](https://arxiv.org/pdf/1605.03481)\n\n> Abstract:Text from social media provides a set of challenges that can cause traditional NLP approaches to fail. Informal language, spelling errors, abbreviations, and special characters are all commonplace in these posts, leading to a prohibitively large vocabulary size for word-level approaches. We propose a character composition model, tweet2vec, which finds vector-space representations of whole tweets by learning complex, non-local dependencies in character sequences. The proposed model outperforms a word-level baseline at predicting user-annotated hashtags associated with the posts, doing significantly better when the input contains many out-of-vocabulary words or unusual character sequences. Our tweet2vec encoder is publicly available.\n\n|     |     |\n| --- | --- |\n| Comments: | 6 pages, 2 figures, 4 tables, accepted as conference paper at ACL 2016 |\n| Subjects: | Machine Learning (cs.LG); Computation and Language (cs.CL) |\n| Cite as: | [arXiv:1605.03481](https://arxiv.org/abs/1605.03481) \\[cs.LG\\] |\n|  | (or [arXiv:1605.03481v2](https://arxiv.org/abs/1605.03481v2) \\[cs.LG\\] for this version) |\n|  | [https://doi.org/10.48550/arXiv.1605.03481](https://doi.org/10.48550/arXiv.1605.03481)<br>Focus to learn more<br>arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Bhuwan Dhingra \\[ [view email](https://arxiv.org/show-email/10585aa8/1605.03481)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/1605.03481v1)**\nWed, 11 May 2016 15:30:09 UTC (559 KB)\n\n**\\[v2\\]**\nTue, 17 May 2016 15:00:38 UTC (559 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Tweet2Vec: Character-Based Distributed Representations for Social Media, by Bhuwan Dhingra and 4 other authors\n\n- [View PDF](https://arxiv.org/pdf/1605.03481)\n- [TeX Source](https://arxiv.org/src/1605.03481)\n- [Other Formats](https://arxiv.org/format/1605.03481)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=1605.03481&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=1605.03481&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2016-05](https://arxiv.org/list/cs.LG/2016-05)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/1605.03481?context=cs)\n\n[cs.CL](https://arxiv.org/abs/1605.03481?context=cs.CL)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1605.03481)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1605.03481)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:1605.03481)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1605.html#DhingraZFMC16) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/DhingraZFMC16)\n\n[Bhuwan Dhingra](https://dblp.uni-trier.de/search/author?author=Bhuwan%20Dhingra)\n\n[Zhong Zhou](https://dblp.uni-trier.de/search/author?author=Zhong%20Zhou)\n\n[Dylan Fitzpatrick](https://dblp.uni-trier.de/search/author?author=Dylan%20Fitzpatrick)\n\n[Michael Muehl](https://dblp.uni-trier.de/search/author?author=Michael%20Muehl)\n\n[William W. Cohen](https://dblp.uni-trier.de/search/author?author=William%20W.%20Cohen)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/1605.03481&description=Tweet2Vec: Character-Based Distributed Representations for Social Media) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/1605.03481&title=Tweet2Vec: Character-Based Distributed Representations for Social Media)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1605.03481) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/1605.03481"
    },
    {
      "title": "Feature Engineering vs BERT on Twitter Data",
      "text": "# Computer Science > Computation and Language\n\n**arXiv:2210.16168** (cs)\n\n\\[Submitted on 28 Oct 2022\\]\n\n# Title:Feature Engineering vs BERT on Twitter Data\n\nAuthors: [Ryiaadh Gani](https://arxiv.org/search/cs?searchtype=author&query=Gani,+R), [Lisa Chalaguine](https://arxiv.org/search/cs?searchtype=author&query=Chalaguine,+L)\n\nView a PDF of the paper titled Feature Engineering vs BERT on Twitter Data, by Ryiaadh Gani and 1 other authors\n\n[View PDF](https://arxiv.org/pdf/2210.16168)\n\n> Abstract:In this paper, we compare the performances of traditional machine learning models using feature engineering and word vectors and the state-of-the-art language model BERT using word embeddings on three datasets. We also consider the time and cost efficiency of feature engineering compared to BERT. From our results we conclude that the use of the BERT model was only worth the time and cost trade-off for one of the three datasets we used for comparison, where the BERT model significantly outperformed any kind of traditional classifier that uses feature vectors, instead of embeddings. Using the BERT model for the other datasets only achieved an increase of 0.03 and 0.05 of accuracy and F1 score respectively, which could be argued makes its use not worth the time and cost of GPU.\n\n|     |     |\n| --- | --- |\n| Subjects: | Computation and Language (cs.CL); Machine Learning (cs.LG) |\n| Cite as: | [arXiv:2210.16168](https://arxiv.org/abs/2210.16168) \\[cs.CL\\] |\n| (or [arXiv:2210.16168v1](https://arxiv.org/abs/2210.16168v1) \\[cs.CL\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2210.16168](https://doi.org/10.48550/arXiv.2210.16168) <br>Focus to learn more<br>arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Lisa Andreevna Chalaguine \\[ [view email](https://arxiv.org/show-email/01fad4a8/2210.16168)\\] **\\[v1\\]**\nFri, 28 Oct 2022 14:43:13 UTC (123 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Feature Engineering vs BERT on Twitter Data, by Ryiaadh Gani and 1 other authors\n\n- [View PDF](https://arxiv.org/pdf/2210.16168)\n\n[view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.CL\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2210.16168&function=prev&context=cs.CL)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2210.16168&function=next&context=cs.CL)\n\n[new](https://arxiv.org/list/cs.CL/new) \\| [recent](https://arxiv.org/list/cs.CL/recent) \\| [2022-10](https://arxiv.org/list/cs.CL/2022-10)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2210.16168?context=cs) [cs.LG](https://arxiv.org/abs/2210.16168?context=cs.LG)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2210.16168)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2210.16168)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2210.16168)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2210.16168) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2210.16168"
    },
    {
      "title": "",
      "text": "arXiv:2505.23797v1 [cs.CL] 26 May 2025\nDetection of Suicidal Risk on Social Media: A\nHybrid Model\n*\nZaihan Yang\nSuffolk University\nBoston, USA\nzyang13@suffolk.edu\nRyan Leonard\nSuffolk University\nBoston, USA\nrleonard2@su.suffolk.edu\nHien Tran\nSuffolk University\nBoston, USA\nhien.tran@su.suffolk.edu\nRory Driscoll\nSuffolk University\nBoston, USA\nrdriscoll@su.suffolk.edu\nChadbourne Davis\nSuffolk University\nBoston, USA\nchad.davis@su.suffolk.edu\nAbstract\u2014Suicidal thoughts and behaviors are increasingly\nrecognized as a critical societal concern, highlighting the urgent\nneed for effective tools to enable early detection of suicidal\nrisk. In this work, we develop robust machine learning models\nthat leverage Reddit posts to automatically classify them into\nfour distinct levels of suicide risk severity. We frame this as a\nmulti-class classification task and propose a RoBERTa-TF-IDF\u0002PCA Hybrid model, integrating the deep contextual embeddings\nfrom Robustly Optimized BERT Approach (RoBERTa), a state\u0002of-the-art deep learning transformer model, with the statistical\nterm-weighting of TF-IDF, further compressed with PCA, to\nboost the accuracy and reliability of suicide risk assessment.\nTo address data imbalance and overfitting, we explore various\ndata resampling techniques and data augmentation strategies\nto enhance model generalization. Additionally, we compare our\nmodel\u2019s performance against that of using RoBERTa only, the\nBERT model and other traditional machine learning classifiers.\nExperimental results demonstrate that the hybrid model can\nachieve improved performance, giving a best weighted F1 score\nof 0.7512.\nIndex Terms\u2014Classification, Deep Learning, Machine learn\u0002ing, Transformers, Large Language models, data imbalance, data\naugmentation, Evaluation, Suicidal Ideation Detection\nI. INTRODUCTION\nSuicidal thoughts and behaviors are increasingly becoming\na significant societal concern. As of the latest estimates from\nWorld Health Organization, approximately 700,000 to 800,000\npeople die by suicide globally each year. In the U.S., suicide\nis the second leading cause of death for individuals aged\n10-34 and the fourth leading cause for those aged 35-64.\nSuicidal thoughts can vary in severity, ranging from explicit\nand repetitive suicidal feelings, to actively planning suicide or\nengaging in self-harm behaviors like cutting or burning, and\nultimately to making actual attempts through methods such as\ncutting, jumping, drug overdose, or using firearms.\nVarious factors influence mental health, leading to serious\noutcomes such as mental health disorders and suicide of\ndifferent severity [1]. However, many of these factors can\nbe mitigated or addressed through effective intervention pro\u0002grams, preventing numerous suicidal tragedies. Efforts have\nbeen made from both psychologists and computer scientists to\ndevelop effective tools for the early detection and identification\nof potential suicidal risk to enable timely intervention. For\npsychologists, they conducted systematic interviews, explored\nelectronic health records to provide solid evidence supporting\nthe findings of potential suicidal factors through statistical\nanalysis [2]\u2013[4]; Computer scientists, in contrast, typically\nemploy machine learning or deep learning techniques using\ncontextual data from social media platforms for suicidal risk\ndetection [1], [7]\u2013[9], [11], [12], [16].\nSocial media platforms like Twitter (X), Reddit, Facebook,\nTumblr, Weibo and etc, provide a valuable space for in\u0002dividuals to express their thoughts, feelings, and opinions,\noffering rich data resources for scientists, particularly com\u0002puter scientists, to develop machine/deep learning models\nfor detecting suicidal ideation and behaviors. As compared\nto Twitter (X) or other platforms, Reddit provides longer\n(no word limit), well-structured (with subreddits), and more\ncontext-rich discussions, making it an excellent platform for\ndetecting suicidal risk. Its support of anonymity and openness\nenables users more likely to share deeply personal struggles\nwithout fear of judgment. In spit of these benefits, using social\nmedia like Reddit for suicidal risk assessment presents several\nchallenges, including data privacy concerns, the need for large\u0002scale labeled datasets, and the complexity of understanding\nlinguistic nuances across different platforms and cultures.\nMoreover, the presence of noise, misinformation, and context\u0002dependent meanings in social media posts adds another layer\nof difficulty in accurately identifying suicidal risk. Another\nsignificant challenge lies in the varying levels of suicidal\nideation\u2014ranging from moderate to severe. Individuals expe\u0002riencing more severe ideation (e.g., those who have attempted\nsuicide) are often less likely to express their thoughts openly\non social media. Our data collection and labeling process\nsupports this observation, resulting in a class imbalance where\nhigh-risk cases are underrepresented. This imbalance poses a\nserious obstacle to building accurate and reliable classification\nmodels.\nExisting methods for analyzing suicidal risk in social media\nrely on both traditional machine learning techniques and deep\nlearning approaches, such as transformers. Traditional machine\nlearning techniques, often based on handcrafted features and\nstatistical models, provide interpretability and require rela\u0002tively fewer computational resources [13], [25]. However,\nthey struggle with capturing complex linguistic structures and\ncontextual meanings, limiting their effectiveness in nuanced\nsuicide risk prediction. On the other hand, deep learning\ntechniques, particularly transformer-based models like BERT\n[29], RoBERTa [30], Gemma and Llama, excel at capturing\ndeep contextual representations of language. These models\nhave demonstrated superior performance in understanding\nsentiment, detecting suicidal ideation, and processing large\u0002scale text data. Despite their advantages, deep learning models\nare often criticized for their lack of interpretability, high data\ndependency, and comparatively high computational costs.\nTo address these limitations while combining the strengths\nof both approaches, we propose a hybrid model that integrates\nword embeddings learned from RoBERTa with TF-IDF (Term\nFrequency-Inverse Document Frequency). RoBERTa captures\ndeep contextualized representations of words, allowing the\nmodel to understand the semantics and nuances of suicidal\nexpressions, while TF-IDF enhances the ability to identify\nimportant terms based on their statistical significance across\ndocuments. The main contribution of our work is highlighted\nas follows:\n\u2022 We proposed a RoBERTa-TF-IDF Hybrid model, integrating\nthe deep contextual embeddings from Robustly Optimized\nBERT Approach (RoBERTa), a state-of-the-art deep learn\u0002ing transformer model, with the statistical term-weighting\nof TF-IDF (Term Frequency-Inverse Document Frequency);\n\u2022 To reduce noise and vocabulary dimensionality, thereby\nenhancing efficiency and model performance, we applied\nPrincipal Component Analysis (PCA) to TF-IDF vectors\nand integrated the reduced representations with word em\u0002beddings learned from RoBERTa.\n\u2022 We scraped data from Reddit platform, and conducted\nthorough human labeling, providing sound annotations for\nposts in terms of their suicidal risk severity;\n\u2022 We explored different data resampling as well as data\naugmentation techniques to deal with data imbalance and\noverfitting, aiming to obtain a more generalized and robust\nmodel;\n\u2022 We compared the classification performance using our pro\u0002posed hybrid model, with that of using RoBERTa only,\nthe BERT model and other traditional machine learning\nclassifiers. Experimental results demonstrate the improved\neffectiveness of our hybrid model.\nII. LITERATURE REVIEW\nIn this section, we present a literature review of existing\nresearch on suicidal risk detection, focusing on four key\naspects: datasets, modeling approaches, feature engineering,\nand risk severity classification.\nPsychologists often rely on p...",
      "url": "https://www.arxiv.org/pdf/2505.23797"
    },
    {
      "title": "Exploring the Performance of Baseline Text Mining Frameworks for Early Prediction of Self Harm Over Social Media",
      "text": "Exploring the Performance of Baseline Text Mining\nFrameworks for Early Prediction of Self Harm Over\nSocial Media\nTanmay Basu1,2,3, Georgios V. Gkoutos1,2,3,4,5\n1Center for Computational Biology, University of Birmingham, UK\n2\nInstitute of Translational Medicine, University Hospitals Birmingham, UK\n3MRC Health Data Research UK (HDR UK), Midlands Site, Birmingham, UK\n4NIHR Experimental Cancer Medicine Centre, Birmingham, UK\n4NIHR Surgical Reconstruction and Microbiology Research Centre, Birmingham, UK\nAbstract\nThe Task 2 of CLEF eRisk 2021 challenge focuses on early prediction of self-harm based on sequen\u0002tially processing pieces of text over social media. The workshop has organized three tasks this year\nand released different corpora for the individual tasks and these are developed using the posts and com\u0002ments over Reddit, a popular social media. The text mining group at Center for Computational Biology\nin University of Birmingham, UK has participated in Task 2 of this challenge and submitted five runs\nfor five different text mining frameworks. The paper explore the performance of different text mining\ntechniques for early risk prediction of self-harm. The techniques involve various classifiers and feature\nengineering schemes. The simple bag of words model and the Doc2Vec based document embeddings\nhave been used to build features from free text. Subsequently, ada boost, random forest, logistic regres\u0002sion and support vector machine (SVM) classifiers are used to identify self-harm from the given texts.\nThe experimental analysis on the test corpus show that the SVM classifier using the conventional bag of\nwords model outperforms the other methods for identifying self-harm. This framework achieves best\nscore in terms of precision among all the submissions of eRisk 2021 challenge for identifying self harm\nover social media.\nKeywords\nidentification of self-harm, text classification, information extraction, text mining\n1. Introduction\nEarly risk prediction is a new research area potentially applicable to a wide variety of situations\nsuch as identifying people with risk of suicidal attempts over social media. Online social plat\u0002forms allow people to share and express their thoughts and feelings freely and publicly with\nother people [1]. The information available over social media is a rich source for sentiment\nanalysis or inferring mental health issues [2]. The CLEF eRisk 2021 shared task focuses on\nCLEF 2021 \u2013 Conference and Labs of the Evaluation Forum, September 21\u201324, 2021, Bucharest, Romania\n\" welcometanmay@gmail.com (T. Basu); g.gkoutos@bham.ac.uk (G. V. Gkoutos)\n~ https://www.birmingham.ac.uk/staff/profiles/cancer-genomic/basu-tanmay.aspx (T. Basu);\nhttps://www.birmingham.ac.uk/staff/profiles/cancer-genomic/gkoutos-georgios.aspx (G. V. Gkoutos)\n\u0012 0000-0001-9536-8075 (T. Basu); 0000-0002-2061-091X (G. V. Gkoutos)\n\u00a9 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).\nCEUR\nWorkshop\nProceedings\nhttp://ceur-ws.org\nISSN 1613-0073\nCEUR Workshop Proceedings (CEUR-WS.org)\nearly prediction of self harm over social media. The main goal of eRisk 2021 challenge is to\ninstigate discussion on the creation of reusable benchmarks for evaluating early risk detection\nalgorithms by exploring issues of evaluation methodology, effectiveness metrics and other\nprocesses related to the creation of test collections for early detection of self harm [3]. The\nworkshop has organized three tasks this year and released different corpora for the individual\ntasks and these are developed using the posts and comments over Reddit, a popular social media\n[3]. However, we have participated in task 2, which focuses on early prediction of self-harm\nover social media.\nSuicide ranks among the leading causes of death around the world [4, 5]. Self harm is a\ntype of suicide attempts that leads to death most of the times. It is associated with a number\nof adverse outcomes, and is strongly associated with future suicide [6, 7]. The World Health\nOrganization has recommended that member states develop self-harm monitoring systems as\npart of their suicide prevention efforts [5]. However, it is generally difficult to identify self\nharm from the early symptoms. The treatment for these diseases can be started on time, if the\nalarming symptoms are diagnosed properly. The recent research has focused on identifying\nself-harm from medical records using machine learning and text mining approaches [8, 4, 5].\nThe CLEF eRisk Lab have been organizing shared task on early risk prediction of self harm over\nsocial media since 2019 [3, 9, 10].\nBurdisso et al. developed a text classification framework for early risk detection based on\nconfidence between the concepts and categories which performs very well for early prediction\nof self harm in eRisk 2019 [11, 12]. The BiTeM group at eRisk 2019 explored different baseline\napproaches including convolutional neural network, bag words model and SVM classifier for\nearly prediction of self harm [13]. Mart\u0131nez et al. used different BERT based classifiers which\nwere trained specifically for early prediction of self harm in eRisk 2020 [14]. They used a variety\nof pretrained models including BERT, DistillBERT, RoBERTa and XLM-RoBERTa and finetuned\nthese models on various training corpora from Reddit, which they created [14, 10]. Ageitos et al.\nimplemented a machine learning approach using textual features and SVM classifier for early\nprediction of self harm in eRisk 2020 [15]. In order to extract relevant features, they followed\na sliding window approach that handles the last messages published by any given user. The\nfeatures considered a wide range of variables, such as title length, words in the title, punctuation,\nemoticons, and other feature sets obtained from sentiment analysis, first person pronouns and\nwords of non-suicidal self-injury [15, 10].\nIn this paper, different text mining frameworks have been developed to identify self harm\nover social media data released as part of eRisk 2021 shared task. The aim is to train a machine\nlearning classifier using the given training corpus to classify individual documents of the test\ncorpus. The performance of a text classification technique is highly dependent on the potential\nfeatures of a corpus. Therefore the performance of different classifiers have been tested follow\u0002ing different feature engineering techniques. The conventional bag of words model [16] and\nthe Doc2Vec based deep learning model [17, 18] have been used to generate features from the\ngiven corpora. We have explored two different term weighting schemes of the bag of words\nmodel, viz., term frequency and inverse frequency (TF-IDF) based term weighting scheme [19]\nand entropy based term weighting scheme [20, 21].\nSubsequently, the performance of ada boost [22], logistic regression [23], random forest [24]\nand support vector machine [25] classifiers have been reported using the bag of words features\nand the Doc2Vec based features individually on the training corpus following 10 fold cross\nvalidation. Therefore, the best five frameworks are chosen based on their performance on the\ntraining corpus in terms of fmeasure and subsequently they have been implemented on the test\ncorpus. The experimental results show that the support vector machine classifier using TF-IDF\nbased term weighting scheme outperforms the other frameworks on the test corpus in terms\nof precision. Moreover, this framework achieves the best precision score among all the runs\nsubmitted in Task 2 of the eRisk 2021 shared task.\nThe paper is organized as follows. The proposed text mining frameworks are explained in\nsection 2. Section 3 describes the experimental evaluation. The conclusion is presented in\nsection 4.\n2. Proposed Frameworks\nVarious text mining frameworks have been proposed here to identify the documents that indicate\nthe risk of self harm from the given corpus. The documents of the corpus are released in XML\n...",
      "url": "https://ceur-ws.org/Vol-2936/paper-76.pdf"
    }
  ]
}