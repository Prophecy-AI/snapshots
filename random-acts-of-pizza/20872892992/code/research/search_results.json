{
  "query": "What ensembling strategies are most effective for Kaggle competitions combining text and tabular data?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Ensembling is the single most reliable way to push a Kaggle solution past the \u201cgood\u2011enough\u201d threshold when the data contain both free\u2011text fields and structured columns.  The current best practice is to train **heterogeneous base learners** \u2013 e.g. a transformer\u2011based text model (BERT, RoBERTa, or an LLM\u2011derived embedding) and several classical tabular algorithms such as LightGBM, CatBoost, or Random Forest \u2013 and then fuse their predictions with either **weighted averaging** or a **stacked meta\u2011learner**.  AutoGluon\u2019s multimodal pipeline does exactly this: it fits a TextPredictor alongside a suite of tabular models and automatically combines them via a weighted ensemble or a stack ensemble, letting you tune the blend weights on a validation split\u202f([auto.gluon.ai](https://auto.gluon.ai/0.1.0/tutorials/tabular_prediction/tabular-multimodal-text-others.html)).  In practice, the weights are learned from out\u2011of\u2011fold predictions, which stabilises the final score and reduces over\u2011fitting to any single modality.\n\nA second, complementary strategy is to **augment the tabular feature space with contextual LLM embeddings** and then apply a strong ensemble classifier (e.g. LightGBM\u202f+\u202fCatBoost\u202f+\u202fXGBoost) on the enriched table.  An ablation study showed that adding LLM\u2011derived vectors to the original columns and ensembling several gradient\u2011boosted trees consistently outperformed either modality alone, especially when the text is semantically rich\u202f([arxiv.org/abs/2411.01645](https://arxiv.org/abs/2411.01645)).  The \u201cBag of Tricks for Multimodal AutoML\u201d paper further recommends **training separate models on raw text (n\u2011grams) and on LLM embeddings, then blending their outputs**, and also suggests **cross\u2011modal alignment tricks (e.g., concatenating token\u2011level attention scores to tabular features) before ensembling**, which has proven effective across a benchmark of 22 multimodal datasets\u202f([arxiv.org/html/2412.16243v1](https://arxiv.org/html/2412.16243v1)).\n\nFinally, recent Kaggle winners have leveraged **parameter\u2011efficient ensembling** such as the TabM approach, which injects lightweight adapters into a base tabular network and ensembles multiple adapter\u2011augmented copies without training full models from scratch.  This yields diversity at a fraction of the compute cost and pairs well with the weighted\u2011average or stacking schemes described above\u202f([github.com/yandex-research/tabm](https://github.com/yandex-research/tabm)).  Combining these ideas\u2014modal\u2011specific base learners, LLM\u2011enhanced tabular features, and either weighted or stacked ensembles (often blended across folds)\u2014constitutes the most effective recipe for Kaggle competitions that mix text and tabular data.",
      "url": ""
    },
    {
      "title": "Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/abs/2411.01645"
    },
    {
      "title": "Bag of Tricks for Multimodal AutoML \n with Image, Text, and Tabular Data",
      "text": "Bag of Tricks for Multimodal AutoML with Image, Text, and Tabular Data\n# Bag of Tricks for Multimodal AutoML\nwith Image, Text, and Tabular Data\nZhiqiang Tang\nAmazon Web Services\nzqtang@amazon.com\n\\\\AndZihan Zhong\nTsinghua University\nzhongzh22@mails.tsinghua.edu.cn\n\\\\ANDTong He\nAmazon Web Services\nhtong@amazon.com\n\\\\AndGerald Friedland\nAmazon Web Services\ngfriedla@amazon.com\nWork done while interning at Amazon Web Services.\n###### Abstract\nThis paper studies the best practices for automatic machine learning (AutoML). While previous AutoML efforts have predominantly focused on unimodal data, the multimodal aspect remains under-explored. Our study delves into classification and regression problems involving flexible combinations of image, text, and tabular data. We curate a benchmark comprising 22 multimodal datasets from diverse real-world applications, encompassing all 4 combinations of the 3 modalities. Across this benchmark, we scrutinize design choices related to multimodal fusion strategies, multimodal data augmentation, converting tabular data into text, cross-modal alignment, and handling missing modalities. Through extensive experimentation and analysis, we distill a collection of effective strategies and consolidate them into a unified pipeline, achieving robust performance on diverse datasets.\n## 1Introduction\nAutomatic machine learning (AutoML)> [\n[> 46\n](https://arxiv.org/html/2412.16243v1#bib.bib46)> , [> 81\n](https://arxiv.org/html/2412.16243v1#bib.bib81)> ]\naims to automate the process of building ML models, including data preprocessing> [\n[> 14\n](https://arxiv.org/html/2412.16243v1#bib.bib14)> ]\n, model selection> [\n[> 2\n](https://arxiv.org/html/2412.16243v1#bib.bib2)> ]\n, hyperparameter tuning> [\n[> 22\n](https://arxiv.org/html/2412.16243v1#bib.bib22)> ]\n, model evaluation> [\n[> 70\n](https://arxiv.org/html/2412.16243v1#bib.bib70)> ]\n, and so on. As the diversity and complexity of state-of-the-art ML techniques grow, AutoML becomes increasingly important to democratize these techniques for broader communities with little or no ML background> [\n[> 39\n](https://arxiv.org/html/2412.16243v1#bib.bib39)> , [> 29\n](https://arxiv.org/html/2412.16243v1#bib.bib29)> ]\n. It also provides experienced practitioners with \"hands-off-the-wheel\" solutions for tackling numerous distinct problems. AutoML systems> [\n[> 20\n](https://arxiv.org/html/2412.16243v1#bib.bib20)> , [> 23\n](https://arxiv.org/html/2412.16243v1#bib.bib23)> ]\ntypically offer user-friendly APIs and robust performance in solving real-world problems. Central to an AutoML system is a collection of \"tricks\" that significantly enhance performance.\nMany studies> [\n[> 108\n](https://arxiv.org/html/2412.16243v1#bib.bib108)> , [> 23\n](https://arxiv.org/html/2412.16243v1#bib.bib23)> , [> 20\n](https://arxiv.org/html/2412.16243v1#bib.bib20)> , [> 46\n](https://arxiv.org/html/2412.16243v1#bib.bib46)> ]\nfocus on the best practices of modeling tabular (categorical or numeric) data. While there has been some progress in other data modalities such as image> [\n[> 34\n](https://arxiv.org/html/2412.16243v1#bib.bib34)> ]\nand text> [\n[> 41\n](https://arxiv.org/html/2412.16243v1#bib.bib41)> ]\n, a noticeable gap exists for multimodal data. Many real-world applications> [\n[> 44\n](https://arxiv.org/html/2412.16243v1#bib.bib44)> , [> 67\n](https://arxiv.org/html/2412.16243v1#bib.bib67)> ]\ninvolve multiple modalities such as image, text, and tabular data. For example,[Table1](https://arxiv.org/html/2412.16243v1#S1.T1)illustrates actual data from the PetFinder Challenge> [\n[> 102\n](https://arxiv.org/html/2412.16243v1#bib.bib102)> ]\n, which aims to predict the speed of pet adoptions. The input of this task includes pet\u2019s profile picture, text descriptions, categorial fields like gender and color, and numeric fields like age and adoption fee. This paper considers tables of this form where rows contain IID samples, and the columns are predictive features. We refer to the value in a particular row and column as a field, which can be an image path, a long text passage, a categorical or numeric value. We focus on the classification and regression tasks where each sample has a single categorical or numeric value to predict.\nThis paper examines a collection of tricks for multimodal supervised learning with a mix of image, text, and tabular data. Our study includes basic procedure refinements (such as greedy soup> [\n[> 94\n](https://arxiv.org/html/2412.16243v1#bib.bib94)> ]\nand gradient clipping> [\n[> 101\n](https://arxiv.org/html/2412.16243v1#bib.bib101)> ]\n) for training models, as well as advanced strategies specialized for multimodal learning> [\n[> 65\n](https://arxiv.org/html/2412.16243v1#bib.bib65)> ]\n. Key aspects of multimodal learning include determining the best multimodal fusion strategies (early> [\n[> 105\n](https://arxiv.org/html/2412.16243v1#bib.bib105)> ]\nvs. late fusion> [\n[> 87\n](https://arxiv.org/html/2412.16243v1#bib.bib87)> ]\n, parallel> [\n[> 87\n](https://arxiv.org/html/2412.16243v1#bib.bib87)> ]\nvs. sequential fusion> [\n[> 75\n](https://arxiv.org/html/2412.16243v1#bib.bib75)> ]\n), conducting data augmentation for multimodal data (independent> [\n[> 62\n](https://arxiv.org/html/2412.16243v1#bib.bib62)> , [> 92\n](https://arxiv.org/html/2412.16243v1#bib.bib92)> ]\nvs. joint augmentation> [\n[> 58\n](https://arxiv.org/html/2412.16243v1#bib.bib58)> ]\n, input> [\n[> 62\n](https://arxiv.org/html/2412.16243v1#bib.bib62)> , [> 92\n](https://arxiv.org/html/2412.16243v1#bib.bib92)> ]\nvs. feature augmentation> [\n[> 85\n](https://arxiv.org/html/2412.16243v1#bib.bib85)> ]\n), assessing the usefulness of cross-modal alignment> [\n[> 69\n](https://arxiv.org/html/2412.16243v1#bib.bib69)> ]\nfor supervised learning, and handling samples with missing modalities> [\n[> 100\n](https://arxiv.org/html/2412.16243v1#bib.bib100)> ]\n. For each aspect, we investigate multiple strategy alternatives. Rather than proposing new techniques, our goal is to gather existing ones from various literatures and codebases and conduct an empirical evaluation in a novel yet practical setting with flexible mixtures of image, text, and tabular modalities.\nWe evaluate these tricks on a new benchmark of 22 datasets collected from various domains and real-world applications> [\n[> 72\n](https://arxiv.org/html/2412.16243v1#bib.bib72)> , [> 63\n](https://arxiv.org/html/2412.16243v1#bib.bib63)> , [> 26\n](https://arxiv.org/html/2412.16243v1#bib.bib26)> ]\n. This benchmark encompasses all 4 possible combinations of image, text, and tabular modalities. Our findings indicate that while some tricks consistently perform well across the entire benchmark, many are effective for certain modality combinations but struggle to generalize across others. Ultimately, we employ a learnable ensembling method> [\n[> 9\n](https://arxiv.org/html/2412.16243v1#bib.bib9)> ]\nto integrate all the techniques into a single pipeline, resulting in superior performance compared to each individual technique. The weights assigned to each technique in the ensemble not only reveal their relative importance but also provide insights into the specific aspects of multimodal learning they address. Interestingly, some tricks, although not improving performance on their own, contribute positively to the ensemble, highlighting the complementary nature of different tricks.\nTable 1:Example of multimodal data with image (Image), text (Description), numeric (Age, Fee), and categorical (Color1, Gender) features from the Petfinder Challenge. The features shown here are a subset of the total 23 features. Based on these features, the task is to predict the pet adoption speed.![[Uncaptioned image]](x1.png)\n## 2Related Work\nAutoML> [\n[> 43\n](https://arxiv.org/html/2412.16243v1#bib.bib43)> , [> 103\n](https://arxiv.org/html/2412.16243v1#bib.bib103)> , [> 77\n](https://arxiv.org/html/2412.16243v1#bib.bib77)> ]\nis an emerging field that aims to incorporate best practices in machine learning (ML) and automate the process of building ML mod...",
      "url": "https://arxiv.org/html/2412.16243v1"
    },
    {
      "title": "Multimodal Data Tables: Combining BERT/Transformers and Classical Tabular Models \u00b6",
      "text": "<div><p>To utilize the <code><span>TextPredictor</span></code> model inside of <code><span>TabularPredictor</span></code>,\nwe must specify the <code><span>hyperparameters</span> <span>=</span> <span>'multimodal'</span></code> in AutoGluon\nTabular. Internally, this will train multiple tabular models as well as\nthe TextPredictor model, and then combine them via either a weighted\nensemble or stack ensemble, as explained in <a href=\"https://arxiv.org/pdf/2003.06505.pdf\">AutoGluon Tabular\nPaper</a>. If you do not specify\n<code><span>hyperparameters</span> <span>=</span> <span>'multimodal'</span></code>, then AutoGluon Tabular will simply\nfeaturize text fields using N-grams and train only tabular models (which\nmay work better if your text is mostly uncommon strings/vocabulary).</p><div><pre><span></span><span>Beginning</span> <span>AutoGluon</span> <span>training</span> <span>...</span>\n<span>AutoGluon</span> <span>will</span> <span>save</span> <span>models</span> <span>to</span> <span>\"ag_tabular_product_sentiment_multimodal/\"</span>\n<span>AutoGluon</span> <span>Version</span><span>:</span> <span>0.1</span><span>.</span><span>0</span><span>b20210301</span>\n<span>Train</span> <span>Data</span> <span>Rows</span><span>:</span> <span>2000</span>\n<span>Train</span> <span>Data</span> <span>Columns</span><span>:</span> <span>2</span>\n<span>Preprocessing</span> <span>data</span> <span>...</span>\n<span>AutoGluon</span> <span>infers</span> <span>your</span> <span>prediction</span> <span>problem</span> <span>is</span><span>:</span> <span>'multiclass'</span> <span>(</span><span>because</span> <span>dtype</span> <span>of</span> <span>label</span><span>-</span><span>column</span> <span>==</span> <span>int</span><span>,</span> <span>but</span> <span>few</span> <span>unique</span> <span>label</span><span>-</span><span>values</span> <span>observed</span><span>)</span><span>.</span>\n <span>4</span> <span>unique</span> <span>label</span> <span>values</span><span>:</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>0</span><span>]</span>\n <span>If</span> <span>'multiclass'</span> <span>is</span> <span>not</span> <span>the</span> <span>correct</span> <span>problem_type</span><span>,</span> <span>please</span> <span>manually</span> <span>specify</span> <span>the</span> <span>problem_type</span> <span>argument</span> <span>in</span> <span>fit</span><span>()</span> <span>(</span><span>You</span> <span>may</span> <span>specify</span> <span>problem_type</span> <span>as</span> <span>one</span> <span>of</span><span>:</span> <span>[</span><span>'binary'</span><span>,</span> <span>'multiclass'</span><span>,</span> <span>'regression'</span><span>])</span>\n<span>NumExpr</span> <span>defaulting</span> <span>to</span> <span>8</span> <span>threads</span><span>.</span>\n<span>Train</span> <span>Data</span> <span>Class</span> <span>Count</span><span>:</span> <span>4</span>\n<span>Using</span> <span>Feature</span> <span>Generators</span> <span>to</span> <span>preprocess</span> <span>the</span> <span>data</span> <span>...</span>\n<span>Fitting</span> <span>AutoMLPipelineFeatureGenerator</span><span>...</span>\n <span>Available</span> <span>Memory</span><span>:</span> <span>13693.17</span> <span>MB</span>\n <span>Train</span> <span>Data</span> <span>(</span><span>Original</span><span>)</span> <span>Memory</span> <span>Usage</span><span>:</span> <span>0.34</span> <span>MB</span> <span>(</span><span>0.0</span><span>%</span> <span>of</span> <span>available</span> <span>memory</span><span>)</span>\n <span>Inferring</span> <span>data</span> <span>type</span> <span>of</span> <span>each</span> <span>feature</span> <span>based</span> <span>on</span> <span>column</span> <span>values</span><span>.</span> <span>Set</span> <span>feature_metadata_in</span> <span>to</span> <span>manually</span> <span>specify</span> <span>special</span> <span>dtypes</span> <span>of</span> <span>the</span> <span>features</span><span>.</span>\n <span>Stage</span> <span>1</span> <span>Generators</span><span>:</span>\n <span>Fitting</span> <span>AsTypeFeatureGenerator</span><span>...</span>\n <span>Stage</span> <span>2</span> <span>Generators</span><span>:</span>\n <span>Fitting</span> <span>FillNaFeatureGenerator</span><span>...</span>\n <span>Stage</span> <span>3</span> <span>Generators</span><span>:</span>\n <span>Fitting</span> <span>IdentityFeatureGenerator</span><span>...</span>\n <span>Fitting</span> <span>IdentityFeatureGenerator</span><span>...</span>\n <span>Fitting</span> <span>RenameFeatureGenerator</span><span>...</span>\n <span>Fitting</span> <span>CategoryFeatureGenerator</span><span>...</span>\n <span>Fitting</span> <span>CategoryMemoryMinimizeFeatureGenerator</span><span>...</span>\n <span>Fitting</span> <span>TextSpecialFeatureGenerator</span><span>...</span>\n <span>Fitting</span> <span>BinnedFeatureGenerator</span><span>...</span>\n <span>Fitting</span> <span>DropDuplicatesFeatureGenerator</span><span>...</span>\n <span>Fitting</span> <span>TextNgramFeatureGenerator</span><span>...</span>\n <span>Fitting</span> <span>CountVectorizer</span> <span>for</span> <span>text</span> <span>features</span><span>:</span> <span>[</span><span>'Product_Description'</span><span>]</span>\n <span>CountVectorizer</span> <span>fit</span> <span>with</span> <span>vocabulary</span> <span>size</span> <span>=</span> <span>230</span>\n <span>Stage</span> <span>4</span> <span>Generators</span><span>:</span>\n <span>Fitting</span> <span>DropUniqueFeatureGenerator</span><span>...</span>\n <span>Types</span> <span>of</span> <span>features</span> <span>in</span> <span>original</span> <span>data</span> <span>(</span><span>raw</span> <span>dtype</span><span>,</span> <span>special</span> <span>dtypes</span><span>):</span>\n <span>(</span><span>'int'</span><span>,</span> <span>[])</span> <span>:</span> <span>1</span> <span>|</span> <span>[</span><span>'Product_Type'</span><span>]</span>\n <span>(</span><span>'object'</span><span>,</span> <span>[</span><span>'text'</span><span>])</span> <span>:</span> <span>1</span> <span>|</span> <span>[</span><span>'Product_Description'</span><span>]</span>\n <span>Types</span> <span>of</span> <span>features</span> <span>in</span> <span>processed</span> <span>data</span> <span>(</span><span>raw</span> <span>dtype</span><span>,</span> <span>special</span> <span>dtypes</span><span>):</span>\n <span>(</span><span>'int'</span><span>,</span> <span>[])</span> <span>:</span> <span>1</span> <span>|</span> <span>[</span><span>'Product_Type'</span><span>]</span>\n <span>(</span><span>'int'</span><span>,</span> <span>[</span><span>'binned'</span><span>,</span> <span>'text_special'</span><span>])</span> <span>:</span> <span>38</span> <span>|</span> <span>[</span><span>'Product_Description.char_count'</span><span>,</span> <span>'Product_Description.word_count'</span><span>,</span> <span>'Product_Description.capital_ratio'</span><span>,</span> <span>'Product_Description.lower_ratio'</span><span>,</span> <span>'Product_Description.digit_ratio'</span><span>,</span> <span>...</span><span>]</span>\n <span>(</span><span>'int'</span><span>,</span> <span>[</span><span>'text_ngram'</span><span>])</span> <span>:</span> <span>231</span> <span>|</span> <span>[</span><span>'__nlp__.about'</span><span>,</span> <span>'__nlp__.all'</span><span>,</span> <span>'__nlp__.amp'</span><span>,</span> <span>'__nlp__.an'</span><span>,</span> <span>'__nlp__.an ipad'</span><span>,</span> <span>...</span><span>]</span>\n <span>(</span><span>'object'</span><span>,</span> <span>[</span><span>'text'</span><span>])</span> <span>:</span> <span>1</span> <span>|</span> <span>[</span><span>'Product_Description_raw_text'</span><span>]</span>\n <span>0.8</span><span>s</span> <span>=</span> <span>Fit</span> <span>runtime</span>\n <span>2</span> <span>features</span> <span>in</span> <span>original</span> <span>data</span> <span>used</span> <span>to</span> <span>generate</span> <span>271</span> <span>features</span> <span>in</span> <...",
      "url": "https://auto.gluon.ai/0.1.0/tutorials/tabular_prediction/tabular-multimodal-text-others.html"
    },
    {
      "title": "Search code, repositories, users, issues, pull requests...",
      "text": "GitHub - yandex-research/tabm: (ICLR 2025) TabM: Advancing Tabular Deep Learning With Parameter-Efficient Ensembling\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/yandex-research/tabm)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/yandex-research/tabm)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=yandex-research/tabm)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[yandex-research](https://github.com/yandex-research)/**[tabm](https://github.com/yandex-research/tabm)**Public\n* [Notifications](https://github.com/login?return_to=/yandex-research/tabm)You must be signed in to change notification settings\n* [Fork77](https://github.com/login?return_to=/yandex-research/tabm)\n* [Star919](https://github.com/login?return_to=/yandex-research/tabm)\n(ICLR 2025) TabM: Advancing Tabular Deep Learning With Parameter-Efficient Ensembling\n[arxiv.org/abs/2410.24210](https://arxiv.org/abs/2410.24210)\n### License\n[Apache-2.0 license](https://github.com/yandex-research/tabm/blob/main/LICENSE)\n[919stars](https://github.com/yandex-research/tabm/stargazers)[77forks](https://github.com/yandex-research/tabm/forks)[Branches](https://github.com/yandex-research/tabm/branches)[Tags](https://github.com/yandex-research/tabm/tags)[Activity](https://github.com/yandex-research/tabm/activity)\n[Star](https://github.com/login?return_to=/yandex-research/tabm)\n[Notifications](https://github.com/login?return_to=/yandex-research/tabm)You must be signed in to change notification settings\n# yandex-research/tabm\nmain\n[Branches](https://github.com/yandex-research/tabm/branches)[Tags](https://github.com/yandex-research/tabm/tags)\n[](https://github.com/yandex-research/tabm/branches)[](https://github.com/yandex-research/tabm/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[50 Commits](https://github.com/yandex-research/tabm/commits/main/)\n[](https://github.com/yandex-research/tabm/commits/main/)\n|\n[images](https://github.com/yandex-research/tabm/tree/main/images)\n|\n[images](https://github.com/yandex-research/tabm/tree/main/images)\n|\n|\n|\n[paper](https://github.com/yandex-research/tabm/tree/main/paper)\n|\n[paper](https://github.com/yandex-research/tabm/tree/main/paper)\n|\n|\n|\n[.gitattributes](https://github.com/yandex-research/tabm/blob/main/.gitattributes)\n|\n[.gitattributes](https://github.com/yandex-research/tabm/blob/main/.gitattributes)\n|\n|\n|\n[.gitignore](https://github.com/yandex-research/tabm/blob/main/.gitignore)\n|\n[.gitignore](https://github.com/yandex-research/tabm/blob/main/.gitignore)\n|\n|\n|\n[.python-version](https://github.com/yandex-research/tabm/blob/main/.python-version)\n|\n[.python-version](https://github.com/yandex-research/tabm/blob/main/.python-version)\n|\n|\n|\n[LICENSE](https://github.com/yandex-research/tabm/blob/main/LICENSE)\n|\n[LICENSE](https://github.com/yandex-research/tabm/blob/main/LICENSE)\n|\n|\n|\n[Makefile](https://github.com/yandex-research/tabm/blob/main/Makefile)\n|\n[Makefile](https://github.com/yandex-research/tabm/blob/main/Makefile)\n|\n|\n|\n[README.md](https://github.com/yandex-research/tabm/blob/main/README.md)\n|\n[README.md](https://github.com/yandex-research/tabm/blob/main/README.md)\n|\n|\n|\n[example.ipynb](https://github.com/yandex-research/tabm/blob/main/example.ipynb)\n|\n[example.ipynb](https://github.com/yandex-research/tabm/blob/main/example.ipynb)\n|\n|\n|\n[pyproject.toml](https://github.com/yandex-research/tabm/blob/main/pyproject.toml)\n|\n[pyproject.toml](https://github.com/yandex-research/tabm/blob/main/pyproject.toml)\n|\n|\n|\n[tabm.py](https://github.com/yandex-research/tabm/blob/main/tabm.py)\n|\n[tabm.py](https://github.com/yandex-research/tabm/blob/main/tabm.py)\n|\n|\n|\n[tabm\\_reference.py](https://github.com/yandex-research/tabm/blob/main/tabm_reference.py)\n|\n[tabm\\_reference.py](https://github.com/yandex-research/tabm/blob/main/tabm_reference.py)\n|\n|\n|\n[test\\_code\\_blocks.py](https://github.com/yandex-research/tabm/blob/main/test_code_blocks.py)\n|\n[test\\_code\\_blocks.py](https://github.com/yandex-research/tabm/blob/main/test_code_blocks.py)\n|\n|\n|\n[uv.lock](https://github.com/yandex-research/tabm/blob/main/uv.lock)\n|\n[uv.lock](https://github.com/yandex-research/tabm/blob/main/uv.lock)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# TabM: Advancing Tabular Deep Learning With Parameter-Efficient Ensembling\" (ICLR 2025)\n[](#tabm-advancing-tabular-deep-learning-with-parameter-efficient-ensembling-iclr-2025)\n\ud83d\udcdc[arXiv](https://arxiv.org/abs/2410.24210)\ud83d\udcda[Other tabular DL projects](https://github.com/yandex-research/rtdl)\nThis is the official repository of the paper \"TabM: Advancing Tabular Deep Learning With\nParameter-Efficient Ensembling\".\nIt consists of two parts:\n* [**Python package**](#python-package)described in this document.\n* [**Paper-related content**](https://github.com/yandex-research/tabm/blob/main/paper/README.md)(code, metrics, hyperparameters, etc.) described in`paper/README.md`.\nTabM on**Kaggle**(as of June 2025)\n* TabM was used in[the winning solution](https://www.kaggle.com/competitions/um-game-playing-strength-of-mcts-variants/discussion/549801)in the competition by UM.\n* TabM was used in[the winning solution](https://www.kaggle.com/competitions/equity-post-HCT-survival-predictions/discussion/566550), as well as in the top-3, top-4, top-5 and many other solutions in the competition by CIBMTR. Later, it turned out that it was possible to achieve the[25-th place](https://www.kaggle.com/competitions/equity-post-HCT-survival-predictions/discussion/567863)out of 3300+ with only TabM, without ensembling it with other models.TabM on**TabReD**(a challenging benchmark)\n[TabReD](https://arxiv.org/abs/2406.19380)is a benchmark based on**real-world industrial datasets**with**time-related distribution drifts**and**hundreds of features**, which makes it more challenging than traditional benchmarks. The figure below shows that TabM achieves higher performance on TabReD (plus one more real-world dataset) compared to prior tabular DL methods.\n[![](https://github.com/yandex-research/tabm/raw/main/images/tabred-and-microsoft.png)](https://github.com/yandex-research/tabm/blob/main/images/tabred-and-microsoft.png)\n*One dot represents a performance score on one dataset. For a given model, a diamond represents the mean value across the datasets.*\nTraining and inference efficiency\nTabM is a simple and reasonably efficient model, which makes it suitable for**real-world applications**, including large datasets. The biggest dataset used in the paper contains**13M objects**, and we are aware of a successful training run on**100M+ objects**, though training takes more time in such cases.\nThe figure below shows that TabM is relatively slower than MLPs and GBDT, but faster than prior tabular DL meth...",
      "url": "https://github.com/yandex-research/tabm"
    },
    {
      "title": "Benchmarking Multimodal AutoML for Tabular Data with Text Fields",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/abs/2111.02705"
    },
    {
      "title": "",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://www.arxiv.org/pdf/2412.16243"
    },
    {
      "title": "Towards Benchmarking Foundation Models for Tabular Data With Text",
      "text": "Towards Benchmarking Foundation Models for Tabular Data With Text\nMartin Mraz\u00b4\n* 1 Breenda Das * 1 Anshul Gupta * 1 Lennart Purucker 1 Frank Hutter 2 3 1\nAbstract\nFoundation models for tabular data are rapidly\nevolving, with increasing interest in extending\nthem to support additional modalities such as free\u0002text features. However, existing benchmarks for\ntabular data rarely include textual columns, and\nidentifying real-world tabular datasets with se\u0002mantically rich text features is non-trivial. We\npropose a series of simple yet effective ablation\u0002style strategies for incorporating text into con\u0002ventional tabular pipelines. Moreover, we bench\u0002mark how state-of-the-art tabular foundation mod\u0002els can handle textual data by manually curating\na collection of real-world tabular datasets with\nmeaningful textual features. Our study is an im\u0002portant step towards improving benchmarking of\nfoundation models for tabular data with text.\n1. Introduction\nFoundation models have begun to transform tabular learn\u0002ing (Erickson et al., 2020b; Hollmann et al., 2025), echo\u0002ing the trajectory of other research fields. A natural next\nstep is mixed-modality tabular modeling, where structured\ncolumns may also include free-text fields such as job de\u0002scriptions, clinical notes, or product summaries. Current\ntabular benchmarks, however, almost never contain textual\ncolumns, cf. (Bischl et al., 2019; Liu et al., 2024; McEl\u0002fresh et al., 2024). Moreover, locating real-world datasets\nwith semantically rich text features is exceptionally difficult,\nwith even exhaustive searches of OpenML and Kaggle only\nyielding a handful of usable candidates (Shi et al., 2021).\nConsequently, current tabular foundation models are rarely\nevaluated for tabular data with text.\nPipelines that can handle tabular data with text vary greatly\n*Equal contribution 1Department of Computer Science, Uni\u0002versity of Freiburg, Freiburg, Germany 2\nPrior Labs, Freiburg,\nGermany 3ELLIS Institute, Tubingen, Germany. Correspon\u0002dence to: Martin Mraz <mrazm@informatik.uni-freiburg.de>,\nBreenda Das <dasb@informatik.uni-freiburg.de>, Anshul Gupta\n<guptaa@informatik.uni-freiburg.de>.\nProceedings of the 42 nd International Conference on Machine\nLearning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025\nby the author(s).\nin their implementation. AutoGluon\u2019s AutoMLPipeline\u0002FeatureGenerator (Erickson et al., 2020a) converts text to\nsparse vectors; CARTE (Kim et al., 2024) applies fastText\nsentence embeddings (Bojanowski et al., 2017). and the\nTabPFNv2 API accepts raw text but does not disclose its\nmethodology. These divergent choices raise a fundamental\nquestion: Which embedding strategy works best, and under\nwhat conditions?\nTo answer this question, we present the first systematic\nstudy of predictive machine learning with foundation mod\u0002els for tabular data with text. We study the performance\nof three representative embedding routes: fastText, Skrub\u2019s\nTableVectorizer, and AutoGluon\u2019s text encoder. We show\nqualitatively, with a simple synthetic counter-example, that\nboth n-gram based and off-the-shelf sentence embeddings\ncan fail to recover highly predictive semantic patterns. More\u0002over, quantitatively, we evaluate these methods on a man\u0002ually curated set of real-world tabular benchmark that (i)\ncontain genuinely informative free-text columns (ii) spans\nover a variety of domains and samples.\nOur contributions are: (I) A qualitative study show cas\u0002ing the limitations of standard n-gram based and generic\nNLP-based embeddings for tabular tasks with text. (II) A\nmanually curated set of real-world tabular datasets with se\u0002mantically rich textual columns. (III) An empirical study of\nthree text embedding pipelines for TabPFNv2 and XGBoost\nwith the TabPFNv2 API and AutoGluon Tabular Predictor\nas baselines.\nOur study reveals the limitations of current methods and\nunderscores the need for new methods to handle tabular data\nwith free text.\n2. Related Work\nApproaches incorporating free-text in tabular learning\nlargely follow two paradigms. First, row-as-text meth\u0002ods serialize entire rows into prompts and delegate pre\u0002diction to a large language model (LLM), as seen in\nTABLLM (Hegselmann et al., 2022), TABLE-LLM (Zhang\net al., 2024). These work well when textual fields dominate\nor in few-shot settings. Second, per-column embedding\nstrategies extract textual embeddings from a single or groups\nof features, while preserving the structural nature of tabular\n1\narXiv:2507.07829v1 [cs.LG] 10 Jul 2025\nTowards Benchmarking Foundation Models for Tabular Data With Text\nFigure 1. Qualitative investigation of textual embeddings for tabular prediction tasks: TabPFN v2 accuracy across five datasets.\nBaselines \u201cNo-Text\u201d uses original input features, \u201cComplete Leak\u201d has target leakage, therefore 100% accuracy for all. Following tests\nembed targets into textual modality. \u201cN-Gram Break\u201d shows TF-IDF breaking under unseen synonyms, \u201cSimple NLP break\u201d shows\nFastText underperforming under noise, \u201cLLM Breaks\u201d shows BERT variant breaking under semantic ambiguity.\ndata. They embed each column using fastText or LLMs\nand then concatenate the resulting embeddings to the table,\nor replace the feature with its individual textual embed\u0002ding, cf. (Koloski et al., 2025; Carballo et al., 2023; Kim\net al., 2024). Grinsztajn et al. (2023) compare 30+ LLM\nand substring-based methods for embedding string columns,\nshowing when LLMs yield better representations.\nIn this study, we investigate pre-column embeddings be\u0002cause we focus on a many-shot setting (e.g., more than 32\ntraining samples), in which LLM-based predictive methods\ndo not perform well, cf. (Hegselmann et al., 2023) and (Ma\net al., 2024), or require a prohibitive amount of fine-tuning\n(Shysheya et al., 2025).\nMost popular prior tabular benchmarks contain no free-text\nfield, cf. (Bischl et al., 2019; Gijsbers et al., 2022; McEl\u0002fresh et al., 2023). For tabular data with text, Shi et al.\n(2021) curated 18 datasets with mixed modalities, but many\nrely almost entirely on text, with only one or two tabular\nfeatures, or features derived from the long text, e.g. # of\nwords (Tang et al., 2024). Thus, they benchmark text-based\nmodels rather than tabular models, focusing on text data\nwith tabular features. In contrast, we focus on tabular mod\u0002els extended to handle text, focusing on tabular data with\nadditional text features. Other studies were often limited to\nan evaluation with just one or two datasets (Carballo et al.,\n2023; Lu et al., 2023). Overall, existing studies for tabular\ndata with text lack a domain-agnostic benchmark where\ntextual features complement, rather than dominate, tabular\ndata. This motivates the new benchmark we present.\nThe CARTE Benchmark. The latest seminal work on\nbenchmarking for tabular data with text is the CARTE (Kim\net al., 2024) benchmark. It includes 51 datasets for tabu\u0002lar data with text. However, when we investigated these\ndatasets more closely, we found that at most 11 out of the\n51 datasets are suited to evaluate tabular data with text.\nMoreover, our manually curated collection of datasets for\nbenchmarking only includes 1 out of the 51 datasets.\nWe share an extensive report of our investigation in Ap\u0002pendix G. In short, we found that most datasets (a) do not\nrepresent predictive machine learning tasks for tabular data\nwith text; (b) are skewed towards text data representing\nmany categories instead of longer free text; (c) were pre\u0002processed manually per dataset with logic that seems to\nfavor CARTE; (d) or were very similar datasets from the\nsame domain, with the same features, or similar semantic\ncontent. Thus, while CARTE was a significant step toward\nbenchmarking and learning for tabular data with text, it falls\nshort in several aspects. Our work complements CARTE\u2019s\nefforts and aims to improve benchmarking for tabular data\nwith text further.\n3. Qualitative Investigation\nIn this section, we evaluate popular text embedding tech\u0002niques: N-Grams, simple NLP models and LLMs for tabular\npr...",
      "url": "https://arxiv.org/pdf/2507.07829"
    },
    {
      "title": "Combining BERT/Transformers and Classical Tabular Models \u2014 AutoGluon Documentation 0.1.1 documentation",
      "text": "# Multimodal Data Tables: Combining BERT/Transformers and Classical Tabular Models [\u00b6](https://auto.gluon.ai/auto.gluon.ai\\#multimodal-data-tables-combining-bert-transformers-and-classical-tabular-models)\n\nHere we introduce how to use AutoGluon Tabular to deal with multimodal\ntabular data that contains text, numeric, and categorical columns. In\nAutoGluon, **raw text data** is considered as a first-class citizen of\ndata tables. AutoGluon Tabular can help you train and combine a diverse\nset of models including classical tabular models like\nLightGBM/RF/CatBoost as well as our pretrained NLP model based\nmultimodal network that is introduced in Section\n\u201c [What\u2019s happening inside?](https://auto.gluon.ai/text_prediction/multimodal_text.html#sec-textprediction-architecture)\u201d of\n[Text Prediction - Multimodal Table with Text](https://auto.gluon.ai/text_prediction/multimodal_text.html#sec-textprediction-multimodal) (used by AutoGluon\u2019s\n`TextPredictor`).\n\n```\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pprint\nimport random\nfrom autogluon.tabular import TabularPredictor\nimport mxnet as mx\n\nnp.random.seed(123)\nrandom.seed(123)\nmx.random.seed(123)\n```\n\n## Product Sentiment Analysis Dataset [\u00b6](https://auto.gluon.ai/auto.gluon.ai\\#product-sentiment-analysis-dataset)\n\nWe consider the product sentiment analysis dataset from a [MachineHack\\\nhackathon](https://www.machinehack.com/hackathons/product_sentiment_classification_weekend_hackathon_19/leaderboard).\nThe goal is to predict a user\u2019s sentiment towards a product given their\nreview (raw text) and a categorical feature indicating the product\u2019s\ntype (e.g., Tablet, Mobile, etc.). We have already split the original\ndataset to be 90% for training and 10% for development/testing (if\nsubmitting your models to the hackathon, we recommend training them on\n100% of the dataset).\n\n```\n!mkdir -p product_sentiment_machine_hack\n!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/train.csv -O product_sentiment_machine_hack/train.csv\n!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/dev.csv -O product_sentiment_machine_hack/dev.csv\n!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/test.csv -O product_sentiment_machine_hack/test.csv\n\n```\n\n```\n--2021-03-10 04:16:17--  https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/train.csv\nResolving autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)... 52.216.147.43\nConnecting to autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)|52.216.147.43|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 689486 (673K) [text/csv]\nSaving to: \u2018product_sentiment_machine_hack/train.csv\u2019\n\nproduct_sentiment_m 100%[===================>] 673.33K  2.05MB/s    in 0.3s\n\n2021-03-10 04:16:18 (2.05 MB/s) - \u2018product_sentiment_machine_hack/train.csv\u2019 saved [689486/689486]\n\n--2021-03-10 04:16:18--  https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/dev.csv\nResolving autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)... 52.216.147.43\nConnecting to autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)|52.216.147.43|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 75517 (74K) [text/csv]\nSaving to: \u2018product_sentiment_machine_hack/dev.csv\u2019\n\nproduct_sentiment_m 100%[===================>]  73.75K   490KB/s    in 0.2s\n\n2021-03-10 04:16:19 (490 KB/s) - \u2018product_sentiment_machine_hack/dev.csv\u2019 saved [75517/75517]\n\n--2021-03-10 04:16:19--  https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/test.csv\nResolving autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)... 52.216.147.43\nConnecting to autogluon-text-data.s3.amazonaws.com (autogluon-text-data.s3.amazonaws.com)|52.216.147.43|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 312194 (305K) [text/csv]\nSaving to: \u2018product_sentiment_machine_hack/test.csv\u2019\n\nproduct_sentiment_m 100%[===================>] 304.88K   943KB/s    in 0.3s\n\n2021-03-10 04:16:20 (943 KB/s) - \u2018product_sentiment_machine_hack/test.csv\u2019 saved [312194/312194]\n\n```\n\n```\nsubsample_size = 2000  # for quick demo, try setting to larger values\nfeature_columns = ['Product_Description', 'Product_Type']\nlabel = 'Sentiment'\n\ntrain_df = pd.read_csv('product_sentiment_machine_hack/train.csv', index_col=0).sample(2000, random_state=123)\ndev_df = pd.read_csv('product_sentiment_machine_hack/dev.csv', index_col=0)\ntest_df = pd.read_csv('product_sentiment_machine_hack/test.csv', index_col=0)\n\ntrain_df = train_df[feature_columns + [label]]\ndev_df = dev_df[feature_columns + [label]]\ntest_df = test_df[feature_columns]\nprint('Number of training samples:', len(train_df))\nprint('Number of dev samples:', len(dev_df))\nprint('Number of test samples:', len(test_df))\n```\n\n```\nNumber of training samples: 2000\nNumber of dev samples: 637\nNumber of test samples: 2728\n```\n\nThere are two features in the dataset: the users\u2019 review of the product\nand the product\u2019s type, and four possible classes to predict.\n\n```\ntrain_df.head()\n```\n\n| Product\\_Description | Product\\_Type | Sentiment |\n| --- | --- | --- |\n| 4532 | they took away the lego pit but replaced it wi... | 0 | 1 |\n| 1831 | #Apple to Open Pop-Up Shop at #SXSW \\[REPORT\\]: ... | 9 | 2 |\n| 3536 | RT @mention False Alarm: Google Circles Not Co... | 5 | 1 |\n| 5157 | Will Google reveal a new social network called... | 9 | 2 |\n| 4643 | Niceness RT @mention Less than 2 hours until w... | 6 | 3 |\n\n```\ndev_df.head()\n```\n\n| Product\\_Description | Product\\_Type | Sentiment |\n| --- | --- | --- |\n| 3170 | Do it. RT @mention Come party w/ Google tonigh... | 3 | 3 |\n| 6301 | Line for iPads at #SXSW. Doesn't look too bad!... | 6 | 3 |\n| 5643 | First up: iPad Design Headaches (2 Tablets, Ca... | 6 | 2 |\n| 1953 | #SXSW: Mint Talks Mobile App Development Chall... | 9 | 2 |\n| 2658 | \u0089\u00db\u00cf@mention Apple store downtown Austin open t... | 9 | 2 |\n\n```\ntest_df.head()\n```\n\n| Product\\_Description | Product\\_Type |\n| --- | --- |\n| Text\\_ID |\n| --- |\n| 5786 | RT @mention Going to #SXSW? The new iPhone gui... | 7 |\n| 5363 | RT @mention 95% of iPhone and Droid apps have ... | 9 |\n| 6716 | RT @mention Thank you to @mention for letting ... | 9 |\n| 4339 | #Thanks @mention we're lovin' the @mention app... | 7 |\n| 66 | At #sxsw? @mention / @mention wanna buy you a ... | 9 |\n\n## AutoGluon Tabular with Multimodal Support [\u00b6](https://auto.gluon.ai/auto.gluon.ai\\#autogluon-tabular-with-multimodal-support)\n\nTo utilize the `TextPredictor` model inside of `TabularPredictor`,\nwe must specify the `hyperparameters = 'multimodal'` in AutoGluon\nTabular. Internally, this will train multiple tabular models as well as\nthe TextPredictor model, and then combine them via either a weighted\nensemble or stack ensemble, as explained in [AutoGluon Tabular\\\nPaper](https://arxiv.org/pdf/2003.06505.pdf). If you do not specify\n`hyperparameters = 'multimodal'`, then AutoGluon Tabular will simply\nfeaturize text fields using N-grams and train only tabular models (which\nmay work better if your text is mostly uncommon strings/vocabulary).\n\n```\nfrom autogluon.tabular import TabularPredictor\npredictor = TabularPredictor(label='Sentiment', path='ag_tabular_product_sentiment_multimodal')\npredictor.fit(train_df, hyperparameters='multimodal')\n```\n\n```\nBeginning AutoGluon training ...\nAutoGluon will save models to \"ag_tabular_product_sentiment_multimodal/\"\nAutoGluon Version:  0.1.1b20210310\nTrain Data Rows:    2000\nTrain Data Columns: 2\nPreprocessing data ...\nAutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n    4 unique label values:  [1, 2, 3, 0]\n    If 'multiclass' is not the correct ...",
      "url": "https://auto.gluon.ai/scoredebugweight/tutorials/tabular_prediction/tabular-multimodal-text-others.html"
    }
  ]
}