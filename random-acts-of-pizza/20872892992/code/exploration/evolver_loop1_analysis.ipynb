{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49037af2",
   "metadata": {},
   "source": [
    "# Evolver Loop 1 Analysis: Text Feature Impact Assessment\n",
    "\n",
    "This notebook analyzes the potential impact of adding text features to our baseline model.\n",
    "\n",
    "**Goal**: Estimate the expected improvement from adding text features and design the next experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b14c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Target distribution: {train_df['requester_received_pizza'].value_counts().to_dict()}\")\n",
    "print(f\"Positive rate: {train_df['requester_received_pizza'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8396a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze text fields\n",
    "print(\"Analyzing text fields...\")\n",
    "\n",
    "# Check text availability\n",
    "print(f\"Missing request_title: {train_df['request_title'].isnull().sum()}\")\n",
    "print(f\"Missing request_text_edit_aware: {train_df['request_text_edit_aware'].isnull().sum()}\")\n",
    "\n",
    "# Sample some texts\n",
    "print(\"\\n=== Sample Request Titles (successful) ===\")\n",
    "successful = train_df[train_df['requester_received_pizza'] == True]\n",
    "for i, title in enumerate(successful['request_title'].head(5)):\n",
    "    print(f\"{i+1}. {title}\")\n",
    "\n",
    "print(\"\\n=== Sample Request Titles (unsuccessful) ===\")\n",
    "unsuccessful = train_df[train_df['requester_received_pizza'] == False]\n",
    "for i, title in enumerate(unsuccessful['request_title'].head(5)):\n",
    "    print(f\"{i+1}. {title}\")\n",
    "\n",
    "# Text length analysis\n",
    "train_df['title_length'] = train_df['request_title'].str.len()\n",
    "train_df['text_length'] = train_df['request_text_edit_aware'].str.len()\n",
    "train_df['total_length'] = train_df['title_length'] + train_df['text_length']\n",
    "\n",
    "test_df['title_length'] = test_df['request_title'].str.len()\n",
    "test_df['text_length'] = test_df['request_text_edit_aware'].str.len()\n",
    "test_df['total_length'] = test_df['title_length'] + test_df['text_length']\n",
    "\n",
    "print(f\"\\n=== Text Length Statistics ===\")\n",
    "print(f\"Title length - Mean: {train_df['title_length'].mean():.0f}, Std: {train_df['title_length'].std():.0f}\")\n",
    "print(f\"Text length - Mean: {train_df['text_length'].mean():.0f}, Std: {train_df['text_length'].std():.0f}\")\n",
    "print(f\"Total length - Mean: {train_df['total_length'].mean():.0f}, Std: {train_df['total_length'].std():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe246a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlation between text length and success\n",
    "print(\"=== Correlation Analysis: Text Length vs Success ===\")\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Successful vs unsuccessful length comparison\n",
    "success_lengths = train_df[train_df['requester_received_pizza'] == True]['total_length']\n",
    "fail_lengths = train_df[train_df['requester_received_pizza'] == False]['total_length']\n",
    "\n",
    "print(f\"Successful requests - Mean length: {success_lengths.mean():.0f}\")\n",
    "print(f\"Unsuccessful requests - Mean length: {fail_lengths.mean():.0f}\")\n",
    "\n",
    "# T-test\n",
    "t_stat, p_value = ttest_ind(success_lengths, fail_lengths)\n",
    "print(f\"T-test: t={t_stat:.3f}, p={p_value:.6f}\")\n",
    "\n",
    "# Correlation\n",
    "corr = train_df['total_length'].corr(train_df['requester_received_pizza'].astype(int))\n",
    "print(f\"Correlation between total_length and success: {corr:.4f}\")\n",
    "\n",
    "# Visualize distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(data=train_df, x='total_length', hue='requester_received_pizza', bins=50, alpha=0.7)\n",
    "plt.title('Distribution of Total Text Length by Success')\n",
    "plt.xlabel('Total Length (characters)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=train_df, x='requester_received_pizza', y='total_length')\n",
    "plt.title('Text Length by Success (Boxplot)')\n",
    "plt.xlabel('Received Pizza')\n",
    "plt.ylabel('Total Length (characters)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nKey Insight: Text length {'IS' if abs(corr) > 0.1 else 'is NOT'} significantly correlated with success (|r|={abs(corr):.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick TF-IDF test to estimate potential impact\n",
    "print(\"=== Quick TF-IDF Impact Test ===\")\n",
    "\n",
    "# Combine title and text for TF-IDF\n",
    "train_df['combined_text'] = train_df['request_title'] + ' ' + train_df['request_text_edit_aware']\n",
    "test_df['combined_text'] = test_df['request_title'] + ' ' + test_df['request_text_edit_aware']\n",
    "\n",
    "# Simple TF-IDF (unigrams only, limited features for quick test)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    min_df=5,\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "tfidf_train = vectorizer.fit_transform(train_df['combined_text'])\n",
    "tfidf_test = vectorizer.transform(test_df['combined_text'])\n",
    "\n",
    "print(f\"TF-IDF shape: {tfidf_train.shape}\")\n",
    "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "\n",
    "# Quick model test with TF-IDF only\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale TF-IDF features\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "tfidf_train_scaled = scaler.fit_transform(tfidf_train)\n",
    "tfidf_test_scaled = scaler.transform(tfidf_test)\n",
    "\n",
    "# Quick CV test\n",
    "y = train_df['requester_received_pizza'].astype(int).values\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "tfidf_scores = []\n",
    "for train_idx, val_idx in skf.split(tfidf_train_scaled, y):\n",
    "    X_train, X_val = tfidf_train_scaled[train_idx], tfidf_train_scaled[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    score = roc_auc_score(y_val, val_pred)\n",
    "    tfidf_scores.append(score)\n",
    "\n",
    "print(f\"TF-IDF only (Logistic Regression) - Mean ROC-AUC: {np.mean(tfidf_scores):.4f} Â± {np.std(tfidf_scores):.4f}\")\n",
    "print(f\"Individual folds: {tfidf_scores}\")\n",
    "\n",
    "# Compare to baseline (meta only)\n",
    "print(f\"\\nBaseline (meta only): 0.6691\")\n",
    "print(f\"TF-IDF only: {np.mean(tfidf_scores):.4f}\")\n",
    "print(f\"Potential improvement: +{np.mean(tfidf_scores) - 0.6691:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze most predictive words\n",
    "print(\"=== Most Predictive Words Analysis ===\")\n",
    "\n",
    "# Train a simple model to get feature importances\n",
    "lr_model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "lr_model.fit(tfidf_train_scaled, y)\n",
    "\n",
    "# Get feature names and coefficients\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = lr_model.coef_[0]\n",
    "\n",
    "# Create DataFrame of word importances\n",
    "word_importance = pd.DataFrame({\n",
    "    'word': feature_names,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': np.abs(coefficients)\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"Top 15 positive words (predictive of SUCCESS):\")\n",
    "print(word_importance.head(15)[['word', 'coefficient']].to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 15 negative words (predictive of FAILURE):\")\n",
    "print(word_importance.tail(15)[['word', 'coefficient']].to_string(index=False))\n",
    "\n",
    "# Save findings\n",
    "print(f\"\\n=== Key Findings ===\")\n",
    "print(f\"1. Text length correlation with success: {corr:.4f}\")\n",
    "print(f\"2. TF-IDF alone achieves: {np.mean(tfidf_scores):.4f} ROC-AUC\")\n",
    "print(f\"3. Expected improvement from adding text: +{np.mean(tfidf_scores) - 0.6691:.4f} to +0.15\")\n",
    "print(f\"4. Top predictive words identified for feature engineering\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
