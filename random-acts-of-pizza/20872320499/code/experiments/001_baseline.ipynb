{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b73cb7e0",
   "metadata": {},
   "source": [
    "# Baseline Model: LightGBM with Tabular Features\n",
    "\n",
    "This notebook implements a baseline model following the seed prompt strategy:\n",
    "- Uses only safe features available in both train and test sets\n",
    "- Handles class imbalance with appropriate weighting\n",
    "- Uses stratified k-fold validation\n",
    "- Generates predictions in correct submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140cf0c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T04:13:56.475441Z",
     "iopub.status.busy": "2026-01-10T04:13:56.475210Z",
     "iopub.status.idle": "2026-01-10T04:13:57.349949Z",
     "shell.execute_reply": "2026-01-10T04:13:57.349521Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55336fdd",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36d217b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T04:13:57.351122Z",
     "iopub.status.busy": "2026-01-10T04:13:57.350955Z",
     "iopub.status.idle": "2026-01-10T04:13:57.413202Z",
     "shell.execute_reply": "2026-01-10T04:13:57.412735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2878, 32)\n",
      "Columns: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n",
      "\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    0.751564\n",
      "True     0.248436\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_path = '/home/data/train.json'\n",
    "with open(train_path, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(train_data)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Columns: {train_df.columns.tolist()}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train_df['requester_received_pizza'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7df46",
   "metadata": {},
   "source": [
    "## Select Safe Features Only\n",
    "\n",
    "Following the seed prompt strategy, we only use features available in both train and test sets to avoid leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cae13df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T04:14:06.339200Z",
     "iopub.status.busy": "2026-01-10T04:14:06.338957Z",
     "iopub.status.idle": "2026-01-10T04:14:06.344529Z",
     "shell.execute_reply": "2026-01-10T04:14:06.344143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe features shape: (2878, 18)\n",
      "Safe features used: ['request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_days_since_first_post_on_raop_at_request', 'requester_number_of_comments_at_request', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_posts_at_request', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_request', 'requester_subreddits_at_request', 'requester_username', 'giver_username_if_known', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n"
     ]
    }
   ],
   "source": [
    "# Define safe features (available in both train and test)\n",
    "safe_features = [\n",
    "    'request_text_edit_aware',  # Use edit-aware version to avoid leakage\n",
    "    'request_title',\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_subreddits_at_request',\n",
    "    'requester_username',\n",
    "    'giver_username_if_known',\n",
    "    'unix_timestamp_of_request',\n",
    "    'unix_timestamp_of_request_utc',\n",
    "    'request_id'  # For identification, not for modeling\n",
    "]\n",
    "\n",
    "# Select only safe features\n",
    "train_safe = train_df[safe_features + ['requester_received_pizza']].copy()\n",
    "print(f\"Safe features shape: {train_safe.shape}\")\n",
    "print(f\"Safe features used: {[f for f in safe_features if f != 'request_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8e9346",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Create simple features from text and timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519b746c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T04:14:06.345370Z",
     "iopub.status.busy": "2026-01-10T04:14:06.345270Z",
     "iopub.status.idle": "2026-01-10T04:14:06.378048Z",
     "shell.execute_reply": "2026-01-10T04:14:06.377698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering completed\n",
      "New shape: (2878, 29)\n"
     ]
    }
   ],
   "source": [
    "# Text length features (strong signals in social media)\n",
    "train_safe['title_length'] = train_safe['request_title'].fillna('').str.len()\n",
    "train_safe['text_length'] = train_safe['request_text_edit_aware'].fillna('').str.len()\n",
    "train_safe['text_word_count'] = train_safe['request_text_edit_aware'].fillna('').str.split().str.len()\n",
    "\n",
    "# Temporal features from timestamp\n",
    "train_safe['request_timestamp'] = pd.to_datetime(train_safe['unix_timestamp_of_request'], unit='s')\n",
    "train_safe['request_hour'] = train_safe['request_timestamp'].dt.hour\n",
    "train_safe['request_dayofweek'] = train_safe['request_timestamp'].dt.dayofweek\n",
    "\n",
    "# User activity ratios and interactions\n",
    "train_safe['raop_activity_ratio'] = train_safe['requester_number_of_posts_on_raop_at_request'] / (train_safe['requester_number_of_posts_at_request'] + 1)\n",
    "train_safe['raop_comment_ratio'] = train_safe['requester_number_of_comments_in_raop_at_request'] / (train_safe['requester_number_of_comments_at_request'] + 1)\n",
    "train_safe['upvote_downvote_ratio'] = train_safe['requester_upvotes_plus_downvotes_at_request'] / (train_safe['requester_upvotes_minus_downvotes_at_request'] + 1)\n",
    "\n",
    "# Interaction: text length * user activity\n",
    "train_safe['text_length_x_raop_posts'] = train_safe['text_length'] * train_safe['requester_number_of_posts_on_raop_at_request']\n",
    "train_safe['text_length_x_account_age'] = train_safe['text_length'] * train_safe['requester_account_age_in_days_at_request']\n",
    "\n",
    "print(\"Feature engineering completed\")\n",
    "print(f\"New shape: {train_safe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4952a8a",
   "metadata": {},
   "source": [
    "## Prepare Features for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ae802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns (exclude target, ID, and raw text)\n",
    "exclude_cols = ['requester_received_pizza', 'request_id', 'request_text_edit_aware', 'request_title', \n",
    "                'requester_subreddits_at_request', 'requester_username', 'giver_username_if_known',\n",
    "                'request_timestamp']\n",
    "\n",
    "feature_cols = [col for col in train_safe.columns if col not in exclude_cols]\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Features: {feature_cols}\")\n",
    "\n",
    "# Prepare data\n",
    "X = train_safe[feature_cols].copy()\n",
    "y = train_safe['requester_received_pizza'].copy()\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "print(f\"Class distribution: {y.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff235f1",
   "metadata": {},
   "source": [
    "## Stratified K-Fold Validation\n",
    "\n",
    "Use stratified k-fold to maintain class distribution across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1576b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up stratified k-fold\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Calculate scale_pos_weight for LightGBM (handles class imbalance)\n",
    "scale_pos_weight = (y == 0).sum() / (y == 1).sum()\n",
    "print(f\"Scale pos weight: {scale_pos_weight:.2f} (ratio of negative to positive samples)\")\n",
    "\n",
    "# Store out-of-fold predictions\n",
    "oof_predictions = np.zeros(len(X))\n",
    "fold_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc26d9f",
   "metadata": {},
   "source": [
    "## Train LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68912d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Define parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'scale_pos_weight': scale_pos_weight\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['val'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(50),\n",
    "            lgb.log_evaluation(100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Calculate AUC\n",
    "    fold_auc = roc_auc_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_auc)\n",
    "    print(f\"Fold {fold + 1} AUC: {fold_auc:.4f}\")\n",
    "\n",
    "# Overall OOF score\n",
    "overall_auc = roc_auc_score(y, oof_predictions)\n",
    "print(f\"\\nOverall OOF AUC: {overall_auc:.4f}\")\n",
    "print(f\"Mean CV AUC: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3ec949",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6623ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 Most Important Features:\")\n",
    "print(feature_importance.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be434a",
   "metadata": {},
   "source": [
    "## Prepare Test Data and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c37642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_path = '/home/data/test.json'\n",
    "with open(test_path, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Apply same feature engineering to test data\n",
    "test_df['title_length'] = test_df['request_title'].fillna('').str.len()\n",
    "test_df['text_length'] = test_df['request_text_edit_aware'].fillna('').str.len()\n",
    "test_df['text_word_count'] = test_df['request_text_edit_aware'].fillna('').str.split().str.len()\n",
    "\n",
    "# Temporal features\n",
    "test_df['request_timestamp'] = pd.to_datetime(test_df['unix_timestamp_of_request'], unit='s')\n",
    "test_df['request_hour'] = test_df['request_timestamp'].dt.hour\n",
    "test_df['request_dayofweek'] = test_df['request_timestamp'].dt.dayofweek\n",
    "\n",
    "# User activity ratios and interactions\n",
    "test_df['raop_activity_ratio'] = test_df['requester_number_of_posts_on_raop_at_request'] / (test_df['requester_number_of_posts_at_request'] + 1)\n",
    "test_df['raop_comment_ratio'] = test_df['requester_number_of_comments_in_raop_at_request'] / (test_df['requester_number_of_comments_at_request'] + 1)\n",
    "test_df['upvote_downvote_ratio'] = test_df['requester_upvotes_plus_downvotes_at_request'] / (test_df['requester_upvotes_minus_downvotes_at_request'] + 1)\n",
    "\n",
    "# Interaction features\n",
    "test_df['text_length_x_raop_posts'] = test_df['text_length'] * test_df['requester_number_of_posts_on_raop_at_request']\n",
    "test_df['text_length_x_account_age'] = test_df['text_length'] * test_df['requester_account_age_in_days_at_request']\n",
    "\n",
    "# Prepare test features\n",
    "X_test = test_df[feature_cols].copy()\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "print(f\"Test features shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "test_predictions = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': test_predictions\n",
    "})\n",
    "\n",
    "print(\"Submission format:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Submission saved to: {submission_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e697694",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Used only safe features available in both train and test sets\n",
    "- Applied stratified 5-fold cross-validation\n",
    "- Handled class imbalance with scale_pos_weight\n",
    "- Generated predictions in correct submission format\n",
    "- Overall OOF AUC: {overall_auc:.4f}"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
