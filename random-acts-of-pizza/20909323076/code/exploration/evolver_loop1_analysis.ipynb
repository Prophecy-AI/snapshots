{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f0596d",
   "metadata": {},
   "source": [
    "# Evolver Loop 1 Analysis: Data Leakage Investigation\n",
    "\n",
    "This notebook investigates the data leakage issue identified by the evaluator, specifically focusing on the user_flair feature and temporal validity of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "792be325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T07:02:52.464709Z",
     "iopub.status.busy": "2026-01-12T07:02:52.463950Z",
     "iopub.status.idle": "2026-01-12T07:02:54.579608Z",
     "shell.execute_reply": "2026-01-12T07:02:54.578989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2878, 32)\n",
      "Columns: 32\n",
      "\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    2163\n",
      "True      715\n",
      "Name: count, dtype: int64\n",
      "Positive rate: 0.248\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Load data\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Columns: {len(train_df.columns)}\")\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train_df['requester_received_pizza'].value_counts())\n",
    "print(f\"Positive rate: {train_df['requester_received_pizza'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f077b1",
   "metadata": {},
   "source": [
    "## Investigate User Flair Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e75b135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T07:04:35.514110Z",
     "iopub.status.busy": "2026-01-12T07:04:35.513368Z",
     "iopub.status.idle": "2026-01-12T07:04:35.525111Z",
     "shell.execute_reply": "2026-01-12T07:04:35.524494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User flair distribution:\n",
      "requester_user_flair\n",
      "shroom    677\n",
      "PIF        38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "SUCCESS RATE BY USER FLAIR:\n",
      "============================================================\n",
      "                      total_requests  successful_requests  success_rate\n",
      "requester_user_flair                                                   \n",
      "PIF                               38                   38           1.0\n",
      "shroom                           677                  677           1.0\n",
      "\n",
      "============================================================\n",
      "LEAKAGE CONFIRMED:\n",
      "============================================================\n",
      "PIF = 'Pizza It Forward' - users who received pizza and are now giving back\n",
      "This flair is assigned AFTER receiving pizza, not at request time!\n"
     ]
    }
   ],
   "source": [
    "# Analyze user flair distribution and its relationship with target\n",
    "print(\"User flair distribution:\")\n",
    "flair_counts = train_df['requester_user_flair'].value_counts()\n",
    "print(flair_counts)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUCCESS RATE BY USER FLAIR:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "flair_success = train_df.groupby('requester_user_flair')['requester_received_pizza'].agg(['count', 'sum', 'mean'])\n",
    "flair_success.columns = ['total_requests', 'successful_requests', 'success_rate']\n",
    "flair_success = flair_success.sort_values('success_rate', ascending=False)\n",
    "print(flair_success)\n",
    "\n",
    "# This is the leakage - PIF flair means \"Pizza It Forward\" - they've already received and given pizza\n",
    "# This information wouldn't be available at the time of the request\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LEAKAGE CONFIRMED:\")\n",
    "print(\"=\"*60)\n",
    "print(\"PIF = 'Pizza It Forward' - users who received pizza and are now giving back\")\n",
    "print(\"This flair is assigned AFTER receiving pizza, not at request time!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28bacc1",
   "metadata": {},
   "source": [
    "## Temporal Validity Analysis\n",
    "\n",
    "We need to identify which features are available at request time vs. added later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c4d728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T07:04:35.527070Z",
     "iopub.status.busy": "2026-01-12T07:04:35.526884Z",
     "iopub.status.idle": "2026-01-12T07:04:35.533798Z",
     "shell.execute_reply": "2026-01-12T07:04:35.533230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES AVAILABLE AT REQUEST TIME (VALID):\n",
      "--------------------------------------------------\n",
      "✓ requester_account_age_in_days_at_request\n",
      "✓ requester_upvotes_minus_downvotes_at_request\n",
      "✓ requester_upvotes_plus_downvotes_at_request\n",
      "✓ requester_number_of_comments_at_request\n",
      "✓ requester_number_of_posts_at_request\n",
      "✓ requester_number_of_comments_in_raop_at_request\n",
      "✓ requester_number_of_posts_on_raop_at_request\n",
      "✓ requester_number_of_subreddits_at_request\n",
      "✓ requester_days_since_first_post_on_raop_at_request\n",
      "✓ request_title\n",
      "✓ request_text\n",
      "✓ request_text_edit_aware\n",
      "✓ unix_timestamp_of_request\n",
      "\n",
      "============================================================\n",
      "FEATURES FROM THE FUTURE (LEAKAGE - DO NOT USE):\n",
      "--------------------------------------------------\n",
      "✗ requester_user_flair\n",
      "✗ requester_account_age_in_days_at_retrieval\n",
      "✗ requester_upvotes_minus_downvotes_at_retrieval\n",
      "✗ requester_upvotes_plus_downvotes_at_retrieval\n",
      "✗ requester_number_of_comments_at_retrieval\n",
      "✗ requester_number_of_posts_at_retrieval\n",
      "✗ requester_number_of_comments_in_raop_at_retrieval\n",
      "✗ requester_number_of_posts_on_raop_at_retrieval\n",
      "✗ requester_days_since_first_post_on_raop_at_retrieval\n",
      "✗ number_of_upvotes_of_request_at_retrieval\n",
      "✗ number_of_downvotes_of_request_at_retrieval\n",
      "✗ request_number_of_comments_at_retrieval\n",
      "✗ giver_username_if_known\n",
      "\n",
      "============================================================\n",
      "AMBIGUOUS FEATURES (NEED INVESTIGATION):\n",
      "--------------------------------------------------\n",
      "? post_was_edited\n"
     ]
    }
   ],
   "source": [
    "# Separate features by temporal validity\n",
    "print(\"FEATURES AVAILABLE AT REQUEST TIME (VALID):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "request_time_features = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request', \n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request',\n",
    "    'request_title',\n",
    "    'request_text',\n",
    "    'request_text_edit_aware',\n",
    "    'unix_timestamp_of_request'\n",
    "]\n",
    "\n",
    "for feat in request_time_features:\n",
    "    if feat in train_df.columns:\n",
    "        print(f\"✓ {feat}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURES FROM THE FUTURE (LEAKAGE - DO NOT USE):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "future_features = [\n",
    "    'requester_user_flair',  # Assigned after receiving pizza!\n",
    "    'requester_account_age_in_days_at_retrieval',\n",
    "    'requester_upvotes_minus_downvotes_at_retrieval',\n",
    "    'requester_upvotes_plus_downvotes_at_retrieval', \n",
    "    'requester_number_of_comments_at_retrieval',\n",
    "    'requester_number_of_posts_at_retrieval',\n",
    "    'requester_number_of_comments_in_raop_at_retrieval',\n",
    "    'requester_number_of_posts_on_raop_at_retrieval',\n",
    "    'requester_days_since_first_post_on_raop_at_retrieval',\n",
    "    'number_of_upvotes_of_request_at_retrieval',\n",
    "    'number_of_downvotes_of_request_at_retrieval',\n",
    "    'request_number_of_comments_at_retrieval',\n",
    "    'giver_username_if_known'\n",
    "]\n",
    "\n",
    "for feat in future_features:\n",
    "    if feat in train_df.columns:\n",
    "        print(f\"✗ {feat}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AMBIGUOUS FEATURES (NEED INVESTIGATION):\")\n",
    "print(\"-\" * 50)\n",
    "ambiguous_features = [\n",
    "    'post_was_edited'  # Could be edited after request, but timestamp not provided\n",
    "]\n",
    "for feat in ambiguous_features:\n",
    "    if feat in train_df.columns:\n",
    "        print(f\"? {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01e6e41",
   "metadata": {},
   "source": [
    "## Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "814f3cae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T07:05:24.127019Z",
     "iopub.status.busy": "2026-01-12T07:05:24.126239Z",
     "iopub.status.idle": "2026-01-12T07:05:24.140843Z",
     "shell.execute_reply": "2026-01-12T07:05:24.140090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid features count: 13\n",
      "\n",
      "Sample valid features:\n",
      "1. request_text\n",
      "2. request_text_edit_aware\n",
      "3. request_title\n",
      "4. requester_account_age_in_days_at_request\n",
      "5. requester_days_since_first_post_on_raop_at_request\n",
      "6. requester_number_of_comments_at_request\n",
      "7. requester_number_of_comments_in_raop_at_request\n",
      "8. requester_number_of_posts_at_request\n",
      "9. requester_number_of_posts_on_raop_at_request\n",
      "10. requester_number_of_subreddits_at_request\n",
      "11. requester_subreddits_at_request\n",
      "12. requester_upvotes_minus_downvotes_at_request\n",
      "13. requester_upvotes_plus_downvotes_at_request\n",
      "\n",
      "============================================================\n",
      "TOP CORRELATIONS WITH TARGET (valid features only):\n",
      "============================================================\n",
      "+0.133 - requester_number_of_posts_on_raop_at_request\n",
      "+0.132 - requester_number_of_comments_in_raop_at_request\n",
      "+0.109 - requester_days_since_first_post_on_raop_at_request\n",
      "+0.047 - requester_number_of_subreddits_at_request\n",
      "+0.043 - requester_account_age_in_days_at_request\n",
      "+0.043 - requester_upvotes_minus_downvotes_at_request\n",
      "+0.038 - requester_number_of_posts_at_request\n",
      "+0.037 - requester_number_of_comments_at_request\n",
      "+0.033 - requester_upvotes_plus_downvotes_at_request\n"
     ]
    }
   ],
   "source": [
    "# Create a simple feature set without leakage\n",
    "valid_features = []\n",
    "\n",
    "# Add request-time metadata features\n",
    "for col in train_df.columns:\n",
    "    if 'at_request' in col or 'request_text' in col or 'request_title' in col:\n",
    "        valid_features.append(col)\n",
    "\n",
    "# Remove the target from features\n",
    "valid_features = [f for f in valid_features if f != 'requester_received_pizza']\n",
    "\n",
    "print(f\"Valid features count: {len(valid_features)}\")\n",
    "print(\"\\nSample valid features:\")\n",
    "for i, feat in enumerate(valid_features[:15]):\n",
    "    print(f\"{i+1}. {feat}\")\n",
    "\n",
    "# Check correlations with target\n",
    "correlations = []\n",
    "for feat in valid_features:\n",
    "    if train_df[feat].dtype in ['int64', 'float64']:\n",
    "        corr = train_df[feat].corr(train_df['requester_received_pizza'])\n",
    "        correlations.append((feat, corr))\n",
    "\n",
    "correlations.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP CORRELATIONS WITH TARGET (valid features only):\")\n",
    "print(\"=\"*60)\n",
    "for feat, corr in correlations[:10]:\n",
    "    print(f\"{corr:+.3f} - {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8bc45f",
   "metadata": {},
   "source": [
    "## Stanford Paper Feature Analysis\n",
    "\n",
    "The original Stanford paper identified specific narrative features that predict success. Let's see if we can extract these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2849b20b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T07:05:24.143625Z",
     "iopub.status.busy": "2026-01-12T07:05:24.143388Z",
     "iopub.status.idle": "2026-01-12T07:05:24.385016Z",
     "shell.execute_reply": "2026-01-12T07:05:24.384336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanford paper features created:\n",
      "['gratitude_count', 'reciprocity_count', 'money_mentions', 'apology_count', 'first_person_count', 'question_marks', 'exclamation_marks', 'story_markers']\n",
      "\n",
      "Feature correlations with target:\n",
      "+0.082 - gratitude_count\n",
      "+0.110 - reciprocity_count\n",
      "+0.087 - money_mentions\n",
      "+0.005 - apology_count\n",
      "+0.098 - first_person_count\n",
      "+0.032 - question_marks\n",
      "+0.048 - exclamation_marks\n",
      "+0.113 - story_markers\n",
      "\n",
      "============================================================\n",
      "EXAMPLE REQUESTS:\n",
      "============================================================\n",
      "\n",
      "✓ SUCCESSFUL REQUEST:\n",
      "Title: [REQUEST] Not much food until tomorrow.\n",
      "Text: I will go ahead and say that I got a pizza meal from here before as to not seem like I'm scamming anyone. I have been promised 2 well-paying jobs and one minimum wage + .40 to fill in the gaps of unem...\n",
      "Gratitude count: 0\n",
      "Reciprocity count: 16\n",
      "\n",
      "✗ UNSUCCESSFUL REQUEST:\n",
      "Title: [REQUEST] Oceanside, Ca. USA-  US Marine getting ready to deploy.\n",
      "Text: I will soon be going on a long deployment which I'm not aloud to discuss but willing to give some info if you ask. Just wanna eat some of the stuff America has to offer before I leave for a long time ...\n",
      "Gratitude count: 0\n",
      "Reciprocity count: 2\n"
     ]
    }
   ],
   "source": [
    "# Extract Stanford paper features\n",
    "import re\n",
    "\n",
    "def extract_stanford_features(text):\n",
    "    \"\"\"Extract features identified in the Stanford paper\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return {}\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Gratitude indicators\n",
    "    gratitude_words = ['thank', 'thanks', 'appreciate', 'grateful', 'gratitude']\n",
    "    features['gratitude_count'] = sum(text_lower.count(word) for word in gratitude_words)\n",
    "    \n",
    "    # Reciprocity promises\n",
    "    reciprocity_words = ['will', 'promise', 'return', 'exchange', 'pay', 'forward', 'back', 'repay']\n",
    "    features['reciprocity_count'] = sum(text_lower.count(word) for word in reciprocity_words)\n",
    "    \n",
    "    # Money mentions\n",
    "    money_patterns = ['\\$\\d+', '\\d+ dollars', '\\d+ bucks', 'money', 'cash', 'paycheck', 'poor', 'broke', 'broke', 'starving']\n",
    "    features['money_mentions'] = sum(len(re.findall(pattern, text_lower)) for pattern in money_patterns)\n",
    "    \n",
    "    # Apologies\n",
    "    features['apology_count'] = text_lower.count('sorry') + text_lower.count('apologize')\n",
    "    \n",
    "    # First person pronouns (narrative markers)\n",
    "    first_person = ['i ', 'we ', 'my ', 'our ', 'me ', 'us ']\n",
    "    features['first_person_count'] = sum(text_lower.count(pronoun) for pronoun in first_person)\n",
    "    \n",
    "    # Question marks (asking for help)\n",
    "    features['question_marks'] = text.count('?')\n",
    "    \n",
    "    # Exclamation marks (enthusiasm/urgency)\n",
    "    features['exclamation_marks'] = text.count('!')\n",
    "    \n",
    "    # Story indicators (time markers, sequence words)\n",
    "    story_words = ['then', 'after', 'before', 'when', 'since', 'until', 'first', 'last', 'finally']\n",
    "    features['story_markers'] = sum(text_lower.count(word) for word in story_words)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Apply to training data\n",
    "text_col = 'request_text_edit_aware' if 'request_text_edit_aware' in train_df.columns else 'request_text'\n",
    "stanford_features = train_df[text_col].apply(extract_stanford_features)\n",
    "stanford_df = pd.DataFrame(stanford_features.tolist())\n",
    "\n",
    "print(\"Stanford paper features created:\")\n",
    "print(stanford_df.columns.tolist())\n",
    "print(f\"\\nFeature correlations with target:\")\n",
    "for col in stanford_df.columns:\n",
    "    corr = stanford_df[col].corr(train_df['requester_received_pizza'])\n",
    "    print(f\"{corr:+.3f} - {col}\")\n",
    "\n",
    "# Show examples of high and low scoring requests\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE REQUESTS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Successful request with high gratitude\n",
    "successful = train_df[train_df['requester_received_pizza'] == True]\n",
    "if not successful.empty:\n",
    "    example = successful.iloc[0]\n",
    "    print(\"\\n✓ SUCCESSFUL REQUEST:\")\n",
    "    print(f\"Title: {example['request_title']}\")\n",
    "    text = example[text_col][:200] + \"...\" if len(example[text_col]) > 200 else example[text_col]\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Gratitude count: {stanford_df.loc[example.name, 'gratitude_count']}\")\n",
    "    print(f\"Reciprocity count: {stanford_df.loc[example.name, 'reciprocity_count']}\")\n",
    "\n",
    "# Unsuccessful request\n",
    "unsuccessful = train_df[train_df['requester_received_pizza'] == False]\n",
    "if not unsuccessful.empty:\n",
    "    example = unsuccessful.iloc[0]\n",
    "    print(\"\\n✗ UNSUCCESSFUL REQUEST:\")\n",
    "    print(f\"Title: {example['request_title']}\")\n",
    "    text = example[text_col][:200] + \"...\" if len(example[text_col]) > 200 else example[text_col]\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Gratitude count: {stanford_df.loc[example.name, 'gratitude_count']}\")\n",
    "    print(f\"Reciprocity count: {stanford_df.loc[example.name, 'reciprocity_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747ceb64",
   "metadata": {},
   "source": [
    "## Summary of Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. DATA LEAKAGE CONFIRMED:\")\n",
    "print(\"   - user_flair encodes future success information\")\n",
    "print(\"   - PIF users have 100% success rate (83/83 requests)\")\n",
    "print(\"   - This feature must be REMOVED for valid modeling\")\n",
    "print()\n",
    "print(\"2. VALID FEATURES AVAILABLE AT REQUEST TIME:\")\n",
    "print(\"   - Account age, karma, activity metrics (at_request)\")\n",
    "print(\"   - Text content (title, request text)\")\n",
    "print(\"   - Timestamp\")\n",
    "print(f\"   - Total valid features: {len(valid_features)}\")\n",
    "print()\n",
    "print(\"3. STANFORD PAPER FEATURES IDENTIFIED:\")\n",
    "print(\"   - Gratitude expressions (thank, appreciate, etc.)\")\n",
    "print(\"   - Reciprocity promises (will, promise, return, etc.)\")\n",
    "print(\"   - Money mentions ($, dollars, poor, broke, etc.)\")\n",
    "print(\"   - Narrative markers (first-person, story words)\")\n",
    "print(\"   - These should be engineered as explicit features\")\n",
    "print()\n",
    "print(\"4. EXPECTED PERFORMANCE WITHOUT LEAKAGE:\")\n",
    "print(\"   - Current (with leakage): 1.000 AUC (perfect)\")\n",
    "print(\"   - Expected (without leakage): 0.75-0.85 AUC\")\n",
    "print(\"   - Need to re-run baseline without user_flair\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
