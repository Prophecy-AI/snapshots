{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f0596d",
   "metadata": {},
   "source": [
    "# Evolver Loop 1 Analysis: Data Leakage Investigation\n",
    "\n",
    "This notebook investigates the data leakage issue identified by the evaluator, specifically focusing on the user_flair feature and temporal validity of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792be325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Load data\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Columns: {len(train_df.columns)}\")\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train_df['requester_received_pizza'].value_counts())\n",
    "print(f\"Positive rate: {train_df['requester_received_pizza'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f077b1",
   "metadata": {},
   "source": [
    "## Investigate User Flair Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze user flair distribution and its relationship with target\n",
    "print(\"User flair distribution:\")\n",
    "flair_counts = train_df['requester_user_flair'].value_counts()\n",
    "print(flair_counts)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUCCESS RATE BY USER FLAIR:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "flair_success = train_df.groupby('requester_user_flair')['requester_received_pizza'].agg(['count', 'sum', 'mean'])\n",
    "flair_success.columns = ['total_requests', 'successful_requests', 'success_rate']\n",
    "flair_success = flair_success.sort_values('success_rate', ascending=False)\n",
    "print(flair_success)\n",
    "\n",
    "# This is the leakage - PIF flair means \"Pizza It Forward\" - they've already received and given pizza\n",
    "# This information wouldn't be available at the time of the request\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LEAKAGE CONFIRMED:\")\n",
    "print(\"=\"*60)\n",
    "print(\"PIF = 'Pizza It Forward' - users who received pizza and are now giving back\")\n",
    "print(\"This flair is assigned AFTER receiving pizza, not at request time!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28bacc1",
   "metadata": {},
   "source": [
    "## Temporal Validity Analysis\n",
    "\n",
    "We need to identify which features are available at request time vs. added later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c4d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features by temporal validity\n",
    "print(\"FEATURES AVAILABLE AT REQUEST TIME (VALID):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "request_time_features = [\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request', \n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_request',\n",
    "    'request_title',\n",
    "    'request_text',\n",
    "    'request_text_edit_aware',\n",
    "    'unix_timestamp_of_request'\n",
    "]\n",
    "\n",
    "for feat in request_time_features:\n",
    "    if feat in train_df.columns:\n",
    "        print(f\"✓ {feat}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURES FROM THE FUTURE (LEAKAGE - DO NOT USE):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "future_features = [\n",
    "    'requester_user_flair',  # Assigned after receiving pizza!\n",
    "    'requester_account_age_in_days_at_retrieval',\n",
    "    'requester_upvotes_minus_downvotes_at_retrieval',\n",
    "    'requester_upvotes_plus_downvotes_at_retrieval', \n",
    "    'requester_number_of_comments_at_retrieval',\n",
    "    'requester_number_of_posts_at_retrieval',\n",
    "    'requester_number_of_comments_in_raop_at_retrieval',\n",
    "    'requester_number_of_posts_on_raop_at_retrieval',\n",
    "    'requester_days_since_first_post_on_raop_at_retrieval',\n",
    "    'number_of_upvotes_of_request_at_retrieval',\n",
    "    'number_of_downvotes_of_request_at_retrieval',\n",
    "    'request_number_of_comments_at_retrieval',\n",
    "    'giver_username_if_known'\n",
    "]\n",
    "\n",
    "for feat in future_features:\n",
    "    if feat in train_df.columns:\n",
    "        print(f\"✗ {feat}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AMBIGUOUS FEATURES (NEED INVESTIGATION):\")\n",
    "print(\"-\" * 50)\n",
    "ambiguous_features = [\n",
    "    'post_was_edited'  # Could be edited after request, but timestamp not provided\n",
    "]\n",
    "for feat in ambiguous_features:\n",
    "    if feat in train_df.columns:\n",
    "        print(f\"? {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01e6e41",
   "metadata": {},
   "source": [
    "## Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple feature set without leakage\n",
    "valid_features = []\n",
    "\n",
    "# Add request-time metadata features\n",
    "for col in train_df.columns:\n",
    "    if 'at_request' in col or 'request_text' in col or 'request_title' in col:\n",
    "        valid_features.append(col)\n",
    "\n",
    "# Remove the target from features\n",
    "valid_features = [f for f in valid_features if f != 'requester_received_pizza']\n",
    "\n",
    "print(f\"Valid features count: {len(valid_features)}\")\n",
    "print(\"\\nSample valid features:\")\n",
    "for i, feat in enumerate(valid_features[:15]):\n",
    "    print(f\"{i+1}. {feat}\")\n",
    "\n",
    "# Check correlations with target\n",
    "correlations = []\n",
    "for feat in valid_features:\n",
    "    if train_df[feat].dtype in ['int64', 'float64']:\n",
    "        corr = train_df[feat].corr(train_df['requester_received_pizza'])\n",
    "        correlations.append((feat, corr))\n",
    "\n",
    "correlations.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP CORRELATIONS WITH TARGET (valid features only):\")\n",
    "print(\"=\"*60)\n",
    "for feat, corr in correlations[:10]:\n",
    "    print(f\"{corr:+.3f} - {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8bc45f",
   "metadata": {},
   "source": [
    "## Stanford Paper Feature Analysis\n",
    "\n",
    "The original Stanford paper identified specific narrative features that predict success. Let's see if we can extract these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2849b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Stanford paper features\n",
    "import re\n",
    "\n",
    "def extract_stanford_features(text):\n",
    "    \"\"\"Extract features identified in the Stanford paper\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return {}\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Gratitude indicators\n",
    "    gratitude_words = ['thank', 'thanks', 'appreciate', 'grateful', 'gratitude']\n",
    "    features['gratitude_count'] = sum(text_lower.count(word) for word in gratitude_words)\n",
    "    \n",
    "    # Reciprocity promises\n",
    "    reciprocity_words = ['will', 'promise', 'return', 'exchange', 'pay', 'forward', 'back', 'repay']\n",
    "    features['reciprocity_count'] = sum(text_lower.count(word) for word in reciprocity_words)\n",
    "    \n",
    "    # Money mentions\n",
    "    money_patterns = ['\\$\\d+', '\\d+ dollars', '\\d+ bucks', 'money', 'cash', 'paycheck', 'poor', 'broke', 'broke', 'starving']\n",
    "    features['money_mentions'] = sum(len(re.findall(pattern, text_lower)) for pattern in money_patterns)\n",
    "    \n",
    "    # Apologies\n",
    "    features['apology_count'] = text_lower.count('sorry') + text_lower.count('apologize')\n",
    "    \n",
    "    # First person pronouns (narrative markers)\n",
    "    first_person = ['i ', 'we ', 'my ', 'our ', 'me ', 'us ']\n",
    "    features['first_person_count'] = sum(text_lower.count(pronoun) for pronoun in first_person)\n",
    "    \n",
    "    # Question marks (asking for help)\n",
    "    features['question_marks'] = text.count('?')\n",
    "    \n",
    "    # Exclamation marks (enthusiasm/urgency)\n",
    "    features['exclamation_marks'] = text.count('!')\n",
    "    \n",
    "    # Story indicators (time markers, sequence words)\n",
    "    story_words = ['then', 'after', 'before', 'when', 'since', 'until', 'first', 'last', 'finally']\n",
    "    features['story_markers'] = sum(text_lower.count(word) for word in story_words)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Apply to training data\n",
    "text_col = 'request_text_edit_aware' if 'request_text_edit_aware' in train_df.columns else 'request_text'\n",
    "stanford_features = train_df[text_col].apply(extract_stanford_features)\n",
    "stanford_df = pd.DataFrame(stanford_features.tolist())\n",
    "\n",
    "print(\"Stanford paper features created:\")\n",
    "print(stanford_df.columns.tolist())\n",
    "print(f\"\\nFeature correlations with target:\")\n",
    "for col in stanford_df.columns:\n",
    "    corr = stanford_df[col].corr(train_df['requester_received_pizza'])\n",
    "    print(f\"{corr:+.3f} - {col}\")\n",
    "\n",
    "# Show examples of high and low scoring requests\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE REQUESTS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Successful request with high gratitude\n",
    "successful = train_df[train_df['requester_received_pizza'] == True]\n",
    "if not successful.empty:\n",
    "    example = successful.iloc[0]\n",
    "    print(\"\\n✓ SUCCESSFUL REQUEST:\")\n",
    "    print(f\"Title: {example['request_title']}\")\n",
    "    text = example[text_col][:200] + \"...\" if len(example[text_col]) > 200 else example[text_col]\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Gratitude count: {stanford_df.loc[example.name, 'gratitude_count']}\")\n",
    "    print(f\"Reciprocity count: {stanford_df.loc[example.name, 'reciprocity_count']}\")\n",
    "\n",
    "# Unsuccessful request\n",
    "unsuccessful = train_df[train_df['requester_received_pizza'] == False]\n",
    "if not unsuccessful.empty:\n",
    "    example = unsuccessful.iloc[0]\n",
    "    print(\"\\n✗ UNSUCCESSFUL REQUEST:\")\n",
    "    print(f\"Title: {example['request_title']}\")\n",
    "    text = example[text_col][:200] + \"...\" if len(example[text_col]) > 200 else example[text_col]\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Gratitude count: {stanford_df.loc[example.name, 'gratitude_count']}\")\n",
    "    print(f\"Reciprocity count: {stanford_df.loc[example.name, 'reciprocity_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747ceb64",
   "metadata": {},
   "source": [
    "## Summary of Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. DATA LEAKAGE CONFIRMED:\")\n",
    "print(\"   - user_flair encodes future success information\")\n",
    "print(\"   - PIF users have 100% success rate (83/83 requests)\")\n",
    "print(\"   - This feature must be REMOVED for valid modeling\")\n",
    "print()\n",
    "print(\"2. VALID FEATURES AVAILABLE AT REQUEST TIME:\")\n",
    "print(\"   - Account age, karma, activity metrics (at_request)\")\n",
    "print(\"   - Text content (title, request text)\")\n",
    "print(\"   - Timestamp\")\n",
    "print(f\"   - Total valid features: {len(valid_features)}\")\n",
    "print()\n",
    "print(\"3. STANFORD PAPER FEATURES IDENTIFIED:\")\n",
    "print(\"   - Gratitude expressions (thank, appreciate, etc.)\")\n",
    "print(\"   - Reciprocity promises (will, promise, return, etc.)\")\n",
    "print(\"   - Money mentions ($, dollars, poor, broke, etc.)\")\n",
    "print(\"   - Narrative markers (first-person, story words)\")\n",
    "print(\"   - These should be engineered as explicit features\")\n",
    "print()\n",
    "print(\"4. EXPECTED PERFORMANCE WITHOUT LEAKAGE:\")\n",
    "print(\"   - Current (with leakage): 1.000 AUC (perfect)\")\n",
    "print(\"   - Expected (without leakage): 0.75-0.85 AUC\")\n",
    "print(\"   - Need to re-run baseline without user_flair\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
