{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "898a8854",
   "metadata": {},
   "source": [
    "# Baseline Experiment: LightGBM with Text and Metadata Features\n",
    "\n",
    "This notebook implements a baseline model following the seed prompt strategy:\n",
    "- LightGBM gradient boosting on engineered features\n",
    "- TF-IDF vectors for text features\n",
    "- Metadata features from the dataset\n",
    "- Stratified 5-fold cross-validation\n",
    "- AUC-ROC evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1615b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T06:14:51.033767Z",
     "iopub.status.busy": "2026-01-12T06:14:51.032653Z",
     "iopub.status.idle": "2026-01-12T06:14:51.038743Z",
     "shell.execute_reply": "2026-01-12T06:14:51.038042Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from scipy.sparse import hstack\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2baf22f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a6701a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T06:14:51.041779Z",
     "iopub.status.busy": "2026-01-12T06:14:51.041050Z",
     "iopub.status.idle": "2026-01-12T06:14:51.139148Z",
     "shell.execute_reply": "2026-01-12T06:14:51.138375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2878, 32)\n",
      "Columns: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n",
      "\n",
      "Target distribution:\n",
      "requester_received_pizza\n",
      "False    0.751564\n",
      "True     0.248436\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "with open('/home/data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "        \n",
    "train_df = pd.DataFrame(train_data)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Columns: {train_df.columns.tolist()}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train_df['requester_received_pizza'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d8f7de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T06:14:51.141386Z",
     "iopub.status.busy": "2026-01-12T06:14:51.140789Z",
     "iopub.status.idle": "2026-01-12T06:14:51.164472Z",
     "shell.execute_reply": "2026-01-12T06:14:51.163733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (1162, 17)\n",
      "Columns: ['giver_username_if_known', 'request_id', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_days_since_first_post_on_raop_at_request', 'requester_number_of_comments_at_request', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_posts_at_request', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_request', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "with open('/home/data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "        \n",
    "test_df = pd.DataFrame(test_data)\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Columns: {test_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed8725",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10829bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata_features(df):\n",
    "    \"\"\"Create metadata features\"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Account age features (only at_request available in test)\n",
    "    features['account_age_at_request'] = df['requester_account_age_in_days_at_request']\n",
    "    \n",
    "    # Karma features (only at_request available in test)\n",
    "    features['karma_at_request'] = df['requester_upvotes_minus_downvotes_at_request']\n",
    "    features['total_votes_at_request'] = df['requester_upvotes_plus_downvotes_at_request']\n",
    "    \n",
    "    # Karma ratios (to handle division by zero)\n",
    "    features['karma_ratio_at_request'] = np.where(\n",
    "        df['requester_upvotes_plus_downvotes_at_request'] > 0,\n",
    "        df['requester_upvotes_minus_downvotes_at_request'] / df['requester_upvotes_plus_downvotes_at_request'],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # Activity metrics (only at_request available in test)\n",
    "    features['comments_at_request'] = df['requester_number_of_comments_at_request']\n",
    "    features['posts_at_request'] = df['requester_number_of_posts_at_request']\n",
    "    \n",
    "    # RAOP-specific activity (only at_request available in test)\n",
    "    features['raop_comments_at_request'] = df['requester_number_of_comments_in_raop_at_request']\n",
    "    features['raop_posts_at_request'] = df['requester_number_of_posts_on_raop_at_request']\n",
    "    \n",
    "    # Subreddit diversity\n",
    "    features['num_subreddits'] = df['requester_number_of_subreddits_at_request']\n",
    "    \n",
    "    # User flair encoding - handle missing in test\n",
    "    if 'requester_user_flair' in df.columns:\n",
    "        flair_map = {'None': 0, 'shroom': 1, 'PIF': 2}\n",
    "        features['user_flair_encoded'] = df['requester_user_flair'].map(flair_map).fillna(0)\n",
    "    else:\n",
    "        # Test set doesn't have flair, use 0 (None) as default\n",
    "        features['user_flair_encoded'] = 0\n",
    "    \n",
    "    # Time-based features\n",
    "    features['unix_timestamp'] = df['unix_timestamp_of_request']\n",
    "    features['hour_of_day'] = pd.to_datetime(df['unix_timestamp_of_request'], unit='s').dt.hour\n",
    "    features['day_of_week'] = pd.to_datetime(df['unix_timestamp_of_request'], unit='s').dt.dayofweek\n",
    "    \n",
    "    # Activity density (add small constant to avoid division by zero)\n",
    "    features['comments_per_day'] = features['comments_at_request'] / (features['account_age_at_request'] + 1)\n",
    "    features['posts_per_day'] = features['posts_at_request'] / (features['account_age_at_request'] + 1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a1a849",
   "metadata": {},
   "source": [
    "## TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF features for text\n",
    "# Use edit-aware text if available\n",
    "text_col = 'request_text_edit_aware' if 'request_text_edit_aware' in train_df.columns else 'request_text'\n",
    "\n",
    "# TF-IDF for request text\n",
    "tfidf_text = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "tfidf_text.fit(train_df[text_col].fillna(''))\n",
    "train_tfidf_text = tfidf_text.transform(train_df[text_col].fillna(''))\n",
    "test_tfidf_text = tfidf_text.transform(test_df[text_col].fillna(''))\n",
    "\n",
    "print(f\"TF-IDF text features shape: {train_tfidf_text.shape}\")\n",
    "\n",
    "# TF-IDF for request title\n",
    "tfidf_title = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "tfidf_title.fit(train_df['request_title'].fillna(''))\n",
    "train_tfidf_title = tfidf_title.transform(train_df['request_title'].fillna(''))\n",
    "test_tfidf_title = tfidf_title.transform(test_df['request_title'].fillna(''))\n",
    "\n",
    "print(f\"TF-IDF title features shape: {train_tfidf_title.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac2a38",
   "metadata": {},
   "source": [
    "## Combine All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd960697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features\n",
    "# Convert metadata and text features to sparse matrices\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "train_meta_sparse = csr_matrix(train_meta_features.fillna(0).values)\n",
    "test_meta_sparse = csr_matrix(test_meta_features.fillna(0).values)\n",
    "\n",
    "train_text_sparse = csr_matrix(train_text_features.fillna(0).values)\n",
    "test_text_sparse = csr_matrix(test_text_features.fillna(0).values)\n",
    "\n",
    "# Stack all features\n",
    "X_train = hstack([\n",
    "    train_tfidf_text,\n",
    "    train_tfidf_title,\n",
    "    train_text_sparse,\n",
    "    train_meta_sparse\n",
    "])\n",
    "\n",
    "X_test = hstack([\n",
    "    test_tfidf_text,\n",
    "    test_tfidf_title,\n",
    "    test_text_sparse,\n",
    "    test_meta_sparse\n",
    "])\n",
    "\n",
    "y_train = train_df['requester_received_pizza'].astype(int).values\n",
    "\n",
    "print(f\"Final training features shape: {X_train.shape}\")\n",
    "print(f\"Final test features shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff533646",
   "metadata": {},
   "source": [
    "## Model Training with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96330a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "predictions = np.zeros(len(test_df))\n",
    "feature_importance_list = []\n",
    "\n",
    "print(\"Training LightGBM model with 5-fold CV...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "    \n",
    "    X_train_fold = X_train[train_idx]\n",
    "    y_train_fold = y_train[train_idx]\n",
    "    X_val_fold = X_train[val_idx]\n",
    "    y_val_fold = y_train[val_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train_fold, label=y_train_fold)\n",
    "    val_data = lgb.Dataset(X_val_fold, label=y_val_fold, reference=train_data)\n",
    "    \n",
    "    # Parameters (conservative for baseline)\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'num_threads': 4\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_pred = model.predict(X_val_fold, num_iteration=model.best_iteration)\n",
    "    val_score = roc_auc_score(y_val_fold, val_pred)\n",
    "    fold_scores.append(val_score)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} AUC: {val_score:.4f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    predictions += test_pred / 5\n",
    "    \n",
    "    # Store feature importance\n",
    "    importance = model.feature_importance(importance_type='gain')\n",
    "    feature_importance_list.append(importance)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Mean CV AUC: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")\n",
    "print(f\"Individual fold scores: {fold_scores}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666536cc",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance\n",
    "feature_names = []\n",
    "feature_names.extend([f'text_tfidf_{i}' for i in range(train_tfidf_text.shape[1])])\n",
    "feature_names.extend([f'title_tfidf_{i}' for i in range(train_tfidf_title.shape[1])])\n",
    "feature_names.extend(train_text_features.columns.tolist())\n",
    "feature_names.extend(train_meta_features.columns.tolist())\n",
    "\n",
    "# Calculate mean importance across folds\n",
    "mean_importance = np.mean(feature_importance_list, axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': mean_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 most important features:\")\n",
    "print(importance_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ebbd4",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e5c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'request_id': test_df['request_id'],\n",
    "    'requester_received_pizza': predictions\n",
    "})\n",
    "\n",
    "# Ensure the format matches sample submission\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc510087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify submission format matches sample\n",
    "sample_sub = pd.read_csv('/home/data/sampleSubmission.csv')\n",
    "print(\"Sample submission format:\")\n",
    "print(sample_sub.head())\n",
    "print(f\"\\nOur submission format:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nFormat matches: {list(submission.columns) == list(sample_sub.columns)}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
