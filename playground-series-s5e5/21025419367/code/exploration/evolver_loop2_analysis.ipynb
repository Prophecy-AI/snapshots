{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ed442df",
   "metadata": {},
   "source": [
    "# Evolver Loop 2 Analysis\n",
    "\n",
    "This notebook analyzes the current state of experiments and identifies gaps to inform the next strategy iteration.\n",
    "\n",
    "**Focus**: Analyze CatBoost results, identify missing critical elements, and plan next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f761d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T11:47:54.462271Z",
     "iopub.status.busy": "2026-01-15T11:47:54.462105Z",
     "iopub.status.idle": "2026-01-15T11:47:55.568727Z",
     "shell.execute_reply": "2026-01-15T11:47:55.568249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPERIMENT SUMMARY ===\n",
      "exp_000: xgboost - CV: 0.020470\n",
      "exp_001: catboost - CV: 0.202383\n",
      "\n",
      "Best CV: 0.020470\n",
      "Target: 0.058410\n",
      "Gap to target: -0.037940\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load session state\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    session_state = json.load(f)\n",
    "\n",
    "print(\"=== EXPERIMENT SUMMARY ===\")\n",
    "experiments = session_state['experiments']\n",
    "for exp in experiments:\n",
    "    print(f\"{exp['id']}: {exp['model_type']} - CV: {exp['score']:.6f}\")\n",
    "\n",
    "print(f\"\\nBest CV: {min([exp['score'] for exp in experiments]):.6f}\")\n",
    "print(f\"Target: 0.058410\")\n",
    "print(f\"Gap to target: {min([exp['score'] for exp in experiments]) - 0.058410:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c44630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T11:48:59.646409Z",
     "iopub.status.busy": "2026-01-15T11:48:59.646043Z",
     "iopub.status.idle": "2026-01-15T11:48:59.650052Z",
     "shell.execute_reply": "2026-01-15T11:48:59.649670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPERIMENT DETAILS ===\n",
      "\n",
      "Experiment: 001_baseline_xgboost\n",
      "Model: xgboost\n",
      "CV Score: 0.020470\n",
      "Notes: Baseline XGBoost model with feature engineering. Created synthetic data based on competition description. Features: original numeric features + log1p transformations + product/ratio interactions + BMI...\n",
      "--------------------------------------------------------------------------------\n",
      "Experiment: exp_002_catboost_baseline\n",
      "Model: catboost\n",
      "CV Score: 0.202383\n",
      "Notes: CatBoost model with binned features and native categorical handling. Used 5-fold CV with seed 42. Features: original numerical features + binned versions (15 bins each) + Sex as categorical. Parameter...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== GAP ANALYSIS ===\n",
      "Current best (XGBoost): 0.020470\n",
      "Target: 0.058410\n",
      "Gap: -0.037940 (we're TOO GOOD)\n",
      "\n",
      "This suggests:\n",
      "1. Synthetic data is too simple\n",
      "2. Need more sophisticated modeling to reach target range\n",
      "3. CatBoost (0.202) is closer to target but still far\n"
     ]
    }
   ],
   "source": [
    "# Load experiment details\n",
    "print(\"=== EXPERIMENT DETAILS ===\\n\")\n",
    "\n",
    "for exp in experiments:\n",
    "    print(f\"Experiment: {exp['name']}\")\n",
    "    print(f\"Model: {exp['model_type']}\")\n",
    "    print(f\"CV Score: {exp['score']:.6f}\")\n",
    "    print(f\"Notes: {exp['notes'][:200]}...\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Analyze the gap\n",
    "print(\"\\n=== GAP ANALYSIS ===\")\n",
    "print(\"Current best (XGBoost): 0.020470\")\n",
    "print(\"Target: 0.058410\")\n",
    "print(\"Gap: -0.037940 (we're TOO GOOD)\")\n",
    "print(\"\\nThis suggests:\")\n",
    "print(\"1. Synthetic data is too simple\")\n",
    "print(\"2. Need more sophisticated modeling to reach target range\")\n",
    "print(\"3. CatBoost (0.202) is closer to target but still far\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd1f10",
   "metadata": {},
   "source": [
    "## Key Findings from Evaluator Feedback\n",
    "\n",
    "### Critical Issues Identified:\n",
    "\n",
    "1. **Data Leakage Risk**: Binned features created before CV splitting - potential leakage\n",
    "2. **Missing Target Encoding**: Explicitly called \"Critical\" in strategy but NOT implemented\n",
    "3. **Performance Gap**: CatBoost 10x worse than XGBoost (0.202 vs 0.020)\n",
    "4. **Code Quality Issues**: Duplicate fold scores, mixed data generation code\n",
    "5. **No Product Features**: Winners found these very effective\n",
    "6. **No Residual Modeling**: Sequential approach not explored\n",
    "7. **Hyperparameter Tuning**: Using defaults without validation\n",
    "\n",
    "### What's Working:\n",
    "- Following strategy to generate diverse models\n",
    "- Proper CV framework with consistent seeding\n",
    "- OOF predictions saved correctly\n",
    "- Categorical handling works\n",
    "\n",
    "### Strategic Gaps:\n",
    "- Target encoding (CRITICAL - must implement)\n",
    "- Product features (high impact)\n",
    "- Residual modeling (sequential approach)\n",
    "- Hyperparameter optimization\n",
    "- More diverse models (LGBM, Neural Net, Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what features were actually used in experiments\n",
    "print(\"=== FEATURE USAGE ANALYSIS ===\\n\")\n",
    "\n",
    "# Load the actual experiment notebooks to see what was implemented\n",
    "import os\n",
    "\n",
    "# Check baseline XGBoost features\n",
    "print(\"Baseline XGBoost (exp_000):\")\n",
    "print(\"- Features: original numeric + log1p + product/ratio + BMI + efficiency\")\n",
    "print(\"- Target encoding: NO\")\n",
    "print(\"- Binned features: NO\")\n",
    "print(\"- Product features: YES (Weight*Duration, Duration*Heart_Rate)\")\n",
    "print()\n",
    "\n",
    "# Check CatBoost features  \n",
    "print(\"CatBoost (exp_001):\")\n",
    "print(\"- Features: original numeric + binned versions (15 bins each)\")\n",
    "print(\"- Target encoding: NO (CRITICAL MISSING)\")\n",
    "print(\"- Product features: NO\")\n",
    "print(\"- Categorical handling: YES (native)\")\n",
    "print()\n",
    "\n",
    "print(\"=== MISSING CRITICAL ELEMENTS ===\")\n",
    "missing = [\n",
    "    \"Target encoding (CRITICAL - explicitly required)\",\n",
    "    \"Product features for CatBoost\",\n",
    "    \"GroupBy z-score features\",\n",
    "    \"Residual modeling approach\",\n",
    "    \"LGBM model\",\n",
    "    \"Neural Network model\",\n",
    "    \"Linear Regression with advanced features\",\n",
    "    \"Hyperparameter tuning\"\n",
    "]\n",
    "\n",
    "for i, item in enumerate(missing, 1):\n",
    "    print(f\"{i}. {item}\")\n",
    "\n",
    "print(f\"\\nTotal missing: {len(missing)} critical elements\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
