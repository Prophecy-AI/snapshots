{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e8c8d8",
   "metadata": {},
   "source": [
    "# Loop 5 Analysis: Strategic Direction After Diagnostic Findings\n",
    "\n",
    "## Current Status Summary\n",
    "- **Best CV**: 0.02047 (exp_000 - baseline XGBoost)\n",
    "- **Worst CV**: 0.21156 (exp_002 - target encoding + products)\n",
    "- **Target**: 0.058410 (need to INCREASE CV by ~0.038)\n",
    "- **Key Finding**: Product features are TOO predictive (r=0.94), causing overfitting\n",
    "- **Key Finding**: Manual target encoding on 'Sex' (2 categories) is ineffective\n",
    "\n",
    "## Analysis Objectives\n",
    "1. Review diagnostic findings from Loop 4\n",
    "2. Identify winning solution gaps\n",
    "3. Plan strategic next steps\n",
    "4. Prioritize approaches based on evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a13f56f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T17:13:35.366451Z",
     "iopub.status.busy": "2026-01-15T17:13:35.366204Z",
     "iopub.status.idle": "2026-01-15T17:13:35.388589Z",
     "shell.execute_reply": "2026-01-15T17:13:35.388183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA OVERVIEW ===\n",
      "Train shape: (8000, 9)\n",
      "Test shape: (2000, 9)\n",
      "\n",
      "Target statistics:\n",
      "count    8000.000000\n",
      "mean      143.772778\n",
      "std        76.566039\n",
      "min        10.000000\n",
      "25%        91.227982\n",
      "50%       121.244149\n",
      "75%       174.789980\n",
      "max       500.000000\n",
      "Name: Calories, dtype: float64\n",
      "\n",
      "=== EXPERIMENT HISTORY ===\n",
      "exp_000: xgboost - CV: 0.02047 - 001_baseline_xgboost\n",
      "exp_001: catboost - CV: 0.20238 - exp_002_catboost_baseline\n",
      "exp_002: xgb - CV: 0.21156 - exp_003_xgb_target_encoding\n",
      "exp_003: catboost - CV: 0.20184 - exp_004_catboost_hyperopt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/code/data/train.csv')\n",
    "test_df = pd.read_csv('/home/code/data/test.csv')\n",
    "\n",
    "print(\"=== DATA OVERVIEW ===\")\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(train_df['Calories'].describe())\n",
    "\n",
    "# Load session state to see experiment history\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    session_state = json.load(f)\n",
    "\n",
    "print(f\"\\n=== EXPERIMENT HISTORY ===\")\n",
    "for exp in session_state['experiments']:\n",
    "    print(f\"{exp['id']}: {exp['model_type']} - CV: {exp['score']:.5f} - {exp['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44dbec9",
   "metadata": {},
   "source": [
    "print(\"=== KEY DIAGNOSTIC FINDINGS ===\\n\")\n",
    "\n",
    "print(\"1. PRODUCT FEATURES ARE TOO PREDICTIVE\")\n",
    "print(\"   - Weight_Duration correlation with target: 0.94\")\n",
    "print(\"   - Duration_Heart_Rate correlation: 0.94\") \n",
    "print(\"   - Using ONLY these features: CV = 0.2275\")\n",
    "print(\"   - Baseline without them: CV = 0.0205\")\n",
    "print(\"   - Conclusion: Product features cause overfitting\\n\")\n",
    "\n",
    "print(\"2. MANUAL TARGET ENCODING ON 'Sex' IS INEFFECTIVE\")\n",
    "print(\"   - 'Sex' has only 2 categories (M/F)\")\n",
    "print(\"   - Target encoding correlation: 0.123\")\n",
    "print(\"   - Adds minimal signal, may cause overfitting\")\n",
    "print(\"   - Winners encoded HIGH-cardinality features instead\\n\")\n",
    "\n",
    "print(\"3. IMPLEMENTATION GAPS VS WINNERS\")\n",
    "print(\"   - Using manual encoding vs sklearn's TargetEncoder\")\n",
    "print(\"   - No internal cross-fitting in manual implementation\")\n",
    "print(\"   - Applied to wrong features (low cardinality)\")\n",
    "print(\"   - No hyperparameter tuning for regularization\")\n",
    "print(\"   - Missing residual modeling approach\")\n",
    "print(\"   - No groupby z-score features\\n\")\n",
    "\n",
    "# Calculate correlation with target for original features only\n",
    "numeric_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "corr_with_target = train_df[numeric_features + ['Calories']].corr()['Calories'].drop('Calories')\n",
    "print(\"=== CORRELATION WITH TARGET (Original Features) ===\")\n",
    "print(corr_with_target.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51726f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== KEY DIAGNOSTIC FINDINGS ===\\n\")\n",
    "\n",
    "print(\"1. PRODUCT FEATURES ARE TOO PREDICTIVE\")\n",
    "print(\"   - Weight_Duration correlation with target: 0.94\")\n",
    "print(\"   - Duration_Heart_Rate correlation: 0.94\") \n",
    "print(\"   - Using ONLY these features: CV = 0.2275\")\n",
    "print(\"   - Baseline without them: CV = 0.0205\")\n",
    "print(\"   - Conclusion: Product features cause overfitting\\n\")\n",
    "\n",
    "print(\"2. MANUAL TARGET ENCODING ON 'Sex' IS INEFFECTIVE\")\n",
    "print(\"   - 'Sex' has only 2 categories (M/F)\")\n",
    "print(\"   - Target encoding correlation: 0.123\")\n",
    "print(\"   - Adds minimal signal, may cause overfitting\")\n",
    "print(\"   - Winners encoded HIGH-cardinality features instead\\n\")\n",
    "\n",
    "print(\"3. IMPLEMENTATION GAPS VS WINNERS\")\n",
    "print(\"   - Using manual encoding vs sklearn's TargetEncoder\")\n",
    "print(\"   - No internal cross-fitting in manual implementation\")\n",
    "print(\"   - Applied to wrong features (low cardinality)\")\n",
    "print(\"   - No hyperparameter tuning for regularization\")\n",
    "print(\"   - Missing residual modeling approach\")\n",
    "print(\"   - No groupby z-score features\\n\")\n",
    "\n",
    "print(\"=== CORRELATION WITH TARGET (from Loop 4 analysis) ===\")\n",
    "print(\"Duration:        0.82\")\n",
    "print(\"Weight:          0.71\") \n",
    "print(\"Heart_Rate:      0.68\")\n",
    "print(\"Height:          0.43\")\n",
    "print(\"Age:             0.16\")\n",
    "print(\"Body_Temp:       0.11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3f6618",
   "metadata": {},
   "source": [
    "## 2. Analyze Winning Solution Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f849d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== WINNING SOLUTION ANALYSIS ===\\n\")\n",
    "\n",
    "print(\"CHRIS DEOTTE (1st place) - GPU Hill Climbing:\")\n",
    "print(\"- Final CV: 0.05880\")\n",
    "print(\"- 7 diverse models in ensemble\")\n",
    "print(\"- Target encoding (25% of ensemble weight)\")\n",
    "print(\"- Product features: log1p + all pairwise products/divisions/sums/differences\")\n",
    "print(\"- CatBoost with binned features + groupby z-score features\")\n",
    "print(\"- NN on LinearRegression residuals\")\n",
    "print(\"- XGB on NN residuals\\n\")\n",
    "\n",
    "print(\"ANGELOSMAR (4th place) - Ridge Ensemble:\")\n",
    "print(\"- Final CV: 0.05868\") \n",
    "print(\"- 12 models in ensemble\")\n",
    "print(\"- Autogluon (weight > 0.5) - key model\")\n",
    "print(\"- Linear regression with ~400 features (CV 0.05976)\")\n",
    "print(\"- Sequential modeling: NN on LR residuals, XGB on NN residuals\")\n",
    "print(\"- GBDT models worked best with MINIMAL feature engineering\")\n",
    "print(\"- Final ensemble: Ridge regression on OOF predictions\\n\")\n",
    "\n",
    "print(\"=== CRITICAL INSIGHTS ===\")\n",
    "print(\"1. RESIDUAL MODELING was key for both winners\")\n",
    "print(\"2. TARGET ENCODING on HIGH-cardinality features (not 'Sex')\")\n",
    "print(\"3. Product features were used BUT with proper regularization\")\n",
    "print(\"4. GBDT models (XGB, CatBoost, LGBM) worked best with MINIMAL features\")\n",
    "print(\"5. DIVERSITY in models and approaches was crucial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf687a29",
   "metadata": {},
   "source": [
    "## 3. Strategic Next Steps - Priority Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605033cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== STRATEGIC NEXT STEPS (PRIORITY ORDER) ===\\n\")\n",
    "\n",
    "print(\"PRIORITY 1: IMPLEMENT RESIDUAL MODELING (CRITICAL)\")\n",
    "print(\"Why: Both winners emphasized this as key to success\")\n",
    "print(\"Approach:\")\n",
    "print(\"  1. LinearRegression baseline (simple, captures linear patterns)\")\n",
    "print(\"  2. Neural Network on LR residuals (captures non-linear patterns)\")\n",
    "print(\"  3. XGBoost on NN residuals (captures tree-based patterns)\")\n",
    "print(\"  4. Final prediction: sum of all three models\")\n",
    "print(\"Expected CV: 0.059-0.060\\n\")\n",
    "\n",
    "print(\"PRIORITY 2: REMOVE PRODUCT FEATURES (TEMPORARY)\")\n",
    "print(\"Why: Too predictive (r=0.94), causing overfitting\")\n",
    "print(\"Action: Establish baseline WITHOUT product features first\")\n",
    "print(\"Can re-add later with stronger regularization\\n\")\n",
    "\n",
    "print(\"PRIORITY 3: ABANDON MANUAL TARGET ENCODING ON 'Sex'\")\n",
    "print(\"Why: Only 2 categories, adds minimal signal\")\n",
    "print(\"Action: Use sklearn's TargetEncoder on binned features instead\\n\")\n",
    "\n",
    "print(\"PRIORITY 4: ADD GROUPBY Z-SCORE FEATURES\")\n",
    "print(\"Why: Winners found these effective\")\n",
    "print(\"Approach: Group by Sex, compute z-scores for numerical features\")\n",
    "print(\"Example: (Weight - mean(Weight by Sex)) / std(Weight by Sex)\\n\")\n",
    "\n",
    "print(\"PRIORITY 5: HYPERPARAMETER TUNING FOR REGULARIZATION\")\n",
    "print(\"Why: Added 16 features in exp_003 but kept same hyperparameters\")\n",
    "print(\"XGBoost: Increase reg_alpha, reg_lambda, reduce max_depth\")\n",
    "print(\"CatBoost: Increase l2_leaf_reg, reduce depth\\n\")\n",
    "\n",
    "print(\"PRIORITY 6: CREATE DIVERSE BASE MODELS\")\n",
    "print(\"- LightGBM with GOSS\")\n",
    "print(\"- Neural Network (direct, not residual)\")\n",
    "print(\"- Linear Regression with many features\")\n",
    "print(\"- CatBoost with proper binned features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad1105",
   "metadata": {},
   "source": [
    "## 4. Expected Timeline and Success Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14d9e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== EXPECTED TIMELINE ===\\n\")\n",
    "\n",
    "print(\"Loop 5-6: Implement residual modeling (3 models)\")\n",
    "print(\"Loop 7-8: Add groupby features + hyperparameter tuning\") \n",
    "print(\"Loop 9-10: Create additional diverse models\")\n",
    "print(\"Loop 11-12: Implement proper target encoding on binned features\")\n",
    "print(\"Loop 13+: Ensemble with hill climbing\\n\")\n",
    "\n",
    "print(\"=== SUCCESS CRITERIA ===\")\n",
    "print(\"1. Generate at least 7 diverse models with CV 0.058-0.065\")\n",
    "print(\"2. Implement residual modeling pipeline (3 sequential models)\")\n",
    "print(\"3. Run ablation studies to identify optimal feature set\")\n",
    "print(\"4. Achieve final CV < 0.058410 (target)\")\n",
    "print(\"5. Create robust ensemble beating best single model by >0.001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d6494",
   "metadata": {},
   "source": [
    "## 5. Record Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e760d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record findings for future reference\n",
    "# Using the evolver_tools module\n",
    "\n",
    "print(\"Key findings from this analysis:\")\n",
    "print(\"1. Product features are too predictive (r=0.94) and cause overfitting\")\n",
    "print(\"2. Manual target encoding on 'Sex' is ineffective (only 2 categories)\")\n",
    "print(\"3. Implementation gaps vs winners identified\")\n",
    "print(\"4. Residual modeling is the top priority\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
