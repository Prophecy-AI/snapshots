## Current Status
- **Best CV score**: 0.202310 from exp_002 (CatBoost baseline)
- **Best LB score**: Not yet submitted (need calibration)
- **Target**: Beat current best LB score

## Response to Evaluator
No evaluator feedback yet for this iteration.

## Data Understanding
- CatBoost outperforms XGBoost (0.202310 vs 0.209215) with same features
- Simple ensemble (averaging) didn't improve over best single model (0.203915 vs 0.202310)
- Current feature engineering works: log1p transforms, product features (Weight_Duration, Duration_Heart_Rate, Height_Weight), ratio features (Weight_Height, BMI)
- Both models successfully use 18 features including categorical 'Sex' handling

## Recommended Approaches (Priority Order)

### Priority 1: Hyperparameter Optimization for CatBoost
CatBoost is our best model - let's maximize its performance:
1. **Learning rate sweep**: Test [0.01, 0.03, 0.05, 0.1] with proportional iterations
2. **Depth exploration**: Test depths [4, 5, 6, 7, 8] - monitor for overfitting
3. **Loss function comparison**: RMSE (current) vs MAE vs Quantile loss
4. **Regularization**: Try L2 regularization (reg_lambda) values [1, 3, 5, 10]
5. **Use Optuna**: Implement Bayesian optimization for systematic search
6. **Early stopping**: Optimize early_stopping_rounds [30, 50, 100]

Expected improvement: 0.002-0.005 CV reduction

### Priority 2: Advanced Feature Engineering
Based on winning solution analysis, implement:
1. **Target Encoding for Sex**: Use sklearn's TargetEncoder with internal CV (cv=5) to create 'Sex_target_enc' feature
2. **Expanded Product Features**: Create all pairwise products of numerical features (Age×Height, Age×Weight, Height×Weight, etc.)
3. **Polynomial Features**: Add squared terms for top features - Duration², Heart_Rate², Weight²
4. **Interaction Terms**: Age×Duration, Weight×Heart_Rate, BMI×Duration, Height×Duration
5. **GroupBy Z-Score**: Create (feature - mean(feature by Sex)) / std(feature by Sex) for each numerical feature

Expected improvement: 0.003-0.008 CV reduction

### Priority 3: Model Diversity for Ensemble
Create complementary models with different approaches:
1. **LightGBM**: Histogram-based GBDT with different feature subsets
2. **Neural Network**: MLP with 2-3 hidden layers (256-128-64), dropout, early stopping
3. **Linear Regression**: Ridge regression with extensive feature engineering (200+ features)
4. **Random Forest**: Different random seeds and max_depth parameters
5. **XGBoost variants**: Different colsample_bytree, subsample parameters

Expected improvement: Enable effective ensembling

### Priority 4: Sophisticated Ensemble Methods
Move beyond simple averaging to proven techniques:
1. **Weighted Averaging**: Weight by 1/CV_score or use Hill Climbing optimization
2. **Ridge Stacking**: Train Ridge regression on OOF predictions as features
3. **Hill Climbing**: Iteratively add models that improve ensemble CV (allow negative weights)
4. **Residual Stacking**: Train models on residuals of previous models (LR → NN → XGB)
5. **Create OOF predictions**: Save OOF and test predictions for all models

Expected improvement: 0.002-0.005 CV reduction over best single model

### Priority 5: Validation and Submission Strategy
1. **First Submission**: Submit best CatBoost model (exp_002) to get LB feedback
2. **CV-LB Analysis**: Compare CV vs LB to understand correlation
3. **Calibration**: If CV-LB gap is large, investigate distribution shift
4. **Prediction Clipping**: Clip final predictions to [train_min, train_max] range
5. **Multiple Submissions**: Test different ensembles to find best LB performance

## What NOT to Try
- Don't waste time on simple averaging - use weighted/hill climbing instead
- Don't skip target encoding - it's critical for handling categorical features
- Don't use identical models in ensemble - diversity is key
- Don't overfit to CV - monitor LB feedback for calibration
- Don't ignore feature importance - focus engineering on top features

## Validation Notes
- Use 5-fold CV with seed 42 (consistent across experiments)
- Track both mean CV and standard deviation across folds
- Save OOF predictions for all models for ensemble analysis
- Monitor for overfitting (CV improving but validation stability decreasing)
- Trust CV as primary signal, but use LB for final calibration