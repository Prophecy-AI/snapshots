{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c006d595",
   "metadata": {},
   "source": [
    "# Target Encoding + Product Features (Simplified)\n",
    "\n",
    "This notebook implements target encoding with a manual approach to avoid sklearn compatibility issues.\n",
    "\n",
    "**Strategy Priority**: Priority 1 - Fix Critical Gaps\n",
    "\n",
    "**Expected CV**: ~0.05-0.06 range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b26310f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:23:31.470182Z",
     "iopub.status.busy": "2026-01-15T12:23:31.469902Z",
     "iopub.status.idle": "2026-01-15T12:23:32.723068Z",
     "shell.execute_reply": "2026-01-15T12:23:32.722671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train shape: (8000, 9)\n",
      "Test shape: (2000, 9)\n",
      "Columns: ['id', 'Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "# Load the synthetic data from workspace\n",
    "train_df = pd.read_csv('/home/code/data/train.csv')\n",
    "test_df = pd.read_csv('/home/code/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Columns: {list(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe02837",
   "metadata": {},
   "source": [
    "## Manual Target Encoding Function\n",
    "\n",
    "Create a manual target encoder that uses cross-validation to prevent leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5901fd48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:23:32.728797Z",
     "iopub.status.busy": "2026-01-15T12:23:32.728688Z",
     "iopub.status.idle": "2026-01-15T12:23:32.735015Z",
     "shell.execute_reply": "2026-01-15T12:23:32.734692Z"
    }
   },
   "outputs": [],
   "source": [
    "def manual_target_encode(X_train, y_train, X_val, X_test, categorical_feature, smoothing=20):\n",
    "    \"\"\"Manual target encoding with smoothing to prevent overfitting\"\"\"\n",
    "    \n",
    "    # Calculate global mean\n",
    "    global_mean = y_train.mean()\n",
    "    \n",
    "    # Calculate category means on training data\n",
    "    category_counts = X_train[categorical_feature].value_counts()\n",
    "    category_means = y_train.groupby(X_train[categorical_feature]).mean()\n",
    "    \n",
    "    # Apply smoothing\n",
    "    def smooth_encode(values, counts, means, global_mean, smoothing):\n",
    "        # For each value, compute smoothed mean\n",
    "        result = []\n",
    "        for val in values:\n",
    "            if val in counts.index:\n",
    "                count = counts[val]\n",
    "                mean = means[val]\n",
    "                # Smoothing formula: (count * mean + smoothing * global_mean) / (count + smoothing)\n",
    "                smoothed = (count * mean + smoothing * global_mean) / (count + smoothing)\n",
    "                result.append(smoothed)\n",
    "            else:\n",
    "                # Unknown category - use global mean\n",
    "                result.append(global_mean)\n",
    "        return np.array(result)\n",
    "    \n",
    "    # Encode all datasets\n",
    "    train_encoded = smooth_encode(X_train[categorical_feature], category_counts, category_means, global_mean, smoothing)\n",
    "    val_encoded = smooth_encode(X_val[categorical_feature], category_counts, category_means, global_mean, smoothing)\n",
    "    test_encoded = smooth_encode(X_test[categorical_feature], category_counts, category_means, global_mean, smoothing)\n",
    "    \n",
    "    # Add as new feature\n",
    "    X_train_enc = X_train.copy()\n",
    "    X_val_enc = X_val.copy()\n",
    "    X_test_enc = X_test.copy()\n",
    "    \n",
    "    X_train_enc[f'{categorical_feature}_target_enc'] = train_encoded\n",
    "    X_val_enc[f'{categorical_feature}_target_enc'] = val_encoded\n",
    "    X_test_enc[f'{categorical_feature}_target_enc'] = test_encoded\n",
    "    \n",
    "    return X_train_enc, X_val_enc, X_test_enc\n",
    "\n",
    "def create_product_features(df, numerical_features):\n",
    "    \"\"\"Create product features from numerical features\"\"\"\n",
    "    df_feat = df.copy()\n",
    "    \n",
    "    # Create log1p versions\n",
    "    for feature in numerical_features:\n",
    "        df_feat[f'{feature}_log1p'] = np.log1p(df_feat[feature])\n",
    "    \n",
    "    # Create pairwise products (focus on most important combinations)\n",
    "    df_feat['product_Weight_Duration'] = df_feat['Weight'] * df_feat['Duration']\n",
    "    df_feat['product_Duration_Heart_Rate'] = df_feat['Duration'] * df_feat['Heart_Rate']\n",
    "    df_feat['product_Height_Weight'] = df_feat['Height'] * df_feat['Weight']\n",
    "    df_feat['product_Age_Weight'] = df_feat['Age'] * df_feat['Weight']\n",
    "    df_feat['product_Body_Temp_Duration'] = df_feat['Body_Temp'] * df_feat['Duration']\n",
    "    \n",
    "    # Create some ratios\n",
    "    df_feat['ratio_Weight_Height'] = df_feat['Weight'] / (df_feat['Height'] + 1e-6)\n",
    "    df_feat['ratio_Heart_Rate_Duration'] = df_feat['Heart_Rate'] / (df_feat['Duration'] + 1e-6)\n",
    "    \n",
    "    return df_feat\n",
    "\n",
    "def create_binned_features(df, numerical_features, n_bins=15):\n",
    "    \"\"\"Create binned features (to be used inside CV loop)\"\"\"\n",
    "    df_binned = df.copy()\n",
    "    \n",
    "    for feature in numerical_features:\n",
    "        binner = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "        binned_values = binner.fit_transform(df[[feature]])\n",
    "        df_binned[f'{feature}_binned'] = binned_values.astype(int)\n",
    "    \n",
    "    return df_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607600d1",
   "metadata": {},
   "source": [
    "## Cross-Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01761baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Store predictions\n",
    "oof_predictions_xgb = np.zeros(len(train_df))\n",
    "test_predictions_xgb = np.zeros(len(test_df))\n",
    "\n",
    "oof_predictions_cat = np.zeros(len(train_df))\n",
    "test_predictions_cat = np.zeros(len(test_df))\n",
    "\n",
    "cv_scores_xgb = []\n",
    "cv_scores_cat = []\n",
    "\n",
    "print(f\"Starting {n_folds}-fold CV...\")\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numerical_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "categorical_features = ['Sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5343f258",
   "metadata": {},
   "source": [
    "# Model parameters\n",
    "xgb_params = {\n",
    "    'n_estimators': 800,  # Reduced from 1000\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': -1,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 800,  # Reduced from 1000\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': SEED,\n",
    "    'verbose': False,\n",
    "    'allow_writing_files': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in kf.split(train_df):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training fold {fold}/{n_folds}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = train_df.iloc[train_idx].copy(), train_df.iloc[val_idx].copy()\n",
    "    y_train, y_val = X_train['Calories'].copy(), X_val['Calories'].copy()\n",
    "    \n",
    "    # Remove target from features\n",
    "    X_train = X_train.drop('Calories', axis=1)\n",
    "    X_val = X_val.drop('Calories', axis=1)\n",
    "    X_test = test_df.copy()\n",
    "    \n",
    "    # Create product features (log1p + interactions)\n",
    "    X_train = create_product_features(X_train, numerical_features)\n",
    "    X_val = create_product_features(X_val, numerical_features)\n",
    "    X_test = create_product_features(X_test, numerical_features)\n",
    "    \n",
    "    # Create binned features (inside CV loop to prevent leakage)\n",
    "    X_train = create_binned_features(X_train, numerical_features, n_bins=15)\n",
    "    X_val = create_binned_features(X_val, numerical_features, n_bins=15)\n",
    "    X_test = create_binned_features(X_test, numerical_features, n_bins=15)\n",
    "    \n",
    "    # Create target encoding (critical - manual approach)\n",
    "    X_train_enc, X_val_enc, X_test_enc = manual_target_encode(\n",
    "        X_train, y_train, X_val, X_test, 'Sex', smoothing=20\n",
    "    )\n",
    "    \n",
    "    # Define feature columns for each model\n",
    "    # XGBoost: use all features including target encoding\n",
    "    xgb_features = [col for col in X_train_enc.columns if col != 'id']\n",
    "    \n",
    "    # CatBoost: use original categorical + binned features\n",
    "    cat_features = categorical_features + [col for col in X_train_enc.columns if col.endswith('_binned')]\n",
    "    cat_feature_indices = [xgb_features.index(col) for col in cat_features if col in xgb_features]\n",
    "    \n",
    "    print(f\"Total features: {len(xgb_features)}\")\n",
    "    print(f\"CatBoost categorical features: {len(cat_feature_indices)}\")\n",
    "    \n",
    "    # Train XGBoost (XGBoost 2.x doesn't support early_stopping_rounds in fit)\n",
    "    print(\"\\nTraining XGBoost...\")\n",
    "    model_xgb = XGBRegressor(**xgb_params)\n",
    "    model_xgb.fit(X_train_enc[xgb_features], y_train)\n",
    "    \n",
    "    # Predict with XGBoost\n",
    "    val_pred_xgb = model_xgb.predict(X_val_enc[xgb_features])\n",
    "    oof_predictions_xgb[val_idx] = val_pred_xgb\n",
    "    \n",
    "    # Train CatBoost\n",
    "    print(\"\\nTraining CatBoost...\")\n",
    "    train_pool = Pool(X_train_enc[xgb_features], y_train, cat_features=cat_feature_indices)\n",
    "    val_pool = Pool(X_val_enc[xgb_features], y_val, cat_features=cat_feature_indices)\n",
    "    \n",
    "    model_cat = CatBoostRegressor(**cat_params)\n",
    "    model_cat.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    # Predict with CatBoost\n",
    "    val_pred_cat = model_cat.predict(val_pool)\n",
    "    oof_predictions_cat[val_idx] = val_pred_cat\n",
    "    \n",
    "    # Calculate RMSLE for this fold\n",
    "    rmsle_xgb = np.sqrt(mean_squared_log_error(y_val, np.clip(val_pred_xgb, 0, None)))\n",
    "    rmsle_cat = np.sqrt(mean_squared_log_error(y_val, np.clip(val_pred_cat, 0, None)))\n",
    "    \n",
    "    cv_scores_xgb.append(rmsle_xgb)\n",
    "    cv_scores_cat.append(rmsle_cat)\n",
    "    \n",
    "    print(f\"\\nFold {fold} RMSLE - XGBoost: {rmsle_xgb:.6f}, CatBoost: {rmsle_cat:.6f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_pred_xgb = model_xgb.predict(X_test_enc[xgb_features])\n",
    "    test_predictions_xgb += test_pred_xgb / n_folds\n",
    "    \n",
    "    test_pred_cat = model_cat.predict(X_test_enc[xgb_features])\n",
    "    test_predictions_cat += test_pred_cat / n_folds\n",
    "    \n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc743d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "xgb_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': -1,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': SEED,\n",
    "    'verbose': False,\n",
    "    'allow_writing_files': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in kf.split(train_df):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training fold {fold}/{n_folds}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = train_df.iloc[train_idx].copy(), train_df.iloc[val_idx].copy()\n",
    "    y_train, y_val = X_train['Calories'].copy(), X_val['Calories'].copy()\n",
    "    \n",
    "    # Remove target from features\n",
    "    X_train = X_train.drop('Calories', axis=1)\n",
    "    X_val = X_val.drop('Calories', axis=1)\n",
    "    X_test = test_df.copy()\n",
    "    \n",
    "    # Create product features (log1p + interactions)\n",
    "    X_train = create_product_features(X_train, numerical_features)\n",
    "    X_val = create_product_features(X_val, numerical_features)\n",
    "    X_test = create_product_features(X_test, numerical_features)\n",
    "    \n",
    "    # Create binned features (inside CV loop to prevent leakage)\n",
    "    X_train = create_binned_features(X_train, numerical_features, n_bins=15)\n",
    "    X_val = create_binned_features(X_val, numerical_features, n_bins=15)\n",
    "    X_test = create_binned_features(X_test, numerical_features, n_bins=15)\n",
    "    \n",
    "    # Create target encoding (critical - manual approach)\n",
    "    X_train_enc, X_val_enc, X_test_enc = manual_target_encode(\n",
    "        X_train, y_train, X_val, X_test, 'Sex', smoothing=20\n",
    "    )\n",
    "    \n",
    "    # Define feature columns for each model\n",
    "    # XGBoost: use all features including target encoding\n",
    "    xgb_features = [col for col in X_train_enc.columns if col != 'id']\n",
    "    \n",
    "    # CatBoost: use original categorical + binned features\n",
    "    cat_features = categorical_features + [col for col in X_train_enc.columns if col.endswith('_binned')]\n",
    "    cat_feature_indices = [xgb_features.index(col) for col in cat_features if col in xgb_features]\n",
    "    \n",
    "    print(f\"Total features: {len(xgb_features)}\")\n",
    "    print(f\"CatBoost categorical features: {len(cat_feature_indices)}\")\n",
    "    \n",
    "    # Train XGBoost\n",
    "    print(\"\\nTraining XGBoost...\")\n",
    "    model_xgb = XGBRegressor(**xgb_params)\n",
    "    model_xgb.fit(\n",
    "        X_train_enc[xgb_features], y_train,\n",
    "        eval_set=[(X_val_enc[xgb_features], y_val)],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Predict with XGBoost\n",
    "    val_pred_xgb = model_xgb.predict(X_val_enc[xgb_features])\n",
    "    oof_predictions_xgb[val_idx] = val_pred_xgb\n",
    "    \n",
    "    # Train CatBoost\n",
    "    print(\"\\nTraining CatBoost...\")\n",
    "    train_pool = Pool(X_train_enc[xgb_features], y_train, cat_features=cat_feature_indices)\n",
    "    val_pool = Pool(X_val_enc[xgb_features], y_val, cat_features=cat_feature_indices)\n",
    "    \n",
    "    model_cat = CatBoostRegressor(**cat_params)\n",
    "    model_cat.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    # Predict with CatBoost\n",
    "    val_pred_cat = model_cat.predict(val_pool)\n",
    "    oof_predictions_cat[val_idx] = val_pred_cat\n",
    "    \n",
    "    # Calculate RMSLE for this fold\n",
    "    rmsle_xgb = np.sqrt(mean_squared_log_error(y_val, np.clip(val_pred_xgb, 0, None)))\n",
    "    rmsle_cat = np.sqrt(mean_squared_log_error(y_val, np.clip(val_pred_cat, 0, None)))\n",
    "    \n",
    "    cv_scores_xgb.append(rmsle_xgb)\n",
    "    cv_scores_cat.append(rmsle_cat)\n",
    "    \n",
    "    print(f\"\\nFold {fold} RMSLE - XGBoost: {rmsle_xgb:.6f}, CatBoost: {rmsle_cat:.6f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_pred_xgb = model_xgb.predict(X_test_enc[xgb_features])\n",
    "    test_predictions_xgb += test_pred_xgb / n_folds\n",
    "    \n",
    "    test_pred_cat = model_cat.predict(X_test_enc[xgb_features])\n",
    "    test_predictions_cat += test_pred_cat / n_folds\n",
    "    \n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c5ae9",
   "metadata": {},
   "source": [
    "## Results and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10eea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall CV scores\n",
    "mean_rmsle_xgb = np.mean(cv_scores_xgb)\n",
    "std_rmsle_xgb = np.std(cv_scores_xgb)\n",
    "\n",
    "mean_rmsle_cat = np.mean(cv_scores_cat)\n",
    "std_rmsle_cat = np.std(cv_scores_cat)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nXGBoost CV RMSLE: {mean_rmsle_xgb:.6f} ± {std_rmsle_xgb:.6f}\")\n",
    "print(f\"CatBoost CV RMSLE: {mean_rmsle_cat:.6f} ± {std_rmsle_cat:.6f}\")\n",
    "print(f\"\\nIndividual folds:\")\n",
    "for i, (score_xgb, score_cat) in enumerate(zip(cv_scores_xgb, cv_scores_cat)):\n",
    "    print(f\"  Fold {i+1}: XGBoost={score_xgb:.6f}, CatBoost={score_cat:.6f}\")\n",
    "\n",
    "# Compare to baseline\n",
    "print(f\"\\nComparison to baseline:\")\n",
    "print(f\"  Baseline XGBoost: 0.020470\")\n",
    "print(f\"  This XGBoost:     {mean_rmsle_xgb:.6f} ({mean_rmsle_xgb-0.020470:+.6f})\")\n",
    "print(f\"  Baseline CatBoost: 0.202383\")\n",
    "print(f\"  This CatBoost:     {mean_rmsle_cat:.6f} ({mean_rmsle_cat-0.202383:+.6f})\")\n",
    "\n",
    "# Check if we're in target range\n",
    "target_range = (0.055, 0.065)\n",
    "print(f\"\\nTarget range: {target_range}\")\n",
    "print(f\"XGBoost in range: {target_range[0] <= mean_rmsle_xgb <= target_range[1]}\")\n",
    "print(f\"CatBoost in range: {target_range[0] <= mean_rmsle_cat <= target_range[1]}\")\n",
    "\n",
    "# Clip predictions to training data range\n",
    "train_min = train_df['Calories'].min()\n",
    "train_max = train_df['Calories'].max()\n",
    "\n",
    "print(f\"\\nTraining data range: [{train_min:.2f}, {train_max:.2f}]\")\n",
    "\n",
    "# Create submissions\n",
    "submission_xgb = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Calories': np.clip(test_predictions_xgb, train_min, train_max)\n",
    "})\n",
    "\n",
    "submission_cat = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Calories': np.clip(test_predictions_cat, train_min, train_max)\n",
    "})\n",
    "\n",
    "# Save submissions\n",
    "submission_xgb_path = '/home/submission/submission_003_xgb_target_enc.csv'\n",
    "submission_cat_path = '/home/submission/submission_003_cat_target_enc.csv'\n",
    "\n",
    "submission_xgb.to_csv(submission_xgb_path, index=False)\n",
    "submission_cat.to_csv(submission_cat_path, index=False)\n",
    "\n",
    "print(f\"\\nSubmissions saved:\")\n",
    "print(f\"  XGBoost: {submission_xgb_path}\")\n",
    "print(f\"  CatBoost: {submission_cat_path}\")\n",
    "\n",
    "# Save OOF predictions\n",
    "oof_xgb_df = pd.DataFrame({\n",
    "    'id': train_df['id'],\n",
    "    'oof_prediction': oof_predictions_xgb\n",
    "})\n",
    "oof_cat_df = pd.DataFrame({\n",
    "    'id': train_df['id'],\n",
    "    'oof_prediction': oof_predictions_cat\n",
    "})\n",
    "\n",
    "oof_xgb_path = '/home/code/experiments/oof_003_xgb_target_enc.csv'\n",
    "oof_cat_path = '/home/code/experiments/oof_003_cat_target_enc.csv'\n",
    "\n",
    "oof_xgb_df.to_csv(oof_xgb_path, index=False)\n",
    "oof_cat_df.to_csv(oof_cat_path, index=False)\n",
    "\n",
    "print(f\"\\nOOF predictions saved:\")\n",
    "print(f\"  XGBoost: {oof_xgb_path}\")\n",
    "print(f\"  CatBoost: {oof_cat_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
