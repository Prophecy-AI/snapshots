{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f3e373",
   "metadata": {},
   "source": [
    "# Baseline XGBoost Model\n",
    "\n",
    "First baseline model using XGBoost with basic feature engineering.\n",
    "\n",
    "Features to include:\n",
    "- Original numerical features\n",
    "- Log1p transformations\n",
    "- Product features (Weight*Duration, Duration*Heart_Rate, Height*Weight)\n",
    "- Ratio features (Weight/Height)\n",
    "- BMI feature\n",
    "\n",
    "Model: XGBoost with 500 trees, learning_rate=0.05, max_depth=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f965d4cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T14:35:21.770266Z",
     "iopub.status.busy": "2026-01-15T14:35:21.769991Z",
     "iopub.status.idle": "2026-01-15T14:35:21.782734Z",
     "shell.execute_reply": "2026-01-15T14:35:21.782353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features...\n",
      "Original Sex unique values: ['M' 'F']\n",
      "After mapping Sex unique values: [nan]\n",
      "Original Sex unique values: ['M' 'F']\n",
      "After mapping Sex unique values: [nan]\n",
      "Number of features: 18\n",
      "Features: ['Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Age_log1p', 'Height_log1p', 'Weight_log1p', 'Duration_log1p', 'Heart_Rate_log1p', 'Body_Temp_log1p', 'Weight_Duration', 'Duration_Heart_Rate', 'Height_Weight', 'Weight_Height', 'BMI']\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering function\n",
    "def create_features(df):\n",
    "    \"\"\"Create engineered features for the model\"\"\"\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Encode categorical features - values are 'M' and 'F'\n",
    "    if 'Sex' in df_new.columns:\n",
    "        df_new['Sex'] = df_new['Sex'].map({'M': 0, 'F': 1})\n",
    "    \n",
    "    # Original numerical features\n",
    "    num_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "    \n",
    "    # Log1p transformations\n",
    "    for col in num_features:\n",
    "        df_new[f'{col}_log1p'] = np.log1p(df_new[col])\n",
    "    \n",
    "    # Product features (from winning solutions)\n",
    "    df_new['Weight_Duration'] = df_new['Weight'] * df_new['Duration']\n",
    "    df_new['Duration_Heart_Rate'] = df_new['Duration'] * df_new['Heart_Rate']\n",
    "    df_new['Height_Weight'] = df_new['Height'] * df_new['Weight']\n",
    "    \n",
    "    # Ratio features\n",
    "    df_new['Weight_Height'] = df_new['Weight'] / (df_new['Height'] + 1e-6)\n",
    "    \n",
    "    # BMI feature (Body Mass Index approximation)\n",
    "    df_new['BMI'] = df_new['Weight'] / ((df_new['Height'] / 100) ** 2 + 1e-6)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# Create features for train and test\n",
    "print(\"Creating features...\")\n",
    "train_feat = create_features(train_df)\n",
    "test_feat = create_features(test_df)\n",
    "\n",
    "# Define feature columns (exclude id and target)\n",
    "feature_cols = [col for col in train_feat.columns if col not in ['id', 'Calories']]\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d4c5b1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T14:35:21.783925Z",
     "iopub.status.busy": "2026-01-15T14:35:21.783671Z",
     "iopub.status.idle": "2026-01-15T14:35:21.788913Z",
     "shell.execute_reply": "2026-01-15T14:35:21.788575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8000, 18)\n",
      "y shape: (8000,)\n",
      "X_test shape: (2000, 18)\n",
      "\n",
      "Data types:\n",
      "Sex                    float64\n",
      "Age                    float64\n",
      "Height                 float64\n",
      "Weight                 float64\n",
      "Duration               float64\n",
      "Heart_Rate             float64\n",
      "Body_Temp              float64\n",
      "Age_log1p              float64\n",
      "Height_log1p           float64\n",
      "Weight_log1p           float64\n",
      "Duration_log1p         float64\n",
      "Heart_Rate_log1p       float64\n",
      "Body_Temp_log1p        float64\n",
      "Weight_Duration        float64\n",
      "Duration_Heart_Rate    float64\n",
      "Height_Weight          float64\n",
      "Weight_Height          float64\n",
      "BMI                    float64\n",
      "dtype: object\n",
      "\n",
      "Sex unique values in train: [nan]\n",
      "Sex unique values in test: [nan]\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X = train_feat[feature_cols]\n",
    "y = train_feat['Calories']\n",
    "X_test = test_feat[feature_cols]\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(X.dtypes.head(20))\n",
    "print(f\"\\nSex unique values in train: {train_feat['Sex'].unique()}\")\n",
    "print(f\"Sex unique values in test: {test_feat['Sex'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ef2aafc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T14:35:21.789839Z",
     "iopub.status.busy": "2026-01-15T14:35:21.789607Z",
     "iopub.status.idle": "2026-01-15T14:35:21.793328Z",
     "shell.execute_reply": "2026-01-15T14:35:21.793014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8000, 18)\n",
      "y shape: (8000,)\n",
      "X_test shape: (2000, 18)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X = train_feat[feature_cols]\n",
    "y = train_feat['Calories']\n",
    "X_test = test_feat[feature_cols]\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e2b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "fold_scores = []\n",
    "\n",
    "print(\"Starting cross-validation...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Create DMatrix objects\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    # Define model parameters\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 6,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'seed': SEED\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=500,\n",
    "        evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_pred = model.predict(dval)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Calculate RMSLE for this fold\n",
    "    # Clip predictions to avoid negative values in log\n",
    "    val_pred_clipped = np.clip(val_pred, 0, None)\n",
    "    fold_score = np.sqrt(mean_squared_log_error(y_val, val_pred_clipped))\n",
    "    fold_scores.append(fold_score)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} RMSLE: {fold_score:.6f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    test_pred = model.predict(dtest)\n",
    "    test_predictions += test_pred / 5  # Average across folds\n",
    "\n",
    "# Calculate overall CV score\n",
    "oof_predictions_clipped = np.clip(oof_predictions, 0, None)\n",
    "cv_score = np.sqrt(mean_squared_log_error(y, oof_predictions_clipped))\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Cross-validation RMSLE: {cv_score:.6f}\")\n",
    "print(f\"Fold scores: {fold_scores}\")\n",
    "print(f\"Mean ± Std: {np.mean(fold_scores):.6f} ± {np.std(fold_scores):.6f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348a2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Calories': test_predictions\n",
    "})\n",
    "\n",
    "# Clip predictions to training data range to prevent unrealistic values\n",
    "train_min = train_df['Calories'].min()\n",
    "train_max = train_df['Calories'].max()\n",
    "submission['Calories'] = submission['Calories'].clip(train_min, train_max)\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"Calories range in submission: [{submission['Calories'].min():.2f}, {submission['Calories'].max():.2f}]\")\n",
    "print(f\"Calories range in training: [{train_min:.2f}, {train_max:.2f}]\")\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/code/submission_candidates/candidate_001_baseline_xgboost.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "\n",
    "# Save OOF predictions for ensemble\n",
    "oof_df = pd.DataFrame({\n",
    "    'id': train_df['id'],\n",
    "    'Calories': oof_predictions\n",
    "})\n",
    "oof_path = '/home/code/experiments/oof_001_baseline_xgboost.csv'\n",
    "oof_df.to_csv(oof_path, index=False)\n",
    "print(f\"OOF predictions saved to: {oof_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
