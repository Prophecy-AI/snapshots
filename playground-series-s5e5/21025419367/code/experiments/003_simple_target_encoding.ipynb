{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c98fe62e",
   "metadata": {},
   "source": [
    "# Simple Target Encoding Implementation\n",
    "\n",
    "Clean implementation avoiding dtype issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639be61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv('/home/code/data/train.csv')\n",
    "test_df = pd.read_csv('/home/code/data/test.csv')\n",
    "\n",
    "print(f\"Train: {train_df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_encoding(X_train, y_train, X_val, X_test, col='Sex', smoothing=20):\n",
    "    \"\"\"Simple target encoding with smoothing\"\"\"\n",
    "    # Global mean\n",
    "    global_mean = y_train.mean()\n",
    "    \n",
    "    # Category stats from training data\n",
    "    stats = y_train.groupby(X_train[col]).agg(['count', 'mean'])\n",
    "    stats.columns = ['count', 'mean']\n",
    "    \n",
    "    # Smoothing function\n",
    "    def encode(series):\n",
    "        result = []\n",
    "        for val in series:\n",
    "            if val in stats.index:\n",
    "                count = stats.loc[val, 'count']\n",
    "                mean = stats.loc[val, 'mean']\n",
    "                # Apply smoothing\n",
    "                smoothed = (count * mean + smoothing * global_mean) / (count + smoothing)\n",
    "                result.append(smoothed)\n",
    "            else:\n",
    "                result.append(global_mean)\n",
    "        return np.array(result)\n",
    "    \n",
    "    # Apply encoding\n",
    "    X_train_enc = X_train.copy()\n",
    "    X_val_enc = X_val.copy()\n",
    "    X_test_enc = X_test.copy()\n",
    "    \n",
    "    X_train_enc[f'{col}_target_enc'] = encode(X_train[col])\n",
    "    X_val_enc[f'{col}_target_enc'] = encode(X_val[col])\n",
    "    X_test_enc[f'{col}_target_enc'] = encode(X_test[col])\n",
    "    \n",
    "    return X_train_enc, X_val_enc, X_test_enc\n",
    "\n",
    "def add_features(df, num_cols):\n",
    "    \"\"\"Add engineered features\"\"\"\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Log transforms\n",
    "    for col in num_cols:\n",
    "        df_new[f'{col}_log1p'] = np.log1p(df_new[col])\n",
    "    \n",
    "    # Products\n",
    "    df_new['Weight_Duration'] = df_new['Weight'] * df_new['Duration']\n",
    "    df_new['Duration_Heart_Rate'] = df_new['Duration'] * df_new['Heart_Rate']\n",
    "    df_new['Height_Weight'] = df_new['Height'] * df_new['Weight']\n",
    "    \n",
    "    # Ratios\n",
    "    df_new['Weight_Height'] = df_new['Weight'] / (df_new['Height'] + 1e-6)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "def add_binned_features(df, num_cols, n_bins=15):\n",
    "    \"\"\"Add binned features\"\"\"\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    for col in num_cols:\n",
    "        binner = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "        binned = binner.fit_transform(df_new[[col]])\n",
    "        df_new[f'{col}_binned'] = binned.astype(int)\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "oof_xgb = np.zeros(len(train_df))\n",
    "test_xgb = np.zeros(len(test_df))\n",
    "\n",
    "oof_cat = np.zeros(len(train_df))\n",
    "test_cat = np.zeros(len(test_df))\n",
    "\n",
    "scores_xgb = []\n",
    "scores_cat = []\n",
    "\n",
    "num_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "\n",
    "print(\"Starting CV...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68952103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "xgb_params = {\n",
    "    'n_estimators': 800,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': -1,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 800,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': SEED,\n",
    "    'verbose': False,\n",
    "    'allow_writing_files': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in kf.split(train_df):\n",
    "    print(f\"\\nFold {fold}/{n_folds}\")\n",
    "    \n",
    "    # Split\n",
    "    X_tr, X_va = train_df.iloc[train_idx].copy(), train_df.iloc[val_idx].copy()\n",
    "    y_tr, y_va = X_tr['Calories'].values, X_va['Calories'].values\n",
    "    \n",
    "    X_tr = X_tr.drop('Calories', axis=1)\n",
    "    X_va = X_va.drop('Calories', axis=1)\n",
    "    X_te = test_df.copy()\n",
    "    \n",
    "    # Add features\n",
    "    X_tr = add_features(X_tr, num_features)\n",
    "    X_va = add_features(X_va, num_features)\n",
    "    X_te = add_features(X_te, num_features)\n",
    "    \n",
    "    # Add binned features\n",
    "    X_tr = add_binned_features(X_tr, num_features)\n",
    "    X_va = add_binned_features(X_va, num_features)\n",
    "    X_te = add_binned_features(X_te, num_features)\n",
    "    \n",
    "    # Target encoding\n",
    "    X_tr_enc, X_va_enc, X_te_enc = get_target_encoding(X_tr, y_tr, X_va, X_te)\n",
    "    \n",
    "    # Prepare features - drop original Sex, keep target encoding\n",
    "    features = [c for c in X_tr_enc.columns if c != 'id' and c != 'Sex']\n",
    "    \n",
    "    # XGBoost data (ensure all numeric)\n",
    "    X_tr_xgb = X_tr_enc[features].astype(float)\n",
    "    X_va_xgb = X_va_enc[features].astype(float)\n",
    "    X_te_xgb = X_te_enc[features].astype(float)\n",
    "    \n",
    "    # CatBoost categorical features (binned features)\n",
    "    cat_features = [c for c in features if c.endswith('_binned')]\n",
    "    cat_indices = [features.index(c) for c in cat_features]\n",
    "    \n",
    "    print(f\"Features: {len(features)}, Cat features: {len(cat_features)}\")\n",
    "    \n",
    "    # Train XGBoost\n",
    "    model_xgb = XGBRegressor(**xgb_params)\n",
    "    model_xgb.fit(X_tr_xgb, y_tr)\n",
    "    \n",
    "    pred_va_xgb = model_xgb.predict(X_va_xgb)\n",
    "    oof_xgb[val_idx] = pred_va_xgb\n",
    "    \n",
    "    # Train CatBoost\n",
    "    train_pool = Pool(X_tr_enc[features], y_tr, cat_features=cat_indices)\n",
    "    val_pool = Pool(X_va_enc[features], y_va, cat_features=cat_indices)\n",
    "    \n",
    "    model_cat = CatBoostRegressor(**cat_params)\n",
    "    model_cat.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    pred_va_cat = model_cat.predict(val_pool)\n",
    "    oof_cat[val_idx] = pred_va_cat\n",
    "    \n",
    "    # Scores\n",
    "    score_xgb = np.sqrt(mean_squared_log_error(y_va, np.clip(pred_va_xgb, 0, None)))\n",
    "    score_cat = np.sqrt(mean_squared_log_error(y_va, np.clip(pred_va_cat, 0, None)))\n",
    "    \n",
    "    scores_xgb.append(score_xgb)\n",
    "    scores_cat.append(score_cat)\n",
    "    \n",
    "    print(f\"RMSLE - XGBoost: {score_xgb:.6f}, CatBoost: {score_cat:.6f}\")\n",
    "    \n",
    "    # Test predictions\n",
    "    test_xgb += model_xgb.predict(X_te_xgb) / n_folds\n",
    "    test_cat += model_cat.predict(X_te_enc[features]) / n_folds\n",
    "    \n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec563339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "mean_xgb = np.mean(scores_xgb)\n",
    "std_xgb = np.std(scores_xgb)\n",
    "\n",
    "mean_cat = np.mean(scores_cat)\n",
    "std_cat = np.std(scores_cat)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"XGBoost: {mean_xgb:.6f} ± {std_xgb:.6f}\")\n",
    "print(f\"CatBoost: {mean_cat:.6f} ± {std_cat:.6f}\")\n",
    "print(f\"\\nIndividual folds: {scores_xgb}\")\n",
    "print(f\"Individual folds: {scores_cat}\")\n",
    "\n",
    "# Compare to baseline\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Baseline XGBoost: 0.020470\")\n",
    "print(f\"  This XGBoost:     {mean_xgb:.6f} ({mean_xgb-0.020470:+.6f})\")\n",
    "print(f\"  Baseline CatBoost: 0.202383\")\n",
    "print(f\"  This CatBoost:     {mean_cat:.6f} ({mean_cat-0.202383:+.6f})\")\n",
    "\n",
    "# Target range\n",
    "target = (0.055, 0.065)\n",
    "print(f\"\\nTarget range: {target}\")\n",
    "print(f\"XGBoost in range: {target[0] <= mean_xgb <= target[1]}\")\n",
    "print(f\"CatBoost in range: {target[0] <= mean_cat <= target[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submissions\n",
    "train_min = train_df['Calories'].min()\n",
    "train_max = train_df['Calories'].max()\n",
    "\n",
    "# XGBoost submission\n",
    "sub_xgb = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Calories': np.clip(test_xgb, train_min, train_max)\n",
    "})\n",
    "sub_xgb.to_csv('/home/submission/submission_003_xgb_simple.csv', index=False)\n",
    "\n",
    "# CatBoost submission\n",
    "sub_cat = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Calories': np.clip(test_cat, train_min, train_max)\n",
    "})\n",
    "sub_cat.to_csv('/home/submission/submission_003_cat_simple.csv', index=False)\n",
    "\n",
    "print(\"Submissions saved:\")\n",
    "print(\"  /home/submission/submission_003_xgb_simple.csv\")\n",
    "print(\"  /home/submission/submission_003_cat_simple.csv\")\n",
    "\n",
    "# Save OOF predictions\n",
    "pd.DataFrame({\n",
    "    'id': train_df['id'],\n",
    "    'oof_prediction': oof_xgb\n",
    "}).to_csv('/home/code/experiments/oof_003_xgb_simple.csv', index=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'id': train_df['id'],\n",
    "    'oof_prediction': oof_cat\n",
    "}).to_csv('/home/code/experiments/oof_003_cat_simple.csv', index=False)\n",
    "\n",
    "print(\"\\nOOF predictions saved:\")\n",
    "print(\"  /home/code/experiments/oof_003_xgb_simple.csv\")\n",
    "print(\"  /home/code/experiments/oof_003_cat_simple.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
