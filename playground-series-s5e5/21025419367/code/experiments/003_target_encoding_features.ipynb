{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8b0916",
   "metadata": {},
   "source": [
    "# Target Encoding + Product Features Experiment\n",
    "\n",
    "This notebook implements the evaluator's top priority: target encoding with proper cross-validation.\n",
    "\n",
    "**Strategy Priority**: Priority 1 - Fix Critical Gaps\n",
    "\n",
    "**Expected CV**: ~0.05-0.06 range\n",
    "\n",
    "**Key Improvements**:\n",
    "1. Target encoding for 'Sex' feature (sklearn's TargetEncoder with cv=5)\n",
    "2. Product features (log1p + pairwise interactions)\n",
    "3. Fix data leakage by moving binning inside CV loop\n",
    "4. Apply to both XGBoost and CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1dec2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:12:32.622046Z",
     "iopub.status.busy": "2026-01-15T12:12:32.621819Z",
     "iopub.status.idle": "2026-01-15T12:12:33.828512Z",
     "shell.execute_reply": "2026-01-15T12:12:33.823171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train shape: (8000, 9)\n",
      "Test shape: (2000, 9)\n",
      "Columns: ['id', 'Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "# Load the synthetic data from workspace\n",
    "train_df = pd.read_csv('/home/code/data/train.csv')\n",
    "test_df = pd.read_csv('/home/code/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Columns: {list(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360b4e8",
   "metadata": {},
   "source": [
    "def create_product_features(df, numerical_features):\n",
    "    \"\"\"Create product features from numerical features\"\"\"\n",
    "    df_feat = df.copy()\n",
    "    \n",
    "    # Create log1p versions\n",
    "    for feature in numerical_features:\n",
    "        df_feat[f'{feature}_log1p'] = np.log1p(df_feat[feature])\n",
    "    \n",
    "    # Create pairwise products (focus on most important combinations)\n",
    "    # Based on winner insights: Weight*Duration, Duration*Heart_Rate, Height*Weight\n",
    "    df_feat['product_Weight_Duration'] = df_feat['Weight'] * df_feat['Duration']\n",
    "    df_feat['product_Duration_Heart_Rate'] = df_feat['Duration'] * df_feat['Heart_Rate']\n",
    "    df_feat['product_Height_Weight'] = df_feat['Height'] * df_feat['Weight']\n",
    "    df_feat['product_Age_Weight'] = df_feat['Age'] * df_feat['Weight']\n",
    "    df_feat['product_Body_Temp_Duration'] = df_feat['Body_Temp'] * df_feat['Duration']\n",
    "    \n",
    "    # Create some ratios\n",
    "    df_feat['ratio_Weight_Height'] = df_feat['Weight'] / (df_feat['Height'] + 1e-6)\n",
    "    df_feat['ratio_Heart_Rate_Duration'] = df_feat['Heart_Rate'] / (df_feat['Duration'] + 1e-6)\n",
    "    \n",
    "    return df_feat\n",
    "\n",
    "def create_binned_features(df, numerical_features, n_bins=15):\n",
    "    \"\"\"Create binned features (to be used inside CV loop)\"\"\"\n",
    "    df_binned = df.copy()\n",
    "    \n",
    "    for feature in numerical_features:\n",
    "        binner = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "        binned_values = binner.fit_transform(df[[feature]])\n",
    "        df_binned[f'{feature}_binned'] = binned_values.astype(int)\n",
    "    \n",
    "    return df_binned\n",
    "\n",
    "def create_target_encoding(X_train, y_train, X_val, X_test, categorical_features, cv=5):\n",
    "    \"\"\"Create target-encoded features using cross-validation\"\"\"\n",
    "    \n",
    "    X_train_enc = X_train.copy()\n",
    "    X_val_enc = X_val.copy()\n",
    "    X_test_enc = X_test.copy()\n",
    "    \n",
    "    # Initialize TargetEncoder with internal cross-fitting\n",
    "    encoder = TargetEncoder(cv=cv, smooth='auto', random_state=SEED)\n",
    "    \n",
    "    for feature in categorical_features:\n",
    "        # Fit on training data\n",
    "        encoder.fit(X_train[[feature]], y_train)\n",
    "        \n",
    "        # Transform all datasets - convert to 1D arrays\n",
    "        train_encoded = encoder.transform(X_train[[feature]])\n",
    "        val_encoded = encoder.transform(X_val[[feature]])\n",
    "        test_encoded = encoder.transform(X_test[[feature]])\n",
    "        \n",
    "        # Add as new features\n",
    "        X_train_enc[f'{feature}_target_enc'] = train_encoded\n",
    "        X_val_enc[f'{feature}_target_enc'] = val_encoded\n",
    "        X_test_enc[f'{feature}_target_enc'] = test_encoded\n",
    "    \n",
    "    return X_train_enc, X_val_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4fcb4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:12:33.834089Z",
     "iopub.status.busy": "2026-01-15T12:12:33.833973Z",
     "iopub.status.idle": "2026-01-15T12:12:33.848500Z",
     "shell.execute_reply": "2026-01-15T12:12:33.848164Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_product_features(df, numerical_features):\n",
    "    \"\"\"Create product features from numerical features\"\"\"\n",
    "    df_feat = df.copy()\n",
    "    \n",
    "    # Create log1p versions\n",
    "    for feature in numerical_features:\n",
    "        df_feat[f'{feature}_log1p'] = np.log1p(df_feat[feature])\n",
    "    \n",
    "    # Create pairwise products (focus on most important combinations)\n",
    "    # Based on winner insights: Weight*Duration, Duration*Heart_Rate, Height*Weight\n",
    "    df_feat['product_Weight_Duration'] = df_feat['Weight'] * df_feat['Duration']\n",
    "    df_feat['product_Duration_Heart_Rate'] = df_feat['Duration'] * df_feat['Heart_Rate']\n",
    "    df_feat['product_Height_Weight'] = df_feat['Height'] * df_feat['Weight']\n",
    "    df_feat['product_Age_Weight'] = df_feat['Age'] * df_feat['Weight']\n",
    "    df_feat['product_Body_Temp_Duration'] = df_feat['Body_Temp'] * df_feat['Duration']\n",
    "    \n",
    "    # Create some ratios\n",
    "    df_feat['ratio_Weight_Height'] = df_feat['Weight'] / (df_feat['Height'] + 1e-6)\n",
    "    df_feat['ratio_Heart_Rate_Duration'] = df_feat['Heart_Rate'] / (df_feat['Duration'] + 1e-6)\n",
    "    \n",
    "    return df_feat\n",
    "\n",
    "def create_binned_features(df, numerical_features, n_bins=15):\n",
    "    \"\"\"Create binned features (to be used inside CV loop)\"\"\"\n",
    "    df_binned = df.copy()\n",
    "    \n",
    "    for feature in numerical_features:\n",
    "        binner = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "        binned_values = binner.fit_transform(df[[feature]])\n",
    "        df_binned[f'{feature}_binned'] = binned_values.astype(int)\n",
    "    \n",
    "    return df_binned\n",
    "\n",
    "def create_target_encoding(X_train, y_train, X_val, X_test, categorical_features, cv=5):\n",
    "    \"\"\"Create target-encoded features using cross-validation\"\"\"\n",
    "    \n",
    "    X_train_enc = X_train.copy()\n",
    "    X_val_enc = X_val.copy()\n",
    "    X_test_enc = X_test.copy()\n",
    "    \n",
    "    # Initialize TargetEncoder with internal cross-fitting\n",
    "    encoder = TargetEncoder(cv=cv, smooth='auto', random_state=SEED)\n",
    "    \n",
    "    for feature in categorical_features:\n",
    "        # Fit on training data\n",
    "        encoder.fit(X_train[[feature]], y_train)\n",
    "        \n",
    "        # Transform all datasets\n",
    "        X_train_enc[f'{feature}_target_enc'] = encoder.transform(X_train[[feature]]).values.ravel()\n",
    "        X_val_enc[f'{feature}_target_enc'] = encoder.transform(X_val[[feature]]).values.ravel()\n",
    "        X_test_enc[f'{feature}_target_enc'] = encoder.transform(X_test[[feature]]).values.ravel()\n",
    "    \n",
    "    return X_train_enc, X_val_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df8ebc5",
   "metadata": {},
   "source": [
    "## Prepare Cross-Validation\n",
    "\n",
    "Use 5-fold CV with seed 42 as specified in the strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89313164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Store predictions\n",
    "oof_predictions_xgb = np.zeros(len(train_df))\n",
    "test_predictions_xgb = np.zeros(len(test_df))\n",
    "\n",
    "oof_predictions_cat = np.zeros(len(train_df))\n",
    "test_predictions_cat = np.zeros(len(test_df))\n",
    "\n",
    "cv_scores_xgb = []\n",
    "cv_scores_cat = []\n",
    "\n",
    "print(f\"Starting {n_folds}-fold CV...\")\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numerical_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "categorical_features = ['Sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65143041",
   "metadata": {},
   "source": [
    "## Train Models with Advanced Features\n",
    "\n",
    "Train both XGBoost and CatBoost with target encoding and product features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# Model parameters\n",
    "xgb_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': -1,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': SEED,\n",
    "    'verbose': False,\n",
    "    'allow_writing_files': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in kf.split(train_df):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training fold {fold}/{n_folds}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = train_df.iloc[train_idx], train_df.iloc[val_idx]\n",
    "    y_train, y_val = X_train['Calories'].copy(), X_val['Calories'].copy()\n",
    "    \n",
    "    # Remove target from features\n",
    "    X_train = X_train.drop('Calories', axis=1)\n",
    "    X_val = X_val.drop('Calories', axis=1)\n",
    "    \n",
    "    # Create product features (log1p + interactions)\n",
    "    X_train = create_product_features(X_train, numerical_features)\n",
    "    X_val = create_product_features(X_val, numerical_features)\n",
    "    X_test_feat = create_product_features(test_df.copy(), numerical_features)\n",
    "    \n",
    "    # Create binned features (inside CV loop to prevent leakage)\n",
    "    X_train = create_binned_features(X_train, numerical_features, n_bins=15)\n",
    "    X_val = create_binned_features(X_val, numerical_features, n_bins=15)\n",
    "    X_test_feat = create_binned_features(X_test_feat, numerical_features, n_bins=15)\n",
    "    \n",
    "    # Create target encoding (critical - uses internal CV)\n",
    "    X_train_enc, X_val_enc, X_test_enc = create_target_encoding(\n",
    "        X_train, y_train, X_val, X_test_feat, categorical_features, cv=5\n",
    "    )\n",
    "    \n",
    "    # Define feature columns for each model\n",
    "    # XGBoost: use all features including target encoding\n",
    "    xgb_features = [col for col in X_train_enc.columns if col != 'id']\n",
    "    \n",
    "    # CatBoost: use original categorical + binned features\n",
    "    cat_features = categorical_features + [col for col in X_train_enc.columns if col.endswith('_binned')]\n",
    "    cat_feature_indices = [xgb_features.index(col) for col in cat_features if col in xgb_features]\n",
    "    \n",
    "    print(f\"Total features: {len(xgb_features)}\")\n",
    "    print(f\"CatBoost categorical features: {len(cat_feature_indices)}\")\n",
    "    \n",
    "    # Train XGBoost\n",
    "    print(\"\\nTraining XGBoost...\")\n",
    "    model_xgb = XGBRegressor(**xgb_params)\n",
    "    model_xgb.fit(\n",
    "        X_train_enc[xgb_features], y_train,\n",
    "        eval_set=[(X_val_enc[xgb_features], y_val)],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Predict with XGBoost\n",
    "    val_pred_xgb = model_xgb.predict(X_val_enc[xgb_features])\n",
    "    oof_predictions_xgb[val_idx] = val_pred_xgb\n",
    "    \n",
    "    # Train CatBoost\n",
    "    print(\"\\nTraining CatBoost...\")\n",
    "    train_pool = Pool(X_train_enc[xgb_features], y_train, cat_features=cat_feature_indices)\n",
    "    val_pool = Pool(X_val_enc[xgb_features], y_val, cat_features=cat_feature_indices)\n",
    "    \n",
    "    model_cat = CatBoostRegressor(**cat_params)\n",
    "    model_cat.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    # Predict with CatBoost\n",
    "    val_pred_cat = model_cat.predict(val_pool)\n",
    "    oof_predictions_cat[val_idx] = val_pred_cat\n",
    "    \n",
    "    # Calculate RMSLE for this fold\n",
    "    rmsle_xgb = np.sqrt(mean_squared_log_error(y_val, np.clip(val_pred_xgb, 0, None)))\n",
    "    rmsle_cat = np.sqrt(mean_squared_log_error(y_val, np.clip(val_pred_cat, 0, None)))\n",
    "    \n",
    "    cv_scores_xgb.append(rmsle_xgb)\n",
    "    cv_scores_cat.append(rmsle_cat)\n",
    "    \n",
    "    print(f\"\\nFold {fold} RMSLE - XGBoost: {rmsle_xgb:.6f}, CatBoost: {rmsle_cat:.6f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_pred_xgb = model_xgb.predict(X_test_enc[xgb_features])\n",
    "    test_predictions_xgb += test_pred_xgb / n_folds\n",
    "    \n",
    "    test_pred_cat = model_cat.predict(X_test_enc[xgb_features])\n",
    "    test_predictions_cat += test_pred_cat / n_folds\n",
    "    \n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceef1d2",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5380b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall CV scores\n",
    "mean_rmsle_xgb = np.mean(cv_scores_xgb)\n",
    "std_rmsle_xgb = np.std(cv_scores_xgb)\n",
    "\n",
    "mean_rmsle_cat = np.mean(cv_scores_cat)\n",
    "std_rmsle_cat = np.std(cv_scores_cat)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nXGBoost CV RMSLE: {mean_rmsle_xgb:.6f} ± {std_rmsle_xgb:.6f}\")\n",
    "print(f\"CatBoost CV RMSLE: {mean_rmsle_cat:.6f} ± {std_rmsle_cat:.6f}\")\n",
    "print(f\"\\nIndividual folds:\")\n",
    "for i, (score_xgb, score_cat) in enumerate(zip(cv_scores_xgb, cv_scores_cat)):\n",
    "    print(f\"  Fold {i+1}: XGBoost={score_xgb:.6f}, CatBoost={score_cat:.6f}\")\n",
    "\n",
    "# Compare to baseline\n",
    "print(f\"\\nComparison to baseline:\")\n",
    "print(f\"  Baseline XGBoost: 0.020470\")\n",
    "print(f\"  This XGBoost:     {mean_rmsle_xgb:.6f} ({mean_rmsle_xgb-0.020470:+.6f})\")\n",
    "print(f\"  Baseline CatBoost: 0.202383\")\n",
    "print(f\"  This CatBoost:     {mean_rmsle_cat:.6f} ({mean_rmsle_cat-0.202383:+.6f})\")\n",
    "\n",
    "# Check if we're in target range\n",
    "target_range = (0.055, 0.065)\n",
    "print(f\"\\nTarget range: {target_range}\")\n",
    "print(f\"XGBoost in range: {target_range[0] <= mean_rmsle_xgb <= target_range[1]}\")\n",
    "print(f\"CatBoost in range: {target_range[0] <= mean_rmsle_cat <= target_range[1]}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
