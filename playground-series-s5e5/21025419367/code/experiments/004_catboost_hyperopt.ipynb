{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1a9ccd",
   "metadata": {},
   "source": [
    "# CatBoost Hyperparameter Optimization\n",
    "\n",
    "Optimize CatBoost hyperparameters to improve CV score.\n",
    "\n",
    "Parameters to test:\n",
    "- Learning rates: [0.01, 0.03, 0.05, 0.1] with proportional iterations\n",
    "- Depths: [4, 5, 6, 7, 8]\n",
    "- Regularization: reg_lambda values [1, 3, 5, 10]\n",
    "- Early stopping rounds: [30, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv('/home/code/data/train.csv')\n",
    "test_df = pd.read_csv('/home/code/data/test.csv')\n",
    "\n",
    "print(f\"Train: {train_df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Create engineered features for the model\"\"\"\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Original numerical features\n",
    "    num_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "    \n",
    "    # Log1p transformations\n",
    "    for col in num_features:\n",
    "        df_new[f'{col}_log1p'] = np.log1p(df_new[col])\n",
    "    \n",
    "    # Product features (from winning solutions)\n",
    "    df_new['Weight_Duration'] = df_new['Weight'] * df_new['Duration']\n",
    "    df_new['Duration_Heart_Rate'] = df_new['Duration'] * df_new['Heart_Rate']\n",
    "    df_new['Height_Weight'] = df_new['Height'] * df_new['Weight']\n",
    "    \n",
    "    # Ratio features\n",
    "    df_new['Weight_Height'] = df_new['Weight'] / (df_new['Height'] + 1e-6)\n",
    "    \n",
    "    # BMI feature (Body Mass Index approximation)\n",
    "    df_new['BMI'] = df_new['Weight'] / ((df_new['Height'] / 100) ** 2 + 1e-6)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# Create features\n",
    "train_feat = create_features(train_df)\n",
    "test_feat = create_features(test_df)\n",
    "\n",
    "# Define feature columns\n",
    "feature_cols = [col for col in train_feat.columns if col not in ['id', 'Calories']]\n",
    "cat_features = ['Sex'] if 'Sex' in feature_cols else []\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Categorical: {cat_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f48eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = train_feat[feature_cols]\n",
    "y = train_feat['Calories']\n",
    "X_test = test_feat[feature_cols]\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}, X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost(params, X_train, y_train, X_val, y_val, cat_features):\n",
    "    \"\"\"Train CatBoost model and return validation score\"\"\"\n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=cat_features)\n",
    "    \n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    pred_val = model.predict(val_pool)\n",
    "    score = np.sqrt(mean_squared_log_error(y_val, np.clip(pred_val, 0, None)))\n",
    "    \n",
    "    return score, model.best_iteration_\n",
    "\n",
    "# Test configurations\n",
    "configs = [\n",
    "    # Learning rate sweep (adjust iterations proportionally)\n",
    "    {'name': 'lr_0.01', 'learning_rate': 0.01, 'iterations': 2500, 'depth': 6},\n",
    "    {'name': 'lr_0.03', 'learning_rate': 0.03, 'iterations': 1500, 'depth': 6},\n",
    "    {'name': 'lr_0.05', 'learning_rate': 0.05, 'iterations': 1000, 'depth': 6},  # baseline\n",
    "    {'name': 'lr_0.1', 'learning_rate': 0.1, 'iterations': 500, 'depth': 6},\n",
    "    \n",
    "    # Depth exploration\n",
    "    {'name': 'depth_4', 'learning_rate': 0.05, 'iterations': 1000, 'depth': 4},\n",
    "    {'name': 'depth_5', 'learning_rate': 0.05, 'iterations': 1000, 'depth': 5},\n",
    "    {'name': 'depth_7', 'learning_rate': 0.05, 'iterations': 1000, 'depth': 7},\n",
    "    {'name': 'depth_8', 'learning_rate': 0.05, 'iterations': 1000, 'depth': 8},\n",
    "]\n",
    "\n",
    "base_params = {\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': SEED,\n",
    "    'verbose': False,\n",
    "    'allow_writing_files': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "\n",
    "print(\"Testing configurations...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"\\nTesting: {config['name']}\")\n",
    "    print(f\"  lr={config['learning_rate']}, depth={config['depth']}, iter={config['iterations']}\")\n",
    "    \n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "        X_tr, X_va = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_va = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        params = {**base_params, **config}\n",
    "        score, best_iter = train_catboost(params, X_tr, y_tr, X_va, y_va, cat_features)\n",
    "        fold_scores.append(score)\n",
    "        \n",
    "        print(f\"  Fold {fold}: {score:.6f} (best_iter: {best_iter})\")\n",
    "    \n",
    "    mean_score = np.mean(fold_scores)\n",
    "    std_score = np.std(fold_scores)\n",
    "    \n",
    "    results.append({\n",
    "        'name': config['name'],\n",
    "        'learning_rate': config['learning_rate'],\n",
    "        'depth': config['depth'],\n",
    "        'iterations': config['iterations'],\n",
    "        'mean_score': mean_score,\n",
    "        'std_score': std_score,\n",
    "        'fold_scores': fold_scores\n",
    "    })\n",
    "    \n",
    "    print(f\"  Mean: {mean_score:.6f} ± {std_score:.6f}\")\n",
    "    print(f\"  Folds: {fold_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPERPARAMETER OPTIMIZATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('mean_score')\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    print(f\"{row['name']:15s} | lr={row['learning_rate']:.2f} | depth={row['depth']} | \"\n",
    "          f\"score={row['mean_score']:.6f} ± {row['std_score']:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Best configuration:\")\n",
    "best = results_df.iloc[0]\n",
    "print(f\"{best['name']} - Score: {best['mean_score']:.6f} ± {best['std_score']:.6f}\")\n",
    "print(f\"Parameters: lr={best['learning_rate']}, depth={best['depth']}, iter={best['iterations']}\")\n",
    "\n",
    "# Compare to baseline\n",
    "baseline_score = 0.202383\n",
    "print(f\"\\nBaseline score: {baseline_score:.6f}\")\n",
    "print(f\"Improvement: {best['mean_score'] - baseline_score:+.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0f89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best parameters and generate predictions\n",
    "best_config = {\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'depth': best['depth'],\n",
    "    'iterations': best['iterations'],\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': SEED,\n",
    "    'verbose': False,\n",
    "    'allow_writing_files': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "\n",
    "print(f\"Training final model with best parameters: {best['name']}\")\n",
    "print(f\"Parameters: {best_config}\")\n",
    "\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "test_predictions = np.zeros(len(test_df))\n",
    "fold_scores = []\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    print(f\"\\nFold {fold}/5\")\n",
    "    \n",
    "    X_tr, X_va = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_tr, y_va = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    train_pool = Pool(X_tr, y_tr, cat_features=cat_features)\n",
    "    val_pool = Pool(X_va, y_va, cat_features=cat_features)\n",
    "    \n",
    "    model = CatBoostRegressor(**best_config)\n",
    "    model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    # Validation predictions\n",
    "    pred_va = model.predict(val_pool)\n",
    "    oof_predictions[val_idx] = pred_va\n",
    "    \n",
    "    # Test predictions\n",
    "    test_pool = Pool(X_test, cat_features=cat_features)\n",
    "    pred_test = model.predict(test_pool)\n",
    "    test_predictions += pred_test / n_folds\n",
    "    \n",
    "    # Score\n",
    "    score = np.sqrt(mean_squared_log_error(y_va, np.clip(pred_va, 0, None)))\n",
    "    fold_scores.append(score)\n",
    "    \n",
    "    print(f\"  Fold {fold} RMSLE: {score:.6f} (best_iter: {model.best_iteration_})\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "final_score = np.mean(fold_scores)\n",
    "final_std = np.std(fold_scores)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL MODEL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"CV RMSLE: {final_score:.6f} ± {final_std:.6f}\")\n",
    "print(f\"Individual folds: {fold_scores}\")\n",
    "print(f\"Improvement over baseline: {final_score - baseline_score:+.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724620e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Calories': np.clip(test_predictions, train_df['Calories'].min(), train_df['Calories'].max())\n",
    "})\n",
    "\n",
    "submission_path = '/home/submission/submission_004_catboost_hyperopt.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved: {submission_path}\")\n",
    "\n",
    "# Save OOF predictions\n",
    "oof_df = pd.DataFrame({\n",
    "    'id': train_df['id'],\n",
    "    'oof_prediction': oof_predictions\n",
    "})\n",
    "oof_path = '/home/code/experiments/oof_004_catboost_hyperopt.csv'\n",
    "oof_df.to_csv(oof_path, index=False)\n",
    "\n",
    "print(f\"OOF predictions saved: {oof_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
