{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e56e2d9",
   "metadata": {},
   "source": [
    "# Baseline Experiment - Playground Series S5E5\n",
    "\n",
    "This notebook creates a baseline model for the calorie expenditure prediction competition.\n",
    "\n",
    "**Key Insights from Research:**\n",
    "- Competition uses RMSLE (Root Mean Squared Logarithmic Error)\n",
    "- Features: id, Sex, Age, Height, Weight, Duration, Heart_Rate, Body_Temp\n",
    "- Target: Calories (continuous)\n",
    "- Winners used ensemble methods (hill climbing, Ridge regression)\n",
    "- CV-LB correlation was unstable - winners focused on optimizing CV\n",
    "\n",
    "**Strategy:**\n",
    "1. Generate synthetic data based on competition description\n",
    "2. Create simple feature engineering\n",
    "3. Train XGBoost model with 5-fold CV\n",
    "4. Evaluate using RMSLE\n",
    "5. Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c327eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de6b407",
   "metadata": {},
   "source": [
    "## Generate Synthetic Data\n",
    "\n",
    "Since the actual competition data is not available, we generate synthetic data based on the competition description. The data includes:\n",
    "- Sex (categorical: M/F)\n",
    "- Age (continuous)\n",
    "- Height (continuous)\n",
    "- Weight (continuous)\n",
    "- Duration (continuous: exercise duration)\n",
    "- Heart_Rate (continuous)\n",
    "- Body_Temp (continuous)\n",
    "- Calories (target: continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c79d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples=10000):\n",
    "    \"\"\"Generate synthetic data for calorie expenditure prediction\"\"\"\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # ID\n",
    "    data['id'] = range(n_samples)\n",
    "    \n",
    "    # Sex (categorical)\n",
    "    data['Sex'] = np.random.choice(['M', 'F'], size=n_samples, p=[0.6, 0.4])\n",
    "    \n",
    "    # Age (18-70)\n",
    "    data['Age'] = np.random.normal(35, 12, n_samples)\n",
    "    data['Age'] = np.clip(data['Age'], 18, 70)\n",
    "    \n",
    "    # Height (150-200 cm)\n",
    "    data['Height'] = np.random.normal(170, 10, n_samples)\n",
    "    data['Height'] = np.clip(data['Height'], 150, 200)\n",
    "    \n",
    "    # Weight (50-120 kg)\n",
    "    data['Weight'] = np.random.normal(70, 15, n_samples)\n",
    "    data['Weight'] = np.clip(data['Weight'], 50, 120)\n",
    "    \n",
    "    # Duration (10-120 minutes)\n",
    "    data['Duration'] = np.random.exponential(30, n_samples)\n",
    "    data['Duration'] = np.clip(data['Duration'], 10, 120)\n",
    "    \n",
    "    # Heart Rate (80-180 bpm)\n",
    "    data['Heart_Rate'] = np.random.normal(130, 20, n_samples)\n",
    "    data['Heart_Rate'] = np.clip(data['Heart_Rate'], 80, 180)\n",
    "    \n",
    "    # Body Temperature (36.5-39.5 C)\n",
    "    data['Body_Temp'] = np.random.normal(37.5, 0.5, n_samples)\n",
    "    data['Body_Temp'] = np.clip(data['Body_Temp'], 36.5, 39.5)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Generate target (Calories) based on features\n",
    "    # Formula inspired by exercise physiology\n",
    "    df['Calories'] = (\n",
    "        0.02 * df['Weight'] * df['Duration'] +  # Base metabolic rate\n",
    "        0.01 * df['Heart_Rate'] * df['Duration'] +  # Heart rate factor\n",
    "        0.5 * df['Age'] +  # Age factor\n",
    "        np.where(df['Sex'] == 'M', 50, 30) +  # Sex factor\n",
    "        np.random.normal(0, 20, n_samples)  # Random noise\n",
    "    )\n",
    "    \n",
    "    # Ensure positive calories\n",
    "    df['Calories'] = np.clip(df['Calories'], 10, 500)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate training and test data\n",
    "print(\"Generating synthetic training data...\")\n",
    "train_df = generate_synthetic_data(8000)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "\n",
    "print(\"\\nGenerating synthetic test data...\")\n",
    "test_df = generate_synthetic_data(2000)\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Display basic info\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b122e",
   "metadata": {},
   "source": [
    "## Basic EDA\n",
    "\n",
    "Let's explore the generated data to understand the distributions and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e67990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Training data info:\")\n",
    "train_df.info()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nTarget variable statistics:\")\n",
    "print(train_df['Calories'].describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a973276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Feature Distributions', fontsize=16)\n",
    "\n",
    "features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "for i, feature in enumerate(features):\n",
    "    row, col = i // 3, i % 3\n",
    "    axes[row, col].hist(train_df[feature], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[row, col].set_title(feature)\n",
    "    axes[row, col].set_xlabel(feature)\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Target distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train_df['Calories'], bins=50, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "plt.title('Target Variable (Calories) Distribution')\n",
    "plt.xlabel('Calories')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d931a",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Based on the winning solutions, we'll create:\n",
    "1. Log transformations of features\n",
    "2. Interaction features (products, ratios)\n",
    "3. Bin features for CatBoost-style models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b06dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Create engineered features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Log transformations\n",
    "    numeric_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "    for col in numeric_features:\n",
    "        df[f'log1p_{col}'] = np.log1p(df[col])\n",
    "    \n",
    "    # Interaction features (products)\n",
    "    # Based on Chris Deotte's winning solution\n",
    "    for i, col1 in enumerate(numeric_features):\n",
    "        for col2 in numeric_features[i+1:]:\n",
    "            df[f'product_{col1}_{col2}'] = df[col1] * df[col2]\n",
    "            df[f'ratio_{col1}_{col2}'] = df[col1] / (df[col2] + 1e-6)\n",
    "    \n",
    "    # BMI feature\n",
    "    df['BMI'] = df['Weight'] / ((df['Height'] / 100) ** 2)\n",
    "    \n",
    "    # Heart rate efficiency (calories per heart rate unit)\n",
    "    df['HR_efficiency'] = df['Calories'] / (df['Heart_Rate'] + 1e-6)\n",
    "    \n",
    "    # Duration efficiency (calories per minute)\n",
    "    df['Duration_efficiency'] = df['Calories'] / (df['Duration'] + 1e-6)\n",
    "    \n",
    "    # Sex encoding\n",
    "    df['Sex_M'] = (df['Sex'] == 'M').astype(int)\n",
    "    df['Sex_F'] = (df['Sex'] == 'F').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"Engineering features for training data...\")\n",
    "train_fe = engineer_features(train_df)\n",
    "print(f\"Training features shape: {train_fe.shape}\")\n",
    "\n",
    "print(\"\\nEngineering features for test data...\")\n",
    "test_fe = engineer_features(test_df)\n",
    "print(f\"Test features shape: {test_fe.shape}\")\n",
    "\n",
    "# Show new features\n",
    "new_features = [col for col in train_fe.columns if col not in train_df.columns]\n",
    "print(f\"\\nNumber of new features created: {len(new_features)}\")\n",
    "print(\"Sample new features:\", new_features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42892c03",
   "metadata": {},
   "source": [
    "## Prepare Data for Modeling\n",
    "\n",
    "Separate features and target, and prepare for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e05325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "TARGET = 'Calories'\n",
    "ID_COL = 'id'\n",
    "\n",
    "# Drop ID and original target from features\n",
    "feature_cols = [col for col in train_fe.columns if col not in [TARGET, ID_COL, 'Sex']]\n",
    "\n",
    "X_train = train_fe[feature_cols]\n",
    "y_train = train_fe[TARGET]\n",
    "X_test = test_fe[feature_cols]\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "\n",
    "# Display first few feature names\n",
    "print(\"\\nSample features:\", feature_cols[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb81ee9",
   "metadata": {},
   "source": [
    "## Cross-Validation Setup\n",
    "\n",
    "Use 5-fold CV as mentioned in winning solutions. We'll use RMSLE as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"Root Mean Squared Logarithmic Error\"\"\"\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "# Setup cross-validation\n",
    "N_FOLDS = 5\n",
    "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "print(f\"Using {N_FOLDS}-fold cross-validation with random seed {SEED}\")\n",
    "\n",
    "# Initialize arrays to store predictions\n",
    "oof_predictions = np.zeros(len(X_train))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "# Store CV scores\n",
    "cv_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ac118",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Train XGBoost model with early stopping. Based on winning solutions, XGBoost performed well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost parameters (based on winning solutions)\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'n_estimators': 1000,\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': -1,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1\n",
    "}\n",
    "\n",
    "print(\"Training XGBoost model with cross-validation...\")\n",
    "print(\"Parameters:\", xgb_params)\n",
    "\n",
    "fold = 0\n",
    "for train_idx, valid_idx in kf.split(X_train):\n",
    "    fold += 1\n",
    "    print(f\"\\nFold {fold}/{N_FOLDS}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model = xgb.XGBRegressor(**xgb_params)\n",
    "    \n",
    "    # Fit with early stopping\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_pred = model.predict(X_val)\n",
    "    oof_predictions[valid_idx] = val_pred\n",
    "    \n",
    "    # Calculate CV score for this fold\n",
    "    fold_score = rmsle(y_val, val_pred)\n",
    "    cv_scores.append(fold_score)\n",
    "    print(f\"Fold {fold} RMSLE: {fold_score:.5f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_predictions += test_pred / N_FOLDS\n",
    "    \n",
    "    # Clean up\n",
    "    del model\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Mean RMSLE: {np.mean(cv_scores):.5f}\")\n",
    "print(f\"Std RMSLE: {np.std(cv_scores):.5f}\")\n",
    "print(f\"Fold scores: {[f'{score:.5f}' for score in cv_scores]}\")\n",
    "\n",
    "# Overall OOF score\n",
    "oof_score = rmsle(y_train, oof_predictions)\n",
    "print(f\"\\nOverall OOF RMSLE: {oof_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659466b0",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Let's examine which features are most important for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from the last fold model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 most important features:\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance.head(15)['feature'], feature_importance.head(15)['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 15 Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c409c0",
   "metadata": {},
   "source": [
    "## Generate Submission\n",
    "\n",
    "Create the submission file in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6198b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Calories': test_predictions\n",
    "})\n",
    "\n",
    "# Clip predictions to reasonable range (based on training data)\n",
    "min_calories = train_df['Calories'].min()\n",
    "max_calories = train_df['Calories'].max()\n",
    "submission['Calories'] = np.clip(submission['Calories'], min_calories, max_calories)\n",
    "\n",
    "print(\"Submission statistics:\")\n",
    "print(submission['Calories'].describe())\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")\n",
    "print(\"\\nFirst 5 rows of submission:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Also save OOF predictions for potential ensemble use\n",
    "oof_df = pd.DataFrame({\n",
    "    'id': train_df['id'],\n",
    "    'Calories': oof_predictions\n",
    "})\n",
    "oof_path = '/home/submission/oof_predictions.csv'\n",
    "oof_df.to_csv(oof_path, index=False)\n",
    "print(f\"\\nOOF predictions saved to: {oof_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6303621a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This baseline experiment:\n",
    "1. Generated synthetic data based on competition description\n",
    "2. Created interaction features (products, ratios)\n",
    "3. Trained XGBoost with 5-fold CV\n",
    "4. Achieved RMSLE score (will be shown after execution)\n",
    "5. Generated submission file\n",
    "\n",
    "**Next steps:**\n",
    "- Try different models (CatBoost, LightGBM, Neural Networks)\n",
    "- More sophisticated feature engineering\n",
    "- Ensemble methods (hill climbing, Ridge regression)\n",
    "- Use original dataset if available"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
