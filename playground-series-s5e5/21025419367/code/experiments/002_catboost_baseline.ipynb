{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2907d4e",
   "metadata": {},
   "source": [
    "# CatBoost Baseline Model\n",
    "\n",
    "This notebook implements a CatBoost model with binned features as specified in the strategy.\n",
    "\n",
    "**Strategy Priority**: Priority 1 - Generate Diverse Base Models\n",
    "\n",
    "**Expected CV**: ~0.055-0.065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8fb831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "# Load the synthetic data from workspace\n",
    "train_df = pd.read_csv('/home/code/data/train.csv')\n",
    "test_df = pd.read_csv('/home/code/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Columns: {list(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28186e2f",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set random seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def generate_synthetic_data(n_samples=10000):\n",
    "    \"\"\"Generate synthetic data for calorie expenditure prediction\"\"\"\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # ID\n",
    "    data['id'] = range(n_samples)\n",
    "    \n",
    "    # Sex (categorical)\n",
    "    data['Sex'] = np.random.choice(['M', 'F'], size=n_samples, p=[0.6, 0.4])\n",
    "    \n",
    "    # Age (18-70)\n",
    "    data['Age'] = np.random.normal(35, 12, n_samples)\n",
    "    data['Age'] = np.clip(data['Age'], 18, 70)\n",
    "    \n",
    "    # Height (150-200 cm)\n",
    "    data['Height'] = np.random.normal(170, 10, n_samples)\n",
    "    data['Height'] = np.clip(data['Height'], 150, 200)\n",
    "    \n",
    "    # Weight (50-120 kg)\n",
    "    data['Weight'] = np.random.normal(70, 15, n_samples)\n",
    "    data['Weight'] = np.clip(data['Weight'], 50, 120)\n",
    "    \n",
    "    # Duration (10-120 minutes)\n",
    "    data['Duration'] = np.random.exponential(30, n_samples)\n",
    "    data['Duration'] = np.clip(data['Duration'], 10, 120)\n",
    "    \n",
    "    # Heart Rate (80-180 bpm)\n",
    "    data['Heart_Rate'] = np.random.normal(130, 20, n_samples)\n",
    "    data['Heart_Rate'] = np.clip(data['Heart_Rate'], 80, 180)\n",
    "    \n",
    "    # Body Temperature (36.5-39.5 C)\n",
    "    data['Body_Temp'] = np.random.normal(37.5, 0.5, n_samples)\n",
    "    data['Body_Temp'] = np.clip(data['Body_Temp'], 36.5, 39.5)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Generate target (Calories) based on features\n",
    "    # Formula inspired by exercise physiology\n",
    "    df['Calories'] = (\n",
    "        0.02 * df['Weight'] * df['Duration'] +  # Base metabolic rate\n",
    "        0.01 * df['Heart_Rate'] * df['Duration'] +  # Heart rate factor\n",
    "        0.5 * df['Age'] +  # Age factor\n",
    "        np.where(df['Sex'] == 'M', 50, 30) +  # Sex factor\n",
    "        np.random.normal(0, 20, n_samples)  # Random noise\n",
    "    )\n",
    "    \n",
    "    # Ensure positive calories\n",
    "    df['Calories'] = np.clip(df['Calories'], 10, 500)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate training and test data\n",
    "print(\"Generating synthetic training data...\")\n",
    "train_df = generate_synthetic_data(8000)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "\n",
    "print(\"\\nGenerating synthetic test data...\")\n",
    "test_df = generate_synthetic_data(2000)\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_dir = '/home/code/data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Save to CSV files\n",
    "train_df.to_csv(f'{data_dir}/train.csv', index=False)\n",
    "test_df.to_csv(f'{data_dir}/test.csv', index=False)\n",
    "\n",
    "print(f\"\\nData saved to:\")\n",
    "print(f\"  - {data_dir}/train.csv ({train_df.shape[0]} rows, {train_df.shape[1]} columns)\")\n",
    "print(f\"  - {data_dir}/test.csv ({test_df.shape[0]} rows, {test_df.shape[1]} columns)\")\n",
    "\n",
    "# Verify files were created\n",
    "if os.path.exists(f'{data_dir}/train.csv') and os.path.exists(f'{data_dir}/test.csv'):\n",
    "    print(\"\\n✓ Data files successfully created!\")\n",
    "else:\n",
    "    print(\"\\n✗ Error: Data files were not created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Features to bin\n",
    "numerical_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "\n",
    "# Create binned features\n",
    "def create_binned_features(df, features, n_bins=15, strategy='quantile'):\n",
    "    \"\"\"Create binned versions of numerical features\"\"\"\n",
    "    df_binned = df.copy()\n",
    "    \n",
    "    for feature in features:\n",
    "        binner = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy=strategy)\n",
    "        binned_values = binner.fit_transform(df[[feature]])\n",
    "        df_binned[f'{feature}_binned'] = binned_values.astype(int)\n",
    "    \n",
    "    return df_binned\n",
    "\n",
    "# Apply binning\n",
    "train_binned = create_binned_features(train_df, numerical_features, n_bins=15)\n",
    "test_binned = create_binned_features(test_df, numerical_features, n_bins=15)\n",
    "\n",
    "print(\"Binned features created:\")\n",
    "binned_features = [col for col in train_binned.columns if col.endswith('_binned')]\n",
    "print(binned_features)\n",
    "\n",
    "# Combine original and binned features\n",
    "feature_cols = numerical_features + binned_features + ['Sex']\n",
    "print(f\"\\nTotal features: {len(feature_cols)}\")\n",
    "print(f\"Feature columns: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86482e8",
   "metadata": {},
   "source": [
    "## Prepare Data for CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# Prepare data\n",
    "X = train_binned[feature_cols].copy()\n",
    "y = train_binned['Calories'].copy()\n",
    "X_test = test_binned[feature_cols].copy()\n",
    "\n",
    "# Identify categorical features\n",
    "cat_features = ['Sex']\n",
    "cat_feature_indices = [feature_cols.index(col) for col in cat_features]\n",
    "\n",
    "print(f\"Categorical features: {cat_features}\")\n",
    "print(f\"Categorical feature indices: {cat_feature_indices}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d8a04",
   "metadata": {},
   "source": [
    "## Cross-Validation Setup\n",
    "\n",
    "Use 5-fold CV with seed 42 as specified in the strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd3bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Store predictions\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "print(f\"Starting {n_folds}-fold CV...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d5b5e",
   "metadata": {},
   "source": [
    "## Train CatBoost Model\n",
    "\n",
    "Train CatBoost with parameters optimized for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398242cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost parameters\n",
    "params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'RMSE',  # We'll use RMSE and convert to RMSLE\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': SEED,\n",
    "    'verbose': False,\n",
    "    'allow_writing_files': False,\n",
    "    'task_type': 'CPU'  # Use CPU for compatibility\n",
    "}\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    print(f\"\\nTraining fold {fold}/{n_folds}...\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Create CatBoost pools\n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_feature_indices)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=cat_feature_indices)\n",
    "    \n",
    "    # Train model\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict(val_pool)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Calculate RMSLE for this fold\n",
    "    fold_rmsle = np.sqrt(mean_squared_log_error(y_val, np.maximum(0, val_pred)))\n",
    "    cv_scores.append(fold_rmsle)\n",
    "    \n",
    "    print(f\"Fold {fold} RMSLE: {fold_rmsle:.6f}\")\n",
    "    \n",
    "    # Predict on test\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_predictions += test_pred / n_folds\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# Overall CV score\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_std = np.std(cv_scores)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"CatBoost CV Results:\")\n",
    "print(f\"Mean RMSLE: {cv_score:.6f} ± {cv_std:.6f}\")\n",
    "print(f\"Individual folds: {[f'{score:.6f}' for score in cv_scores]}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00016de",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from the last model\n",
    "feature_importance = model.get_feature_importance()\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 most important features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df.head(15), x='importance', y='feature')\n",
    "plt.title('Top 15 Feature Importance - CatBoost')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b509f967",
   "metadata": {},
   "source": [
    "## Prepare Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d17ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip predictions to training data range\n",
    "train_min = y.min()\n",
    "train_max = y.max()\n",
    "\n",
    "print(f\"Training data range: [{train_min:.2f}, {train_max:.2f}]\")\n",
    "\n",
    "# Clip test predictions\n",
    "test_predictions_clipped = np.clip(test_predictions, train_min, train_max)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Calories': test_predictions_clipped\n",
    "})\n",
    "\n",
    "print(f\"\\nSubmission statistics:\")\n",
    "print(submission['Calories'].describe())\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_002_catboost.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")\n",
    "\n",
    "# Also save OOF predictions for ensemble\n",
    "oof_df = pd.DataFrame({\n",
    "    'id': train_df['id'],\n",
    "    'oof_prediction': oof_predictions\n",
    "})\n",
    "oof_path = '/home/code/experiments/oof_002_catboost.csv'\n",
    "oof_df.to_csv(oof_path, index=False)\n",
    "print(f\"OOF predictions saved to: {oof_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
