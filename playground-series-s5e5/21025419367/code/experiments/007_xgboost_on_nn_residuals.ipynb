{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157f25f0",
   "metadata": {},
   "source": [
    "# XGBoost on NN Residuals - Three-Stage Pipeline\n",
    "\n",
    "This notebook implements the final stage of the residual modeling pipeline:\n",
    "1. Linear Regression (exp_005) - captures linear patterns\n",
    "2. Neural Network on LR residuals (exp_006) - captures non-linear patterns  \n",
    "3. XGBoost on NN residuals (exp_007) - captures remaining patterns\n",
    "\n",
    "Expected to improve upon the 0.02047 baseline from direct XGBoost modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78902728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:17:41.990277Z",
     "iopub.status.busy": "2026-01-15T21:17:41.990023Z",
     "iopub.status.idle": "2026-01-15T21:17:43.189157Z",
     "shell.execute_reply": "2026-01-15T21:17:43.188706Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc2829",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5879f67e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:17:43.190746Z",
     "iopub.status.busy": "2026-01-15T21:17:43.190584Z",
     "iopub.status.idle": "2026-01-15T21:17:43.211922Z",
     "shell.execute_reply": "2026-01-15T21:17:43.211549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (8000, 9)\n",
      "Test data shape: (2000, 9)\n",
      "Residuals from NN shape: (8000, 2)\n",
      "\n",
      "Residuals statistics:\n",
      "count    8000.000000\n",
      "mean       -0.050198\n",
      "std        20.603560\n",
      "min       -81.094214\n",
      "25%       -13.991381\n",
      "50%         0.005975\n",
      "75%        13.958964\n",
      "max        74.479004\n",
      "Name: residual, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('/home/nonroot/snapshots/playground-series-s5e5/21025419367/code/data/train.csv')\n",
    "test_df = pd.read_csv('/home/nonroot/snapshots/playground-series-s5e5/21025419367/code/data/test.csv')\n",
    "\n",
    "# Load residuals from NN stage (exp_006)\n",
    "residuals_nn = pd.read_csv('/home/code/experiments/006_neural_network_residuals/residuals_after_nn.csv')\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Residuals from NN shape: {residuals_nn.shape}\")\n",
    "print(f\"\\nResiduals statistics:\")\n",
    "print(residuals_nn['residual'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf49024",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Create features for XGBoost stage. Based on winning solutions analysis:\n",
    "- Log1p transforms of numeric features\n",
    "- Product features (pairwise interactions)\n",
    "- Binned features for categorical handling\n",
    "- Groupby z-score features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31eb3cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:17:43.212997Z",
     "iopub.status.busy": "2026-01-15T21:17:43.212712Z",
     "iopub.status.idle": "2026-01-15T21:17:43.245696Z",
     "shell.execute_reply": "2026-01-15T21:17:43.241456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features for training data...\n",
      "Train features shape: (8000, 37)\n",
      "Engineering features for test data...\n",
      "Test features shape: (2000, 37)\n",
      "Number of features: 35\n",
      "Feature columns: ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Age_log1p', 'Height_log1p', 'Weight_log1p', 'Duration_log1p']...\n"
     ]
    }
   ],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Engineer features for XGBoost on residuals\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Original numeric features\n",
    "    numeric_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "    \n",
    "    # 1. Log1p transforms\n",
    "    for col in numeric_features:\n",
    "        df[f'{col}_log1p'] = np.log1p(df[col])\n",
    "    \n",
    "    # 2. Product features (pairwise interactions) - these are valuable but caused overfitting in direct modeling\n",
    "    # Now applied to residuals where they may capture remaining patterns\n",
    "    df['product_Weight_Duration'] = df['Weight'] * df['Duration']\n",
    "    df['product_Duration_Heart_Rate'] = df['Duration'] * df['Heart_Rate']\n",
    "    df['product_Height_Weight'] = df['Height'] * df['Weight']\n",
    "    df['product_Age_Weight'] = df['Age'] * df['Weight']\n",
    "    df['product_Duration_Body_Temp'] = df['Duration'] * df['Body_Temp']\n",
    "    \n",
    "    # 3. Ratio features\n",
    "    df['ratio_Weight_Height'] = df['Weight'] / (df['Height'] + 1e-6)\n",
    "    df['ratio_BMI'] = df['Weight'] / ((df['Height'] / 100) ** 2 + 1e-6)\n",
    "    df['ratio_Duration_Weight'] = df['Duration'] / (df['Weight'] + 1e-6)\n",
    "    df['ratio_Heart_Rate_Age'] = df['Heart_Rate'] / (df['Age'] + 1e-6)\n",
    "    \n",
    "    # 4. Sum features\n",
    "    df['sum_Weight_Duration'] = df['Weight'] + df['Duration']\n",
    "    df['sum_Height_Weight'] = df['Height'] + df['Weight']\n",
    "    df['sum_Age_Weight'] = df['Age'] + df['Weight']\n",
    "    \n",
    "    # 5. Difference features\n",
    "    df['diff_Height_Weight'] = df['Height'] - df['Weight']\n",
    "    df['diff_Age_Weight'] = df['Age'] - df['Weight']\n",
    "    df['diff_Duration_Heart_Rate'] = df['Duration'] - df['Heart_Rate']\n",
    "    \n",
    "    # 6. Binned features (equal-width bins)\n",
    "    for col in numeric_features:\n",
    "        df[f'{col}_binned'] = pd.cut(df[col], bins=9, labels=False)\n",
    "    \n",
    "    # 7. One-hot encode Sex and drop original\n",
    "    if 'Sex' in df.columns:\n",
    "        sex_dummies = pd.get_dummies(df['Sex'], prefix='Sex')\n",
    "        df = pd.concat([df, sex_dummies], axis=1)\n",
    "        df = df.drop(columns=['Sex'])  # Drop original Sex column\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to train and test data\n",
    "print(\"Engineering features for training data...\")\n",
    "train_features = engineer_features(train_df)\n",
    "print(f\"Train features shape: {train_features.shape}\")\n",
    "\n",
    "print(\"Engineering features for test data...\")\n",
    "test_features = engineer_features(test_df)\n",
    "print(f\"Test features shape: {test_features.shape}\")\n",
    "\n",
    "# Define feature columns (exclude id and target)\n",
    "feature_cols = [col for col in train_features.columns if col not in ['id', 'Calories']]\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Feature columns: {feature_cols[:10]}...\")  # Show first 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f4d6e",
   "metadata": {},
   "source": [
    "## Prepare Data for XGBoost\n",
    "\n",
    "Target: residuals from NN stage (remaining patterns after Linear+NN)\n",
    "Features: engineered features above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac5c049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:17:43.250403Z",
     "iopub.status.busy": "2026-01-15T21:17:43.250268Z",
     "iopub.status.idle": "2026-01-15T21:17:43.254345Z",
     "shell.execute_reply": "2026-01-15T21:17:43.253982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8000, 35)\n",
      "X_test shape: (2000, 35)\n",
      "y_residuals shape: (8000,)\n",
      "y_residuals range: [-81.09, 74.48]\n"
     ]
    }
   ],
   "source": [
    "# Target is residuals from NN stage\n",
    "y_residuals = residuals_nn['residual'].values\n",
    "\n",
    "# Features for XGBoost\n",
    "X_train = train_features[feature_cols]\n",
    "X_test = test_features[feature_cols]\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_residuals shape: {y_residuals.shape}\")\n",
    "print(f\"y_residuals range: [{y_residuals.min():.2f}, {y_residuals.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a835f8",
   "metadata": {},
   "source": [
    "## Cross-Validation Setup\n",
    "\n",
    "Use 5-fold CV with same seed as previous stages to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da2f2b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:17:43.255168Z",
     "iopub.status.busy": "2026-01-15T21:17:43.255071Z",
     "iopub.status.idle": "2026-01-15T21:17:43.257757Z",
     "shell.execute_reply": "2026-01-15T21:17:43.257416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-fold CV...\n"
     ]
    }
   ],
   "source": [
    "# 5-fold CV\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Initialize arrays for OOF predictions\n",
    "oof_predictions = np.zeros(len(X_train))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "# Store fold scores\n",
    "fold_scores = []\n",
    "\n",
    "print(f\"Starting {n_splits}-fold CV...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaef40c",
   "metadata": {},
   "source": [
    "## Load OOF Predictions from Previous Stages\n",
    "\n",
    "Need Linear Regression and Neural Network OOF predictions to combine with XGBoost predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a35ae0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:17:43.258535Z",
     "iopub.status.busy": "2026-01-15T21:17:43.258440Z",
     "iopub.status.idle": "2026-01-15T21:17:43.267580Z",
     "shell.execute_reply": "2026-01-15T21:17:43.267240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR OOF shape: (8000,)\n",
      "NN residual OOF shape: (8000,)\n",
      "LR predictions range: [42.76, 429.20]\n",
      "NN residual predictions range: [-52.15, 57.38]\n"
     ]
    }
   ],
   "source": [
    "# Load OOF predictions from Linear Regression (exp_005)\n",
    "lr_oof = pd.read_csv('/home/code/experiments/005_linear_regression/oof_005_linear_regression.csv')\n",
    "lr_predictions = lr_oof['oof_prediction'].values\n",
    "\n",
    "# Load OOF predictions from Neural Network (exp_006)  \n",
    "nn_oof = pd.read_csv('/home/code/experiments/006_neural_network_residuals/oof_006_neural_network_residuals.csv')\n",
    "nn_residual_predictions = nn_oof['residual_prediction'].values\n",
    "\n",
    "print(f\"LR OOF shape: {lr_predictions.shape}\")\n",
    "print(f\"NN residual OOF shape: {nn_residual_predictions.shape}\")\n",
    "print(f\"LR predictions range: [{lr_predictions.min():.2f}, {lr_predictions.max():.2f}]\")\n",
    "print(f\"NN residual predictions range: [{nn_residual_predictions.min():.2f}, {nn_residual_predictions.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348ad37",
   "metadata": {},
   "source": [
    "## Train XGBoost on Residuals\n",
    "\n",
    "Train XGBoost to capture remaining patterns in residuals after Linear+NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069664d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:17:43.268608Z",
     "iopub.status.busy": "2026-01-15T21:17:43.268305Z",
     "iopub.status.idle": "2026-01-15T21:17:49.077980Z",
     "shell.execute_reply": "2026-01-15T21:17:49.077443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost on residuals...\n",
      "Parameters: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8, 'n_estimators': 800, 'random_state': 42, 'n_jobs': 4}\n",
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1 RMSLE: 0.207970\n",
      "\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2 RMSLE: 0.199187\n",
      "\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3 RMSLE: 0.212461\n",
      "\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4 RMSLE: 0.220010\n",
      "\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5 RMSLE: 0.199985\n",
      "\n",
      "==================================================\n",
      "CV RMSLE: 0.207923 ± 0.007823\n",
      "Fold scores: [0.2079695970354534, 0.19918747729955139, 0.21246057368225243, 0.22001000190857645, 0.1999854477957768]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost parameters (conservative, as recommended in strategy)\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.03,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'n_estimators': 800,\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': 4\n",
    "}\n",
    "\n",
    "print(\"Training XGBoost on residuals...\")\n",
    "print(f\"Parameters: {params}\")\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "    print(f\"\\nFold {fold}/{n_splits}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_residuals[train_idx], y_residuals[val_idx]\n",
    "    \n",
    "    # Train XGBoost model\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set (residuals)\n",
    "    val_residual_pred = model.predict(X_val)\n",
    "    oof_predictions[val_idx] = val_residual_pred\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_fold_pred = model.predict(X_test)\n",
    "    test_predictions += test_fold_pred / n_splits\n",
    "    \n",
    "    # Calculate fold score (RMSLE on combined predictions)\n",
    "    # Combined prediction = LR + NN residual + XGB residual\n",
    "    val_combined_pred = (lr_predictions[val_idx] + \n",
    "                        nn_residual_predictions[val_idx] + \n",
    "                        val_residual_pred)\n",
    "    \n",
    "    # Clip predictions to avoid log(negative)\n",
    "    val_combined_pred = np.clip(val_combined_pred, 1e-6, None)\n",
    "    \n",
    "    fold_score = np.sqrt(mean_squared_log_error(train_df['Calories'].iloc[val_idx], val_combined_pred))\n",
    "    fold_scores.append(fold_score)\n",
    "    \n",
    "    print(f\"  Fold {fold} RMSLE: {fold_score:.6f}\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"CV RMSLE: {np.mean(fold_scores):.6f} ± {np.std(fold_scores):.6f}\")\n",
    "print(f\"Fold scores: {fold_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c632714",
   "metadata": {},
   "source": [
    "## Analyze Results\n",
    "\n",
    "Compare performance to baseline and previous stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85cb1ae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:23:36.992351Z",
     "iopub.status.busy": "2026-01-15T21:23:36.992102Z",
     "iopub.status.idle": "2026-01-15T21:23:36.997511Z",
     "shell.execute_reply": "2026-01-15T21:23:36.997109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FINAL PIPELINE RESULTS\n",
      "==================================================\n",
      "Linear Regression only: 0.208762 (from exp_005)\n",
      "Linear + NN:             0.201961 (from exp_006)\n",
      "Linear + NN + XGBoost:   0.208070\n",
      "Improvement from NN:     0.006801\n",
      "Improvement from XGB:    -0.006109\n",
      "Total improvement:       0.000692\n",
      "\n",
      "Baseline XGBoost:        0.020470 (from exp_000)\n",
      "Pipeline vs Baseline:    0.187600\n",
      "\n",
      "❌ Pipeline does NOT beat baseline (difference: 0.187600)\n"
     ]
    }
   ],
   "source": [
    "# Calculate combined OOF predictions\n",
    "oof_combined = lr_predictions + nn_residual_predictions + oof_predictions\n",
    "\n",
    "# Clip to avoid log issues\n",
    "oof_combined = np.clip(oof_combined, 1e-6, None)\n",
    "\n",
    "# Overall CV score\n",
    "cv_score = np.sqrt(mean_squared_log_error(train_df['Calories'], oof_combined))\n",
    "\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"FINAL PIPELINE RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Linear Regression only: 0.208762 (from exp_005)\")\n",
    "print(f\"Linear + NN:             0.201961 (from exp_006)\")\n",
    "print(f\"Linear + NN + XGBoost:   {cv_score:.6f}\")\n",
    "print(f\"Improvement from NN:     {0.208762 - 0.201961:.6f}\")\n",
    "print(f\"Improvement from XGB:    {0.201961 - cv_score:.6f}\")\n",
    "print(f\"Total improvement:       {0.208762 - cv_score:.6f}\")\n",
    "print(f\"\\nBaseline XGBoost:        0.020470 (from exp_000)\")\n",
    "print(f\"Pipeline vs Baseline:    {cv_score - 0.020470:.6f}\")\n",
    "\n",
    "# Check if we beat the baseline\n",
    "if cv_score < 0.02047:\n",
    "    print(f\"\\n✅ SUCCESS: Pipeline BEATS baseline by {0.02047 - cv_score:.6f}\")\n",
    "else:\n",
    "    print(f\"\\n❌ Pipeline does NOT beat baseline (difference: {cv_score - 0.02047:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2b0e3b",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcb4cc7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:23:36.998538Z",
     "iopub.status.busy": "2026-01-15T21:23:36.998273Z",
     "iopub.status.idle": "2026-01-15T21:23:37.062480Z",
     "shell.execute_reply": "2026-01-15T21:23:37.062097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF predictions saved. Shape: (8000, 6)\n",
      "Linear test predictions shape: (2000,)\n",
      "NN test predictions shape: (2000,)\n",
      "XGBoost test predictions shape: (2000,)\n",
      "Final test predictions shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Save OOF predictions\n",
    "oof_df = pd.DataFrame({\n",
    "    'id': train_df['id'],\n",
    "    'Calories_actual': train_df['Calories'],\n",
    "    'Calories_pred': oof_combined,\n",
    "    'lr_pred': lr_predictions,\n",
    "    'nn_residual_pred': nn_residual_predictions,\n",
    "    'xgb_residual_pred': oof_predictions\n",
    "})\n",
    "\n",
    "oof_df.to_csv('/home/code/experiments/007_xgboost_on_nn_residuals/oof_007_xgboost_residuals.csv', index=False)\n",
    "print(f\"OOF predictions saved. Shape: {oof_df.shape}\")\n",
    "\n",
    "# For test predictions, we need to combine all three stages\n",
    "# Stage 1: Linear Regression (re-train on full data)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Prepare linear features (same as exp_005)\n",
    "linear_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "X_train_linear = train_df[linear_features].values\n",
    "X_test_linear = test_df[linear_features].values\n",
    "\n",
    "# One-hot encode Sex\n",
    "sex_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "sex_train = sex_encoder.fit_transform(train_df[['Sex']])\n",
    "sex_test = sex_encoder.transform(test_df[['Sex']])\n",
    "\n",
    "# Combine features\n",
    "X_train_linear = np.hstack([X_train_linear, sex_train])\n",
    "X_test_linear = np.hstack([X_test_linear, sex_test])\n",
    "\n",
    "# Train linear model\n",
    "linear_model = Ridge(alpha=1.0, random_state=SEED)\n",
    "linear_model.fit(X_train_linear, train_df['Calories'])\n",
    "\n",
    "# Predict linear component\n",
    "linear_test_pred = linear_model.predict(X_test_linear)\n",
    "\n",
    "# Stage 2: Neural Network (load test predictions from exp_006)\n",
    "nn_test_pred = nn_oof['oof_prediction'].iloc[:len(test_df)].values\n",
    "\n",
    "# Stage 3: XGBoost (use test_predictions from current experiment)\n",
    "# Combine all three stages\n",
    "test_final_pred = linear_test_pred + nn_test_pred + test_predictions\n",
    "\n",
    "print(f\"Linear test predictions shape: {linear_test_pred.shape}\")\n",
    "print(f\"NN test predictions shape: {nn_test_pred.shape}\")\n",
    "print(f\"XGBoost test predictions shape: {test_predictions.shape}\")\n",
    "print(f\"Final test predictions shape: {test_final_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a963c",
   "metadata": {},
   "source": [
    "## Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b02c9aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:23:37.063828Z",
     "iopub.status.busy": "2026-01-15T21:23:37.063628Z",
     "iopub.status.idle": "2026-01-15T21:23:37.073828Z",
     "shell.execute_reply": "2026-01-15T21:23:37.073460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: /home/submission/submission_007_xgboost_residuals.csv\n",
      "Submission shape: (2000, 2)\n",
      "\n",
      "Submission statistics:\n",
      "count    2000.000000\n",
      "mean      283.904177\n",
      "std        95.035448\n",
      "min       130.576972\n",
      "25%       208.720153\n",
      "50%       262.912489\n",
      "75%       342.793989\n",
      "max       500.000000\n",
      "Name: Calories, dtype: float64\n",
      "\n",
      "First 5 rows:\n",
      "   id    Calories\n",
      "0   0  231.286335\n",
      "1   1  498.945765\n",
      "2   2  451.410100\n",
      "3   3  283.451680\n",
      "4   4  279.757727\n"
     ]
    }
   ],
   "source": [
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Calories': test_final_pred\n",
    "})\n",
    "\n",
    "# Ensure proper format and clipping\n",
    "submission_df['Calories'] = submission_df['Calories'].clip(\n",
    "    lower=train_df['Calories'].min(), \n",
    "    upper=train_df['Calories'].max()\n",
    ")\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_007_xgboost_residuals.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(f\"\\nSubmission statistics:\")\n",
    "print(submission_df['Calories'].describe())\n",
    "\n",
    "# Show first few rows\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
