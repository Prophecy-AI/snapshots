{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157f25f0",
   "metadata": {},
   "source": [
    "# XGBoost on NN Residuals - Three-Stage Pipeline\n",
    "\n",
    "This notebook implements the final stage of the residual modeling pipeline:\n",
    "1. Linear Regression (exp_005) - captures linear patterns\n",
    "2. Neural Network on LR residuals (exp_006) - captures non-linear patterns  \n",
    "3. XGBoost on NN residuals (exp_007) - captures remaining patterns\n",
    "\n",
    "Expected to improve upon the 0.02047 baseline from direct XGBoost modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78902728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:03:19.973019Z",
     "iopub.status.busy": "2026-01-15T21:03:19.972776Z",
     "iopub.status.idle": "2026-01-15T21:03:21.100341Z",
     "shell.execute_reply": "2026-01-15T21:03:21.099929Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc2829",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5879f67e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:03:21.101795Z",
     "iopub.status.busy": "2026-01-15T21:03:21.101555Z",
     "iopub.status.idle": "2026-01-15T21:03:21.123249Z",
     "shell.execute_reply": "2026-01-15T21:03:21.122808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (8000, 9)\n",
      "Test data shape: (2000, 9)\n",
      "Residuals from NN shape: (8000, 2)\n",
      "\n",
      "Residuals statistics:\n",
      "count    8000.000000\n",
      "mean       -0.050198\n",
      "std        20.603560\n",
      "min       -81.094214\n",
      "25%       -13.991381\n",
      "50%         0.005975\n",
      "75%        13.958964\n",
      "max        74.479004\n",
      "Name: residual, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('/home/nonroot/snapshots/playground-series-s5e5/21025419367/code/data/train.csv')\n",
    "test_df = pd.read_csv('/home/nonroot/snapshots/playground-series-s5e5/21025419367/code/data/test.csv')\n",
    "\n",
    "# Load residuals from NN stage (exp_006)\n",
    "residuals_nn = pd.read_csv('/home/code/experiments/006_neural_network_residuals/residuals_after_nn.csv')\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Residuals from NN shape: {residuals_nn.shape}\")\n",
    "print(f\"\\nResiduals statistics:\")\n",
    "print(residuals_nn['residual'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf49024",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Create features for XGBoost stage. Based on winning solutions analysis:\n",
    "- Log1p transforms of numeric features\n",
    "- Product features (pairwise interactions)\n",
    "- Binned features for categorical handling\n",
    "- Groupby z-score features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31eb3cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:03:21.124653Z",
     "iopub.status.busy": "2026-01-15T21:03:21.124387Z",
     "iopub.status.idle": "2026-01-15T21:03:21.151936Z",
     "shell.execute_reply": "2026-01-15T21:03:21.151568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features for training data...\n",
      "Train features shape: (8000, 38)\n",
      "Engineering features for test data...\n",
      "Test features shape: (2000, 38)\n",
      "Number of features: 36\n",
      "Feature columns: ['Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Age_log1p', 'Height_log1p', 'Weight_log1p']...\n"
     ]
    }
   ],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Engineer features for XGBoost on residuals\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Original numeric features\n",
    "    numeric_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "    \n",
    "    # 1. Log1p transforms\n",
    "    for col in numeric_features:\n",
    "        df[f'{col}_log1p'] = np.log1p(df[col])\n",
    "    \n",
    "    # 2. Product features (pairwise interactions) - these are valuable but caused overfitting in direct modeling\n",
    "    # Now applied to residuals where they may capture remaining patterns\n",
    "    df['product_Weight_Duration'] = df['Weight'] * df['Duration']\n",
    "    df['product_Duration_Heart_Rate'] = df['Duration'] * df['Heart_Rate']\n",
    "    df['product_Height_Weight'] = df['Height'] * df['Weight']\n",
    "    df['product_Age_Weight'] = df['Age'] * df['Weight']\n",
    "    df['product_Duration_Body_Temp'] = df['Duration'] * df['Body_Temp']\n",
    "    \n",
    "    # 3. Ratio features\n",
    "    df['ratio_Weight_Height'] = df['Weight'] / (df['Height'] + 1e-6)\n",
    "    df['ratio_BMI'] = df['Weight'] / ((df['Height'] / 100) ** 2 + 1e-6)\n",
    "    df['ratio_Duration_Weight'] = df['Duration'] / (df['Weight'] + 1e-6)\n",
    "    df['ratio_Heart_Rate_Age'] = df['Heart_Rate'] / (df['Age'] + 1e-6)\n",
    "    \n",
    "    # 4. Sum features\n",
    "    df['sum_Weight_Duration'] = df['Weight'] + df['Duration']\n",
    "    df['sum_Height_Weight'] = df['Height'] + df['Weight']\n",
    "    df['sum_Age_Weight'] = df['Age'] + df['Weight']\n",
    "    \n",
    "    # 5. Difference features\n",
    "    df['diff_Height_Weight'] = df['Height'] - df['Weight']\n",
    "    df['diff_Age_Weight'] = df['Age'] - df['Weight']\n",
    "    df['diff_Duration_Heart_Rate'] = df['Duration'] - df['Heart_Rate']\n",
    "    \n",
    "    # 6. Binned features (equal-width bins)\n",
    "    for col in numeric_features:\n",
    "        df[f'{col}_binned'] = pd.cut(df[col], bins=9, labels=False)\n",
    "    \n",
    "    # 7. One-hot encode Sex\n",
    "    if 'Sex' in df.columns:\n",
    "        sex_dummies = pd.get_dummies(df['Sex'], prefix='Sex')\n",
    "        df = pd.concat([df, sex_dummies], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to train and test data\n",
    "print(\"Engineering features for training data...\")\n",
    "train_features = engineer_features(train_df)\n",
    "print(f\"Train features shape: {train_features.shape}\")\n",
    "\n",
    "print(\"Engineering features for test data...\")\n",
    "test_features = engineer_features(test_df)\n",
    "print(f\"Test features shape: {test_features.shape}\")\n",
    "\n",
    "# Define feature columns (exclude id and target)\n",
    "feature_cols = [col for col in train_features.columns if col not in ['id', 'Calories']]\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Feature columns: {feature_cols[:10]}...\")  # Show first 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f4d6e",
   "metadata": {},
   "source": [
    "## Prepare Data for XGBoost\n",
    "\n",
    "Target: residuals from NN stage (remaining patterns after Linear+NN)\n",
    "Features: engineered features above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target is residuals from NN stage\n",
    "y_residuals = residuals_nn['residual'].values\n",
    "\n",
    "# Features for XGBoost\n",
    "X_train = train_features[feature_cols]\n",
    "X_test = test_features[feature_cols]\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_residuals shape: {y_residuals.shape}\")\n",
    "print(f\"y_residuals range: [{y_residuals.min():.2f}, {y_residuals.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a835f8",
   "metadata": {},
   "source": [
    "## Cross-Validation Setup\n",
    "\n",
    "Use 5-fold CV with same seed as previous stages to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold CV\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Initialize arrays for OOF predictions\n",
    "oof_predictions = np.zeros(len(X_train))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "# Store fold scores\n",
    "fold_scores = []\n",
    "\n",
    "print(f\"Starting {n_splits}-fold CV...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaef40c",
   "metadata": {},
   "source": [
    "## Load OOF Predictions from Previous Stages\n",
    "\n",
    "Need Linear Regression and Neural Network OOF predictions to combine with XGBoost predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OOF predictions from Linear Regression (exp_005)\n",
    "lr_oof = pd.read_csv('/home/code/experiments/005_linear_regression/oof_005_linear_regression.csv')\n",
    "lr_predictions = lr_oof['Calories_pred'].values\n",
    "\n",
    "# Load OOF predictions from Neural Network (exp_006)  \n",
    "nn_oof = pd.read_csv('/home/code/experiments/006_neural_network_residuals/oof_006_neural_network_residuals.csv')\n",
    "nn_residual_predictions = nn_oof['residual_pred'].values\n",
    "\n",
    "print(f\"LR OOF shape: {lr_predictions.shape}\")\n",
    "print(f\"NN residual OOF shape: {nn_residual_predictions.shape}\")\n",
    "print(f\"LR predictions range: [{lr_predictions.min():.2f}, {lr_predictions.max():.2f}]\")\n",
    "print(f\"NN residual predictions range: [{nn_residual_predictions.min():.2f}, {nn_residual_predictions.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348ad37",
   "metadata": {},
   "source": [
    "## Train XGBoost on Residuals\n",
    "\n",
    "Train XGBoost to capture remaining patterns in residuals after Linear+NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069664d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost parameters (conservative, as recommended in strategy)\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.03,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'n_estimators': 800,\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': 4\n",
    "}\n",
    "\n",
    "print(\"Training XGBoost on residuals...\")\n",
    "print(f\"Parameters: {params}\")\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "    print(f\"\\nFold {fold}/{n_splits}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_residuals[train_idx], y_residuals[val_idx]\n",
    "    \n",
    "    # Train XGBoost model\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set (residuals)\n",
    "    val_residual_pred = model.predict(X_val)\n",
    "    oof_predictions[val_idx] = val_residual_pred\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_fold_pred = model.predict(X_test)\n",
    "    test_predictions += test_fold_pred / n_splits\n",
    "    \n",
    "    # Calculate fold score (RMSLE on combined predictions)\n",
    "    # Combined prediction = LR + NN residual + XGB residual\n",
    "    val_combined_pred = (lr_predictions[val_idx] + \n",
    "                        nn_residual_predictions[val_idx] + \n",
    "                        val_residual_pred)\n",
    "    \n",
    "    # Clip predictions to avoid log(negative)\n",
    "    val_combined_pred = np.clip(val_combined_pred, 1e-6, None)\n",
    "    \n",
    "    fold_score = np.sqrt(mean_squared_log_error(train_df['Calories'].iloc[val_idx], val_combined_pred))\n",
    "    fold_scores.append(fold_score)\n",
    "    \n",
    "    print(f\"  Fold {fold} RMSLE: {fold_score:.6f}\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"CV RMSLE: {np.mean(fold_scores):.6f} ± {np.std(fold_scores):.6f}\")\n",
    "print(f\"Fold scores: {fold_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c632714",
   "metadata": {},
   "source": [
    "## Analyze Results\n",
    "\n",
    "Compare performance to baseline and previous stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate combined OOF predictions\n",
    "oof_combined = lr_predictions + nn_residual_predictions + oof_predictions\n",
    "\n",
    "# Clip to avoid log issues\n",
    "oof_combined = np.clip(oof_combined, 1e-6, None)\n",
    "\n",
    "# Overall CV score\n",
    "cv_score = np.sqrt(mean_squared_log_error(train_df['Calories'], oof_combined))\n",
    "\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"FINAL PIPELINE RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Linear Regression only: 0.208762 (from exp_005)\")\n",
    "print(f\"Linear + NN:             0.201961 (from exp_006)\")\n",
    "print(f\"Linear + NN + XGBoost:   {cv_score:.6f}\")\n",
    "print(f\"Improvement from NN:     {0.208762 - 0.201961:.6f}\")\n",
    "print(f\"Improvement from XGB:    {0.201961 - cv_score:.6f}\")\n",
    "print(f\"Total improvement:       {0.208762 - cv_score:.6f}\")\n",
    "print(f\"\\nBaseline XGBoost:        0.020470 (from exp_000)\")\n",
    "print(f\"Pipeline vs Baseline:    {cv_score - 0.020470:.6f}\")\n",
    "\n",
    "# Check if we beat the baseline\n",
    "if cv_score < 0.02047:\n",
    "    print(f\"\\n✅ SUCCESS: Pipeline BEATS baseline by {0.02047 - cv_score:.6f}\")\n",
    "else:\n",
    "    print(f\"\\n❌ Pipeline does NOT beat baseline (difference: {cv_score - 0.02047:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2b0e3b",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save OOF predictions\n",
    "oof_df = pd.DataFrame({\n",
    "    'id': train_df['id'],\n",
    "    'Calories_actual': train_df['Calories'],\n",
    "    'Calories_pred': oof_combined,\n",
    "    'lr_pred': lr_predictions,\n",
    "    'nn_residual_pred': nn_residual_predictions,\n",
    "    'xgb_residual_pred': oof_predictions\n",
    "})\n",
    "\n",
    "oof_df.to_csv('/home/code/experiments/007_xgboost_on_nn_residuals/oof_007_xgboost_residuals.csv', index=False)\n",
    "print(f\"OOF predictions saved. Shape: {oof_df.shape}\")\n",
    "\n",
    "# Save test predictions (combined pipeline)\n",
    "test_combined_pred = (nn_oof['Calories_pred'].iloc[:len(test_df)].values +  # Use NN test predictions\n",
    "                      test_predictions)\n",
    "\n",
    "# For the linear component, we need to generate test predictions\n",
    "# Load linear regression model and predict on test\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Re-train linear model on full data for test predictions\n",
    "linear_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Sex_M', 'Sex_F']\n",
    "X_train_linear = train_features[linear_features]\n",
    "X_test_linear = test_features[linear_features]\n",
    "\n",
    "lr_model = Ridge(alpha=1.0, random_state=SEED)\n",
    "lr_model.fit(X_train_linear, train_df['Calories'])\n",
    "lr_test_pred = lr_model.predict(X_test_linear)\n",
    "\n",
    "# Final test predictions\n",
    "test_final_pred = lr_test_pred + test_predictions\n",
    "\n",
    "# Clip predictions\n",
    "test_final_pred = np.clip(test_final_pred, train_df['Calories'].min(), train_df['Calories'].max())\n",
    "\n",
    "# Save test predictions\n",
    "test_pred_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Calories_pred': test_final_pred\n",
    "})\n",
    "\n",
    "test_pred_df.to_csv('/home/code/experiments/007_xgboost_on_nn_residuals/test_007_xgboost_residuals.csv', index=False)\n",
    "print(f\"Test predictions saved. Shape: {test_pred_df.shape}\")\n",
    "print(f\"Test predictions range: [{test_final_pred.min():.2f}, {test_final_pred.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a963c",
   "metadata": {},
   "source": [
    "## Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Calories': test_final_pred\n",
    "})\n",
    "\n",
    "# Ensure proper format and clipping\n",
    "submission_df['Calories'] = submission_df['Calories'].clip(\n",
    "    lower=train_df['Calories'].min(), \n",
    "    upper=train_df['Calories'].max()\n",
    ")\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_007_xgboost_residuals.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(f\"\\nSubmission statistics:\")\n",
    "print(submission_df['Calories'].describe())\n",
    "\n",
    "# Show first few rows\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
