{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"},{"sourceId":9293783,"sourceType":"datasetVersion","datasetId":5626665},{"sourceId":12918935,"sourceType":"datasetVersion","datasetId":8174480},{"sourceId":259081663,"sourceType":"kernelVersion"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":214.764366,"end_time":"2025-01-29T01:21:19.245096","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-01-29T01:17:44.48073","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ğŸ”¥ Top 1%Solution|ğŸ†High-0.97772,esay is all you need!\n> Author: H-Z-Ning  \n> Date: 2025-08-25  \n> Dataset: [Kaggle Competition Page](https://www.kaggle.com/competitions/cmi-detect-behavior-with-sensor-data)\n\n---\n\n## ğŸ“š Table of Contents\n1. [Project Overview](#project-overview)  \n2. [Environment & Load Data](#environment--load-data)  \n3. [Feature Engineering](#feature-engineering)  \n4. [LightGBM Model Hyper-parameter Configuration](#lightgbm-model-hyper-parameter-configuration)  \n5. [LightGBM Training](#lightgbm-training)  \n6. [Submission](#submission)  \n7. [Future Work](#future-work)\n\n---\n\n### ğŸ§¾ Project Overview\nThe goal is to predict whether a bank client will subscribe to a term deposit (`y` = \"yes\"/\"no\") using the classic bank-marketing-full dataset.  \nKey steps: \nâ€¢ Engineer robust numeric & categorical features.  \nâ€¢ Train a tuned LightGBM model with target & frequency encoding\nâ€¢ Generate predictions for submission.\n\n---\n\n\n### ğŸ”§ Feature Engineering\nAll transformations are reproducible and leakage-safe.\n\n#### 1. ğŸ”¢ Numeric Feature Transformations\nâ€¢ call duration to avoid harsh splits & retain smooth trend. |\n\n#### 2. ğŸ§© Categorical Feature Combination\nâ€¢ Explicitly injects job Ã— education interaction.  \nâ€¢ High cardinality handled by target & frequency encoding.\n\n#### 3. ğŸ¯ Target & Frequency Encoding\nâ€¢ Target encoding supplies per-category success rates.  \nâ€¢ Frequency encoding provides sample-size hints to the model.\n\n#### 4. ğŸ”§ Type Conversion\nâ€¢ Ensures LightGBM/CatBoost use integer codes internallyâ€”fast & memory-efficient.  \nâ€¢ Prevents accidental one-hot blow-ups in scikit-learn pipelines.\n\n---\n\n### ğŸš€ LightGBM Model Hyper-parameter Configuration\n- LightGBM is fast, memory-efficient, and delivers state-of-the-art accuracy.\n\n---\n\n### ğŸ’»Future Work\nâ€¢ Hyper-parameter tuning: with Optuna or Hyperopt.  \nâ€¢ Stacking / Blending: with CatBoost & XGBoost.  \nâ€¢ Explainability: SHAP value inspection to understand key drivers.","metadata":{}},{"cell_type":"markdown","source":"## ğŸ“ŠLoad Data \n\nPlease load /kaggle/input/bank-marketing-dataset-full/bank-full.csv and use this data for training to improve accuracy.","metadata":{}},{"cell_type":"code","source":"%%time\n\nimport pandas as pd \nimport numpy as np\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nos.environ['PYTHONWARNINGS'] = 'ignore'\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n\n!git clone https://github.com/muhammadabdullah0303/AbdML\n\nimport sys\nsys.path.append('/kaggle/working/repository')\n\nfrom AbdML.main import AbdBase\nSEED = 42\n\n\n\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e8/train.csv')\nsample = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\ntest = pd.read_csv(\"/kaggle/input/playground-series-s5e8/test.csv\")\noriginal = pd.read_csv(\"/kaggle/input/bank-marketing-dataset-full/bank-full.csv\", sep=';')\n\ntrain = train.drop('id', axis=1)\ntest = test.drop('id', axis=1)\n\noriginal['y'] = original['y'].map({'no': 0, 'yes': 1})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:22.515257Z","iopub.execute_input":"2025-08-31T13:25:22.515601Z","iopub.status.idle":"2025-08-31T13:25:32.302951Z","shell.execute_reply.started":"2025-08-31T13:25:22.515572Z","shell.execute_reply":"2025-08-31T13:25:32.302154Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ“ˆ Eigenvalue Analysis","metadata":{}},{"cell_type":"markdown","source":"### ğŸ“Š Descriptive Statistics","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nsns.set(style=\"whitegrid\", font_scale=1.1)\n\n# 1) è®¡ç®—éœ€è¦çš„ç»Ÿè®¡é‡\nnum_cols = train.select_dtypes(include=['float64', 'int64']).columns   # åªä¿ç•™æ•°å€¼åˆ—\ndesc = train[num_cols].describe().T                                    # åŸºç¡€æè¿°ç»Ÿè®¡\ndesc['skew'] = train[num_cols].skew()                                  # ååº¦\ndesc['kurtosis'] = train[num_cols].kurt()                              # å³°åº¦\n\n# 2) æŠŠè¦ç”»çš„åˆ—æŒ‘å‡ºæ¥ï¼ˆä½ ä¹Ÿå¯ä»¥æŒ‰éœ€å¢åˆ ï¼‰\nplot_cols = ['mean', 'std', 'min', '25%', '50%', '75%', 'max', 'skew', 'kurtosis']\nplot_df = desc[plot_cols].reset_index().melt(id_vars='index',\n                                             var_name='stat',\n                                             value_name='value')\n\n# 3) ç”»å›¾\nfig, ax = plt.subplots(1, 2, figsize=(20, 6))\n\n# å·¦å›¾ï¼šåŸå§‹å°ºåº¦\nsns.barplot(data=plot_df[~plot_df['stat'].isin(['skew', 'kurtosis'])],\n            x='index', y='value', hue='stat', ax=ax[0])\nax[0].set_title('Descriptive Statistics (mean, std, quartiles â€¦)')\nax[0].tick_params(axis='x', rotation=90)\n\n# å³å›¾ï¼šskew & kurtosisï¼ˆé€šå¸¸æ•°å€¼è¾ƒå°ï¼Œå•å¼€ä¸€å›¾ï¼‰\nskew_kurt = plot_df[plot_df['stat'].isin(['skew', 'kurtosis'])]\nsns.barplot(data=skew_kurt, x='index', y='value', hue='stat', ax=ax[1])\nax[1].set_title('Skewness & Kurtosis')\nax[1].tick_params(axis='x', rotation=90)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:32.303764Z","iopub.execute_input":"2025-08-31T13:25:32.304039Z","iopub.status.idle":"2025-08-31T13:25:33.642428Z","shell.execute_reply.started":"2025-08-31T13:25:32.304002Z","shell.execute_reply":"2025-08-31T13:25:33.641748Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ğŸ¨ Data Distribution: Age and Balance","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\", category=FutureWarning,\n                        message=\".*use_inf_as_na.*\")\n\nplt.figure(figsize=(14, 6))\n\n\nplt.subplot(1, 2, 1)\nsns.histplot(train['age'], kde=True, color='skyblue', bins=20)\nplt.title('Distribution of Age')\n\n\nplt.subplot(1, 2, 2)\nsns.histplot(train['balance'], kde=True, color='orange', bins=20)\nplt.title('Distribution of Balance')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:33.644424Z","iopub.execute_input":"2025-08-31T13:25:33.644835Z","iopub.status.idle":"2025-08-31T13:25:39.861695Z","shell.execute_reply.started":"2025-08-31T13:25:33.644816Z","shell.execute_reply":"2025-08-31T13:25:39.860905Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ğŸ“ˆ Distribution of Target Variable (y)","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\nsns.countplot(x='y', data=train, palette='Set2')\nplt.title('Distribution of Target Variable (y)')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:39.862471Z","iopub.execute_input":"2025-08-31T13:25:39.862745Z","iopub.status.idle":"2025-08-31T13:25:40.033105Z","shell.execute_reply.started":"2025-08-31T13:25:39.862725Z","shell.execute_reply":"2025-08-31T13:25:40.032278Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ğŸ” Distribution of Categorical Features: job, marital, education, default, housing, loan, contact, month, poutcomeÂ¶","metadata":{}},{"cell_type":"code","source":"categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n\nplt.figure(figsize=(14, 12))\nfor i, column in enumerate(categorical_columns, 1):\n    plt.subplot(3, 3, i)\n    sns.countplot(x=column, data=train, palette='Set2')\n    plt.title(f'Distribution of {column}')\n    plt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:40.033948Z","iopub.execute_input":"2025-08-31T13:25:40.034269Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ğŸ”— Relationship Between Continuous Features and Target Variable (Age, Balance, Duration, and y)Â¶\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, 6))\n\n\nplt.subplot(1, 3, 1)\nsns.boxplot(x='y', y='age', data=train, palette='Set2')\nplt.title('Age vs Target Variable (y)')\n\n\nplt.subplot(1, 3, 2)\nsns.boxplot(x='y', y='balance', data=train, palette='Set2')\nplt.title('Balance vs Target Variable (y)')\n\n\nplt.subplot(1, 3, 3)\nsns.boxplot(x='y', y='duration', data=train, palette='Set2')\nplt.title('Duration vs Target Variable (y)')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:44.244641Z","iopub.execute_input":"2025-08-31T13:25:44.244896Z","iopub.status.idle":"2025-08-31T13:25:45.215169Z","shell.execute_reply.started":"2025-08-31T13:25:44.244874Z","shell.execute_reply":"2025-08-31T13:25:45.214564Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ğŸ“Š Relationship Between Target Variable and Other Features: Bar Chart","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, 6))\n\n\nsns.countplot(x='job', hue='y', data=train, palette='Set2')\nplt.title('Job vs Target Variable (y)')\nplt.xticks(rotation=45)\nplt.show()\n\n\nsns.countplot(x='marital', hue='y', data=train, palette='Set2')\nplt.title('Marital Status vs Target Variable (y)')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:45.215947Z","iopub.execute_input":"2025-08-31T13:25:45.21629Z","iopub.status.idle":"2025-08-31T13:25:46.492675Z","shell.execute_reply.started":"2025-08-31T13:25:45.216271Z","shell.execute_reply":"2025-08-31T13:25:46.491877Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ”§ **Feature Engineering!**\n\nBelow, the features will be processed as follows:\n- **Create new numeric features** (`balance_log`, `duration_sin/cos`, etc.)\n- **Create new categorical features** (`job_edu`, `contacted_before`)\n- **Apply mean-target encoding and count encoding to all categorical variables**\n- **Convert all categorical variables to pandas `category` dtype at once for efficient handling by LightGBM / CatBoost and similar libraries**","metadata":{}},{"cell_type":"markdown","source":"### **1. ğŸ”¢ Numeric Feature Transformations**\n\n- **1.1 balance_log = log1p(balance.clip(0))**  \n  â€¢ The original `balance` is heavily right-skewed: most clients have little money, while a few have huge balances.  \n  â€¢ `log1p` compresses the tail, bringing the distribution closer to normal and reducing the impact of extreme values while keeping zeros intact (`log1p(0)=0`).  \n  â€¢ Tree models tolerate skew, but the compressed scale yields more stable split points and easier interactions with other features.\n\n- **1.2 contacted_before = (pdays != -1).astype(int)**  \n  â€¢ `pdays = -1` means â€œnever contacted beforeâ€; any other value is days since the last contact.  \n  â€¢ Turning â€œhas been contacted or notâ€ into a clean 0/1 indicator directly captures client familiarity.  \n  â€¢ Linear models gain a straightforward dummy variable; tree models save one split.\n\n- **1.3 duration_sin / duration_cos**  \n  â€¢ `duration` is the length of the last phone call in seconds.  \n  â€¢ It is strongly correlated with purchase probability, yet raw values can lead tree models to over-fit by grouping all calls â‰¥ 400 s into one leaf.  \n  â€¢ Mapping 0â€“âˆ seconds to periodic [-1, 1] via sin/cos provides â€œsoftâ€ bins:  \n    â€“ 400 s â‡’ sin â‰ˆ 0, cos â‰ˆ -1  \n    â€“ 800 s â‡’ sin â‰ˆ 0, cos â‰ˆ 1  \n  â€¢ This keeps the â€œlonger calls â†’ higher conversionâ€ signal, avoids harsh cut-offs, and delivers smooth periodic inputs for neural nets.\n\n- Change\n\n  df['duration_sin'] = np.sin(2*np.pi * df['duration'] / 400)\n\n  \n  df['duration_cos'] = np.cos(2*np.pi * df['duration'] / 400)\n\n- to\n\n  df['duration_sin'] = np.sin(2*np.pi * df['duration'] / 800)\n\n  \n  df['duration_cos'] = np.cos(2*np.pi * df['duration'] / 800)\n  ","metadata":{}},{"cell_type":"code","source":"%%time\nCOLS = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n       'previous', 'poutcome',]\n\n\n\ndef NEW_FE(df):\n    \n    df['balance_log'] = np.log1p(df['balance'].clip(lower=0))\n    df['job_edu'] = df['job'].astype(str) + \"_\" + df['education'].astype(str)\n    df['contacted_before'] = (df['pdays'] != -1).astype(int)\n\n    df['duration_sin'] = np.sin(2*np.pi * df['duration'] / 800)\n    df['duration_cos'] = np.cos(2*np.pi * df['duration'] / 800)\n\n    return df\n\ntrain = NEW_FE(train)\ntest = NEW_FE(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:46.493358Z","iopub.execute_input":"2025-08-31T13:25:46.493604Z","iopub.status.idle":"2025-08-31T13:25:46.751167Z","shell.execute_reply.started":"2025-08-31T13:25:46.493585Z","shell.execute_reply":"2025-08-31T13:25:46.750424Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ğŸ» **Violin Plot: Balance vs Service Acceptance**  \nDraws a violin plot of log-transformed balance split by acceptance status, revealing both distribution shape and median differences between clients who accept (1) and decline (0) the deposit service.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.violinplot(x='y', y='balance_log', data=train)\nplt.title('Relationship between Log of Balance and Service Acceptance')\nplt.xlabel('Accepts Deposit Service (0=No, 1=Yes)')\nplt.ylabel('Log of Balance')\nplt.xticks([0, 1], ['No', 'Yes'])\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:46.753725Z","iopub.execute_input":"2025-08-31T13:25:46.753936Z","iopub.status.idle":"2025-08-31T13:25:48.203875Z","shell.execute_reply.started":"2025-08-31T13:25:46.753919Z","shell.execute_reply":"2025-08-31T13:25:48.203129Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ğŸ“ˆ **Stacked Bar of Job-Edu vs Acceptance**  \nGroups data by job & education, computes normalized y counts, then plots a stacked bar chart revealing how service acceptance rates vary across combined jobâ€“education categories.","metadata":{}},{"cell_type":"code","source":"job_edu_counts = train.groupby('job_edu')['y'].value_counts(normalize=True).unstack().fillna(0)\n\nplt.figure(figsize=(12, 7))\njob_edu_counts.plot(kind='bar', stacked=True, figsize=(12, 7))\nplt.title('Proportion of Customers Accepting the Service by Job and Education Level')\nplt.xlabel('Job and Education Level')\nplt.ylabel('Proportion')\nplt.xticks(rotation=45, ha='right')\nplt.legend(title='Accepts Service', labels=['No', 'Yes'])\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:48.205058Z","iopub.execute_input":"2025-08-31T13:25:48.205533Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To sort in descending order by the proportion of customers who accepted the service (the \"Yes\" column).","metadata":{}},{"cell_type":"code","source":"print(job_edu_counts.columns)","metadata":{"trusted":true,"execution":{"iopub.execute_input":"2025-08-31T13:25:49.347054Z","iopub.status.idle":"2025-08-31T13:25:49.3517Z","shell.execute_reply.started":"2025-08-31T13:25:49.347036Z","shell.execute_reply":"2025-08-31T13:25:49.350891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# è®¡ç®—å„ç»„ä¸­ y çš„æ¯”ä¾‹\njob_edu_counts = (\n    train.groupby('job_edu')['y']\n         .value_counts(normalize=True)\n         .unstack()\n         .fillna(0)\n)\n\n# æŒ‰â€œYesâ€åˆ—ä»é«˜åˆ°ä½æ’åº\njob_edu_counts = job_edu_counts.sort_values(by=1, ascending=False)\n\n# ç»˜å›¾\nplt.figure(figsize=(12, 7))\njob_edu_counts.plot(kind='bar', stacked=True, figsize=(12, 7))\nplt.title('Proportion of Customers Accepting the Service by Job and Education Level')\nplt.xlabel('Job and Education Level')\nplt.ylabel('Proportion')\nplt.xticks(rotation=45, ha='right')\nplt.legend(title='Accepts Service', labels=['No', 'Yes'])\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:49.352616Z","iopub.execute_input":"2025-08-31T13:25:49.352952Z","iopub.status.idle":"2025-08-31T13:25:50.230483Z","shell.execute_reply.started":"2025-08-31T13:25:49.352925Z","shell.execute_reply":"2025-08-31T13:25:50.229654Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ğŸ“Š **Crosstab & Bar Chart**  \nCreates an index-normalized crosstab of `contacted_before` vs `y`, then plots a bar chart showing the proportion of clients who accept the service, grouped by prior contact status.","metadata":{}},{"cell_type":"code","source":"# Create a crosstab to count the data\ncontact_y_crosstab = pd.crosstab(train['contacted_before'], train['y'], normalize='index')\n\ncontact_y_crosstab.plot(kind='bar', figsize=(8, 6))\nplt.title('Relationship Between Being Contacted Before and Service Acceptance')\nplt.xlabel('Contacted Before (0=No, 1=Yes)')\nplt.ylabel('Proportion')\nplt.xticks(rotation=0)\nplt.legend(title='Accepts Service', labels=['No', 'Yes'])\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:50.231237Z","iopub.execute_input":"2025-08-31T13:25:50.231537Z","iopub.status.idle":"2025-08-31T13:25:50.467812Z","shell.execute_reply.started":"2025-08-31T13:25:50.23151Z","shell.execute_reply":"2025-08-31T13:25:50.467125Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ğŸ¨ **KDE Distributions of Cyclical Duration Features by Target Class**  \nThe code plots side-by-side filled KDEs to compare how the sine and cosine transformations of duration differ between the two classes of the target variable y.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns, matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,3))\n\n# --- duration_sin ä¸ y çš„å…³ç³» ---\nplt.subplot(1,2,1)\nsns.kdeplot(data=train, x='duration_sin', hue='y', fill=True, palette={0:'#1f77b4', 1:'#ff7f0e'})\nplt.title('Distribution of duration_sin by y')\n# --- duration_cos ä¸ y çš„å…³ç³» ---\nplt.subplot(1,2,2)\nsns.kdeplot(data=train, x='duration_cos', hue='y', fill=True, palette={0:'#1f77b4', 1:'#ff7f0e'})\nplt.title('Distribution of duration_cos by y')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:50.468604Z","iopub.execute_input":"2025-08-31T13:25:50.468872Z","iopub.status.idle":"2025-08-31T13:25:56.148664Z","shell.execute_reply.started":"2025-08-31T13:25:50.468853Z","shell.execute_reply":"2025-08-31T13:25:56.147686Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2. ğŸ§© **Categorical Feature Combination**  \n- **job_edu = job + '_' + education**  \n  â€¢ Tree models can split on `job` or `education` separately, but rarely discover interactions like â€œblue-collar + primaryâ€ vs. â€œmanagement + universityâ€ on their own.  \n  â€¢ Manually concatenating the two categories gives the model an explicit second-order interaction; LightGBM can exploit this with a single split.  \n  â€¢ The trade-off is a higher cardinality, so frequency / target encoding (see next steps) is essential to prevent overfitting.","metadata":{}},{"cell_type":"code","source":"cat_cols = ['job','marital', \"education\", 'contact', 'poutcome','month','default','housing','loan','job_edu']\n\nmean = train['y'].mean() \n\nfor c in COLS:\n    new_col = f\"{c}_mean_target_orig\"\n    train[new_col] = train[c].map(original.groupby(c)['y'].mean())\n    train[new_col] = train[new_col].fillna(mean)\n    test[new_col] = test[c].map(original.groupby(c)['y'].mean())\n    test[new_col] = test[new_col].fillna(mean)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:56.149812Z","iopub.execute_input":"2025-08-31T13:25:56.150121Z","iopub.status.idle":"2025-08-31T13:25:56.872344Z","shell.execute_reply.started":"2025-08-31T13:25:56.150095Z","shell.execute_reply":"2025-08-31T13:25:56.871781Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3. ğŸ¯ **Target & Frequency Encoding**  \n```markdown\nfor c in COLS:\n    c_mean_target_orig = category_mean(y)   # target encoding\n    c_count          = category_count       # frequency encoding\n```\n\n- **3.1 Target Encoding**  \n  â€¢ Replace each category with its historical purchase rate in the training data.  \n  â€¢ Tree models gain an immediate, powerful signalâ€”e.g., â€œmanagement jobs convert at 25 %â€â€”speeding up splits; linear models can use it directly.  \n  â€¢ Solves the problem of high-cardinality features (e.g., `job_edu`) that are otherwise hard to learn.  \n  â€¢ Statistics are computed on the **full original dataset** and then mapped identically to train/test to avoid leakage; unseen categories are imputed with the global mean to prevent missing values.\n\n- **3.2 Frequency Encoding**  \n  â€¢ Add the raw occurrence count of each category as an extra numeric feature.  \n  â€¢ Rare categories have noisy target estimates; the model can down-weight them using the count (similar to giving LightGBM a â€œsample-size hintâ€).  \n  â€¢ In some cases, rare categories themselves indicate anomalies or premium clients, which frequency encoding can capture.\n```","metadata":{}},{"cell_type":"code","source":"for c in COLS:\n    mapping_count = original[c].value_counts()\n    train[f\"{c}_count\"] = train[c].map(mapping_count).fillna(0)\n    test[f\"{c}_count\"] = test[c].map(mapping_count).fillna(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:56.873047Z","iopub.execute_input":"2025-08-31T13:25:56.87323Z","iopub.status.idle":"2025-08-31T13:25:57.581019Z","shell.execute_reply.started":"2025-08-31T13:25:56.873215Z","shell.execute_reply":"2025-08-31T13:25:57.580035Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4. ğŸ”§ **Type Conversion**  \n- Convert `cat_cols` to pandas `category` dtype  \n  â€¢ LightGBM and CatBoost can natively handle integer-encoded categoriesâ€”faster execution and lower memory.  \n  â€¢ Prevents scikit-learn pipelines from exploding them into a huge sparse one-hot matrix.  \n  â€¢ Keeps missing-value and unseen-category handling consistent with library defaults.","metadata":{}},{"cell_type":"code","source":"def update(df):\n\n    for col in cat_cols:\n        df[col] = df[col].astype('category')\n    return df\n\ntrain = update(train)\ntest = update(test)\n\ntrain.head()","metadata":{"papermill":{"duration":7.909023,"end_time":"2025-01-29T01:18:06.027791","exception":false,"start_time":"2025-01-29T01:17:58.118768","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:57.582047Z","iopub.execute_input":"2025-08-31T13:25:57.582362Z","iopub.status.idle":"2025-08-31T13:25:58.140846Z","shell.execute_reply.started":"2025-08-31T13:25:57.582334Z","shell.execute_reply":"2025-08-31T13:25:58.140136Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸš€ LightGBM Model Hyper-parameter Configuration\n","metadata":{}},{"cell_type":"code","source":"# %%time\n\n# from sklearn.metrics import roc_auc_score\n\n# def ROC_AUC(y_true, y_pred_proba):\n#     return roc_auc_score(y_true, y_pred_proba)\n\n\n# cat_cols = ['job','marital', \"education\", 'contact', 'poutcome','month','default','housing','loan','job_edu']\n\n# encode_c = {'cat_c': cat_cols}\n\n# base = AbdBase(train_data=train, test_data=test, target_column='y',gpu=False, prob=True, test_prob=True,\n#                  problem_type=\"classification\", metric=\"custom\", seed=SEED,ohe_fe=False,ordinal_encoder=encode_c,\n#                  n_splits=5,early_stop=True,num_classes=2,cat_features=False,custom_metric=ROC_AUC,\n#                  fold_type='SKF')","metadata":{"papermill":{"duration":0.026039,"end_time":"2025-01-29T01:18:06.074895","exception":false,"start_time":"2025-01-29T01:18:06.048856","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:58.141694Z","iopub.execute_input":"2025-08-31T13:25:58.141938Z","iopub.status.idle":"2025-08-31T13:25:58.145564Z","shell.execute_reply.started":"2025-08-31T13:25:58.14192Z","shell.execute_reply":"2025-08-31T13:25:58.144925Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ LightGBM Training","metadata":{"papermill":{"duration":0.004799,"end_time":"2025-01-29T01:19:50.321451","exception":false,"start_time":"2025-01-29T01:19:50.316652","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# %%time\n\n# ParamsLgb = {'n_estimators': 40000, 'learning_rate': 0.0358306214515723, 'num_leaves': 228, 'max_depth': 6,\n#              'min_child_samples': 83, 'subsample': 0.8700304020753131, 'colsample_bytree': 0.6169349166144594,\n#              'reg_alpha': 3.700714656885025, 'reg_lambda': 4.709578317972932,\"objective\": \"binary\",\n#              \"metric\": \"binary_logloss\"}\n\n# results_Lgb_1 = base.Train_ML(ParamsLgb,'LGBM',e_stop=150)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:58.146243Z","iopub.execute_input":"2025-08-31T13:25:58.146496Z","iopub.status.idle":"2025-08-31T13:25:58.159432Z","shell.execute_reply.started":"2025-08-31T13:25:58.14648Z","shell.execute_reply":"2025-08-31T13:25:58.15872Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ“¤Submission","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nsub1 = pd.read_csv(\"/kaggle/input/s05e08data/submission_97763.csv\")\nsub2 = pd.read_csv(\"/kaggle/input/s05e08data/submission_97772.csv\")\nsub = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\ny = 0.3*sub1['y'] + 0.7*sub2['y']\n\nsub['y'] = y\n\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:58.160207Z","iopub.execute_input":"2025-08-31T13:25:58.160614Z","iopub.status.idle":"2025-08-31T13:25:58.970977Z","shell.execute_reply.started":"2025-08-31T13:25:58.160588Z","shell.execute_reply":"2025-08-31T13:25:58.970356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%time\n\n# def save_outputs(base_file_name, oof, pred):\n#     oof_df = pd.DataFrame(oof)\n#     pred_df = pd.DataFrame(pred)\n\n#     oof_df.to_csv(f\"{base_file_name}_OOF.csv\", index=False)\n#     pred_df.to_csv(f\"{base_file_name}_PREDS.csv\", index=False)\n\n# save_outputs('LGBM_0.9743',results_Lgb_1[0], results_Lgb_1[1])\n# mp = results_Lgb_1[1]\n\n# sample['y'] = mp\n# sample.to_csv('submission.csv', index=False)\n# sample.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:25:58.972124Z","iopub.execute_input":"2025-08-31T13:25:58.972346Z","iopub.status.idle":"2025-08-31T13:25:58.975605Z","shell.execute_reply.started":"2025-08-31T13:25:58.972321Z","shell.execute_reply":"2025-08-31T13:25:58.974833Z"}},"outputs":[],"execution_count":null}]}