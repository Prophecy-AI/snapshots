# Titanic Survival Prediction - Loop 4 Strategy

## Current Status
- Best CV score: 0.8373 from exp_003 (Threshold-Tuned Ensemble)
- Best LB score: 0.7847 from exp_003 (Threshold-Tuned Ensemble)
- CV-LB gap: +5.26% (consistent with previous experiments)
- Submissions used: 3/10 (5 remaining)

## Response to Evaluator
- Technical verdict was **TRUSTWORTHY** - execution is sound
- Evaluator's top priority: "SUBMIT THIS MODEL IMMEDIATELY to validate the survival rate hypothesis"
- **DONE - and it WORKED!** LB improved from 0.7775 to 0.7847 (+0.72%, 3 passengers)
- Key concerns raised:
  1. Threshold 0.55 gives best OOF accuracy (0.8418) but wasn't tested - **Valid, worth exploring**
  2. 15 predictions differ between Simple RF and Threshold-Tuned - **Analyzed: Threshold-Tuned won net +3**
  3. Target of 1.0 is impossible - **Acknowledged, focusing on realistic 0.80+ goal**
- **My synthesis**: The survival rate hypothesis is CONFIRMED. Lower survival rate (~31%) performs better on LB. The threshold tuning approach is validated. Now we need to push toward 0.80+ using stacking.

## Submission History Analysis
| Exp | Model | CV | LB | Gap | Survival Rate | Notes |
|-----|-------|-----|-----|-----|---------------|-------|
| exp_000 | XGBoost (13 features) | 0.8316 | 0.7584 | +7.32% | 37.6% | Overfitting |
| exp_001 | Simple RF (7 features) | 0.8238 | 0.7775 | +4.63% | 31.3% | Simpler = better |
| exp_003 | Threshold-Tuned Ensemble | 0.8373 | 0.7847 | +5.26% | 31.1% | **BEST LB** |

**Key Pattern**: Lower survival rate (~31%) consistently outperforms training rate (38.4%) on LB.

## Data Understanding
Reference notebooks:
- `exploration/eda.ipynb` - Feature distributions, survival patterns
- `exploration/evolver_loop4_lb_feedback.ipynb` - Latest LB feedback analysis
- `research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/` - Stacking approach (0.808 LB)

Key patterns:
- Sex is dominant: Female 74.2% survival vs Male 18.9%
- Pclass matters: 1st class 63%, 3rd class 24%
- 15 disagreements between RF and Threshold-Tuned: Threshold-Tuned correctly predicted more 3rd class Masters as survivors
- Test set appears to have lower survival rate than training (distribution shift)

## Recommended Approaches (Priority Order)

### Priority 1: Stacking with Out-of-Fold Predictions (HIGHEST PRIORITY)
**Rationale**: The stacking kernel achieved 0.808 LB (top 9%). This is a proven approach that could push us to 0.80+.

**Action**:
1. Use 5 base models: RF, ExtraTrees, AdaBoost, GradientBoosting, SVC
2. Generate out-of-fold predictions using 5-fold Stratified CV (CRITICAL: avoid leakage)
3. Stack predictions as features for XGBoost meta-learner
4. Use 8 features (with Title) for base models
5. XGBoost meta-learner: n_estimators=2000, max_depth=4, gamma=0.9, subsample=0.8
6. **IMPORTANT**: Apply threshold tuning to final predictions to achieve ~31% survival rate

**Implementation details from kernel**:
```python
# Base model parameters
rf_params = {'n_estimators': 500, 'max_depth': 6, 'min_samples_leaf': 2}
et_params = {'n_estimators': 500, 'max_depth': 8, 'min_samples_leaf': 2}
ada_params = {'n_estimators': 500, 'learning_rate': 0.75}
gb_params = {'n_estimators': 500, 'max_depth': 5, 'min_samples_leaf': 2}
svc_params = {'kernel': 'linear', 'C': 0.025}

# OOF prediction function
def get_oof(clf, x_train, y_train, x_test, kfold):
    oof_train = np.zeros((len(x_train),))
    oof_test = np.zeros((len(x_test),))
    oof_test_skf = np.empty((kfold.n_splits, len(x_test)))
    
    for i, (train_idx, val_idx) in enumerate(kfold.split(x_train, y_train)):
        clf.fit(x_train[train_idx], y_train[train_idx])
        oof_train[val_idx] = clf.predict(x_train[val_idx])
        oof_test_skf[i, :] = clf.predict(x_test)
    
    oof_test[:] = oof_test_skf.mean(axis=0)
    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)

# Stack OOF predictions
x_train_stack = np.concatenate((et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)
x_test_stack = np.concatenate((et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)

# XGBoost meta-learner
gbm = xgb.XGBClassifier(n_estimators=2000, max_depth=4, gamma=0.9, subsample=0.8, colsample_bytree=0.8)
```

**Expected outcome**: CV ~0.83-0.84, LB ~0.78-0.81

### Priority 2: Threshold 0.55 Test (Best OOF Accuracy)
**Rationale**: Evaluator noted threshold 0.55 gives best OOF accuracy (0.8418) with 144 survivors (34.4%). This is a middle ground worth testing.

**Action**:
1. Use same ensemble from exp_003
2. Apply threshold 0.55 instead of 0.608
3. This gives 144 survivors (34.4% survival rate) vs 130 (31.1%)
4. Submit to test whether OOF accuracy or survival rate matching is more predictive

**Expected outcome**: LB could be better or worse than 0.7847 - this tests the hypothesis

### Priority 3: Blending RF + Threshold-Tuned Ensemble
**Rationale**: Simple RF and Threshold-Tuned Ensemble agree on 96.4% of predictions but differ on 15. Blending might capture the best of both.

**Action**:
1. Load predictions from exp_001 (Simple RF) and exp_003 (Threshold-Tuned)
2. Average probabilities: (RF_prob + Thresh_prob) / 2
3. Apply threshold to achieve ~31% survival rate
4. Submit to test if blending helps

### Priority 4: Feature Engineering + Stacking
**Rationale**: Add FamilySize and Has_Cabin features to base models for stacking.

**Action**:
1. Add FamilySize = SibSp + Parch + 1
2. Add IsAlone = 1 if FamilySize == 1
3. Add Has_Cabin = 1 if Cabin is not null
4. Use these features in stacking approach

## What NOT to Try
- More complex models without stacking (will overfit)
- Hyperparameter tuning without calibration (survival rate matters more)
- Chasing CV score alone (CV 0.8373 â†’ LB 0.7847, gap is real)
- Features that increase CV-LB gap (Deck, Name_length)

## Validation Notes
- Use 5-fold Stratified CV with random_state=42 (consistent)
- **Trust survival rate pattern**: ~31% survival rate performs best on LB
- Expected LB = CV - 0.05 (based on recent submissions)
- Monitor survival rate: aim for ~31% (130 survivors)

## Target Reality Check
- **Impossible target**: 1.0 (100% accuracy)
- **State-of-the-art**: 81-85% LB
- **Current best LB**: 0.7847 (78.47%)
- **Realistic goal**: 0.80-0.81 (80-81%)
- **Gap to close**: 1.5-2.5% (6-10 passengers)

## Experiment Plan for Loop 4
1. **exp_004**: Stacking with 5 base models + XGBoost meta-learner + threshold tuning
2. **exp_005**: Threshold 0.55 on current ensemble (test OOF accuracy hypothesis)
3. **exp_006**: Blending RF + Threshold-Tuned Ensemble

## Submission Strategy
- 5 submissions remaining
- Submit stacking model (exp_004) - highest potential
- If stacking works (LB > 0.7847), iterate on stacking variations
- If stacking fails, try blending approaches
- Save 2 submissions for final ensemble tuning

## Critical Success Factors
1. **Stacking done correctly**: OOF predictions must avoid leakage
2. **Threshold calibration**: Apply to final predictions to achieve ~31% survival rate
3. **Model diversity**: Use different model types (tree-based, linear, SVM)
4. **Feature consistency**: Use same preprocessing across all base models
