# Titanic Survival Prediction - Loop 3 Strategy

## Current Status
- Best CV score: 0.8328 from exp_002 (Voting Ensemble)
- Best LB score: 0.7775 from exp_001 (Simple RF, 7 features)
- CV-LB gap: ~4.6% (exp_001)
- Submissions used: 2/10 (6 remaining)

## Response to Evaluator
- Technical verdict was **TRUSTWORTHY** - execution is sound
- Evaluator's top priority: "Submit this model AND a threshold-adjusted version to test the survival rate hypothesis"
- **I AGREE with this priority**. The evaluator correctly identified the critical pattern:
  - XGBoost (37.6% survival) → LB 0.7584
  - Simple RF (31.3% survival) → LB 0.7775
  - Ensemble (37.6% survival) → Expected LB ~0.76-0.77 (same as XGBoost)
- Key concerns raised:
  1. Survival rate (37.6%) matches XGBoost exactly - **CONFIRMED in my analysis**
  2. Ensemble wasn't submitted - **AGREE, we need LB feedback**
  3. Ensemble CV (0.8328) < GradientBoosting alone (0.8384) - **Valid concern**
  4. LogisticRegression (0.8103) dragging down ensemble - **Valid concern**
- **My synthesis**: The survival rate hypothesis is compelling. The 30 passengers where Simple RF differs from Ensemble are mostly 3rd class females (20F, 10M, 27 from Pclass 3). Ensemble predicts 28 of these as survivors while Simple RF predicts only 2. This suggests the test set has fewer 3rd class female survivors than training data.

## Critical Insight: Survival Rate Calibration
**The pattern is clear:**
- Training survival rate: 38.4%
- XGBoost predicted: 37.6% → LB 0.7584 (close to train rate)
- Simple RF predicted: 31.3% → LB 0.7775 (lower than train rate)
- Ensemble predicted: 37.6% → Expected LB ~0.76-0.77

**Hypothesis**: The test set has a LOWER survival rate than training. Models that predict fewer survivors perform better on LB.

## Data Understanding
Reference notebooks:
- `exploration/eda.ipynb` - Feature distributions, survival patterns
- `exploration/evolver_loop2_lb_feedback.ipynb` - CV-LB gap analysis
- `exploration/evolver_loop3_analysis.ipynb` - Survival rate hypothesis analysis
- `research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/` - Stacking approach (0.808 LB)

Key patterns:
- Sex is dominant: Female 74.2% survival vs Male 18.9%
- Pclass matters: 1st class 63%, 3rd class 24%
- The 30 different predictions between Simple RF and Ensemble are mostly 3rd class passengers
- Simple RF is more conservative on 3rd class female survival predictions

## Recommended Approaches (Priority Order)

### Priority 1: Threshold Tuning on Ensemble
**Rationale**: Test the survival rate hypothesis directly. If we can reduce the ensemble's survival rate from 37.6% to ~31% by adjusting the threshold from 0.5 to ~0.55-0.60, we should see LB improvement.

**Action**:
1. Load the ensemble's probability predictions (from exp_002)
2. Test thresholds: 0.52, 0.55, 0.58, 0.60
3. Find threshold that gives ~31% survival rate (~130 survivors)
4. Create submission with adjusted threshold
5. Submit to validate hypothesis

**Expected outcome**: If hypothesis correct, LB should improve to ~0.77-0.78

### Priority 2: Stacking with Out-of-Fold Predictions
**Rationale**: The stacking kernel achieved 0.808 LB (top 9%). This is a proven approach.

**Action**:
1. Use 5 base models: RF, ExtraTrees, AdaBoost, GradientBoosting, SVC
2. Generate out-of-fold predictions using 5-fold CV (CRITICAL: avoid leakage)
3. Stack predictions as features for XGBoost meta-learner
4. Use simple feature set (7-8 features) for base models
5. Tune XGBoost meta-learner: n_estimators=2000, max_depth=4, gamma=0.9

**Expected outcome**: CV ~0.83-0.84, LB ~0.78-0.81

### Priority 3: Weighted Voting Ensemble
**Rationale**: Current ensemble uses equal weights. GradientBoosting (0.8384) is much better than LogisticRegression (0.8103).

**Action**:
1. Remove LogisticRegression (weakest model)
2. Use weighted voting: GB=2, RF=1, SVC=1
3. Or use CV scores as weights: GB=0.8384, RF=0.8305, SVC=0.8350
4. Keep 8 features (with Title)

### Priority 4: Conservative Feature Engineering
**Rationale**: The Simple RF's success suggests simpler is better. But we might be missing signal.

**Action**:
1. Keep core features: Sex, Pclass, Age, SibSp, Parch, Fare, Embarked
2. Add Title (captures sex + social status)
3. Consider FamilySize = SibSp + Parch + 1
4. Avoid: Has_Cabin, Deck, Name_length (may add noise)

## What NOT to Try
- More complex models (will overfit more)
- More features without validation (13 features led to overfitting)
- Hyperparameter tuning before fixing calibration issue
- Chasing CV score (CV 0.8328 doesn't guarantee good LB)

## Validation Notes
- Use 5-fold Stratified CV (current approach is sound)
- **Trust survival rate pattern over CV score**
- Expected LB = CV - 0.04 to 0.05 (based on Simple RF gap)
- Monitor survival rate: aim for ~31% (130 survivors)

## Target Reality Check
- **Impossible target**: 1.0 (100% accuracy)
- **State-of-the-art**: 81-85% LB
- **Current best LB**: 0.7775 (77.75%)
- **Realistic goal**: 0.80-0.81 (80-81%)
- **Immediate goal**: Beat 0.7775 with threshold tuning or stacking

## Experiment Plan for Loop 3
1. **exp_003**: Threshold-adjusted ensemble (target ~31% survival rate)
2. **exp_004**: Stacking with 5 base models + XGBoost meta-learner
3. **exp_005**: Weighted voting ensemble (remove LR, weight by CV)

## Submission Strategy
- Submit exp_003 (threshold-adjusted) to test survival rate hypothesis
- If hypothesis confirmed, focus on calibration
- If hypothesis wrong, focus on stacking for higher ceiling
- Save 3-4 submissions for final ensemble tuning
