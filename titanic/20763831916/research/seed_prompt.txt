# Titanic Survival Prediction - Loop 3 Strategy

## Current Status
- Best CV score: 0.8316 from exp_000 (Baseline XGBoost)
- Best LB score: **0.7775** from exp_001 (Simple RF 7 features) ← NEW BEST
- CV-LB gap: +4.6% (improved from +7.3%)
- Submissions used: 2/10 (6 remaining)

## Response to Evaluator
- Technical verdict was **TRUSTWORTHY** - execution is sound
- Evaluator's top priority was "Submit exp_001 to validate hypothesis" - **DONE**
- **Result: Hypothesis VALIDATED** - simpler model improved LB by 2.5%
- Key concerns raised and responses:
  1. ✅ Experiment submitted - hypothesis validated
  2. Title feature dropped - **AGREE, should add back** (captures sex + social status)
  3. Survival rate too low (31.3%) - **Actually worked better** (baseline over-predicted)
  4. Ensemble methods unexplored - **AGREE, next priority**

## CRITICAL: Target is Impossible
**The target of 1.0 (100% accuracy) is fundamentally impossible for Titanic.**
- State-of-the-art: 81-85% accuracy
- Top 0.6% achieved 81.1% with voting ensemble
- Current best LB: 0.7775 (77.75%)
- Gap to realistic goal (0.80): 2.3%

**Realistic goals:**
- ✅ Beat 0.7584 (previous LB): ACHIEVED
- Reach 0.78-0.80: Next target
- Reach 0.81-0.82: Excellent (top 10%)

## What We Learned from LB Feedback
1. **Simpler models generalize better** - 7 features beat 13 features on LB
2. **Lower survival rate predictions worked** - 31.3% beat 37.6%
3. **CV is not reliable** - Lower CV (0.8238) achieved higher LB (0.7775)
4. **Feature engineering can hurt** - Too many features led to overfitting

## Data Understanding
Reference notebooks:
- `exploration/eda.ipynb` - Feature distributions, survival patterns
- `exploration/evolver_loop2_lb_feedback.ipynb` - LB feedback analysis

Key patterns to exploit:
- Sex is dominant: Female 74.2% survival vs Male 18.9%
- Pclass matters: 1st class 63%, 3rd class 24%
- Title captures both sex AND social status (Mr vs Master, Mrs vs Miss)
- Distribution shift: Embarked C is 24.4% in test vs 18.9% in train

## Recommended Approaches (Priority Order)

### Priority 1: Voting Ensemble with Simple Features + Title
**Rationale**: 
- Ensembles are proven to work (0.808 LB in kernels)
- Diversity reduces variance and overfitting
- Title adds valuable signal without adding noise

**Action**:
- Use 8 features: Pclass, Sex_Code, Age, SibSp, Parch, Fare, Embarked_Code, Title_Code
- Combine diverse models: RandomForest, LogisticRegression, GradientBoosting, SVC
- Use soft voting (probability averaging)
- Keep models simple (max_depth=5, regularization)
- Expected CV: ~0.82, Expected LB: ~0.78-0.80

### Priority 2: Multiple Seeds Ensemble
**Rationale**: TF-DF kernel shows ensembling 100 models with different seeds improves robustness

**Action**:
- Train same model architecture with different random seeds
- Average predictions
- Reduces variance from random initialization

### Priority 3: Stacking Ensemble
**Rationale**: More sophisticated than voting, achieved 0.808 LB in kernels.

**Action**:
- Level 1: RF, ExtraTrees, AdaBoost, GradientBoosting, SVC
- Generate out-of-fold predictions (5-fold CV)
- Level 2: LogisticRegression on stacked features (simpler meta-learner)
- Try after voting ensemble works

## What NOT to Try
- ❌ More than 10 features (proven to overfit)
- ❌ Complex single models (XGBoost with 13 features failed)
- ❌ Chasing CV score (CV 0.8316 gave LB 0.7584, CV 0.8238 gave LB 0.7775)
- ❌ High survival rate predictions (31.3% worked better than 37.6%)

## Validation Notes
- Use 5-fold Stratified CV (current approach is sound)
- **Expected CV-LB gap: 4-5%** (based on exp_001)
- A model with CV 0.82 might achieve LB 0.77-0.78
- Submit when CV improves OR when trying fundamentally different approach

## Experiment Plan for Loop 3

### exp_002: Voting Ensemble with Title
**Goal**: Combine diversity of multiple models with simple feature set

**Features (8 total)**:
- Pclass, Sex_Code, Age, SibSp, Parch, Fare, Embarked_Code, Title_Code

**Models**:
- RandomForestClassifier(n_estimators=100, max_depth=5)
- LogisticRegression(C=1.0)
- GradientBoostingClassifier(n_estimators=100, max_depth=3)
- SVC(kernel='rbf', probability=True, C=1.0)

**Ensemble**: VotingClassifier with soft voting

**Expected**: CV ~0.82, LB ~0.78-0.80

### exp_003 (if exp_002 works): Stacking Ensemble
**Goal**: Use out-of-fold predictions as meta-features

**Base models**: Same as exp_002 + ExtraTrees, AdaBoost
**Meta-learner**: LogisticRegression (simple to avoid overfitting)

## Key Success Factors
1. **Keep features simple** - 8 features maximum
2. **Use ensemble diversity** - Different model types
3. **Regularize heavily** - max_depth=5, min_samples_leaf=5
4. **Trust LB over CV** - CV is not reliable for this problem
5. **Don't over-predict survival** - 31-35% survival rate seems optimal
