# Titanic Survival Prediction - Loop 5 Strategy

## Current Status
- Best CV score: 0.8496 from exp_004 (Stacking at threshold 0.5) or 0.8373 (threshold 0.615)
- Best LB score: 0.7847 from exp_003 (Threshold-Tuned Ensemble)
- CV-LB gap: +5.3% (consistent across recent submissions)
- Submissions used: 3/10 (5 remaining)

## Response to Evaluator
- Technical verdict was **TRUSTWORTHY** - execution is sound, stacking implementation is correct
- Evaluator's top priority: "SUBMIT THE STACKING MODEL to validate whether it improves over threshold-tuned ensemble"
- **I AGREE** - We need LB feedback on stacking before deciding next steps
- Key concerns raised:
  1. Stacking CV at threshold 0.615 (0.8373) equals threshold-tuned CV - **Valid, this is a concern**
  2. The 15 different predictions are unanalyzed - **ANALYZED: 11F/4M, 13 from Pclass 3, mostly young females vs children/elderly**
  3. Threshold 0.5 not explored - **Valid, this is our backup if threshold 0.615 doesn't improve LB**
  4. Target of 1.0 is impossible - **Acknowledged, focusing on realistic 0.80+ goal**
- **My synthesis**: Submit stacking at threshold 0.615 first. If no improvement, we have two options:
  1. Try threshold 0.5 (higher CV, 133 survivors)
  2. Pivot to feature engineering (ticket prefixes, family survival rates)

## Submission History Analysis
| Exp | Model | CV | LB | Gap | Survival Rate | Notes |
|-----|-------|-----|-----|-----|---------------|-------|
| exp_000 | XGBoost (13 features) | 0.8316 | 0.7584 | +7.32% | 37.6% | Overfitting |
| exp_001 | Simple RF (7 features) | 0.8238 | 0.7775 | +4.63% | 31.3% | Simpler = better |
| exp_003 | Threshold-Tuned Ensemble | 0.8373 | 0.7847 | +5.26% | 31.1% | **BEST LB** |
| exp_004 | Stacking (threshold 0.615) | 0.8373 | ??? | ??? | 31.3% | **SUBMIT THIS** |

**Key Pattern**: Lower survival rate (~31%) consistently outperforms training rate (38.4%) on LB.

## Data Understanding
Reference notebooks:
- `exploration/eda.ipynb` - Feature distributions, survival patterns
- `exploration/evolver_loop5_analysis.ipynb` - Stacking vs Threshold-Tuned comparison
- `research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/` - Stacking approach (0.808 LB)

Key patterns:
- Sex is dominant: Female 74.2% survival vs Male 18.9%
- Pclass matters: 1st class 63%, 3rd class 24%
- 15 predictions differ between Stacking and Threshold-Tuned:
  - Stacking predicts survival for 8 more (mostly young 3rd class females, ages 18-36)
  - Threshold-Tuned predicts survival for 7 more (children/elderly, ages 0.83-64)
- Test set appears to have lower survival rate than training (distribution shift)

## Recommended Approaches (Priority Order)

### Priority 1: SUBMIT STACKING MODEL (exp_004)
**Rationale**: We need LB feedback to validate whether stacking improves over voting ensemble. The experiment is complete and ready.

**Action**:
1. Submit candidate_004.csv (stacking, threshold 0.615, 131 survivors, 31.3%)
2. Expected LB: ~0.78-0.79 (similar to threshold-tuned ensemble)
3. This tests: Does stacking improve over voting ensemble when both are calibrated to ~31% survival rate?

### Priority 2: If Stacking Improves (LB > 0.7847)
**Rationale**: Stacking adds value - continue refining the approach.

**Action**:
1. Add more diverse base models (LogisticRegression, neural network)
2. Try different meta-learners (LightGBM, CatBoost)
3. Experiment with probability averaging instead of prediction stacking

### Priority 3: If Stacking Doesn't Improve (LB â‰¤ 0.7847)
**Rationale**: Stacking doesn't add value at this calibration. Try alternative approaches.

**Option A: Threshold 0.5 Variant**
- Submit stacking at threshold 0.5 (CV 0.8496, 133 survivors, 31.8%)
- Tests whether higher CV matters more than exact survival rate matching
- This is still close to the target survival rate

**Option B: Feature Engineering**
- Add FamilySize = SibSp + Parch + 1
- Add IsAlone = 1 if FamilySize == 1
- Add Has_Cabin = 1 if Cabin is not null
- Add Ticket prefix extraction
- Add Family survival rate (from training data)

**Option C: Blending**
- Blend Simple RF + Threshold-Tuned + Stacking predictions
- Use weighted average of probabilities
- Apply threshold to achieve ~31% survival rate

### Priority 4: Analyze Differing Predictions
**Rationale**: Understanding who the models disagree on can inform feature engineering.

**Action**:
1. The 15 passengers where Stacking and Threshold-Tuned differ:
   - Stacking=1, Threshold=0: 8 passengers (mostly young 3rd class females)
   - Stacking=0, Threshold=1: 7 passengers (children/elderly)
2. After LB feedback, analyze which predictions were correct
3. Use this to inform feature engineering

## What NOT to Try
- More complex models without calibration (survival rate matters more than CV)
- Hyperparameter tuning without LB feedback (need to validate approach first)
- Features that increase CV-LB gap (Deck, Name_length showed overfitting)
- Chasing CV score alone (CV 0.8496 might not translate to better LB)

## Validation Notes
- Use 5-fold Stratified CV with random_state=42 (consistent)
- **Trust survival rate pattern**: ~31% survival rate performs best on LB
- Expected LB = CV - 0.05 (based on recent submissions)
- Monitor survival rate: aim for ~31% (130-133 survivors)

## Target Reality Check
- **Impossible target**: 1.0 (100% accuracy)
- **State-of-the-art**: 81-85% LB
- **Current best LB**: 0.7847 (78.47%)
- **Realistic goal**: 0.80-0.81 (80-81%)
- **Gap to close**: 1.5-2.5% (6-10 passengers)

## Experiment Plan for Loop 5
1. **SUBMIT exp_004** (Stacking, threshold 0.615) - Get LB feedback
2. Based on LB feedback:
   - If improved: Iterate on stacking (more base models, different meta-learner)
   - If not improved: Try threshold 0.5 variant OR pivot to feature engineering

## Submission Strategy
- 5 submissions remaining
- Submit stacking model (exp_004) - validate approach
- If stacking works (LB > 0.7847), iterate on stacking variations
- If stacking fails, try threshold 0.5 variant
- Save 2-3 submissions for final ensemble tuning

## Critical Success Factors
1. **Get LB feedback**: Submit stacking to validate approach
2. **Threshold calibration**: ~31% survival rate is key
3. **Model diversity**: If stacking doesn't help, try different approaches
4. **Feature engineering**: May be needed to break through plateau
