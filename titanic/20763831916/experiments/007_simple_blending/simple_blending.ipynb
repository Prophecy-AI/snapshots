{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61a38bc",
   "metadata": {},
   "source": [
    "# Simple Blending of Best LB Models\n",
    "\n",
    "## Goal: Combine exp_001 (Simple RF) and exp_003 (Threshold-Tuned Ensemble)\n",
    "\n",
    "## Key Learnings:\n",
    "1. **CV is NOT predictive of LB** - Higher CV often means worse LB\n",
    "2. **Simpler models work better** - 8 features beats 13 features\n",
    "3. **~31% survival rate is optimal** - All models with 130-131 survivors\n",
    "4. **Stacking and complex features overfit** - Both hurt LB\n",
    "\n",
    "## Submission History:\n",
    "| Exp | Model | CV | LB | Survivors |\n",
    "|-----|-------|-----|-----|----------|\n",
    "| exp_001 | Simple RF (7 features) | 0.8238 | 0.7775 | 131 |\n",
    "| exp_003 | Threshold-Tuned Ensemble (8 features) | 0.8373 | 0.7847 | 130 |\n",
    "\n",
    "## Approach:\n",
    "1. Re-train both models to get OOF probabilities\n",
    "2. Simple average: 0.5 * RF_prob + 0.5 * Ensemble_prob\n",
    "3. Apply threshold for ~31% survival rate (130 survivors)\n",
    "4. Compare predictions with exp_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b684288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4997ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for exp_001 (Simple RF - 7 features, NO Title)\n",
    "def preprocess_simple(train_df, test_df):\n",
    "    train_data = train_df.copy()\n",
    "    test_data = test_df.copy()\n",
    "    \n",
    "    # Sex encoding\n",
    "    train_data['Sex_Code'] = (train_data['Sex'] == 'male').astype(int)\n",
    "    test_data['Sex_Code'] = (test_data['Sex'] == 'male').astype(int)\n",
    "    \n",
    "    # Embarked\n",
    "    train_data['Embarked'] = train_data['Embarked'].fillna('S')\n",
    "    test_data['Embarked'] = test_data['Embarked'].fillna('S')\n",
    "    embarked_map = {'S': 0, 'C': 1, 'Q': 2}\n",
    "    train_data['Embarked_Code'] = train_data['Embarked'].map(embarked_map)\n",
    "    test_data['Embarked_Code'] = test_data['Embarked'].map(embarked_map)\n",
    "    \n",
    "    # Fare imputation (from train only)\n",
    "    train_fare_median = train_data['Fare'].median()\n",
    "    train_data['Fare'] = train_data['Fare'].fillna(train_fare_median)\n",
    "    test_data['Fare'] = test_data['Fare'].fillna(train_fare_median)\n",
    "    \n",
    "    # Age imputation (from train only)\n",
    "    train_age_median = train_data['Age'].median()\n",
    "    train_data['Age'] = train_data['Age'].fillna(train_age_median)\n",
    "    test_data['Age'] = test_data['Age'].fillna(train_age_median)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "train_simple, test_simple = preprocess_simple(train, test)\n",
    "print(\"Simple preprocessing complete (7 features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for exp_003 (Threshold-Tuned Ensemble - 8 features, WITH Title)\n",
    "def preprocess_with_title(train_df, test_df):\n",
    "    train_data = train_df.copy()\n",
    "    test_data = test_df.copy()\n",
    "    \n",
    "    # Title extraction\n",
    "    for df in [train_data, test_data]:\n",
    "        df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "        title_mapping = {\n",
    "            'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "            'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "            'Lady': 'Rare', 'Countess': 'Rare', 'Capt': 'Rare', 'Col': 'Rare',\n",
    "            'Don': 'Rare', 'Dr': 'Rare', 'Major': 'Rare', 'Rev': 'Rare',\n",
    "            'Sir': 'Rare', 'Jonkheer': 'Rare', 'Dona': 'Rare'\n",
    "        }\n",
    "        df['Title'] = df['Title'].map(title_mapping).fillna('Rare')\n",
    "    \n",
    "    title_order = ['Mr', 'Miss', 'Mrs', 'Master', 'Rare']\n",
    "    title_map = {t: i for i, t in enumerate(title_order)}\n",
    "    train_data['Title_Code'] = train_data['Title'].map(title_map)\n",
    "    test_data['Title_Code'] = test_data['Title'].map(title_map)\n",
    "    \n",
    "    # Sex encoding\n",
    "    train_data['Sex_Code'] = (train_data['Sex'] == 'male').astype(int)\n",
    "    test_data['Sex_Code'] = (test_data['Sex'] == 'male').astype(int)\n",
    "    \n",
    "    # Embarked\n",
    "    train_data['Embarked'] = train_data['Embarked'].fillna('S')\n",
    "    test_data['Embarked'] = test_data['Embarked'].fillna('S')\n",
    "    embarked_map = {'S': 0, 'C': 1, 'Q': 2}\n",
    "    train_data['Embarked_Code'] = train_data['Embarked'].map(embarked_map)\n",
    "    test_data['Embarked_Code'] = test_data['Embarked'].map(embarked_map)\n",
    "    \n",
    "    # Fare imputation (from train only)\n",
    "    train_fare_median = train_data['Fare'].median()\n",
    "    train_data['Fare'] = train_data['Fare'].fillna(train_fare_median)\n",
    "    test_data['Fare'] = test_data['Fare'].fillna(train_fare_median)\n",
    "    \n",
    "    # Age imputation (from train only, by Title/Pclass)\n",
    "    age_medians = train_data.groupby(['Title', 'Pclass'])['Age'].median()\n",
    "    train_age_median = train_data['Age'].median()\n",
    "    \n",
    "    def fill_age(row, medians, fallback):\n",
    "        if pd.isna(row['Age']):\n",
    "            try:\n",
    "                return medians[(row['Title'], row['Pclass'])]\n",
    "            except KeyError:\n",
    "                return fallback\n",
    "        return row['Age']\n",
    "    \n",
    "    train_data['Age'] = train_data.apply(lambda x: fill_age(x, age_medians, train_age_median), axis=1)\n",
    "    test_data['Age'] = test_data.apply(lambda x: fill_age(x, age_medians, train_age_median), axis=1)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "train_title, test_title = preprocess_with_title(train, test)\n",
    "print(\"Title preprocessing complete (8 features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "# exp_001: 7 features (no Title)\n",
    "features_simple = ['Pclass', 'Sex_Code', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Code']\n",
    "\n",
    "# exp_003: 8 features (with Title)\n",
    "features_title = ['Pclass', 'Sex_Code', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Code', 'Title_Code']\n",
    "\n",
    "X_simple = train_simple[features_simple].values\n",
    "X_title = train_title[features_title].values\n",
    "y = train['Survived'].values\n",
    "\n",
    "X_test_simple = test_simple[features_simple].values\n",
    "X_test_title = test_title[features_title].values\n",
    "test_ids = test['PassengerId'].values\n",
    "\n",
    "print(f\"Simple features (7): {features_simple}\")\n",
    "print(f\"Title features (8): {features_title}\")\n",
    "print(f\"\\nX_simple shape: {X_simple.shape}\")\n",
    "print(f\"X_title shape: {X_title.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "# exp_001: Simple RF\n",
    "def create_simple_rf():\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=5, min_samples_leaf=5,\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "\n",
    "# exp_003: Voting Ensemble\n",
    "def create_voting_ensemble():\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=5, min_samples_leaf=5,\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "    lr = LogisticRegression(C=1.0, max_iter=1000, random_state=42)\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=100, max_depth=3, learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    svc = SVC(kernel='rbf', C=1.0, probability=True, random_state=42)\n",
    "    \n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[('rf', rf), ('lr', lr), ('gb', gb), ('svc', svc)],\n",
    "        voting='soft'\n",
    "    )\n",
    "    return ensemble\n",
    "\n",
    "print(\"Models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e36893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate OOF probabilities for both models\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Model 1: Simple RF (7 features)\n",
    "print(\"Training Simple RF (exp_001 style)...\")\n",
    "oof_probs_rf = np.zeros(len(X_simple))\n",
    "test_probs_rf = np.zeros(len(X_test_simple))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_simple, y)):\n",
    "    X_train, X_val = X_simple[train_idx], X_simple[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = create_simple_rf()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    oof_probs_rf[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_probs_rf += model.predict_proba(X_test_simple)[:, 1] / kfold.n_splits\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_probs_rf[val_idx] >= 0.5).astype(int))\n",
    "    print(f\"  Fold {fold+1}: {fold_acc:.4f}\")\n",
    "\n",
    "rf_cv = accuracy_score(y, (oof_probs_rf >= 0.5).astype(int))\n",
    "print(f\"  Simple RF CV: {rf_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d976e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Voting Ensemble (8 features)\n",
    "print(\"\\nTraining Voting Ensemble (exp_003 style)...\")\n",
    "oof_probs_ens = np.zeros(len(X_title))\n",
    "test_probs_ens = np.zeros(len(X_test_title))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_title, y)):\n",
    "    X_train, X_val = X_title[train_idx], X_title[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Scale for SVC and LR\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test_title)\n",
    "    \n",
    "    model = create_voting_ensemble()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    oof_probs_ens[val_idx] = model.predict_proba(X_val_scaled)[:, 1]\n",
    "    test_probs_ens += model.predict_proba(X_test_scaled)[:, 1] / kfold.n_splits\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_probs_ens[val_idx] >= 0.5).astype(int))\n",
    "    print(f\"  Fold {fold+1}: {fold_acc:.4f}\")\n",
    "\n",
    "ens_cv = accuracy_score(y, (oof_probs_ens >= 0.5).astype(int))\n",
    "print(f\"  Voting Ensemble CV: {ens_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Blending: Average probabilities\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SIMPLE BLENDING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test different blend weights\n",
    "weights_to_test = [(0.5, 0.5), (0.4, 0.6), (0.3, 0.7), (0.6, 0.4)]\n",
    "\n",
    "print(f\"\\n{'Weight (RF, Ens)':<20} {'OOF CV':<12} {'Test Survivors':<15}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for w_rf, w_ens in weights_to_test:\n",
    "    oof_blend = w_rf * oof_probs_rf + w_ens * oof_probs_ens\n",
    "    test_blend = w_rf * test_probs_rf + w_ens * test_probs_ens\n",
    "    \n",
    "    oof_preds = (oof_blend >= 0.5).astype(int)\n",
    "    test_preds = (test_blend >= 0.5).astype(int)\n",
    "    \n",
    "    cv = accuracy_score(y, oof_preds)\n",
    "    survivors = test_preds.sum()\n",
    "    \n",
    "    print(f\"({w_rf:.1f}, {w_ens:.1f}){'':<12} {cv:.4f}{'':<6} {survivors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a447ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 50-50 blend and apply threshold tuning\n",
    "blend_oof = 0.5 * oof_probs_rf + 0.5 * oof_probs_ens\n",
    "blend_test = 0.5 * test_probs_rf + 0.5 * test_probs_ens\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"THRESHOLD ANALYSIS FOR 50-50 BLEND\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "thresholds = [0.45, 0.48, 0.50, 0.52, 0.55, 0.58, 0.60, 0.62, 0.65]\n",
    "\n",
    "print(f\"\\n{'Threshold':<12} {'Survivors':<12} {'Survival Rate':<15} {'OOF Accuracy':<15}\")\n",
    "print(\"-\"*55)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    test_preds = (blend_test >= thresh).astype(int)\n",
    "    oof_preds = (blend_oof >= thresh).astype(int)\n",
    "    survivors = test_preds.sum()\n",
    "    survival_rate = test_preds.mean()\n",
    "    oof_acc = accuracy_score(y, oof_preds)\n",
    "    \n",
    "    marker = \"\"\n",
    "    if 128 <= survivors <= 132:\n",
    "        marker = \" <- TARGET\"\n",
    "    \n",
    "    print(f\"{thresh:<12.2f} {survivors:<12} {survival_rate:<15.3f} {oof_acc:<15.4f}{marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold for ~130 survivors\n",
    "target_survivors = 130\n",
    "\n",
    "low, high = 0.4, 0.7\n",
    "while high - low > 0.001:\n",
    "    mid = (low + high) / 2\n",
    "    survivors = (blend_test >= mid).sum()\n",
    "    if survivors > target_survivors:\n",
    "        low = mid\n",
    "    else:\n",
    "        high = mid\n",
    "\n",
    "optimal_threshold = (low + high) / 2\n",
    "optimal_survivors = (blend_test >= optimal_threshold).sum()\n",
    "\n",
    "print(f\"\\nOptimal threshold for ~{target_survivors} survivors: {optimal_threshold:.3f}\")\n",
    "print(f\"Actual survivors: {optimal_survivors}\")\n",
    "print(f\"Survival rate: {optimal_survivors/len(blend_test):.3f}\")\n",
    "\n",
    "# Calculate OOF accuracy at optimal threshold\n",
    "oof_preds_opt = (blend_oof >= optimal_threshold).astype(int)\n",
    "oof_acc_opt = accuracy_score(y, oof_preds_opt)\n",
    "print(f\"OOF accuracy at optimal threshold: {oof_acc_opt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b05b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with exp_003 (best LB)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON WITH BEST LB (exp_003)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load exp_003 predictions\n",
    "exp_003 = pd.read_csv('/home/code/submission_candidates/candidate_003.csv')\n",
    "\n",
    "# Create blend predictions\n",
    "blend_preds = (blend_test >= optimal_threshold).astype(int)\n",
    "\n",
    "# Compare\n",
    "agreement = (exp_003['Survived'].values == blend_preds).sum()\n",
    "disagreement = len(blend_preds) - agreement\n",
    "\n",
    "print(f\"\\nAgreement with exp_003: {agreement}/{len(blend_preds)} ({agreement/len(blend_preds)*100:.1f}%)\")\n",
    "print(f\"Disagreement: {disagreement} passengers\")\n",
    "\n",
    "# Analyze disagreements\n",
    "if disagreement > 0:\n",
    "    diff_mask = exp_003['Survived'].values != blend_preds\n",
    "    diff_ids = test_ids[diff_mask]\n",
    "    exp_003_vals = exp_003['Survived'].values[diff_mask]\n",
    "    blend_vals = blend_preds[diff_mask]\n",
    "    \n",
    "    print(f\"\\nDisagreements:\")\n",
    "    print(f\"  exp_003=1, blend=0: {((exp_003_vals == 1) & (blend_vals == 0)).sum()}\")\n",
    "    print(f\"  exp_003=0, blend=1: {((exp_003_vals == 0) & (blend_vals == 1)).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5683fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also compare with exp_001 (Simple RF)\n",
    "exp_001 = pd.read_csv('/home/code/submission_candidates/candidate_001.csv')\n",
    "\n",
    "agreement_001 = (exp_001['Survived'].values == blend_preds).sum()\n",
    "print(f\"\\nAgreement with exp_001: {agreement_001}/{len(blend_preds)} ({agreement_001/len(blend_preds)*100:.1f}%)\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSimple RF (exp_001): CV {rf_cv:.4f}, LB 0.7775\")\n",
    "print(f\"Voting Ensemble (exp_003): CV {ens_cv:.4f}, LB 0.7847\")\n",
    "print(f\"50-50 Blend: CV {oof_acc_opt:.4f}\")\n",
    "print(f\"\\nBlend survivors: {optimal_survivors} ({optimal_survivors/len(blend_test)*100:.1f}%)\")\n",
    "print(f\"exp_003 survivors: {exp_003['Survived'].sum()} ({exp_003['Survived'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_ids,\n",
    "    'Survived': blend_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} rows\")\n",
    "print(f\"\\nSurvived distribution:\")\n",
    "print(submission['Survived'].value_counts())\n",
    "print(f\"\\nSurvival rate: {submission['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95668628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT SUMMARY: Simple Blending\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nApproach:\")\n",
    "print(f\"  - Blend Simple RF (7 features) + Voting Ensemble (8 features)\")\n",
    "print(f\"  - Weight: 50% RF + 50% Ensemble\")\n",
    "print(f\"  - Threshold: {optimal_threshold:.3f}\")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Simple RF CV: {rf_cv:.4f}\")\n",
    "print(f\"  Voting Ensemble CV: {ens_cv:.4f}\")\n",
    "print(f\"  Blend CV (threshold {optimal_threshold:.3f}): {oof_acc_opt:.4f}\")\n",
    "\n",
    "print(f\"\\nSubmission:\")\n",
    "print(f\"  Survivors: {submission['Survived'].sum()} ({submission['Survived'].mean()*100:.1f}%)\")\n",
    "print(f\"  Differs from exp_003 by: {disagreement} passengers\")\n",
    "\n",
    "print(f\"\\nComparison to previous best:\")\n",
    "print(f\"  exp_003: CV 0.8373, LB 0.7847, 130 survivors\")\n",
    "print(f\"  Blend:   CV {oof_acc_opt:.4f}, ?? LB, {submission['Survived'].sum()} survivors\")\n",
    "\n",
    "if oof_acc_opt >= 0.8373 and disagreement > 0:\n",
    "    print(f\"\\n✓ CV similar/better AND predictions differ - worth considering\")\n",
    "else:\n",
    "    print(f\"\\n⚠ CV lower or predictions same as exp_003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save candidate\n",
    "import shutil\n",
    "shutil.copy('/home/submission/submission.csv', '/home/code/submission_candidates/candidate_006.csv')\n",
    "print(\"Saved candidate_006.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
