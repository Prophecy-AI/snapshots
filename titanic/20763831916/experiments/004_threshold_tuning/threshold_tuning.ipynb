{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "259b0703",
   "metadata": {},
   "source": [
    "# Threshold Tuning on Ensemble Predictions\n",
    "\n",
    "## Hypothesis: Lower survival rate predictions perform better on LB\n",
    "\n",
    "Evidence:\n",
    "- XGBoost (37.6% survival) → LB 0.7584\n",
    "- Simple RF (31.3% survival) → LB 0.7775 (BEST)\n",
    "- Ensemble (37.6% survival) → Expected LB ~0.76-0.77\n",
    "\n",
    "## Goal: Adjust threshold to reduce survival rate from 37.6% to ~31%\n",
    "\n",
    "This tests whether the test set has a lower survival rate than training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70303403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Training survival rate: {train['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a309b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse preprocessing from exp_002\n",
    "def preprocess_with_title(train_df, test_df):\n",
    "    \"\"\"Preprocessing with Title feature\"\"\"\n",
    "    train_data = train_df.copy()\n",
    "    test_data = test_df.copy()\n",
    "    \n",
    "    # Title extraction\n",
    "    for df in [train_data, test_data]:\n",
    "        df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "        title_mapping = {\n",
    "            'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "            'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "            'Lady': 'Rare', 'Countess': 'Rare', 'Capt': 'Rare', 'Col': 'Rare',\n",
    "            'Don': 'Rare', 'Dr': 'Rare', 'Major': 'Rare', 'Rev': 'Rare',\n",
    "            'Sir': 'Rare', 'Jonkheer': 'Rare', 'Dona': 'Rare'\n",
    "        }\n",
    "        df['Title'] = df['Title'].map(title_mapping).fillna('Rare')\n",
    "    \n",
    "    # Title encoding\n",
    "    title_order = ['Mr', 'Miss', 'Mrs', 'Master', 'Rare']\n",
    "    title_map = {t: i for i, t in enumerate(title_order)}\n",
    "    train_data['Title_Code'] = train_data['Title'].map(title_map)\n",
    "    test_data['Title_Code'] = test_data['Title'].map(title_map)\n",
    "    \n",
    "    # Sex encoding\n",
    "    train_data['Sex_Code'] = (train_data['Sex'] == 'male').astype(int)\n",
    "    test_data['Sex_Code'] = (test_data['Sex'] == 'male').astype(int)\n",
    "    \n",
    "    # Embarked\n",
    "    train_data['Embarked'] = train_data['Embarked'].fillna('S')\n",
    "    test_data['Embarked'] = test_data['Embarked'].fillna('S')\n",
    "    embarked_map = {'S': 0, 'C': 1, 'Q': 2}\n",
    "    train_data['Embarked_Code'] = train_data['Embarked'].map(embarked_map)\n",
    "    test_data['Embarked_Code'] = test_data['Embarked'].map(embarked_map)\n",
    "    \n",
    "    # Fare\n",
    "    train_fare_median = train_data['Fare'].median()\n",
    "    train_data['Fare'] = train_data['Fare'].fillna(train_fare_median)\n",
    "    test_data['Fare'] = test_data['Fare'].fillna(train_fare_median)\n",
    "    \n",
    "    # Age (from train only)\n",
    "    age_medians = train_data.groupby(['Title', 'Pclass'])['Age'].median()\n",
    "    train_age_median = train_data['Age'].median()\n",
    "    \n",
    "    def fill_age(row, medians, fallback):\n",
    "        if pd.isna(row['Age']):\n",
    "            try:\n",
    "                return medians[(row['Title'], row['Pclass'])]\n",
    "            except KeyError:\n",
    "                return fallback\n",
    "        return row['Age']\n",
    "    \n",
    "    train_data['Age'] = train_data.apply(lambda x: fill_age(x, age_medians, train_age_median), axis=1)\n",
    "    test_data['Age'] = test_data.apply(lambda x: fill_age(x, age_medians, train_age_median), axis=1)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "train_processed, test_processed = preprocess_with_title(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "feature_cols = ['Pclass', 'Sex_Code', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Code', 'Title_Code']\n",
    "\n",
    "X = train_processed[feature_cols].values\n",
    "y = train_processed['Survived'].values\n",
    "X_test = test_processed[feature_cols].values\n",
    "test_ids = test_processed['PassengerId'].values\n",
    "\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"X shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ed31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ensemble and get probability predictions\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define models\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_leaf=5, random_state=42, n_jobs=-1)\n",
    "lr = LogisticRegression(C=1.0, max_iter=1000, random_state=42)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, min_samples_leaf=5, random_state=42)\n",
    "svc = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('lr', lr), ('gb', gb), ('svc', svc)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Get OOF predictions and test predictions\n",
    "oof_probs = np.zeros(len(X))\n",
    "test_probs = np.zeros(len(X_test))\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    voting_clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    oof_probs[val_idx] = voting_clf.predict_proba(X_val_scaled)[:, 1]\n",
    "    test_probs += voting_clf.predict_proba(X_test_scaled)[:, 1] / kfold.n_splits\n",
    "    \n",
    "    val_pred = (oof_probs[val_idx] >= 0.5).astype(int)\n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_acc)\n",
    "    print(f\"Fold {fold+1}: {fold_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nCV Accuracy (threshold=0.5): {accuracy_score(y, (oof_probs >= 0.5).astype(int)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a391aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze probability distribution\n",
    "print(\"Test Probability Distribution:\")\n",
    "print(f\"  Mean: {test_probs.mean():.3f}\")\n",
    "print(f\"  Std: {test_probs.std():.3f}\")\n",
    "print(f\"  Min: {test_probs.min():.3f}\")\n",
    "print(f\"  Max: {test_probs.max():.3f}\")\n",
    "print(f\"\\nPercentiles:\")\n",
    "for p in [10, 25, 50, 75, 90]:\n",
    "    print(f\"  {p}th: {np.percentile(test_probs, p):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1567d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different thresholds\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"THRESHOLD ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "thresholds = [0.45, 0.50, 0.52, 0.55, 0.58, 0.60, 0.62, 0.65]\n",
    "\n",
    "print(f\"\\n{'Threshold':<12} {'Survivors':<12} {'Survival Rate':<15} {'OOF Accuracy':<15}\")\n",
    "print(\"-\"*55)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    test_preds = (test_probs >= thresh).astype(int)\n",
    "    oof_preds = (oof_probs >= thresh).astype(int)\n",
    "    survivors = test_preds.sum()\n",
    "    survival_rate = test_preds.mean()\n",
    "    oof_acc = accuracy_score(y, oof_preds)\n",
    "    \n",
    "    # Highlight target range\n",
    "    marker = \"\" \n",
    "    if 125 <= survivors <= 135:  # Target ~31% survival rate\n",
    "        marker = \" ← TARGET RANGE\"\n",
    "    \n",
    "    print(f\"{thresh:<12.2f} {survivors:<12} {survival_rate:<15.3f} {oof_acc:<15.4f}{marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc09c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold for ~31% survival rate (130 survivors)\n",
    "target_survivors = 131  # Same as Simple RF\n",
    "\n",
    "# Binary search for threshold\n",
    "low, high = 0.4, 0.7\n",
    "while high - low > 0.001:\n",
    "    mid = (low + high) / 2\n",
    "    survivors = (test_probs >= mid).sum()\n",
    "    if survivors > target_survivors:\n",
    "        low = mid\n",
    "    else:\n",
    "        high = mid\n",
    "\n",
    "optimal_threshold = (low + high) / 2\n",
    "optimal_survivors = (test_probs >= optimal_threshold).sum()\n",
    "optimal_survival_rate = (test_probs >= optimal_threshold).mean()\n",
    "\n",
    "print(f\"\\nOptimal threshold for ~{target_survivors} survivors: {optimal_threshold:.3f}\")\n",
    "print(f\"Actual survivors: {optimal_survivors}\")\n",
    "print(f\"Survival rate: {optimal_survival_rate:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions at different thresholds\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREDICTION COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "preds_05 = (test_probs >= 0.5).astype(int)  # Default threshold\n",
    "preds_opt = (test_probs >= optimal_threshold).astype(int)  # Optimized threshold\n",
    "\n",
    "print(f\"\\nDefault (0.5): {preds_05.sum()} survivors ({preds_05.mean()*100:.1f}%)\")\n",
    "print(f\"Optimized ({optimal_threshold:.3f}): {preds_opt.sum()} survivors ({preds_opt.mean()*100:.1f}%)\")\n",
    "print(f\"\\nDifference: {preds_05.sum() - preds_opt.sum()} passengers changed from 1→0\")\n",
    "\n",
    "# Who are the passengers that changed?\n",
    "changed_idx = np.where((preds_05 == 1) & (preds_opt == 0))[0]\n",
    "print(f\"\\nPassengers changed from Survived=1 to Survived=0: {len(changed_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the changed passengers\n",
    "if len(changed_idx) > 0:\n",
    "    changed_passengers = test_processed.iloc[changed_idx]\n",
    "    print(\"\\nProfile of changed passengers:\")\n",
    "    print(f\"  Sex: {changed_passengers['Sex'].value_counts().to_dict()}\")\n",
    "    print(f\"  Pclass: {changed_passengers['Pclass'].value_counts().to_dict()}\")\n",
    "    print(f\"  Title: {changed_passengers['Title'].value_counts().to_dict()}\")\n",
    "    print(f\"  Mean Age: {changed_passengers['Age'].mean():.1f}\")\n",
    "    print(f\"  Mean Fare: {changed_passengers['Fare'].mean():.1f}\")\n",
    "    \n",
    "    # Show probability distribution of changed passengers\n",
    "    changed_probs = test_probs[changed_idx]\n",
    "    print(f\"\\n  Probability range: {changed_probs.min():.3f} - {changed_probs.max():.3f}\")\n",
    "    print(f\"  Mean probability: {changed_probs.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76cc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission with optimized threshold\n",
    "test_preds_optimized = (test_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_ids,\n",
    "    'Survived': test_preds_optimized\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} rows\")\n",
    "print(f\"\\nSurvived distribution:\")\n",
    "print(submission['Survived'].value_counts())\n",
    "print(f\"\\nSurvival rate: {submission['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate OOF accuracy with optimized threshold\n",
    "oof_preds_opt = (oof_probs >= optimal_threshold).astype(int)\n",
    "oof_acc_opt = accuracy_score(y, oof_preds_opt)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: Voting Ensemble (RF + LR + GB + SVC)\")\n",
    "print(f\"Features: 8 features with Title\")\n",
    "print(f\"Threshold: {optimal_threshold:.3f} (optimized for ~31% survival rate)\")\n",
    "print(f\"\\nOOF Accuracy:\")\n",
    "print(f\"  Default (0.5): {accuracy_score(y, (oof_probs >= 0.5).astype(int)):.4f}\")\n",
    "print(f\"  Optimized ({optimal_threshold:.3f}): {oof_acc_opt:.4f}\")\n",
    "print(f\"\\nSubmission:\")\n",
    "print(f\"  Survivors: {submission['Survived'].sum()} ({submission['Survived'].mean()*100:.1f}%)\")\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Simple RF (LB 0.7775): 131 survivors (31.3%)\")\n",
    "print(f\"  XGBoost (LB 0.7584): 157 survivors (37.6%)\")\n",
    "print(f\"  This submission: {submission['Survived'].sum()} survivors ({submission['Survived'].mean()*100:.1f}%)\")\n",
    "print(f\"\\nExpected LB: If hypothesis correct, should be ~0.77-0.78\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
