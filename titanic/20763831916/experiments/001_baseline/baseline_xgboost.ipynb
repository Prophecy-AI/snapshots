{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1197aea6",
   "metadata": {},
   "source": [
    "# Baseline XGBoost Model for Titanic Survival Prediction\n",
    "\n",
    "This notebook implements a baseline model with:\n",
    "- Feature engineering (Title, FamilySize, Has_Cabin, Deck)\n",
    "- Age imputation by Title/Pclass/Sex\n",
    "- XGBoost with 5-fold Stratified CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04121faa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:27:51.764859Z",
     "iopub.status.busy": "2026-01-06T22:27:51.764229Z",
     "iopub.status.idle": "2026-01-06T22:27:52.827357Z",
     "shell.execute_reply": "2026-01-06T22:27:52.826754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Target distribution:\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414af519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:27:52.829841Z",
     "iopub.status.busy": "2026-01-06T22:27:52.829296Z",
     "iopub.status.idle": "2026-01-06T22:27:52.853274Z",
     "shell.execute_reply": "2026-01-06T22:27:52.852625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title distribution:\n",
      "Title\n",
      "Mr        517\n",
      "Miss      185\n",
      "Mrs       126\n",
      "Master     40\n",
      "Rare       23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering Function\n",
    "def engineer_features(df, is_train=True):\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 1. Title extraction from Name\n",
    "    data['Title'] = data['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Group rare titles\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "        'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "        'Lady': 'Rare', 'Countess': 'Rare', 'Capt': 'Rare', 'Col': 'Rare',\n",
    "        'Don': 'Rare', 'Dr': 'Rare', 'Major': 'Rare', 'Rev': 'Rare',\n",
    "        'Sir': 'Rare', 'Jonkheer': 'Rare', 'Dona': 'Rare'\n",
    "    }\n",
    "    data['Title'] = data['Title'].map(title_mapping)\n",
    "    data['Title'] = data['Title'].fillna('Rare')  # Handle any unmapped titles\n",
    "    \n",
    "    # 2. Family features\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "    data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 3. Cabin features\n",
    "    data['Has_Cabin'] = data['Cabin'].notna().astype(int)\n",
    "    data['Deck'] = data['Cabin'].str[0].fillna('U')  # U for Unknown\n",
    "    \n",
    "    # 4. Name length\n",
    "    data['Name_length'] = data['Name'].apply(len)\n",
    "    \n",
    "    # 5. Sex encoding\n",
    "    data['Sex_Code'] = (data['Sex'] == 'male').astype(int)\n",
    "    \n",
    "    # 6. Embarked - fill missing with mode 'S'\n",
    "    data['Embarked'] = data['Embarked'].fillna('S')\n",
    "    \n",
    "    # 7. Fare - fill missing with median by Pclass\n",
    "    if data['Fare'].isna().any():\n",
    "        fare_median = data.groupby('Pclass')['Fare'].transform('median')\n",
    "        data['Fare'] = data['Fare'].fillna(fare_median)\n",
    "        # If still missing, use overall median\n",
    "        data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Apply feature engineering\n",
    "train_fe = engineer_features(train, is_train=True)\n",
    "test_fe = engineer_features(test, is_train=False)\n",
    "\n",
    "print(\"Title distribution:\")\n",
    "print(train_fe['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e56fbaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:27:52.855495Z",
     "iopub.status.busy": "2026-01-06T22:27:52.854961Z",
     "iopub.status.idle": "2026-01-06T22:27:52.928658Z",
     "shell.execute_reply": "2026-01-06T22:27:52.928066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Age in train: 0\n",
      "Missing Age in test: 0\n"
     ]
    }
   ],
   "source": [
    "# Age imputation using median by Title, Pclass, Sex\n",
    "def impute_age(train_df, test_df):\n",
    "    # Combine for consistent imputation\n",
    "    combined = pd.concat([train_df, test_df], axis=0)\n",
    "    \n",
    "    # Calculate median age by Title, Pclass, Sex\n",
    "    age_medians = combined.groupby(['Title', 'Pclass', 'Sex'])['Age'].median()\n",
    "    \n",
    "    def fill_age(row):\n",
    "        if pd.isna(row['Age']):\n",
    "            try:\n",
    "                return age_medians[(row['Title'], row['Pclass'], row['Sex'])]\n",
    "            except KeyError:\n",
    "                # Fallback to Title only\n",
    "                try:\n",
    "                    return combined[combined['Title'] == row['Title']]['Age'].median()\n",
    "                except:\n",
    "                    return combined['Age'].median()\n",
    "        return row['Age']\n",
    "    \n",
    "    train_df['Age'] = train_df.apply(fill_age, axis=1)\n",
    "    test_df['Age'] = test_df.apply(fill_age, axis=1)\n",
    "    \n",
    "    # Final fallback for any remaining NaN\n",
    "    overall_median = combined['Age'].median()\n",
    "    train_df['Age'] = train_df['Age'].fillna(overall_median)\n",
    "    test_df['Age'] = test_df['Age'].fillna(overall_median)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_fe, test_fe = impute_age(train_fe, test_fe)\n",
    "\n",
    "print(f\"Missing Age in train: {train_fe['Age'].isna().sum()}\")\n",
    "print(f\"Missing Age in test: {test_fe['Age'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da326bbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:27:52.930632Z",
     "iopub.status.busy": "2026-01-06T22:27:52.930385Z",
     "iopub.status.idle": "2026-01-06T22:27:52.941700Z",
     "shell.execute_reply": "2026-01-06T22:27:52.941109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features: ['Pclass', 'Sex_Code', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Code', 'Title_Code', 'FamilySize', 'IsAlone', 'Has_Cabin', 'Deck_Code', 'Name_length']\n",
      "Number of features: 13\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features\n",
    "def encode_features(train_df, test_df):\n",
    "    # Combine for consistent encoding\n",
    "    combined = pd.concat([train_df, test_df], axis=0)\n",
    "    \n",
    "    # Label encode categorical columns\n",
    "    le_title = LabelEncoder()\n",
    "    le_embarked = LabelEncoder()\n",
    "    le_deck = LabelEncoder()\n",
    "    \n",
    "    combined['Title_Code'] = le_title.fit_transform(combined['Title'])\n",
    "    combined['Embarked_Code'] = le_embarked.fit_transform(combined['Embarked'])\n",
    "    combined['Deck_Code'] = le_deck.fit_transform(combined['Deck'])\n",
    "    \n",
    "    # Split back\n",
    "    train_encoded = combined.iloc[:len(train_df)].copy()\n",
    "    test_encoded = combined.iloc[len(train_df):].copy()\n",
    "    \n",
    "    return train_encoded, test_encoded\n",
    "\n",
    "train_fe, test_fe = encode_features(train_fe, test_fe)\n",
    "\n",
    "# Define feature columns\n",
    "feature_cols = [\n",
    "    'Pclass', 'Sex_Code', 'Age', 'SibSp', 'Parch', 'Fare',\n",
    "    'Embarked_Code', 'Title_Code', 'FamilySize', 'IsAlone',\n",
    "    'Has_Cabin', 'Deck_Code', 'Name_length'\n",
    "]\n",
    "\n",
    "print(f\"\\nFeatures: {feature_cols}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868a1043",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:27:52.943438Z",
     "iopub.status.busy": "2026-01-06T22:27:52.943240Z",
     "iopub.status.idle": "2026-01-06T22:27:52.948911Z",
     "shell.execute_reply": "2026-01-06T22:27:52.948373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (891, 13)\n",
      "y shape: (891,)\n",
      "X_test shape: (418, 13)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for modeling\n",
    "X = train_fe[feature_cols].values\n",
    "y = train_fe['Survived'].values\n",
    "X_test = test_fe[feature_cols].values\n",
    "test_ids = test_fe['PassengerId'].values\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceb60d81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:27:52.950719Z",
     "iopub.status.busy": "2026-01-06T22:27:52.950501Z",
     "iopub.status.idle": "2026-01-06T22:27:53.491078Z",
     "shell.execute_reply": "2026-01-06T22:27:53.490212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.8659\n",
      "Fold 2: Accuracy = 0.8427\n",
      "Fold 3: Accuracy = 0.7921\n",
      "Fold 4: Accuracy = 0.8258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Accuracy = 0.8315\n",
      "\n",
      "==================================================\n",
      "Overall CV Accuracy: 0.8316 (+/- 0.0240)\n",
      "Mean Fold Accuracy: 0.8316\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold Stratified Cross-Validation with XGBoost\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# XGBoost parameters\n",
    "xgb_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'logloss',\n",
    "    'use_label_encoder': False\n",
    "}\n",
    "\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    \n",
    "    # Predict on validation\n",
    "    val_pred = model.predict(X_val)\n",
    "    oof_preds[val_idx] = val_pred\n",
    "    \n",
    "    # Predict on test\n",
    "    test_preds += model.predict_proba(X_test)[:, 1] / kfold.n_splits\n",
    "    \n",
    "    # Calculate fold accuracy\n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_acc)\n",
    "    print(f\"Fold {fold+1}: Accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "# Overall CV score\n",
    "cv_score = accuracy_score(y, oof_preds)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Overall CV Accuracy: {cv_score:.4f} (+/- {np.std(fold_scores):.4f})\")\n",
    "print(f\"Mean Fold Accuracy: {np.mean(fold_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d36cf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:27:53.493326Z",
     "iopub.status.busy": "2026-01-06T22:27:53.492745Z",
     "iopub.status.idle": "2026-01-06T22:27:53.502325Z",
     "shell.execute_reply": "2026-01-06T22:27:53.501739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved with 418 rows\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         0\n",
      "5          897         0\n",
      "6          898         0\n",
      "7          899         0\n",
      "8          900         1\n",
      "9          901         0\n",
      "\n",
      "Survived distribution in submission:\n",
      "Survived\n",
      "0    261\n",
      "1    157\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "test_preds_binary = (test_preds >= 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_ids,\n",
    "    'Survived': test_preds_binary\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} rows\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nSurvived distribution in submission:\")\n",
    "print(submission['Survived'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "992fdc73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:27:53.504486Z",
     "iopub.status.busy": "2026-01-06T22:27:53.504065Z",
     "iopub.status.idle": "2026-01-06T22:27:54.639782Z",
     "shell.execute_reply": "2026-01-06T22:27:54.639186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "      feature  importance\n",
      "     Sex_Code    0.435369\n",
      "       Pclass    0.117915\n",
      "   Title_Code    0.075708\n",
      "    Deck_Code    0.074499\n",
      "   FamilySize    0.054085\n",
      "        SibSp    0.049530\n",
      "Embarked_Code    0.036041\n",
      "          Age    0.033081\n",
      "         Fare    0.031031\n",
      "  Name_length    0.029951\n",
      "    Has_Cabin    0.022722\n",
      "        Parch    0.021337\n",
      "      IsAlone    0.018730\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train final model on all data for feature importance\n",
    "final_model = xgb.XGBClassifier(**xgb_params)\n",
    "final_model.fit(X, y, verbose=False)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(importance.to_string(index=False))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
