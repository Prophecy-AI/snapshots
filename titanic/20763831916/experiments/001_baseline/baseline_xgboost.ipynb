{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1197aea6",
   "metadata": {},
   "source": [
    "# Baseline XGBoost Model for Titanic Survival Prediction\n",
    "\n",
    "This notebook implements a baseline model with:\n",
    "- Feature engineering (Title, FamilySize, Has_Cabin, Deck)\n",
    "- Age imputation by Title/Pclass/Sex\n",
    "- XGBoost with 5-fold Stratified CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04121faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414af519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Function\n",
    "def engineer_features(df, is_train=True):\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 1. Title extraction from Name\n",
    "    data['Title'] = data['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Group rare titles\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "        'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "        'Lady': 'Rare', 'Countess': 'Rare', 'Capt': 'Rare', 'Col': 'Rare',\n",
    "        'Don': 'Rare', 'Dr': 'Rare', 'Major': 'Rare', 'Rev': 'Rare',\n",
    "        'Sir': 'Rare', 'Jonkheer': 'Rare', 'Dona': 'Rare'\n",
    "    }\n",
    "    data['Title'] = data['Title'].map(title_mapping)\n",
    "    data['Title'] = data['Title'].fillna('Rare')  # Handle any unmapped titles\n",
    "    \n",
    "    # 2. Family features\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "    data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 3. Cabin features\n",
    "    data['Has_Cabin'] = data['Cabin'].notna().astype(int)\n",
    "    data['Deck'] = data['Cabin'].str[0].fillna('U')  # U for Unknown\n",
    "    \n",
    "    # 4. Name length\n",
    "    data['Name_length'] = data['Name'].apply(len)\n",
    "    \n",
    "    # 5. Sex encoding\n",
    "    data['Sex_Code'] = (data['Sex'] == 'male').astype(int)\n",
    "    \n",
    "    # 6. Embarked - fill missing with mode 'S'\n",
    "    data['Embarked'] = data['Embarked'].fillna('S')\n",
    "    \n",
    "    # 7. Fare - fill missing with median by Pclass\n",
    "    if data['Fare'].isna().any():\n",
    "        fare_median = data.groupby('Pclass')['Fare'].transform('median')\n",
    "        data['Fare'] = data['Fare'].fillna(fare_median)\n",
    "        # If still missing, use overall median\n",
    "        data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Apply feature engineering\n",
    "train_fe = engineer_features(train, is_train=True)\n",
    "test_fe = engineer_features(test, is_train=False)\n",
    "\n",
    "print(\"Title distribution:\")\n",
    "print(train_fe['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age imputation using median by Title, Pclass, Sex\n",
    "def impute_age(train_df, test_df):\n",
    "    # Combine for consistent imputation\n",
    "    combined = pd.concat([train_df, test_df], axis=0)\n",
    "    \n",
    "    # Calculate median age by Title, Pclass, Sex\n",
    "    age_medians = combined.groupby(['Title', 'Pclass', 'Sex'])['Age'].median()\n",
    "    \n",
    "    def fill_age(row):\n",
    "        if pd.isna(row['Age']):\n",
    "            try:\n",
    "                return age_medians[(row['Title'], row['Pclass'], row['Sex'])]\n",
    "            except KeyError:\n",
    "                # Fallback to Title only\n",
    "                try:\n",
    "                    return combined[combined['Title'] == row['Title']]['Age'].median()\n",
    "                except:\n",
    "                    return combined['Age'].median()\n",
    "        return row['Age']\n",
    "    \n",
    "    train_df['Age'] = train_df.apply(fill_age, axis=1)\n",
    "    test_df['Age'] = test_df.apply(fill_age, axis=1)\n",
    "    \n",
    "    # Final fallback for any remaining NaN\n",
    "    overall_median = combined['Age'].median()\n",
    "    train_df['Age'] = train_df['Age'].fillna(overall_median)\n",
    "    test_df['Age'] = test_df['Age'].fillna(overall_median)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_fe, test_fe = impute_age(train_fe, test_fe)\n",
    "\n",
    "print(f\"Missing Age in train: {train_fe['Age'].isna().sum()}\")\n",
    "print(f\"Missing Age in test: {test_fe['Age'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da326bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "def encode_features(train_df, test_df):\n",
    "    # Combine for consistent encoding\n",
    "    combined = pd.concat([train_df, test_df], axis=0)\n",
    "    \n",
    "    # Label encode categorical columns\n",
    "    le_title = LabelEncoder()\n",
    "    le_embarked = LabelEncoder()\n",
    "    le_deck = LabelEncoder()\n",
    "    \n",
    "    combined['Title_Code'] = le_title.fit_transform(combined['Title'])\n",
    "    combined['Embarked_Code'] = le_embarked.fit_transform(combined['Embarked'])\n",
    "    combined['Deck_Code'] = le_deck.fit_transform(combined['Deck'])\n",
    "    \n",
    "    # Split back\n",
    "    train_encoded = combined.iloc[:len(train_df)].copy()\n",
    "    test_encoded = combined.iloc[len(train_df):].copy()\n",
    "    \n",
    "    return train_encoded, test_encoded\n",
    "\n",
    "train_fe, test_fe = encode_features(train_fe, test_fe)\n",
    "\n",
    "# Define feature columns\n",
    "feature_cols = [\n",
    "    'Pclass', 'Sex_Code', 'Age', 'SibSp', 'Parch', 'Fare',\n",
    "    'Embarked_Code', 'Title_Code', 'FamilySize', 'IsAlone',\n",
    "    'Has_Cabin', 'Deck_Code', 'Name_length'\n",
    "]\n",
    "\n",
    "print(f\"\\nFeatures: {feature_cols}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a1043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "X = train_fe[feature_cols].values\n",
    "y = train_fe['Survived'].values\n",
    "X_test = test_fe[feature_cols].values\n",
    "test_ids = test_fe['PassengerId'].values\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb60d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Stratified Cross-Validation with XGBoost\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# XGBoost parameters\n",
    "xgb_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'logloss',\n",
    "    'use_label_encoder': False\n",
    "}\n",
    "\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    \n",
    "    # Predict on validation\n",
    "    val_pred = model.predict(X_val)\n",
    "    oof_preds[val_idx] = val_pred\n",
    "    \n",
    "    # Predict on test\n",
    "    test_preds += model.predict_proba(X_test)[:, 1] / kfold.n_splits\n",
    "    \n",
    "    # Calculate fold accuracy\n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_acc)\n",
    "    print(f\"Fold {fold+1}: Accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "# Overall CV score\n",
    "cv_score = accuracy_score(y, oof_preds)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Overall CV Accuracy: {cv_score:.4f} (+/- {np.std(fold_scores):.4f})\")\n",
    "print(f\"Mean Fold Accuracy: {np.mean(fold_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d36cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "test_preds_binary = (test_preds >= 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_ids,\n",
    "    'Survived': test_preds_binary\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} rows\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nSurvived distribution in submission:\")\n",
    "print(submission['Survived'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992fdc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train final model on all data for feature importance\n",
    "final_model = xgb.XGBClassifier(**xgb_params)\n",
    "final_model.fit(X, y, verbose=False)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(importance.to_string(index=False))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
