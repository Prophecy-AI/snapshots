{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9bd12c5",
   "metadata": {},
   "source": [
    "# Simple Random Forest with Fewer Features\n",
    "\n",
    "## Goal: Reduce CV-LB Gap (Overfitting)\n",
    "\n",
    "Previous baseline: CV 0.8316, LB 0.7584 (7.3% gap)\n",
    "\n",
    "This experiment:\n",
    "- Use only 6 core features: Sex, Pclass, SibSp, Parch, Fare, Embarked\n",
    "- Simple Random Forest with max_depth=5\n",
    "- Minimal feature engineering to avoid overfitting\n",
    "- Age imputation on TRAIN ONLY (avoid leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal preprocessing - avoid complex feature engineering\n",
    "def preprocess_simple(train_df, test_df):\n",
    "    \"\"\"Simple preprocessing with minimal features to reduce overfitting\"\"\"\n",
    "    train_data = train_df.copy()\n",
    "    test_data = test_df.copy()\n",
    "    \n",
    "    # 1. Sex encoding (most important feature)\n",
    "    train_data['Sex_Code'] = (train_data['Sex'] == 'male').astype(int)\n",
    "    test_data['Sex_Code'] = (test_data['Sex'] == 'male').astype(int)\n",
    "    \n",
    "    # 2. Embarked - fill missing with mode 'S', then encode\n",
    "    train_data['Embarked'] = train_data['Embarked'].fillna('S')\n",
    "    test_data['Embarked'] = test_data['Embarked'].fillna('S')\n",
    "    embarked_map = {'S': 0, 'C': 1, 'Q': 2}\n",
    "    train_data['Embarked_Code'] = train_data['Embarked'].map(embarked_map)\n",
    "    test_data['Embarked_Code'] = test_data['Embarked'].map(embarked_map)\n",
    "    \n",
    "    # 3. Fare - fill missing with median from TRAIN only\n",
    "    train_fare_median = train_data['Fare'].median()\n",
    "    train_data['Fare'] = train_data['Fare'].fillna(train_fare_median)\n",
    "    test_data['Fare'] = test_data['Fare'].fillna(train_fare_median)\n",
    "    \n",
    "    # 4. Age - fill missing with median from TRAIN only (by Sex and Pclass)\n",
    "    # Calculate medians from train only\n",
    "    age_medians = train_data.groupby(['Sex', 'Pclass'])['Age'].median()\n",
    "    \n",
    "    def fill_age(row, medians, fallback):\n",
    "        if pd.isna(row['Age']):\n",
    "            try:\n",
    "                return medians[(row['Sex'], row['Pclass'])]\n",
    "            except KeyError:\n",
    "                return fallback\n",
    "        return row['Age']\n",
    "    \n",
    "    train_age_median = train_data['Age'].median()\n",
    "    train_data['Age'] = train_data.apply(lambda x: fill_age(x, age_medians, train_age_median), axis=1)\n",
    "    test_data['Age'] = test_data.apply(lambda x: fill_age(x, age_medians, train_age_median), axis=1)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "train_processed, test_processed = preprocess_simple(train, test)\n",
    "\n",
    "print(f\"Missing values in train:\")\n",
    "print(train_processed[['Age', 'Fare', 'Embarked_Code']].isna().sum())\n",
    "print(f\"\\nMissing values in test:\")\n",
    "print(test_processed[['Age', 'Fare', 'Embarked_Code']].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3b020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SIMPLE feature set (6 features only)\n",
    "feature_cols_simple = ['Pclass', 'Sex_Code', 'SibSp', 'Parch', 'Fare', 'Embarked_Code']\n",
    "\n",
    "# Also test with Age added (7 features)\n",
    "feature_cols_with_age = ['Pclass', 'Sex_Code', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Code']\n",
    "\n",
    "print(f\"Simple features (6): {feature_cols_simple}\")\n",
    "print(f\"With Age (7): {feature_cols_with_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13214d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X_simple = train_processed[feature_cols_simple].values\n",
    "X_with_age = train_processed[feature_cols_with_age].values\n",
    "y = train_processed['Survived'].values\n",
    "\n",
    "X_test_simple = test_processed[feature_cols_simple].values\n",
    "X_test_with_age = test_processed[feature_cols_with_age].values\n",
    "test_ids = test_processed['PassengerId'].values\n",
    "\n",
    "print(f\"X_simple shape: {X_simple.shape}\")\n",
    "print(f\"X_with_age shape: {X_with_age.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b82bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Stratified CV with Simple Random Forest\n",
    "def evaluate_model(X, y, X_test, model_params, n_splits=5):\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        model = RandomForestClassifier(**model_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        val_pred = model.predict(X_val)\n",
    "        oof_preds[val_idx] = val_pred\n",
    "        \n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / n_splits\n",
    "        \n",
    "        fold_acc = accuracy_score(y_val, val_pred)\n",
    "        fold_scores.append(fold_acc)\n",
    "        print(f\"  Fold {fold+1}: {fold_acc:.4f}\")\n",
    "    \n",
    "    cv_score = accuracy_score(y, oof_preds)\n",
    "    return cv_score, np.std(fold_scores), test_preds, fold_scores\n",
    "\n",
    "# Simple RF parameters (conservative to avoid overfitting)\n",
    "rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 5,\n",
    "    'max_features': 'sqrt',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Simple features (6 features)\n",
    "print(\"=\"*50)\n",
    "print(\"Test 1: Simple RF with 6 features\")\n",
    "print(\"=\"*50)\n",
    "cv_simple, std_simple, preds_simple, folds_simple = evaluate_model(\n",
    "    X_simple, y, X_test_simple, rf_params\n",
    ")\n",
    "print(f\"\\nCV Accuracy: {cv_simple:.4f} (+/- {std_simple:.4f})\")\n",
    "print(f\"Fold scores: {[f'{s:.4f}' for s in folds_simple]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: With Age (7 features)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Test 2: Simple RF with 7 features (+ Age)\")\n",
    "print(\"=\"*50)\n",
    "cv_with_age, std_with_age, preds_with_age, folds_with_age = evaluate_model(\n",
    "    X_with_age, y, X_test_with_age, rf_params\n",
    ")\n",
    "print(f\"\\nCV Accuracy: {cv_with_age:.4f} (+/- {std_with_age:.4f})\")\n",
    "print(f\"Fold scores: {[f'{s:.4f}' for s in folds_with_age]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(f\"6 features: CV = {cv_simple:.4f} (+/- {std_simple:.4f})\")\n",
    "print(f\"7 features: CV = {cv_with_age:.4f} (+/- {std_with_age:.4f})\")\n",
    "print(f\"\\nPrevious baseline (13 features XGBoost): CV = 0.8316, LB = 0.7584\")\n",
    "print(f\"\\nExpected LB (assuming 7% gap): {cv_simple - 0.07:.4f} to {cv_with_age - 0.07:.4f}\")\n",
    "\n",
    "# Choose the better model\n",
    "if cv_simple >= cv_with_age:\n",
    "    best_preds = preds_simple\n",
    "    best_cv = cv_simple\n",
    "    best_std = std_simple\n",
    "    best_features = '6 features'\n",
    "else:\n",
    "    best_preds = preds_with_age\n",
    "    best_cv = cv_with_age\n",
    "    best_std = std_with_age\n",
    "    best_features = '7 features'\n",
    "\n",
    "print(f\"\\nUsing {best_features} for submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6238189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission with best model\n",
    "test_preds_binary = (best_preds >= 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_ids,\n",
    "    'Survived': test_preds_binary\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} rows\")\n",
    "print(f\"\\nSurvived distribution:\")\n",
    "print(submission['Survived'].value_counts())\n",
    "print(f\"\\nSurvival rate: {submission['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea56112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for the best model\n",
    "final_model = RandomForestClassifier(**rf_params)\n",
    "if best_features == '6 features':\n",
    "    final_model.fit(X_simple, y)\n",
    "    feature_names = feature_cols_simple\n",
    "else:\n",
    "    final_model.fit(X_with_age, y)\n",
    "    feature_names = feature_cols_with_age\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Model: Random Forest (max_depth=5, n_estimators=100)\")\n",
    "print(f\"Features: {best_features}\")\n",
    "print(f\"CV Accuracy: {best_cv:.4f} (+/- {best_std:.4f})\")\n",
    "print(f\"\\nComparison to baseline:\")\n",
    "print(f\"  Baseline XGBoost (13 features): CV=0.8316, LB=0.7584 (gap=7.3%)\")\n",
    "print(f\"  This model ({best_features}): CV={best_cv:.4f}\")\n",
    "print(f\"\\nExpected LB improvement: Simpler model should have smaller CV-LB gap\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
