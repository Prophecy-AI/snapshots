{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c196f9a7",
   "metadata": {},
   "source": [
    "# Voting Ensemble with Title Feature\n",
    "\n",
    "## Goal: Improve LB score using ensemble diversity\n",
    "\n",
    "Current best: LB 0.7775 (Simple RF, 7 features)\n",
    "\n",
    "This experiment:\n",
    "- Add Title feature back (captures sex + social status)\n",
    "- Use 8 features: Pclass, Sex_Code, Age, SibSp, Parch, Fare, Embarked_Code, Title_Code\n",
    "- Voting ensemble: RF, LogisticRegression, GradientBoosting, SVC\n",
    "- Soft voting (probability averaging)\n",
    "- Keep models simple to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b10b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering with Title\n",
    "def preprocess_with_title(train_df, test_df):\n",
    "    \"\"\"Preprocessing with Title feature added\"\"\"\n",
    "    train_data = train_df.copy()\n",
    "    test_data = test_df.copy()\n",
    "    \n",
    "    # 1. Title extraction from Name\n",
    "    for df in [train_data, test_data]:\n",
    "        df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "        # Group rare titles\n",
    "        title_mapping = {\n",
    "            'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "            'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "            'Lady': 'Rare', 'Countess': 'Rare', 'Capt': 'Rare', 'Col': 'Rare',\n",
    "            'Don': 'Rare', 'Dr': 'Rare', 'Major': 'Rare', 'Rev': 'Rare',\n",
    "            'Sir': 'Rare', 'Jonkheer': 'Rare', 'Dona': 'Rare'\n",
    "        }\n",
    "        df['Title'] = df['Title'].map(title_mapping).fillna('Rare')\n",
    "    \n",
    "    # 2. Title encoding (consistent across train/test)\n",
    "    title_order = ['Mr', 'Miss', 'Mrs', 'Master', 'Rare']\n",
    "    title_map = {t: i for i, t in enumerate(title_order)}\n",
    "    train_data['Title_Code'] = train_data['Title'].map(title_map)\n",
    "    test_data['Title_Code'] = test_data['Title'].map(title_map)\n",
    "    \n",
    "    # 3. Sex encoding\n",
    "    train_data['Sex_Code'] = (train_data['Sex'] == 'male').astype(int)\n",
    "    test_data['Sex_Code'] = (test_data['Sex'] == 'male').astype(int)\n",
    "    \n",
    "    # 4. Embarked - fill missing with mode 'S', then encode\n",
    "    train_data['Embarked'] = train_data['Embarked'].fillna('S')\n",
    "    test_data['Embarked'] = test_data['Embarked'].fillna('S')\n",
    "    embarked_map = {'S': 0, 'C': 1, 'Q': 2}\n",
    "    train_data['Embarked_Code'] = train_data['Embarked'].map(embarked_map)\n",
    "    test_data['Embarked_Code'] = test_data['Embarked'].map(embarked_map)\n",
    "    \n",
    "    # 5. Fare - fill missing with median from TRAIN only\n",
    "    train_fare_median = train_data['Fare'].median()\n",
    "    train_data['Fare'] = train_data['Fare'].fillna(train_fare_median)\n",
    "    test_data['Fare'] = test_data['Fare'].fillna(train_fare_median)\n",
    "    \n",
    "    # 6. Age - fill missing with median from TRAIN only (by Title and Pclass)\n",
    "    age_medians = train_data.groupby(['Title', 'Pclass'])['Age'].median()\n",
    "    train_age_median = train_data['Age'].median()\n",
    "    \n",
    "    def fill_age(row, medians, fallback):\n",
    "        if pd.isna(row['Age']):\n",
    "            try:\n",
    "                return medians[(row['Title'], row['Pclass'])]\n",
    "            except KeyError:\n",
    "                return fallback\n",
    "        return row['Age']\n",
    "    \n",
    "    train_data['Age'] = train_data.apply(lambda x: fill_age(x, age_medians, train_age_median), axis=1)\n",
    "    test_data['Age'] = test_data.apply(lambda x: fill_age(x, age_medians, train_age_median), axis=1)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "train_processed, test_processed = preprocess_with_title(train, test)\n",
    "\n",
    "print(\"Title distribution:\")\n",
    "print(train_processed['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba67b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature set (8 features)\n",
    "feature_cols = ['Pclass', 'Sex_Code', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Code', 'Title_Code']\n",
    "\n",
    "print(f\"Features ({len(feature_cols)}): {feature_cols}\")\n",
    "\n",
    "# Prepare data\n",
    "X = train_processed[feature_cols].values\n",
    "y = train_processed['Survived'].values\n",
    "X_test = test_processed[feature_cols].values\n",
    "test_ids = test_processed['PassengerId'].values\n",
    "\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ebb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models (simple, regularized)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=5, \n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    C=1.0,\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svc = SVC(\n",
    "    kernel='rbf',\n",
    "    C=1.0,\n",
    "    gamma='scale',\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Base models defined:\")\n",
    "print(\"- RandomForest (max_depth=5)\")\n",
    "print(\"- LogisticRegression (C=1.0)\")\n",
    "print(\"- GradientBoosting (max_depth=3)\")\n",
    "print(\"- SVC (rbf kernel, C=1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03251bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf),\n",
    "        ('lr', lr),\n",
    "        ('gb', gb),\n",
    "        ('svc', svc)\n",
    "    ],\n",
    "    voting='soft'  # Use probability averaging\n",
    ")\n",
    "\n",
    "print(\"Voting Classifier created with soft voting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Stratified CV\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds = np.zeros(len(X))\n",
    "oof_probs = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "fold_scores = []\n",
    "\n",
    "# Also track individual model scores\n",
    "model_scores = {'rf': [], 'lr': [], 'gb': [], 'svc': []}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Scale features for LR and SVC\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train voting classifier\n",
    "    voting_clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on validation\n",
    "    val_pred = voting_clf.predict(X_val_scaled)\n",
    "    val_prob = voting_clf.predict_proba(X_val_scaled)[:, 1]\n",
    "    oof_preds[val_idx] = val_pred\n",
    "    oof_probs[val_idx] = val_prob\n",
    "    \n",
    "    # Predict on test\n",
    "    test_preds += voting_clf.predict_proba(X_test_scaled)[:, 1] / kfold.n_splits\n",
    "    \n",
    "    # Calculate fold accuracy\n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_acc)\n",
    "    \n",
    "    # Track individual model scores\n",
    "    for name, model in voting_clf.named_estimators_.items():\n",
    "        model_pred = model.predict(X_val_scaled)\n",
    "        model_scores[name].append(accuracy_score(y_val, model_pred))\n",
    "    \n",
    "    print(f\"Fold {fold+1}: Ensemble={fold_acc:.4f} | RF={model_scores['rf'][-1]:.4f} | LR={model_scores['lr'][-1]:.4f} | GB={model_scores['gb'][-1]:.4f} | SVC={model_scores['svc'][-1]:.4f}\")\n",
    "\n",
    "# Overall CV score\n",
    "cv_score = accuracy_score(y, oof_preds)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Overall CV Accuracy: {cv_score:.4f} (+/- {np.std(fold_scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare individual models vs ensemble\n",
    "print(\"\\nModel Comparison (Mean CV Accuracy):\")\n",
    "print(f\"  RandomForest:     {np.mean(model_scores['rf']):.4f} (+/- {np.std(model_scores['rf']):.4f})\")\n",
    "print(f\"  LogisticReg:      {np.mean(model_scores['lr']):.4f} (+/- {np.std(model_scores['lr']):.4f})\")\n",
    "print(f\"  GradientBoosting: {np.mean(model_scores['gb']):.4f} (+/- {np.std(model_scores['gb']):.4f})\")\n",
    "print(f\"  SVC:              {np.mean(model_scores['svc']):.4f} (+/- {np.std(model_scores['svc']):.4f})\")\n",
    "print(f\"  ENSEMBLE:         {cv_score:.4f} (+/- {np.std(fold_scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f31ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "test_preds_binary = (test_preds >= 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_ids,\n",
    "    'Survived': test_preds_binary\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} rows\")\n",
    "print(f\"\\nSurvived distribution:\")\n",
    "print(submission['Survived'].value_counts())\n",
    "print(f\"\\nSurvival rate: {submission['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11711f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Model: Voting Ensemble (RF + LR + GB + SVC) with soft voting\")\n",
    "print(f\"Features: {len(feature_cols)} - {feature_cols}\")\n",
    "print(f\"CV Accuracy: {cv_score:.4f} (+/- {np.std(fold_scores):.4f})\")\n",
    "print(f\"\\nComparison to previous experiments:\")\n",
    "print(f\"  exp_000 (XGBoost 13 features): CV=0.8316, LB=0.7584\")\n",
    "print(f\"  exp_001 (Simple RF 7 features): CV=0.8238, LB=0.7775\")\n",
    "print(f\"  exp_002 (Voting Ensemble 8 features): CV={cv_score:.4f}\")\n",
    "print(f\"\\nExpected LB (assuming 4-5% gap): {cv_score - 0.05:.4f} to {cv_score - 0.04:.4f}\")\n",
    "print(f\"Submission survival rate: {submission['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01824b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction confidence\n",
    "print(\"\\nPrediction Confidence Analysis:\")\n",
    "print(f\"Mean probability: {test_preds.mean():.3f}\")\n",
    "print(f\"Std probability: {test_preds.std():.3f}\")\n",
    "print(f\"\\nConfidence distribution:\")\n",
    "print(f\"  Very confident (p<0.2 or p>0.8): {((test_preds < 0.2) | (test_preds > 0.8)).sum()} ({((test_preds < 0.2) | (test_preds > 0.8)).mean()*100:.1f}%)\")\n",
    "print(f\"  Uncertain (0.4 < p < 0.6): {((test_preds > 0.4) & (test_preds < 0.6)).sum()} ({((test_preds > 0.4) & (test_preds < 0.6)).mean()*100:.1f}%)\")\n",
    "\n",
    "# Compare with previous best (Simple RF)\n",
    "print(f\"\\nNote: Previous best (Simple RF) had survival rate 31.3%\")\n",
    "print(f\"This model has survival rate {submission['Survived'].mean()*100:.1f}%\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
