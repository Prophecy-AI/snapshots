{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d81310e",
   "metadata": {},
   "source": [
    "# Loop 1 LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- **CV Score**: 0.8316\n",
    "- **LB Score**: 0.7584\n",
    "- **Gap**: +0.0732 (CV is 7.3% higher than LB)\n",
    "\n",
    "This is a significant gap that needs investigation. Possible causes:\n",
    "1. Overfitting to training data\n",
    "2. Distribution shift between train and test\n",
    "3. Data leakage in CV (imputation on combined data)\n",
    "4. Model complexity too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873020e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nTrain survival rate: {train['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437909fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check submission distribution vs training distribution\n",
    "submission = pd.read_csv('/home/code/submission_candidates/candidate_000.csv')\n",
    "print(f\"Submission survival rate: {submission['Survived'].mean():.3f}\")\n",
    "print(f\"Train survival rate: {train['Survived'].mean():.3f}\")\n",
    "print(f\"\\nDifference: {submission['Survived'].mean() - train['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature distributions between train and test\n",
    "def compare_distributions(train, test, col):\n",
    "    if col in train.columns and col in test.columns:\n",
    "        train_vals = train[col].dropna()\n",
    "        test_vals = test[col].dropna()\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Train mean: {train_vals.mean():.3f}, std: {train_vals.std():.3f}\")\n",
    "        print(f\"  Test mean: {test_vals.mean():.3f}, std: {test_vals.std():.3f}\")\n",
    "        print(f\"  Difference: {abs(train_vals.mean() - test_vals.mean()):.3f}\")\n",
    "\n",
    "for col in ['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']:\n",
    "    compare_distributions(train, test, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78e121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check categorical distributions\n",
    "print(\"Sex distribution:\")\n",
    "print(f\"  Train: {train['Sex'].value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"  Test: {test['Sex'].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "print(\"\\nEmbarked distribution:\")\n",
    "print(f\"  Train: {train['Embarked'].value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"  Test: {test['Embarked'].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "print(\"\\nPclass distribution:\")\n",
    "print(f\"  Train: {train['Pclass'].value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"  Test: {test['Pclass'].value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d256b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing value patterns\n",
    "print(\"Missing values comparison:\")\n",
    "print(f\"\\nAge missing:\")\n",
    "print(f\"  Train: {train['Age'].isna().sum()}/{len(train)} ({train['Age'].isna().mean()*100:.1f}%)\")\n",
    "print(f\"  Test: {test['Age'].isna().sum()}/{len(test)} ({test['Age'].isna().mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nCabin missing:\")\n",
    "print(f\"  Train: {train['Cabin'].isna().sum()}/{len(train)} ({train['Cabin'].isna().mean()*100:.1f}%)\")\n",
    "print(f\"  Test: {test['Cabin'].isna().sum()}/{len(test)} ({test['Cabin'].isna().mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcfecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title extraction and comparison\n",
    "train['Title'] = train['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "test['Title'] = test['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "print(\"Title distribution:\")\n",
    "print(f\"\\nTrain:\")\n",
    "print(train['Title'].value_counts(normalize=True).head(10))\n",
    "print(f\"\\nTest:\")\n",
    "print(test['Title'].value_counts(normalize=True).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a713d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the gender-based baseline\n",
    "# Simple rule: Female = 1, Male = 0\n",
    "gender_baseline = (test['Sex'] == 'female').astype(int)\n",
    "print(f\"Gender-only baseline prediction survival rate: {gender_baseline.mean():.3f}\")\n",
    "print(f\"This is the simplest baseline - typically achieves ~76-77% LB\")\n",
    "\n",
    "# Our submission\n",
    "print(f\"\\nOur submission survival rate: {submission['Survived'].mean():.3f}\")\n",
    "print(f\"Difference from gender baseline: {submission['Survived'].mean() - gender_baseline.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2923c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze fold variance from the experiment\n",
    "fold_scores = [0.8659, 0.8427, 0.7921, 0.8258, 0.8315]\n",
    "print(f\"Fold scores: {fold_scores}\")\n",
    "print(f\"Mean: {np.mean(fold_scores):.4f}\")\n",
    "print(f\"Std: {np.std(fold_scores):.4f}\")\n",
    "print(f\"Min: {min(fold_scores):.4f}\")\n",
    "print(f\"Max: {max(fold_scores):.4f}\")\n",
    "print(f\"Range: {max(fold_scores) - min(fold_scores):.4f}\")\n",
    "\n",
    "print(f\"\\nThe high variance ({np.std(fold_scores):.4f}) suggests the model is sensitive to data splits.\")\n",
    "print(f\"The LB score of 0.7584 is below even the worst fold (0.7921).\")\n",
    "print(f\"This suggests potential overfitting or distribution shift.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374ad94",
   "metadata": {},
   "source": [
    "## Analysis Summary\n",
    "\n",
    "### Key Findings:\n",
    "1. **CV-LB Gap of 7.3%** is significant and concerning\n",
    "2. The LB score (75.84%) is below even the worst CV fold (79.21%)\n",
    "3. This suggests either:\n",
    "   - Overfitting to training data patterns\n",
    "   - Distribution shift between train and test\n",
    "   - Data leakage in preprocessing (imputation on combined data)\n",
    "\n",
    "### Recommendations:\n",
    "1. **Simplify the model** - reduce complexity to prevent overfitting\n",
    "2. **Use simpler imputation** - avoid combining train+test for imputation\n",
    "3. **Try ensemble methods** - voting classifiers are more robust\n",
    "4. **Consider simpler features** - reduce feature count\n",
    "5. **Regularization** - increase regularization in XGBoost\n",
    "\n",
    "### Target Recalibration:\n",
    "- The target of 1.0 (100%) is **impossible**\n",
    "- State-of-the-art is 81-85% LB\n",
    "- Current 75.84% is below the gender-only baseline (~76-77%)\n",
    "- **Immediate goal: Beat 77% LB (gender baseline)**\n",
    "- **Stretch goal: Reach 80%+ LB**"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
