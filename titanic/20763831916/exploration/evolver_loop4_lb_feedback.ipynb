{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc64fd30",
   "metadata": {},
   "source": [
    "# Loop 4 LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- **exp_003**: Threshold-Tuned Ensemble (31% survival rate)\n",
    "  - CV: 0.8373 | LB: 0.7847 | Gap: +5.26%\n",
    "\n",
    "## Submission History\n",
    "| Exp | Model | CV | LB | Gap | Survival Rate |\n",
    "|-----|-------|-----|-----|-----|---------------|\n",
    "| exp_000 | XGBoost (13 features) | 0.8316 | 0.7584 | +7.32% | 37.6% |\n",
    "| exp_001 | Simple RF (7 features) | 0.8238 | 0.7775 | +4.63% | 31.3% |\n",
    "| exp_003 | Threshold-Tuned Ensemble | 0.8373 | 0.7847 | +5.26% | 31.1% |\n",
    "\n",
    "## Key Observations\n",
    "1. **Threshold tuning WORKED!** LB improved from 0.7775 to 0.7847 (+0.72%)\n",
    "2. **Best LB so far**: 0.7847 (78.47% accuracy)\n",
    "3. **CV-LB gap reduced**: From 7.32% (XGBoost) to 5.26% (Threshold-Tuned)\n",
    "4. **Survival rate hypothesis CONFIRMED**: Lower survival rate (~31%) performs better on LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effccfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load all submissions for comparison\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "# Load predictions\n",
    "xgb_pred = pd.read_csv('/home/code/submission_candidates/candidate_000.csv')\n",
    "rf_pred = pd.read_csv('/home/code/submission_candidates/candidate_001.csv')\n",
    "thresh_pred = pd.read_csv('/home/code/submission_candidates/candidate_003.csv')\n",
    "\n",
    "print(\"Survival rates:\")\n",
    "print(f\"  Training: {train['Survived'].mean():.3f}\")\n",
    "print(f\"  XGBoost (LB 0.7584): {xgb_pred['Survived'].mean():.3f}\")\n",
    "print(f\"  Simple RF (LB 0.7775): {rf_pred['Survived'].mean():.3f}\")\n",
    "print(f\"  Threshold-Tuned (LB 0.7847): {thresh_pred['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47a503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions between best models\n",
    "print(\"\\nPrediction Agreement Analysis:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# RF vs Threshold-Tuned\n",
    "rf_vs_thresh = (rf_pred['Survived'] == thresh_pred['Survived']).sum()\n",
    "print(f\"\\nSimple RF vs Threshold-Tuned:\")\n",
    "print(f\"  Agreement: {rf_vs_thresh}/418 ({rf_vs_thresh/418*100:.1f}%)\")\n",
    "print(f\"  Disagreement: {418-rf_vs_thresh} passengers\")\n",
    "\n",
    "# Where do they differ?\n",
    "diff_idx = rf_pred['Survived'] != thresh_pred['Survived']\n",
    "print(f\"\\nDifferences:\")\n",
    "print(f\"  RF=1, Thresh=0: {((rf_pred['Survived']==1) & (thresh_pred['Survived']==0)).sum()}\")\n",
    "print(f\"  RF=0, Thresh=1: {((rf_pred['Survived']==0) & (thresh_pred['Survived']==1)).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ec0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze passengers where models differ\n",
    "test_with_preds = test.copy()\n",
    "test_with_preds['RF_Pred'] = rf_pred['Survived']\n",
    "test_with_preds['Thresh_Pred'] = thresh_pred['Survived']\n",
    "test_with_preds['XGB_Pred'] = xgb_pred['Survived']\n",
    "\n",
    "# Extract Title\n",
    "test_with_preds['Title'] = test_with_preds['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Where RF=1 but Thresh=0 (RF predicts survival, Thresh doesn't)\n",
    "rf_yes_thresh_no = test_with_preds[(test_with_preds['RF_Pred']==1) & (test_with_preds['Thresh_Pred']==0)]\n",
    "print(f\"\\nPassengers where RF=1 but Thresh=0 ({len(rf_yes_thresh_no)} passengers):\")\n",
    "if len(rf_yes_thresh_no) > 0:\n",
    "    print(f\"  Sex: {rf_yes_thresh_no['Sex'].value_counts().to_dict()}\")\n",
    "    print(f\"  Pclass: {rf_yes_thresh_no['Pclass'].value_counts().to_dict()}\")\n",
    "    print(f\"  Title: {rf_yes_thresh_no['Title'].value_counts().to_dict()}\")\n",
    "\n",
    "# Where RF=0 but Thresh=1 (Thresh predicts survival, RF doesn't)\n",
    "rf_no_thresh_yes = test_with_preds[(test_with_preds['RF_Pred']==0) & (test_with_preds['Thresh_Pred']==1)]\n",
    "print(f\"\\nPassengers where RF=0 but Thresh=1 ({len(rf_no_thresh_yes)} passengers):\")\n",
    "if len(rf_no_thresh_yes) > 0:\n",
    "    print(f\"  Sex: {rf_no_thresh_yes['Sex'].value_counts().to_dict()}\")\n",
    "    print(f\"  Pclass: {rf_no_thresh_yes['Pclass'].value_counts().to_dict()}\")\n",
    "    print(f\"  Title: {rf_no_thresh_yes['Title'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate which model got more right on the disagreements\n",
    "# Since Thresh got LB 0.7847 and RF got 0.7775, Thresh is better by 3 passengers (0.72% of 418)\n",
    "\n",
    "lb_diff = 0.7847 - 0.7775\n",
    "passengers_diff = round(lb_diff * 418)\n",
    "print(f\"\\nLB Score Analysis:\")\n",
    "print(f\"  Threshold-Tuned: 0.7847\")\n",
    "print(f\"  Simple RF: 0.7775\")\n",
    "print(f\"  Difference: {lb_diff:.4f} ({passengers_diff} passengers)\")\n",
    "\n",
    "print(f\"\\nThis means Threshold-Tuned got ~{passengers_diff} more predictions correct than Simple RF.\")\n",
    "print(f\"The {418-rf_vs_thresh} disagreements between models resulted in net +{passengers_diff} for Threshold-Tuned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfcd0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the best possible score we can achieve?\n",
    "# State-of-the-art is 81-85% accuracy\n",
    "# Current best: 0.7847\n",
    "# Target: 1.0 (impossible)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCORE TRAJECTORY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSubmission History:\")\n",
    "print(f\"  #1: XGBoost (13 features) → LB 0.7584\")\n",
    "print(f\"  #2: Simple RF (7 features) → LB 0.7775 (+1.91%)\")\n",
    "print(f\"  #3: Threshold-Tuned Ensemble → LB 0.7847 (+0.72%)\")\n",
    "print(f\"\\nTotal improvement: +2.63% (from 0.7584 to 0.7847)\")\n",
    "print(f\"\\nState-of-the-art: 0.81-0.85\")\n",
    "print(f\"Gap to close: {0.81 - 0.7847:.4f} to {0.85 - 0.7847:.4f}\")\n",
    "print(f\"\\nTarget: 1.0 (IMPOSSIBLE - inherent noise in data)\")\n",
    "print(f\"\\nRealistic goal: 0.80+ would be excellent (top ~10%)\")\n",
    "print(f\"Current position: 0.7847 is competitive but not top-tier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af632e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What strategies could push us to 0.80+?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGIES TO REACH 0.80+\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. STACKING (proven to achieve 0.808 LB)\n",
    "   - Use 5 base models: RF, ExtraTrees, AdaBoost, GradientBoosting, SVC\n",
    "   - Generate OOF predictions using 5-fold CV\n",
    "   - Train XGBoost as meta-learner on stacked predictions\n",
    "   - Apply threshold tuning to final predictions\n",
    "\n",
    "2. BLENDING RF + Threshold-Tuned Ensemble\n",
    "   - Average predictions from both models\n",
    "   - Or use weighted average based on LB performance\n",
    "   - Simple RF: 0.7775, Threshold-Tuned: 0.7847\n",
    "\n",
    "3. FEATURE ENGINEERING\n",
    "   - Add FamilySize, IsAlone features\n",
    "   - Add Has_Cabin, Deck features\n",
    "   - Ticket frequency (passengers sharing same ticket)\n",
    "   - Age/Fare binning\n",
    "\n",
    "4. THRESHOLD OPTIMIZATION\n",
    "   - Current threshold 0.608 gave 31.1% survival\n",
    "   - Try threshold 0.55 (best OOF accuracy 0.8418, 34.4% survival)\n",
    "   - Find optimal threshold that balances OOF accuracy and survival rate\n",
    "\n",
    "5. MODEL DIVERSITY\n",
    "   - Add CatBoost, LightGBM to ensemble\n",
    "   - Neural network (simple MLP)\n",
    "   - Different feature subsets for different models\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd8e55",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Threshold tuning validated**: LB improved from 0.7775 to 0.7847 by adjusting threshold to match ~31% survival rate\n",
    "\n",
    "2. **CV-LB gap is consistent**: ~5% gap is expected for this dataset\n",
    "\n",
    "3. **Survival rate matters**: Lower survival rate predictions (~31%) perform better than training rate (38.4%)\n",
    "\n",
    "4. **Next steps**:\n",
    "   - Stacking is the most promising approach (proven 0.808 LB)\n",
    "   - Blending RF + Threshold-Tuned could also help\n",
    "   - More feature engineering (FamilySize, Has_Cabin, Deck)\n",
    "\n",
    "5. **Target of 1.0 is impossible**: Focus on incremental improvements toward 0.80+"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
