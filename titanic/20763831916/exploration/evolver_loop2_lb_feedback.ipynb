{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82c4529",
   "metadata": {},
   "source": [
    "# Loop 2 LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- **exp_000 (XGBoost 13 features)**: CV 0.8316 → LB 0.7584 (gap: +7.3%)\n",
    "- **exp_001 (Simple RF 7 features)**: CV 0.8238 → LB 0.7775 (gap: +4.6%)\n",
    "\n",
    "## Key Insight\n",
    "The simpler model hypothesis was **VALIDATED**:\n",
    "- LB improved by 1.9% (0.7584 → 0.7775)\n",
    "- CV-LB gap reduced from 7.3% to 4.6%\n",
    "\n",
    "This confirms that the baseline was overfitting to training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dbfca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Analyze the two submissions\n",
    "results = {\n",
    "    'Experiment': ['exp_000 (XGBoost 13 features)', 'exp_001 (Simple RF 7 features)'],\n",
    "    'CV Score': [0.8316, 0.8238],\n",
    "    'LB Score': [0.7584, 0.7775],\n",
    "    'CV-LB Gap': [0.8316 - 0.7584, 0.8238 - 0.7775]\n",
    "}\n",
    "df = pd.DataFrame(results)\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nLB Improvement: {0.7775 - 0.7584:.4f} (+{(0.7775 - 0.7584)/0.7584*100:.1f}%)\")\n",
    "print(f\"Gap Reduction: {(0.8316 - 0.7584) - (0.8238 - 0.7775):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to understand what's happening\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(\"Training data shape:\", train.shape)\n",
    "print(\"Test data shape:\", test.shape)\n",
    "print(f\"\\nTraining survival rate: {train['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba9e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both submissions and compare\n",
    "try:\n",
    "    sub_baseline = pd.read_csv('/home/code/submission_candidates/candidate_000.csv')\n",
    "    sub_simple = pd.read_csv('/home/code/submission_candidates/candidate_001.csv')\n",
    "    \n",
    "    print(\"Baseline (XGBoost) survival rate:\", sub_baseline['Survived'].mean())\n",
    "    print(\"Simple RF survival rate:\", sub_simple['Survived'].mean())\n",
    "    \n",
    "    # Compare predictions\n",
    "    agreement = (sub_baseline['Survived'] == sub_simple['Survived']).mean()\n",
    "    print(f\"\\nPrediction agreement: {agreement:.1%}\")\n",
    "    \n",
    "    # Where do they differ?\n",
    "    diff_mask = sub_baseline['Survived'] != sub_simple['Survived']\n",
    "    print(f\"Different predictions: {diff_mask.sum()} passengers\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading submissions: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6acba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the passengers where predictions differ\n",
    "if diff_mask.sum() > 0:\n",
    "    diff_ids = sub_baseline[diff_mask]['PassengerId'].values\n",
    "    diff_test = test[test['PassengerId'].isin(diff_ids)].copy()\n",
    "    \n",
    "    print(f\"Passengers with different predictions: {len(diff_test)}\")\n",
    "    print(\"\\nSex distribution:\")\n",
    "    print(diff_test['Sex'].value_counts())\n",
    "    print(\"\\nPclass distribution:\")\n",
    "    print(diff_test['Pclass'].value_counts())\n",
    "    \n",
    "    # What did each model predict?\n",
    "    baseline_preds = sub_baseline[diff_mask]['Survived'].values\n",
    "    simple_preds = sub_simple[diff_mask]['Survived'].values\n",
    "    \n",
    "    print(f\"\\nBaseline predicted survivors: {baseline_preds.sum()}\")\n",
    "    print(f\"Simple RF predicted survivors: {simple_preds.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e194700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: Simple RF predicts fewer survivors but scores BETTER on LB\n",
    "# This suggests the baseline was over-predicting survival\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\\nBaseline (XGBoost 13 features):\n",
    "- CV: 0.8316 (higher)\n",
    "- LB: 0.7584 (lower)\n",
    "- Survival rate: {sub_baseline['Survived'].mean():.3f}\n",
    "\n",
    "Simple RF (7 features):\n",
    "- CV: 0.8238 (lower)\n",
    "- LB: 0.7775 (higher!)\n",
    "- Survival rate: {sub_simple['Survived'].mean():.3f}\n",
    "\n",
    "Conclusion:\n",
    "1. The simpler model generalizes BETTER despite lower CV\n",
    "2. The baseline was overfitting to training patterns\n",
    "3. Reducing features from 13 to 7 improved LB by 2%\n",
    "4. The CV-LB gap reduced from 7.3% to 4.6%\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the next step?\n",
    "print(\"=\"*60)\n",
    "print(\"NEXT STEPS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. The simpler model approach is VALIDATED\n",
    "   - Continue with simple feature sets\n",
    "   - Consider adding back Title (captures sex + social status)\n",
    "\n",
    "2. Ensemble methods should help further\n",
    "   - Voting ensemble with diverse models\n",
    "   - Stacking with out-of-fold predictions\n",
    "   - Use the same simple feature set\n",
    "\n",
    "3. Target: 1.0 is IMPOSSIBLE\n",
    "   - State-of-the-art is 81-85% accuracy\n",
    "   - Current best LB: 0.7775 (77.75%)\n",
    "   - Realistic target: 0.80-0.81 (80-81%)\n",
    "   - Need ~2-3% improvement\n",
    "\n",
    "4. Remaining submissions: 6\n",
    "   - Use wisely to validate ensemble approaches\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8878334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what we need to beat\n",
    "target = 1.0\n",
    "current_best_lb = 0.7775\n",
    "gap_to_target = target - current_best_lb\n",
    "\n",
    "print(f\"Target: {target}\")\n",
    "print(f\"Current best LB: {current_best_lb}\")\n",
    "print(f\"Gap to target: {gap_to_target:.4f} ({gap_to_target*100:.1f}%)\")\n",
    "print(f\"\\nNOTE: Target of 1.0 (100% accuracy) is IMPOSSIBLE for Titanic.\")\n",
    "print(f\"State-of-the-art is ~0.85 (85%). Best public solutions achieve ~0.81-0.85.\")\n",
    "print(f\"\\nRealistic goal: Achieve 0.80+ (80%+ accuracy)\")\n",
    "print(f\"Gap to realistic goal: {0.80 - current_best_lb:.4f} ({(0.80 - current_best_lb)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1a35eb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Learned\n",
    "1. **Simpler models generalize better** - The 7-feature RF outperformed 13-feature XGBoost on LB\n",
    "2. **CV-LB gap reduced** - From 7.3% to 4.6%, indicating less overfitting\n",
    "3. **Feature engineering can hurt** - Too many features led to overfitting\n",
    "\n",
    "### Strategy Going Forward\n",
    "1. **Keep features simple** - 7-10 core features maximum\n",
    "2. **Add Title back** - It captures sex + social status, was 0.08 importance\n",
    "3. **Try ensemble methods** - Voting/stacking with simple feature set\n",
    "4. **Focus on LB, not CV** - CV is not reliable for this problem\n",
    "\n",
    "### Target Reality Check\n",
    "- Target of 1.0 is impossible (100% accuracy)\n",
    "- State-of-the-art is 81-85%\n",
    "- Current best: 77.75%\n",
    "- Realistic improvement: 2-3% to reach ~80%"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
