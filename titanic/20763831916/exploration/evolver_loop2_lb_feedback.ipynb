{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82c4529",
   "metadata": {},
   "source": [
    "# Loop 2 LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- **exp_000 (XGBoost 13 features)**: CV 0.8316 → LB 0.7584 (gap: +7.3%)\n",
    "- **exp_001 (Simple RF 7 features)**: CV 0.8238 → LB 0.7775 (gap: +4.6%)\n",
    "\n",
    "## Key Insight\n",
    "The simpler model hypothesis was **VALIDATED**:\n",
    "- LB improved by 1.9% (0.7584 → 0.7775)\n",
    "- CV-LB gap reduced from 7.3% to 4.6%\n",
    "\n",
    "This confirms that the baseline was overfitting to training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64dbfca0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:38:30.157177Z",
     "iopub.status.busy": "2026-01-06T22:38:30.156355Z",
     "iopub.status.idle": "2026-01-06T22:38:30.629029Z",
     "shell.execute_reply": "2026-01-06T22:38:30.628365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Experiment  CV Score  LB Score  CV-LB Gap\n",
      " exp_000 (XGBoost 13 features)    0.8316    0.7584     0.0732\n",
      "exp_001 (Simple RF 7 features)    0.8238    0.7775     0.0463\n",
      "\n",
      "LB Improvement: 0.0191 (+2.5%)\n",
      "Gap Reduction: 0.0269\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Analyze the two submissions\n",
    "results = {\n",
    "    'Experiment': ['exp_000 (XGBoost 13 features)', 'exp_001 (Simple RF 7 features)'],\n",
    "    'CV Score': [0.8316, 0.8238],\n",
    "    'LB Score': [0.7584, 0.7775],\n",
    "    'CV-LB Gap': [0.8316 - 0.7584, 0.8238 - 0.7775]\n",
    "}\n",
    "df = pd.DataFrame(results)\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nLB Improvement: {0.7775 - 0.7584:.4f} (+{(0.7775 - 0.7584)/0.7584*100:.1f}%)\")\n",
    "print(f\"Gap Reduction: {(0.8316 - 0.7584) - (0.8238 - 0.7775):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a411b2d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:38:30.631254Z",
     "iopub.status.busy": "2026-01-06T22:38:30.630959Z",
     "iopub.status.idle": "2026-01-06T22:38:30.643348Z",
     "shell.execute_reply": "2026-01-06T22:38:30.642789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (891, 12)\n",
      "Test data shape: (418, 11)\n",
      "\n",
      "Training survival rate: 0.384\n"
     ]
    }
   ],
   "source": [
    "# Load data to understand what's happening\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(\"Training data shape:\", train.shape)\n",
    "print(\"Test data shape:\", test.shape)\n",
    "print(f\"\\nTraining survival rate: {train['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba9e67c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:38:30.645295Z",
     "iopub.status.busy": "2026-01-06T22:38:30.645080Z",
     "iopub.status.idle": "2026-01-06T22:38:30.653483Z",
     "shell.execute_reply": "2026-01-06T22:38:30.652899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (XGBoost) survival rate: 0.37559808612440193\n",
      "Simple RF survival rate: 0.3133971291866029\n",
      "\n",
      "Prediction agreement: 91.4%\n",
      "Different predictions: 36 passengers\n"
     ]
    }
   ],
   "source": [
    "# Load both submissions and compare\n",
    "try:\n",
    "    sub_baseline = pd.read_csv('/home/code/submission_candidates/candidate_000.csv')\n",
    "    sub_simple = pd.read_csv('/home/code/submission_candidates/candidate_001.csv')\n",
    "    \n",
    "    print(\"Baseline (XGBoost) survival rate:\", sub_baseline['Survived'].mean())\n",
    "    print(\"Simple RF survival rate:\", sub_simple['Survived'].mean())\n",
    "    \n",
    "    # Compare predictions\n",
    "    agreement = (sub_baseline['Survived'] == sub_simple['Survived']).mean()\n",
    "    print(f\"\\nPrediction agreement: {agreement:.1%}\")\n",
    "    \n",
    "    # Where do they differ?\n",
    "    diff_mask = sub_baseline['Survived'] != sub_simple['Survived']\n",
    "    print(f\"Different predictions: {diff_mask.sum()} passengers\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading submissions: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de6acba1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:38:30.655702Z",
     "iopub.status.busy": "2026-01-06T22:38:30.655075Z",
     "iopub.status.idle": "2026-01-06T22:38:30.665177Z",
     "shell.execute_reply": "2026-01-06T22:38:30.664610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passengers with different predictions: 36\n",
      "\n",
      "Sex distribution:\n",
      "Sex\n",
      "male      19\n",
      "female    17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Pclass distribution:\n",
      "Pclass\n",
      "3    26\n",
      "1     9\n",
      "2     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Baseline predicted survivors: 31\n",
      "Simple RF predicted survivors: 5\n"
     ]
    }
   ],
   "source": [
    "# Analyze the passengers where predictions differ\n",
    "if diff_mask.sum() > 0:\n",
    "    diff_ids = sub_baseline[diff_mask]['PassengerId'].values\n",
    "    diff_test = test[test['PassengerId'].isin(diff_ids)].copy()\n",
    "    \n",
    "    print(f\"Passengers with different predictions: {len(diff_test)}\")\n",
    "    print(\"\\nSex distribution:\")\n",
    "    print(diff_test['Sex'].value_counts())\n",
    "    print(\"\\nPclass distribution:\")\n",
    "    print(diff_test['Pclass'].value_counts())\n",
    "    \n",
    "    # What did each model predict?\n",
    "    baseline_preds = sub_baseline[diff_mask]['Survived'].values\n",
    "    simple_preds = sub_simple[diff_mask]['Survived'].values\n",
    "    \n",
    "    print(f\"\\nBaseline predicted survivors: {baseline_preds.sum()}\")\n",
    "    print(f\"Simple RF predicted survivors: {simple_preds.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e194700",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:38:30.666878Z",
     "iopub.status.busy": "2026-01-06T22:38:30.666650Z",
     "iopub.status.idle": "2026-01-06T22:38:30.676034Z",
     "shell.execute_reply": "2026-01-06T22:38:30.675451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KEY INSIGHT\n",
      "============================================================\n",
      "\n",
      "Baseline (XGBoost 13 features):\n",
      "- CV: 0.8316 (higher)\n",
      "- LB: 0.7584 (lower)\n",
      "- Survival rate: 0.376\n",
      "\n",
      "Simple RF (7 features):\n",
      "- CV: 0.8238 (lower)\n",
      "- LB: 0.7775 (higher!)\n",
      "- Survival rate: 0.313\n",
      "\n",
      "Conclusion:\n",
      "1. The simpler model generalizes BETTER despite lower CV\n",
      "2. The baseline was overfitting to training patterns\n",
      "3. Reducing features from 13 to 7 improved LB by 2%\n",
      "4. The CV-LB gap reduced from 7.3% to 4.6%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Key insight: Simple RF predicts fewer survivors but scores BETTER on LB\n",
    "# This suggests the baseline was over-predicting survival\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\\nBaseline (XGBoost 13 features):\n",
    "- CV: 0.8316 (higher)\n",
    "- LB: 0.7584 (lower)\n",
    "- Survival rate: {sub_baseline['Survived'].mean():.3f}\n",
    "\n",
    "Simple RF (7 features):\n",
    "- CV: 0.8238 (lower)\n",
    "- LB: 0.7775 (higher!)\n",
    "- Survival rate: {sub_simple['Survived'].mean():.3f}\n",
    "\n",
    "Conclusion:\n",
    "1. The simpler model generalizes BETTER despite lower CV\n",
    "2. The baseline was overfitting to training patterns\n",
    "3. Reducing features from 13 to 7 improved LB by 2%\n",
    "4. The CV-LB gap reduced from 7.3% to 4.6%\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd4ebad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:38:30.677767Z",
     "iopub.status.busy": "2026-01-06T22:38:30.677516Z",
     "iopub.status.idle": "2026-01-06T22:38:30.692287Z",
     "shell.execute_reply": "2026-01-06T22:38:30.691724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NEXT STEPS ANALYSIS\n",
      "============================================================\n",
      "\n",
      "1. The simpler model approach is VALIDATED\n",
      "   - Continue with simple feature sets\n",
      "   - Consider adding back Title (captures sex + social status)\n",
      "\n",
      "2. Ensemble methods should help further\n",
      "   - Voting ensemble with diverse models\n",
      "   - Stacking with out-of-fold predictions\n",
      "   - Use the same simple feature set\n",
      "\n",
      "3. Target: 1.0 is IMPOSSIBLE\n",
      "   - State-of-the-art is 81-85% accuracy\n",
      "   - Current best LB: 0.7775 (77.75%)\n",
      "   - Realistic target: 0.80-0.81 (80-81%)\n",
      "   - Need ~2-3% improvement\n",
      "\n",
      "4. Remaining submissions: 6\n",
      "   - Use wisely to validate ensemble approaches\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What's the next step?\n",
    "print(\"=\"*60)\n",
    "print(\"NEXT STEPS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. The simpler model approach is VALIDATED\n",
    "   - Continue with simple feature sets\n",
    "   - Consider adding back Title (captures sex + social status)\n",
    "\n",
    "2. Ensemble methods should help further\n",
    "   - Voting ensemble with diverse models\n",
    "   - Stacking with out-of-fold predictions\n",
    "   - Use the same simple feature set\n",
    "\n",
    "3. Target: 1.0 is IMPOSSIBLE\n",
    "   - State-of-the-art is 81-85% accuracy\n",
    "   - Current best LB: 0.7775 (77.75%)\n",
    "   - Realistic target: 0.80-0.81 (80-81%)\n",
    "   - Need ~2-3% improvement\n",
    "\n",
    "4. Remaining submissions: 6\n",
    "   - Use wisely to validate ensemble approaches\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8878334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T22:38:30.694223Z",
     "iopub.status.busy": "2026-01-06T22:38:30.694000Z",
     "iopub.status.idle": "2026-01-06T22:38:30.699227Z",
     "shell.execute_reply": "2026-01-06T22:38:30.698698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1.0\n",
      "Current best LB: 0.7775\n",
      "Gap to target: 0.2225 (22.3%)\n",
      "\n",
      "NOTE: Target of 1.0 (100% accuracy) is IMPOSSIBLE for Titanic.\n",
      "State-of-the-art is ~0.85 (85%). Best public solutions achieve ~0.81-0.85.\n",
      "\n",
      "Realistic goal: Achieve 0.80+ (80%+ accuracy)\n",
      "Gap to realistic goal: 0.0225 (2.3%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate what we need to beat\n",
    "target = 1.0\n",
    "current_best_lb = 0.7775\n",
    "gap_to_target = target - current_best_lb\n",
    "\n",
    "print(f\"Target: {target}\")\n",
    "print(f\"Current best LB: {current_best_lb}\")\n",
    "print(f\"Gap to target: {gap_to_target:.4f} ({gap_to_target*100:.1f}%)\")\n",
    "print(f\"\\nNOTE: Target of 1.0 (100% accuracy) is IMPOSSIBLE for Titanic.\")\n",
    "print(f\"State-of-the-art is ~0.85 (85%). Best public solutions achieve ~0.81-0.85.\")\n",
    "print(f\"\\nRealistic goal: Achieve 0.80+ (80%+ accuracy)\")\n",
    "print(f\"Gap to realistic goal: {0.80 - current_best_lb:.4f} ({(0.80 - current_best_lb)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1a35eb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Learned\n",
    "1. **Simpler models generalize better** - The 7-feature RF outperformed 13-feature XGBoost on LB\n",
    "2. **CV-LB gap reduced** - From 7.3% to 4.6%, indicating less overfitting\n",
    "3. **Feature engineering can hurt** - Too many features led to overfitting\n",
    "\n",
    "### Strategy Going Forward\n",
    "1. **Keep features simple** - 7-10 core features maximum\n",
    "2. **Add Title back** - It captures sex + social status, was 0.08 importance\n",
    "3. **Try ensemble methods** - Voting/stacking with simple feature set\n",
    "4. **Focus on LB, not CV** - CV is not reliable for this problem\n",
    "\n",
    "### Target Reality Check\n",
    "- Target of 1.0 is impossible (100% accuracy)\n",
    "- State-of-the-art is 81-85%\n",
    "- Current best: 77.75%\n",
    "- Realistic improvement: 2-3% to reach ~80%"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
