{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a6fbcb",
   "metadata": {},
   "source": [
    "# Evolver Loop 1 Analysis\n",
    "\n",
    "Analysis of current state and identification of improvement opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc1bee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:06.008498Z",
     "iopub.status.busy": "2026-01-15T00:30:06.007778Z",
     "iopub.status.idle": "2026-01-15T00:30:07.361335Z",
     "shell.execute_reply": "2026-01-15T00:30:07.360797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(\"\\nTrain info:\")\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8d7ed0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:07.363444Z",
     "iopub.status.busy": "2026-01-15T00:30:07.362959Z",
     "iopub.status.idle": "2026-01-15T00:30:07.370376Z",
     "shell.execute_reply": "2026-01-15T00:30:07.369874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Results:\n",
      "Mean CV Score: 0.8541 ± 0.0226\n",
      "OOF Accuracy: 0.8541\n",
      "CV Scores: ['0.8827', '0.8652', '0.8146', '0.8483', '0.8596']\n",
      "\n",
      "Top Features:\n",
      "         feature   importance\n",
      "0            Sex  1524.733730\n",
      "1  FarePerPerson   602.632620\n",
      "2            Age   579.309369\n",
      "3           Fare   539.415274\n",
      "4         Pclass   453.235429\n",
      "5          Title   373.418227\n",
      "6    CabinLetter   221.311582\n",
      "7       Embarked   136.412549\n",
      "8          SibSp   100.128826\n",
      "9     FamilySize    86.340292\n"
     ]
    }
   ],
   "source": [
    "# Load previous experiment results\n",
    "with open('/home/code/experiments/001_baseline_results.json', 'r') as f:\n",
    "    baseline_results = json.load(f)\n",
    "\n",
    "print(\"Baseline Results:\")\n",
    "print(f\"Mean CV Score: {baseline_results['mean_cv_score']:.4f} ± {baseline_results['std_cv_score']:.4f}\")\n",
    "print(f\"OOF Accuracy: {baseline_results['oof_accuracy']:.4f}\")\n",
    "print(f\"CV Scores: {[f'{score:.4f}' for score in baseline_results['cv_scores']]}\")\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame(baseline_results['feature_importance'])\n",
    "print(\"\\nTop Features:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3e5ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:07.372327Z",
     "iopub.status.busy": "2026-01-15T00:30:07.371813Z",
     "iopub.status.idle": "2026-01-15T00:30:07.379323Z",
     "shell.execute_reply": "2026-01-15T00:30:07.378773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Train:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Test:\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "\n",
      "Target distribution in train:\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analyze missing values\n",
    "print(\"Missing Values in Train:\")\n",
    "print(train_df.isnull().sum())\n",
    "print(\"\\nMissing Values in Test:\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# Analyze target distribution\n",
    "print(f\"\\nTarget distribution in train:\")\n",
    "print(train_df['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63edd12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:07.381100Z",
     "iopub.status.busy": "2026-01-15T00:30:07.380721Z",
     "iopub.status.idle": "2026-01-15T00:30:07.393394Z",
     "shell.execute_reply": "2026-01-15T00:30:07.392914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival by Sex:\n",
      "        Total  Survived  Survival_Rate\n",
      "Sex                                   \n",
      "female    314       233       0.742038\n",
      "male      577       109       0.188908\n",
      "\n",
      "Survival by Pclass:\n",
      "        Total  Survived  Survival_Rate\n",
      "Pclass                                \n",
      "1         216       136       0.629630\n",
      "2         184        87       0.472826\n",
      "3         491       119       0.242363\n",
      "\n",
      "Survival by Embarked:\n",
      "          Total  Survived  Survival_Rate\n",
      "Embarked                                \n",
      "C           168        93       0.553571\n",
      "Q            77        30       0.389610\n",
      "S           644       217       0.336957\n"
     ]
    }
   ],
   "source": [
    "# Analyze feature distributions by target\n",
    "# Sex feature\n",
    "print(\"Survival by Sex:\")\n",
    "sex_survival = train_df.groupby('Sex')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "sex_survival.columns = ['Total', 'Survived', 'Survival_Rate']\n",
    "print(sex_survival)\n",
    "\n",
    "# Pclass feature\n",
    "print(\"\\nSurvival by Pclass:\")\n",
    "pclass_survival = train_df.groupby('Pclass')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "pclass_survival.columns = ['Total', 'Survived', 'Survival_Rate']\n",
    "print(pclass_survival)\n",
    "\n",
    "# Embarked feature\n",
    "print(\"\\nSurvival by Embarked:\")\n",
    "embarked_survival = train_df.groupby('Embarked')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "embarked_survival.columns = ['Total', 'Survived', 'Survival_Rate']\n",
    "print(embarked_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91a22422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:07.395308Z",
     "iopub.status.busy": "2026-01-15T00:30:07.394862Z",
     "iopub.status.idle": "2026-01-15T00:30:07.406531Z",
     "shell.execute_reply": "2026-01-15T00:30:07.405992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age statistics:\n",
      "count    714.000000\n",
      "mean      29.699118\n",
      "std       14.526497\n",
      "min        0.420000\n",
      "25%       20.125000\n",
      "50%       28.000000\n",
      "75%       38.000000\n",
      "max       80.000000\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "Survival by AgeGroup:\n",
      "            Total  Survived  Survival_Rate\n",
      "AgeGroup                                  \n",
      "Child          69        40       0.579710\n",
      "Teen           70        30       0.428571\n",
      "YoungAdult    358       137       0.382682\n",
      "Adult         195        78       0.400000\n",
      "Senior         22         5       0.227273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48839/4263522885.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  age_survival = train_df.groupby('AgeGroup')['Survived'].agg(['count', 'sum', 'mean'])\n"
     ]
    }
   ],
   "source": [
    "# Analyze Age patterns\n",
    "print(\"Age statistics:\")\n",
    "print(train_df['Age'].describe())\n",
    "\n",
    "# Create age groups and analyze survival\n",
    "age_bins = [0, 12, 18, 35, 60, 100]\n",
    "age_labels = ['Child', 'Teen', 'YoungAdult', 'Adult', 'Senior']\n",
    "train_df['AgeGroup'] = pd.cut(train_df['Age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "print(\"\\nSurvival by AgeGroup:\")\n",
    "age_survival = train_df.groupby('AgeGroup')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "age_survival.columns = ['Total', 'Survived', 'Survival_Rate']\n",
    "print(age_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e700ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:07.408213Z",
     "iopub.status.busy": "2026-01-15T00:30:07.407760Z",
     "iopub.status.idle": "2026-01-15T00:30:07.418683Z",
     "shell.execute_reply": "2026-01-15T00:30:07.418211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival by FamilySize:\n",
      "            Total  Survived  Survival_Rate\n",
      "FamilySize                                \n",
      "1             537       163       0.303538\n",
      "2             161        89       0.552795\n",
      "3             102        59       0.578431\n",
      "4              29        21       0.724138\n",
      "5              15         3       0.200000\n",
      "6              22         3       0.136364\n",
      "7              12         4       0.333333\n",
      "8               6         0       0.000000\n",
      "11              7         0       0.000000\n",
      "\n",
      "Survival by IsAlone:\n",
      "         Total  Survived  Survival_Rate\n",
      "IsAlone                                \n",
      "0          354       179       0.505650\n",
      "1          537       163       0.303538\n"
     ]
    }
   ],
   "source": [
    "# Analyze family features\n",
    "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
    "print(\"Survival by FamilySize:\")\n",
    "family_survival = train_df.groupby('FamilySize')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "family_survival.columns = ['Total', 'Survived', 'Survival_Rate']\n",
    "print(family_survival.head(10))\n",
    "\n",
    "# Create IsAlone feature\n",
    "train_df['IsAlone'] = (train_df['FamilySize'] == 1).astype(int)\n",
    "print(\"\\nSurvival by IsAlone:\")\n",
    "alone_survival = train_df.groupby('IsAlone')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "alone_survival.columns = ['Total', 'Survived', 'Survival_Rate']\n",
    "print(alone_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "335d1940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:07.420369Z",
     "iopub.status.busy": "2026-01-15T00:30:07.420182Z",
     "iopub.status.idle": "2026-01-15T00:30:07.432227Z",
     "shell.execute_reply": "2026-01-15T00:30:07.431544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fare statistics:\n",
      "count    891.000000\n",
      "mean      32.204208\n",
      "std       49.693429\n",
      "min        0.000000\n",
      "25%        7.910400\n",
      "50%       14.454200\n",
      "75%       31.000000\n",
      "max      512.329200\n",
      "Name: Fare, dtype: float64\n",
      "\n",
      "Survival by FareBin:\n",
      "          Total  Survived  Survival_Rate\n",
      "FareBin                                 \n",
      "VeryLow     179        39       0.217877\n",
      "Low         184        37       0.201087\n",
      "Medium      172        73       0.424419\n",
      "High        180        80       0.444444\n",
      "VeryHigh    176       113       0.642045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48839/2325912622.py:8: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  fare_survival = train_df.groupby('FareBin')['Survived'].agg(['count', 'sum', 'mean'])\n"
     ]
    }
   ],
   "source": [
    "# Analyze Fare patterns\n",
    "print(\"Fare statistics:\")\n",
    "print(train_df['Fare'].describe())\n",
    "\n",
    "# Create fare bins\n",
    "train_df['FareBin'] = pd.qcut(train_df['Fare'], q=5, labels=['VeryLow', 'Low', 'Medium', 'High', 'VeryHigh'])\n",
    "print(\"\\nSurvival by FareBin:\")\n",
    "fare_survival = train_df.groupby('FareBin')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "fare_survival.columns = ['Total', 'Survived', 'Survival_Rate']\n",
    "print(fare_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1b5bb58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:07.434118Z",
     "iopub.status.busy": "2026-01-15T00:30:07.433753Z",
     "iopub.status.idle": "2026-01-15T00:30:07.442590Z",
     "shell.execute_reply": "2026-01-15T00:30:07.442081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title distribution:\n",
      "Title\n",
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Col           2\n",
      "Mlle          2\n",
      "Major         2\n",
      "Ms            1\n",
      "Mme           1\n",
      "Don           1\n",
      "Lady          1\n",
      "Sir           1\n",
      "Capt          1\n",
      "Countess      1\n",
      "Jonkheer      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Survival by Title:\n",
      "          Total  Survived  Survival_Rate\n",
      "Title                                   \n",
      "Capt          1         0       0.000000\n",
      "Col           2         1       0.500000\n",
      "Countess      1         1       1.000000\n",
      "Don           1         0       0.000000\n",
      "Dr            7         3       0.428571\n",
      "Jonkheer      1         0       0.000000\n",
      "Lady          1         1       1.000000\n",
      "Major         2         1       0.500000\n",
      "Master       40        23       0.575000\n",
      "Miss        182       127       0.697802\n",
      "Mlle          2         2       1.000000\n",
      "Mme           1         1       1.000000\n",
      "Mr          517        81       0.156673\n",
      "Mrs         125        99       0.792000\n",
      "Ms            1         1       1.000000\n",
      "Rev           6         0       0.000000\n",
      "Sir           1         1       1.000000\n"
     ]
    }
   ],
   "source": [
    "# Analyze Title patterns (extracted from Name)\n",
    "train_df['Title'] = train_df['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
    "\n",
    "print(\"Title distribution:\")\n",
    "print(train_df['Title'].value_counts())\n",
    "\n",
    "print(\"\\nSurvival by Title:\")\n",
    "title_survival = train_df.groupby('Title')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "title_survival.columns = ['Total', 'Survived', 'Survival_Rate']\n",
    "print(title_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "698c2c8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:07.444080Z",
     "iopub.status.busy": "2026-01-15T00:30:07.443922Z",
     "iopub.status.idle": "2026-01-15T00:30:07.455790Z",
     "shell.execute_reply": "2026-01-15T00:30:07.455309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival by HasCabin:\n",
      "          Total  Survived  Survival_Rate\n",
      "HasCabin                                \n",
      "0           687       206       0.299854\n",
      "1           204       136       0.666667\n",
      "\n",
      "Survival by CabinLetter:\n",
      "             Total  Survived  Survival_Rate\n",
      "CabinLetter                                \n",
      "A               15         7       0.466667\n",
      "B               47        35       0.744681\n",
      "C               59        35       0.593220\n",
      "D               33        25       0.757576\n",
      "E               32        24       0.750000\n",
      "F               13         8       0.615385\n",
      "G                4         2       0.500000\n",
      "T                1         0       0.000000\n",
      "Unknown        687       206       0.299854\n"
     ]
    }
   ],
   "source": [
    "# Analyze Cabin patterns\n",
    "train_df['HasCabin'] = train_df['Cabin'].notna().astype(int)\n",
    "train_df['CabinLetter'] = train_df['Cabin'].str[0]\n",
    "train_df['CabinLetter'] = train_df['CabinLetter'].fillna('Unknown')\n",
    "\n",
    "print(\"Survival by HasCabin:\")\n",
    "cabin_survival = train_df.groupby('HasCabin')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "cabin_survival.columns = ['Total', 'Survived', 'Survival_Rate']\n",
    "print(cabin_survival)\n",
    "\n",
    "print(\"\\nSurvival by CabinLetter:\")\n",
    "cabin_letter_survival = train_df.groupby('CabinLetter')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "cabin_letter_survival.columns = ['Total', 'Survived', 'Survival_Rate']\n",
    "print(cabin_letter_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba9f14a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:51.931312Z",
     "iopub.status.busy": "2026-01-15T00:30:51.930697Z",
     "iopub.status.idle": "2026-01-15T00:30:51.941508Z",
     "shell.execute_reply": "2026-01-15T00:30:51.940978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential new feature ideas:\n",
      "\n",
      "1. NameLength correlation with survival: 0.3323\n",
      "\n",
      "2. TicketPrefix distribution:\n",
      "TicketPrefix\n",
      "None    661\n",
      "PC       60\n",
      "C        33\n",
      "A        29\n",
      "STON     18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "3. FarePerPerson correlation with survival: 0.2216\n",
      "\n",
      "4. Family survival rate feature - needs careful implementation to avoid leakage\n"
     ]
    }
   ],
   "source": [
    "# Identify potential new features\n",
    "print(\"Potential new feature ideas:\")\n",
    "\n",
    "# 1. Name length\n",
    "train_df['NameLength'] = train_df['Name'].str.len()\n",
    "print(f\"\\n1. NameLength correlation with survival: {train_df['NameLength'].corr(train_df['Survived']):.4f}\")\n",
    "\n",
    "# 2. Ticket patterns - check if ticket has numbers only or mixed\n",
    "train_df['TicketPrefix'] = train_df['Ticket'].str.extract('([A-Za-z]+)', expand=False)\n",
    "train_df['TicketPrefix'] = train_df['TicketPrefix'].fillna('None')\n",
    "print(\"\\n2. TicketPrefix distribution:\")\n",
    "print(train_df['TicketPrefix'].value_counts().head())\n",
    "\n",
    "# 3. Fare per person (already in baseline)\n",
    "train_df['FarePerPerson'] = train_df['Fare'] / train_df['FamilySize']\n",
    "print(f\"\\n3. FarePerPerson correlation with survival: {train_df['FarePerPerson'].corr(train_df['Survived']):.4f}\")\n",
    "\n",
    "# 4. Family survival rate (would need cross-validation to avoid leakage)\n",
    "print(\"\\n4. Family survival rate feature - needs careful implementation to avoid leakage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16a5cf67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:51.943253Z",
     "iopub.status.busy": "2026-01-15T00:30:51.942866Z",
     "iopub.status.idle": "2026-01-15T00:30:51.950542Z",
     "shell.execute_reply": "2026-01-15T00:30:51.950075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Leakage Analysis:\n",
      "==================================================\n",
      "\n",
      "1. Current preprocessing approach:\n",
      "- Median imputation: Done globally before CV\n",
      "- Label encoding: Fit on combined train+test before CV\n",
      "- This leaks test distribution information into training\n",
      "\n",
      "2. Impact on CV scores:\n",
      "- Current CV score: 0.8541\n",
      "- This may be optimistic due to leakage\n",
      "- LB score may be lower than CV\n",
      "\n",
      "3. What needs to be fixed:\n",
      "- Move ALL preprocessing inside CV loop\n",
      "- Fit imputers/encoders on train fold only\n",
      "- Transform val/test with fitted transformers\n"
     ]
    }
   ],
   "source": [
    "# Check for data leakage concerns\n",
    "print(\"Data Leakage Analysis:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n1. Current preprocessing approach:\")\n",
    "print(\"- Median imputation: Done globally before CV\")\n",
    "print(\"- Label encoding: Fit on combined train+test before CV\")\n",
    "print(\"- This leaks test distribution information into training\")\n",
    "\n",
    "print(\"\\n2. Impact on CV scores:\")\n",
    "print(f\"- Current CV score: {baseline_results['mean_cv_score']:.4f}\")\n",
    "print(\"- This may be optimistic due to leakage\")\n",
    "print(\"- LB score may be lower than CV\")\n",
    "\n",
    "print(\"\\n3. What needs to be fixed:\")\n",
    "print(\"- Move ALL preprocessing inside CV loop\")\n",
    "print(\"- Fit imputers/encoders on train fold only\")\n",
    "print(\"- Transform val/test with fitted transformers\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
