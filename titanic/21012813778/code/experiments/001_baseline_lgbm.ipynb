{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40d20d4",
   "metadata": {},
   "source": [
    "# Titanic Baseline: LightGBM\n",
    "\n",
    "First baseline experiment using LightGBM with basic feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c9eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "\n",
    "# Create experiments directory\n",
    "os.makedirs('/home/code/experiments', exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(\"\\nTrain columns:\", train_df.columns.tolist())\n",
    "print(\"\\nTest columns:\", test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99bb84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic feature engineering\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Fill missing values\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    \n",
    "    # Extract titles from names\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Simplify titles\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', 'Master': 'Master',\n",
    "        'Dr': 'Other', 'Rev': 'Other', 'Col': 'Other', 'Major': 'Other',\n",
    "        'Mlle': 'Miss', 'Countess': 'Other', 'Ms': 'Miss', 'Lady': 'Other',\n",
    "        'Jonkheer': 'Other', 'Don': 'Other', 'Dona': 'Other', 'Mme': 'Mrs',\n",
    "        'Capt': 'Other', 'Sir': 'Other'\n",
    "    }\n",
    "    df['Title'] = df['Title'].map(title_mapping)\n",
    "    \n",
    "    # Family features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # Age groups\n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], \n",
    "                           labels=['Child', 'Teen', 'YoungAdult', 'Adult', 'Senior'])\n",
    "    \n",
    "    # Fare per person\n",
    "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "    \n",
    "    # Cabin features\n",
    "    df['HasCabin'] = df['Cabin'].notna().astype(int)\n",
    "    df['CabinLetter'] = df['Cabin'].str[0]\n",
    "    df['CabinLetter'] = df['CabinLetter'].fillna('Unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_processed = engineer_features(train_df)\n",
    "test_processed = engineer_features(test_df)\n",
    "\n",
    "print(\"Features engineered successfully\")\n",
    "print(\"\\nSample of new features:\")\n",
    "print(train_processed[['Title', 'FamilySize', 'IsAlone', 'AgeGroup', 'FarePerPerson', 'HasCabin']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'AgeGroup', 'CabinLetter']\n",
    "numerical_features = ['Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'FarePerPerson', 'HasCabin']\n",
    "\n",
    "# Combine all features\n",
    "feature_columns = categorical_features + numerical_features\n",
    "\n",
    "# Create feature matrices\n",
    "X = train_processed[feature_columns]\n",
    "y = train_processed['Survived']\n",
    "X_test = test_processed[feature_columns]\n",
    "\n",
    "print(f\"Training features shape: {X.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"\\nFeatures: {feature_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_encoded = X.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on combined data to handle unseen categories\n",
    "    combined_data = pd.concat([X[col], X_test[col]], axis=0)\n",
    "    le.fit(combined_data)\n",
    "    \n",
    "    X_encoded[col] = le.transform(X[col])\n",
    "    X_test_encoded[col] = le.transform(X_test[col])\n",
    "    \n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"Categorical features encoded\")\n",
    "print(\"\\nSample of encoded data:\")\n",
    "print(X_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "cv_scores = []\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "print(f\"Starting {n_splits}-fold cross-validation...\")\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in skf.split(X_encoded, y):\n",
    "    print(f\"\\nFold {fold}/{n_splits}\")\n",
    "    \n",
    "    X_train, X_val = X_encoded.iloc[train_idx], X_encoded.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    # Parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_error',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    val_pred_binary = (val_pred > 0.5).astype(int)\n",
    "    \n",
    "    test_pred = model.predict(X_test_encoded, num_iteration=model.best_iteration)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, val_pred_binary)\n",
    "    cv_scores.append(accuracy)\n",
    "    \n",
    "    # Store OOF predictions\n",
    "    oof_predictions[val_idx] = val_pred_binary\n",
    "    \n",
    "    # Accumulate test predictions\n",
    "    test_predictions += test_pred / n_splits\n",
    "    \n",
    "    print(f\"Fold {fold} Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# Overall CV score\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Cross-Validation Results:\")\n",
    "print(f\"Mean Accuracy: {mean_cv_score:.4f} Â± {std_cv_score:.4f}\")\n",
    "print(f\"Individual folds: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# OOF accuracy\n",
    "oof_accuracy = accuracy_score(y, oof_predictions)\n",
    "print(f\"OOF Accuracy: {oof_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf2b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': (test_predictions > 0.5).astype(int)\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "print(f\"\\nSubmission shape: {submission_df.shape}\")\n",
    "print(\"\\nFirst 10 rows of submission:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "# Verify submission format\n",
    "print(f\"\\nSubmission columns: {submission_df.columns.tolist()}\")\n",
    "print(f\"Unique values in Survived: {submission_df['Survived'].unique()}\")\n",
    "print(f\"Value counts:\\n{submission_df['Survived'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = model.feature_importance(importance_type='gain')\n",
    "feature_names = X_encoded.columns.tolist()\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'cv_scores': cv_scores,\n",
    "    'mean_cv_score': mean_cv_score,\n",
    "    'std_cv_score': std_cv_score,\n",
    "    'oof_accuracy': oof_accuracy,\n",
    "    'feature_importance': importance_df.to_dict('records')\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('/home/code/experiments/001_baseline_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to: /home/code/experiments/001_baseline_results.json\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
