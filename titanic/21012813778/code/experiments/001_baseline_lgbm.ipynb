{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40d20d4",
   "metadata": {},
   "source": [
    "# Titanic Baseline: LightGBM\n",
    "\n",
    "First baseline experiment using LightGBM with basic feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c9eb45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:53:59.298227Z",
     "iopub.status.busy": "2026-01-14T23:53:59.297566Z",
     "iopub.status.idle": "2026-01-14T23:54:00.352689Z",
     "shell.execute_reply": "2026-01-14T23:54:00.352140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Train columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "\n",
      "Test columns: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "\n",
    "# Create experiments directory\n",
    "os.makedirs('/home/code/experiments', exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(\"\\nTrain columns:\", train_df.columns.tolist())\n",
    "print(\"\\nTest columns:\", test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d99bb84e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:54:00.355075Z",
     "iopub.status.busy": "2026-01-14T23:54:00.354654Z",
     "iopub.status.idle": "2026-01-14T23:54:00.379472Z",
     "shell.execute_reply": "2026-01-14T23:54:00.378943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features engineered successfully\n",
      "\n",
      "Sample of new features:\n",
      "  Title  FamilySize  IsAlone    AgeGroup  FarePerPerson  HasCabin\n",
      "0    Mr           2        0  YoungAdult        3.62500         0\n",
      "1   Mrs           2        0       Adult       35.64165         1\n",
      "2  Miss           1        1  YoungAdult        7.92500         0\n",
      "3   Mrs           2        0  YoungAdult       26.55000         1\n",
      "4    Mr           1        1  YoungAdult        8.05000         0\n"
     ]
    }
   ],
   "source": [
    "# Basic feature engineering\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Fill missing values\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    \n",
    "    # Extract titles from names\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Simplify titles\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', 'Master': 'Master',\n",
    "        'Dr': 'Other', 'Rev': 'Other', 'Col': 'Other', 'Major': 'Other',\n",
    "        'Mlle': 'Miss', 'Countess': 'Other', 'Ms': 'Miss', 'Lady': 'Other',\n",
    "        'Jonkheer': 'Other', 'Don': 'Other', 'Dona': 'Other', 'Mme': 'Mrs',\n",
    "        'Capt': 'Other', 'Sir': 'Other'\n",
    "    }\n",
    "    df['Title'] = df['Title'].map(title_mapping)\n",
    "    \n",
    "    # Family features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # Age groups\n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], \n",
    "                           labels=['Child', 'Teen', 'YoungAdult', 'Adult', 'Senior'])\n",
    "    \n",
    "    # Fare per person\n",
    "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "    \n",
    "    # Cabin features\n",
    "    df['HasCabin'] = df['Cabin'].notna().astype(int)\n",
    "    df['CabinLetter'] = df['Cabin'].str[0]\n",
    "    df['CabinLetter'] = df['CabinLetter'].fillna('Unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_processed = engineer_features(train_df)\n",
    "test_processed = engineer_features(test_df)\n",
    "\n",
    "print(\"Features engineered successfully\")\n",
    "print(\"\\nSample of new features:\")\n",
    "print(train_processed[['Title', 'FamilySize', 'IsAlone', 'AgeGroup', 'FarePerPerson', 'HasCabin']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab33a609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:54:00.381434Z",
     "iopub.status.busy": "2026-01-14T23:54:00.381014Z",
     "iopub.status.idle": "2026-01-14T23:54:00.387088Z",
     "shell.execute_reply": "2026-01-14T23:54:00.386630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (891, 13)\n",
      "Test features shape: (418, 13)\n",
      "\n",
      "Features: ['Pclass', 'Sex', 'Embarked', 'Title', 'AgeGroup', 'CabinLetter', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'FarePerPerson', 'HasCabin']\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for modeling\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'AgeGroup', 'CabinLetter']\n",
    "numerical_features = ['Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'FarePerPerson', 'HasCabin']\n",
    "\n",
    "# Combine all features\n",
    "feature_columns = categorical_features + numerical_features\n",
    "\n",
    "# Create feature matrices\n",
    "X = train_processed[feature_columns]\n",
    "y = train_processed['Survived']\n",
    "X_test = test_processed[feature_columns]\n",
    "\n",
    "print(f\"Training features shape: {X.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"\\nFeatures: {feature_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d3709a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:54:00.388903Z",
     "iopub.status.busy": "2026-01-14T23:54:00.388536Z",
     "iopub.status.idle": "2026-01-14T23:54:00.404759Z",
     "shell.execute_reply": "2026-01-14T23:54:00.404271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features encoded\n",
      "\n",
      "Sample of encoded data:\n",
      "   Pclass  Sex  Embarked  Title  AgeGroup  CabinLetter   Age  SibSp  Parch  \\\n",
      "0       2    1         2      2         4            8  22.0      1      0   \n",
      "1       0    0         0      3         0            2  38.0      1      0   \n",
      "2       2    0         2      1         4            8  26.0      0      0   \n",
      "3       0    0         2      3         4            2  35.0      1      0   \n",
      "4       2    1         2      2         4            8  35.0      0      0   \n",
      "\n",
      "      Fare  FamilySize  FarePerPerson  HasCabin  \n",
      "0   7.2500           2        3.62500         0  \n",
      "1  71.2833           2       35.64165         1  \n",
      "2   7.9250           1        7.92500         0  \n",
      "3  53.1000           2       26.55000         1  \n",
      "4   8.0500           1        8.05000         0  \n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_encoded = X.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on combined data to handle unseen categories\n",
    "    combined_data = pd.concat([X[col], X_test[col]], axis=0)\n",
    "    le.fit(combined_data)\n",
    "    \n",
    "    X_encoded[col] = le.transform(X[col])\n",
    "    X_test_encoded[col] = le.transform(X_test[col])\n",
    "    \n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"Categorical features encoded\")\n",
    "print(\"\\nSample of encoded data:\")\n",
    "print(X_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee35651d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:54:00.406619Z",
     "iopub.status.busy": "2026-01-14T23:54:00.406464Z",
     "iopub.status.idle": "2026-01-14T23:54:00.742262Z",
     "shell.execute_reply": "2026-01-14T23:54:00.741709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-fold cross-validation...\n",
      "\n",
      "Fold 1/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid's binary_error: 0.117318\n",
      "Fold 1 Accuracy: 0.8827\n",
      "\n",
      "Fold 2/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid's binary_error: 0.134831\n",
      "Fold 2 Accuracy: 0.8652\n",
      "\n",
      "Fold 3/5\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid's binary_error: 0.185393\n",
      "Fold 3 Accuracy: 0.8146\n",
      "\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid's binary_error: 0.151685\n",
      "Fold 4 Accuracy: 0.8483\n",
      "\n",
      "Fold 5/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid's binary_error: 0.140449\n",
      "Fold 5 Accuracy: 0.8596\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Results:\n",
      "Mean Accuracy: 0.8541 ± 0.0226\n",
      "Individual folds: ['0.8827', '0.8652', '0.8146', '0.8483', '0.8596']\n",
      "==================================================\n",
      "OOF Accuracy: 0.8541\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation setup\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "cv_scores = []\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "print(f\"Starting {n_splits}-fold cross-validation...\")\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in skf.split(X_encoded, y):\n",
    "    print(f\"\\nFold {fold}/{n_splits}\")\n",
    "    \n",
    "    X_train, X_val = X_encoded.iloc[train_idx], X_encoded.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    # Parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_error',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    val_pred_binary = (val_pred > 0.5).astype(int)\n",
    "    \n",
    "    test_pred = model.predict(X_test_encoded, num_iteration=model.best_iteration)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, val_pred_binary)\n",
    "    cv_scores.append(accuracy)\n",
    "    \n",
    "    # Store OOF predictions\n",
    "    oof_predictions[val_idx] = val_pred_binary\n",
    "    \n",
    "    # Accumulate test predictions\n",
    "    test_predictions += test_pred / n_splits\n",
    "    \n",
    "    print(f\"Fold {fold} Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# Overall CV score\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Cross-Validation Results:\")\n",
    "print(f\"Mean Accuracy: {mean_cv_score:.4f} ± {std_cv_score:.4f}\")\n",
    "print(f\"Individual folds: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# OOF accuracy\n",
    "oof_accuracy = accuracy_score(y, oof_predictions)\n",
    "print(f\"OOF Accuracy: {oof_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83cf2b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:54:42.399639Z",
     "iopub.status.busy": "2026-01-14T23:54:42.399002Z",
     "iopub.status.idle": "2026-01-14T23:54:42.408507Z",
     "shell.execute_reply": "2026-01-14T23:54:42.407784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: /home/submission/submission.csv\n",
      "\n",
      "Submission shape: (418, 2)\n",
      "\n",
      "First 10 rows of submission:\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         0\n",
      "5          897         0\n",
      "6          898         1\n",
      "7          899         0\n",
      "8          900         1\n",
      "9          901         0\n",
      "\n",
      "Submission columns: ['PassengerId', 'Survived']\n",
      "Unique values in Survived: [0 1]\n",
      "Value counts:\n",
      "Survived\n",
      "0    275\n",
      "1    143\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': (test_predictions > 0.5).astype(int)\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "print(f\"\\nSubmission shape: {submission_df.shape}\")\n",
    "print(\"\\nFirst 10 rows of submission:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "# Verify submission format\n",
    "print(f\"\\nSubmission columns: {submission_df.columns.tolist()}\")\n",
    "print(f\"Unique values in Survived: {submission_df['Survived'].unique()}\")\n",
    "print(f\"Value counts:\\n{submission_df['Survived'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d7e941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:54:42.410371Z",
     "iopub.status.busy": "2026-01-14T23:54:42.410144Z",
     "iopub.status.idle": "2026-01-14T23:54:42.421285Z",
     "shell.execute_reply": "2026-01-14T23:54:42.420772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Important Features:\n",
      "          feature   importance\n",
      "1             Sex  1524.733730\n",
      "11  FarePerPerson   602.632620\n",
      "6             Age   579.309369\n",
      "9            Fare   539.415274\n",
      "0          Pclass   453.235429\n",
      "3           Title   373.418227\n",
      "5     CabinLetter   221.311582\n",
      "2        Embarked   136.412549\n",
      "7           SibSp   100.128826\n",
      "10     FamilySize    86.340292\n",
      "\n",
      "Results saved to: /home/code/experiments/001_baseline_results.json\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "feature_importance = model.feature_importance(importance_type='gain')\n",
    "feature_names = X_encoded.columns.tolist()\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'cv_scores': cv_scores,\n",
    "    'mean_cv_score': mean_cv_score,\n",
    "    'std_cv_score': std_cv_score,\n",
    "    'oof_accuracy': oof_accuracy,\n",
    "    'feature_importance': importance_df.to_dict('records')\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('/home/code/experiments/001_baseline_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to: /home/code/experiments/001_baseline_results.json\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
