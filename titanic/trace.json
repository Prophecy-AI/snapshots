{
  "spans": [
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "b327c467c14bea69",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683461951455522,
      "end_time": 1767683466688989164,
      "duration": 4.737533642,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}]",
        "llm.input_tokens": 4710,
        "llm.output_tokens": 219,
        "llm.total_tokens": 4929,
        "llm.latency_ms": 4737.607955932617,
        "llm.completion": "REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.\n[Tool Use: Read]\n[Tool Use: ListFiles]\n[Tool Use: ListFiles]\n[Tool Use: ListFiles]",
        "llm.reasoning": "REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.",
        "llm.cost_usd": 0.017415
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "1171e8f943bd4029",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ReadTool",
      "kind": "INTERNAL",
      "start_time": 1767683466689289361,
      "end_time": 1767683466690039450,
      "duration": 0.000750089,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ReadTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x73eac37d9c90>\", \"input\": {\"file_path\": \"../research/description.md\"}}",
        "tool.output": "{\"content\": \"# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\\\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\\\" target=\\\"_blank\\\">\\\"Join Competition button</a> to create an account and gain access to the <a href=\\\"https://www.kaggle.com/c/titanic/data\\\" target=\\\"_blank\\\">competition data</a>. Then check out <a href=\\\"https://www.kaggle.com/alexisbcook/titanic-tutorial\\\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\\\"699\\\" height=\\\"368\\\" src=\\\"https://www.youtube.com/embed/8yZMXCaFshs\\\" title=\\\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\\\" frameborder=\\\"0\\\" allow=\\\"encrypted-media\\\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\\\"https://www.kaggle.com/c/titanic/discussion\\\" target=\\\"_blank\\\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\\\"https://www.kaggle.com/c/titanic/data\\\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\\\"699\\\" align=\\\"center\\\" src=\\\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\\\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\\\"699\\\" align=\\\"center\\\" src=\\\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\\\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\\\"https://www.kaggle.com/c/titanic/discussion\\\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\\\"https://www.kaggle.com/c/titanic/notebooks\\\">here</a>.\\n\\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\\\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\\\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\\\"_blank\\\" href=\\\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\\\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\\\"https://www.kaggle.com/c/titanic/data\\\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\\\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\\\" target=\\\"_blank\\\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\\\"width: 100%;\\\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\\\"https://www.kaggle.com/c/titanic/team\\\" target=\\\"_blank\\\">Team</a> page.</p>\\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\\\"https://www.kaggle.com/c/titanic/discussion\\\" target=\\\"_blank\\\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\\\"https://www.kaggle.com/c/titanic/notebooks\\\" target=\\\"_blank\\\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\\\"https://www.kaggle.com/learn/overview\\\" target=\\\"&quot;_blank\\\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\\\"I worked so hard to get that score! Give it back!\\\"</i> Read more about our decision to implement a rolling leaderboard <a href=\\\"https://www.kaggle.com/c/titanic/discussion/6240\\\" target=\\\"_blank\\\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\\\"https://www.kaggle.com/c/titanic/discussion\\\" target=\\\"_blank\\\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\\\"https://www.kaggle.com/contact\\\" target=\\\"_blank\\\">contact us</a>.</p>\", \"is_error\": false}",
        "tool.duration_ms": 0.6492137908935547
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "331899d9319de829",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ListFilesTool",
      "kind": "INTERNAL",
      "start_time": 1767683466690211825,
      "end_time": 1767683466690418869,
      "duration": 0.000207044,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ListFilesTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x73eac37d9ed0>\", \"input\": {\"directory_path\": \"../research/writeups\"}}",
        "tool.output": "{\"content\": \"Not a directory: /home/code/exploration/../research/writeups\", \"is_error\": true}",
        "tool.duration_ms": 0.2505779266357422
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "09c4799578ecf619",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ListFilesTool",
      "kind": "INTERNAL",
      "start_time": 1767683466690548292,
      "end_time": 1767683466690820968,
      "duration": 0.000272676,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ListFilesTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x73eac37d9ed0>\", \"input\": {\"directory_path\": \"../research/kernels\"}}",
        "tool.output": "{\"content\": \"/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/\", \"is_error\": false}",
        "tool.duration_ms": 0.3039836883544922
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "e07ed78666cdd269",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ListFilesTool",
      "kind": "INTERNAL",
      "start_time": 1767683466690931932,
      "end_time": 1767683466691155417,
      "duration": 0.000223485,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ListFilesTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x73eac37d9ed0>\", \"input\": {\"directory_path\": \"/home/data\"}}",
        "tool.output": "{\"content\": \"/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)\", \"is_error\": false}",
        "tool.duration_ms": 0.2498626708984375
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "b4f6f514328aee7b",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683466726878683,
      "end_time": 1767683472501222938,
      "duration": 5.774344255,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}]",
        "llm.input_tokens": 9287,
        "llm.output_tokens": 252,
        "llm.total_tokens": 9539,
        "llm.latency_ms": 5774.402141571045,
        "llm.completion": "REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\n[Tool Use: Read]\n[Tool Use: Read]",
        "llm.reasoning": "REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.",
        "llm.cost_usd": 0.031641
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "50c94eaa397b1491",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ReadTool",
      "kind": "INTERNAL",
      "start_time": 1767683472501464154,
      "end_time": 1767683472501827050,
      "duration": 0.000362896,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ReadTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x73eac37d9c90>\", \"input\": {\"file_path\": \"../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py\"}}",
        "tool.output": "{\"content\": \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\", \"is_error\": true}",
        "tool.duration_ms": 0.3933906555175781
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "2965643efbfe54af",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ReadTool",
      "kind": "INTERNAL",
      "start_time": 1767683472501959012,
      "end_time": 1767683472502166373,
      "duration": 0.000207361,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ReadTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x73eac37d9c90>\", \"input\": {\"file_path\": \"../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py\"}}",
        "tool.output": "{\"content\": \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\", \"is_error\": true}",
        "tool.duration_ms": 0.23412704467773438
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "300b474e1daf5a0a",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683473424494991,
      "end_time": 1767683477482144327,
      "duration": 4.057649336,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}]",
        "llm.input_tokens": 9734,
        "llm.output_tokens": 210,
        "llm.total_tokens": 9944,
        "llm.latency_ms": 4057.689905166626,
        "llm.completion": "REASONING: Let me check the actual file structure in these kernel directories.\n[Tool Use: ListFiles]\n[Tool Use: ListFiles]\n[Tool Use: ListFiles]",
        "llm.reasoning": "REASONING: Let me check the actual file structure in these kernel directories.",
        "llm.cost_usd": 0.032352
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "92bd0ec926397d86",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ListFilesTool",
      "kind": "INTERNAL",
      "start_time": 1767683477482373628,
      "end_time": 1767683477482723087,
      "duration": 0.000349459,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ListFilesTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x73eac37d9ed0>\", \"input\": {\"directory_path\": \"../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\"}}",
        "tool.output": "{\"content\": \"/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)\", \"is_error\": false}",
        "tool.duration_ms": 0.37860870361328125
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "245f5e5fea3dc14e",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ListFilesTool",
      "kind": "INTERNAL",
      "start_time": 1767683477482861524,
      "end_time": 1767683477483064491,
      "duration": 0.000202967,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ListFilesTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x73eac37d9ed0>\", \"input\": {\"directory_path\": \"../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}}",
        "tool.output": "{\"content\": \"/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)\", \"is_error\": false}",
        "tool.duration_ms": 0.23794174194335938
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "892de4b36c2054b6",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ListFilesTool",
      "kind": "INTERNAL",
      "start_time": 1767683477483150115,
      "end_time": 1767683477483329338,
      "duration": 0.000179223,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ListFilesTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ListFilesTool object at 0x73eac37d9ed0>\", \"input\": {\"directory_path\": \"../research/kernels/startupsci_titanic-data-science-solutions\"}}",
        "tool.output": "{\"content\": \"/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\", \"is_error\": false}",
        "tool.duration_ms": 0.18739700317382812
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "32b9f2c0def74fb4",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683478375309725,
      "end_time": 1767683484630392216,
      "duration": 6.255082491,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}]",
        "llm.input_tokens": 10234,
        "llm.output_tokens": 286,
        "llm.total_tokens": 10520,
        "llm.latency_ms": 6255.128860473633,
        "llm.completion": "REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\n[Tool Use: Bash]",
        "llm.reasoning": "REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.",
        "llm.cost_usd": 0.034992
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "c2b1886ffbe8b566",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "BashTool",
      "kind": "INTERNAL",
      "start_time": 1767683484630684821,
      "end_time": 1767683484669084839,
      "duration": 0.038400018,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "BashTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.BashTool object at 0x73eac37d9f10>\", \"input\": {\"command\": \"cd ../research/kernels && python3 -c \\\"\\nimport json\\n# Read the 99% accuracy framework notebook\\nwith open('ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/a-data-science-framework-to-achieve-99-accuracy.ipynb') as f:\\n    nb = json.load(f)\\n# Extract markdown and code cells\\nfor i, cell in enumerate(nb['cells'][:30]):  # First 30 cells\\n    if cell['cell_type'] == 'markdown':\\n        print(f'=== MARKDOWN {i} ===')\\n        print(''.join(cell['source'][:500]))\\n    elif cell['cell_type'] == 'code':\\n        print(f'=== CODE {i} ===')\\n        print(''.join(cell['source'][:300]))\\n    print()\\n\\\"\"}}",
        "tool.output": "{\"content\": \"=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\\\"ch1\\\"></a>\\n# How a Data Scientist Beat the Odds\\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\\\"ch2\\\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\\\"ch3\\\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\\\"ch4\\\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\\\"Python version: {}\\\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv('../input/train.csv')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\\\"ch5\\\"></a>\\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint('Train columns with null values:\\\\n', data1.isnull().sum())\\nprint(\\\"-\\\"*10)\\n\\nprint('Test/Validation columns with null values:\\\\n', data_val.isnull().sum())\\nprint(\\\"-\\\"*10)\\n\\ndata_raw.describe(include = 'all')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let's execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset['Embarked'].fillna(dataset['Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\\n\\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\\n    dataset['IsAlone'].loc[dataset['FamilySize'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we've cleaned our data, let's do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint('Train columns with null values: \\\\n', data1.isnull().sum())\\nprint(\\\"-\\\"*10)\\nprint (data1.info())\\nprint(\\\"-\\\"*10)\\n\\nprint('Test/Validation columns with null values: \\\\n', data_val.isnull().sum())\\nprint(\\\"-\\\"*10)\\nprint (data_val.info())\\nprint(\\\"-\\\"*10)\\n\\ndata_raw.describe(include = 'all')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\\\"ch6\\\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != 'float64' :\\n        print('Survival Correlation by:', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\\nsns.barplot(x = 'Pclass', y = 'Survived',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let's compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\\naxis1.set_title('Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\\naxis1.set_title('Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\\\"FamilySize\\\", y=\\\"Survived\\\", hue=\\\"Sex\\\", data=data1,\\n              palette={\\\"male\\\": \\\"blue\\\", \\\"female\\\": \\\"pink\\\"},\\n              markers=[\\\"*\\\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = 'Embarked')\\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\\na.map(sns.kdeplot, 'Age', shade= True )\\na.set(xlim=(0 , data1['Age'].max()))\\na.add_legend()\\n\\n\", \"is_error\": false}",
        "tool.duration_ms": 38.30456733703613
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "82ffbaaa29052b45",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683486403904142,
      "end_time": 1767683492082866784,
      "duration": 5.678962642,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}]",
        "llm.input_tokens": 13833,
        "llm.output_tokens": 300,
        "llm.total_tokens": 14133,
        "llm.latency_ms": 5679.001331329346,
        "llm.completion": "REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.\n[Tool Use: Bash]",
        "llm.reasoning": "REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.",
        "llm.cost_usd": 0.045999
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "0311d42abe81ef35",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "BashTool",
      "kind": "INTERNAL",
      "start_time": 1767683492083198931,
      "end_time": 1767683492121923953,
      "duration": 0.038725022,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "BashTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.BashTool object at 0x73eac37d9f10>\", \"input\": {\"command\": \"cd ../research/kernels && python3 -c \\\"\\nimport json\\n# Read the 99% accuracy framework notebook - later cells\\nwith open('ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/a-data-science-framework-to-achieve-99-accuracy.ipynb') as f:\\n    nb = json.load(f)\\n# Extract markdown and code cells\\nfor i, cell in enumerate(nb['cells'][30:50]):  # Cells 30-50\\n    if cell['cell_type'] == 'markdown':\\n        print(f'=== MARKDOWN {i+30} ===')\\n        print(''.join(cell['source'][:800]))\\n    elif cell['cell_type'] == 'code':\\n        print(f'=== CODE {i+30} ===')\\n        print(''.join(cell['source'][:500]))\\n    print()\\n\\\"\"}}",
        "tool.output": "{\"content\": \"=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\\nh.map(plt.hist, 'Age', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={'shrink':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor='white',\\n        annot_kws={'fontsize':12 }\\n    )\\n    \\n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\\\"ch7\\\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title('Machine Learning Algorithm Accuracy Score \\\\n')\\nplt.xlabel('Accuracy Score (%)')\\nplt.ylabel('Algorithm')\\n\\n=== MARKDOWN 36 ===\\n<a id=\\\"ch8\\\"></a>\\n## 5.1 Evaluate Model Performance\\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\\nprint('Survival Decision Tree w/Female Node: \\\\n',pivot_female)\\n\\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\\nprint('\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {'Predict':[]})\\n    male_title = ['Master'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, 'Predict'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, 'Sex'] == 'female'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title='Confusion matrix',\\n                          cmap=plt.cm.Blues):\\n    \\\"\\\"\\\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \\\"\\\"\\\"\\n    if normalize:\\n        cm = cm.astype('float'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \\\"predicting\\\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\\\"ch9\\\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint('BEFORE DT Parameters: ', dtree.get_params())\\nprint(\\\"BEFORE DT Training w/bin score mean: {:.2f}\\\". format(base_results['train_score'].mean()*100)) \\nprint(\\\"BEFORE DT Test w/bin score mean: {:.2f}\\\". format(base_results['test_score'].mean()*100))\\nprint(\\\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\\\"ch10\\\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \\nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\\n\\nprint(\\\"BEFORE DT RFE Training w/bin score mean: {:.2f}\\\". format(base_results['train_score'].mean()*100)) \\nprint(\\\"BEFORE DT RFE Test w/bin score mean: {:.2f}\\\". format(base_results['test_score'].mean()*100))\\nprint(\\\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\\\". format(base_results['test_score'].std()*100*3))\\nprint('-'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\\\"ch11\\\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1's, but enough blues and light reds to create a \\\"super algorithm\\\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    ('ada', ensemble.AdaBoostClassifier()),\\n    ('bc', ensemble.BaggingClassifier()),\\n    ('etc',ensemble.ExtraTreesClassif\\n\\n\", \"is_error\": false}",
        "tool.duration_ms": 38.671016693115234
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "3088993c4da75f70",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683492164839294,
      "end_time": 1767683500961095539,
      "duration": 8.796256245,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}]",
        "llm.input_tokens": 17187,
        "llm.output_tokens": 275,
        "llm.total_tokens": 17462,
        "llm.latency_ms": 8796.285152435303,
        "llm.completion": "REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.\n[Tool Use: Bash]",
        "llm.reasoning": "REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.",
        "llm.cost_usd": 0.055686
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "373d20259b6be026",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "BashTool",
      "kind": "INTERNAL",
      "start_time": 1767683500961352721,
      "end_time": 1767683500999471621,
      "duration": 0.0381189,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "BashTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.BashTool object at 0x73eac37d9f10>\", \"input\": {\"command\": \"cd ../research/kernels && python3 -c \\\"\\nimport json\\n# Read the ensembling notebook\\nwith open('arthurtok_introduction-to-ensembling-stacking-in-python/introduction-to-ensembling-stacking-in-python.ipynb') as f:\\n    nb = json.load(f)\\n# Extract markdown and code cells\\nfor i, cell in enumerate(nb['cells'][:35]):\\n    if cell['cell_type'] == 'markdown':\\n        print(f'=== MARKDOWN {i} ===')\\n        print(''.join(cell['source'][:600]))\\n    elif cell['cell_type'] == 'code':\\n        print(f'=== CODE {i} ===')\\n        print(''.join(cell['source'][:400]))\\n    print()\\n\\\"\"}}",
        "tool.output": "{\"content\": \"=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv('../input/train.csv')\\ntest = pd.read_csv('../input/test.csv')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test['PassengerId']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain['Name_length'] = train['Name'].apply(len)\\ntest['Name_length'] = test['Name'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain['Has_Cabin'] = train[\\\"Cabin\\\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest['Has_Cabin'] = test[\\\"Cabin\\\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor='white', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params['random_state'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \\\"seen\\\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    'n_jobs': -1,\\n    'n_estimators': 500,\\n     'warm_start': True, \\n     #'max_features': 0.2,\\n    'max_depth': 6,\\n    'min_samples_leaf': 2,\\n    'max_features' : 'sqrt',\\n    'verbose': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    'n_jobs': -1,\\n    'n_estimators':500,\\n    #'max_features': 0.5,\\n    'max_depth'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train['Survived'].ravel()\\ntrain = train.drop(['Survived'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {'features': cols,\\n     'Random Forest feature importances': rf_features,\\n     'Extra Trees  feature importances': et_features,\\n      'AdaBoost feature importances': ada_features,\\n    'Gradient Boost feature importances': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \\\"Scatter\\\" as follows:\\n\\n\", \"is_error\": false}",
        "tool.duration_ms": 37.99796104431152
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "5267f3a702578584",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683501953190251,
      "end_time": 1767683511276017106,
      "duration": 9.322826855,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}]",
        "llm.input_tokens": 21325,
        "llm.output_tokens": 453,
        "llm.total_tokens": 21778,
        "llm.latency_ms": 9322.843074798584,
        "llm.completion": "REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\n[Tool Use: RecordFinding]\n[Tool Use: RecordFinding]\n[Tool Use: RecordFinding]",
        "llm.reasoning": "REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.",
        "llm.cost_usd": 0.07077
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "64d71584d7286730",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "RecordFindingTool",
      "kind": "INTERNAL",
      "start_time": 1767683511276260956,
      "end_time": 1767683511277275110,
      "duration": 0.001014154,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "RecordFindingTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.findings.RecordFindingTool object at 0x73eac380cf50>\", \"input\": {\"finding\": \"Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, Has_Cabin binary, Name_length, FareBin (binned fare), AgeBin (binned age)\", \"source\": \"../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\"}}",
        "tool.output": "{\"content\": \"‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\", \"is_error\": false}",
        "tool.duration_ms": 1.0440349578857422
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "0245640caaa42f8f",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "RecordFindingTool",
      "kind": "INTERNAL",
      "start_time": 1767683511277409104,
      "end_time": 1767683511278637053,
      "duration": 0.001227949,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "RecordFindingTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.findings.RecordFindingTool object at 0x73eac380cf50>\", \"input\": {\"finding\": \"Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) with out-of-fold predictions, then XGBoost as second-level meta-classifier\", \"source\": \"../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}}",
        "tool.output": "{\"content\": \"‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\", \"is_error\": false}",
        "tool.duration_ms": 1.2350082397460938
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "e3f8c0387d8d9bfc",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "RecordFindingTool",
      "kind": "INTERNAL",
      "start_time": 1767683511278773074,
      "end_time": 1767683511279636160,
      "duration": 0.000863086,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "RecordFindingTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.findings.RecordFindingTool object at 0x73eac380cf50>\", \"input\": {\"finding\": \"Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For GradientBoosting: n_estimators=500, max_depth=5, min_samples_leaf=2\", \"source\": \"../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}}",
        "tool.output": "{\"content\": \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\", \"is_error\": false}",
        "tool.duration_ms": 0.8842945098876953
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "1c7069b3b118023c",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683512222062866,
      "end_time": 1767683517477490622,
      "duration": 5.255427756,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}]",
        "llm.input_tokens": 22081,
        "llm.output_tokens": 227,
        "llm.total_tokens": 22308,
        "llm.latency_ms": 5255.4216384887695,
        "llm.completion": "REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.\n[Tool Use: CreateNotebook]",
        "llm.reasoning": "REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.",
        "llm.cost_usd": 0.069648
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "0dcbdc1aa8fbf52a",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "CreateNotebookTool",
      "kind": "INTERNAL",
      "start_time": 1767683517477810892,
      "end_time": 1767683518969532395,
      "duration": 1.491721503,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "CreateNotebookTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.CreateNotebookTool object at 0x73eac37d9f90>\", \"input\": {\"notebook_path\": \"eda.ipynb\", \"cells\": [{\"cell_type\": \"code\", \"content\": \"import pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\"}]}}",
        "tool.output": "{\"content\": \"Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\", \"is_error\": false}",
        "tool.duration_ms": 1491.7285442352295
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "50a2af03f03ac098",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683520795697310,
      "end_time": 1767683523989739039,
      "duration": 3.194041729,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}]",
        "llm.input_tokens": 22354,
        "llm.output_tokens": 73,
        "llm.total_tokens": 22427,
        "llm.latency_ms": 3194.1261291503906,
        "llm.completion": "[Tool Use: ExecuteCellRange]",
        "llm.cost_usd": 0.068157
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "86c4047fbc21df4f",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767683523990020037,
      "end_time": 1767683524551853315,
      "duration": 0.561833278,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x73eac37d9e10>\", \"input\": {\"start_cell\": 0, \"duration\": 30}}",
        "tool.output": "{\"content\": \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\", \"is_error\": false}",
        "tool.duration_ms": 561.8677139282227
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "096a869cbaef9f25",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683526355547425,
      "end_time": 1767683532420211029,
      "duration": 6.064663604,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}]",
        "llm.input_tokens": 22683,
        "llm.output_tokens": 141,
        "llm.total_tokens": 22824,
        "llm.latency_ms": 6064.71848487854,
        "llm.completion": "[Tool Use: AddNotebookCell]",
        "llm.cost_usd": 0.070164
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "b258e77f7f6384b2",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "AddNotebookCellTool",
      "kind": "INTERNAL",
      "start_time": 1767683532420456007,
      "end_time": 1767683532422392265,
      "duration": 0.001936258,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "AddNotebookCellTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x73eac37f4d50>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\"}}",
        "tool.output": "{\"content\": \"Added code cell at 1\", \"is_error\": false}",
        "tool.duration_ms": 1.9609928131103516
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "e5611d8cda1ae2f4",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683533342574121,
      "end_time": 1767683535997195304,
      "duration": 2.654621183,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}]",
        "llm.input_tokens": 22842,
        "llm.output_tokens": 73,
        "llm.total_tokens": 22915,
        "llm.latency_ms": 2654.703140258789,
        "llm.completion": "[Tool Use: ExecuteCellRange]",
        "llm.cost_usd": 0.069621
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "20b26bff2a5b5c7b",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767683535997486421,
      "end_time": 1767683536014928934,
      "duration": 0.017442513,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x73eac37d9e10>\", \"input\": {\"start_cell\": 1, \"duration\": 30}}",
        "tool.output": "{\"content\": \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\", \"is_error\": false}",
        "tool.duration_ms": 17.484664916992188
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "dbc6f6e926d7c345",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683537021728441,
      "end_time": 1767683541166503002,
      "duration": 4.144774561,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}]",
        "llm.input_tokens": 23240,
        "llm.output_tokens": 172,
        "llm.total_tokens": 23412,
        "llm.latency_ms": 4144.8814868927,
        "llm.completion": "[Tool Use: AddNotebookCell]",
        "llm.cost_usd": 0.07229999999999999
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "21db08fa77eef6c0",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "AddNotebookCellTool",
      "kind": "INTERNAL",
      "start_time": 1767683541166753481,
      "end_time": 1767683541168750941,
      "duration": 0.00199746,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "AddNotebookCellTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x73eac37f4d50>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\\\nprint('\\\\\\\\nSurvival by Pclass:')\\\\nprint(train.groupby('Pclass')['Survived'].mean())\\\\nprint('\\\\\\\\nSurvival by Embarked:')\\\\nprint(train.groupby('Embarked')['Survived'].mean())\"}}",
        "tool.output": "{\"content\": \"Added code cell at 2\", \"is_error\": false}",
        "tool.duration_ms": 2.016782760620117
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "cdd79ecfbf00765d",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683542115053901,
      "end_time": 1767683546025425865,
      "duration": 3.910371964,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}]",
        "llm.input_tokens": 23430,
        "llm.output_tokens": 170,
        "llm.total_tokens": 23600,
        "llm.latency_ms": 3910.4158878326416,
        "llm.completion": "[Tool Use: EditNotebookCell]",
        "llm.cost_usd": 0.07284
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "ef91090683e1ddfa",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "EditNotebookCellTool",
      "kind": "INTERNAL",
      "start_time": 1767683546025719275,
      "end_time": 1767683546027446257,
      "duration": 0.001726982,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "EditNotebookCellTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.EditNotebookCellTool object at 0x73eac3802f90>\", \"input\": {\"cell_index\": 2, \"new_content\": \"# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\"}}",
        "tool.output": "{\"content\": \"Edited cell 2. Re-run to update kernel state.\", \"is_error\": false}",
        "tool.duration_ms": 1.745462417602539
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "6432d609ff490ff7",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683546981259243,
      "end_time": 1767683550942038032,
      "duration": 3.960778789,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}]",
        "llm.input_tokens": 23625,
        "llm.output_tokens": 73,
        "llm.total_tokens": 23698,
        "llm.latency_ms": 3960.793972015381,
        "llm.completion": "[Tool Use: ExecuteCellRange]",
        "llm.cost_usd": 0.07197
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "2c549478125d6e26",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767683550942308005,
      "end_time": 1767683550960476217,
      "duration": 0.018168212,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x73eac37d9e10>\", \"input\": {\"start_cell\": 2, \"duration\": 30}}",
        "tool.output": "{\"content\": \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\", \"is_error\": false}",
        "tool.duration_ms": 18.188953399658203
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "3bb5ee3106987acd",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683551920120724,
      "end_time": 1767683557373022073,
      "duration": 5.452901349,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}]",
        "llm.input_tokens": 23947,
        "llm.output_tokens": 246,
        "llm.total_tokens": 24193,
        "llm.latency_ms": 5452.930450439453,
        "llm.completion": "[Tool Use: RecordFinding]\n[Tool Use: RecordFinding]",
        "llm.cost_usd": 0.075531
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "e4313768cb520359",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "RecordFindingTool",
      "kind": "INTERNAL",
      "start_time": 1767683557373250627,
      "end_time": 1767683557374348755,
      "duration": 0.001098128,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "RecordFindingTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.findings.RecordFindingTool object at 0x73eac380cf50>\", \"input\": {\"finding\": \"Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: 24%. Embarked C: 55%, Q: 39%, S: 34%\", \"source\": \"exploration/eda.ipynb\"}}",
        "tool.output": "{\"content\": \"‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb\", \"is_error\": false}",
        "tool.duration_ms": 1.1279582977294922
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "26970c63df8da352",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "RecordFindingTool",
      "kind": "INTERNAL",
      "start_time": 1767683557374469012,
      "end_time": 1767683557375400680,
      "duration": 0.000931668,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "RecordFindingTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.findings.RecordFindingTool object at 0x73eac380cf50>\", \"input\": {\"finding\": \"Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 test). Cabin is ~77% missing.\", \"source\": \"exploration/eda.ipynb\"}}",
        "tool.output": "{\"content\": \"‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb\", \"is_error\": false}",
        "tool.duration_ms": 0.9522438049316406
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "6b07d646c1e789d7",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683558363581224,
      "end_time": 1767683565622395682,
      "duration": 7.258814458,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n\ntool: ‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\n  Source: exploration/eda.ipynb\ntool: ‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\n  Source: exploration/eda.ipynb",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb'}, {'role': 'tool', 'content': '‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb'}]",
        "llm.input_tokens": 24378,
        "llm.output_tokens": 350,
        "llm.total_tokens": 24728,
        "llm.latency_ms": 7258.850336074829,
        "llm.completion": "REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.\n[Tool Use: Bash]",
        "llm.reasoning": "REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.",
        "llm.cost_usd": 0.07838400000000001
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "19142304cadfae17",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "BashTool",
      "kind": "INTERNAL",
      "start_time": 1767683565622761203,
      "end_time": 1767683565662007217,
      "duration": 0.039246014,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "BashTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.BashTool object at 0x73eac37d9f10>\", \"input\": {\"command\": \"cd ../research/kernels && python3 -c \\\"\\nimport json\\n# Read the titanic data science solutions notebook\\nwith open('startupsci_titanic-data-science-solutions/titanic-data-science-solutions.ipynb') as f:\\n    nb = json.load(f)\\n# Extract markdown and code cells - focus on feature engineering\\nfor i, cell in enumerate(nb['cells'][20:40]):\\n    if cell['cell_type'] == 'markdown':\\n        content = ''.join(cell['source'])\\n        if 'feature' in content.lower() or 'title' in content.lower() or 'engineer' in content.lower():\\n            print(f'=== MARKDOWN {i+20} ===')\\n            print(content[:600])\\n            print()\\n    elif cell['cell_type'] == 'code':\\n        content = ''.join(cell['source'])\\n        if 'Title' in content or 'FamilySize' in content or 'IsAlone' in content:\\n            print(f'=== CODE {i+20} ===')\\n            print(content[:500])\\n            print()\\n\\\"\"}}",
        "tool.output": "{\"content\": \"=== MARKDOWN 23 ===\\n## Analyze by visualizing data\\n\\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n\\n### Correlating numerical features\\n\\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\\n\\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \\n\\n=== MARKDOWN 25 ===\\n### Correlating numerical and ordinal features\\n\\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n\\n**Observations.**\\n\\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n- Pclass varies in terms of Age distribution of passengers.\\n\\n**Decisions\\n\\n=== MARKDOWN 27 ===\\n### Correlating categorical features\\n\\nNow we can correlate categorical features with our solution goal.\\n\\n**Observations.**\\n\\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n- Ports of embarkation have varying survival rates for Pcla\\n\\n=== MARKDOWN 29 ===\\n### Correlating categorical and numerical features\\n\\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n\\n**Observations.**\\n\\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n\\n**Decisions.**\\n\\n- Consider banding Fare feature.\\n\\n=== MARKDOWN 31 ===\\n## Wrangle data\\n\\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n\\n### Correcting by dropping features\\n\\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n\\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n\\n\\n=== MARKDOWN 33 ===\\n### Creating new feature extracting from existing\\n\\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n\\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n\\n**Observations.**\\n\\nWhen we plot Title, Age, and Survived, we note the following observations.\\n\\n- Most titles band Age groups accurately. For example: Master\\n\\n=== CODE 34 ===\\nfor dataset in combine:\\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)\\n\\npd.crosstab(train_df['Title'], train_df['Sex'])\\n\\n=== MARKDOWN 35 ===\\nWe can replace many titles with a more common name or classify them as `Rare`.\\n\\n=== CODE 36 ===\\nfor dataset in combine:\\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\\\\n \\t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\\n\\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\\n    \\ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\\n\\n=== MARKDOWN 37 ===\\nWe can convert the categorical titles to ordinal.\\n\\n=== CODE 38 ===\\ntitle_mapping = {\\\"Mr\\\": 1, \\\"Miss\\\": 2, \\\"Mrs\\\": 3, \\\"Master\\\": 4, \\\"Rare\\\": 5}\\nfor dataset in combine:\\n    dataset['Title'] = dataset['Title'].map(title_mapping)\\n    dataset['Title'] = dataset['Title'].fillna(0)\\n\\ntrain_df.head()\\n\\n=== MARKDOWN 39 ===\\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\\n\\n\", \"is_error\": false}",
        "tool.duration_ms": 39.19482231140137
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "52213fdb4fc18390",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683566782198011,
      "end_time": 1767683596112217737,
      "duration": 29.330019726,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n\ntool: ‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\n  Source: exploration/eda.ipynb\ntool: ‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\n  Source: exploration/eda.ipynb\ntool: === MARKDOWN 23 ===\n## Analyze by visualizing data\n\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\n\n### Correlating numerical features\n\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\n\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \n\n=== MARKDOWN 25 ===\n### Correlating numerical and ordinal features\n\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n\n**Observations.**\n\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n- Pclass varies in terms of Age distribution of passengers.\n\n**Decisions\n\n=== MARKDOWN 27 ===\n### Correlating categorical features\n\nNow we can correlate categorical features with our solution goal.\n\n**Observations.**\n\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\n- Ports of embarkation have varying survival rates for Pcla\n\n=== MARKDOWN 29 ===\n### Correlating categorical and numerical features\n\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n\n**Observations.**\n\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n\n**Decisions.**\n\n- Consider banding Fare feature.\n\n=== MARKDOWN 31 ===\n## Wrangle data\n\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n\n### Correcting by dropping features\n\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\n\n\n=== MARKDOWN 33 ===\n### Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n\n**Observations.**\n\nWhen we plot Title, Age, and Survived, we note the following observations.\n\n- Most titles band Age groups accurately. For example: Master\n\n=== CODE 34 ===\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])\n\n=== MARKDOWN 35 ===\nWe can replace many titles with a more common name or classify them as `Rare`.\n\n=== CODE 36 ===\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n\n=== MARKDOWN 37 ===\nWe can convert the categorical titles to ordinal.\n\n=== CODE 38 ===\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()\n\n=== MARKDOWN 39 ===\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\n\n",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb'}, {'role': 'tool', 'content': '‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb'}, {'role': 'assistant', 'content': 'REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.'}, {'role': 'tool', 'content': '=== MARKDOWN 23 ===\\n## Analyze by visualizing data\\n\\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n\\n### Correlating numerical features\\n\\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\\n\\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \\n\\n=== MARKDOWN 25 ===\\n### Correlating numerical and ordinal features\\n\\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n\\n**Observations.**\\n\\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n- Pclass varies in terms of Age distribution of passengers.\\n\\n**Decisions\\n\\n=== MARKDOWN 27 ===\\n### Correlating categorical features\\n\\nNow we can correlate categorical features with our solution goal.\\n\\n**Observations.**\\n\\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n- Ports of embarkation have varying survival rates for Pcla\\n\\n=== MARKDOWN 29 ===\\n### Correlating categorical and numerical features\\n\\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n\\n**Observations.**\\n\\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n\\n**Decisions.**\\n\\n- Consider banding Fare feature.\\n\\n=== MARKDOWN 31 ===\\n## Wrangle data\\n\\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n\\n### Correcting by dropping features\\n\\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n\\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n\\n\\n=== MARKDOWN 33 ===\\n### Creating new feature extracting from existing\\n\\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n\\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n\\n**Observations.**\\n\\nWhen we plot Title, Age, and Survived, we note the following observations.\\n\\n- Most titles band Age groups accurately. For example: Master\\n\\n=== CODE 34 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset.Name.str.extract(\\' ([A-Za-z]+)\\\\.\\', expand=False)\\n\\npd.crosstab(train_df[\\'Title\\'], train_df[\\'Sex\\'])\\n\\n=== MARKDOWN 35 ===\\nWe can replace many titles with a more common name or classify them as `Rare`.\\n\\n=== CODE 36 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace([\\'Lady\\', \\'Countess\\',\\'Capt\\', \\'Col\\',\\\\\\n \\t\\'Don\\', \\'Dr\\', \\'Major\\', \\'Rev\\', \\'Sir\\', \\'Jonkheer\\', \\'Dona\\'], \\'Rare\\')\\n\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mlle\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Ms\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mme\\', \\'Mrs\\')\\n    \\ntrain_df[[\\'Title\\', \\'Survived\\']].groupby([\\'Title\\'], as_index=False).mean()\\n\\n=== MARKDOWN 37 ===\\nWe can convert the categorical titles to ordinal.\\n\\n=== CODE 38 ===\\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].map(title_mapping)\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].fillna(0)\\n\\ntrain_df.head()\\n\\n=== MARKDOWN 39 ===\\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\\n\\n'}]",
        "llm.input_tokens": 26003,
        "llm.output_tokens": 1440,
        "llm.total_tokens": 27443,
        "llm.latency_ms": 29329.951763153076,
        "llm.completion": "REASONING: Now I have comprehensive information. Let me write the seed prompt with all the techniques I've learned.\n[Tool Use: Write]",
        "llm.reasoning": "REASONING: Now I have comprehensive information. Let me write the seed prompt with all the techniques I've learned.",
        "llm.cost_usd": 0.099609
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "70d93858fd25257b",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "WriteTool",
      "kind": "INTERNAL",
      "start_time": 1767683596112608477,
      "end_time": 1767683596113287411,
      "duration": 0.000678934,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "WriteTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.WriteTool object at 0x73eac37d9e90>\", \"input\": {\"file_path\": \"seed_prompt.txt\", \"content\": \"# Titanic Survival Prediction - Techniques Guide\\n\\n## Data Understanding\\n**Reference notebooks for data characteristics:**\\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\\n- Target is imbalanced: 61.6% died, 38.4% survived\\n\\n## Feature Engineering (Critical for High Accuracy)\\n\\n### Title Extraction from Name\\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)`\\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\\n- Title is highly predictive: Master (young boys) had high survival\\n\\n### Family Features\\n- **FamilySize** = SibSp + Parch + 1\\n- **IsAlone** = 1 if FamilySize == 1, else 0\\n- Family size affects survival: solo travelers and very large families had lower survival\\n\\n### Cabin Features\\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\\n- ~77% missing - use Has_Cabin binary flag\\n\\n### Fare and Age Binning\\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\\n- Binning helps tree models find splits\\n\\n### Name Length\\n- **Name_length** = len(Name) - can be proxy for social status\\n\\n### Ticket Features\\n- Ticket prefix extraction (some tickets have letter prefixes)\\n- Ticket frequency (shared tickets indicate traveling together)\\n\\n## Missing Value Handling\\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\\n- **Embarked**: Fill with mode ('S' - Southampton)\\n- **Fare**: Fill with median (by Pclass)\\n- **Cabin**: Create Has_Cabin flag, don't impute\\n\\n## Models\\n\\n### Single Models (Baseline)\\nFor this small tabular dataset, tree-based models work well:\\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\\n- **XGBoost**: Similar parameters, use early stopping\\n- **Extra Trees**: n_estimators=500, max_depth=6\\n- **Logistic Regression**: Good baseline, use regularization\\n\\n### Ensemble Approaches (Higher Accuracy)\\n\\n#### Voting Classifier\\nCombine multiple models with soft voting:\\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\\n- Use soft voting (probability-based) for better results\\n\\n#### Stacking (Best Approach)\\nTwo-level stacking architecture:\\n1. **First Level (Base Models)**: \\n   - Random Forest\\n   - Extra Trees\\n   - AdaBoost\\n   - Gradient Boosting\\n   - SVC (with probability=True)\\n   \\n2. **Second Level (Meta-Classifier)**:\\n   - XGBoost or Logistic Regression\\n   \\n3. **Out-of-Fold Predictions**:\\n   - Use K-Fold (K=5) to generate out-of-fold predictions\\n   - This prevents overfitting when training meta-classifier\\n   - Each base model generates predictions on held-out fold\\n   - Stack these predictions as features for meta-classifier\\n\\n## Validation Strategy\\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\\n- Small dataset (891 samples) - CV is critical to avoid overfitting\\n- Track both train and validation scores to detect overfitting\\n\\n## Hyperparameter Tuning\\n- Use GridSearchCV or RandomizedSearchCV\\n- Key parameters to tune:\\n  - Tree depth (max_depth): 3-8\\n  - Number of estimators: 100-1000\\n  - Learning rate (for boosting): 0.01-0.1\\n  - Min samples per leaf: 1-5\\n- Use cross-validation during tuning\\n\\n## Feature Selection\\n- Use Recursive Feature Elimination (RFE) with cross-validation\\n- Check feature importances from tree models\\n- Most important features typically: Sex, Title, Pclass, Fare, Age\\n\\n## Key Insights from Top Kernels\\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\\n3. Title extraction captures both sex and age information effectively\\n4. Family size has non-linear relationship with survival\\n5. Ensemble methods consistently outperform single models\\n\\n## Submission Strategy\\n- Generate predictions using best ensemble model\\n- Consider averaging predictions from multiple models\\n- Threshold at 0.5 for binary classification\\n- Format: PassengerId, Survived (0 or 1)\\n\"}}",
        "tool.output": "{\"content\": \"Wrote to /home/code/exploration/seed_prompt.txt\", \"is_error\": false}",
        "tool.duration_ms": 0.7441043853759766
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "a634a67e325175b4",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683597237727022,
      "end_time": 1767683603464404643,
      "duration": 6.226677621,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n\ntool: ‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\n  Source: exploration/eda.ipynb\ntool: ‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\n  Source: exploration/eda.ipynb\ntool: === MARKDOWN 23 ===\n## Analyze by visualizing data\n\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\n\n### Correlating numerical features\n\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\n\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \n\n=== MARKDOWN 25 ===\n### Correlating numerical and ordinal features\n\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n\n**Observations.**\n\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n- Pclass varies in terms of Age distribution of passengers.\n\n**Decisions\n\n=== MARKDOWN 27 ===\n### Correlating categorical features\n\nNow we can correlate categorical features with our solution goal.\n\n**Observations.**\n\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\n- Ports of embarkation have varying survival rates for Pcla\n\n=== MARKDOWN 29 ===\n### Correlating categorical and numerical features\n\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n\n**Observations.**\n\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n\n**Decisions.**\n\n- Consider banding Fare feature.\n\n=== MARKDOWN 31 ===\n## Wrangle data\n\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n\n### Correcting by dropping features\n\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\n\n\n=== MARKDOWN 33 ===\n### Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n\n**Observations.**\n\nWhen we plot Title, Age, and Survived, we note the following observations.\n\n- Most titles band Age groups accurately. For example: Master\n\n=== CODE 34 ===\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])\n\n=== MARKDOWN 35 ===\nWe can replace many titles with a more common name or classify them as `Rare`.\n\n=== CODE 36 ===\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n\n=== MARKDOWN 37 ===\nWe can convert the categorical titles to ordinal.\n\n=== CODE 38 ===\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()\n\n=== MARKDOWN 39 ===\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\n\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb'}, {'role': 'tool', 'content': '‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb'}, {'role': 'assistant', 'content': 'REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.'}, {'role': 'tool', 'content': '=== MARKDOWN 23 ===\\n## Analyze by visualizing data\\n\\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n\\n### Correlating numerical features\\n\\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\\n\\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \\n\\n=== MARKDOWN 25 ===\\n### Correlating numerical and ordinal features\\n\\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n\\n**Observations.**\\n\\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n- Pclass varies in terms of Age distribution of passengers.\\n\\n**Decisions\\n\\n=== MARKDOWN 27 ===\\n### Correlating categorical features\\n\\nNow we can correlate categorical features with our solution goal.\\n\\n**Observations.**\\n\\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n- Ports of embarkation have varying survival rates for Pcla\\n\\n=== MARKDOWN 29 ===\\n### Correlating categorical and numerical features\\n\\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n\\n**Observations.**\\n\\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n\\n**Decisions.**\\n\\n- Consider banding Fare feature.\\n\\n=== MARKDOWN 31 ===\\n## Wrangle data\\n\\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n\\n### Correcting by dropping features\\n\\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n\\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n\\n\\n=== MARKDOWN 33 ===\\n### Creating new feature extracting from existing\\n\\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n\\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n\\n**Observations.**\\n\\nWhen we plot Title, Age, and Survived, we note the following observations.\\n\\n- Most titles band Age groups accurately. For example: Master\\n\\n=== CODE 34 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset.Name.str.extract(\\' ([A-Za-z]+)\\\\.\\', expand=False)\\n\\npd.crosstab(train_df[\\'Title\\'], train_df[\\'Sex\\'])\\n\\n=== MARKDOWN 35 ===\\nWe can replace many titles with a more common name or classify them as `Rare`.\\n\\n=== CODE 36 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace([\\'Lady\\', \\'Countess\\',\\'Capt\\', \\'Col\\',\\\\\\n \\t\\'Don\\', \\'Dr\\', \\'Major\\', \\'Rev\\', \\'Sir\\', \\'Jonkheer\\', \\'Dona\\'], \\'Rare\\')\\n\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mlle\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Ms\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mme\\', \\'Mrs\\')\\n    \\ntrain_df[[\\'Title\\', \\'Survived\\']].groupby([\\'Title\\'], as_index=False).mean()\\n\\n=== MARKDOWN 37 ===\\nWe can convert the categorical titles to ordinal.\\n\\n=== CODE 38 ===\\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].map(title_mapping)\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].fillna(0)\\n\\ntrain_df.head()\\n\\n=== MARKDOWN 39 ===\\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now I have comprehensive information. Let me write the seed prompt with all the techniques I've learned.\"}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}]",
        "llm.input_tokens": 27470,
        "llm.output_tokens": 278,
        "llm.total_tokens": 27748,
        "llm.latency_ms": 6226.725101470947,
        "llm.completion": "REASONING: Now let me check if there are any additional techniques in the Alexis Cook tutorial that might be helpful, and also search for any advanced techniques that could help beat the 1.0 target score (which is 100% accuracy - extremely challenging).\n[Tool Use: Bash]",
        "llm.reasoning": "REASONING: Now let me check if there are any additional techniques in the Alexis Cook tutorial that might be helpful, and also search for any advanced techniques that could help beat the 1.0 target score (which is 100% accuracy - extremely challenging).",
        "llm.cost_usd": 0.08657999999999999
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "c8ee56c24330d691",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "BashTool",
      "kind": "INTERNAL",
      "start_time": 1767683603464687199,
      "end_time": 1767683603494636731,
      "duration": 0.029949532,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "BashTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.BashTool object at 0x73eac37d9f10>\", \"input\": {\"command\": \"cd ../research/kernels && python3 -c \\\"\\nimport json\\n# Read the Alexis Cook tutorial\\nwith open('alexisbcook_titanic-tutorial/titanic-tutorial.ipynb') as f:\\n    nb = json.load(f)\\n# Extract all cells\\nfor i, cell in enumerate(nb['cells']):\\n    if cell['cell_type'] == 'markdown':\\n        print(f'=== MARKDOWN {i} ===')\\n        print(''.join(cell['source'][:400]))\\n    elif cell['cell_type'] == 'code':\\n        print(f'=== CODE {i} ===')\\n        print(''.join(cell['source'][:300]))\\n    print()\\n\\\"\"}}",
        "tool.output": "{\"content\": \"=== MARKDOWN 0 ===\\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\\n\\n=== MARKDOWN 1 ===\\n# Part 2: Your coding environment\\n\\nIn this section, you'll train your own machine learning model to improve your predictions.  _If you've never written code before or don't have any experience with machine learning, don't worry!  We don't assume any prior experience in this tutorial._\\n\\n## The Notebook\\n\\nThe first thing to do is to create a Kaggle Notebook where you'll store all of your code.  You c\\n\\n=== CODE 2 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n# For example, here's several helpful packages to load in \\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data proc\\n\\n=== MARKDOWN 3 ===\\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We'll do that next.\\n\\n## Load the data\\n\\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\\n\\n![](https://i.imgur.com/OQBax9n.png)\\n\\nType the two lines of code below into your second code cell.  Then, once you're done, either click on the blue pl\\n\\n=== CODE 4 ===\\ntrain_data = pd.read_csv(\\\"/kaggle/input/titanic/train.csv\\\")\\ntrain_data.head()\\n\\n=== MARKDOWN 5 ===\\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It's very important that you see this output **in your notebook** before proceeding with the tutorial!\\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\\n\\n=== CODE 6 ===\\ntest_data = pd.read_csv(\\\"/kaggle/input/titanic/test.csv\\\")\\ntest_data.head()\\n\\n=== MARKDOWN 7 ===\\nAs before, make sure that you see the output above in your notebook before continuing.  \\n\\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\\n\\n# Part 3: Your first submission\\n\\n=== CODE 8 ===\\nwomen = train_data.loc[train_data.Sex == 'female'][\\\"Survived\\\"]\\nrate_women = sum(women)/len(women)\\n\\nprint(\\\"% of women who survived:\\\", rate_women)\\n\\n=== MARKDOWN 9 ===\\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\\n\\nThen, run the code below in another code cell:\\n\\n=== CODE 10 ===\\nmen = train_data.loc[train_data.Sex == 'male'][\\\"Survived\\\"]\\nrate_men = sum(men)/len(men)\\n\\nprint(\\\"% of men who survived:\\\", rate_men)\\n\\n=== MARKDOWN 11 ===\\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\\n\\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\\n\\nBut at the end of the day, this gender-based s\\n\\n=== CODE 12 ===\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\ny = train_data[\\\"Survived\\\"]\\n\\nfeatures = [\\\"Pclass\\\", \\\"Sex\\\", \\\"SibSp\\\", \\\"Parch\\\"]\\nX = pd.get_dummies(train_data[features])\\nX_test = pd.get_dummies(test_data[features])\\n\\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\\nmodel.f\\n\\n=== MARKDOWN 13 ===\\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\\n> Again, don't worry if this code doesn't make sense to you!  For now, we'll focus on how to generate and submit predictions.\\n\\nOnce you're ready, click on the **\\\"Save Version\\\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \\n- Ensure tha\\n\\n=== MARKDOWN 14 ===\\n# Part 4: Learn more!\\n\\nIf you're interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we've presented here.  You'll also know enough to generate even better predictions!\\n\\n\", \"is_error\": false}",
        "tool.duration_ms": 29.905319213867188
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "feacb5f176c992a4",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683604562895920,
      "end_time": 1767683608827498647,
      "duration": 4.264602727,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n\ntool: ‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\n  Source: exploration/eda.ipynb\ntool: ‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\n  Source: exploration/eda.ipynb\ntool: === MARKDOWN 23 ===\n## Analyze by visualizing data\n\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\n\n### Correlating numerical features\n\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\n\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \n\n=== MARKDOWN 25 ===\n### Correlating numerical and ordinal features\n\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n\n**Observations.**\n\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n- Pclass varies in terms of Age distribution of passengers.\n\n**Decisions\n\n=== MARKDOWN 27 ===\n### Correlating categorical features\n\nNow we can correlate categorical features with our solution goal.\n\n**Observations.**\n\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\n- Ports of embarkation have varying survival rates for Pcla\n\n=== MARKDOWN 29 ===\n### Correlating categorical and numerical features\n\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n\n**Observations.**\n\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n\n**Decisions.**\n\n- Consider banding Fare feature.\n\n=== MARKDOWN 31 ===\n## Wrangle data\n\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n\n### Correcting by dropping features\n\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\n\n\n=== MARKDOWN 33 ===\n### Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n\n**Observations.**\n\nWhen we plot Title, Age, and Survived, we note the following observations.\n\n- Most titles band Age groups accurately. For example: Master\n\n=== CODE 34 ===\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])\n\n=== MARKDOWN 35 ===\nWe can replace many titles with a more common name or classify them as `Rare`.\n\n=== CODE 36 ===\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n\n=== MARKDOWN 37 ===\nWe can convert the categorical titles to ordinal.\n\n=== CODE 38 ===\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()\n\n=== MARKDOWN 39 ===\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\n\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: === MARKDOWN 0 ===\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\n\n=== MARKDOWN 1 ===\n# Part 2: Your coding environment\n\nIn this section, you'll train your own machine learning model to improve your predictions.  _If you've never written code before or don't have any experience with machine learning, don't worry!  We don't assume any prior experience in this tutorial._\n\n## The Notebook\n\nThe first thing to do is to create a Kaggle Notebook where you'll store all of your code.  You c\n\n=== CODE 2 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data proc\n\n=== MARKDOWN 3 ===\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We'll do that next.\n\n## Load the data\n\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\n\n![](https://i.imgur.com/OQBax9n.png)\n\nType the two lines of code below into your second code cell.  Then, once you're done, either click on the blue pl\n\n=== CODE 4 ===\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()\n\n=== MARKDOWN 5 ===\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It's very important that you see this output **in your notebook** before proceeding with the tutorial!\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\n\n=== CODE 6 ===\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()\n\n=== MARKDOWN 7 ===\nAs before, make sure that you see the output above in your notebook before continuing.  \n\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\n\n# Part 3: Your first submission\n\n=== CODE 8 ===\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\n=== MARKDOWN 9 ===\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\n\nThen, run the code below in another code cell:\n\n=== CODE 10 ===\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)\n\n=== MARKDOWN 11 ===\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\n\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\n\nBut at the end of the day, this gender-based s\n\n=== CODE 12 ===\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.f\n\n=== MARKDOWN 13 ===\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\n> Again, don't worry if this code doesn't make sense to you!  For now, we'll focus on how to generate and submit predictions.\n\nOnce you're ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \n- Ensure tha\n\n=== MARKDOWN 14 ===\n# Part 4: Learn more!\n\nIf you're interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we've presented here.  You'll also know enough to generate even better predictions!\n\n",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb'}, {'role': 'tool', 'content': '‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb'}, {'role': 'assistant', 'content': 'REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.'}, {'role': 'tool', 'content': '=== MARKDOWN 23 ===\\n## Analyze by visualizing data\\n\\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n\\n### Correlating numerical features\\n\\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\\n\\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \\n\\n=== MARKDOWN 25 ===\\n### Correlating numerical and ordinal features\\n\\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n\\n**Observations.**\\n\\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n- Pclass varies in terms of Age distribution of passengers.\\n\\n**Decisions\\n\\n=== MARKDOWN 27 ===\\n### Correlating categorical features\\n\\nNow we can correlate categorical features with our solution goal.\\n\\n**Observations.**\\n\\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n- Ports of embarkation have varying survival rates for Pcla\\n\\n=== MARKDOWN 29 ===\\n### Correlating categorical and numerical features\\n\\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n\\n**Observations.**\\n\\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n\\n**Decisions.**\\n\\n- Consider banding Fare feature.\\n\\n=== MARKDOWN 31 ===\\n## Wrangle data\\n\\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n\\n### Correcting by dropping features\\n\\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n\\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n\\n\\n=== MARKDOWN 33 ===\\n### Creating new feature extracting from existing\\n\\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n\\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n\\n**Observations.**\\n\\nWhen we plot Title, Age, and Survived, we note the following observations.\\n\\n- Most titles band Age groups accurately. For example: Master\\n\\n=== CODE 34 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset.Name.str.extract(\\' ([A-Za-z]+)\\\\.\\', expand=False)\\n\\npd.crosstab(train_df[\\'Title\\'], train_df[\\'Sex\\'])\\n\\n=== MARKDOWN 35 ===\\nWe can replace many titles with a more common name or classify them as `Rare`.\\n\\n=== CODE 36 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace([\\'Lady\\', \\'Countess\\',\\'Capt\\', \\'Col\\',\\\\\\n \\t\\'Don\\', \\'Dr\\', \\'Major\\', \\'Rev\\', \\'Sir\\', \\'Jonkheer\\', \\'Dona\\'], \\'Rare\\')\\n\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mlle\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Ms\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mme\\', \\'Mrs\\')\\n    \\ntrain_df[[\\'Title\\', \\'Survived\\']].groupby([\\'Title\\'], as_index=False).mean()\\n\\n=== MARKDOWN 37 ===\\nWe can convert the categorical titles to ordinal.\\n\\n=== CODE 38 ===\\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].map(title_mapping)\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].fillna(0)\\n\\ntrain_df.head()\\n\\n=== MARKDOWN 39 ===\\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now I have comprehensive information. Let me write the seed prompt with all the techniques I've learned.\"}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': 'REASONING: Now let me check if there are any additional techniques in the Alexis Cook tutorial that might be helpful, and also search for any advanced techniques that could help beat the 1.0 target score (which is 100% accuracy - extremely challenging).'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\\n\\n=== MARKDOWN 1 ===\\n# Part 2: Your coding environment\\n\\nIn this section, you\\'ll train your own machine learning model to improve your predictions.  _If you\\'ve never written code before or don\\'t have any experience with machine learning, don\\'t worry!  We don\\'t assume any prior experience in this tutorial._\\n\\n## The Notebook\\n\\nThe first thing to do is to create a Kaggle Notebook where you\\'ll store all of your code.  You c\\n\\n=== CODE 2 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load in \\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data proc\\n\\n=== MARKDOWN 3 ===\\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We\\'ll do that next.\\n\\n## Load the data\\n\\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\\n\\n![](https://i.imgur.com/OQBax9n.png)\\n\\nType the two lines of code below into your second code cell.  Then, once you\\'re done, either click on the blue pl\\n\\n=== CODE 4 ===\\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntrain_data.head()\\n\\n=== MARKDOWN 5 ===\\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It\\'s very important that you see this output **in your notebook** before proceeding with the tutorial!\\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\\n\\n=== CODE 6 ===\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\\ntest_data.head()\\n\\n=== MARKDOWN 7 ===\\nAs before, make sure that you see the output above in your notebook before continuing.  \\n\\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\\n\\n# Part 3: Your first submission\\n\\n=== CODE 8 ===\\nwomen = train_data.loc[train_data.Sex == \\'female\\'][\"Survived\"]\\nrate_women = sum(women)/len(women)\\n\\nprint(\"% of women who survived:\", rate_women)\\n\\n=== MARKDOWN 9 ===\\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\\n\\nThen, run the code below in another code cell:\\n\\n=== CODE 10 ===\\nmen = train_data.loc[train_data.Sex == \\'male\\'][\"Survived\"]\\nrate_men = sum(men)/len(men)\\n\\nprint(\"% of men who survived:\", rate_men)\\n\\n=== MARKDOWN 11 ===\\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\\n\\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\\n\\nBut at the end of the day, this gender-based s\\n\\n=== CODE 12 ===\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\\nX = pd.get_dummies(train_data[features])\\nX_test = pd.get_dummies(test_data[features])\\n\\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\\nmodel.f\\n\\n=== MARKDOWN 13 ===\\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\\n> Again, don\\'t worry if this code doesn\\'t make sense to you!  For now, we\\'ll focus on how to generate and submit predictions.\\n\\nOnce you\\'re ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \\n- Ensure tha\\n\\n=== MARKDOWN 14 ===\\n# Part 4: Learn more!\\n\\nIf you\\'re interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we\\'ve presented here.  You\\'ll also know enough to generate even better predictions!\\n\\n'}]",
        "llm.input_tokens": 29051,
        "llm.output_tokens": 109,
        "llm.total_tokens": 29160,
        "llm.latency_ms": 4264.658689498901,
        "llm.completion": "REASONING: The tutorial is basic. Let me search for advanced techniques that could help achieve very high accuracy on this problem, particularly since the target is 100% accuracy which is extremely challenging.\n[Tool Use: WebSearch]",
        "llm.reasoning": "REASONING: The tutorial is basic. Let me search for advanced techniques that could help achieve very high accuracy on this problem, particularly since the target is 100% accuracy which is extremely challenging.",
        "llm.cost_usd": 0.08878799999999999
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "12d3f5a126134746",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "WebSearchTool",
      "kind": "INTERNAL",
      "start_time": 1767683608827797546,
      "end_time": 1767683613801412400,
      "duration": 4.973614854,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "WebSearchTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.research.WebSearchTool object at 0x73eac380cd10>\", \"input\": {\"query\": \"What are the best techniques to achieve highest accuracy on Titanic Kaggle competition?\"}}",
        "tool.output": "{\"content\": \"SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80‚ÄØ% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random‚ÄØForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n**Step‚Äëby‚Äëstep recipe**\\n\\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \\n\\n2. **Impute & create missing‚Äëvalue flags**  \\n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \\n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1‚ÄØif Cabin not null, else‚ÄØ0).  \\n   * Optionally encode the original *Cabin* letter as a categorical feature.  \\n\\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \\n   * **FamilySize** = `SibSp + Parch + 1`  \\n   * **IsAlone** = 1‚ÄØif *FamilySize*‚ÄØ=‚ÄØ1 else‚ÄØ0  \\n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \\n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \\n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \\n\\n   These engineered columns lifted baseline scores from ~72‚ÄØ% to ~78‚ÄØ% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \\n\\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35‚ÄØ% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \\n\\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \\n   * `n_estimators` (200‚Äë1000)  \\n   * `max_depth` (5‚Äë15)  \\n   * `min_samples_split` / `min_samples_leaf`  \\n   * `max_features` (sqrt, log2, or a fraction)  \\n\\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100‚ÄØ% Accuracy‚Äù notebook placed the author in the top‚ÄØ3‚ÄØ%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \\n\\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•‚ÄØ0.84) before uploading.  \\n\\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\\n\\n--- Result 2 ---\\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\\n\\nContent:\\nSeptember 10, 2016¬†¬†¬†¬†¬†33min read\\n\\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\\n\\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\\n\\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I'm writing this post, I am ranked among the top 4% of all Kagglers.\\n\\nThis post is the opportunity to share my solution with you.\\n\\nTo make this tutorial more \\\"academic\\\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I'll follow with feature engineering and finally present the predictive model I set up.\\n\\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\\nThe main libraries involved in this tutorial are:\\n\\n- **Pandas** for data manipulation and ingestion\\n- **Matplotlib** and **seaborn** for data visualization\\n- **Numpy** for multidimensional array computing\\n- **sklearn** for machine learning and predictive modeling\\n\\n### Installation procedure\\n\\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\\n\\n### Nota Bene\\n\\nThis is my first attempt as a blogger and as a machine learning practitioner.\\n\\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\\n\\nHope you've got everything set on your computer. Let's get started.\\n\\n## I - Exploratory data analysis\\n\\nAs in different data projects, we'll first start diving into the data and build up our first intuitions.\\n\\nIn this section, we'll be doing four things.\\n\\n- Data extraction : we'll load the dataset and have a first look at it.\\n- Cleaning : we'll fill in missing values.\\n- Plotting : we'll create some interesting charts that'll (hopefully) spot correlations and hidden insights out of the data.\\n- Assumptions : we'll formulate hypotheses from the charts.\\n\\nWe tweak the style of this notebook a little bit to have centered plots.\\n\\n```\\nfrom IPython.core.display import HTML\\nHTML(\\\"\\\"\\\"\\n<style>\\n.output_png {\\n    display: table-cell;\\n    text-align: center;\\n    vertical-align: middle;\\n}\\n</style>\\n\\\"\\\"\\\");\\n```\\n\\nWe import the useful libraries.\\n\\n```\\n%matplotlib inline\\n\\nimport warnings\\nwarnings.filterwarnings('ignore')\\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\\n\\nimport pandas as pd\\npd.options.display.max_columns = 100\\n\\nfrom matplotlib import pyplot as plt\\nimport numpy as np\\n\\nimport seaborn as sns\\n\\nimport pylab as plot\\nparams = {\\n    'axes.labelsize': \\\"large\\\",\\n    'xtick.labelsize': 'x-large',\\n    'legend.fontsize': 20,\\n    'figure.dpi': 150,\\n    'figure.figsize': [25, 7]\\n}\\nplot.rcParams.update(params)\\n```\\n\\nTwo datasets are available: a training set and a test set.\\nWe'll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\\n\\nWe'll see how this procedure is done at the end of this post.\\n\\nNow let's start by loading the training set.\\n\\n```\\ndata = pd.read_csv('./data/train.csv')\\nprint(data.shape)\\n#(891, 12)\\n```\\n\\nWe have:\\n\\n- 891 rows\\n- 12 columns\\n\\nPandas allows you to have a sneak peak at your data.\\n\\n```\\ndata.head()\\n```\\n\\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\\n\\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he's dead. The is the variable we're going to predict.\\n\\nThe other variables describe the passengers. They are the **features**.\\n\\n- PassengerId: and id given to each traveler on the boat\\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\\n- The Name of the passeger\\n- The Sex\\n- The Age\\n- SibSp: number of siblings and spouses traveling with the passenger\\n- Parch: number of parents and children traveling with the passenger\\n- The ticket number\\n- The ticket Fare\\n- The cabin number\\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\\n\\nPandas allows you to a have a high-level simple statistical description of the numerical features.\\nThis can be done using the describe method.\\n\\n```\\ndata.describe()\\n```\\n\\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\\n\\nThe count variable shows that 177 values are missing in the Age column.\\n\\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\\n\\n```\\ndata['Age'] = data['Age'].fillna(data['Age'].median())\\n```\\n\\nLet's now make some charts.\\n\\nLet's visualize survival based on the gender.\\n\\n```\\ndata['Died'] = 1 - data['Survived']\\ndata.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\\n                                                          stacked=True, colors=['g', 'r']);\\n```\\n\\nIt looks like male passengers are more likely to succumb.\\n\\nLet's plot the same graph but with ratio instead.\\n\\n```\\ndata.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\\n                                                           stacked=True, colors=['g', 'r']);\\n```\\n\\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\\n\\nLet's now correlate the survival with the age variable.\\n\\n```\\nfig = plt.figure(figsize=(25, 7))\\nsns.violinplot(x='Sex', y='Age',\\n               hue='Survived', data=data,\\n               split=True,\\n               palette={0: \\\"r\\\", 1: \\\"g\\\"}\\n              );\\n```\\n\\nAs we saw in the chart above and validate by the following:\\n\\n- Women survive more than men, as depicted by the larger female green histogram\\n\\nNow, we see that:\\n\\n- The age conditions the survival for male passengers:\\n\\n  - Younger male tend to survive\\n  - A large number of passengers between 20 and 40 succumb\\n- The age doesn't seem to have a direct impact on the female survival\\n\\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\\\"Women and children first !\\\"**.\\n\\nRight?\\n\\nLet's now focus on the Fare ticket of each passenger and see how it could impact the survival.\\n\\n```\\nfigure = plt.figure(figsize=(25, 7))\\nplt.hist([dat...\\n\\n--- Result 3 ---\\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\nURL: https://github.com/alicevillar/titanic-kaggle\\n\\nContent:\\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\\n\\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\\n\\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n- [Fork\\\\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n- [Star\\\\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n[6\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n\\n# alicevillar/titanic-kaggle\\n\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n\\nmain\\n\\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\\n\\nGo to file\\n\\nCode\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\\n| ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\\n| ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\\n| View all files |\\n\\n## Repository files navigation\\n\\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n\\nThe objective of Kaggle's Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\\n\\n### Quick Start:\\n\\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\\n\\n### Dependencies:\\n\\n- [Numpy](https://numpy.org/)\\n- [Pandas](https://pandas.pydata.org/)\\n- [SciKit-Learn](https://scikit-learn.org/)\\n- [Matplotlib](https://matplotlib.org/)\\n- [Seaborn](https://seaborn.pydata.org/)\\n\\n### Approach\\n\\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\\n\\n### Kaggle Competition \\\\| Titanic Machine Learning from Disaster\\n\\nKaggle's challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle's [Competition Page](https://www.kaggle.com/c/titanic):\\n\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\\\"\\n\\n### Results\\n\\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\\n\\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\\n\\n## About\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n### Topics\\n\\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\\n\\n### Resources\\n\\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\\n\\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n### Stars\\n\\n[**6**\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\\n\\n### Watchers\\n\\n[**1**\\\\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\\n\\n### Forks\\n\\n[**3**\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\\n\\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\\n\\n--- Result 4 ---\\nTitle: Search code, repositories, users, issues, pull requests...\\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\n\\nContent:\\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[Skip to content](#start-of-content)\\n## Navigation Menu\\nToggle navigation\\n[](https://github.com/)\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nSearch or jump to...\\n# Search code, repositories, users, issues, pull requests...\\n</option></form>\\nSearch\\nClear\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n# Provide feedback\\n</option></form>\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancelSubmit feedback\\n# Saved searches\\n## Use saved searches to filter your results more quickly\\n</option></form>\\nName\\nQuery\\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\nCancelCreate saved search\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nResetting focus\\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\\n{{ message }}\\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\nmain\\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\nGo to file\\nCode\\nOpen more actions menu\\n## Folders and files\\n|Name|Name|\\nLast commit message\\n|\\nLast commit date\\n|\\n## Latest commit\\n## History\\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n|\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n|\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n|\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n|\\n|\\nView all files\\n|\\n## Repository files navigation\\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\~72% to \\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n# Titanic Survival Prediction\\n[](#titanic-survival-prediction)\\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\\n* **Detailed EDA**\\nA Jupyter notebook that walks through exploratory data analysis:\\n* Summary statistics\\n* Missing-value patterns\\n* Feature distributions and pairwise relationships\\n* Correlation heatmaps\\n* **Feature Engineering**\\nCreation of high-signal features from raw inputs, including:\\n* `Has\\\\_Cabin`(binary cabin indicator)\\n* `FareBin`(quantile-based fare categories)\\n* Group-median imputation for`Age`, then 10-year age bins\\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\\n* `Title`extracted and consolidated from passenger names\\n* **Model Comparison**\\nTraining and evaluation of multiple classifiers on the engineered feature set:\\n* Random Forest\\n* Support Vector Machine\\n* K-Nearest Neighbors (k=3,5,7)\\n* XGBoost\\n* LightGBM\\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\\n* **Analysis &amp; Interpretation**\\nInline Markdown commentary explains:\\n* Why each feature matters\\n* How missing data were handled\\n* The rationale for model selection\\n* Key takeaways and next-step recommendations\\n## Repository Structure\\n[](#repository-structure)\\ndata/\\n* train.csv # Official Kaggle training set\\n* test.csv # Official Kaggle test set\\nnotebooks/\\n* titanic\\\\_analysis.ipynb\\n‚Ä¢EDA, feature engineering, model training\\n‚Ä¢Detailed Markdown analysis\\n* README.md # Project overview and instructions\\n## Contributing\\n[](#contributing)\\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\\n## About\\nPredict Titanic survival using t...\\n\\n--- Result 5 ---\\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\n\\nContent:\\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\\nAman Krishna\\n2022-04-20T07:23:42Z\\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\n\\n## The art of fine-tuning a model\\n\\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\\n\\n7 min read\\n\\n\\nApr 19, 2022\\n\\n\\nListen\\n\\nShare\\n\\nPress enter or click to view image in full size\\n\\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\\n\\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\\n\\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\\n\\nYou can find the complete code on Github **_:_**\\n\\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \\n\\n**Machine Learning model build for survivor prediction for Kaggle's titanic competition - kaggle_titanic/Model‚Ä¶**\\n\\ngithub.com]\\n\\n## Which Model to use?\\n\\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\\n\\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\\n\\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\\n\\n## Pre-Requisite\\n\\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\\n\\n### Dropping Features\\n\\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\\n\\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\\n\\n### Code\\n\\n### Dummify Data\\n\\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\\n\\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\\n\\n**We will be using One-Hot encoding on our categorical features.**\\n\\n### Code\\n\\n### Split Data\\n\\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\\n\\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\\n\\n## Training\\n\\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\\n\\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\\n\\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\\n\\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\\n\\n### Code\\n\\n## Fine Tuning\\n\\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\\n\\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\\n\\n### Code\\n\\n### Output\\n\\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\\n\\nPress enter or click to view image in full size\\n\\nGrid Search Results\\n\\n## Refining Search Space: Max Depth & Max Samples\\n\\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\\n\\n### How?\\n\\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\\n\\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\\n\\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest max_Depth & max_samples\\n\\n## Fine Tune: Min Sample Split & Min Sample Leaf\\n\\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest min_samples_leaf & min_samples_split\\n\\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\\n\\n## Fine Tune: Number of Estimators\\n\\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest n_estimator value\\n\\n## Refining Search Space: Number of estima...\\n\\n--- Result 6 ---\\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\\n\\nContent:\\n<div><div><div><a href=\\\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\\\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\\\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\\\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\\n\\n--- Result 7 ---\\nTitle: Titanic - Machine Learning from Disaster\\nURL: https://www.kaggle.com/c/titanic/code\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\\\"https://www.kaggle.com/organizations/kaggle\\\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\\\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\\\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\\\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\\\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/maita27/titanic/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\\\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\\\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\\\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\\\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h ago</span></span> </span><span><span><span>Score: 0.72488</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster-xgboost/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>notebook2de88c4bdc</p><p><span><span>Updated <span>2h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/ahzaradsh/notebook2de88c4bdc/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li></li><li><div><div><p>Building an Interactive GUI in Kaggle with ipywidg</p><p><span><span>Updated <span>5d ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/zohaib123/building-an-interactive-gui-in-kaggle-with-ipywidg/comments\\\">3 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span><span><span><span> +9</span></span></span></span></span></span></p></div><div><p><span>13</span></p><p><span><span> Bronze</span></span></p></div></div></li><li><div><p>Titanic predict using R</p><p><span><span>Updated <span>2d ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/resious/titanic-predict-using-r/comments\\\">3 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Competition Code File No 554488522</p><p><span><span>Updated <span>2d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/hmdanyal/titanic-competition-code-file-no-554488522/comments\\\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>simple</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77751</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/blue68/simple/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanik_Eƒüitim</p><p><span><span>Updated <span>2d ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/kadirkrtls/titanik-e-itim/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><div><p>My Titanic Model (XGBoost,LogReg,GridSearchCV)</p><p><span><span>Updated <span>3d ago</span></span> </span><span><span><span>Score: 0.78708</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/emirhngull/my-titanic-model-xgboost-logreg-gridsearchcv/comments\\\">5 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></sp...\\n\\n--- Result 8 ---\\nTitle: Titanic Competition [Journey to 100% Accuracy]\\nURL: https://www.kaggle.com/code/amerwafiy/titanic-competition-journey-to-100-accuracy\\n\\nContent:\\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n\\n[Learn more](https://www.kaggle.com/cookies)\\n\\nOK, Got it.\\n\\n###### Something went wrong and this page crashed!\\n\\nIf the issue persists, it's likely a problem on our side.\\n\\n```\\n\\nLoading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\n    at b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=8cd3a1b73a88961fadc8:1:10922)\\n```\\n\\nRefresh\\n\\n--- Result 9 ---\\nTitle: How to Predict %80 Accuracy in the Titanic Disaster Competition\\nURL: https://python.plainenglish.io/how-to-predict-80-accuracy-in-titanic-disaster-competition-762f5c0f4bfb?gi=189b98032ad3\\n\\nContent:\\n<div><div><div><a href=\\\"https://medium.com/@ozzgur.sanli?source=post_page---byline--762f5c0f4bfb---------------------------------------\\\"><div><p></p></div></a></div><p>In this post, I will explain how to achieve accuracy over 80% in Kaggle‚Äôs Titanic Disaster Competition by using data manipulation, feature engineering techniques, and machine learning algorithms. Even though achieving the highest accuracy is our main objective, I believe this project is highly \\\"core\\\" for people who are new to data science or simply want to refresh their memory on the subject.</p><figure></figure><p>For those who do not know about Kaggle‚Äôs competition, let me quickly inform you that our goal is to predict the survivors of the Titanic disaster. On Kaggle's page, you can find comprehensive information about this subject. This page includes graphs that provide a detailed description of the data set's attributes.</p><p>First of all, we will quickly examine the data set (EDA), and then we will determine if there are outliers. We will fill in any missing data, if there are any. We interpret the notable results based on the correlations found in the dataset between the independent and dependent variables. A machine-learning model is going to be developed based on these findings. The process is displayed below.</p><figure><figcaption>The workflow of Project</figcaption></figure><p>Let‚Äôs begin by importing the packages we need.</p><pre><span>This Python 3 environment comes with many helpful analytics libraries installed<br/># It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python<br/>For example, here are several helpful packages to load<br/>import numpy as np<br/>import pandas as pd<br/>import seaborn as sns<br/>from matplotlib import pyplot as plt<br/>from datetime import date<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import LabelEncoder, StandardScaler<br/>import joblib<br/>import pandas as pd<br/>from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, and AdaBoostClassifier<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import cross_validate, GridSearchCV,cross_val_score<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.svm import SVC<br/>from sklearn.tree import DecisionTreeClassifier<br/>from xgboost import XGBClassifier<br/>import warnings<br/>warnings.filterwarnings(\\\"ignore\\\")<br/># Input data files are available in the read-only \\\"../input/\\\" directory<br/>For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory<p>import os<br/>for dirname, _, filenames in os.walk('/kaggle/input'):<br/> for filename in filenames:<br/> print(os.path.join(dirname, filename))</p></span></pre><p>Now load the dataset. There‚Äôre 2 datasets: one is the ‚Äútrain.csv‚Äù dataset, which has the ‚ÄúSurvived‚Äù variable filled with 1‚Äì0, and the other is the \\\"test.csv,\\\" from which we will predict the survived ones.</p><pre><span>train = pd.read_csv(\\\"/kaggle/input/titanic/train.csv\\\")<br/>test = pd.read_csv(\\\"/kaggle/input/titanic/test.csv\\\")<br/>df = pd.concat([train, test], axis=0)<br/></span></pre><h2><strong>Exploratory Data Analysis</strong></h2><p>For exploratory data analysis, we will use .head(), info(), describe() functions.</p><pre><span>df.head()<br/>Out[4]: <br/> PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked<br/>0 1 0.000 3 Braund, Mr. Owen Harris male 22.000 1 0 A/5 21171 7.250 NaN S<br/>1 2 1.000 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.000 1 0 PC 17599 71.283 C85 C<br/>2 3 1.000 3 Heikkinen, Miss. Laina female 26.000 0 0 STON/O2. 3101282 7.925 NaN S<br/>3 4 1.000 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.000 1 0 113803 53.100 C123 S<br/>4 5 0.000 3 Allen, Mr. William Henry male 35.000 0 0 373450 8.050 NaN S</span></pre><pre><span>df.info()<br/>&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>Int64Index: 1309 entries, 0 to 417<br/>Data columns (total 12 columns):<br/> # Column Non-Null Count Dtype <br/>--- ------ -------------- ----- <br/> 0 PassengerId 1309 non-null int64 <br/> 1 Survived 891 non-null float64<br/> 2 Pclass 1309 non-null int64 <br/> 3 Name 1309 non-null object <br/> 4 Sex 1309 non-null object <br/> 5 Age 1046 non-null float64<br/> 6 SibSp 1309 non-null int64 <br/> 7 Parch 1309 non-null int64 <br/> 8 Ticket 1309 non-null object <br/> 9 Fare 1308 non-null float64<br/> 10 Cabin 295 non-null object <br/> 11 Embarked 1307 non-null object <br/>dtypes: float64(3), int64(4), object(5)<br/>memory usage: 132.9+ KB</span></pre><pre><span>df.describe().T<br/>Out[5]: <br/> count mean std min 25% 50% 75% max<br/>PassengerId 1309.000 655.000 378.020 1.000 328.000 655.000 982.000 1309.000<br/>Survived 891.000 0.384 0.487 0.000 0.000 0.000 1.000 1.000<br/>Pclass 1309.000 2.295 0.838 1.000 2.000 3.000 3.000 3.000<br/>Age 1046.000 29.881 14.413 0.170 21.000 28.000 39.000 80.000<br/>SibSp 1309.000 0.499 1.042 0.000 0.000 0.000 1.000 8.000<br/>Parch 1309.000 0.385 0.866 0.000 0.000 0.000 0.000 9.000<br/>Fare 1308.000 33.295 51.759 0.000 7.896 14.454 31.275 512.329</span></pre><p>Considering that you have reviewed the data before, I am going through these parts a little fast because of not extending the reading time.</p><p>In order to visually examine the dataset, we will first divide the columns of the data into numerical columns and categorical columns. Thus, we can more easily show the relationship of these columns with the ‚ÄúSurvived‚Äù variable, that is, the target variable.</p><p>We use the function ‚Äúgrab_col_names()‚Äù to separate the columns according to their types. This function separates the columns in the data into numerical, categorical, numerical but originally categorical, and categorical but originally cardinal.</p><pre><span>def grab_col_names(dataframe, cat_th=10, car_th=20):<br/> \\\"\\\"\\\"<br/> It provides the names of categorical, numerical, and categorical but cardinal variables in the dataset.<br/> Note: Numerical-looking categorical variables are also included in the categorical variables.<p> Parameters<br/> ------<br/> dataframe: dataframe<br/> The dataframe from which variable names are to be retrieved<br/> cat_th: int, optional<br/> Threshold value for variables that are numerical but categorical.<br/> car_th: int, optinal<br/> Threshold value for variables that are categorical but cardinal.<br/> Returns<br/> ------<br/> cat_cols: list<br/> Categorical variable list<br/> num_cols: list<br/> Numeric variable list<br/> cat_but_car: list<br/> List of categorical variables that appear to be cardinal</p><p> Examples<br/> ------<br/> import seaborn as sns<br/> df = sns.load_dataset(\\\"iris\\\")<br/> print(grab_col_names(df))</p><p> Notes<br/> ------<br/> cat_cols + num_cols + cat_but_car = total number of variables<br/> num_but_cat is within cat_cols<br/> The sum of the 3 lists returned equals the total number of variables: <br/> cat_cols + num_cols + cat_but_car = total number of variables<br/> \\\"\\\"\\\"</p><p> # cat_cols, cat_but_car<br/> cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \\\"O\\\"]<br/> num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() &lt; cat_th and<br/> dataframe[col].dtypes != \\\"O\\\"]<br/> cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() &gt; car_th and<br/> dataframe[col].dtypes == \\\"O\\\"]<br/> cat_cols = cat_cols + num_but_cat<br/> cat_cols = [col for col in cat_cols if col not in cat_but_car]</p><p> # num_cols<br/> num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \\\"O\\\"]<br/> num_cols = [col for col in num_cols if col not in num_but_cat]</p><p> print(f\\\"Observations: {dataframe.shape[0]}\\\")<br/> print(f\\\"Variables: {dataframe.shape[1]}\\\")<br/> print(f'cat_cols: {len(cat_cols)}')<br/> print(f'num_cols: {len(num_cols)}')<br/> print(f'cat_but_car: {len...\\n\", \"is_error\": false, \"results\": [{\"title\": \"ANSWER\", \"text\": \"Based on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80‚ÄØ% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random‚ÄØForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n**Step‚Äëby‚Äëstep recipe**\\n\\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \\n\\n2. **Impute & create missing‚Äëvalue flags**  \\n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \\n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1‚ÄØif Cabin not null, else‚ÄØ0).  \\n   * Optionally encode the original *Cabin* letter as a categorical feature.  \\n\\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \\n   * **FamilySize** = `SibSp + Parch + 1`  \\n   * **IsAlone** = 1‚ÄØif *FamilySize*‚ÄØ=‚ÄØ1 else‚ÄØ0  \\n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \\n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \\n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \\n\\n   These engineered columns lifted baseline scores from ~72‚ÄØ% to ~78‚ÄØ% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \\n\\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35‚ÄØ% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \\n\\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \\n   * `n_estimators` (200‚Äë1000)  \\n   * `max_depth` (5‚Äë15)  \\n   * `min_samples_split` / `min_samples_leaf`  \\n   * `max_features` (sqrt, log2, or a fraction)  \\n\\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100‚ÄØ% Accuracy‚Äù notebook placed the author in the top‚ÄØ3‚ÄØ%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \\n\\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•‚ÄØ0.84) before uploading.  \\n\\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\", \"url\": \"\"}, {\"title\": \"How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\", \"text\": \"September 10, 2016¬†¬†¬†¬†¬†33min read\\n\\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\\n\\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\\n\\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I'm writing this post, I am ranked among the top 4% of all Kagglers.\\n\\nThis post is the opportunity to share my solution with you.\\n\\nTo make this tutorial more \\\"academic\\\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I'll follow with feature engineering and finally present the predictive model I set up.\\n\\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\\nThe main libraries involved in this tutorial are:\\n\\n- **Pandas** for data manipulation and ingestion\\n- **Matplotlib** and **seaborn** for data visualization\\n- **Numpy** for multidimensional array computing\\n- **sklearn** for machine learning and predictive modeling\\n\\n### Installation procedure\\n\\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\\n\\n### Nota Bene\\n\\nThis is my first attempt as a blogger and as a machine learning practitioner.\\n\\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\\n\\nHope you've got everything set on your computer. Let's get started.\\n\\n## I - Exploratory data analysis\\n\\nAs in different data projects, we'll first start diving into the data and build up our first intuitions.\\n\\nIn this section, we'll be doing four things.\\n\\n- Data extraction : we'll load the dataset and have a first look at it.\\n- Cleaning : we'll fill in missing values.\\n- Plotting : we'll create some interesting charts that'll (hopefully) spot correlations and hidden insights out of the data.\\n- Assumptions : we'll formulate hypotheses from the charts.\\n\\nWe tweak the style of this notebook a little bit to have centered plots.\\n\\n```\\nfrom IPython.core.display import HTML\\nHTML(\\\"\\\"\\\"\\n<style>\\n.output_png {\\n    display: table-cell;\\n    text-align: center;\\n    vertical-align: middle;\\n}\\n</style>\\n\\\"\\\"\\\");\\n```\\n\\nWe import the useful libraries.\\n\\n```\\n%matplotlib inline\\n\\nimport warnings\\nwarnings.filterwarnings('ignore')\\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\\n\\nimport pandas as pd\\npd.options.display.max_columns = 100\\n\\nfrom matplotlib import pyplot as plt\\nimport numpy as np\\n\\nimport seaborn as sns\\n\\nimport pylab as plot\\nparams = {\\n    'axes.labelsize': \\\"large\\\",\\n    'xtick.labelsize': 'x-large',\\n    'legend.fontsize': 20,\\n    'figure.dpi': 150,\\n    'figure.figsize': [25, 7]\\n}\\nplot.rcParams.update(params)\\n```\\n\\nTwo datasets are available: a training set and a test set.\\nWe'll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\\n\\nWe'll see how this procedure is done at the end of this post.\\n\\nNow let's start by loading the training set.\\n\\n```\\ndata = pd.read_csv('./data/train.csv')\\nprint(data.shape)\\n#(891, 12)\\n```\\n\\nWe have:\\n\\n- 891 rows\\n- 12 columns\\n\\nPandas allows you to have a sneak peak at your data.\\n\\n```\\ndata.head()\\n```\\n\\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\\n\\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he's dead. The is the variable we're going to predict.\\n\\nThe other variables describe the passengers. They are the **features**.\\n\\n- PassengerId: and id given to each traveler on the boat\\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\\n- The Name of the passeger\\n- The Sex\\n- The Age\\n- SibSp: number of siblings and spouses traveling with the passenger\\n- Parch: number of parents and children traveling with the passenger\\n- The ticket number\\n- The ticket Fare\\n- The cabin number\\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\\n\\nPandas allows you to a have a high-level simple statistical description of the numerical features.\\nThis can be done using the describe method.\\n\\n```\\ndata.describe()\\n```\\n\\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\\n\\nThe count variable shows that 177 values are missing in the Age column.\\n\\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\\n\\n```\\ndata['Age'] = data['Age'].fillna(data['Age'].median())\\n```\\n\\nLet's now make some charts.\\n\\nLet's visualize survival based on the gender.\\n\\n```\\ndata['Died'] = 1 - data['Survived']\\ndata.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\\n                                                          stacked=True, colors=['g', 'r']);\\n```\\n\\nIt looks like male passengers are more likely to succumb.\\n\\nLet's plot the same graph but with ratio instead.\\n\\n```\\ndata.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\\n                                                           stacked=True, colors=['g', 'r']);\\n```\\n\\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\\n\\nLet's now correlate the survival with the age variable.\\n\\n```\\nfig = plt.figure(figsize=(25, 7))\\nsns.violinplot(x='Sex', y='Age',\\n               hue='Survived', data=data,\\n               split=True,\\n               palette={0: \\\"r\\\", 1: \\\"g\\\"}\\n              );\\n```\\n\\nAs we saw in the chart above and validate by the following:\\n\\n- Women survive more than men, as depicted by the larger female green histogram\\n\\nNow, we see that:\\n\\n- The age conditions the survival for male passengers:\\n\\n  - Younger male tend to survive\\n  - A large number of passengers between 20 and 40 succumb\\n- The age doesn't seem to have a direct impact on the female survival\\n\\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\\\"Women and children first !\\\"**.\\n\\nRight?\\n\\nLet's now focus on the Fare ticket of each passenger and see how it could impact the survival.\\n\\n```\\nfigure = plt.figure(figsize=(25, 7))\\nplt.hist([dat...\", \"url\": \"https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\"}, {\"title\": \"GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\", \"text\": \"[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\\n\\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\\n\\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n- [Fork\\\\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n- [Star\\\\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n[6\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n\\n# alicevillar/titanic-kaggle\\n\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n\\nmain\\n\\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\\n\\nGo to file\\n\\nCode\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\\n| ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\\n| ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\\n| View all files |\\n\\n## Repository files navigation\\n\\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n\\nThe objective of Kaggle's Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\\n\\n### Quick Start:\\n\\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\\n\\n### Dependencies:\\n\\n- [Numpy](https://numpy.org/)\\n- [Pandas](https://pandas.pydata.org/)\\n- [SciKit-Learn](https://scikit-learn.org/)\\n- [Matplotlib](https://matplotlib.org/)\\n- [Seaborn](https://seaborn.pydata.org/)\\n\\n### Approach\\n\\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\\n\\n### Kaggle Competition \\\\| Titanic Machine Learning from Disaster\\n\\nKaggle's challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle's [Competition Page](https://www.kaggle.com/c/titanic):\\n\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\\\"\\n\\n### Results\\n\\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\\n\\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\\n\\n## About\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n### Topics\\n\\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\\n\\n### Resources\\n\\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\\n\\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n### Stars\\n\\n[**6**\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\\n\\n### Watchers\\n\\n[**1**\\\\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\\n\\n### Forks\\n\\n[**3**\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\\n\\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\", \"url\": \"https://github.com/alicevillar/titanic-kaggle\"}, {\"title\": \"Search code, repositories, users, issues, pull requests...\", \"text\": \"GitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[Skip to content](#start-of-content)\\n## Navigation Menu\\nToggle navigation\\n[](https://github.com/)\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nSearch or jump to...\\n# Search code, repositories, users, issues, pull requests...\\n</option></form>\\nSearch\\nClear\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n# Provide feedback\\n</option></form>\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancelSubmit feedback\\n# Saved searches\\n## Use saved searches to filter your results more quickly\\n</option></form>\\nName\\nQuery\\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\nCancelCreate saved search\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nResetting focus\\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\\n{{ message }}\\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\nmain\\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\nGo to file\\nCode\\nOpen more actions menu\\n## Folders and files\\n|Name|Name|\\nLast commit message\\n|\\nLast commit date\\n|\\n## Latest commit\\n## History\\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n|\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n|\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n|\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n|\\n|\\nView all files\\n|\\n## Repository files navigation\\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\~72% to \\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n# Titanic Survival Prediction\\n[](#titanic-survival-prediction)\\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\\n* **Detailed EDA**\\nA Jupyter notebook that walks through exploratory data analysis:\\n* Summary statistics\\n* Missing-value patterns\\n* Feature distributions and pairwise relationships\\n* Correlation heatmaps\\n* **Feature Engineering**\\nCreation of high-signal features from raw inputs, including:\\n* `Has\\\\_Cabin`(binary cabin indicator)\\n* `FareBin`(quantile-based fare categories)\\n* Group-median imputation for`Age`, then 10-year age bins\\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\\n* `Title`extracted and consolidated from passenger names\\n* **Model Comparison**\\nTraining and evaluation of multiple classifiers on the engineered feature set:\\n* Random Forest\\n* Support Vector Machine\\n* K-Nearest Neighbors (k=3,5,7)\\n* XGBoost\\n* LightGBM\\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\\n* **Analysis &amp; Interpretation**\\nInline Markdown commentary explains:\\n* Why each feature matters\\n* How missing data were handled\\n* The rationale for model selection\\n* Key takeaways and next-step recommendations\\n## Repository Structure\\n[](#repository-structure)\\ndata/\\n* train.csv # Official Kaggle training set\\n* test.csv # Official Kaggle test set\\nnotebooks/\\n* titanic\\\\_analysis.ipynb\\n‚Ä¢EDA, feature engineering, model training\\n‚Ä¢Detailed Markdown analysis\\n* README.md # Project overview and instructions\\n## Contributing\\n[](#contributing)\\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\\n## About\\nPredict Titanic survival using t...\", \"url\": \"https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\"}, {\"title\": \"Kaggle Titanic Challenge: Training & Fine-Tuning the Model\", \"text\": \"Aman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\\nAman Krishna\\n2022-04-20T07:23:42Z\\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\n\\n## The art of fine-tuning a model\\n\\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\\n\\n7 min read\\n\\n\\nApr 19, 2022\\n\\n\\nListen\\n\\nShare\\n\\nPress enter or click to view image in full size\\n\\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\\n\\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\\n\\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\\n\\nYou can find the complete code on Github **_:_**\\n\\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \\n\\n**Machine Learning model build for survivor prediction for Kaggle's titanic competition - kaggle_titanic/Model‚Ä¶**\\n\\ngithub.com]\\n\\n## Which Model to use?\\n\\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\\n\\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\\n\\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\\n\\n## Pre-Requisite\\n\\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\\n\\n### Dropping Features\\n\\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\\n\\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\\n\\n### Code\\n\\n### Dummify Data\\n\\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\\n\\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\\n\\n**We will be using One-Hot encoding on our categorical features.**\\n\\n### Code\\n\\n### Split Data\\n\\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\\n\\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\\n\\n## Training\\n\\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\\n\\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\\n\\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\\n\\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\\n\\n### Code\\n\\n## Fine Tuning\\n\\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\\n\\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\\n\\n### Code\\n\\n### Output\\n\\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\\n\\nPress enter or click to view image in full size\\n\\nGrid Search Results\\n\\n## Refining Search Space: Max Depth & Max Samples\\n\\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\\n\\n### How?\\n\\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\\n\\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\\n\\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest max_Depth & max_samples\\n\\n## Fine Tune: Min Sample Split & Min Sample Leaf\\n\\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest min_samples_leaf & min_samples_split\\n\\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\\n\\n## Fine Tune: Number of Estimators\\n\\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest n_estimator value\\n\\n## Refining Search Space: Number of estima...\", \"url\": \"https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\"}, {\"title\": \"How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\", \"text\": \"<div><div><div><a href=\\\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\\\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\\\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\\\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\", \"url\": \"https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\"}, {\"title\": \"Titanic - Machine Learning from Disaster\", \"text\": \"<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\\\"https://www.kaggle.com/organizations/kaggle\\\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\\\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\\\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\\\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\\\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/maita27/titanic/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\\\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\\\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\\\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\\\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h ago</span></span> </span><span><span><span>Score: 0.72488</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster-xgboost/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>notebook2de88c4bdc</p><p><span><span>Updated <span>2h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/ahzaradsh/notebook2de88c4bdc/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li></li><li><div><div><p>Building an Interactive GUI in Kaggle with ipywidg</p><p><span><span>Updated <span>5d ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/zohaib123/building-an-interactive-gui-in-kaggle-with-ipywidg/comments\\\">3 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span><span><span><span> +9</span></span></span></span></span></span></p></div><div><p><span>13</span></p><p><span><span> Bronze</span></span></p></div></div></li><li><div><p>Titanic predict using R</p><p><span><span>Updated <span>2d ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/resious/titanic-predict-using-r/comments\\\">3 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Competition Code File No 554488522</p><p><span><span>Updated <span>2d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/hmdanyal/titanic-competition-code-file-no-554488522/comments\\\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>simple</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77751</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/blue68/simple/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanik_Eƒüitim</p><p><span><span>Updated <span>2d ago</span></span> </span><span><span><a href=\\\"https://www.kaggle.com/code/kadirkrtls/titanik-e-itim/comments\\\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><div><p>My Titanic Model (XGBoost,LogReg,GridSearchCV)</p><p><span><span>Updated <span>3d ago</span></span> </span><span><span><span>Score: 0.78708</span> ¬∑ <a href=\\\"https://www.kaggle.com/code/emirhngull/my-titanic-model-xgboost-logreg-gridsearchcv/comments\\\">5 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></sp...\", \"url\": \"https://www.kaggle.com/c/titanic/code\"}, {\"title\": \"Titanic Competition [Journey to 100% Accuracy]\", \"text\": \"Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\\n\\n[Learn more](https://www.kaggle.com/cookies)\\n\\nOK, Got it.\\n\\n###### Something went wrong and this page crashed!\\n\\nIf the issue persists, it's likely a problem on our side.\\n\\n```\\n\\nLoading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 8198 failed.\\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\\n    at b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=8cd3a1b73a88961fadc8:1:10922)\\n```\\n\\nRefresh\", \"url\": \"https://www.kaggle.com/code/amerwafiy/titanic-competition-journey-to-100-accuracy\"}, {\"title\": \"How to Predict %80 Accuracy in the Titanic Disaster Competition\", \"text\": \"<div><div><div><a href=\\\"https://medium.com/@ozzgur.sanli?source=post_page---byline--762f5c0f4bfb---------------------------------------\\\"><div><p></p></div></a></div><p>In this post, I will explain how to achieve accuracy over 80% in Kaggle‚Äôs Titanic Disaster Competition by using data manipulation, feature engineering techniques, and machine learning algorithms. Even though achieving the highest accuracy is our main objective, I believe this project is highly \\\"core\\\" for people who are new to data science or simply want to refresh their memory on the subject.</p><figure></figure><p>For those who do not know about Kaggle‚Äôs competition, let me quickly inform you that our goal is to predict the survivors of the Titanic disaster. On Kaggle's page, you can find comprehensive information about this subject. This page includes graphs that provide a detailed description of the data set's attributes.</p><p>First of all, we will quickly examine the data set (EDA), and then we will determine if there are outliers. We will fill in any missing data, if there are any. We interpret the notable results based on the correlations found in the dataset between the independent and dependent variables. A machine-learning model is going to be developed based on these findings. The process is displayed below.</p><figure><figcaption>The workflow of Project</figcaption></figure><p>Let‚Äôs begin by importing the packages we need.</p><pre><span>This Python 3 environment comes with many helpful analytics libraries installed<br/># It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python<br/>For example, here are several helpful packages to load<br/>import numpy as np<br/>import pandas as pd<br/>import seaborn as sns<br/>from matplotlib import pyplot as plt<br/>from datetime import date<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import LabelEncoder, StandardScaler<br/>import joblib<br/>import pandas as pd<br/>from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, and AdaBoostClassifier<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import cross_validate, GridSearchCV,cross_val_score<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.svm import SVC<br/>from sklearn.tree import DecisionTreeClassifier<br/>from xgboost import XGBClassifier<br/>import warnings<br/>warnings.filterwarnings(\\\"ignore\\\")<br/># Input data files are available in the read-only \\\"../input/\\\" directory<br/>For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory<p>import os<br/>for dirname, _, filenames in os.walk('/kaggle/input'):<br/> for filename in filenames:<br/> print(os.path.join(dirname, filename))</p></span></pre><p>Now load the dataset. There‚Äôre 2 datasets: one is the ‚Äútrain.csv‚Äù dataset, which has the ‚ÄúSurvived‚Äù variable filled with 1‚Äì0, and the other is the \\\"test.csv,\\\" from which we will predict the survived ones.</p><pre><span>train = pd.read_csv(\\\"/kaggle/input/titanic/train.csv\\\")<br/>test = pd.read_csv(\\\"/kaggle/input/titanic/test.csv\\\")<br/>df = pd.concat([train, test], axis=0)<br/></span></pre><h2><strong>Exploratory Data Analysis</strong></h2><p>For exploratory data analysis, we will use .head(), info(), describe() functions.</p><pre><span>df.head()<br/>Out[4]: <br/> PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked<br/>0 1 0.000 3 Braund, Mr. Owen Harris male 22.000 1 0 A/5 21171 7.250 NaN S<br/>1 2 1.000 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.000 1 0 PC 17599 71.283 C85 C<br/>2 3 1.000 3 Heikkinen, Miss. Laina female 26.000 0 0 STON/O2. 3101282 7.925 NaN S<br/>3 4 1.000 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.000 1 0 113803 53.100 C123 S<br/>4 5 0.000 3 Allen, Mr. William Henry male 35.000 0 0 373450 8.050 NaN S</span></pre><pre><span>df.info()<br/>&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>Int64Index: 1309 entries, 0 to 417<br/>Data columns (total 12 columns):<br/> # Column Non-Null Count Dtype <br/>--- ------ -------------- ----- <br/> 0 PassengerId 1309 non-null int64 <br/> 1 Survived 891 non-null float64<br/> 2 Pclass 1309 non-null int64 <br/> 3 Name 1309 non-null object <br/> 4 Sex 1309 non-null object <br/> 5 Age 1046 non-null float64<br/> 6 SibSp 1309 non-null int64 <br/> 7 Parch 1309 non-null int64 <br/> 8 Ticket 1309 non-null object <br/> 9 Fare 1308 non-null float64<br/> 10 Cabin 295 non-null object <br/> 11 Embarked 1307 non-null object <br/>dtypes: float64(3), int64(4), object(5)<br/>memory usage: 132.9+ KB</span></pre><pre><span>df.describe().T<br/>Out[5]: <br/> count mean std min 25% 50% 75% max<br/>PassengerId 1309.000 655.000 378.020 1.000 328.000 655.000 982.000 1309.000<br/>Survived 891.000 0.384 0.487 0.000 0.000 0.000 1.000 1.000<br/>Pclass 1309.000 2.295 0.838 1.000 2.000 3.000 3.000 3.000<br/>Age 1046.000 29.881 14.413 0.170 21.000 28.000 39.000 80.000<br/>SibSp 1309.000 0.499 1.042 0.000 0.000 0.000 1.000 8.000<br/>Parch 1309.000 0.385 0.866 0.000 0.000 0.000 0.000 9.000<br/>Fare 1308.000 33.295 51.759 0.000 7.896 14.454 31.275 512.329</span></pre><p>Considering that you have reviewed the data before, I am going through these parts a little fast because of not extending the reading time.</p><p>In order to visually examine the dataset, we will first divide the columns of the data into numerical columns and categorical columns. Thus, we can more easily show the relationship of these columns with the ‚ÄúSurvived‚Äù variable, that is, the target variable.</p><p>We use the function ‚Äúgrab_col_names()‚Äù to separate the columns according to their types. This function separates the columns in the data into numerical, categorical, numerical but originally categorical, and categorical but originally cardinal.</p><pre><span>def grab_col_names(dataframe, cat_th=10, car_th=20):<br/> \\\"\\\"\\\"<br/> It provides the names of categorical, numerical, and categorical but cardinal variables in the dataset.<br/> Note: Numerical-looking categorical variables are also included in the categorical variables.<p> Parameters<br/> ------<br/> dataframe: dataframe<br/> The dataframe from which variable names are to be retrieved<br/> cat_th: int, optional<br/> Threshold value for variables that are numerical but categorical.<br/> car_th: int, optinal<br/> Threshold value for variables that are categorical but cardinal.<br/> Returns<br/> ------<br/> cat_cols: list<br/> Categorical variable list<br/> num_cols: list<br/> Numeric variable list<br/> cat_but_car: list<br/> List of categorical variables that appear to be cardinal</p><p> Examples<br/> ------<br/> import seaborn as sns<br/> df = sns.load_dataset(\\\"iris\\\")<br/> print(grab_col_names(df))</p><p> Notes<br/> ------<br/> cat_cols + num_cols + cat_but_car = total number of variables<br/> num_but_cat is within cat_cols<br/> The sum of the 3 lists returned equals the total number of variables: <br/> cat_cols + num_cols + cat_but_car = total number of variables<br/> \\\"\\\"\\\"</p><p> # cat_cols, cat_but_car<br/> cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \\\"O\\\"]<br/> num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() &lt; cat_th and<br/> dataframe[col].dtypes != \\\"O\\\"]<br/> cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() &gt; car_th and<br/> dataframe[col].dtypes == \\\"O\\\"]<br/> cat_cols = cat_cols + num_but_cat<br/> cat_cols = [col for col in cat_cols if col not in cat_but_car]</p><p> # num_cols<br/> num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \\\"O\\\"]<br/> num_cols = [col for col in num_cols if col not in num_but_cat]</p><p> print(f\\\"Observations: {dataframe.shape[0]}\\\")<br/> print(f\\\"Variables: {dataframe.shape[1]}\\\")<br/> print(f'cat_cols: {len(cat_cols)}')<br/> print(f'num_cols: {len(num_cols)}')<br/> print(f'cat_but_car: {len...\", \"url\": \"https://python.plainenglish.io/how-to-predict-80-accuracy-in-titanic-disaster-competition-762f5c0f4bfb?gi=189b98032ad3\"}]}",
        "tool.duration_ms": 4972.1667766571045
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "8fdeeb20280f70a0",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683614995131881,
      "end_time": 1767683622369419189,
      "duration": 7.374287308,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n\ntool: ‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\n  Source: exploration/eda.ipynb\ntool: ‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\n  Source: exploration/eda.ipynb\ntool: === MARKDOWN 23 ===\n## Analyze by visualizing data\n\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\n\n### Correlating numerical features\n\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\n\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \n\n=== MARKDOWN 25 ===\n### Correlating numerical and ordinal features\n\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n\n**Observations.**\n\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n- Pclass varies in terms of Age distribution of passengers.\n\n**Decisions\n\n=== MARKDOWN 27 ===\n### Correlating categorical features\n\nNow we can correlate categorical features with our solution goal.\n\n**Observations.**\n\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\n- Ports of embarkation have varying survival rates for Pcla\n\n=== MARKDOWN 29 ===\n### Correlating categorical and numerical features\n\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n\n**Observations.**\n\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n\n**Decisions.**\n\n- Consider banding Fare feature.\n\n=== MARKDOWN 31 ===\n## Wrangle data\n\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n\n### Correcting by dropping features\n\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\n\n\n=== MARKDOWN 33 ===\n### Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n\n**Observations.**\n\nWhen we plot Title, Age, and Survived, we note the following observations.\n\n- Most titles band Age groups accurately. For example: Master\n\n=== CODE 34 ===\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])\n\n=== MARKDOWN 35 ===\nWe can replace many titles with a more common name or classify them as `Rare`.\n\n=== CODE 36 ===\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n\n=== MARKDOWN 37 ===\nWe can convert the categorical titles to ordinal.\n\n=== CODE 38 ===\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()\n\n=== MARKDOWN 39 ===\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\n\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: === MARKDOWN 0 ===\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\n\n=== MARKDOWN 1 ===\n# Part 2: Your coding environment\n\nIn this section, you'll train your own machine learning model to improve your predictions.  _If you've never written code before or don't have any experience with machine learning, don't worry!  We don't assume any prior experience in this tutorial._\n\n## The Notebook\n\nThe first thing to do is to create a Kaggle Notebook where you'll store all of your code.  You c\n\n=== CODE 2 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data proc\n\n=== MARKDOWN 3 ===\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We'll do that next.\n\n## Load the data\n\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\n\n![](https://i.imgur.com/OQBax9n.png)\n\nType the two lines of code below into your second code cell.  Then, once you're done, either click on the blue pl\n\n=== CODE 4 ===\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()\n\n=== MARKDOWN 5 ===\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It's very important that you see this output **in your notebook** before proceeding with the tutorial!\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\n\n=== CODE 6 ===\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()\n\n=== MARKDOWN 7 ===\nAs before, make sure that you see the output above in your notebook before continuing.  \n\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\n\n# Part 3: Your first submission\n\n=== CODE 8 ===\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\n=== MARKDOWN 9 ===\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\n\nThen, run the code below in another code cell:\n\n=== CODE 10 ===\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)\n\n=== MARKDOWN 11 ===\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\n\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\n\nBut at the end of the day, this gender-based s\n\n=== CODE 12 ===\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.f\n\n=== MARKDOWN 13 ===\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\n> Again, don't worry if this code doesn't make sense to you!  For now, we'll focus on how to generate and submit predictions.\n\nOnce you're ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \n- Ensure tha\n\n=== MARKDOWN 14 ===\n# Part 4: Learn more!\n\nIf you're interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we've presented here.  You'll also know enough to generate even better predictions!\n\n\ntool: SEARCH RESULTS (9 found)\n==================================================\n\n--- Result 1 ---\nTitle: ANSWER\n\nContent:\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80‚ÄØ% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random‚ÄØForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n**Step‚Äëby‚Äëstep recipe**\n\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \n\n2. **Impute & create missing‚Äëvalue flags**  \n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1‚ÄØif Cabin not null, else‚ÄØ0).  \n   * Optionally encode the original *Cabin* letter as a categorical feature.  \n\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \n   * **FamilySize** = `SibSp + Parch + 1`  \n   * **IsAlone** = 1‚ÄØif *FamilySize*‚ÄØ=‚ÄØ1 else‚ÄØ0  \n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \n\n   These engineered columns lifted baseline scores from ~72‚ÄØ% to ~78‚ÄØ% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \n\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35‚ÄØ% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \n\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \n   * `n_estimators` (200‚Äë1000)  \n   * `max_depth` (5‚Äë15)  \n   * `min_samples_split` / `min_samples_leaf`  \n   * `max_features` (sqrt, log2, or a fraction)  \n\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100‚ÄØ% Accuracy‚Äù notebook placed the author in the top‚ÄØ3‚ÄØ%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \n\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•‚ÄØ0.84) before uploading.  \n\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\n\n--- Result 2 ---\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\n\nContent:\nSeptember 10, 2016¬†¬†¬†¬†¬†33min read\n\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\n\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\n\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I'm writing this post, I am ranked among the top 4% of all Kagglers.\n\nThis post is the opportunity to share my solution with you.\n\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I'll follow with feature engineering and finally present the predictive model I set up.\n\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\nThe main libraries involved in this tutorial are:\n\n- **Pandas** for data manipulation and ingestion\n- **Matplotlib** and **seaborn** for data visualization\n- **Numpy** for multidimensional array computing\n- **sklearn** for machine learning and predictive modeling\n\n### Installation procedure\n\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\n\n### Nota Bene\n\nThis is my first attempt as a blogger and as a machine learning practitioner.\n\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\n\nHope you've got everything set on your computer. Let's get started.\n\n## I - Exploratory data analysis\n\nAs in different data projects, we'll first start diving into the data and build up our first intuitions.\n\nIn this section, we'll be doing four things.\n\n- Data extraction : we'll load the dataset and have a first look at it.\n- Cleaning : we'll fill in missing values.\n- Plotting : we'll create some interesting charts that'll (hopefully) spot correlations and hidden insights out of the data.\n- Assumptions : we'll formulate hypotheses from the charts.\n\nWe tweak the style of this notebook a little bit to have centered plots.\n\n```\nfrom IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n</style>\n\"\"\");\n```\n\nWe import the useful libraries.\n\n```\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\nimport pandas as pd\npd.options.display.max_columns = 100\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimport seaborn as sns\n\nimport pylab as plot\nparams = {\n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n}\nplot.rcParams.update(params)\n```\n\nTwo datasets are available: a training set and a test set.\nWe'll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\n\nWe'll see how this procedure is done at the end of this post.\n\nNow let's start by loading the training set.\n\n```\ndata = pd.read_csv('./data/train.csv')\nprint(data.shape)\n#(891, 12)\n```\n\nWe have:\n\n- 891 rows\n- 12 columns\n\nPandas allows you to have a sneak peak at your data.\n\n```\ndata.head()\n```\n\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\n\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he's dead. The is the variable we're going to predict.\n\nThe other variables describe the passengers. They are the **features**.\n\n- PassengerId: and id given to each traveler on the boat\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\n- The Name of the passeger\n- The Sex\n- The Age\n- SibSp: number of siblings and spouses traveling with the passenger\n- Parch: number of parents and children traveling with the passenger\n- The ticket number\n- The ticket Fare\n- The cabin number\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\n\nPandas allows you to a have a high-level simple statistical description of the numerical features.\nThis can be done using the describe method.\n\n```\ndata.describe()\n```\n\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\n| --- | --- | --- | --- | --- | --- | --- |\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\n\nThe count variable shows that 177 values are missing in the Age column.\n\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\n\n```\ndata['Age'] = data['Age'].fillna(data['Age'].median())\n```\n\nLet's now make some charts.\n\nLet's visualize survival based on the gender.\n\n```\ndata['Died'] = 1 - data['Survived']\ndata.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                          stacked=True, colors=['g', 'r']);\n```\n\nIt looks like male passengers are more likely to succumb.\n\nLet's plot the same graph but with ratio instead.\n\n```\ndata.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                           stacked=True, colors=['g', 'r']);\n```\n\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\n\nLet's now correlate the survival with the age variable.\n\n```\nfig = plt.figure(figsize=(25, 7))\nsns.violinplot(x='Sex', y='Age',\n               hue='Survived', data=data,\n               split=True,\n               palette={0: \"r\", 1: \"g\"}\n              );\n```\n\nAs we saw in the chart above and validate by the following:\n\n- Women survive more than men, as depicted by the larger female green histogram\n\nNow, we see that:\n\n- The age conditions the survival for male passengers:\n\n  - Younger male tend to survive\n  - A large number of passengers between 20 and 40 succumb\n- The age doesn't seem to have a direct impact on the female survival\n\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\n\nRight?\n\nLet's now focus on the Fare ticket of each passenger and see how it could impact the survival.\n\n```\nfigure = plt.figure(figsize=(25, 7))\nplt.hist([dat...\n\n--- Result 3 ---\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\nURL: https://github.com/alicevillar/titanic-kaggle\n\nContent:\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n- [Fork\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n- [Star\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n[6\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n\n# alicevillar/titanic-kaggle\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmain\n\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\n| ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\n| ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n\nThe objective of Kaggle's Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\n\n### Quick Start:\n\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\n\n### Dependencies:\n\n- [Numpy](https://numpy.org/)\n- [Pandas](https://pandas.pydata.org/)\n- [SciKit-Learn](https://scikit-learn.org/)\n- [Matplotlib](https://matplotlib.org/)\n- [Seaborn](https://seaborn.pydata.org/)\n\n### Approach\n\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\n\n### Kaggle Competition \\| Titanic Machine Learning from Disaster\n\nKaggle's challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle's [Competition Page](https://www.kaggle.com/c/titanic):\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\n\n### Results\n\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\n\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\n\n## About\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n### Topics\n\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\n\n### Resources\n\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\n\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n### Stars\n\n[**6**\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\n\n### Watchers\n\n[**1**\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\n\n### Forks\n\n[**3**\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\n\n--- Result 4 ---\nTitle: Search code, repositories, users, issues, pull requests...\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\n\nContent:\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\nmain\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n|\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n|\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n|\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\~72% to \\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n# Titanic Survival Prediction\n[](#titanic-survival-prediction)\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\n* **Detailed EDA**\nA Jupyter notebook that walks through exploratory data analysis:\n* Summary statistics\n* Missing-value patterns\n* Feature distributions and pairwise relationships\n* Correlation heatmaps\n* **Feature Engineering**\nCreation of high-signal features from raw inputs, including:\n* `Has\\_Cabin`(binary cabin indicator)\n* `FareBin`(quantile-based fare categories)\n* Group-median imputation for`Age`, then 10-year age bins\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\n* `Title`extracted and consolidated from passenger names\n* **Model Comparison**\nTraining and evaluation of multiple classifiers on the engineered feature set:\n* Random Forest\n* Support Vector Machine\n* K-Nearest Neighbors (k=3,5,7)\n* XGBoost\n* LightGBM\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\n* **Analysis &amp; Interpretation**\nInline Markdown commentary explains:\n* Why each feature matters\n* How missing data were handled\n* The rationale for model selection\n* Key takeaways and next-step recommendations\n## Repository Structure\n[](#repository-structure)\ndata/\n* train.csv # Official Kaggle training set\n* test.csv # Official Kaggle test set\nnotebooks/\n* titanic\\_analysis.ipynb\n‚Ä¢EDA, feature engineering, model training\n‚Ä¢Detailed Markdown analysis\n* README.md # Project overview and instructions\n## Contributing\n[](#contributing)\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\n## About\nPredict Titanic survival using t...\n\n--- Result 5 ---\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\n\nContent:\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\nAman Krishna\n2022-04-20T07:23:42Z\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\n\n## The art of fine-tuning a model\n\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\n\n7 min read\n\n\nApr 19, 2022\n\n\nListen\n\nShare\n\nPress enter or click to view image in full size\n\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\n\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\n\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\n\nYou can find the complete code on Github **_:_**\n\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \n\n**Machine Learning model build for survivor prediction for Kaggle's titanic competition - kaggle_titanic/Model‚Ä¶**\n\ngithub.com]\n\n## Which Model to use?\n\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\n\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\n\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\n\n## Pre-Requisite\n\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\n\n### Dropping Features\n\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\n\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\n\n### Code\n\n### Dummify Data\n\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\n\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\n\n**We will be using One-Hot encoding on our categorical features.**\n\n### Code\n\n### Split Data\n\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\n\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\n\n## Training\n\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\n\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\n\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\n\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\n\n### Code\n\n## Fine Tuning\n\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\n\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\n\n### Code\n\n### Output\n\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\n\nPress enter or click to view image in full size\n\nGrid Search Results\n\n## Refining Search Space: Max Depth & Max Samples\n\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\n\n### How?\n\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\n\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\n\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest max_Depth & max_samples\n\n## Fine Tune: Min Sample Split & Min Sample Leaf\n\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest min_samples_leaf & min_samples_split\n\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\n\n## Fine Tune: Number of Estimators\n\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest n_estimator value\n\n## Refining Search Space: Number of estima...\n\n--- Result 6 ---\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\n\nContent:\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\n\n--- Result 7 ---\nTitle: Titanic - Machine Learning from Disaster\nURL: https://www.kaggle.com/c/titanic/code\n\nContent:\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \n\n[... truncated 11780 characters ...]",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb'}, {'role': 'tool', 'content': '‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb'}, {'role': 'assistant', 'content': 'REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.'}, {'role': 'tool', 'content': '=== MARKDOWN 23 ===\\n## Analyze by visualizing data\\n\\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n\\n### Correlating numerical features\\n\\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\\n\\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \\n\\n=== MARKDOWN 25 ===\\n### Correlating numerical and ordinal features\\n\\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n\\n**Observations.**\\n\\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n- Pclass varies in terms of Age distribution of passengers.\\n\\n**Decisions\\n\\n=== MARKDOWN 27 ===\\n### Correlating categorical features\\n\\nNow we can correlate categorical features with our solution goal.\\n\\n**Observations.**\\n\\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n- Ports of embarkation have varying survival rates for Pcla\\n\\n=== MARKDOWN 29 ===\\n### Correlating categorical and numerical features\\n\\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n\\n**Observations.**\\n\\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n\\n**Decisions.**\\n\\n- Consider banding Fare feature.\\n\\n=== MARKDOWN 31 ===\\n## Wrangle data\\n\\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n\\n### Correcting by dropping features\\n\\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n\\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n\\n\\n=== MARKDOWN 33 ===\\n### Creating new feature extracting from existing\\n\\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n\\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n\\n**Observations.**\\n\\nWhen we plot Title, Age, and Survived, we note the following observations.\\n\\n- Most titles band Age groups accurately. For example: Master\\n\\n=== CODE 34 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset.Name.str.extract(\\' ([A-Za-z]+)\\\\.\\', expand=False)\\n\\npd.crosstab(train_df[\\'Title\\'], train_df[\\'Sex\\'])\\n\\n=== MARKDOWN 35 ===\\nWe can replace many titles with a more common name or classify them as `Rare`.\\n\\n=== CODE 36 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace([\\'Lady\\', \\'Countess\\',\\'Capt\\', \\'Col\\',\\\\\\n \\t\\'Don\\', \\'Dr\\', \\'Major\\', \\'Rev\\', \\'Sir\\', \\'Jonkheer\\', \\'Dona\\'], \\'Rare\\')\\n\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mlle\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Ms\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mme\\', \\'Mrs\\')\\n    \\ntrain_df[[\\'Title\\', \\'Survived\\']].groupby([\\'Title\\'], as_index=False).mean()\\n\\n=== MARKDOWN 37 ===\\nWe can convert the categorical titles to ordinal.\\n\\n=== CODE 38 ===\\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].map(title_mapping)\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].fillna(0)\\n\\ntrain_df.head()\\n\\n=== MARKDOWN 39 ===\\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now I have comprehensive information. Let me write the seed prompt with all the techniques I've learned.\"}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': 'REASONING: Now let me check if there are any additional techniques in the Alexis Cook tutorial that might be helpful, and also search for any advanced techniques that could help beat the 1.0 target score (which is 100% accuracy - extremely challenging).'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\\n\\n=== MARKDOWN 1 ===\\n# Part 2: Your coding environment\\n\\nIn this section, you\\'ll train your own machine learning model to improve your predictions.  _If you\\'ve never written code before or don\\'t have any experience with machine learning, don\\'t worry!  We don\\'t assume any prior experience in this tutorial._\\n\\n## The Notebook\\n\\nThe first thing to do is to create a Kaggle Notebook where you\\'ll store all of your code.  You c\\n\\n=== CODE 2 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load in \\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data proc\\n\\n=== MARKDOWN 3 ===\\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We\\'ll do that next.\\n\\n## Load the data\\n\\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\\n\\n![](https://i.imgur.com/OQBax9n.png)\\n\\nType the two lines of code below into your second code cell.  Then, once you\\'re done, either click on the blue pl\\n\\n=== CODE 4 ===\\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntrain_data.head()\\n\\n=== MARKDOWN 5 ===\\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It\\'s very important that you see this output **in your notebook** before proceeding with the tutorial!\\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\\n\\n=== CODE 6 ===\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\\ntest_data.head()\\n\\n=== MARKDOWN 7 ===\\nAs before, make sure that you see the output above in your notebook before continuing.  \\n\\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\\n\\n# Part 3: Your first submission\\n\\n=== CODE 8 ===\\nwomen = train_data.loc[train_data.Sex == \\'female\\'][\"Survived\"]\\nrate_women = sum(women)/len(women)\\n\\nprint(\"% of women who survived:\", rate_women)\\n\\n=== MARKDOWN 9 ===\\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\\n\\nThen, run the code below in another code cell:\\n\\n=== CODE 10 ===\\nmen = train_data.loc[train_data.Sex == \\'male\\'][\"Survived\"]\\nrate_men = sum(men)/len(men)\\n\\nprint(\"% of men who survived:\", rate_men)\\n\\n=== MARKDOWN 11 ===\\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\\n\\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\\n\\nBut at the end of the day, this gender-based s\\n\\n=== CODE 12 ===\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\\nX = pd.get_dummies(train_data[features])\\nX_test = pd.get_dummies(test_data[features])\\n\\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\\nmodel.f\\n\\n=== MARKDOWN 13 ===\\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\\n> Again, don\\'t worry if this code doesn\\'t make sense to you!  For now, we\\'ll focus on how to generate and submit predictions.\\n\\nOnce you\\'re ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \\n- Ensure tha\\n\\n=== MARKDOWN 14 ===\\n# Part 4: Learn more!\\n\\nIf you\\'re interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we\\'ve presented here.  You\\'ll also know enough to generate even better predictions!\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: The tutorial is basic. Let me search for advanced techniques that could help achieve very high accuracy on this problem, particularly since the target is 100% accuracy which is extremely challenging.'}, {'role': 'tool', 'content': 'SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80\\u202f% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random\\u202fForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n**Step‚Äëby‚Äëstep recipe**\\n\\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \\n\\n2. **Impute & create missing‚Äëvalue flags**  \\n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \\n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1\\u202fif Cabin not null, else\\u202f0).  \\n   * Optionally encode the original *Cabin* letter as a categorical feature.  \\n\\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \\n   * **FamilySize** = `SibSp + Parch + 1`  \\n   * **IsAlone** = 1\\u202fif *FamilySize*\\u202f=\\u202f1 else\\u202f0  \\n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \\n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \\n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \\n\\n   These engineered columns lifted baseline scores from ~72\\u202f% to ~78\\u202f% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \\n\\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35\\u202f% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \\n\\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \\n   * `n_estimators` (200‚Äë1000)  \\n   * `max_depth` (5‚Äë15)  \\n   * `min_samples_split` / `min_samples_leaf`  \\n   * `max_features` (sqrt, log2, or a fraction)  \\n\\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100\\u202f% Accuracy‚Äù notebook placed the author in the top\\u202f3\\u202f%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \\n\\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•\\u202f0.84) before uploading.  \\n\\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\\n\\n--- Result 2 ---\\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\\n\\nContent:\\nSeptember 10, 2016\\xa0\\xa0\\xa0\\xa0\\xa033min read\\n\\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\\n\\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\\n\\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I\\'m writing this post, I am ranked among the top 4% of all Kagglers.\\n\\nThis post is the opportunity to share my solution with you.\\n\\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I\\'ll follow with feature engineering and finally present the predictive model I set up.\\n\\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\\nThe main libraries involved in this tutorial are:\\n\\n- **Pandas** for data manipulation and ingestion\\n- **Matplotlib** and **seaborn** for data visualization\\n- **Numpy** for multidimensional array computing\\n- **sklearn** for machine learning and predictive modeling\\n\\n### Installation procedure\\n\\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\\n\\n### Nota Bene\\n\\nThis is my first attempt as a blogger and as a machine learning practitioner.\\n\\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\\n\\nHope you\\'ve got everything set on your computer. Let\\'s get started.\\n\\n## I - Exploratory data analysis\\n\\nAs in different data projects, we\\'ll first start diving into the data and build up our first intuitions.\\n\\nIn this section, we\\'ll be doing four things.\\n\\n- Data extraction : we\\'ll load the dataset and have a first look at it.\\n- Cleaning : we\\'ll fill in missing values.\\n- Plotting : we\\'ll create some interesting charts that\\'ll (hopefully) spot correlations and hidden insights out of the data.\\n- Assumptions : we\\'ll formulate hypotheses from the charts.\\n\\nWe tweak the style of this notebook a little bit to have centered plots.\\n\\n```\\nfrom IPython.core.display import HTML\\nHTML(\"\"\"\\n<style>\\n.output_png {\\n    display: table-cell;\\n    text-align: center;\\n    vertical-align: middle;\\n}\\n</style>\\n\"\"\");\\n```\\n\\nWe import the useful libraries.\\n\\n```\\n%matplotlib inline\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\nwarnings.filterwarnings(\\'ignore\\', category=DeprecationWarning)\\n\\nimport pandas as pd\\npd.options.display.max_columns = 100\\n\\nfrom matplotlib import pyplot as plt\\nimport numpy as np\\n\\nimport seaborn as sns\\n\\nimport pylab as plot\\nparams = {\\n    \\'axes.labelsize\\': \"large\",\\n    \\'xtick.labelsize\\': \\'x-large\\',\\n    \\'legend.fontsize\\': 20,\\n    \\'figure.dpi\\': 150,\\n    \\'figure.figsize\\': [25, 7]\\n}\\nplot.rcParams.update(params)\\n```\\n\\nTwo datasets are available: a training set and a test set.\\nWe\\'ll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\\n\\nWe\\'ll see how this procedure is done at the end of this post.\\n\\nNow let\\'s start by loading the training set.\\n\\n```\\ndata = pd.read_csv(\\'./data/train.csv\\')\\nprint(data.shape)\\n#(891, 12)\\n```\\n\\nWe have:\\n\\n- 891 rows\\n- 12 columns\\n\\nPandas allows you to have a sneak peak at your data.\\n\\n```\\ndata.head()\\n```\\n\\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\\n\\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he\\'s dead. The is the variable we\\'re going to predict.\\n\\nThe other variables describe the passengers. They are the **features**.\\n\\n- PassengerId: and id given to each traveler on the boat\\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\\n- The Name of the passeger\\n- The Sex\\n- The Age\\n- SibSp: number of siblings and spouses traveling with the passenger\\n- Parch: number of parents and children traveling with the passenger\\n- The ticket number\\n- The ticket Fare\\n- The cabin number\\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\\n\\nPandas allows you to a have a high-level simple statistical description of the numerical features.\\nThis can be done using the describe method.\\n\\n```\\ndata.describe()\\n```\\n\\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\\n\\nThe count variable shows that 177 values are missing in the Age column.\\n\\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\\n\\n```\\ndata[\\'Age\\'] = data[\\'Age\\'].fillna(data[\\'Age\\'].median())\\n```\\n\\nLet\\'s now make some charts.\\n\\nLet\\'s visualize survival based on the gender.\\n\\n```\\ndata[\\'Died\\'] = 1 - data[\\'Survived\\']\\ndata.groupby(\\'Sex\\').agg(\\'sum\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                          stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nIt looks like male passengers are more likely to succumb.\\n\\nLet\\'s plot the same graph but with ratio instead.\\n\\n```\\ndata.groupby(\\'Sex\\').agg(\\'mean\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                           stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\\n\\nLet\\'s now correlate the survival with the age variable.\\n\\n```\\nfig = plt.figure(figsize=(25, 7))\\nsns.violinplot(x=\\'Sex\\', y=\\'Age\\',\\n               hue=\\'Survived\\', data=data,\\n               split=True,\\n               palette={0: \"r\", 1: \"g\"}\\n              );\\n```\\n\\nAs we saw in the chart above and validate by the following:\\n\\n- Women survive more than men, as depicted by the larger female green histogram\\n\\nNow, we see that:\\n\\n- The age conditions the survival for male passengers:\\n\\n  - Younger male tend to survive\\n  - A large number of passengers between 20 and 40 succumb\\n- The age doesn\\'t seem to have a direct impact on the female survival\\n\\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\\n\\nRight?\\n\\nLet\\'s now focus on the Fare ticket of each passenger and see how it could impact the survival.\\n\\n```\\nfigure = plt.figure(figsize=(25, 7))\\nplt.hist([dat...\\n\\n--- Result 3 ---\\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\nURL: https://github.com/alicevillar/titanic-kaggle\\n\\nContent:\\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\\n\\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\\n\\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n- [Fork\\\\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n- [Star\\\\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n[6\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n\\n# alicevillar/titanic-kaggle\\n\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n\\nmain\\n\\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\\n\\nGo to file\\n\\nCode\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\\n| ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\\n| ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\\n| View all files |\\n\\n## Repository files navigation\\n\\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n\\nThe objective of Kaggle\\'s Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\\n\\n### Quick Start:\\n\\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\\n\\n### Dependencies:\\n\\n- [Numpy](https://numpy.org/)\\n- [Pandas](https://pandas.pydata.org/)\\n- [SciKit-Learn](https://scikit-learn.org/)\\n- [Matplotlib](https://matplotlib.org/)\\n- [Seaborn](https://seaborn.pydata.org/)\\n\\n### Approach\\n\\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\\n\\n### Kaggle Competition \\\\| Titanic Machine Learning from Disaster\\n\\nKaggle\\'s challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle\\'s [Competition Page](https://www.kaggle.com/c/titanic):\\n\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\\n\\n### Results\\n\\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\\n\\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\\n\\n## About\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n### Topics\\n\\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\\n\\n### Resources\\n\\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\\n\\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n### Stars\\n\\n[**6**\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\\n\\n### Watchers\\n\\n[**1**\\\\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\\n\\n### Forks\\n\\n[**3**\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\\n\\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\\n\\n--- Result 4 ---\\nTitle: Search code, repositories, users, issues, pull requests...\\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\n\\nContent:\\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[Skip to content](#start-of-content)\\n## Navigation Menu\\nToggle navigation\\n[](https://github.com/)\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nSearch or jump to...\\n# Search code, repositories, users, issues, pull requests...\\n</option></form>\\nSearch\\nClear\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n# Provide feedback\\n</option></form>\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancelSubmit feedback\\n# Saved searches\\n## Use saved searches to filter your results more quickly\\n</option></form>\\nName\\nQuery\\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\nCancelCreate saved search\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nResetting focus\\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\\n{{ message }}\\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\nmain\\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\nGo to file\\nCode\\nOpen more actions menu\\n## Folders and files\\n|Name|Name|\\nLast commit message\\n|\\nLast commit date\\n|\\n## Latest commit\\n## History\\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n|\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n|\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n|\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n|\\n|\\nView all files\\n|\\n## Repository files navigation\\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\~72% to \\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n# Titanic Survival Prediction\\n[](#titanic-survival-prediction)\\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\\n* **Detailed EDA**\\nA Jupyter notebook that walks through exploratory data analysis:\\n* Summary statistics\\n* Missing-value patterns\\n* Feature distributions and pairwise relationships\\n* Correlation heatmaps\\n* **Feature Engineering**\\nCreation of high-signal features from raw inputs, including:\\n* `Has\\\\_Cabin`(binary cabin indicator)\\n* `FareBin`(quantile-based fare categories)\\n* Group-median imputation for`Age`, then 10-year age bins\\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\\n* `Title`extracted and consolidated from passenger names\\n* **Model Comparison**\\nTraining and evaluation of multiple classifiers on the engineered feature set:\\n* Random Forest\\n* Support Vector Machine\\n* K-Nearest Neighbors (k=3,5,7)\\n* XGBoost\\n* LightGBM\\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\\n* **Analysis &amp; Interpretation**\\nInline Markdown commentary explains:\\n* Why each feature matters\\n* How missing data were handled\\n* The rationale for model selection\\n* Key takeaways and next-step recommendations\\n## Repository Structure\\n[](#repository-structure)\\ndata/\\n* train.csv # Official Kaggle training set\\n* test.csv # Official Kaggle test set\\nnotebooks/\\n* titanic\\\\_analysis.ipynb\\n‚Ä¢EDA, feature engineering, model training\\n‚Ä¢Detailed Markdown analysis\\n* README.md # Project overview and instructions\\n## Contributing\\n[](#contributing)\\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\\n## About\\nPredict Titanic survival using t...\\n\\n--- Result 5 ---\\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\n\\nContent:\\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\\nAman Krishna\\n2022-04-20T07:23:42Z\\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\n\\n## The art of fine-tuning a model\\n\\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\\n\\n7 min read\\n\\n\\nApr 19, 2022\\n\\n\\nListen\\n\\nShare\\n\\nPress enter or click to view image in full size\\n\\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\\n\\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\\n\\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\\n\\nYou can find the complete code on Github **_:_**\\n\\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \\n\\n**Machine Learning model build for survivor prediction for Kaggle\\'s titanic competition - kaggle_titanic/Model‚Ä¶**\\n\\ngithub.com]\\n\\n## Which Model to use?\\n\\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\\n\\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\\n\\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\\n\\n## Pre-Requisite\\n\\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\\n\\n### Dropping Features\\n\\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\\n\\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\\n\\n### Code\\n\\n### Dummify Data\\n\\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\\n\\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\\n\\n**We will be using One-Hot encoding on our categorical features.**\\n\\n### Code\\n\\n### Split Data\\n\\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\\n\\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\\n\\n## Training\\n\\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\\n\\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\\n\\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\\n\\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\\n\\n### Code\\n\\n## Fine Tuning\\n\\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\\n\\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\\n\\n### Code\\n\\n### Output\\n\\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\\n\\nPress enter or click to view image in full size\\n\\nGrid Search Results\\n\\n## Refining Search Space: Max Depth & Max Samples\\n\\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\\n\\n### How?\\n\\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\\n\\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\\n\\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest max_Depth & max_samples\\n\\n## Fine Tune: Min Sample Split & Min Sample Leaf\\n\\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest min_samples_leaf & min_samples_split\\n\\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\\n\\n## Fine Tune: Number of Estimators\\n\\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest n_estimator value\\n\\n## Refining Search Space: Number of estima...\\n\\n--- Result 6 ---\\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\\n\\nContent:\\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\\n\\n--- Result 7 ---\\nTitle: Titanic - Machine Learning from Disaster\\nURL: https://www.kaggle.com/c/titanic/code\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \\n\\n[... truncated 11780 characters ...]'}]",
        "llm.input_tokens": 44368,
        "llm.output_tokens": 188,
        "llm.total_tokens": 44556,
        "llm.latency_ms": 7374.311685562134,
        "llm.completion": "REASONING: This is very helpful! The search confirms that achieving 100% accuracy is essentially impossible without cheating (using external data). The realistic best scores are in the 80-86% range. Let me update the seed prompt with this important context and add more specific techniques.\n[Tool Use: RecordFinding]",
        "llm.reasoning": "REASONING: This is very helpful! The search confirms that achieving 100% accuracy is essentially impossible without cheating (using external data). The realistic best scores are in the 80-86% range. Let me update the seed prompt with this important context and add more specific techniques.",
        "llm.cost_usd": 0.135924
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "90299c8b205e807c",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "RecordFindingTool",
      "kind": "INTERNAL",
      "start_time": 1767683622369700560,
      "end_time": 1767683622370860964,
      "duration": 0.001160404,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "RecordFindingTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.findings.RecordFindingTool object at 0x73eac380cf50>\", \"input\": {\"finding\": \"Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use external data (cheating). Best legitimate approaches: thorough feature engineering + tuned Random Forest or ensemble.\", \"source\": \"Web search - Kaggle Titanic best techniques\"}}",
        "tool.output": "{\"content\": \"‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\\n  Source: Web search - Kaggle Titanic best techniques\", \"is_error\": false}",
        "tool.duration_ms": 1.188516616821289
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "d4cfab8673b0335d",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683623539929785,
      "end_time": 1767683626160316270,
      "duration": 2.620386485,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n\ntool: ‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\n  Source: exploration/eda.ipynb\ntool: ‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\n  Source: exploration/eda.ipynb\ntool: === MARKDOWN 23 ===\n## Analyze by visualizing data\n\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\n\n### Correlating numerical features\n\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\n\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \n\n=== MARKDOWN 25 ===\n### Correlating numerical and ordinal features\n\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n\n**Observations.**\n\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n- Pclass varies in terms of Age distribution of passengers.\n\n**Decisions\n\n=== MARKDOWN 27 ===\n### Correlating categorical features\n\nNow we can correlate categorical features with our solution goal.\n\n**Observations.**\n\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\n- Ports of embarkation have varying survival rates for Pcla\n\n=== MARKDOWN 29 ===\n### Correlating categorical and numerical features\n\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n\n**Observations.**\n\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n\n**Decisions.**\n\n- Consider banding Fare feature.\n\n=== MARKDOWN 31 ===\n## Wrangle data\n\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n\n### Correcting by dropping features\n\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\n\n\n=== MARKDOWN 33 ===\n### Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n\n**Observations.**\n\nWhen we plot Title, Age, and Survived, we note the following observations.\n\n- Most titles band Age groups accurately. For example: Master\n\n=== CODE 34 ===\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])\n\n=== MARKDOWN 35 ===\nWe can replace many titles with a more common name or classify them as `Rare`.\n\n=== CODE 36 ===\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n\n=== MARKDOWN 37 ===\nWe can convert the categorical titles to ordinal.\n\n=== CODE 38 ===\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()\n\n=== MARKDOWN 39 ===\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\n\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: === MARKDOWN 0 ===\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\n\n=== MARKDOWN 1 ===\n# Part 2: Your coding environment\n\nIn this section, you'll train your own machine learning model to improve your predictions.  _If you've never written code before or don't have any experience with machine learning, don't worry!  We don't assume any prior experience in this tutorial._\n\n## The Notebook\n\nThe first thing to do is to create a Kaggle Notebook where you'll store all of your code.  You c\n\n=== CODE 2 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data proc\n\n=== MARKDOWN 3 ===\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We'll do that next.\n\n## Load the data\n\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\n\n![](https://i.imgur.com/OQBax9n.png)\n\nType the two lines of code below into your second code cell.  Then, once you're done, either click on the blue pl\n\n=== CODE 4 ===\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()\n\n=== MARKDOWN 5 ===\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It's very important that you see this output **in your notebook** before proceeding with the tutorial!\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\n\n=== CODE 6 ===\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()\n\n=== MARKDOWN 7 ===\nAs before, make sure that you see the output above in your notebook before continuing.  \n\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\n\n# Part 3: Your first submission\n\n=== CODE 8 ===\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\n=== MARKDOWN 9 ===\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\n\nThen, run the code below in another code cell:\n\n=== CODE 10 ===\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)\n\n=== MARKDOWN 11 ===\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\n\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\n\nBut at the end of the day, this gender-based s\n\n=== CODE 12 ===\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.f\n\n=== MARKDOWN 13 ===\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\n> Again, don't worry if this code doesn't make sense to you!  For now, we'll focus on how to generate and submit predictions.\n\nOnce you're ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \n- Ensure tha\n\n=== MARKDOWN 14 ===\n# Part 4: Learn more!\n\nIf you're interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we've presented here.  You'll also know enough to generate even better predictions!\n\n\ntool: SEARCH RESULTS (9 found)\n==================================================\n\n--- Result 1 ---\nTitle: ANSWER\n\nContent:\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80‚ÄØ% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random‚ÄØForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n**Step‚Äëby‚Äëstep recipe**\n\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \n\n2. **Impute & create missing‚Äëvalue flags**  \n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1‚ÄØif Cabin not null, else‚ÄØ0).  \n   * Optionally encode the original *Cabin* letter as a categorical feature.  \n\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \n   * **FamilySize** = `SibSp + Parch + 1`  \n   * **IsAlone** = 1‚ÄØif *FamilySize*‚ÄØ=‚ÄØ1 else‚ÄØ0  \n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \n\n   These engineered columns lifted baseline scores from ~72‚ÄØ% to ~78‚ÄØ% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \n\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35‚ÄØ% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \n\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \n   * `n_estimators` (200‚Äë1000)  \n   * `max_depth` (5‚Äë15)  \n   * `min_samples_split` / `min_samples_leaf`  \n   * `max_features` (sqrt, log2, or a fraction)  \n\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100‚ÄØ% Accuracy‚Äù notebook placed the author in the top‚ÄØ3‚ÄØ%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \n\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•‚ÄØ0.84) before uploading.  \n\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\n\n--- Result 2 ---\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\n\nContent:\nSeptember 10, 2016¬†¬†¬†¬†¬†33min read\n\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\n\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\n\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I'm writing this post, I am ranked among the top 4% of all Kagglers.\n\nThis post is the opportunity to share my solution with you.\n\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I'll follow with feature engineering and finally present the predictive model I set up.\n\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\nThe main libraries involved in this tutorial are:\n\n- **Pandas** for data manipulation and ingestion\n- **Matplotlib** and **seaborn** for data visualization\n- **Numpy** for multidimensional array computing\n- **sklearn** for machine learning and predictive modeling\n\n### Installation procedure\n\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\n\n### Nota Bene\n\nThis is my first attempt as a blogger and as a machine learning practitioner.\n\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\n\nHope you've got everything set on your computer. Let's get started.\n\n## I - Exploratory data analysis\n\nAs in different data projects, we'll first start diving into the data and build up our first intuitions.\n\nIn this section, we'll be doing four things.\n\n- Data extraction : we'll load the dataset and have a first look at it.\n- Cleaning : we'll fill in missing values.\n- Plotting : we'll create some interesting charts that'll (hopefully) spot correlations and hidden insights out of the data.\n- Assumptions : we'll formulate hypotheses from the charts.\n\nWe tweak the style of this notebook a little bit to have centered plots.\n\n```\nfrom IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n</style>\n\"\"\");\n```\n\nWe import the useful libraries.\n\n```\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\nimport pandas as pd\npd.options.display.max_columns = 100\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimport seaborn as sns\n\nimport pylab as plot\nparams = {\n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n}\nplot.rcParams.update(params)\n```\n\nTwo datasets are available: a training set and a test set.\nWe'll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\n\nWe'll see how this procedure is done at the end of this post.\n\nNow let's start by loading the training set.\n\n```\ndata = pd.read_csv('./data/train.csv')\nprint(data.shape)\n#(891, 12)\n```\n\nWe have:\n\n- 891 rows\n- 12 columns\n\nPandas allows you to have a sneak peak at your data.\n\n```\ndata.head()\n```\n\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\n\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he's dead. The is the variable we're going to predict.\n\nThe other variables describe the passengers. They are the **features**.\n\n- PassengerId: and id given to each traveler on the boat\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\n- The Name of the passeger\n- The Sex\n- The Age\n- SibSp: number of siblings and spouses traveling with the passenger\n- Parch: number of parents and children traveling with the passenger\n- The ticket number\n- The ticket Fare\n- The cabin number\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\n\nPandas allows you to a have a high-level simple statistical description of the numerical features.\nThis can be done using the describe method.\n\n```\ndata.describe()\n```\n\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\n| --- | --- | --- | --- | --- | --- | --- |\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\n\nThe count variable shows that 177 values are missing in the Age column.\n\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\n\n```\ndata['Age'] = data['Age'].fillna(data['Age'].median())\n```\n\nLet's now make some charts.\n\nLet's visualize survival based on the gender.\n\n```\ndata['Died'] = 1 - data['Survived']\ndata.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                          stacked=True, colors=['g', 'r']);\n```\n\nIt looks like male passengers are more likely to succumb.\n\nLet's plot the same graph but with ratio instead.\n\n```\ndata.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                           stacked=True, colors=['g', 'r']);\n```\n\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\n\nLet's now correlate the survival with the age variable.\n\n```\nfig = plt.figure(figsize=(25, 7))\nsns.violinplot(x='Sex', y='Age',\n               hue='Survived', data=data,\n               split=True,\n               palette={0: \"r\", 1: \"g\"}\n              );\n```\n\nAs we saw in the chart above and validate by the following:\n\n- Women survive more than men, as depicted by the larger female green histogram\n\nNow, we see that:\n\n- The age conditions the survival for male passengers:\n\n  - Younger male tend to survive\n  - A large number of passengers between 20 and 40 succumb\n- The age doesn't seem to have a direct impact on the female survival\n\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\n\nRight?\n\nLet's now focus on the Fare ticket of each passenger and see how it could impact the survival.\n\n```\nfigure = plt.figure(figsize=(25, 7))\nplt.hist([dat...\n\n--- Result 3 ---\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\nURL: https://github.com/alicevillar/titanic-kaggle\n\nContent:\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n- [Fork\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n- [Star\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n[6\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n\n# alicevillar/titanic-kaggle\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmain\n\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\n| ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\n| ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n\nThe objective of Kaggle's Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\n\n### Quick Start:\n\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\n\n### Dependencies:\n\n- [Numpy](https://numpy.org/)\n- [Pandas](https://pandas.pydata.org/)\n- [SciKit-Learn](https://scikit-learn.org/)\n- [Matplotlib](https://matplotlib.org/)\n- [Seaborn](https://seaborn.pydata.org/)\n\n### Approach\n\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\n\n### Kaggle Competition \\| Titanic Machine Learning from Disaster\n\nKaggle's challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle's [Competition Page](https://www.kaggle.com/c/titanic):\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\n\n### Results\n\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\n\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\n\n## About\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n### Topics\n\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\n\n### Resources\n\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\n\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n### Stars\n\n[**6**\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\n\n### Watchers\n\n[**1**\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\n\n### Forks\n\n[**3**\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\n\n--- Result 4 ---\nTitle: Search code, repositories, users, issues, pull requests...\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\n\nContent:\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\nmain\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n|\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n|\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n|\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\~72% to \\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n# Titanic Survival Prediction\n[](#titanic-survival-prediction)\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\n* **Detailed EDA**\nA Jupyter notebook that walks through exploratory data analysis:\n* Summary statistics\n* Missing-value patterns\n* Feature distributions and pairwise relationships\n* Correlation heatmaps\n* **Feature Engineering**\nCreation of high-signal features from raw inputs, including:\n* `Has\\_Cabin`(binary cabin indicator)\n* `FareBin`(quantile-based fare categories)\n* Group-median imputation for`Age`, then 10-year age bins\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\n* `Title`extracted and consolidated from passenger names\n* **Model Comparison**\nTraining and evaluation of multiple classifiers on the engineered feature set:\n* Random Forest\n* Support Vector Machine\n* K-Nearest Neighbors (k=3,5,7)\n* XGBoost\n* LightGBM\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\n* **Analysis &amp; Interpretation**\nInline Markdown commentary explains:\n* Why each feature matters\n* How missing data were handled\n* The rationale for model selection\n* Key takeaways and next-step recommendations\n## Repository Structure\n[](#repository-structure)\ndata/\n* train.csv # Official Kaggle training set\n* test.csv # Official Kaggle test set\nnotebooks/\n* titanic\\_analysis.ipynb\n‚Ä¢EDA, feature engineering, model training\n‚Ä¢Detailed Markdown analysis\n* README.md # Project overview and instructions\n## Contributing\n[](#contributing)\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\n## About\nPredict Titanic survival using t...\n\n--- Result 5 ---\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\n\nContent:\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\nAman Krishna\n2022-04-20T07:23:42Z\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\n\n## The art of fine-tuning a model\n\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\n\n7 min read\n\n\nApr 19, 2022\n\n\nListen\n\nShare\n\nPress enter or click to view image in full size\n\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\n\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\n\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\n\nYou can find the complete code on Github **_:_**\n\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \n\n**Machine Learning model build for survivor prediction for Kaggle's titanic competition - kaggle_titanic/Model‚Ä¶**\n\ngithub.com]\n\n## Which Model to use?\n\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\n\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\n\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\n\n## Pre-Requisite\n\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\n\n### Dropping Features\n\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\n\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\n\n### Code\n\n### Dummify Data\n\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\n\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\n\n**We will be using One-Hot encoding on our categorical features.**\n\n### Code\n\n### Split Data\n\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\n\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\n\n## Training\n\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\n\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\n\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\n\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\n\n### Code\n\n## Fine Tuning\n\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\n\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\n\n### Code\n\n### Output\n\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\n\nPress enter or click to view image in full size\n\nGrid Search Results\n\n## Refining Search Space: Max Depth & Max Samples\n\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\n\n### How?\n\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\n\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\n\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest max_Depth & max_samples\n\n## Fine Tune: Min Sample Split & Min Sample Leaf\n\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest min_samples_leaf & min_samples_split\n\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\n\n## Fine Tune: Number of Estimators\n\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest n_estimator value\n\n## Refining Search Space: Number of estima...\n\n--- Result 6 ---\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\n\nContent:\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\n\n--- Result 7 ---\nTitle: Titanic - Machine Learning from Disaster\nURL: https://www.kaggle.com/c/titanic/code\n\nContent:\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \n\n[... truncated 11780 characters ...]\ntool: ‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\n  Source: Web search - Kaggle Titanic best techniques",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb'}, {'role': 'tool', 'content': '‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb'}, {'role': 'assistant', 'content': 'REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.'}, {'role': 'tool', 'content': '=== MARKDOWN 23 ===\\n## Analyze by visualizing data\\n\\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n\\n### Correlating numerical features\\n\\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\\n\\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \\n\\n=== MARKDOWN 25 ===\\n### Correlating numerical and ordinal features\\n\\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n\\n**Observations.**\\n\\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n- Pclass varies in terms of Age distribution of passengers.\\n\\n**Decisions\\n\\n=== MARKDOWN 27 ===\\n### Correlating categorical features\\n\\nNow we can correlate categorical features with our solution goal.\\n\\n**Observations.**\\n\\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n- Ports of embarkation have varying survival rates for Pcla\\n\\n=== MARKDOWN 29 ===\\n### Correlating categorical and numerical features\\n\\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n\\n**Observations.**\\n\\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n\\n**Decisions.**\\n\\n- Consider banding Fare feature.\\n\\n=== MARKDOWN 31 ===\\n## Wrangle data\\n\\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n\\n### Correcting by dropping features\\n\\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n\\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n\\n\\n=== MARKDOWN 33 ===\\n### Creating new feature extracting from existing\\n\\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n\\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n\\n**Observations.**\\n\\nWhen we plot Title, Age, and Survived, we note the following observations.\\n\\n- Most titles band Age groups accurately. For example: Master\\n\\n=== CODE 34 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset.Name.str.extract(\\' ([A-Za-z]+)\\\\.\\', expand=False)\\n\\npd.crosstab(train_df[\\'Title\\'], train_df[\\'Sex\\'])\\n\\n=== MARKDOWN 35 ===\\nWe can replace many titles with a more common name or classify them as `Rare`.\\n\\n=== CODE 36 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace([\\'Lady\\', \\'Countess\\',\\'Capt\\', \\'Col\\',\\\\\\n \\t\\'Don\\', \\'Dr\\', \\'Major\\', \\'Rev\\', \\'Sir\\', \\'Jonkheer\\', \\'Dona\\'], \\'Rare\\')\\n\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mlle\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Ms\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mme\\', \\'Mrs\\')\\n    \\ntrain_df[[\\'Title\\', \\'Survived\\']].groupby([\\'Title\\'], as_index=False).mean()\\n\\n=== MARKDOWN 37 ===\\nWe can convert the categorical titles to ordinal.\\n\\n=== CODE 38 ===\\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].map(title_mapping)\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].fillna(0)\\n\\ntrain_df.head()\\n\\n=== MARKDOWN 39 ===\\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now I have comprehensive information. Let me write the seed prompt with all the techniques I've learned.\"}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': 'REASONING: Now let me check if there are any additional techniques in the Alexis Cook tutorial that might be helpful, and also search for any advanced techniques that could help beat the 1.0 target score (which is 100% accuracy - extremely challenging).'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\\n\\n=== MARKDOWN 1 ===\\n# Part 2: Your coding environment\\n\\nIn this section, you\\'ll train your own machine learning model to improve your predictions.  _If you\\'ve never written code before or don\\'t have any experience with machine learning, don\\'t worry!  We don\\'t assume any prior experience in this tutorial._\\n\\n## The Notebook\\n\\nThe first thing to do is to create a Kaggle Notebook where you\\'ll store all of your code.  You c\\n\\n=== CODE 2 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load in \\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data proc\\n\\n=== MARKDOWN 3 ===\\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We\\'ll do that next.\\n\\n## Load the data\\n\\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\\n\\n![](https://i.imgur.com/OQBax9n.png)\\n\\nType the two lines of code below into your second code cell.  Then, once you\\'re done, either click on the blue pl\\n\\n=== CODE 4 ===\\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntrain_data.head()\\n\\n=== MARKDOWN 5 ===\\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It\\'s very important that you see this output **in your notebook** before proceeding with the tutorial!\\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\\n\\n=== CODE 6 ===\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\\ntest_data.head()\\n\\n=== MARKDOWN 7 ===\\nAs before, make sure that you see the output above in your notebook before continuing.  \\n\\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\\n\\n# Part 3: Your first submission\\n\\n=== CODE 8 ===\\nwomen = train_data.loc[train_data.Sex == \\'female\\'][\"Survived\"]\\nrate_women = sum(women)/len(women)\\n\\nprint(\"% of women who survived:\", rate_women)\\n\\n=== MARKDOWN 9 ===\\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\\n\\nThen, run the code below in another code cell:\\n\\n=== CODE 10 ===\\nmen = train_data.loc[train_data.Sex == \\'male\\'][\"Survived\"]\\nrate_men = sum(men)/len(men)\\n\\nprint(\"% of men who survived:\", rate_men)\\n\\n=== MARKDOWN 11 ===\\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\\n\\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\\n\\nBut at the end of the day, this gender-based s\\n\\n=== CODE 12 ===\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\\nX = pd.get_dummies(train_data[features])\\nX_test = pd.get_dummies(test_data[features])\\n\\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\\nmodel.f\\n\\n=== MARKDOWN 13 ===\\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\\n> Again, don\\'t worry if this code doesn\\'t make sense to you!  For now, we\\'ll focus on how to generate and submit predictions.\\n\\nOnce you\\'re ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \\n- Ensure tha\\n\\n=== MARKDOWN 14 ===\\n# Part 4: Learn more!\\n\\nIf you\\'re interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we\\'ve presented here.  You\\'ll also know enough to generate even better predictions!\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: The tutorial is basic. Let me search for advanced techniques that could help achieve very high accuracy on this problem, particularly since the target is 100% accuracy which is extremely challenging.'}, {'role': 'tool', 'content': 'SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80\\u202f% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random\\u202fForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n**Step‚Äëby‚Äëstep recipe**\\n\\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \\n\\n2. **Impute & create missing‚Äëvalue flags**  \\n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \\n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1\\u202fif Cabin not null, else\\u202f0).  \\n   * Optionally encode the original *Cabin* letter as a categorical feature.  \\n\\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \\n   * **FamilySize** = `SibSp + Parch + 1`  \\n   * **IsAlone** = 1\\u202fif *FamilySize*\\u202f=\\u202f1 else\\u202f0  \\n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \\n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \\n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \\n\\n   These engineered columns lifted baseline scores from ~72\\u202f% to ~78\\u202f% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \\n\\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35\\u202f% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \\n\\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \\n   * `n_estimators` (200‚Äë1000)  \\n   * `max_depth` (5‚Äë15)  \\n   * `min_samples_split` / `min_samples_leaf`  \\n   * `max_features` (sqrt, log2, or a fraction)  \\n\\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100\\u202f% Accuracy‚Äù notebook placed the author in the top\\u202f3\\u202f%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \\n\\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•\\u202f0.84) before uploading.  \\n\\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\\n\\n--- Result 2 ---\\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\\n\\nContent:\\nSeptember 10, 2016\\xa0\\xa0\\xa0\\xa0\\xa033min read\\n\\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\\n\\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\\n\\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I\\'m writing this post, I am ranked among the top 4% of all Kagglers.\\n\\nThis post is the opportunity to share my solution with you.\\n\\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I\\'ll follow with feature engineering and finally present the predictive model I set up.\\n\\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\\nThe main libraries involved in this tutorial are:\\n\\n- **Pandas** for data manipulation and ingestion\\n- **Matplotlib** and **seaborn** for data visualization\\n- **Numpy** for multidimensional array computing\\n- **sklearn** for machine learning and predictive modeling\\n\\n### Installation procedure\\n\\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\\n\\n### Nota Bene\\n\\nThis is my first attempt as a blogger and as a machine learning practitioner.\\n\\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\\n\\nHope you\\'ve got everything set on your computer. Let\\'s get started.\\n\\n## I - Exploratory data analysis\\n\\nAs in different data projects, we\\'ll first start diving into the data and build up our first intuitions.\\n\\nIn this section, we\\'ll be doing four things.\\n\\n- Data extraction : we\\'ll load the dataset and have a first look at it.\\n- Cleaning : we\\'ll fill in missing values.\\n- Plotting : we\\'ll create some interesting charts that\\'ll (hopefully) spot correlations and hidden insights out of the data.\\n- Assumptions : we\\'ll formulate hypotheses from the charts.\\n\\nWe tweak the style of this notebook a little bit to have centered plots.\\n\\n```\\nfrom IPython.core.display import HTML\\nHTML(\"\"\"\\n<style>\\n.output_png {\\n    display: table-cell;\\n    text-align: center;\\n    vertical-align: middle;\\n}\\n</style>\\n\"\"\");\\n```\\n\\nWe import the useful libraries.\\n\\n```\\n%matplotlib inline\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\nwarnings.filterwarnings(\\'ignore\\', category=DeprecationWarning)\\n\\nimport pandas as pd\\npd.options.display.max_columns = 100\\n\\nfrom matplotlib import pyplot as plt\\nimport numpy as np\\n\\nimport seaborn as sns\\n\\nimport pylab as plot\\nparams = {\\n    \\'axes.labelsize\\': \"large\",\\n    \\'xtick.labelsize\\': \\'x-large\\',\\n    \\'legend.fontsize\\': 20,\\n    \\'figure.dpi\\': 150,\\n    \\'figure.figsize\\': [25, 7]\\n}\\nplot.rcParams.update(params)\\n```\\n\\nTwo datasets are available: a training set and a test set.\\nWe\\'ll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\\n\\nWe\\'ll see how this procedure is done at the end of this post.\\n\\nNow let\\'s start by loading the training set.\\n\\n```\\ndata = pd.read_csv(\\'./data/train.csv\\')\\nprint(data.shape)\\n#(891, 12)\\n```\\n\\nWe have:\\n\\n- 891 rows\\n- 12 columns\\n\\nPandas allows you to have a sneak peak at your data.\\n\\n```\\ndata.head()\\n```\\n\\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\\n\\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he\\'s dead. The is the variable we\\'re going to predict.\\n\\nThe other variables describe the passengers. They are the **features**.\\n\\n- PassengerId: and id given to each traveler on the boat\\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\\n- The Name of the passeger\\n- The Sex\\n- The Age\\n- SibSp: number of siblings and spouses traveling with the passenger\\n- Parch: number of parents and children traveling with the passenger\\n- The ticket number\\n- The ticket Fare\\n- The cabin number\\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\\n\\nPandas allows you to a have a high-level simple statistical description of the numerical features.\\nThis can be done using the describe method.\\n\\n```\\ndata.describe()\\n```\\n\\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\\n\\nThe count variable shows that 177 values are missing in the Age column.\\n\\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\\n\\n```\\ndata[\\'Age\\'] = data[\\'Age\\'].fillna(data[\\'Age\\'].median())\\n```\\n\\nLet\\'s now make some charts.\\n\\nLet\\'s visualize survival based on the gender.\\n\\n```\\ndata[\\'Died\\'] = 1 - data[\\'Survived\\']\\ndata.groupby(\\'Sex\\').agg(\\'sum\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                          stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nIt looks like male passengers are more likely to succumb.\\n\\nLet\\'s plot the same graph but with ratio instead.\\n\\n```\\ndata.groupby(\\'Sex\\').agg(\\'mean\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                           stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\\n\\nLet\\'s now correlate the survival with the age variable.\\n\\n```\\nfig = plt.figure(figsize=(25, 7))\\nsns.violinplot(x=\\'Sex\\', y=\\'Age\\',\\n               hue=\\'Survived\\', data=data,\\n               split=True,\\n               palette={0: \"r\", 1: \"g\"}\\n              );\\n```\\n\\nAs we saw in the chart above and validate by the following:\\n\\n- Women survive more than men, as depicted by the larger female green histogram\\n\\nNow, we see that:\\n\\n- The age conditions the survival for male passengers:\\n\\n  - Younger male tend to survive\\n  - A large number of passengers between 20 and 40 succumb\\n- The age doesn\\'t seem to have a direct impact on the female survival\\n\\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\\n\\nRight?\\n\\nLet\\'s now focus on the Fare ticket of each passenger and see how it could impact the survival.\\n\\n```\\nfigure = plt.figure(figsize=(25, 7))\\nplt.hist([dat...\\n\\n--- Result 3 ---\\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\nURL: https://github.com/alicevillar/titanic-kaggle\\n\\nContent:\\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\\n\\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\\n\\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n- [Fork\\\\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n- [Star\\\\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n[6\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n\\n# alicevillar/titanic-kaggle\\n\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n\\nmain\\n\\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\\n\\nGo to file\\n\\nCode\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\\n| ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\\n| ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\\n| View all files |\\n\\n## Repository files navigation\\n\\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n\\nThe objective of Kaggle\\'s Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\\n\\n### Quick Start:\\n\\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\\n\\n### Dependencies:\\n\\n- [Numpy](https://numpy.org/)\\n- [Pandas](https://pandas.pydata.org/)\\n- [SciKit-Learn](https://scikit-learn.org/)\\n- [Matplotlib](https://matplotlib.org/)\\n- [Seaborn](https://seaborn.pydata.org/)\\n\\n### Approach\\n\\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\\n\\n### Kaggle Competition \\\\| Titanic Machine Learning from Disaster\\n\\nKaggle\\'s challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle\\'s [Competition Page](https://www.kaggle.com/c/titanic):\\n\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\\n\\n### Results\\n\\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\\n\\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\\n\\n## About\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n### Topics\\n\\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\\n\\n### Resources\\n\\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\\n\\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n### Stars\\n\\n[**6**\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\\n\\n### Watchers\\n\\n[**1**\\\\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\\n\\n### Forks\\n\\n[**3**\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\\n\\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\\n\\n--- Result 4 ---\\nTitle: Search code, repositories, users, issues, pull requests...\\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\n\\nContent:\\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[Skip to content](#start-of-content)\\n## Navigation Menu\\nToggle navigation\\n[](https://github.com/)\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nSearch or jump to...\\n# Search code, repositories, users, issues, pull requests...\\n</option></form>\\nSearch\\nClear\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n# Provide feedback\\n</option></form>\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancelSubmit feedback\\n# Saved searches\\n## Use saved searches to filter your results more quickly\\n</option></form>\\nName\\nQuery\\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\nCancelCreate saved search\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nResetting focus\\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\\n{{ message }}\\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\nmain\\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\nGo to file\\nCode\\nOpen more actions menu\\n## Folders and files\\n|Name|Name|\\nLast commit message\\n|\\nLast commit date\\n|\\n## Latest commit\\n## History\\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n|\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n|\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n|\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n|\\n|\\nView all files\\n|\\n## Repository files navigation\\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\~72% to \\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n# Titanic Survival Prediction\\n[](#titanic-survival-prediction)\\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\\n* **Detailed EDA**\\nA Jupyter notebook that walks through exploratory data analysis:\\n* Summary statistics\\n* Missing-value patterns\\n* Feature distributions and pairwise relationships\\n* Correlation heatmaps\\n* **Feature Engineering**\\nCreation of high-signal features from raw inputs, including:\\n* `Has\\\\_Cabin`(binary cabin indicator)\\n* `FareBin`(quantile-based fare categories)\\n* Group-median imputation for`Age`, then 10-year age bins\\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\\n* `Title`extracted and consolidated from passenger names\\n* **Model Comparison**\\nTraining and evaluation of multiple classifiers on the engineered feature set:\\n* Random Forest\\n* Support Vector Machine\\n* K-Nearest Neighbors (k=3,5,7)\\n* XGBoost\\n* LightGBM\\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\\n* **Analysis &amp; Interpretation**\\nInline Markdown commentary explains:\\n* Why each feature matters\\n* How missing data were handled\\n* The rationale for model selection\\n* Key takeaways and next-step recommendations\\n## Repository Structure\\n[](#repository-structure)\\ndata/\\n* train.csv # Official Kaggle training set\\n* test.csv # Official Kaggle test set\\nnotebooks/\\n* titanic\\\\_analysis.ipynb\\n‚Ä¢EDA, feature engineering, model training\\n‚Ä¢Detailed Markdown analysis\\n* README.md # Project overview and instructions\\n## Contributing\\n[](#contributing)\\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\\n## About\\nPredict Titanic survival using t...\\n\\n--- Result 5 ---\\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\n\\nContent:\\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\\nAman Krishna\\n2022-04-20T07:23:42Z\\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\n\\n## The art of fine-tuning a model\\n\\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\\n\\n7 min read\\n\\n\\nApr 19, 2022\\n\\n\\nListen\\n\\nShare\\n\\nPress enter or click to view image in full size\\n\\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\\n\\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\\n\\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\\n\\nYou can find the complete code on Github **_:_**\\n\\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \\n\\n**Machine Learning model build for survivor prediction for Kaggle\\'s titanic competition - kaggle_titanic/Model‚Ä¶**\\n\\ngithub.com]\\n\\n## Which Model to use?\\n\\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\\n\\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\\n\\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\\n\\n## Pre-Requisite\\n\\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\\n\\n### Dropping Features\\n\\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\\n\\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\\n\\n### Code\\n\\n### Dummify Data\\n\\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\\n\\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\\n\\n**We will be using One-Hot encoding on our categorical features.**\\n\\n### Code\\n\\n### Split Data\\n\\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\\n\\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\\n\\n## Training\\n\\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\\n\\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\\n\\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\\n\\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\\n\\n### Code\\n\\n## Fine Tuning\\n\\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\\n\\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\\n\\n### Code\\n\\n### Output\\n\\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\\n\\nPress enter or click to view image in full size\\n\\nGrid Search Results\\n\\n## Refining Search Space: Max Depth & Max Samples\\n\\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\\n\\n### How?\\n\\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\\n\\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\\n\\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest max_Depth & max_samples\\n\\n## Fine Tune: Min Sample Split & Min Sample Leaf\\n\\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest min_samples_leaf & min_samples_split\\n\\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\\n\\n## Fine Tune: Number of Estimators\\n\\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest n_estimator value\\n\\n## Refining Search Space: Number of estima...\\n\\n--- Result 6 ---\\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\\n\\nContent:\\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\\n\\n--- Result 7 ---\\nTitle: Titanic - Machine Learning from Disaster\\nURL: https://www.kaggle.com/c/titanic/code\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \\n\\n[... truncated 11780 characters ...]'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! The search confirms that achieving 100% accuracy is essentially impossible without cheating (using external data). The realistic best scores are in the 80-86% range. Let me update the seed prompt with this important context and add more specific techniques.'}, {'role': 'tool', 'content': '‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\\n  Source: Web search - Kaggle Titanic best techniques'}]",
        "llm.input_tokens": 44619,
        "llm.output_tokens": 57,
        "llm.total_tokens": 44676,
        "llm.latency_ms": 2620.41974067688,
        "llm.completion": "[Tool Use: Read]",
        "llm.cost_usd": 0.134712
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "d15981eadfc5e8a7",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ReadTool",
      "kind": "INTERNAL",
      "start_time": 1767683626160585783,
      "end_time": 1767683626160975664,
      "duration": 0.000389881,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ReadTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.ReadTool object at 0x73eac37d9c90>\", \"input\": {\"file_path\": \"seed_prompt.txt\"}}",
        "tool.output": "{\"content\": \"# Titanic Survival Prediction - Techniques Guide\\n\\n## Data Understanding\\n**Reference notebooks for data characteristics:**\\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\\n- Target is imbalanced: 61.6% died, 38.4% survived\\n\\n## Feature Engineering (Critical for High Accuracy)\\n\\n### Title Extraction from Name\\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)`\\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\\n- Title is highly predictive: Master (young boys) had high survival\\n\\n### Family Features\\n- **FamilySize** = SibSp + Parch + 1\\n- **IsAlone** = 1 if FamilySize == 1, else 0\\n- Family size affects survival: solo travelers and very large families had lower survival\\n\\n### Cabin Features\\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\\n- ~77% missing - use Has_Cabin binary flag\\n\\n### Fare and Age Binning\\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\\n- Binning helps tree models find splits\\n\\n### Name Length\\n- **Name_length** = len(Name) - can be proxy for social status\\n\\n### Ticket Features\\n- Ticket prefix extraction (some tickets have letter prefixes)\\n- Ticket frequency (shared tickets indicate traveling together)\\n\\n## Missing Value Handling\\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\\n- **Embarked**: Fill with mode ('S' - Southampton)\\n- **Fare**: Fill with median (by Pclass)\\n- **Cabin**: Create Has_Cabin flag, don't impute\\n\\n## Models\\n\\n### Single Models (Baseline)\\nFor this small tabular dataset, tree-based models work well:\\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\\n- **XGBoost**: Similar parameters, use early stopping\\n- **Extra Trees**: n_estimators=500, max_depth=6\\n- **Logistic Regression**: Good baseline, use regularization\\n\\n### Ensemble Approaches (Higher Accuracy)\\n\\n#### Voting Classifier\\nCombine multiple models with soft voting:\\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\\n- Use soft voting (probability-based) for better results\\n\\n#### Stacking (Best Approach)\\nTwo-level stacking architecture:\\n1. **First Level (Base Models)**: \\n   - Random Forest\\n   - Extra Trees\\n   - AdaBoost\\n   - Gradient Boosting\\n   - SVC (with probability=True)\\n   \\n2. **Second Level (Meta-Classifier)**:\\n   - XGBoost or Logistic Regression\\n   \\n3. **Out-of-Fold Predictions**:\\n   - Use K-Fold (K=5) to generate out-of-fold predictions\\n   - This prevents overfitting when training meta-classifier\\n   - Each base model generates predictions on held-out fold\\n   - Stack these predictions as features for meta-classifier\\n\\n## Validation Strategy\\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\\n- Small dataset (891 samples) - CV is critical to avoid overfitting\\n- Track both train and validation scores to detect overfitting\\n\\n## Hyperparameter Tuning\\n- Use GridSearchCV or RandomizedSearchCV\\n- Key parameters to tune:\\n  - Tree depth (max_depth): 3-8\\n  - Number of estimators: 100-1000\\n  - Learning rate (for boosting): 0.01-0.1\\n  - Min samples per leaf: 1-5\\n- Use cross-validation during tuning\\n\\n## Feature Selection\\n- Use Recursive Feature Elimination (RFE) with cross-validation\\n- Check feature importances from tree models\\n- Most important features typically: Sex, Title, Pclass, Fare, Age\\n\\n## Key Insights from Top Kernels\\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\\n3. Title extraction captures both sex and age information effectively\\n4. Family size has non-linear relationship with survival\\n5. Ensemble methods consistently outperform single models\\n\\n## Submission Strategy\\n- Generate predictions using best ensemble model\\n- Consider averaging predictions from multiple models\\n- Threshold at 0.5 for binary classification\\n- Format: PassengerId, Survived (0 or 1)\\n\", \"is_error\": false}",
        "tool.duration_ms": 0.40602684020996094
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "b34ac5754ce3eff6",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683627335770018,
      "end_time": 1767683663461728160,
      "duration": 36.125958142,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n\ntool: ‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\n  Source: exploration/eda.ipynb\ntool: ‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\n  Source: exploration/eda.ipynb\ntool: === MARKDOWN 23 ===\n## Analyze by visualizing data\n\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\n\n### Correlating numerical features\n\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\n\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \n\n=== MARKDOWN 25 ===\n### Correlating numerical and ordinal features\n\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n\n**Observations.**\n\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n- Pclass varies in terms of Age distribution of passengers.\n\n**Decisions\n\n=== MARKDOWN 27 ===\n### Correlating categorical features\n\nNow we can correlate categorical features with our solution goal.\n\n**Observations.**\n\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\n- Ports of embarkation have varying survival rates for Pcla\n\n=== MARKDOWN 29 ===\n### Correlating categorical and numerical features\n\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n\n**Observations.**\n\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n\n**Decisions.**\n\n- Consider banding Fare feature.\n\n=== MARKDOWN 31 ===\n## Wrangle data\n\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n\n### Correcting by dropping features\n\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\n\n\n=== MARKDOWN 33 ===\n### Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n\n**Observations.**\n\nWhen we plot Title, Age, and Survived, we note the following observations.\n\n- Most titles band Age groups accurately. For example: Master\n\n=== CODE 34 ===\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])\n\n=== MARKDOWN 35 ===\nWe can replace many titles with a more common name or classify them as `Rare`.\n\n=== CODE 36 ===\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n\n=== MARKDOWN 37 ===\nWe can convert the categorical titles to ordinal.\n\n=== CODE 38 ===\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()\n\n=== MARKDOWN 39 ===\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\n\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: === MARKDOWN 0 ===\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\n\n=== MARKDOWN 1 ===\n# Part 2: Your coding environment\n\nIn this section, you'll train your own machine learning model to improve your predictions.  _If you've never written code before or don't have any experience with machine learning, don't worry!  We don't assume any prior experience in this tutorial._\n\n## The Notebook\n\nThe first thing to do is to create a Kaggle Notebook where you'll store all of your code.  You c\n\n=== CODE 2 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data proc\n\n=== MARKDOWN 3 ===\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We'll do that next.\n\n## Load the data\n\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\n\n![](https://i.imgur.com/OQBax9n.png)\n\nType the two lines of code below into your second code cell.  Then, once you're done, either click on the blue pl\n\n=== CODE 4 ===\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()\n\n=== MARKDOWN 5 ===\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It's very important that you see this output **in your notebook** before proceeding with the tutorial!\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\n\n=== CODE 6 ===\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()\n\n=== MARKDOWN 7 ===\nAs before, make sure that you see the output above in your notebook before continuing.  \n\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\n\n# Part 3: Your first submission\n\n=== CODE 8 ===\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\n=== MARKDOWN 9 ===\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\n\nThen, run the code below in another code cell:\n\n=== CODE 10 ===\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)\n\n=== MARKDOWN 11 ===\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\n\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\n\nBut at the end of the day, this gender-based s\n\n=== CODE 12 ===\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.f\n\n=== MARKDOWN 13 ===\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\n> Again, don't worry if this code doesn't make sense to you!  For now, we'll focus on how to generate and submit predictions.\n\nOnce you're ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \n- Ensure tha\n\n=== MARKDOWN 14 ===\n# Part 4: Learn more!\n\nIf you're interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we've presented here.  You'll also know enough to generate even better predictions!\n\n\ntool: SEARCH RESULTS (9 found)\n==================================================\n\n--- Result 1 ---\nTitle: ANSWER\n\nContent:\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80‚ÄØ% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random‚ÄØForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n**Step‚Äëby‚Äëstep recipe**\n\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \n\n2. **Impute & create missing‚Äëvalue flags**  \n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1‚ÄØif Cabin not null, else‚ÄØ0).  \n   * Optionally encode the original *Cabin* letter as a categorical feature.  \n\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \n   * **FamilySize** = `SibSp + Parch + 1`  \n   * **IsAlone** = 1‚ÄØif *FamilySize*‚ÄØ=‚ÄØ1 else‚ÄØ0  \n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \n\n   These engineered columns lifted baseline scores from ~72‚ÄØ% to ~78‚ÄØ% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \n\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35‚ÄØ% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \n\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \n   * `n_estimators` (200‚Äë1000)  \n   * `max_depth` (5‚Äë15)  \n   * `min_samples_split` / `min_samples_leaf`  \n   * `max_features` (sqrt, log2, or a fraction)  \n\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100‚ÄØ% Accuracy‚Äù notebook placed the author in the top‚ÄØ3‚ÄØ%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \n\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•‚ÄØ0.84) before uploading.  \n\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\n\n--- Result 2 ---\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\n\nContent:\nSeptember 10, 2016¬†¬†¬†¬†¬†33min read\n\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\n\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\n\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I'm writing this post, I am ranked among the top 4% of all Kagglers.\n\nThis post is the opportunity to share my solution with you.\n\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I'll follow with feature engineering and finally present the predictive model I set up.\n\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\nThe main libraries involved in this tutorial are:\n\n- **Pandas** for data manipulation and ingestion\n- **Matplotlib** and **seaborn** for data visualization\n- **Numpy** for multidimensional array computing\n- **sklearn** for machine learning and predictive modeling\n\n### Installation procedure\n\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\n\n### Nota Bene\n\nThis is my first attempt as a blogger and as a machine learning practitioner.\n\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\n\nHope you've got everything set on your computer. Let's get started.\n\n## I - Exploratory data analysis\n\nAs in different data projects, we'll first start diving into the data and build up our first intuitions.\n\nIn this section, we'll be doing four things.\n\n- Data extraction : we'll load the dataset and have a first look at it.\n- Cleaning : we'll fill in missing values.\n- Plotting : we'll create some interesting charts that'll (hopefully) spot correlations and hidden insights out of the data.\n- Assumptions : we'll formulate hypotheses from the charts.\n\nWe tweak the style of this notebook a little bit to have centered plots.\n\n```\nfrom IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n</style>\n\"\"\");\n```\n\nWe import the useful libraries.\n\n```\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\nimport pandas as pd\npd.options.display.max_columns = 100\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimport seaborn as sns\n\nimport pylab as plot\nparams = {\n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n}\nplot.rcParams.update(params)\n```\n\nTwo datasets are available: a training set and a test set.\nWe'll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\n\nWe'll see how this procedure is done at the end of this post.\n\nNow let's start by loading the training set.\n\n```\ndata = pd.read_csv('./data/train.csv')\nprint(data.shape)\n#(891, 12)\n```\n\nWe have:\n\n- 891 rows\n- 12 columns\n\nPandas allows you to have a sneak peak at your data.\n\n```\ndata.head()\n```\n\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\n\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he's dead. The is the variable we're going to predict.\n\nThe other variables describe the passengers. They are the **features**.\n\n- PassengerId: and id given to each traveler on the boat\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\n- The Name of the passeger\n- The Sex\n- The Age\n- SibSp: number of siblings and spouses traveling with the passenger\n- Parch: number of parents and children traveling with the passenger\n- The ticket number\n- The ticket Fare\n- The cabin number\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\n\nPandas allows you to a have a high-level simple statistical description of the numerical features.\nThis can be done using the describe method.\n\n```\ndata.describe()\n```\n\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\n| --- | --- | --- | --- | --- | --- | --- |\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\n\nThe count variable shows that 177 values are missing in the Age column.\n\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\n\n```\ndata['Age'] = data['Age'].fillna(data['Age'].median())\n```\n\nLet's now make some charts.\n\nLet's visualize survival based on the gender.\n\n```\ndata['Died'] = 1 - data['Survived']\ndata.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                          stacked=True, colors=['g', 'r']);\n```\n\nIt looks like male passengers are more likely to succumb.\n\nLet's plot the same graph but with ratio instead.\n\n```\ndata.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                           stacked=True, colors=['g', 'r']);\n```\n\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\n\nLet's now correlate the survival with the age variable.\n\n```\nfig = plt.figure(figsize=(25, 7))\nsns.violinplot(x='Sex', y='Age',\n               hue='Survived', data=data,\n               split=True,\n               palette={0: \"r\", 1: \"g\"}\n              );\n```\n\nAs we saw in the chart above and validate by the following:\n\n- Women survive more than men, as depicted by the larger female green histogram\n\nNow, we see that:\n\n- The age conditions the survival for male passengers:\n\n  - Younger male tend to survive\n  - A large number of passengers between 20 and 40 succumb\n- The age doesn't seem to have a direct impact on the female survival\n\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\n\nRight?\n\nLet's now focus on the Fare ticket of each passenger and see how it could impact the survival.\n\n```\nfigure = plt.figure(figsize=(25, 7))\nplt.hist([dat...\n\n--- Result 3 ---\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\nURL: https://github.com/alicevillar/titanic-kaggle\n\nContent:\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n- [Fork\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n- [Star\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n[6\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n\n# alicevillar/titanic-kaggle\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmain\n\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\n| ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\n| ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n\nThe objective of Kaggle's Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\n\n### Quick Start:\n\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\n\n### Dependencies:\n\n- [Numpy](https://numpy.org/)\n- [Pandas](https://pandas.pydata.org/)\n- [SciKit-Learn](https://scikit-learn.org/)\n- [Matplotlib](https://matplotlib.org/)\n- [Seaborn](https://seaborn.pydata.org/)\n\n### Approach\n\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\n\n### Kaggle Competition \\| Titanic Machine Learning from Disaster\n\nKaggle's challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle's [Competition Page](https://www.kaggle.com/c/titanic):\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\n\n### Results\n\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\n\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\n\n## About\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n### Topics\n\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\n\n### Resources\n\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\n\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n### Stars\n\n[**6**\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\n\n### Watchers\n\n[**1**\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\n\n### Forks\n\n[**3**\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\n\n--- Result 4 ---\nTitle: Search code, repositories, users, issues, pull requests...\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\n\nContent:\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\nmain\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n|\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n|\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n|\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\~72% to \\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n# Titanic Survival Prediction\n[](#titanic-survival-prediction)\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\n* **Detailed EDA**\nA Jupyter notebook that walks through exploratory data analysis:\n* Summary statistics\n* Missing-value patterns\n* Feature distributions and pairwise relationships\n* Correlation heatmaps\n* **Feature Engineering**\nCreation of high-signal features from raw inputs, including:\n* `Has\\_Cabin`(binary cabin indicator)\n* `FareBin`(quantile-based fare categories)\n* Group-median imputation for`Age`, then 10-year age bins\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\n* `Title`extracted and consolidated from passenger names\n* **Model Comparison**\nTraining and evaluation of multiple classifiers on the engineered feature set:\n* Random Forest\n* Support Vector Machine\n* K-Nearest Neighbors (k=3,5,7)\n* XGBoost\n* LightGBM\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\n* **Analysis &amp; Interpretation**\nInline Markdown commentary explains:\n* Why each feature matters\n* How missing data were handled\n* The rationale for model selection\n* Key takeaways and next-step recommendations\n## Repository Structure\n[](#repository-structure)\ndata/\n* train.csv # Official Kaggle training set\n* test.csv # Official Kaggle test set\nnotebooks/\n* titanic\\_analysis.ipynb\n‚Ä¢EDA, feature engineering, model training\n‚Ä¢Detailed Markdown analysis\n* README.md # Project overview and instructions\n## Contributing\n[](#contributing)\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\n## About\nPredict Titanic survival using t...\n\n--- Result 5 ---\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\n\nContent:\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\nAman Krishna\n2022-04-20T07:23:42Z\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\n\n## The art of fine-tuning a model\n\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\n\n7 min read\n\n\nApr 19, 2022\n\n\nListen\n\nShare\n\nPress enter or click to view image in full size\n\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\n\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\n\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\n\nYou can find the complete code on Github **_:_**\n\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \n\n**Machine Learning model build for survivor prediction for Kaggle's titanic competition - kaggle_titanic/Model‚Ä¶**\n\ngithub.com]\n\n## Which Model to use?\n\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\n\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\n\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\n\n## Pre-Requisite\n\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\n\n### Dropping Features\n\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\n\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\n\n### Code\n\n### Dummify Data\n\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\n\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\n\n**We will be using One-Hot encoding on our categorical features.**\n\n### Code\n\n### Split Data\n\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\n\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\n\n## Training\n\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\n\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\n\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\n\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\n\n### Code\n\n## Fine Tuning\n\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\n\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\n\n### Code\n\n### Output\n\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\n\nPress enter or click to view image in full size\n\nGrid Search Results\n\n## Refining Search Space: Max Depth & Max Samples\n\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\n\n### How?\n\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\n\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\n\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest max_Depth & max_samples\n\n## Fine Tune: Min Sample Split & Min Sample Leaf\n\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest min_samples_leaf & min_samples_split\n\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\n\n## Fine Tune: Number of Estimators\n\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest n_estimator value\n\n## Refining Search Space: Number of estima...\n\n--- Result 6 ---\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\n\nContent:\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\n\n--- Result 7 ---\nTitle: Titanic - Machine Learning from Disaster\nURL: https://www.kaggle.com/c/titanic/code\n\nContent:\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \n\n[... truncated 11780 characters ...]\ntool: ‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\n  Source: Web search - Kaggle Titanic best techniques\ntool: # Titanic Survival Prediction - Techniques Guide\n\n## Data Understanding\n**Reference notebooks for data characteristics:**\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\n- Target is imbalanced: 61.6% died, 38.4% survived\n\n## Feature Engineering (Critical for High Accuracy)\n\n### Title Extraction from Name\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\.', expand=False)`\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\n- Title is highly predictive: Master (young boys) had high survival\n\n### Family Features\n- **FamilySize** = SibSp + Parch + 1\n- **IsAlone** = 1 if FamilySize == 1, else 0\n- Family size affects survival: solo travelers and very large families had lower survival\n\n### Cabin Features\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\n- ~77% missing - use Has_Cabin binary flag\n\n### Fare and Age Binning\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\n- Binning helps tree models find splits\n\n### Name Length\n- **Name_length** = len(Name) - can be proxy for social status\n\n### Ticket Features\n- Ticket prefix extraction (some tickets have letter prefixes)\n- Ticket frequency (shared tickets indicate traveling together)\n\n## Missing Value Handling\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\n- **Embarked**: Fill with mode ('S' - Southampton)\n- **Fare**: Fill with median (by Pclass)\n- **Cabin**: Create Has_Cabin flag, don't impute\n\n## Models\n\n### Single Models (Baseline)\nFor this small tabular dataset, tree-based models work well:\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\n- **XGBoost**: Similar parameters, use early stopping\n- **Extra Trees**: n_estimators=500, max_depth=6\n- **Logistic Regression**: Good baseline, use regularization\n\n### Ensemble Approaches (Higher Accuracy)\n\n#### Voting Classifier\nCombine multiple models with soft voting:\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n- Use soft voting (probability-based) for better results\n\n#### Stacking (Best Approach)\nTwo-level stacking architecture:\n1. **First Level (Base Models)**: \n   - Random Forest\n   - Extra Trees\n   - AdaBoost\n   - Gradient Boosting\n   - SVC (with probability=True)\n   \n2. **Second Level (Meta-Classifier)**:\n   - XGBoost or Logistic Regression\n   \n3. **Out-of-Fold Predictions**:\n   - Use K-Fold (K=5) to generate out-of-fold predictions\n   - This prevents overfitting when training meta-classifier\n   - Each base model generates predictions on held-out fold\n   - Stack these predictions as features for meta-classifier\n\n## Validation Strategy\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\n- Small dataset (891 samples) - CV is critical to avoid overfitting\n- Track both train and validation scores to detect overfitting\n\n## Hyperparameter Tuning\n- Use GridSearchCV or RandomizedSearchCV\n- Key parameters to tune:\n  - Tree depth (max_depth): 3-8\n  - Number of estimators: 100-1000\n  - Learning rate (for boosting): 0.01-0.1\n  - Min samples per leaf: 1-5\n- Use cross-validation during tuning\n\n## Feature Selection\n- Use Recursive Feature Elimination (RFE) with cross-validation\n- Check feature importances from tree models\n- Most important features typically: Sex, Title, Pclass, Fare, Age\n\n## Key Insights from Top Kernels\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\n3. Title extraction captures both sex and age information effectively\n4. Family size has non-linear relationship with survival\n5. Ensemble methods consistently outperform single models\n\n## Submission Strategy\n- Generate predictions using best ensemble model\n- Consider averaging predictions from multiple models\n- Threshold at 0.5 for binary classification\n- Format: PassengerId, Survived (0 or 1)\n",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb'}, {'role': 'tool', 'content': '‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb'}, {'role': 'assistant', 'content': 'REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.'}, {'role': 'tool', 'content': '=== MARKDOWN 23 ===\\n## Analyze by visualizing data\\n\\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n\\n### Correlating numerical features\\n\\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\\n\\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \\n\\n=== MARKDOWN 25 ===\\n### Correlating numerical and ordinal features\\n\\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n\\n**Observations.**\\n\\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n- Pclass varies in terms of Age distribution of passengers.\\n\\n**Decisions\\n\\n=== MARKDOWN 27 ===\\n### Correlating categorical features\\n\\nNow we can correlate categorical features with our solution goal.\\n\\n**Observations.**\\n\\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n- Ports of embarkation have varying survival rates for Pcla\\n\\n=== MARKDOWN 29 ===\\n### Correlating categorical and numerical features\\n\\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n\\n**Observations.**\\n\\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n\\n**Decisions.**\\n\\n- Consider banding Fare feature.\\n\\n=== MARKDOWN 31 ===\\n## Wrangle data\\n\\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n\\n### Correcting by dropping features\\n\\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n\\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n\\n\\n=== MARKDOWN 33 ===\\n### Creating new feature extracting from existing\\n\\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n\\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n\\n**Observations.**\\n\\nWhen we plot Title, Age, and Survived, we note the following observations.\\n\\n- Most titles band Age groups accurately. For example: Master\\n\\n=== CODE 34 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset.Name.str.extract(\\' ([A-Za-z]+)\\\\.\\', expand=False)\\n\\npd.crosstab(train_df[\\'Title\\'], train_df[\\'Sex\\'])\\n\\n=== MARKDOWN 35 ===\\nWe can replace many titles with a more common name or classify them as `Rare`.\\n\\n=== CODE 36 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace([\\'Lady\\', \\'Countess\\',\\'Capt\\', \\'Col\\',\\\\\\n \\t\\'Don\\', \\'Dr\\', \\'Major\\', \\'Rev\\', \\'Sir\\', \\'Jonkheer\\', \\'Dona\\'], \\'Rare\\')\\n\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mlle\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Ms\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mme\\', \\'Mrs\\')\\n    \\ntrain_df[[\\'Title\\', \\'Survived\\']].groupby([\\'Title\\'], as_index=False).mean()\\n\\n=== MARKDOWN 37 ===\\nWe can convert the categorical titles to ordinal.\\n\\n=== CODE 38 ===\\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].map(title_mapping)\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].fillna(0)\\n\\ntrain_df.head()\\n\\n=== MARKDOWN 39 ===\\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now I have comprehensive information. Let me write the seed prompt with all the techniques I've learned.\"}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': 'REASONING: Now let me check if there are any additional techniques in the Alexis Cook tutorial that might be helpful, and also search for any advanced techniques that could help beat the 1.0 target score (which is 100% accuracy - extremely challenging).'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\\n\\n=== MARKDOWN 1 ===\\n# Part 2: Your coding environment\\n\\nIn this section, you\\'ll train your own machine learning model to improve your predictions.  _If you\\'ve never written code before or don\\'t have any experience with machine learning, don\\'t worry!  We don\\'t assume any prior experience in this tutorial._\\n\\n## The Notebook\\n\\nThe first thing to do is to create a Kaggle Notebook where you\\'ll store all of your code.  You c\\n\\n=== CODE 2 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load in \\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data proc\\n\\n=== MARKDOWN 3 ===\\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We\\'ll do that next.\\n\\n## Load the data\\n\\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\\n\\n![](https://i.imgur.com/OQBax9n.png)\\n\\nType the two lines of code below into your second code cell.  Then, once you\\'re done, either click on the blue pl\\n\\n=== CODE 4 ===\\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntrain_data.head()\\n\\n=== MARKDOWN 5 ===\\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It\\'s very important that you see this output **in your notebook** before proceeding with the tutorial!\\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\\n\\n=== CODE 6 ===\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\\ntest_data.head()\\n\\n=== MARKDOWN 7 ===\\nAs before, make sure that you see the output above in your notebook before continuing.  \\n\\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\\n\\n# Part 3: Your first submission\\n\\n=== CODE 8 ===\\nwomen = train_data.loc[train_data.Sex == \\'female\\'][\"Survived\"]\\nrate_women = sum(women)/len(women)\\n\\nprint(\"% of women who survived:\", rate_women)\\n\\n=== MARKDOWN 9 ===\\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\\n\\nThen, run the code below in another code cell:\\n\\n=== CODE 10 ===\\nmen = train_data.loc[train_data.Sex == \\'male\\'][\"Survived\"]\\nrate_men = sum(men)/len(men)\\n\\nprint(\"% of men who survived:\", rate_men)\\n\\n=== MARKDOWN 11 ===\\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\\n\\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\\n\\nBut at the end of the day, this gender-based s\\n\\n=== CODE 12 ===\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\\nX = pd.get_dummies(train_data[features])\\nX_test = pd.get_dummies(test_data[features])\\n\\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\\nmodel.f\\n\\n=== MARKDOWN 13 ===\\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\\n> Again, don\\'t worry if this code doesn\\'t make sense to you!  For now, we\\'ll focus on how to generate and submit predictions.\\n\\nOnce you\\'re ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \\n- Ensure tha\\n\\n=== MARKDOWN 14 ===\\n# Part 4: Learn more!\\n\\nIf you\\'re interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we\\'ve presented here.  You\\'ll also know enough to generate even better predictions!\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: The tutorial is basic. Let me search for advanced techniques that could help achieve very high accuracy on this problem, particularly since the target is 100% accuracy which is extremely challenging.'}, {'role': 'tool', 'content': 'SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80\\u202f% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random\\u202fForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n**Step‚Äëby‚Äëstep recipe**\\n\\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \\n\\n2. **Impute & create missing‚Äëvalue flags**  \\n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \\n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1\\u202fif Cabin not null, else\\u202f0).  \\n   * Optionally encode the original *Cabin* letter as a categorical feature.  \\n\\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \\n   * **FamilySize** = `SibSp + Parch + 1`  \\n   * **IsAlone** = 1\\u202fif *FamilySize*\\u202f=\\u202f1 else\\u202f0  \\n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \\n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \\n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \\n\\n   These engineered columns lifted baseline scores from ~72\\u202f% to ~78\\u202f% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \\n\\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35\\u202f% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \\n\\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \\n   * `n_estimators` (200‚Äë1000)  \\n   * `max_depth` (5‚Äë15)  \\n   * `min_samples_split` / `min_samples_leaf`  \\n   * `max_features` (sqrt, log2, or a fraction)  \\n\\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100\\u202f% Accuracy‚Äù notebook placed the author in the top\\u202f3\\u202f%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \\n\\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•\\u202f0.84) before uploading.  \\n\\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\\n\\n--- Result 2 ---\\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\\n\\nContent:\\nSeptember 10, 2016\\xa0\\xa0\\xa0\\xa0\\xa033min read\\n\\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\\n\\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\\n\\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I\\'m writing this post, I am ranked among the top 4% of all Kagglers.\\n\\nThis post is the opportunity to share my solution with you.\\n\\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I\\'ll follow with feature engineering and finally present the predictive model I set up.\\n\\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\\nThe main libraries involved in this tutorial are:\\n\\n- **Pandas** for data manipulation and ingestion\\n- **Matplotlib** and **seaborn** for data visualization\\n- **Numpy** for multidimensional array computing\\n- **sklearn** for machine learning and predictive modeling\\n\\n### Installation procedure\\n\\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\\n\\n### Nota Bene\\n\\nThis is my first attempt as a blogger and as a machine learning practitioner.\\n\\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\\n\\nHope you\\'ve got everything set on your computer. Let\\'s get started.\\n\\n## I - Exploratory data analysis\\n\\nAs in different data projects, we\\'ll first start diving into the data and build up our first intuitions.\\n\\nIn this section, we\\'ll be doing four things.\\n\\n- Data extraction : we\\'ll load the dataset and have a first look at it.\\n- Cleaning : we\\'ll fill in missing values.\\n- Plotting : we\\'ll create some interesting charts that\\'ll (hopefully) spot correlations and hidden insights out of the data.\\n- Assumptions : we\\'ll formulate hypotheses from the charts.\\n\\nWe tweak the style of this notebook a little bit to have centered plots.\\n\\n```\\nfrom IPython.core.display import HTML\\nHTML(\"\"\"\\n<style>\\n.output_png {\\n    display: table-cell;\\n    text-align: center;\\n    vertical-align: middle;\\n}\\n</style>\\n\"\"\");\\n```\\n\\nWe import the useful libraries.\\n\\n```\\n%matplotlib inline\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\nwarnings.filterwarnings(\\'ignore\\', category=DeprecationWarning)\\n\\nimport pandas as pd\\npd.options.display.max_columns = 100\\n\\nfrom matplotlib import pyplot as plt\\nimport numpy as np\\n\\nimport seaborn as sns\\n\\nimport pylab as plot\\nparams = {\\n    \\'axes.labelsize\\': \"large\",\\n    \\'xtick.labelsize\\': \\'x-large\\',\\n    \\'legend.fontsize\\': 20,\\n    \\'figure.dpi\\': 150,\\n    \\'figure.figsize\\': [25, 7]\\n}\\nplot.rcParams.update(params)\\n```\\n\\nTwo datasets are available: a training set and a test set.\\nWe\\'ll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\\n\\nWe\\'ll see how this procedure is done at the end of this post.\\n\\nNow let\\'s start by loading the training set.\\n\\n```\\ndata = pd.read_csv(\\'./data/train.csv\\')\\nprint(data.shape)\\n#(891, 12)\\n```\\n\\nWe have:\\n\\n- 891 rows\\n- 12 columns\\n\\nPandas allows you to have a sneak peak at your data.\\n\\n```\\ndata.head()\\n```\\n\\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\\n\\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he\\'s dead. The is the variable we\\'re going to predict.\\n\\nThe other variables describe the passengers. They are the **features**.\\n\\n- PassengerId: and id given to each traveler on the boat\\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\\n- The Name of the passeger\\n- The Sex\\n- The Age\\n- SibSp: number of siblings and spouses traveling with the passenger\\n- Parch: number of parents and children traveling with the passenger\\n- The ticket number\\n- The ticket Fare\\n- The cabin number\\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\\n\\nPandas allows you to a have a high-level simple statistical description of the numerical features.\\nThis can be done using the describe method.\\n\\n```\\ndata.describe()\\n```\\n\\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\\n\\nThe count variable shows that 177 values are missing in the Age column.\\n\\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\\n\\n```\\ndata[\\'Age\\'] = data[\\'Age\\'].fillna(data[\\'Age\\'].median())\\n```\\n\\nLet\\'s now make some charts.\\n\\nLet\\'s visualize survival based on the gender.\\n\\n```\\ndata[\\'Died\\'] = 1 - data[\\'Survived\\']\\ndata.groupby(\\'Sex\\').agg(\\'sum\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                          stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nIt looks like male passengers are more likely to succumb.\\n\\nLet\\'s plot the same graph but with ratio instead.\\n\\n```\\ndata.groupby(\\'Sex\\').agg(\\'mean\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                           stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\\n\\nLet\\'s now correlate the survival with the age variable.\\n\\n```\\nfig = plt.figure(figsize=(25, 7))\\nsns.violinplot(x=\\'Sex\\', y=\\'Age\\',\\n               hue=\\'Survived\\', data=data,\\n               split=True,\\n               palette={0: \"r\", 1: \"g\"}\\n              );\\n```\\n\\nAs we saw in the chart above and validate by the following:\\n\\n- Women survive more than men, as depicted by the larger female green histogram\\n\\nNow, we see that:\\n\\n- The age conditions the survival for male passengers:\\n\\n  - Younger male tend to survive\\n  - A large number of passengers between 20 and 40 succumb\\n- The age doesn\\'t seem to have a direct impact on the female survival\\n\\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\\n\\nRight?\\n\\nLet\\'s now focus on the Fare ticket of each passenger and see how it could impact the survival.\\n\\n```\\nfigure = plt.figure(figsize=(25, 7))\\nplt.hist([dat...\\n\\n--- Result 3 ---\\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\nURL: https://github.com/alicevillar/titanic-kaggle\\n\\nContent:\\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\\n\\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\\n\\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n- [Fork\\\\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n- [Star\\\\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n[6\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n\\n# alicevillar/titanic-kaggle\\n\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n\\nmain\\n\\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\\n\\nGo to file\\n\\nCode\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\\n| ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\\n| ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\\n| View all files |\\n\\n## Repository files navigation\\n\\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n\\nThe objective of Kaggle\\'s Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\\n\\n### Quick Start:\\n\\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\\n\\n### Dependencies:\\n\\n- [Numpy](https://numpy.org/)\\n- [Pandas](https://pandas.pydata.org/)\\n- [SciKit-Learn](https://scikit-learn.org/)\\n- [Matplotlib](https://matplotlib.org/)\\n- [Seaborn](https://seaborn.pydata.org/)\\n\\n### Approach\\n\\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\\n\\n### Kaggle Competition \\\\| Titanic Machine Learning from Disaster\\n\\nKaggle\\'s challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle\\'s [Competition Page](https://www.kaggle.com/c/titanic):\\n\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\\n\\n### Results\\n\\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\\n\\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\\n\\n## About\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n### Topics\\n\\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\\n\\n### Resources\\n\\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\\n\\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n### Stars\\n\\n[**6**\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\\n\\n### Watchers\\n\\n[**1**\\\\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\\n\\n### Forks\\n\\n[**3**\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\\n\\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\\n\\n--- Result 4 ---\\nTitle: Search code, repositories, users, issues, pull requests...\\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\n\\nContent:\\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[Skip to content](#start-of-content)\\n## Navigation Menu\\nToggle navigation\\n[](https://github.com/)\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nSearch or jump to...\\n# Search code, repositories, users, issues, pull requests...\\n</option></form>\\nSearch\\nClear\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n# Provide feedback\\n</option></form>\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancelSubmit feedback\\n# Saved searches\\n## Use saved searches to filter your results more quickly\\n</option></form>\\nName\\nQuery\\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\nCancelCreate saved search\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nResetting focus\\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\\n{{ message }}\\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\nmain\\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\nGo to file\\nCode\\nOpen more actions menu\\n## Folders and files\\n|Name|Name|\\nLast commit message\\n|\\nLast commit date\\n|\\n## Latest commit\\n## History\\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n|\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n|\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n|\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n|\\n|\\nView all files\\n|\\n## Repository files navigation\\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\~72% to \\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n# Titanic Survival Prediction\\n[](#titanic-survival-prediction)\\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\\n* **Detailed EDA**\\nA Jupyter notebook that walks through exploratory data analysis:\\n* Summary statistics\\n* Missing-value patterns\\n* Feature distributions and pairwise relationships\\n* Correlation heatmaps\\n* **Feature Engineering**\\nCreation of high-signal features from raw inputs, including:\\n* `Has\\\\_Cabin`(binary cabin indicator)\\n* `FareBin`(quantile-based fare categories)\\n* Group-median imputation for`Age`, then 10-year age bins\\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\\n* `Title`extracted and consolidated from passenger names\\n* **Model Comparison**\\nTraining and evaluation of multiple classifiers on the engineered feature set:\\n* Random Forest\\n* Support Vector Machine\\n* K-Nearest Neighbors (k=3,5,7)\\n* XGBoost\\n* LightGBM\\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\\n* **Analysis &amp; Interpretation**\\nInline Markdown commentary explains:\\n* Why each feature matters\\n* How missing data were handled\\n* The rationale for model selection\\n* Key takeaways and next-step recommendations\\n## Repository Structure\\n[](#repository-structure)\\ndata/\\n* train.csv # Official Kaggle training set\\n* test.csv # Official Kaggle test set\\nnotebooks/\\n* titanic\\\\_analysis.ipynb\\n‚Ä¢EDA, feature engineering, model training\\n‚Ä¢Detailed Markdown analysis\\n* README.md # Project overview and instructions\\n## Contributing\\n[](#contributing)\\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\\n## About\\nPredict Titanic survival using t...\\n\\n--- Result 5 ---\\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\n\\nContent:\\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\\nAman Krishna\\n2022-04-20T07:23:42Z\\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\n\\n## The art of fine-tuning a model\\n\\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\\n\\n7 min read\\n\\n\\nApr 19, 2022\\n\\n\\nListen\\n\\nShare\\n\\nPress enter or click to view image in full size\\n\\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\\n\\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\\n\\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\\n\\nYou can find the complete code on Github **_:_**\\n\\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \\n\\n**Machine Learning model build for survivor prediction for Kaggle\\'s titanic competition - kaggle_titanic/Model‚Ä¶**\\n\\ngithub.com]\\n\\n## Which Model to use?\\n\\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\\n\\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\\n\\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\\n\\n## Pre-Requisite\\n\\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\\n\\n### Dropping Features\\n\\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\\n\\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\\n\\n### Code\\n\\n### Dummify Data\\n\\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\\n\\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\\n\\n**We will be using One-Hot encoding on our categorical features.**\\n\\n### Code\\n\\n### Split Data\\n\\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\\n\\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\\n\\n## Training\\n\\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\\n\\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\\n\\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\\n\\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\\n\\n### Code\\n\\n## Fine Tuning\\n\\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\\n\\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\\n\\n### Code\\n\\n### Output\\n\\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\\n\\nPress enter or click to view image in full size\\n\\nGrid Search Results\\n\\n## Refining Search Space: Max Depth & Max Samples\\n\\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\\n\\n### How?\\n\\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\\n\\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\\n\\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest max_Depth & max_samples\\n\\n## Fine Tune: Min Sample Split & Min Sample Leaf\\n\\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest min_samples_leaf & min_samples_split\\n\\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\\n\\n## Fine Tune: Number of Estimators\\n\\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest n_estimator value\\n\\n## Refining Search Space: Number of estima...\\n\\n--- Result 6 ---\\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\\n\\nContent:\\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\\n\\n--- Result 7 ---\\nTitle: Titanic - Machine Learning from Disaster\\nURL: https://www.kaggle.com/c/titanic/code\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \\n\\n[... truncated 11780 characters ...]'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! The search confirms that achieving 100% accuracy is essentially impossible without cheating (using external data). The realistic best scores are in the 80-86% range. Let me update the seed prompt with this important context and add more specific techniques.'}, {'role': 'tool', 'content': '‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\\n  Source: Web search - Kaggle Titanic best techniques'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"# Titanic Survival Prediction - Techniques Guide\\n\\n## Data Understanding\\n**Reference notebooks for data characteristics:**\\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\\n- Target is imbalanced: 61.6% died, 38.4% survived\\n\\n## Feature Engineering (Critical for High Accuracy)\\n\\n### Title Extraction from Name\\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)`\\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\\n- Title is highly predictive: Master (young boys) had high survival\\n\\n### Family Features\\n- **FamilySize** = SibSp + Parch + 1\\n- **IsAlone** = 1 if FamilySize == 1, else 0\\n- Family size affects survival: solo travelers and very large families had lower survival\\n\\n### Cabin Features\\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\\n- ~77% missing - use Has_Cabin binary flag\\n\\n### Fare and Age Binning\\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\\n- Binning helps tree models find splits\\n\\n### Name Length\\n- **Name_length** = len(Name) - can be proxy for social status\\n\\n### Ticket Features\\n- Ticket prefix extraction (some tickets have letter prefixes)\\n- Ticket frequency (shared tickets indicate traveling together)\\n\\n## Missing Value Handling\\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\\n- **Embarked**: Fill with mode ('S' - Southampton)\\n- **Fare**: Fill with median (by Pclass)\\n- **Cabin**: Create Has_Cabin flag, don't impute\\n\\n## Models\\n\\n### Single Models (Baseline)\\nFor this small tabular dataset, tree-based models work well:\\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\\n- **XGBoost**: Similar parameters, use early stopping\\n- **Extra Trees**: n_estimators=500, max_depth=6\\n- **Logistic Regression**: Good baseline, use regularization\\n\\n### Ensemble Approaches (Higher Accuracy)\\n\\n#### Voting Classifier\\nCombine multiple models with soft voting:\\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\\n- Use soft voting (probability-based) for better results\\n\\n#### Stacking (Best Approach)\\nTwo-level stacking architecture:\\n1. **First Level (Base Models)**: \\n   - Random Forest\\n   - Extra Trees\\n   - AdaBoost\\n   - Gradient Boosting\\n   - SVC (with probability=True)\\n   \\n2. **Second Level (Meta-Classifier)**:\\n   - XGBoost or Logistic Regression\\n   \\n3. **Out-of-Fold Predictions**:\\n   - Use K-Fold (K=5) to generate out-of-fold predictions\\n   - This prevents overfitting when training meta-classifier\\n   - Each base model generates predictions on held-out fold\\n   - Stack these predictions as features for meta-classifier\\n\\n## Validation Strategy\\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\\n- Small dataset (891 samples) - CV is critical to avoid overfitting\\n- Track both train and validation scores to detect overfitting\\n\\n## Hyperparameter Tuning\\n- Use GridSearchCV or RandomizedSearchCV\\n- Key parameters to tune:\\n  - Tree depth (max_depth): 3-8\\n  - Number of estimators: 100-1000\\n  - Learning rate (for boosting): 0.01-0.1\\n  - Min samples per leaf: 1-5\\n- Use cross-validation during tuning\\n\\n## Feature Selection\\n- Use Recursive Feature Elimination (RFE) with cross-validation\\n- Check feature importances from tree models\\n- Most important features typically: Sex, Title, Pclass, Fare, Age\\n\\n## Key Insights from Top Kernels\\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\\n3. Title extraction captures both sex and age information effectively\\n4. Family size has non-linear relationship with survival\\n5. Ensemble methods consistently outperform single models\\n\\n## Submission Strategy\\n- Generate predictions using best ensemble model\\n- Consider averaging predictions from multiple models\\n- Threshold at 0.5 for binary classification\\n- Format: PassengerId, Survived (0 or 1)\\n\"}]",
        "llm.input_tokens": 46030,
        "llm.output_tokens": 1902,
        "llm.total_tokens": 47932,
        "llm.latency_ms": 36125.97966194153,
        "llm.completion": "[Tool Use: Write]",
        "llm.cost_usd": 0.16662000000000002
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "5f70a2264c88c529",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "WriteTool",
      "kind": "INTERNAL",
      "start_time": 1767683663462200590,
      "end_time": 1767683663463198807,
      "duration": 0.000998217,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "WriteTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.file_tools.WriteTool object at 0x73eac37d9e90>\", \"input\": {\"file_path\": \"seed_prompt.txt\", \"content\": \"# Titanic Survival Prediction - Techniques Guide\\n\\n## Competition Context\\n- **Metric**: Accuracy (percentage of correct predictions)\\n- **Target**: Beat 1.0 (100% accuracy) - NOTE: This is essentially impossible with legitimate methods\\n- **Realistic expectations**: Top performers achieve 80-86% accuracy. Top 3% scores around 81-84%\\n- **Dataset size**: 891 train, 418 test - very small, requires careful regularization\\n\\n## Data Understanding\\n**Reference notebooks for data characteristics:**\\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\\n- Target is imbalanced: 61.6% died, 38.4% survived\\n\\n## Feature Engineering (Critical for High Accuracy)\\n\\nFeature engineering is the biggest driver of accuracy gains (can lift from ~72% to ~84%).\\n\\n### Title Extraction from Name (MOST IMPORTANT)\\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)`\\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\\n- Title is highly predictive: Master (young boys) had high survival\\n- Title captures both gender and age information in one feature\\n\\n### Family Features\\n- **FamilySize** = SibSp + Parch + 1\\n- **IsAlone** = 1 if FamilySize == 1, else 0\\n- Family size affects survival: solo travelers and very large families had lower survival\\n- Consider creating family size bins (1, 2-4, 5+)\\n\\n### Cabin Features\\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\\n- ~77% missing - use Has_Cabin binary flag primarily\\n\\n### Fare and Age Binning\\n- **FareBin**: Bin fare into quartiles using pd.qcut or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\\n- Binning helps tree models find splits\\n- Note: Some experiments show using raw Age/Fare directly works better than bins\\n\\n### Name Length\\n- **Name_length** = len(Name) - can be proxy for social status\\n\\n### Ticket Features\\n- Ticket prefix extraction (some tickets have letter prefixes)\\n- Ticket frequency (shared tickets indicate traveling together)\\n- Can one-hot encode ticket prefixes\\n\\n## Missing Value Handling\\n- **Age**: Fill with median (by Pclass and Sex for better accuracy) or use model-based imputation\\n- **Embarked**: Fill with mode ('S' - Southampton)\\n- **Fare**: Fill with median (by Pclass)\\n- **Cabin**: Create Has_Cabin flag, don't impute the actual cabin\\n\\n## Models\\n\\n### Single Models (Baseline)\\nFor this small tabular dataset, tree-based models work well:\\n- **Random Forest**: Best single model, typically achieves 84%+\\n  - n_estimators=500-1000, max_depth=6-19, min_samples_leaf=2, max_features='sqrt'\\n  - Fine-tune with GridSearchCV\\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\\n- **XGBoost/LightGBM**: Similar parameters, use early stopping\\n- **Extra Trees**: n_estimators=500, max_depth=6\\n- **Logistic Regression**: Good baseline, use regularization (C parameter)\\n- **SVC**: Can work well with proper kernel selection\\n\\n### Ensemble Approaches (Higher Accuracy)\\n\\n#### Voting Classifier\\nCombine multiple models with soft voting:\\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\\n- Use soft voting (probability-based) for better results\\n\\n#### Stacking (Best Approach for Top Scores)\\nTwo-level stacking architecture:\\n1. **First Level (Base Models)**: \\n   - Random Forest\\n   - Extra Trees\\n   - AdaBoost\\n   - Gradient Boosting\\n   - SVC (with probability=True)\\n   \\n2. **Second Level (Meta-Classifier)**:\\n   - XGBoost or Logistic Regression\\n   \\n3. **Out-of-Fold Predictions**:\\n   - Use K-Fold (K=5) to generate out-of-fold predictions\\n   - This prevents overfitting when training meta-classifier\\n   - Each base model generates predictions on held-out fold\\n   - Stack these predictions as features for meta-classifier\\n\\n## Validation Strategy\\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\\n- Small dataset (891 samples) - CV is critical to avoid overfitting\\n- Track both train and validation scores to detect overfitting\\n- If train accuracy >> validation accuracy, model is overfitting\\n\\n## Hyperparameter Tuning (Critical for Best Results)\\nUse GridSearchCV with stratified K-fold:\\n\\n### Random Forest Key Parameters:\\n- n_estimators: [200, 500, 1000, 2000, 5000]\\n- max_depth: [5, 10, 15, 19, 25]\\n- max_samples: [0.4, 0.5, 0.6]\\n- max_features: ['sqrt', 'auto', 'log2']\\n- min_samples_split: [2, 5, 10]\\n- min_samples_leaf: [1, 2, 4]\\n- criterion: ['gini', 'entropy']\\n\\n### Tuning Strategy:\\n1. Start with broad search on key parameters\\n2. Refine search space around best values\\n3. Fine-tune n_estimators last (more is generally better)\\n\\n## Feature Selection\\n- Use Recursive Feature Elimination (RFE) with cross-validation\\n- Check feature importances from tree models\\n- Most important features typically: Sex, Title, Pclass, Fare, Age\\n- Drop features with very low importance\\n\\n## Key Insights from Top Kernels\\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\\n3. Title extraction captures both sex and age information effectively\\n4. Family size has non-linear relationship with survival\\n5. Ensemble methods consistently outperform single models\\n6. Feature engineering matters more than model selection\\n\\n## Submission Strategy\\n- Generate predictions using best ensemble model\\n- Consider averaging predictions from multiple models\\n- Threshold at 0.5 for binary classification\\n- Format: PassengerId, Survived (0 or 1)\\n- Submit multiple variations to find best public leaderboard score\\n\\n## Common Pitfalls to Avoid\\n1. Overfitting to training data (use CV)\\n2. Data leakage (ensure test data preprocessing matches train)\\n3. Not handling missing values consistently between train/test\\n4. Using too many features without enough data\\n5. Not tuning hyperparameters\\n\"}}",
        "tool.output": "{\"content\": \"Wrote to /home/code/exploration/seed_prompt.txt\", \"is_error\": false}",
        "tool.duration_ms": 1.1017322540283203
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "c9600c28b7ab5950",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683664639895485,
      "end_time": 1767683670984193918,
      "duration": 6.344298433,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n\ntool: ‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\n  Source: exploration/eda.ipynb\ntool: ‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\n  Source: exploration/eda.ipynb\ntool: === MARKDOWN 23 ===\n## Analyze by visualizing data\n\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\n\n### Correlating numerical features\n\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\n\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \n\n=== MARKDOWN 25 ===\n### Correlating numerical and ordinal features\n\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n\n**Observations.**\n\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n- Pclass varies in terms of Age distribution of passengers.\n\n**Decisions\n\n=== MARKDOWN 27 ===\n### Correlating categorical features\n\nNow we can correlate categorical features with our solution goal.\n\n**Observations.**\n\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\n- Ports of embarkation have varying survival rates for Pcla\n\n=== MARKDOWN 29 ===\n### Correlating categorical and numerical features\n\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n\n**Observations.**\n\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n\n**Decisions.**\n\n- Consider banding Fare feature.\n\n=== MARKDOWN 31 ===\n## Wrangle data\n\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n\n### Correcting by dropping features\n\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\n\n\n=== MARKDOWN 33 ===\n### Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n\n**Observations.**\n\nWhen we plot Title, Age, and Survived, we note the following observations.\n\n- Most titles band Age groups accurately. For example: Master\n\n=== CODE 34 ===\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])\n\n=== MARKDOWN 35 ===\nWe can replace many titles with a more common name or classify them as `Rare`.\n\n=== CODE 36 ===\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n\n=== MARKDOWN 37 ===\nWe can convert the categorical titles to ordinal.\n\n=== CODE 38 ===\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()\n\n=== MARKDOWN 39 ===\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\n\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: === MARKDOWN 0 ===\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\n\n=== MARKDOWN 1 ===\n# Part 2: Your coding environment\n\nIn this section, you'll train your own machine learning model to improve your predictions.  _If you've never written code before or don't have any experience with machine learning, don't worry!  We don't assume any prior experience in this tutorial._\n\n## The Notebook\n\nThe first thing to do is to create a Kaggle Notebook where you'll store all of your code.  You c\n\n=== CODE 2 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data proc\n\n=== MARKDOWN 3 ===\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We'll do that next.\n\n## Load the data\n\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\n\n![](https://i.imgur.com/OQBax9n.png)\n\nType the two lines of code below into your second code cell.  Then, once you're done, either click on the blue pl\n\n=== CODE 4 ===\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()\n\n=== MARKDOWN 5 ===\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It's very important that you see this output **in your notebook** before proceeding with the tutorial!\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\n\n=== CODE 6 ===\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()\n\n=== MARKDOWN 7 ===\nAs before, make sure that you see the output above in your notebook before continuing.  \n\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\n\n# Part 3: Your first submission\n\n=== CODE 8 ===\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\n=== MARKDOWN 9 ===\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\n\nThen, run the code below in another code cell:\n\n=== CODE 10 ===\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)\n\n=== MARKDOWN 11 ===\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\n\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\n\nBut at the end of the day, this gender-based s\n\n=== CODE 12 ===\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.f\n\n=== MARKDOWN 13 ===\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\n> Again, don't worry if this code doesn't make sense to you!  For now, we'll focus on how to generate and submit predictions.\n\nOnce you're ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \n- Ensure tha\n\n=== MARKDOWN 14 ===\n# Part 4: Learn more!\n\nIf you're interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we've presented here.  You'll also know enough to generate even better predictions!\n\n\ntool: SEARCH RESULTS (9 found)\n==================================================\n\n--- Result 1 ---\nTitle: ANSWER\n\nContent:\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80‚ÄØ% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random‚ÄØForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n**Step‚Äëby‚Äëstep recipe**\n\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \n\n2. **Impute & create missing‚Äëvalue flags**  \n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1‚ÄØif Cabin not null, else‚ÄØ0).  \n   * Optionally encode the original *Cabin* letter as a categorical feature.  \n\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \n   * **FamilySize** = `SibSp + Parch + 1`  \n   * **IsAlone** = 1‚ÄØif *FamilySize*‚ÄØ=‚ÄØ1 else‚ÄØ0  \n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \n\n   These engineered columns lifted baseline scores from ~72‚ÄØ% to ~78‚ÄØ% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \n\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35‚ÄØ% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \n\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \n   * `n_estimators` (200‚Äë1000)  \n   * `max_depth` (5‚Äë15)  \n   * `min_samples_split` / `min_samples_leaf`  \n   * `max_features` (sqrt, log2, or a fraction)  \n\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100‚ÄØ% Accuracy‚Äù notebook placed the author in the top‚ÄØ3‚ÄØ%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \n\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•‚ÄØ0.84) before uploading.  \n\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\n\n--- Result 2 ---\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\n\nContent:\nSeptember 10, 2016¬†¬†¬†¬†¬†33min read\n\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\n\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\n\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I'm writing this post, I am ranked among the top 4% of all Kagglers.\n\nThis post is the opportunity to share my solution with you.\n\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I'll follow with feature engineering and finally present the predictive model I set up.\n\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\nThe main libraries involved in this tutorial are:\n\n- **Pandas** for data manipulation and ingestion\n- **Matplotlib** and **seaborn** for data visualization\n- **Numpy** for multidimensional array computing\n- **sklearn** for machine learning and predictive modeling\n\n### Installation procedure\n\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\n\n### Nota Bene\n\nThis is my first attempt as a blogger and as a machine learning practitioner.\n\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\n\nHope you've got everything set on your computer. Let's get started.\n\n## I - Exploratory data analysis\n\nAs in different data projects, we'll first start diving into the data and build up our first intuitions.\n\nIn this section, we'll be doing four things.\n\n- Data extraction : we'll load the dataset and have a first look at it.\n- Cleaning : we'll fill in missing values.\n- Plotting : we'll create some interesting charts that'll (hopefully) spot correlations and hidden insights out of the data.\n- Assumptions : we'll formulate hypotheses from the charts.\n\nWe tweak the style of this notebook a little bit to have centered plots.\n\n```\nfrom IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n</style>\n\"\"\");\n```\n\nWe import the useful libraries.\n\n```\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\nimport pandas as pd\npd.options.display.max_columns = 100\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimport seaborn as sns\n\nimport pylab as plot\nparams = {\n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n}\nplot.rcParams.update(params)\n```\n\nTwo datasets are available: a training set and a test set.\nWe'll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\n\nWe'll see how this procedure is done at the end of this post.\n\nNow let's start by loading the training set.\n\n```\ndata = pd.read_csv('./data/train.csv')\nprint(data.shape)\n#(891, 12)\n```\n\nWe have:\n\n- 891 rows\n- 12 columns\n\nPandas allows you to have a sneak peak at your data.\n\n```\ndata.head()\n```\n\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\n\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he's dead. The is the variable we're going to predict.\n\nThe other variables describe the passengers. They are the **features**.\n\n- PassengerId: and id given to each traveler on the boat\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\n- The Name of the passeger\n- The Sex\n- The Age\n- SibSp: number of siblings and spouses traveling with the passenger\n- Parch: number of parents and children traveling with the passenger\n- The ticket number\n- The ticket Fare\n- The cabin number\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\n\nPandas allows you to a have a high-level simple statistical description of the numerical features.\nThis can be done using the describe method.\n\n```\ndata.describe()\n```\n\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\n| --- | --- | --- | --- | --- | --- | --- |\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\n\nThe count variable shows that 177 values are missing in the Age column.\n\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\n\n```\ndata['Age'] = data['Age'].fillna(data['Age'].median())\n```\n\nLet's now make some charts.\n\nLet's visualize survival based on the gender.\n\n```\ndata['Died'] = 1 - data['Survived']\ndata.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                          stacked=True, colors=['g', 'r']);\n```\n\nIt looks like male passengers are more likely to succumb.\n\nLet's plot the same graph but with ratio instead.\n\n```\ndata.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                           stacked=True, colors=['g', 'r']);\n```\n\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\n\nLet's now correlate the survival with the age variable.\n\n```\nfig = plt.figure(figsize=(25, 7))\nsns.violinplot(x='Sex', y='Age',\n               hue='Survived', data=data,\n               split=True,\n               palette={0: \"r\", 1: \"g\"}\n              );\n```\n\nAs we saw in the chart above and validate by the following:\n\n- Women survive more than men, as depicted by the larger female green histogram\n\nNow, we see that:\n\n- The age conditions the survival for male passengers:\n\n  - Younger male tend to survive\n  - A large number of passengers between 20 and 40 succumb\n- The age doesn't seem to have a direct impact on the female survival\n\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\n\nRight?\n\nLet's now focus on the Fare ticket of each passenger and see how it could impact the survival.\n\n```\nfigure = plt.figure(figsize=(25, 7))\nplt.hist([dat...\n\n--- Result 3 ---\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\nURL: https://github.com/alicevillar/titanic-kaggle\n\nContent:\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n- [Fork\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n- [Star\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n[6\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n\n# alicevillar/titanic-kaggle\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmain\n\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\n| ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\n| ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n\nThe objective of Kaggle's Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\n\n### Quick Start:\n\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\n\n### Dependencies:\n\n- [Numpy](https://numpy.org/)\n- [Pandas](https://pandas.pydata.org/)\n- [SciKit-Learn](https://scikit-learn.org/)\n- [Matplotlib](https://matplotlib.org/)\n- [Seaborn](https://seaborn.pydata.org/)\n\n### Approach\n\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\n\n### Kaggle Competition \\| Titanic Machine Learning from Disaster\n\nKaggle's challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle's [Competition Page](https://www.kaggle.com/c/titanic):\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\n\n### Results\n\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\n\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\n\n## About\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n### Topics\n\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\n\n### Resources\n\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\n\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n### Stars\n\n[**6**\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\n\n### Watchers\n\n[**1**\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\n\n### Forks\n\n[**3**\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\n\n--- Result 4 ---\nTitle: Search code, repositories, users, issues, pull requests...\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\n\nContent:\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\nmain\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n|\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n|\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n|\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\~72% to \\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n# Titanic Survival Prediction\n[](#titanic-survival-prediction)\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\n* **Detailed EDA**\nA Jupyter notebook that walks through exploratory data analysis:\n* Summary statistics\n* Missing-value patterns\n* Feature distributions and pairwise relationships\n* Correlation heatmaps\n* **Feature Engineering**\nCreation of high-signal features from raw inputs, including:\n* `Has\\_Cabin`(binary cabin indicator)\n* `FareBin`(quantile-based fare categories)\n* Group-median imputation for`Age`, then 10-year age bins\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\n* `Title`extracted and consolidated from passenger names\n* **Model Comparison**\nTraining and evaluation of multiple classifiers on the engineered feature set:\n* Random Forest\n* Support Vector Machine\n* K-Nearest Neighbors (k=3,5,7)\n* XGBoost\n* LightGBM\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\n* **Analysis &amp; Interpretation**\nInline Markdown commentary explains:\n* Why each feature matters\n* How missing data were handled\n* The rationale for model selection\n* Key takeaways and next-step recommendations\n## Repository Structure\n[](#repository-structure)\ndata/\n* train.csv # Official Kaggle training set\n* test.csv # Official Kaggle test set\nnotebooks/\n* titanic\\_analysis.ipynb\n‚Ä¢EDA, feature engineering, model training\n‚Ä¢Detailed Markdown analysis\n* README.md # Project overview and instructions\n## Contributing\n[](#contributing)\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\n## About\nPredict Titanic survival using t...\n\n--- Result 5 ---\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\n\nContent:\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\nAman Krishna\n2022-04-20T07:23:42Z\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\n\n## The art of fine-tuning a model\n\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\n\n7 min read\n\n\nApr 19, 2022\n\n\nListen\n\nShare\n\nPress enter or click to view image in full size\n\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\n\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\n\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\n\nYou can find the complete code on Github **_:_**\n\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \n\n**Machine Learning model build for survivor prediction for Kaggle's titanic competition - kaggle_titanic/Model‚Ä¶**\n\ngithub.com]\n\n## Which Model to use?\n\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\n\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\n\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\n\n## Pre-Requisite\n\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\n\n### Dropping Features\n\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\n\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\n\n### Code\n\n### Dummify Data\n\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\n\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\n\n**We will be using One-Hot encoding on our categorical features.**\n\n### Code\n\n### Split Data\n\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\n\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\n\n## Training\n\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\n\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\n\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\n\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\n\n### Code\n\n## Fine Tuning\n\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\n\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\n\n### Code\n\n### Output\n\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\n\nPress enter or click to view image in full size\n\nGrid Search Results\n\n## Refining Search Space: Max Depth & Max Samples\n\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\n\n### How?\n\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\n\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\n\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest max_Depth & max_samples\n\n## Fine Tune: Min Sample Split & Min Sample Leaf\n\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest min_samples_leaf & min_samples_split\n\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\n\n## Fine Tune: Number of Estimators\n\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest n_estimator value\n\n## Refining Search Space: Number of estima...\n\n--- Result 6 ---\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\n\nContent:\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\n\n--- Result 7 ---\nTitle: Titanic - Machine Learning from Disaster\nURL: https://www.kaggle.com/c/titanic/code\n\nContent:\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \n\n[... truncated 11780 characters ...]\ntool: ‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\n  Source: Web search - Kaggle Titanic best techniques\ntool: # Titanic Survival Prediction - Techniques Guide\n\n## Data Understanding\n**Reference notebooks for data characteristics:**\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\n- Target is imbalanced: 61.6% died, 38.4% survived\n\n## Feature Engineering (Critical for High Accuracy)\n\n### Title Extraction from Name\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\.', expand=False)`\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\n- Title is highly predictive: Master (young boys) had high survival\n\n### Family Features\n- **FamilySize** = SibSp + Parch + 1\n- **IsAlone** = 1 if FamilySize == 1, else 0\n- Family size affects survival: solo travelers and very large families had lower survival\n\n### Cabin Features\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\n- ~77% missing - use Has_Cabin binary flag\n\n### Fare and Age Binning\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\n- Binning helps tree models find splits\n\n### Name Length\n- **Name_length** = len(Name) - can be proxy for social status\n\n### Ticket Features\n- Ticket prefix extraction (some tickets have letter prefixes)\n- Ticket frequency (shared tickets indicate traveling together)\n\n## Missing Value Handling\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\n- **Embarked**: Fill with mode ('S' - Southampton)\n- **Fare**: Fill with median (by Pclass)\n- **Cabin**: Create Has_Cabin flag, don't impute\n\n## Models\n\n### Single Models (Baseline)\nFor this small tabular dataset, tree-based models work well:\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\n- **XGBoost**: Similar parameters, use early stopping\n- **Extra Trees**: n_estimators=500, max_depth=6\n- **Logistic Regression**: Good baseline, use regularization\n\n### Ensemble Approaches (Higher Accuracy)\n\n#### Voting Classifier\nCombine multiple models with soft voting:\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n- Use soft voting (probability-based) for better results\n\n#### Stacking (Best Approach)\nTwo-level stacking architecture:\n1. **First Level (Base Models)**: \n   - Random Forest\n   - Extra Trees\n   - AdaBoost\n   - Gradient Boosting\n   - SVC (with probability=True)\n   \n2. **Second Level (Meta-Classifier)**:\n   - XGBoost or Logistic Regression\n   \n3. **Out-of-Fold Predictions**:\n   - Use K-Fold (K=5) to generate out-of-fold predictions\n   - This prevents overfitting when training meta-classifier\n   - Each base model generates predictions on held-out fold\n   - Stack these predictions as features for meta-classifier\n\n## Validation Strategy\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\n- Small dataset (891 samples) - CV is critical to avoid overfitting\n- Track both train and validation scores to detect overfitting\n\n## Hyperparameter Tuning\n- Use GridSearchCV or RandomizedSearchCV\n- Key parameters to tune:\n  - Tree depth (max_depth): 3-8\n  - Number of estimators: 100-1000\n  - Learning rate (for boosting): 0.01-0.1\n  - Min samples per leaf: 1-5\n- Use cross-validation during tuning\n\n## Feature Selection\n- Use Recursive Feature Elimination (RFE) with cross-validation\n- Check feature importances from tree models\n- Most important features typically: Sex, Title, Pclass, Fare, Age\n\n## Key Insights from Top Kernels\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\n3. Title extraction captures both sex and age information effectively\n4. Family size has non-linear relationship with survival\n5. Ensemble methods consistently outperform single models\n\n## Submission Strategy\n- Generate predictions using best ensemble model\n- Consider averaging predictions from multiple models\n- Threshold at 0.5 for binary classification\n- Format: PassengerId, Survived (0 or 1)\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb'}, {'role': 'tool', 'content': '‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb'}, {'role': 'assistant', 'content': 'REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.'}, {'role': 'tool', 'content': '=== MARKDOWN 23 ===\\n## Analyze by visualizing data\\n\\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n\\n### Correlating numerical features\\n\\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\\n\\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \\n\\n=== MARKDOWN 25 ===\\n### Correlating numerical and ordinal features\\n\\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n\\n**Observations.**\\n\\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n- Pclass varies in terms of Age distribution of passengers.\\n\\n**Decisions\\n\\n=== MARKDOWN 27 ===\\n### Correlating categorical features\\n\\nNow we can correlate categorical features with our solution goal.\\n\\n**Observations.**\\n\\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n- Ports of embarkation have varying survival rates for Pcla\\n\\n=== MARKDOWN 29 ===\\n### Correlating categorical and numerical features\\n\\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n\\n**Observations.**\\n\\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n\\n**Decisions.**\\n\\n- Consider banding Fare feature.\\n\\n=== MARKDOWN 31 ===\\n## Wrangle data\\n\\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n\\n### Correcting by dropping features\\n\\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n\\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n\\n\\n=== MARKDOWN 33 ===\\n### Creating new feature extracting from existing\\n\\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n\\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n\\n**Observations.**\\n\\nWhen we plot Title, Age, and Survived, we note the following observations.\\n\\n- Most titles band Age groups accurately. For example: Master\\n\\n=== CODE 34 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset.Name.str.extract(\\' ([A-Za-z]+)\\\\.\\', expand=False)\\n\\npd.crosstab(train_df[\\'Title\\'], train_df[\\'Sex\\'])\\n\\n=== MARKDOWN 35 ===\\nWe can replace many titles with a more common name or classify them as `Rare`.\\n\\n=== CODE 36 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace([\\'Lady\\', \\'Countess\\',\\'Capt\\', \\'Col\\',\\\\\\n \\t\\'Don\\', \\'Dr\\', \\'Major\\', \\'Rev\\', \\'Sir\\', \\'Jonkheer\\', \\'Dona\\'], \\'Rare\\')\\n\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mlle\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Ms\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mme\\', \\'Mrs\\')\\n    \\ntrain_df[[\\'Title\\', \\'Survived\\']].groupby([\\'Title\\'], as_index=False).mean()\\n\\n=== MARKDOWN 37 ===\\nWe can convert the categorical titles to ordinal.\\n\\n=== CODE 38 ===\\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].map(title_mapping)\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].fillna(0)\\n\\ntrain_df.head()\\n\\n=== MARKDOWN 39 ===\\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now I have comprehensive information. Let me write the seed prompt with all the techniques I've learned.\"}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': 'REASONING: Now let me check if there are any additional techniques in the Alexis Cook tutorial that might be helpful, and also search for any advanced techniques that could help beat the 1.0 target score (which is 100% accuracy - extremely challenging).'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\\n\\n=== MARKDOWN 1 ===\\n# Part 2: Your coding environment\\n\\nIn this section, you\\'ll train your own machine learning model to improve your predictions.  _If you\\'ve never written code before or don\\'t have any experience with machine learning, don\\'t worry!  We don\\'t assume any prior experience in this tutorial._\\n\\n## The Notebook\\n\\nThe first thing to do is to create a Kaggle Notebook where you\\'ll store all of your code.  You c\\n\\n=== CODE 2 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load in \\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data proc\\n\\n=== MARKDOWN 3 ===\\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We\\'ll do that next.\\n\\n## Load the data\\n\\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\\n\\n![](https://i.imgur.com/OQBax9n.png)\\n\\nType the two lines of code below into your second code cell.  Then, once you\\'re done, either click on the blue pl\\n\\n=== CODE 4 ===\\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntrain_data.head()\\n\\n=== MARKDOWN 5 ===\\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It\\'s very important that you see this output **in your notebook** before proceeding with the tutorial!\\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\\n\\n=== CODE 6 ===\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\\ntest_data.head()\\n\\n=== MARKDOWN 7 ===\\nAs before, make sure that you see the output above in your notebook before continuing.  \\n\\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\\n\\n# Part 3: Your first submission\\n\\n=== CODE 8 ===\\nwomen = train_data.loc[train_data.Sex == \\'female\\'][\"Survived\"]\\nrate_women = sum(women)/len(women)\\n\\nprint(\"% of women who survived:\", rate_women)\\n\\n=== MARKDOWN 9 ===\\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\\n\\nThen, run the code below in another code cell:\\n\\n=== CODE 10 ===\\nmen = train_data.loc[train_data.Sex == \\'male\\'][\"Survived\"]\\nrate_men = sum(men)/len(men)\\n\\nprint(\"% of men who survived:\", rate_men)\\n\\n=== MARKDOWN 11 ===\\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\\n\\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\\n\\nBut at the end of the day, this gender-based s\\n\\n=== CODE 12 ===\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\\nX = pd.get_dummies(train_data[features])\\nX_test = pd.get_dummies(test_data[features])\\n\\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\\nmodel.f\\n\\n=== MARKDOWN 13 ===\\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\\n> Again, don\\'t worry if this code doesn\\'t make sense to you!  For now, we\\'ll focus on how to generate and submit predictions.\\n\\nOnce you\\'re ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \\n- Ensure tha\\n\\n=== MARKDOWN 14 ===\\n# Part 4: Learn more!\\n\\nIf you\\'re interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we\\'ve presented here.  You\\'ll also know enough to generate even better predictions!\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: The tutorial is basic. Let me search for advanced techniques that could help achieve very high accuracy on this problem, particularly since the target is 100% accuracy which is extremely challenging.'}, {'role': 'tool', 'content': 'SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80\\u202f% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random\\u202fForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n**Step‚Äëby‚Äëstep recipe**\\n\\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \\n\\n2. **Impute & create missing‚Äëvalue flags**  \\n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \\n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1\\u202fif Cabin not null, else\\u202f0).  \\n   * Optionally encode the original *Cabin* letter as a categorical feature.  \\n\\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \\n   * **FamilySize** = `SibSp + Parch + 1`  \\n   * **IsAlone** = 1\\u202fif *FamilySize*\\u202f=\\u202f1 else\\u202f0  \\n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \\n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \\n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \\n\\n   These engineered columns lifted baseline scores from ~72\\u202f% to ~78\\u202f% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \\n\\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35\\u202f% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \\n\\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \\n   * `n_estimators` (200‚Äë1000)  \\n   * `max_depth` (5‚Äë15)  \\n   * `min_samples_split` / `min_samples_leaf`  \\n   * `max_features` (sqrt, log2, or a fraction)  \\n\\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100\\u202f% Accuracy‚Äù notebook placed the author in the top\\u202f3\\u202f%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \\n\\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•\\u202f0.84) before uploading.  \\n\\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\\n\\n--- Result 2 ---\\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\\n\\nContent:\\nSeptember 10, 2016\\xa0\\xa0\\xa0\\xa0\\xa033min read\\n\\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\\n\\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\\n\\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I\\'m writing this post, I am ranked among the top 4% of all Kagglers.\\n\\nThis post is the opportunity to share my solution with you.\\n\\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I\\'ll follow with feature engineering and finally present the predictive model I set up.\\n\\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\\nThe main libraries involved in this tutorial are:\\n\\n- **Pandas** for data manipulation and ingestion\\n- **Matplotlib** and **seaborn** for data visualization\\n- **Numpy** for multidimensional array computing\\n- **sklearn** for machine learning and predictive modeling\\n\\n### Installation procedure\\n\\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\\n\\n### Nota Bene\\n\\nThis is my first attempt as a blogger and as a machine learning practitioner.\\n\\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\\n\\nHope you\\'ve got everything set on your computer. Let\\'s get started.\\n\\n## I - Exploratory data analysis\\n\\nAs in different data projects, we\\'ll first start diving into the data and build up our first intuitions.\\n\\nIn this section, we\\'ll be doing four things.\\n\\n- Data extraction : we\\'ll load the dataset and have a first look at it.\\n- Cleaning : we\\'ll fill in missing values.\\n- Plotting : we\\'ll create some interesting charts that\\'ll (hopefully) spot correlations and hidden insights out of the data.\\n- Assumptions : we\\'ll formulate hypotheses from the charts.\\n\\nWe tweak the style of this notebook a little bit to have centered plots.\\n\\n```\\nfrom IPython.core.display import HTML\\nHTML(\"\"\"\\n<style>\\n.output_png {\\n    display: table-cell;\\n    text-align: center;\\n    vertical-align: middle;\\n}\\n</style>\\n\"\"\");\\n```\\n\\nWe import the useful libraries.\\n\\n```\\n%matplotlib inline\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\nwarnings.filterwarnings(\\'ignore\\', category=DeprecationWarning)\\n\\nimport pandas as pd\\npd.options.display.max_columns = 100\\n\\nfrom matplotlib import pyplot as plt\\nimport numpy as np\\n\\nimport seaborn as sns\\n\\nimport pylab as plot\\nparams = {\\n    \\'axes.labelsize\\': \"large\",\\n    \\'xtick.labelsize\\': \\'x-large\\',\\n    \\'legend.fontsize\\': 20,\\n    \\'figure.dpi\\': 150,\\n    \\'figure.figsize\\': [25, 7]\\n}\\nplot.rcParams.update(params)\\n```\\n\\nTwo datasets are available: a training set and a test set.\\nWe\\'ll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\\n\\nWe\\'ll see how this procedure is done at the end of this post.\\n\\nNow let\\'s start by loading the training set.\\n\\n```\\ndata = pd.read_csv(\\'./data/train.csv\\')\\nprint(data.shape)\\n#(891, 12)\\n```\\n\\nWe have:\\n\\n- 891 rows\\n- 12 columns\\n\\nPandas allows you to have a sneak peak at your data.\\n\\n```\\ndata.head()\\n```\\n\\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\\n\\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he\\'s dead. The is the variable we\\'re going to predict.\\n\\nThe other variables describe the passengers. They are the **features**.\\n\\n- PassengerId: and id given to each traveler on the boat\\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\\n- The Name of the passeger\\n- The Sex\\n- The Age\\n- SibSp: number of siblings and spouses traveling with the passenger\\n- Parch: number of parents and children traveling with the passenger\\n- The ticket number\\n- The ticket Fare\\n- The cabin number\\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\\n\\nPandas allows you to a have a high-level simple statistical description of the numerical features.\\nThis can be done using the describe method.\\n\\n```\\ndata.describe()\\n```\\n\\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\\n\\nThe count variable shows that 177 values are missing in the Age column.\\n\\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\\n\\n```\\ndata[\\'Age\\'] = data[\\'Age\\'].fillna(data[\\'Age\\'].median())\\n```\\n\\nLet\\'s now make some charts.\\n\\nLet\\'s visualize survival based on the gender.\\n\\n```\\ndata[\\'Died\\'] = 1 - data[\\'Survived\\']\\ndata.groupby(\\'Sex\\').agg(\\'sum\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                          stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nIt looks like male passengers are more likely to succumb.\\n\\nLet\\'s plot the same graph but with ratio instead.\\n\\n```\\ndata.groupby(\\'Sex\\').agg(\\'mean\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                           stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\\n\\nLet\\'s now correlate the survival with the age variable.\\n\\n```\\nfig = plt.figure(figsize=(25, 7))\\nsns.violinplot(x=\\'Sex\\', y=\\'Age\\',\\n               hue=\\'Survived\\', data=data,\\n               split=True,\\n               palette={0: \"r\", 1: \"g\"}\\n              );\\n```\\n\\nAs we saw in the chart above and validate by the following:\\n\\n- Women survive more than men, as depicted by the larger female green histogram\\n\\nNow, we see that:\\n\\n- The age conditions the survival for male passengers:\\n\\n  - Younger male tend to survive\\n  - A large number of passengers between 20 and 40 succumb\\n- The age doesn\\'t seem to have a direct impact on the female survival\\n\\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\\n\\nRight?\\n\\nLet\\'s now focus on the Fare ticket of each passenger and see how it could impact the survival.\\n\\n```\\nfigure = plt.figure(figsize=(25, 7))\\nplt.hist([dat...\\n\\n--- Result 3 ---\\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\nURL: https://github.com/alicevillar/titanic-kaggle\\n\\nContent:\\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\\n\\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\\n\\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n- [Fork\\\\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n- [Star\\\\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n[6\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n\\n# alicevillar/titanic-kaggle\\n\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n\\nmain\\n\\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\\n\\nGo to file\\n\\nCode\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\\n| ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\\n| ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\\n| View all files |\\n\\n## Repository files navigation\\n\\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n\\nThe objective of Kaggle\\'s Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\\n\\n### Quick Start:\\n\\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\\n\\n### Dependencies:\\n\\n- [Numpy](https://numpy.org/)\\n- [Pandas](https://pandas.pydata.org/)\\n- [SciKit-Learn](https://scikit-learn.org/)\\n- [Matplotlib](https://matplotlib.org/)\\n- [Seaborn](https://seaborn.pydata.org/)\\n\\n### Approach\\n\\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\\n\\n### Kaggle Competition \\\\| Titanic Machine Learning from Disaster\\n\\nKaggle\\'s challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle\\'s [Competition Page](https://www.kaggle.com/c/titanic):\\n\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\\n\\n### Results\\n\\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\\n\\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\\n\\n## About\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n### Topics\\n\\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\\n\\n### Resources\\n\\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\\n\\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n### Stars\\n\\n[**6**\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\\n\\n### Watchers\\n\\n[**1**\\\\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\\n\\n### Forks\\n\\n[**3**\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\\n\\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\\n\\n--- Result 4 ---\\nTitle: Search code, repositories, users, issues, pull requests...\\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\n\\nContent:\\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[Skip to content](#start-of-content)\\n## Navigation Menu\\nToggle navigation\\n[](https://github.com/)\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nSearch or jump to...\\n# Search code, repositories, users, issues, pull requests...\\n</option></form>\\nSearch\\nClear\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n# Provide feedback\\n</option></form>\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancelSubmit feedback\\n# Saved searches\\n## Use saved searches to filter your results more quickly\\n</option></form>\\nName\\nQuery\\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\nCancelCreate saved search\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nResetting focus\\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\\n{{ message }}\\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\nmain\\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\nGo to file\\nCode\\nOpen more actions menu\\n## Folders and files\\n|Name|Name|\\nLast commit message\\n|\\nLast commit date\\n|\\n## Latest commit\\n## History\\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n|\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n|\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n|\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n|\\n|\\nView all files\\n|\\n## Repository files navigation\\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\~72% to \\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n# Titanic Survival Prediction\\n[](#titanic-survival-prediction)\\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\\n* **Detailed EDA**\\nA Jupyter notebook that walks through exploratory data analysis:\\n* Summary statistics\\n* Missing-value patterns\\n* Feature distributions and pairwise relationships\\n* Correlation heatmaps\\n* **Feature Engineering**\\nCreation of high-signal features from raw inputs, including:\\n* `Has\\\\_Cabin`(binary cabin indicator)\\n* `FareBin`(quantile-based fare categories)\\n* Group-median imputation for`Age`, then 10-year age bins\\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\\n* `Title`extracted and consolidated from passenger names\\n* **Model Comparison**\\nTraining and evaluation of multiple classifiers on the engineered feature set:\\n* Random Forest\\n* Support Vector Machine\\n* K-Nearest Neighbors (k=3,5,7)\\n* XGBoost\\n* LightGBM\\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\\n* **Analysis &amp; Interpretation**\\nInline Markdown commentary explains:\\n* Why each feature matters\\n* How missing data were handled\\n* The rationale for model selection\\n* Key takeaways and next-step recommendations\\n## Repository Structure\\n[](#repository-structure)\\ndata/\\n* train.csv # Official Kaggle training set\\n* test.csv # Official Kaggle test set\\nnotebooks/\\n* titanic\\\\_analysis.ipynb\\n‚Ä¢EDA, feature engineering, model training\\n‚Ä¢Detailed Markdown analysis\\n* README.md # Project overview and instructions\\n## Contributing\\n[](#contributing)\\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\\n## About\\nPredict Titanic survival using t...\\n\\n--- Result 5 ---\\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\n\\nContent:\\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\\nAman Krishna\\n2022-04-20T07:23:42Z\\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\n\\n## The art of fine-tuning a model\\n\\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\\n\\n7 min read\\n\\n\\nApr 19, 2022\\n\\n\\nListen\\n\\nShare\\n\\nPress enter or click to view image in full size\\n\\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\\n\\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\\n\\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\\n\\nYou can find the complete code on Github **_:_**\\n\\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \\n\\n**Machine Learning model build for survivor prediction for Kaggle\\'s titanic competition - kaggle_titanic/Model‚Ä¶**\\n\\ngithub.com]\\n\\n## Which Model to use?\\n\\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\\n\\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\\n\\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\\n\\n## Pre-Requisite\\n\\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\\n\\n### Dropping Features\\n\\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\\n\\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\\n\\n### Code\\n\\n### Dummify Data\\n\\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\\n\\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\\n\\n**We will be using One-Hot encoding on our categorical features.**\\n\\n### Code\\n\\n### Split Data\\n\\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\\n\\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\\n\\n## Training\\n\\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\\n\\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\\n\\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\\n\\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\\n\\n### Code\\n\\n## Fine Tuning\\n\\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\\n\\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\\n\\n### Code\\n\\n### Output\\n\\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\\n\\nPress enter or click to view image in full size\\n\\nGrid Search Results\\n\\n## Refining Search Space: Max Depth & Max Samples\\n\\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\\n\\n### How?\\n\\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\\n\\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\\n\\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest max_Depth & max_samples\\n\\n## Fine Tune: Min Sample Split & Min Sample Leaf\\n\\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest min_samples_leaf & min_samples_split\\n\\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\\n\\n## Fine Tune: Number of Estimators\\n\\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest n_estimator value\\n\\n## Refining Search Space: Number of estima...\\n\\n--- Result 6 ---\\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\\n\\nContent:\\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\\n\\n--- Result 7 ---\\nTitle: Titanic - Machine Learning from Disaster\\nURL: https://www.kaggle.com/c/titanic/code\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \\n\\n[... truncated 11780 characters ...]'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! The search confirms that achieving 100% accuracy is essentially impossible without cheating (using external data). The realistic best scores are in the 80-86% range. Let me update the seed prompt with this important context and add more specific techniques.'}, {'role': 'tool', 'content': '‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\\n  Source: Web search - Kaggle Titanic best techniques'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"# Titanic Survival Prediction - Techniques Guide\\n\\n## Data Understanding\\n**Reference notebooks for data characteristics:**\\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\\n- Target is imbalanced: 61.6% died, 38.4% survived\\n\\n## Feature Engineering (Critical for High Accuracy)\\n\\n### Title Extraction from Name\\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)`\\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\\n- Title is highly predictive: Master (young boys) had high survival\\n\\n### Family Features\\n- **FamilySize** = SibSp + Parch + 1\\n- **IsAlone** = 1 if FamilySize == 1, else 0\\n- Family size affects survival: solo travelers and very large families had lower survival\\n\\n### Cabin Features\\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\\n- ~77% missing - use Has_Cabin binary flag\\n\\n### Fare and Age Binning\\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\\n- Binning helps tree models find splits\\n\\n### Name Length\\n- **Name_length** = len(Name) - can be proxy for social status\\n\\n### Ticket Features\\n- Ticket prefix extraction (some tickets have letter prefixes)\\n- Ticket frequency (shared tickets indicate traveling together)\\n\\n## Missing Value Handling\\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\\n- **Embarked**: Fill with mode ('S' - Southampton)\\n- **Fare**: Fill with median (by Pclass)\\n- **Cabin**: Create Has_Cabin flag, don't impute\\n\\n## Models\\n\\n### Single Models (Baseline)\\nFor this small tabular dataset, tree-based models work well:\\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\\n- **XGBoost**: Similar parameters, use early stopping\\n- **Extra Trees**: n_estimators=500, max_depth=6\\n- **Logistic Regression**: Good baseline, use regularization\\n\\n### Ensemble Approaches (Higher Accuracy)\\n\\n#### Voting Classifier\\nCombine multiple models with soft voting:\\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\\n- Use soft voting (probability-based) for better results\\n\\n#### Stacking (Best Approach)\\nTwo-level stacking architecture:\\n1. **First Level (Base Models)**: \\n   - Random Forest\\n   - Extra Trees\\n   - AdaBoost\\n   - Gradient Boosting\\n   - SVC (with probability=True)\\n   \\n2. **Second Level (Meta-Classifier)**:\\n   - XGBoost or Logistic Regression\\n   \\n3. **Out-of-Fold Predictions**:\\n   - Use K-Fold (K=5) to generate out-of-fold predictions\\n   - This prevents overfitting when training meta-classifier\\n   - Each base model generates predictions on held-out fold\\n   - Stack these predictions as features for meta-classifier\\n\\n## Validation Strategy\\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\\n- Small dataset (891 samples) - CV is critical to avoid overfitting\\n- Track both train and validation scores to detect overfitting\\n\\n## Hyperparameter Tuning\\n- Use GridSearchCV or RandomizedSearchCV\\n- Key parameters to tune:\\n  - Tree depth (max_depth): 3-8\\n  - Number of estimators: 100-1000\\n  - Learning rate (for boosting): 0.01-0.1\\n  - Min samples per leaf: 1-5\\n- Use cross-validation during tuning\\n\\n## Feature Selection\\n- Use Recursive Feature Elimination (RFE) with cross-validation\\n- Check feature importances from tree models\\n- Most important features typically: Sex, Title, Pclass, Fare, Age\\n\\n## Key Insights from Top Kernels\\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\\n3. Title extraction captures both sex and age information effectively\\n4. Family size has non-linear relationship with survival\\n5. Ensemble methods consistently outperform single models\\n\\n## Submission Strategy\\n- Generate predictions using best ensemble model\\n- Consider averaging predictions from multiple models\\n- Threshold at 0.5 for binary classification\\n- Format: PassengerId, Survived (0 or 1)\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}]",
        "llm.input_tokens": 47959,
        "llm.output_tokens": 209,
        "llm.total_tokens": 48168,
        "llm.latency_ms": 6344.309568405151,
        "llm.completion": "REASONING: Let me add a few more cells to the EDA notebook to explore Title extraction and family size patterns, which are key features. Then I'll finalize the seed prompt.\n[Tool Use: AddNotebookCell]",
        "llm.reasoning": "REASONING: Let me add a few more cells to the EDA notebook to explore Title extraction and family size patterns, which are key features. Then I'll finalize the seed prompt.",
        "llm.cost_usd": 0.147012
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "1b8ff16360a6dbed",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "AddNotebookCellTool",
      "kind": "INTERNAL",
      "start_time": 1767683670984451147,
      "end_time": 1767683670986686544,
      "duration": 0.002235397,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "AddNotebookCellTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x73eac37f4d50>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Extract Title from Name\\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\\nprint('Title distribution:')\\nprint(train['Title'].value_counts())\\nprint('\\\\nSurvival by Title:')\\nprint(train.groupby('Title')['Survived'].agg(['mean', 'count']).sort_values('count', ascending=False))\"}}",
        "tool.output": "{\"content\": \"Added code cell at 3\", \"is_error\": false}",
        "tool.duration_ms": 2.265453338623047
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "238c68db14263055",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683672236826261,
      "end_time": 1767683676123740203,
      "duration": 3.886913942,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n\ntool: ‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\n  Source: exploration/eda.ipynb\ntool: ‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\n  Source: exploration/eda.ipynb\ntool: === MARKDOWN 23 ===\n## Analyze by visualizing data\n\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\n\n### Correlating numerical features\n\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\n\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \n\n=== MARKDOWN 25 ===\n### Correlating numerical and ordinal features\n\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n\n**Observations.**\n\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n- Pclass varies in terms of Age distribution of passengers.\n\n**Decisions\n\n=== MARKDOWN 27 ===\n### Correlating categorical features\n\nNow we can correlate categorical features with our solution goal.\n\n**Observations.**\n\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\n- Ports of embarkation have varying survival rates for Pcla\n\n=== MARKDOWN 29 ===\n### Correlating categorical and numerical features\n\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n\n**Observations.**\n\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n\n**Decisions.**\n\n- Consider banding Fare feature.\n\n=== MARKDOWN 31 ===\n## Wrangle data\n\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n\n### Correcting by dropping features\n\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\n\n\n=== MARKDOWN 33 ===\n### Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n\n**Observations.**\n\nWhen we plot Title, Age, and Survived, we note the following observations.\n\n- Most titles band Age groups accurately. For example: Master\n\n=== CODE 34 ===\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])\n\n=== MARKDOWN 35 ===\nWe can replace many titles with a more common name or classify them as `Rare`.\n\n=== CODE 36 ===\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n\n=== MARKDOWN 37 ===\nWe can convert the categorical titles to ordinal.\n\n=== CODE 38 ===\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()\n\n=== MARKDOWN 39 ===\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\n\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: === MARKDOWN 0 ===\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\n\n=== MARKDOWN 1 ===\n# Part 2: Your coding environment\n\nIn this section, you'll train your own machine learning model to improve your predictions.  _If you've never written code before or don't have any experience with machine learning, don't worry!  We don't assume any prior experience in this tutorial._\n\n## The Notebook\n\nThe first thing to do is to create a Kaggle Notebook where you'll store all of your code.  You c\n\n=== CODE 2 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data proc\n\n=== MARKDOWN 3 ===\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We'll do that next.\n\n## Load the data\n\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\n\n![](https://i.imgur.com/OQBax9n.png)\n\nType the two lines of code below into your second code cell.  Then, once you're done, either click on the blue pl\n\n=== CODE 4 ===\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()\n\n=== MARKDOWN 5 ===\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It's very important that you see this output **in your notebook** before proceeding with the tutorial!\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\n\n=== CODE 6 ===\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()\n\n=== MARKDOWN 7 ===\nAs before, make sure that you see the output above in your notebook before continuing.  \n\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\n\n# Part 3: Your first submission\n\n=== CODE 8 ===\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\n=== MARKDOWN 9 ===\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\n\nThen, run the code below in another code cell:\n\n=== CODE 10 ===\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)\n\n=== MARKDOWN 11 ===\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\n\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\n\nBut at the end of the day, this gender-based s\n\n=== CODE 12 ===\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.f\n\n=== MARKDOWN 13 ===\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\n> Again, don't worry if this code doesn't make sense to you!  For now, we'll focus on how to generate and submit predictions.\n\nOnce you're ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \n- Ensure tha\n\n=== MARKDOWN 14 ===\n# Part 4: Learn more!\n\nIf you're interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we've presented here.  You'll also know enough to generate even better predictions!\n\n\ntool: SEARCH RESULTS (9 found)\n==================================================\n\n--- Result 1 ---\nTitle: ANSWER\n\nContent:\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80‚ÄØ% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random‚ÄØForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n**Step‚Äëby‚Äëstep recipe**\n\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \n\n2. **Impute & create missing‚Äëvalue flags**  \n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1‚ÄØif Cabin not null, else‚ÄØ0).  \n   * Optionally encode the original *Cabin* letter as a categorical feature.  \n\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \n   * **FamilySize** = `SibSp + Parch + 1`  \n   * **IsAlone** = 1‚ÄØif *FamilySize*‚ÄØ=‚ÄØ1 else‚ÄØ0  \n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \n\n   These engineered columns lifted baseline scores from ~72‚ÄØ% to ~78‚ÄØ% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \n\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35‚ÄØ% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \n\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \n   * `n_estimators` (200‚Äë1000)  \n   * `max_depth` (5‚Äë15)  \n   * `min_samples_split` / `min_samples_leaf`  \n   * `max_features` (sqrt, log2, or a fraction)  \n\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100‚ÄØ% Accuracy‚Äù notebook placed the author in the top‚ÄØ3‚ÄØ%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \n\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•‚ÄØ0.84) before uploading.  \n\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\n\n--- Result 2 ---\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\n\nContent:\nSeptember 10, 2016¬†¬†¬†¬†¬†33min read\n\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\n\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\n\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I'm writing this post, I am ranked among the top 4% of all Kagglers.\n\nThis post is the opportunity to share my solution with you.\n\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I'll follow with feature engineering and finally present the predictive model I set up.\n\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\nThe main libraries involved in this tutorial are:\n\n- **Pandas** for data manipulation and ingestion\n- **Matplotlib** and **seaborn** for data visualization\n- **Numpy** for multidimensional array computing\n- **sklearn** for machine learning and predictive modeling\n\n### Installation procedure\n\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\n\n### Nota Bene\n\nThis is my first attempt as a blogger and as a machine learning practitioner.\n\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\n\nHope you've got everything set on your computer. Let's get started.\n\n## I - Exploratory data analysis\n\nAs in different data projects, we'll first start diving into the data and build up our first intuitions.\n\nIn this section, we'll be doing four things.\n\n- Data extraction : we'll load the dataset and have a first look at it.\n- Cleaning : we'll fill in missing values.\n- Plotting : we'll create some interesting charts that'll (hopefully) spot correlations and hidden insights out of the data.\n- Assumptions : we'll formulate hypotheses from the charts.\n\nWe tweak the style of this notebook a little bit to have centered plots.\n\n```\nfrom IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n</style>\n\"\"\");\n```\n\nWe import the useful libraries.\n\n```\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\nimport pandas as pd\npd.options.display.max_columns = 100\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimport seaborn as sns\n\nimport pylab as plot\nparams = {\n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n}\nplot.rcParams.update(params)\n```\n\nTwo datasets are available: a training set and a test set.\nWe'll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\n\nWe'll see how this procedure is done at the end of this post.\n\nNow let's start by loading the training set.\n\n```\ndata = pd.read_csv('./data/train.csv')\nprint(data.shape)\n#(891, 12)\n```\n\nWe have:\n\n- 891 rows\n- 12 columns\n\nPandas allows you to have a sneak peak at your data.\n\n```\ndata.head()\n```\n\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\n\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he's dead. The is the variable we're going to predict.\n\nThe other variables describe the passengers. They are the **features**.\n\n- PassengerId: and id given to each traveler on the boat\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\n- The Name of the passeger\n- The Sex\n- The Age\n- SibSp: number of siblings and spouses traveling with the passenger\n- Parch: number of parents and children traveling with the passenger\n- The ticket number\n- The ticket Fare\n- The cabin number\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\n\nPandas allows you to a have a high-level simple statistical description of the numerical features.\nThis can be done using the describe method.\n\n```\ndata.describe()\n```\n\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\n| --- | --- | --- | --- | --- | --- | --- |\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\n\nThe count variable shows that 177 values are missing in the Age column.\n\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\n\n```\ndata['Age'] = data['Age'].fillna(data['Age'].median())\n```\n\nLet's now make some charts.\n\nLet's visualize survival based on the gender.\n\n```\ndata['Died'] = 1 - data['Survived']\ndata.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                          stacked=True, colors=['g', 'r']);\n```\n\nIt looks like male passengers are more likely to succumb.\n\nLet's plot the same graph but with ratio instead.\n\n```\ndata.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                           stacked=True, colors=['g', 'r']);\n```\n\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\n\nLet's now correlate the survival with the age variable.\n\n```\nfig = plt.figure(figsize=(25, 7))\nsns.violinplot(x='Sex', y='Age',\n               hue='Survived', data=data,\n               split=True,\n               palette={0: \"r\", 1: \"g\"}\n              );\n```\n\nAs we saw in the chart above and validate by the following:\n\n- Women survive more than men, as depicted by the larger female green histogram\n\nNow, we see that:\n\n- The age conditions the survival for male passengers:\n\n  - Younger male tend to survive\n  - A large number of passengers between 20 and 40 succumb\n- The age doesn't seem to have a direct impact on the female survival\n\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\n\nRight?\n\nLet's now focus on the Fare ticket of each passenger and see how it could impact the survival.\n\n```\nfigure = plt.figure(figsize=(25, 7))\nplt.hist([dat...\n\n--- Result 3 ---\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\nURL: https://github.com/alicevillar/titanic-kaggle\n\nContent:\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n- [Fork\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n- [Star\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n[6\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n\n# alicevillar/titanic-kaggle\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmain\n\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\n| ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\n| ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n\nThe objective of Kaggle's Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\n\n### Quick Start:\n\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\n\n### Dependencies:\n\n- [Numpy](https://numpy.org/)\n- [Pandas](https://pandas.pydata.org/)\n- [SciKit-Learn](https://scikit-learn.org/)\n- [Matplotlib](https://matplotlib.org/)\n- [Seaborn](https://seaborn.pydata.org/)\n\n### Approach\n\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\n\n### Kaggle Competition \\| Titanic Machine Learning from Disaster\n\nKaggle's challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle's [Competition Page](https://www.kaggle.com/c/titanic):\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\n\n### Results\n\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\n\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\n\n## About\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n### Topics\n\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\n\n### Resources\n\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\n\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n### Stars\n\n[**6**\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\n\n### Watchers\n\n[**1**\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\n\n### Forks\n\n[**3**\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\n\n--- Result 4 ---\nTitle: Search code, repositories, users, issues, pull requests...\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\n\nContent:\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\nmain\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n|\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n|\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n|\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\~72% to \\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n# Titanic Survival Prediction\n[](#titanic-survival-prediction)\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\n* **Detailed EDA**\nA Jupyter notebook that walks through exploratory data analysis:\n* Summary statistics\n* Missing-value patterns\n* Feature distributions and pairwise relationships\n* Correlation heatmaps\n* **Feature Engineering**\nCreation of high-signal features from raw inputs, including:\n* `Has\\_Cabin`(binary cabin indicator)\n* `FareBin`(quantile-based fare categories)\n* Group-median imputation for`Age`, then 10-year age bins\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\n* `Title`extracted and consolidated from passenger names\n* **Model Comparison**\nTraining and evaluation of multiple classifiers on the engineered feature set:\n* Random Forest\n* Support Vector Machine\n* K-Nearest Neighbors (k=3,5,7)\n* XGBoost\n* LightGBM\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\n* **Analysis &amp; Interpretation**\nInline Markdown commentary explains:\n* Why each feature matters\n* How missing data were handled\n* The rationale for model selection\n* Key takeaways and next-step recommendations\n## Repository Structure\n[](#repository-structure)\ndata/\n* train.csv # Official Kaggle training set\n* test.csv # Official Kaggle test set\nnotebooks/\n* titanic\\_analysis.ipynb\n‚Ä¢EDA, feature engineering, model training\n‚Ä¢Detailed Markdown analysis\n* README.md # Project overview and instructions\n## Contributing\n[](#contributing)\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\n## About\nPredict Titanic survival using t...\n\n--- Result 5 ---\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\n\nContent:\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\nAman Krishna\n2022-04-20T07:23:42Z\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\n\n## The art of fine-tuning a model\n\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\n\n7 min read\n\n\nApr 19, 2022\n\n\nListen\n\nShare\n\nPress enter or click to view image in full size\n\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\n\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\n\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\n\nYou can find the complete code on Github **_:_**\n\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \n\n**Machine Learning model build for survivor prediction for Kaggle's titanic competition - kaggle_titanic/Model‚Ä¶**\n\ngithub.com]\n\n## Which Model to use?\n\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\n\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\n\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\n\n## Pre-Requisite\n\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\n\n### Dropping Features\n\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\n\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\n\n### Code\n\n### Dummify Data\n\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\n\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\n\n**We will be using One-Hot encoding on our categorical features.**\n\n### Code\n\n### Split Data\n\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\n\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\n\n## Training\n\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\n\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\n\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\n\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\n\n### Code\n\n## Fine Tuning\n\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\n\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\n\n### Code\n\n### Output\n\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\n\nPress enter or click to view image in full size\n\nGrid Search Results\n\n## Refining Search Space: Max Depth & Max Samples\n\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\n\n### How?\n\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\n\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\n\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest max_Depth & max_samples\n\n## Fine Tune: Min Sample Split & Min Sample Leaf\n\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest min_samples_leaf & min_samples_split\n\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\n\n## Fine Tune: Number of Estimators\n\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest n_estimator value\n\n## Refining Search Space: Number of estima...\n\n--- Result 6 ---\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\n\nContent:\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\n\n--- Result 7 ---\nTitle: Titanic - Machine Learning from Disaster\nURL: https://www.kaggle.com/c/titanic/code\n\nContent:\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \n\n[... truncated 11780 characters ...]\ntool: ‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\n  Source: Web search - Kaggle Titanic best techniques\ntool: # Titanic Survival Prediction - Techniques Guide\n\n## Data Understanding\n**Reference notebooks for data characteristics:**\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\n- Target is imbalanced: 61.6% died, 38.4% survived\n\n## Feature Engineering (Critical for High Accuracy)\n\n### Title Extraction from Name\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\.', expand=False)`\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\n- Title is highly predictive: Master (young boys) had high survival\n\n### Family Features\n- **FamilySize** = SibSp + Parch + 1\n- **IsAlone** = 1 if FamilySize == 1, else 0\n- Family size affects survival: solo travelers and very large families had lower survival\n\n### Cabin Features\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\n- ~77% missing - use Has_Cabin binary flag\n\n### Fare and Age Binning\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\n- Binning helps tree models find splits\n\n### Name Length\n- **Name_length** = len(Name) - can be proxy for social status\n\n### Ticket Features\n- Ticket prefix extraction (some tickets have letter prefixes)\n- Ticket frequency (shared tickets indicate traveling together)\n\n## Missing Value Handling\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\n- **Embarked**: Fill with mode ('S' - Southampton)\n- **Fare**: Fill with median (by Pclass)\n- **Cabin**: Create Has_Cabin flag, don't impute\n\n## Models\n\n### Single Models (Baseline)\nFor this small tabular dataset, tree-based models work well:\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\n- **XGBoost**: Similar parameters, use early stopping\n- **Extra Trees**: n_estimators=500, max_depth=6\n- **Logistic Regression**: Good baseline, use regularization\n\n### Ensemble Approaches (Higher Accuracy)\n\n#### Voting Classifier\nCombine multiple models with soft voting:\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n- Use soft voting (probability-based) for better results\n\n#### Stacking (Best Approach)\nTwo-level stacking architecture:\n1. **First Level (Base Models)**: \n   - Random Forest\n   - Extra Trees\n   - AdaBoost\n   - Gradient Boosting\n   - SVC (with probability=True)\n   \n2. **Second Level (Meta-Classifier)**:\n   - XGBoost or Logistic Regression\n   \n3. **Out-of-Fold Predictions**:\n   - Use K-Fold (K=5) to generate out-of-fold predictions\n   - This prevents overfitting when training meta-classifier\n   - Each base model generates predictions on held-out fold\n   - Stack these predictions as features for meta-classifier\n\n## Validation Strategy\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\n- Small dataset (891 samples) - CV is critical to avoid overfitting\n- Track both train and validation scores to detect overfitting\n\n## Hyperparameter Tuning\n- Use GridSearchCV or RandomizedSearchCV\n- Key parameters to tune:\n  - Tree depth (max_depth): 3-8\n  - Number of estimators: 100-1000\n  - Learning rate (for boosting): 0.01-0.1\n  - Min samples per leaf: 1-5\n- Use cross-validation during tuning\n\n## Feature Selection\n- Use Recursive Feature Elimination (RFE) with cross-validation\n- Check feature importances from tree models\n- Most important features typically: Sex, Title, Pclass, Fare, Age\n\n## Key Insights from Top Kernels\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\n3. Title extraction captures both sex and age information effectively\n4. Family size has non-linear relationship with survival\n5. Ensemble methods consistently outperform single models\n\n## Submission Strategy\n- Generate predictions using best ensemble model\n- Consider averaging predictions from multiple models\n- Threshold at 0.5 for binary classification\n- Format: PassengerId, Survived (0 or 1)\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: Added code cell at 3",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb'}, {'role': 'tool', 'content': '‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb'}, {'role': 'assistant', 'content': 'REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.'}, {'role': 'tool', 'content': '=== MARKDOWN 23 ===\\n## Analyze by visualizing data\\n\\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n\\n### Correlating numerical features\\n\\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\\n\\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \\n\\n=== MARKDOWN 25 ===\\n### Correlating numerical and ordinal features\\n\\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n\\n**Observations.**\\n\\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n- Pclass varies in terms of Age distribution of passengers.\\n\\n**Decisions\\n\\n=== MARKDOWN 27 ===\\n### Correlating categorical features\\n\\nNow we can correlate categorical features with our solution goal.\\n\\n**Observations.**\\n\\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n- Ports of embarkation have varying survival rates for Pcla\\n\\n=== MARKDOWN 29 ===\\n### Correlating categorical and numerical features\\n\\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n\\n**Observations.**\\n\\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n\\n**Decisions.**\\n\\n- Consider banding Fare feature.\\n\\n=== MARKDOWN 31 ===\\n## Wrangle data\\n\\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n\\n### Correcting by dropping features\\n\\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n\\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n\\n\\n=== MARKDOWN 33 ===\\n### Creating new feature extracting from existing\\n\\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n\\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n\\n**Observations.**\\n\\nWhen we plot Title, Age, and Survived, we note the following observations.\\n\\n- Most titles band Age groups accurately. For example: Master\\n\\n=== CODE 34 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset.Name.str.extract(\\' ([A-Za-z]+)\\\\.\\', expand=False)\\n\\npd.crosstab(train_df[\\'Title\\'], train_df[\\'Sex\\'])\\n\\n=== MARKDOWN 35 ===\\nWe can replace many titles with a more common name or classify them as `Rare`.\\n\\n=== CODE 36 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace([\\'Lady\\', \\'Countess\\',\\'Capt\\', \\'Col\\',\\\\\\n \\t\\'Don\\', \\'Dr\\', \\'Major\\', \\'Rev\\', \\'Sir\\', \\'Jonkheer\\', \\'Dona\\'], \\'Rare\\')\\n\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mlle\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Ms\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mme\\', \\'Mrs\\')\\n    \\ntrain_df[[\\'Title\\', \\'Survived\\']].groupby([\\'Title\\'], as_index=False).mean()\\n\\n=== MARKDOWN 37 ===\\nWe can convert the categorical titles to ordinal.\\n\\n=== CODE 38 ===\\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].map(title_mapping)\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].fillna(0)\\n\\ntrain_df.head()\\n\\n=== MARKDOWN 39 ===\\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now I have comprehensive information. Let me write the seed prompt with all the techniques I've learned.\"}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': 'REASONING: Now let me check if there are any additional techniques in the Alexis Cook tutorial that might be helpful, and also search for any advanced techniques that could help beat the 1.0 target score (which is 100% accuracy - extremely challenging).'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\\n\\n=== MARKDOWN 1 ===\\n# Part 2: Your coding environment\\n\\nIn this section, you\\'ll train your own machine learning model to improve your predictions.  _If you\\'ve never written code before or don\\'t have any experience with machine learning, don\\'t worry!  We don\\'t assume any prior experience in this tutorial._\\n\\n## The Notebook\\n\\nThe first thing to do is to create a Kaggle Notebook where you\\'ll store all of your code.  You c\\n\\n=== CODE 2 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load in \\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data proc\\n\\n=== MARKDOWN 3 ===\\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We\\'ll do that next.\\n\\n## Load the data\\n\\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\\n\\n![](https://i.imgur.com/OQBax9n.png)\\n\\nType the two lines of code below into your second code cell.  Then, once you\\'re done, either click on the blue pl\\n\\n=== CODE 4 ===\\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntrain_data.head()\\n\\n=== MARKDOWN 5 ===\\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It\\'s very important that you see this output **in your notebook** before proceeding with the tutorial!\\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\\n\\n=== CODE 6 ===\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\\ntest_data.head()\\n\\n=== MARKDOWN 7 ===\\nAs before, make sure that you see the output above in your notebook before continuing.  \\n\\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\\n\\n# Part 3: Your first submission\\n\\n=== CODE 8 ===\\nwomen = train_data.loc[train_data.Sex == \\'female\\'][\"Survived\"]\\nrate_women = sum(women)/len(women)\\n\\nprint(\"% of women who survived:\", rate_women)\\n\\n=== MARKDOWN 9 ===\\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\\n\\nThen, run the code below in another code cell:\\n\\n=== CODE 10 ===\\nmen = train_data.loc[train_data.Sex == \\'male\\'][\"Survived\"]\\nrate_men = sum(men)/len(men)\\n\\nprint(\"% of men who survived:\", rate_men)\\n\\n=== MARKDOWN 11 ===\\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\\n\\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\\n\\nBut at the end of the day, this gender-based s\\n\\n=== CODE 12 ===\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\\nX = pd.get_dummies(train_data[features])\\nX_test = pd.get_dummies(test_data[features])\\n\\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\\nmodel.f\\n\\n=== MARKDOWN 13 ===\\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\\n> Again, don\\'t worry if this code doesn\\'t make sense to you!  For now, we\\'ll focus on how to generate and submit predictions.\\n\\nOnce you\\'re ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \\n- Ensure tha\\n\\n=== MARKDOWN 14 ===\\n# Part 4: Learn more!\\n\\nIf you\\'re interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we\\'ve presented here.  You\\'ll also know enough to generate even better predictions!\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: The tutorial is basic. Let me search for advanced techniques that could help achieve very high accuracy on this problem, particularly since the target is 100% accuracy which is extremely challenging.'}, {'role': 'tool', 'content': 'SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80\\u202f% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random\\u202fForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n**Step‚Äëby‚Äëstep recipe**\\n\\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \\n\\n2. **Impute & create missing‚Äëvalue flags**  \\n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \\n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1\\u202fif Cabin not null, else\\u202f0).  \\n   * Optionally encode the original *Cabin* letter as a categorical feature.  \\n\\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \\n   * **FamilySize** = `SibSp + Parch + 1`  \\n   * **IsAlone** = 1\\u202fif *FamilySize*\\u202f=\\u202f1 else\\u202f0  \\n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \\n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \\n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \\n\\n   These engineered columns lifted baseline scores from ~72\\u202f% to ~78\\u202f% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \\n\\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35\\u202f% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \\n\\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \\n   * `n_estimators` (200‚Äë1000)  \\n   * `max_depth` (5‚Äë15)  \\n   * `min_samples_split` / `min_samples_leaf`  \\n   * `max_features` (sqrt, log2, or a fraction)  \\n\\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100\\u202f% Accuracy‚Äù notebook placed the author in the top\\u202f3\\u202f%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \\n\\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•\\u202f0.84) before uploading.  \\n\\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\\n\\n--- Result 2 ---\\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\\n\\nContent:\\nSeptember 10, 2016\\xa0\\xa0\\xa0\\xa0\\xa033min read\\n\\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\\n\\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\\n\\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I\\'m writing this post, I am ranked among the top 4% of all Kagglers.\\n\\nThis post is the opportunity to share my solution with you.\\n\\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I\\'ll follow with feature engineering and finally present the predictive model I set up.\\n\\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\\nThe main libraries involved in this tutorial are:\\n\\n- **Pandas** for data manipulation and ingestion\\n- **Matplotlib** and **seaborn** for data visualization\\n- **Numpy** for multidimensional array computing\\n- **sklearn** for machine learning and predictive modeling\\n\\n### Installation procedure\\n\\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\\n\\n### Nota Bene\\n\\nThis is my first attempt as a blogger and as a machine learning practitioner.\\n\\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\\n\\nHope you\\'ve got everything set on your computer. Let\\'s get started.\\n\\n## I - Exploratory data analysis\\n\\nAs in different data projects, we\\'ll first start diving into the data and build up our first intuitions.\\n\\nIn this section, we\\'ll be doing four things.\\n\\n- Data extraction : we\\'ll load the dataset and have a first look at it.\\n- Cleaning : we\\'ll fill in missing values.\\n- Plotting : we\\'ll create some interesting charts that\\'ll (hopefully) spot correlations and hidden insights out of the data.\\n- Assumptions : we\\'ll formulate hypotheses from the charts.\\n\\nWe tweak the style of this notebook a little bit to have centered plots.\\n\\n```\\nfrom IPython.core.display import HTML\\nHTML(\"\"\"\\n<style>\\n.output_png {\\n    display: table-cell;\\n    text-align: center;\\n    vertical-align: middle;\\n}\\n</style>\\n\"\"\");\\n```\\n\\nWe import the useful libraries.\\n\\n```\\n%matplotlib inline\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\nwarnings.filterwarnings(\\'ignore\\', category=DeprecationWarning)\\n\\nimport pandas as pd\\npd.options.display.max_columns = 100\\n\\nfrom matplotlib import pyplot as plt\\nimport numpy as np\\n\\nimport seaborn as sns\\n\\nimport pylab as plot\\nparams = {\\n    \\'axes.labelsize\\': \"large\",\\n    \\'xtick.labelsize\\': \\'x-large\\',\\n    \\'legend.fontsize\\': 20,\\n    \\'figure.dpi\\': 150,\\n    \\'figure.figsize\\': [25, 7]\\n}\\nplot.rcParams.update(params)\\n```\\n\\nTwo datasets are available: a training set and a test set.\\nWe\\'ll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\\n\\nWe\\'ll see how this procedure is done at the end of this post.\\n\\nNow let\\'s start by loading the training set.\\n\\n```\\ndata = pd.read_csv(\\'./data/train.csv\\')\\nprint(data.shape)\\n#(891, 12)\\n```\\n\\nWe have:\\n\\n- 891 rows\\n- 12 columns\\n\\nPandas allows you to have a sneak peak at your data.\\n\\n```\\ndata.head()\\n```\\n\\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\\n\\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he\\'s dead. The is the variable we\\'re going to predict.\\n\\nThe other variables describe the passengers. They are the **features**.\\n\\n- PassengerId: and id given to each traveler on the boat\\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\\n- The Name of the passeger\\n- The Sex\\n- The Age\\n- SibSp: number of siblings and spouses traveling with the passenger\\n- Parch: number of parents and children traveling with the passenger\\n- The ticket number\\n- The ticket Fare\\n- The cabin number\\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\\n\\nPandas allows you to a have a high-level simple statistical description of the numerical features.\\nThis can be done using the describe method.\\n\\n```\\ndata.describe()\\n```\\n\\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\\n\\nThe count variable shows that 177 values are missing in the Age column.\\n\\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\\n\\n```\\ndata[\\'Age\\'] = data[\\'Age\\'].fillna(data[\\'Age\\'].median())\\n```\\n\\nLet\\'s now make some charts.\\n\\nLet\\'s visualize survival based on the gender.\\n\\n```\\ndata[\\'Died\\'] = 1 - data[\\'Survived\\']\\ndata.groupby(\\'Sex\\').agg(\\'sum\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                          stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nIt looks like male passengers are more likely to succumb.\\n\\nLet\\'s plot the same graph but with ratio instead.\\n\\n```\\ndata.groupby(\\'Sex\\').agg(\\'mean\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                           stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\\n\\nLet\\'s now correlate the survival with the age variable.\\n\\n```\\nfig = plt.figure(figsize=(25, 7))\\nsns.violinplot(x=\\'Sex\\', y=\\'Age\\',\\n               hue=\\'Survived\\', data=data,\\n               split=True,\\n               palette={0: \"r\", 1: \"g\"}\\n              );\\n```\\n\\nAs we saw in the chart above and validate by the following:\\n\\n- Women survive more than men, as depicted by the larger female green histogram\\n\\nNow, we see that:\\n\\n- The age conditions the survival for male passengers:\\n\\n  - Younger male tend to survive\\n  - A large number of passengers between 20 and 40 succumb\\n- The age doesn\\'t seem to have a direct impact on the female survival\\n\\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\\n\\nRight?\\n\\nLet\\'s now focus on the Fare ticket of each passenger and see how it could impact the survival.\\n\\n```\\nfigure = plt.figure(figsize=(25, 7))\\nplt.hist([dat...\\n\\n--- Result 3 ---\\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\nURL: https://github.com/alicevillar/titanic-kaggle\\n\\nContent:\\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\\n\\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\\n\\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n- [Fork\\\\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n- [Star\\\\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n[6\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n\\n# alicevillar/titanic-kaggle\\n\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n\\nmain\\n\\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\\n\\nGo to file\\n\\nCode\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\\n| ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\\n| ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\\n| View all files |\\n\\n## Repository files navigation\\n\\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n\\nThe objective of Kaggle\\'s Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\\n\\n### Quick Start:\\n\\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\\n\\n### Dependencies:\\n\\n- [Numpy](https://numpy.org/)\\n- [Pandas](https://pandas.pydata.org/)\\n- [SciKit-Learn](https://scikit-learn.org/)\\n- [Matplotlib](https://matplotlib.org/)\\n- [Seaborn](https://seaborn.pydata.org/)\\n\\n### Approach\\n\\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\\n\\n### Kaggle Competition \\\\| Titanic Machine Learning from Disaster\\n\\nKaggle\\'s challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle\\'s [Competition Page](https://www.kaggle.com/c/titanic):\\n\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\\n\\n### Results\\n\\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\\n\\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\\n\\n## About\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n### Topics\\n\\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\\n\\n### Resources\\n\\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\\n\\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n### Stars\\n\\n[**6**\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\\n\\n### Watchers\\n\\n[**1**\\\\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\\n\\n### Forks\\n\\n[**3**\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\\n\\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\\n\\n--- Result 4 ---\\nTitle: Search code, repositories, users, issues, pull requests...\\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\n\\nContent:\\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[Skip to content](#start-of-content)\\n## Navigation Menu\\nToggle navigation\\n[](https://github.com/)\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nSearch or jump to...\\n# Search code, repositories, users, issues, pull requests...\\n</option></form>\\nSearch\\nClear\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n# Provide feedback\\n</option></form>\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancelSubmit feedback\\n# Saved searches\\n## Use saved searches to filter your results more quickly\\n</option></form>\\nName\\nQuery\\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\nCancelCreate saved search\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nResetting focus\\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\\n{{ message }}\\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\nmain\\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\nGo to file\\nCode\\nOpen more actions menu\\n## Folders and files\\n|Name|Name|\\nLast commit message\\n|\\nLast commit date\\n|\\n## Latest commit\\n## History\\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n|\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n|\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n|\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n|\\n|\\nView all files\\n|\\n## Repository files navigation\\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\~72% to \\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n# Titanic Survival Prediction\\n[](#titanic-survival-prediction)\\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\\n* **Detailed EDA**\\nA Jupyter notebook that walks through exploratory data analysis:\\n* Summary statistics\\n* Missing-value patterns\\n* Feature distributions and pairwise relationships\\n* Correlation heatmaps\\n* **Feature Engineering**\\nCreation of high-signal features from raw inputs, including:\\n* `Has\\\\_Cabin`(binary cabin indicator)\\n* `FareBin`(quantile-based fare categories)\\n* Group-median imputation for`Age`, then 10-year age bins\\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\\n* `Title`extracted and consolidated from passenger names\\n* **Model Comparison**\\nTraining and evaluation of multiple classifiers on the engineered feature set:\\n* Random Forest\\n* Support Vector Machine\\n* K-Nearest Neighbors (k=3,5,7)\\n* XGBoost\\n* LightGBM\\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\\n* **Analysis &amp; Interpretation**\\nInline Markdown commentary explains:\\n* Why each feature matters\\n* How missing data were handled\\n* The rationale for model selection\\n* Key takeaways and next-step recommendations\\n## Repository Structure\\n[](#repository-structure)\\ndata/\\n* train.csv # Official Kaggle training set\\n* test.csv # Official Kaggle test set\\nnotebooks/\\n* titanic\\\\_analysis.ipynb\\n‚Ä¢EDA, feature engineering, model training\\n‚Ä¢Detailed Markdown analysis\\n* README.md # Project overview and instructions\\n## Contributing\\n[](#contributing)\\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\\n## About\\nPredict Titanic survival using t...\\n\\n--- Result 5 ---\\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\n\\nContent:\\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\\nAman Krishna\\n2022-04-20T07:23:42Z\\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\n\\n## The art of fine-tuning a model\\n\\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\\n\\n7 min read\\n\\n\\nApr 19, 2022\\n\\n\\nListen\\n\\nShare\\n\\nPress enter or click to view image in full size\\n\\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\\n\\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\\n\\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\\n\\nYou can find the complete code on Github **_:_**\\n\\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \\n\\n**Machine Learning model build for survivor prediction for Kaggle\\'s titanic competition - kaggle_titanic/Model‚Ä¶**\\n\\ngithub.com]\\n\\n## Which Model to use?\\n\\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\\n\\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\\n\\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\\n\\n## Pre-Requisite\\n\\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\\n\\n### Dropping Features\\n\\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\\n\\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\\n\\n### Code\\n\\n### Dummify Data\\n\\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\\n\\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\\n\\n**We will be using One-Hot encoding on our categorical features.**\\n\\n### Code\\n\\n### Split Data\\n\\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\\n\\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\\n\\n## Training\\n\\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\\n\\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\\n\\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\\n\\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\\n\\n### Code\\n\\n## Fine Tuning\\n\\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\\n\\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\\n\\n### Code\\n\\n### Output\\n\\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\\n\\nPress enter or click to view image in full size\\n\\nGrid Search Results\\n\\n## Refining Search Space: Max Depth & Max Samples\\n\\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\\n\\n### How?\\n\\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\\n\\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\\n\\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest max_Depth & max_samples\\n\\n## Fine Tune: Min Sample Split & Min Sample Leaf\\n\\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest min_samples_leaf & min_samples_split\\n\\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\\n\\n## Fine Tune: Number of Estimators\\n\\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest n_estimator value\\n\\n## Refining Search Space: Number of estima...\\n\\n--- Result 6 ---\\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\\n\\nContent:\\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\\n\\n--- Result 7 ---\\nTitle: Titanic - Machine Learning from Disaster\\nURL: https://www.kaggle.com/c/titanic/code\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \\n\\n[... truncated 11780 characters ...]'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! The search confirms that achieving 100% accuracy is essentially impossible without cheating (using external data). The realistic best scores are in the 80-86% range. Let me update the seed prompt with this important context and add more specific techniques.'}, {'role': 'tool', 'content': '‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\\n  Source: Web search - Kaggle Titanic best techniques'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"# Titanic Survival Prediction - Techniques Guide\\n\\n## Data Understanding\\n**Reference notebooks for data characteristics:**\\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\\n- Target is imbalanced: 61.6% died, 38.4% survived\\n\\n## Feature Engineering (Critical for High Accuracy)\\n\\n### Title Extraction from Name\\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)`\\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\\n- Title is highly predictive: Master (young boys) had high survival\\n\\n### Family Features\\n- **FamilySize** = SibSp + Parch + 1\\n- **IsAlone** = 1 if FamilySize == 1, else 0\\n- Family size affects survival: solo travelers and very large families had lower survival\\n\\n### Cabin Features\\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\\n- ~77% missing - use Has_Cabin binary flag\\n\\n### Fare and Age Binning\\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\\n- Binning helps tree models find splits\\n\\n### Name Length\\n- **Name_length** = len(Name) - can be proxy for social status\\n\\n### Ticket Features\\n- Ticket prefix extraction (some tickets have letter prefixes)\\n- Ticket frequency (shared tickets indicate traveling together)\\n\\n## Missing Value Handling\\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\\n- **Embarked**: Fill with mode ('S' - Southampton)\\n- **Fare**: Fill with median (by Pclass)\\n- **Cabin**: Create Has_Cabin flag, don't impute\\n\\n## Models\\n\\n### Single Models (Baseline)\\nFor this small tabular dataset, tree-based models work well:\\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\\n- **XGBoost**: Similar parameters, use early stopping\\n- **Extra Trees**: n_estimators=500, max_depth=6\\n- **Logistic Regression**: Good baseline, use regularization\\n\\n### Ensemble Approaches (Higher Accuracy)\\n\\n#### Voting Classifier\\nCombine multiple models with soft voting:\\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\\n- Use soft voting (probability-based) for better results\\n\\n#### Stacking (Best Approach)\\nTwo-level stacking architecture:\\n1. **First Level (Base Models)**: \\n   - Random Forest\\n   - Extra Trees\\n   - AdaBoost\\n   - Gradient Boosting\\n   - SVC (with probability=True)\\n   \\n2. **Second Level (Meta-Classifier)**:\\n   - XGBoost or Logistic Regression\\n   \\n3. **Out-of-Fold Predictions**:\\n   - Use K-Fold (K=5) to generate out-of-fold predictions\\n   - This prevents overfitting when training meta-classifier\\n   - Each base model generates predictions on held-out fold\\n   - Stack these predictions as features for meta-classifier\\n\\n## Validation Strategy\\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\\n- Small dataset (891 samples) - CV is critical to avoid overfitting\\n- Track both train and validation scores to detect overfitting\\n\\n## Hyperparameter Tuning\\n- Use GridSearchCV or RandomizedSearchCV\\n- Key parameters to tune:\\n  - Tree depth (max_depth): 3-8\\n  - Number of estimators: 100-1000\\n  - Learning rate (for boosting): 0.01-0.1\\n  - Min samples per leaf: 1-5\\n- Use cross-validation during tuning\\n\\n## Feature Selection\\n- Use Recursive Feature Elimination (RFE) with cross-validation\\n- Check feature importances from tree models\\n- Most important features typically: Sex, Title, Pclass, Fare, Age\\n\\n## Key Insights from Top Kernels\\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\\n3. Title extraction captures both sex and age information effectively\\n4. Family size has non-linear relationship with survival\\n5. Ensemble methods consistently outperform single models\\n\\n## Submission Strategy\\n- Generate predictions using best ensemble model\\n- Consider averaging predictions from multiple models\\n- Threshold at 0.5 for binary classification\\n- Format: PassengerId, Survived (0 or 1)\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': \"REASONING: Let me add a few more cells to the EDA notebook to explore Title extraction and family size patterns, which are key features. Then I'll finalize the seed prompt.\"}, {'role': 'tool', 'content': 'Added code cell at 3'}]",
        "llm.input_tokens": 48186,
        "llm.output_tokens": 73,
        "llm.total_tokens": 48259,
        "llm.latency_ms": 3886.9309425354004,
        "llm.completion": "[Tool Use: ExecuteCellRange]",
        "llm.cost_usd": 0.145653
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "314f173992cd1fd2",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767683676124147857,
      "end_time": 1767683676153856519,
      "duration": 0.029708662,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x73eac37d9e10>\", \"input\": {\"start_cell\": 3, \"duration\": 30}}",
        "tool.output": "{\"content\": \"Executed cells 3-3\\n==================================================\\n\\nCell 3:\\n```\\n# Extract Title from Name\\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\\nprint('Title distribution:')\\nprint(train['Title'].value_counts())\\nprint('\\\\nSurvival by Title:')\\nprint(train.groupby('Title')['Survived'].agg(['mean', 'count']).sort_values('count', ascending=False))\\n```\\nOutput:\\nTitle distribution:\\nTitle\\nMr          517\\nMiss        182\\nMrs         125\\nMaster       40\\nDr            7\\nRev           6\\nCol           2\\nMlle          2\\nMajor         2\\nMs            1\\nMme           1\\nDon           1\\nLady          1\\nSir           1\\nCapt          1\\nCountess      1\\nJonkheer      1\\nName: count, dtype: int64\\n\\nSurvival by Title:\\n              mean  count\\nTitle                    \\nMr        0.156673    517\\nMiss      0.697802    182\\nMrs       0.792000    125\\nMaster    0.575000     40\\nDr        0.428571      7\\nRev       0.000000      6\\nMlle      1.000000      2\\nMajor     0.500000      2\\nCol       0.500000      2\\nCapt      0.000000      1\\nLady      1.000000      1\\nCountess  1.000000      1\\nDon       0.000000      1\\nJonkheer  0.000000      1\\nMme       1.000000      1\\nMs        1.000000      1\\nSir       1.000000      1\\n\", \"is_error\": false}",
        "tool.duration_ms": 29.757022857666016
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "45eaa95cde742e2b",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683677374742301,
      "end_time": 1767683682692919871,
      "duration": 5.31817757,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n\ntool: ‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\n  Source: exploration/eda.ipynb\ntool: ‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\n  Source: exploration/eda.ipynb\ntool: === MARKDOWN 23 ===\n## Analyze by visualizing data\n\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\n\n### Correlating numerical features\n\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\n\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \n\n=== MARKDOWN 25 ===\n### Correlating numerical and ordinal features\n\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n\n**Observations.**\n\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n- Pclass varies in terms of Age distribution of passengers.\n\n**Decisions\n\n=== MARKDOWN 27 ===\n### Correlating categorical features\n\nNow we can correlate categorical features with our solution goal.\n\n**Observations.**\n\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\n- Ports of embarkation have varying survival rates for Pcla\n\n=== MARKDOWN 29 ===\n### Correlating categorical and numerical features\n\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n\n**Observations.**\n\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n\n**Decisions.**\n\n- Consider banding Fare feature.\n\n=== MARKDOWN 31 ===\n## Wrangle data\n\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n\n### Correcting by dropping features\n\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\n\n\n=== MARKDOWN 33 ===\n### Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n\n**Observations.**\n\nWhen we plot Title, Age, and Survived, we note the following observations.\n\n- Most titles band Age groups accurately. For example: Master\n\n=== CODE 34 ===\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])\n\n=== MARKDOWN 35 ===\nWe can replace many titles with a more common name or classify them as `Rare`.\n\n=== CODE 36 ===\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n\n=== MARKDOWN 37 ===\nWe can convert the categorical titles to ordinal.\n\n=== CODE 38 ===\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()\n\n=== MARKDOWN 39 ===\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\n\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: === MARKDOWN 0 ===\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\n\n=== MARKDOWN 1 ===\n# Part 2: Your coding environment\n\nIn this section, you'll train your own machine learning model to improve your predictions.  _If you've never written code before or don't have any experience with machine learning, don't worry!  We don't assume any prior experience in this tutorial._\n\n## The Notebook\n\nThe first thing to do is to create a Kaggle Notebook where you'll store all of your code.  You c\n\n=== CODE 2 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data proc\n\n=== MARKDOWN 3 ===\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We'll do that next.\n\n## Load the data\n\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\n\n![](https://i.imgur.com/OQBax9n.png)\n\nType the two lines of code below into your second code cell.  Then, once you're done, either click on the blue pl\n\n=== CODE 4 ===\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()\n\n=== MARKDOWN 5 ===\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It's very important that you see this output **in your notebook** before proceeding with the tutorial!\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\n\n=== CODE 6 ===\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()\n\n=== MARKDOWN 7 ===\nAs before, make sure that you see the output above in your notebook before continuing.  \n\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\n\n# Part 3: Your first submission\n\n=== CODE 8 ===\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\n=== MARKDOWN 9 ===\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\n\nThen, run the code below in another code cell:\n\n=== CODE 10 ===\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)\n\n=== MARKDOWN 11 ===\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\n\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\n\nBut at the end of the day, this gender-based s\n\n=== CODE 12 ===\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.f\n\n=== MARKDOWN 13 ===\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\n> Again, don't worry if this code doesn't make sense to you!  For now, we'll focus on how to generate and submit predictions.\n\nOnce you're ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \n- Ensure tha\n\n=== MARKDOWN 14 ===\n# Part 4: Learn more!\n\nIf you're interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we've presented here.  You'll also know enough to generate even better predictions!\n\n\ntool: SEARCH RESULTS (9 found)\n==================================================\n\n--- Result 1 ---\nTitle: ANSWER\n\nContent:\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80‚ÄØ% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random‚ÄØForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n**Step‚Äëby‚Äëstep recipe**\n\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \n\n2. **Impute & create missing‚Äëvalue flags**  \n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1‚ÄØif Cabin not null, else‚ÄØ0).  \n   * Optionally encode the original *Cabin* letter as a categorical feature.  \n\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \n   * **FamilySize** = `SibSp + Parch + 1`  \n   * **IsAlone** = 1‚ÄØif *FamilySize*‚ÄØ=‚ÄØ1 else‚ÄØ0  \n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \n\n   These engineered columns lifted baseline scores from ~72‚ÄØ% to ~78‚ÄØ% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \n\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35‚ÄØ% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \n\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \n   * `n_estimators` (200‚Äë1000)  \n   * `max_depth` (5‚Äë15)  \n   * `min_samples_split` / `min_samples_leaf`  \n   * `max_features` (sqrt, log2, or a fraction)  \n\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100‚ÄØ% Accuracy‚Äù notebook placed the author in the top‚ÄØ3‚ÄØ%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \n\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•‚ÄØ0.84) before uploading.  \n\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\n\n--- Result 2 ---\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\n\nContent:\nSeptember 10, 2016¬†¬†¬†¬†¬†33min read\n\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\n\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\n\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I'm writing this post, I am ranked among the top 4% of all Kagglers.\n\nThis post is the opportunity to share my solution with you.\n\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I'll follow with feature engineering and finally present the predictive model I set up.\n\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\nThe main libraries involved in this tutorial are:\n\n- **Pandas** for data manipulation and ingestion\n- **Matplotlib** and **seaborn** for data visualization\n- **Numpy** for multidimensional array computing\n- **sklearn** for machine learning and predictive modeling\n\n### Installation procedure\n\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\n\n### Nota Bene\n\nThis is my first attempt as a blogger and as a machine learning practitioner.\n\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\n\nHope you've got everything set on your computer. Let's get started.\n\n## I - Exploratory data analysis\n\nAs in different data projects, we'll first start diving into the data and build up our first intuitions.\n\nIn this section, we'll be doing four things.\n\n- Data extraction : we'll load the dataset and have a first look at it.\n- Cleaning : we'll fill in missing values.\n- Plotting : we'll create some interesting charts that'll (hopefully) spot correlations and hidden insights out of the data.\n- Assumptions : we'll formulate hypotheses from the charts.\n\nWe tweak the style of this notebook a little bit to have centered plots.\n\n```\nfrom IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n</style>\n\"\"\");\n```\n\nWe import the useful libraries.\n\n```\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\nimport pandas as pd\npd.options.display.max_columns = 100\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimport seaborn as sns\n\nimport pylab as plot\nparams = {\n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n}\nplot.rcParams.update(params)\n```\n\nTwo datasets are available: a training set and a test set.\nWe'll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\n\nWe'll see how this procedure is done at the end of this post.\n\nNow let's start by loading the training set.\n\n```\ndata = pd.read_csv('./data/train.csv')\nprint(data.shape)\n#(891, 12)\n```\n\nWe have:\n\n- 891 rows\n- 12 columns\n\nPandas allows you to have a sneak peak at your data.\n\n```\ndata.head()\n```\n\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\n\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he's dead. The is the variable we're going to predict.\n\nThe other variables describe the passengers. They are the **features**.\n\n- PassengerId: and id given to each traveler on the boat\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\n- The Name of the passeger\n- The Sex\n- The Age\n- SibSp: number of siblings and spouses traveling with the passenger\n- Parch: number of parents and children traveling with the passenger\n- The ticket number\n- The ticket Fare\n- The cabin number\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\n\nPandas allows you to a have a high-level simple statistical description of the numerical features.\nThis can be done using the describe method.\n\n```\ndata.describe()\n```\n\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\n| --- | --- | --- | --- | --- | --- | --- |\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\n\nThe count variable shows that 177 values are missing in the Age column.\n\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\n\n```\ndata['Age'] = data['Age'].fillna(data['Age'].median())\n```\n\nLet's now make some charts.\n\nLet's visualize survival based on the gender.\n\n```\ndata['Died'] = 1 - data['Survived']\ndata.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                          stacked=True, colors=['g', 'r']);\n```\n\nIt looks like male passengers are more likely to succumb.\n\nLet's plot the same graph but with ratio instead.\n\n```\ndata.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                           stacked=True, colors=['g', 'r']);\n```\n\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\n\nLet's now correlate the survival with the age variable.\n\n```\nfig = plt.figure(figsize=(25, 7))\nsns.violinplot(x='Sex', y='Age',\n               hue='Survived', data=data,\n               split=True,\n               palette={0: \"r\", 1: \"g\"}\n              );\n```\n\nAs we saw in the chart above and validate by the following:\n\n- Women survive more than men, as depicted by the larger female green histogram\n\nNow, we see that:\n\n- The age conditions the survival for male passengers:\n\n  - Younger male tend to survive\n  - A large number of passengers between 20 and 40 succumb\n- The age doesn't seem to have a direct impact on the female survival\n\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\n\nRight?\n\nLet's now focus on the Fare ticket of each passenger and see how it could impact the survival.\n\n```\nfigure = plt.figure(figsize=(25, 7))\nplt.hist([dat...\n\n--- Result 3 ---\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\nURL: https://github.com/alicevillar/titanic-kaggle\n\nContent:\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n- [Fork\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n- [Star\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n[6\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n\n# alicevillar/titanic-kaggle\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmain\n\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\n| ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\n| ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n\nThe objective of Kaggle's Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\n\n### Quick Start:\n\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\n\n### Dependencies:\n\n- [Numpy](https://numpy.org/)\n- [Pandas](https://pandas.pydata.org/)\n- [SciKit-Learn](https://scikit-learn.org/)\n- [Matplotlib](https://matplotlib.org/)\n- [Seaborn](https://seaborn.pydata.org/)\n\n### Approach\n\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\n\n### Kaggle Competition \\| Titanic Machine Learning from Disaster\n\nKaggle's challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle's [Competition Page](https://www.kaggle.com/c/titanic):\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\n\n### Results\n\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\n\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\n\n## About\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n### Topics\n\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\n\n### Resources\n\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\n\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n### Stars\n\n[**6**\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\n\n### Watchers\n\n[**1**\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\n\n### Forks\n\n[**3**\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\n\n--- Result 4 ---\nTitle: Search code, repositories, users, issues, pull requests...\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\n\nContent:\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\nmain\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n|\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n|\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n|\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\~72% to \\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n# Titanic Survival Prediction\n[](#titanic-survival-prediction)\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\n* **Detailed EDA**\nA Jupyter notebook that walks through exploratory data analysis:\n* Summary statistics\n* Missing-value patterns\n* Feature distributions and pairwise relationships\n* Correlation heatmaps\n* **Feature Engineering**\nCreation of high-signal features from raw inputs, including:\n* `Has\\_Cabin`(binary cabin indicator)\n* `FareBin`(quantile-based fare categories)\n* Group-median imputation for`Age`, then 10-year age bins\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\n* `Title`extracted and consolidated from passenger names\n* **Model Comparison**\nTraining and evaluation of multiple classifiers on the engineered feature set:\n* Random Forest\n* Support Vector Machine\n* K-Nearest Neighbors (k=3,5,7)\n* XGBoost\n* LightGBM\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\n* **Analysis &amp; Interpretation**\nInline Markdown commentary explains:\n* Why each feature matters\n* How missing data were handled\n* The rationale for model selection\n* Key takeaways and next-step recommendations\n## Repository Structure\n[](#repository-structure)\ndata/\n* train.csv # Official Kaggle training set\n* test.csv # Official Kaggle test set\nnotebooks/\n* titanic\\_analysis.ipynb\n‚Ä¢EDA, feature engineering, model training\n‚Ä¢Detailed Markdown analysis\n* README.md # Project overview and instructions\n## Contributing\n[](#contributing)\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\n## About\nPredict Titanic survival using t...\n\n--- Result 5 ---\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\n\nContent:\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\nAman Krishna\n2022-04-20T07:23:42Z\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\n\n## The art of fine-tuning a model\n\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\n\n7 min read\n\n\nApr 19, 2022\n\n\nListen\n\nShare\n\nPress enter or click to view image in full size\n\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\n\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\n\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\n\nYou can find the complete code on Github **_:_**\n\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \n\n**Machine Learning model build for survivor prediction for Kaggle's titanic competition - kaggle_titanic/Model‚Ä¶**\n\ngithub.com]\n\n## Which Model to use?\n\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\n\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\n\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\n\n## Pre-Requisite\n\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\n\n### Dropping Features\n\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\n\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\n\n### Code\n\n### Dummify Data\n\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\n\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\n\n**We will be using One-Hot encoding on our categorical features.**\n\n### Code\n\n### Split Data\n\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\n\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\n\n## Training\n\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\n\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\n\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\n\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\n\n### Code\n\n## Fine Tuning\n\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\n\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\n\n### Code\n\n### Output\n\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\n\nPress enter or click to view image in full size\n\nGrid Search Results\n\n## Refining Search Space: Max Depth & Max Samples\n\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\n\n### How?\n\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\n\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\n\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest max_Depth & max_samples\n\n## Fine Tune: Min Sample Split & Min Sample Leaf\n\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest min_samples_leaf & min_samples_split\n\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\n\n## Fine Tune: Number of Estimators\n\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest n_estimator value\n\n## Refining Search Space: Number of estima...\n\n--- Result 6 ---\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\n\nContent:\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\n\n--- Result 7 ---\nTitle: Titanic - Machine Learning from Disaster\nURL: https://www.kaggle.com/c/titanic/code\n\nContent:\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \n\n[... truncated 11780 characters ...]\ntool: ‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\n  Source: Web search - Kaggle Titanic best techniques\ntool: # Titanic Survival Prediction - Techniques Guide\n\n## Data Understanding\n**Reference notebooks for data characteristics:**\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\n- Target is imbalanced: 61.6% died, 38.4% survived\n\n## Feature Engineering (Critical for High Accuracy)\n\n### Title Extraction from Name\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\.', expand=False)`\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\n- Title is highly predictive: Master (young boys) had high survival\n\n### Family Features\n- **FamilySize** = SibSp + Parch + 1\n- **IsAlone** = 1 if FamilySize == 1, else 0\n- Family size affects survival: solo travelers and very large families had lower survival\n\n### Cabin Features\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\n- ~77% missing - use Has_Cabin binary flag\n\n### Fare and Age Binning\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\n- Binning helps tree models find splits\n\n### Name Length\n- **Name_length** = len(Name) - can be proxy for social status\n\n### Ticket Features\n- Ticket prefix extraction (some tickets have letter prefixes)\n- Ticket frequency (shared tickets indicate traveling together)\n\n## Missing Value Handling\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\n- **Embarked**: Fill with mode ('S' - Southampton)\n- **Fare**: Fill with median (by Pclass)\n- **Cabin**: Create Has_Cabin flag, don't impute\n\n## Models\n\n### Single Models (Baseline)\nFor this small tabular dataset, tree-based models work well:\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\n- **XGBoost**: Similar parameters, use early stopping\n- **Extra Trees**: n_estimators=500, max_depth=6\n- **Logistic Regression**: Good baseline, use regularization\n\n### Ensemble Approaches (Higher Accuracy)\n\n#### Voting Classifier\nCombine multiple models with soft voting:\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n- Use soft voting (probability-based) for better results\n\n#### Stacking (Best Approach)\nTwo-level stacking architecture:\n1. **First Level (Base Models)**: \n   - Random Forest\n   - Extra Trees\n   - AdaBoost\n   - Gradient Boosting\n   - SVC (with probability=True)\n   \n2. **Second Level (Meta-Classifier)**:\n   - XGBoost or Logistic Regression\n   \n3. **Out-of-Fold Predictions**:\n   - Use K-Fold (K=5) to generate out-of-fold predictions\n   - This prevents overfitting when training meta-classifier\n   - Each base model generates predictions on held-out fold\n   - Stack these predictions as features for meta-classifier\n\n## Validation Strategy\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\n- Small dataset (891 samples) - CV is critical to avoid overfitting\n- Track both train and validation scores to detect overfitting\n\n## Hyperparameter Tuning\n- Use GridSearchCV or RandomizedSearchCV\n- Key parameters to tune:\n  - Tree depth (max_depth): 3-8\n  - Number of estimators: 100-1000\n  - Learning rate (for boosting): 0.01-0.1\n  - Min samples per leaf: 1-5\n- Use cross-validation during tuning\n\n## Feature Selection\n- Use Recursive Feature Elimination (RFE) with cross-validation\n- Check feature importances from tree models\n- Most important features typically: Sex, Title, Pclass, Fare, Age\n\n## Key Insights from Top Kernels\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\n3. Title extraction captures both sex and age information effectively\n4. Family size has non-linear relationship with survival\n5. Ensemble methods consistently outperform single models\n\n## Submission Strategy\n- Generate predictions using best ensemble model\n- Consider averaging predictions from multiple models\n- Threshold at 0.5 for binary classification\n- Format: PassengerId, Survived (0 or 1)\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: Added code cell at 3\ntool: Executed cells 3-3\n==================================================\n\nCell 3:\n```\n# Extract Title from Name\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\nprint('Title distribution:')\nprint(train['Title'].value_counts())\nprint('\\nSurvival by Title:')\nprint(train.groupby('Title')['Survived'].agg(['mean', 'count']).sort_values('count', ascending=False))\n```\nOutput:\nTitle distribution:\nTitle\nMr          517\nMiss        182\nMrs         125\nMaster       40\nDr            7\nRev           6\nCol           2\nMlle          2\nMajor         2\nMs            1\nMme           1\nDon           1\nLady          1\nSir           1\nCapt          1\nCountess      1\nJonkheer      1\nName: count, dtype: int64\n\nSurvival by Title:\n              mean  count\nTitle                    \nMr        0.156673    517\nMiss      0.697802    182\nMrs       0.792000    125\nMaster    0.575000     40\nDr        0.428571      7\nRev       0.000000      6\nMlle      1.000000      2\nMajor     0.500000      2\nCol       0.500000      2\nCapt      0.000000      1\nLady      1.000000      1\nCountess  1.000000      1\nDon       0.000000      1\nJonkheer  0.000000      1\nMme       1.000000      1\nMs        1.000000      1\nSir       1.000000      1\n",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb'}, {'role': 'tool', 'content': '‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb'}, {'role': 'assistant', 'content': 'REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.'}, {'role': 'tool', 'content': '=== MARKDOWN 23 ===\\n## Analyze by visualizing data\\n\\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n\\n### Correlating numerical features\\n\\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\\n\\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \\n\\n=== MARKDOWN 25 ===\\n### Correlating numerical and ordinal features\\n\\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n\\n**Observations.**\\n\\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n- Pclass varies in terms of Age distribution of passengers.\\n\\n**Decisions\\n\\n=== MARKDOWN 27 ===\\n### Correlating categorical features\\n\\nNow we can correlate categorical features with our solution goal.\\n\\n**Observations.**\\n\\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n- Ports of embarkation have varying survival rates for Pcla\\n\\n=== MARKDOWN 29 ===\\n### Correlating categorical and numerical features\\n\\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n\\n**Observations.**\\n\\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n\\n**Decisions.**\\n\\n- Consider banding Fare feature.\\n\\n=== MARKDOWN 31 ===\\n## Wrangle data\\n\\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n\\n### Correcting by dropping features\\n\\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n\\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n\\n\\n=== MARKDOWN 33 ===\\n### Creating new feature extracting from existing\\n\\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n\\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n\\n**Observations.**\\n\\nWhen we plot Title, Age, and Survived, we note the following observations.\\n\\n- Most titles band Age groups accurately. For example: Master\\n\\n=== CODE 34 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset.Name.str.extract(\\' ([A-Za-z]+)\\\\.\\', expand=False)\\n\\npd.crosstab(train_df[\\'Title\\'], train_df[\\'Sex\\'])\\n\\n=== MARKDOWN 35 ===\\nWe can replace many titles with a more common name or classify them as `Rare`.\\n\\n=== CODE 36 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace([\\'Lady\\', \\'Countess\\',\\'Capt\\', \\'Col\\',\\\\\\n \\t\\'Don\\', \\'Dr\\', \\'Major\\', \\'Rev\\', \\'Sir\\', \\'Jonkheer\\', \\'Dona\\'], \\'Rare\\')\\n\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mlle\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Ms\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mme\\', \\'Mrs\\')\\n    \\ntrain_df[[\\'Title\\', \\'Survived\\']].groupby([\\'Title\\'], as_index=False).mean()\\n\\n=== MARKDOWN 37 ===\\nWe can convert the categorical titles to ordinal.\\n\\n=== CODE 38 ===\\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].map(title_mapping)\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].fillna(0)\\n\\ntrain_df.head()\\n\\n=== MARKDOWN 39 ===\\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now I have comprehensive information. Let me write the seed prompt with all the techniques I've learned.\"}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': 'REASONING: Now let me check if there are any additional techniques in the Alexis Cook tutorial that might be helpful, and also search for any advanced techniques that could help beat the 1.0 target score (which is 100% accuracy - extremely challenging).'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\\n\\n=== MARKDOWN 1 ===\\n# Part 2: Your coding environment\\n\\nIn this section, you\\'ll train your own machine learning model to improve your predictions.  _If you\\'ve never written code before or don\\'t have any experience with machine learning, don\\'t worry!  We don\\'t assume any prior experience in this tutorial._\\n\\n## The Notebook\\n\\nThe first thing to do is to create a Kaggle Notebook where you\\'ll store all of your code.  You c\\n\\n=== CODE 2 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load in \\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data proc\\n\\n=== MARKDOWN 3 ===\\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We\\'ll do that next.\\n\\n## Load the data\\n\\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\\n\\n![](https://i.imgur.com/OQBax9n.png)\\n\\nType the two lines of code below into your second code cell.  Then, once you\\'re done, either click on the blue pl\\n\\n=== CODE 4 ===\\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntrain_data.head()\\n\\n=== MARKDOWN 5 ===\\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It\\'s very important that you see this output **in your notebook** before proceeding with the tutorial!\\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\\n\\n=== CODE 6 ===\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\\ntest_data.head()\\n\\n=== MARKDOWN 7 ===\\nAs before, make sure that you see the output above in your notebook before continuing.  \\n\\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\\n\\n# Part 3: Your first submission\\n\\n=== CODE 8 ===\\nwomen = train_data.loc[train_data.Sex == \\'female\\'][\"Survived\"]\\nrate_women = sum(women)/len(women)\\n\\nprint(\"% of women who survived:\", rate_women)\\n\\n=== MARKDOWN 9 ===\\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\\n\\nThen, run the code below in another code cell:\\n\\n=== CODE 10 ===\\nmen = train_data.loc[train_data.Sex == \\'male\\'][\"Survived\"]\\nrate_men = sum(men)/len(men)\\n\\nprint(\"% of men who survived:\", rate_men)\\n\\n=== MARKDOWN 11 ===\\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\\n\\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\\n\\nBut at the end of the day, this gender-based s\\n\\n=== CODE 12 ===\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\\nX = pd.get_dummies(train_data[features])\\nX_test = pd.get_dummies(test_data[features])\\n\\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\\nmodel.f\\n\\n=== MARKDOWN 13 ===\\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\\n> Again, don\\'t worry if this code doesn\\'t make sense to you!  For now, we\\'ll focus on how to generate and submit predictions.\\n\\nOnce you\\'re ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \\n- Ensure tha\\n\\n=== MARKDOWN 14 ===\\n# Part 4: Learn more!\\n\\nIf you\\'re interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we\\'ve presented here.  You\\'ll also know enough to generate even better predictions!\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: The tutorial is basic. Let me search for advanced techniques that could help achieve very high accuracy on this problem, particularly since the target is 100% accuracy which is extremely challenging.'}, {'role': 'tool', 'content': 'SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80\\u202f% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random\\u202fForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n**Step‚Äëby‚Äëstep recipe**\\n\\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \\n\\n2. **Impute & create missing‚Äëvalue flags**  \\n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \\n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1\\u202fif Cabin not null, else\\u202f0).  \\n   * Optionally encode the original *Cabin* letter as a categorical feature.  \\n\\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \\n   * **FamilySize** = `SibSp + Parch + 1`  \\n   * **IsAlone** = 1\\u202fif *FamilySize*\\u202f=\\u202f1 else\\u202f0  \\n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \\n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \\n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \\n\\n   These engineered columns lifted baseline scores from ~72\\u202f% to ~78\\u202f% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \\n\\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35\\u202f% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \\n\\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \\n   * `n_estimators` (200‚Äë1000)  \\n   * `max_depth` (5‚Äë15)  \\n   * `min_samples_split` / `min_samples_leaf`  \\n   * `max_features` (sqrt, log2, or a fraction)  \\n\\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100\\u202f% Accuracy‚Äù notebook placed the author in the top\\u202f3\\u202f%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \\n\\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•\\u202f0.84) before uploading.  \\n\\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\\n\\n--- Result 2 ---\\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\\n\\nContent:\\nSeptember 10, 2016\\xa0\\xa0\\xa0\\xa0\\xa033min read\\n\\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\\n\\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\\n\\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I\\'m writing this post, I am ranked among the top 4% of all Kagglers.\\n\\nThis post is the opportunity to share my solution with you.\\n\\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I\\'ll follow with feature engineering and finally present the predictive model I set up.\\n\\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\\nThe main libraries involved in this tutorial are:\\n\\n- **Pandas** for data manipulation and ingestion\\n- **Matplotlib** and **seaborn** for data visualization\\n- **Numpy** for multidimensional array computing\\n- **sklearn** for machine learning and predictive modeling\\n\\n### Installation procedure\\n\\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\\n\\n### Nota Bene\\n\\nThis is my first attempt as a blogger and as a machine learning practitioner.\\n\\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\\n\\nHope you\\'ve got everything set on your computer. Let\\'s get started.\\n\\n## I - Exploratory data analysis\\n\\nAs in different data projects, we\\'ll first start diving into the data and build up our first intuitions.\\n\\nIn this section, we\\'ll be doing four things.\\n\\n- Data extraction : we\\'ll load the dataset and have a first look at it.\\n- Cleaning : we\\'ll fill in missing values.\\n- Plotting : we\\'ll create some interesting charts that\\'ll (hopefully) spot correlations and hidden insights out of the data.\\n- Assumptions : we\\'ll formulate hypotheses from the charts.\\n\\nWe tweak the style of this notebook a little bit to have centered plots.\\n\\n```\\nfrom IPython.core.display import HTML\\nHTML(\"\"\"\\n<style>\\n.output_png {\\n    display: table-cell;\\n    text-align: center;\\n    vertical-align: middle;\\n}\\n</style>\\n\"\"\");\\n```\\n\\nWe import the useful libraries.\\n\\n```\\n%matplotlib inline\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\nwarnings.filterwarnings(\\'ignore\\', category=DeprecationWarning)\\n\\nimport pandas as pd\\npd.options.display.max_columns = 100\\n\\nfrom matplotlib import pyplot as plt\\nimport numpy as np\\n\\nimport seaborn as sns\\n\\nimport pylab as plot\\nparams = {\\n    \\'axes.labelsize\\': \"large\",\\n    \\'xtick.labelsize\\': \\'x-large\\',\\n    \\'legend.fontsize\\': 20,\\n    \\'figure.dpi\\': 150,\\n    \\'figure.figsize\\': [25, 7]\\n}\\nplot.rcParams.update(params)\\n```\\n\\nTwo datasets are available: a training set and a test set.\\nWe\\'ll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\\n\\nWe\\'ll see how this procedure is done at the end of this post.\\n\\nNow let\\'s start by loading the training set.\\n\\n```\\ndata = pd.read_csv(\\'./data/train.csv\\')\\nprint(data.shape)\\n#(891, 12)\\n```\\n\\nWe have:\\n\\n- 891 rows\\n- 12 columns\\n\\nPandas allows you to have a sneak peak at your data.\\n\\n```\\ndata.head()\\n```\\n\\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\\n\\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he\\'s dead. The is the variable we\\'re going to predict.\\n\\nThe other variables describe the passengers. They are the **features**.\\n\\n- PassengerId: and id given to each traveler on the boat\\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\\n- The Name of the passeger\\n- The Sex\\n- The Age\\n- SibSp: number of siblings and spouses traveling with the passenger\\n- Parch: number of parents and children traveling with the passenger\\n- The ticket number\\n- The ticket Fare\\n- The cabin number\\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\\n\\nPandas allows you to a have a high-level simple statistical description of the numerical features.\\nThis can be done using the describe method.\\n\\n```\\ndata.describe()\\n```\\n\\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\\n\\nThe count variable shows that 177 values are missing in the Age column.\\n\\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\\n\\n```\\ndata[\\'Age\\'] = data[\\'Age\\'].fillna(data[\\'Age\\'].median())\\n```\\n\\nLet\\'s now make some charts.\\n\\nLet\\'s visualize survival based on the gender.\\n\\n```\\ndata[\\'Died\\'] = 1 - data[\\'Survived\\']\\ndata.groupby(\\'Sex\\').agg(\\'sum\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                          stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nIt looks like male passengers are more likely to succumb.\\n\\nLet\\'s plot the same graph but with ratio instead.\\n\\n```\\ndata.groupby(\\'Sex\\').agg(\\'mean\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                           stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\\n\\nLet\\'s now correlate the survival with the age variable.\\n\\n```\\nfig = plt.figure(figsize=(25, 7))\\nsns.violinplot(x=\\'Sex\\', y=\\'Age\\',\\n               hue=\\'Survived\\', data=data,\\n               split=True,\\n               palette={0: \"r\", 1: \"g\"}\\n              );\\n```\\n\\nAs we saw in the chart above and validate by the following:\\n\\n- Women survive more than men, as depicted by the larger female green histogram\\n\\nNow, we see that:\\n\\n- The age conditions the survival for male passengers:\\n\\n  - Younger male tend to survive\\n  - A large number of passengers between 20 and 40 succumb\\n- The age doesn\\'t seem to have a direct impact on the female survival\\n\\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\\n\\nRight?\\n\\nLet\\'s now focus on the Fare ticket of each passenger and see how it could impact the survival.\\n\\n```\\nfigure = plt.figure(figsize=(25, 7))\\nplt.hist([dat...\\n\\n--- Result 3 ---\\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\nURL: https://github.com/alicevillar/titanic-kaggle\\n\\nContent:\\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\\n\\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\\n\\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n- [Fork\\\\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n- [Star\\\\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n[6\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n\\n# alicevillar/titanic-kaggle\\n\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n\\nmain\\n\\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\\n\\nGo to file\\n\\nCode\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\\n| ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\\n| ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\\n| View all files |\\n\\n## Repository files navigation\\n\\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n\\nThe objective of Kaggle\\'s Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\\n\\n### Quick Start:\\n\\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\\n\\n### Dependencies:\\n\\n- [Numpy](https://numpy.org/)\\n- [Pandas](https://pandas.pydata.org/)\\n- [SciKit-Learn](https://scikit-learn.org/)\\n- [Matplotlib](https://matplotlib.org/)\\n- [Seaborn](https://seaborn.pydata.org/)\\n\\n### Approach\\n\\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\\n\\n### Kaggle Competition \\\\| Titanic Machine Learning from Disaster\\n\\nKaggle\\'s challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle\\'s [Competition Page](https://www.kaggle.com/c/titanic):\\n\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\\n\\n### Results\\n\\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\\n\\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\\n\\n## About\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n### Topics\\n\\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\\n\\n### Resources\\n\\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\\n\\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n### Stars\\n\\n[**6**\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\\n\\n### Watchers\\n\\n[**1**\\\\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\\n\\n### Forks\\n\\n[**3**\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\\n\\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\\n\\n--- Result 4 ---\\nTitle: Search code, repositories, users, issues, pull requests...\\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\n\\nContent:\\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[Skip to content](#start-of-content)\\n## Navigation Menu\\nToggle navigation\\n[](https://github.com/)\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nSearch or jump to...\\n# Search code, repositories, users, issues, pull requests...\\n</option></form>\\nSearch\\nClear\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n# Provide feedback\\n</option></form>\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancelSubmit feedback\\n# Saved searches\\n## Use saved searches to filter your results more quickly\\n</option></form>\\nName\\nQuery\\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\nCancelCreate saved search\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nResetting focus\\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\\n{{ message }}\\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\nmain\\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\nGo to file\\nCode\\nOpen more actions menu\\n## Folders and files\\n|Name|Name|\\nLast commit message\\n|\\nLast commit date\\n|\\n## Latest commit\\n## History\\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n|\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n|\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n|\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n|\\n|\\nView all files\\n|\\n## Repository files navigation\\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\~72% to \\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n# Titanic Survival Prediction\\n[](#titanic-survival-prediction)\\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\\n* **Detailed EDA**\\nA Jupyter notebook that walks through exploratory data analysis:\\n* Summary statistics\\n* Missing-value patterns\\n* Feature distributions and pairwise relationships\\n* Correlation heatmaps\\n* **Feature Engineering**\\nCreation of high-signal features from raw inputs, including:\\n* `Has\\\\_Cabin`(binary cabin indicator)\\n* `FareBin`(quantile-based fare categories)\\n* Group-median imputation for`Age`, then 10-year age bins\\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\\n* `Title`extracted and consolidated from passenger names\\n* **Model Comparison**\\nTraining and evaluation of multiple classifiers on the engineered feature set:\\n* Random Forest\\n* Support Vector Machine\\n* K-Nearest Neighbors (k=3,5,7)\\n* XGBoost\\n* LightGBM\\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\\n* **Analysis &amp; Interpretation**\\nInline Markdown commentary explains:\\n* Why each feature matters\\n* How missing data were handled\\n* The rationale for model selection\\n* Key takeaways and next-step recommendations\\n## Repository Structure\\n[](#repository-structure)\\ndata/\\n* train.csv # Official Kaggle training set\\n* test.csv # Official Kaggle test set\\nnotebooks/\\n* titanic\\\\_analysis.ipynb\\n‚Ä¢EDA, feature engineering, model training\\n‚Ä¢Detailed Markdown analysis\\n* README.md # Project overview and instructions\\n## Contributing\\n[](#contributing)\\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\\n## About\\nPredict Titanic survival using t...\\n\\n--- Result 5 ---\\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\n\\nContent:\\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\\nAman Krishna\\n2022-04-20T07:23:42Z\\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\n\\n## The art of fine-tuning a model\\n\\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\\n\\n7 min read\\n\\n\\nApr 19, 2022\\n\\n\\nListen\\n\\nShare\\n\\nPress enter or click to view image in full size\\n\\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\\n\\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\\n\\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\\n\\nYou can find the complete code on Github **_:_**\\n\\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \\n\\n**Machine Learning model build for survivor prediction for Kaggle\\'s titanic competition - kaggle_titanic/Model‚Ä¶**\\n\\ngithub.com]\\n\\n## Which Model to use?\\n\\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\\n\\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\\n\\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\\n\\n## Pre-Requisite\\n\\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\\n\\n### Dropping Features\\n\\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\\n\\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\\n\\n### Code\\n\\n### Dummify Data\\n\\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\\n\\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\\n\\n**We will be using One-Hot encoding on our categorical features.**\\n\\n### Code\\n\\n### Split Data\\n\\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\\n\\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\\n\\n## Training\\n\\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\\n\\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\\n\\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\\n\\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\\n\\n### Code\\n\\n## Fine Tuning\\n\\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\\n\\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\\n\\n### Code\\n\\n### Output\\n\\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\\n\\nPress enter or click to view image in full size\\n\\nGrid Search Results\\n\\n## Refining Search Space: Max Depth & Max Samples\\n\\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\\n\\n### How?\\n\\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\\n\\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\\n\\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest max_Depth & max_samples\\n\\n## Fine Tune: Min Sample Split & Min Sample Leaf\\n\\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest min_samples_leaf & min_samples_split\\n\\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\\n\\n## Fine Tune: Number of Estimators\\n\\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest n_estimator value\\n\\n## Refining Search Space: Number of estima...\\n\\n--- Result 6 ---\\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\\n\\nContent:\\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\\n\\n--- Result 7 ---\\nTitle: Titanic - Machine Learning from Disaster\\nURL: https://www.kaggle.com/c/titanic/code\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \\n\\n[... truncated 11780 characters ...]'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! The search confirms that achieving 100% accuracy is essentially impossible without cheating (using external data). The realistic best scores are in the 80-86% range. Let me update the seed prompt with this important context and add more specific techniques.'}, {'role': 'tool', 'content': '‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\\n  Source: Web search - Kaggle Titanic best techniques'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"# Titanic Survival Prediction - Techniques Guide\\n\\n## Data Understanding\\n**Reference notebooks for data characteristics:**\\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\\n- Target is imbalanced: 61.6% died, 38.4% survived\\n\\n## Feature Engineering (Critical for High Accuracy)\\n\\n### Title Extraction from Name\\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)`\\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\\n- Title is highly predictive: Master (young boys) had high survival\\n\\n### Family Features\\n- **FamilySize** = SibSp + Parch + 1\\n- **IsAlone** = 1 if FamilySize == 1, else 0\\n- Family size affects survival: solo travelers and very large families had lower survival\\n\\n### Cabin Features\\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\\n- ~77% missing - use Has_Cabin binary flag\\n\\n### Fare and Age Binning\\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\\n- Binning helps tree models find splits\\n\\n### Name Length\\n- **Name_length** = len(Name) - can be proxy for social status\\n\\n### Ticket Features\\n- Ticket prefix extraction (some tickets have letter prefixes)\\n- Ticket frequency (shared tickets indicate traveling together)\\n\\n## Missing Value Handling\\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\\n- **Embarked**: Fill with mode ('S' - Southampton)\\n- **Fare**: Fill with median (by Pclass)\\n- **Cabin**: Create Has_Cabin flag, don't impute\\n\\n## Models\\n\\n### Single Models (Baseline)\\nFor this small tabular dataset, tree-based models work well:\\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\\n- **XGBoost**: Similar parameters, use early stopping\\n- **Extra Trees**: n_estimators=500, max_depth=6\\n- **Logistic Regression**: Good baseline, use regularization\\n\\n### Ensemble Approaches (Higher Accuracy)\\n\\n#### Voting Classifier\\nCombine multiple models with soft voting:\\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\\n- Use soft voting (probability-based) for better results\\n\\n#### Stacking (Best Approach)\\nTwo-level stacking architecture:\\n1. **First Level (Base Models)**: \\n   - Random Forest\\n   - Extra Trees\\n   - AdaBoost\\n   - Gradient Boosting\\n   - SVC (with probability=True)\\n   \\n2. **Second Level (Meta-Classifier)**:\\n   - XGBoost or Logistic Regression\\n   \\n3. **Out-of-Fold Predictions**:\\n   - Use K-Fold (K=5) to generate out-of-fold predictions\\n   - This prevents overfitting when training meta-classifier\\n   - Each base model generates predictions on held-out fold\\n   - Stack these predictions as features for meta-classifier\\n\\n## Validation Strategy\\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\\n- Small dataset (891 samples) - CV is critical to avoid overfitting\\n- Track both train and validation scores to detect overfitting\\n\\n## Hyperparameter Tuning\\n- Use GridSearchCV or RandomizedSearchCV\\n- Key parameters to tune:\\n  - Tree depth (max_depth): 3-8\\n  - Number of estimators: 100-1000\\n  - Learning rate (for boosting): 0.01-0.1\\n  - Min samples per leaf: 1-5\\n- Use cross-validation during tuning\\n\\n## Feature Selection\\n- Use Recursive Feature Elimination (RFE) with cross-validation\\n- Check feature importances from tree models\\n- Most important features typically: Sex, Title, Pclass, Fare, Age\\n\\n## Key Insights from Top Kernels\\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\\n3. Title extraction captures both sex and age information effectively\\n4. Family size has non-linear relationship with survival\\n5. Ensemble methods consistently outperform single models\\n\\n## Submission Strategy\\n- Generate predictions using best ensemble model\\n- Consider averaging predictions from multiple models\\n- Threshold at 0.5 for binary classification\\n- Format: PassengerId, Survived (0 or 1)\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': \"REASONING: Let me add a few more cells to the EDA notebook to explore Title extraction and family size patterns, which are key features. Then I'll finalize the seed prompt.\"}, {'role': 'tool', 'content': 'Added code cell at 3'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 3-3\\n==================================================\\n\\nCell 3:\\n```\\n# Extract Title from Name\\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\\nprint('Title distribution:')\\nprint(train['Title'].value_counts())\\nprint('\\\\nSurvival by Title:')\\nprint(train.groupby('Title')['Survived'].agg(['mean', 'count']).sort_values('count', ascending=False))\\n```\\nOutput:\\nTitle distribution:\\nTitle\\nMr          517\\nMiss        182\\nMrs         125\\nMaster       40\\nDr            7\\nRev           6\\nCol           2\\nMlle          2\\nMajor         2\\nMs            1\\nMme           1\\nDon           1\\nLady          1\\nSir           1\\nCapt          1\\nCountess      1\\nJonkheer      1\\nName: count, dtype: int64\\n\\nSurvival by Title:\\n              mean  count\\nTitle                    \\nMr        0.156673    517\\nMiss      0.697802    182\\nMrs       0.792000    125\\nMaster    0.575000     40\\nDr        0.428571      7\\nRev       0.000000      6\\nMlle      1.000000      2\\nMajor     0.500000      2\\nCol       0.500000      2\\nCapt      0.000000      1\\nLady      1.000000      1\\nCountess  1.000000      1\\nDon       0.000000      1\\nJonkheer  0.000000      1\\nMme       1.000000      1\\nMs        1.000000      1\\nSir       1.000000      1\\n\"}]",
        "llm.input_tokens": 48665,
        "llm.output_tokens": 136,
        "llm.total_tokens": 48801,
        "llm.latency_ms": 5318.2213306427,
        "llm.completion": "[Tool Use: RecordFinding]",
        "llm.cost_usd": 0.14803500000000003
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "b539992b40c06597",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "RecordFindingTool",
      "kind": "INTERNAL",
      "start_time": 1767683682693180987,
      "end_time": 1767683682694414397,
      "duration": 0.00123341,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "RecordFindingTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.findings.RecordFindingTool object at 0x73eac380cf50>\", \"input\": {\"finding\": \"Title survival rates: Mr 15.7%, Miss 69.8%, Mrs 79.2%, Master 57.5%. Title is highly predictive - Mr (adult males) have very low survival, Mrs/Miss (females) have high survival, Master (young boys) moderate.\", \"source\": \"exploration/eda.ipynb\"}}",
        "tool.output": "{\"content\": \"‚úì Recorded finding: Title survival rates: Mr 15.7%, Miss 69.8%, Mrs 79.2%, Master 57.5%. Title is highly predictive - Mr...\\n  Source: exploration/eda.ipynb\", \"is_error\": false}",
        "tool.duration_ms": 1.277923583984375
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "e01a90a8086fe2d6",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683683973371396,
      "end_time": 1767683688751282608,
      "duration": 4.777911212,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n\ntool: ‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\n  Source: exploration/eda.ipynb\ntool: ‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\n  Source: exploration/eda.ipynb\ntool: === MARKDOWN 23 ===\n## Analyze by visualizing data\n\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\n\n### Correlating numerical features\n\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\n\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \n\n=== MARKDOWN 25 ===\n### Correlating numerical and ordinal features\n\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n\n**Observations.**\n\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n- Pclass varies in terms of Age distribution of passengers.\n\n**Decisions\n\n=== MARKDOWN 27 ===\n### Correlating categorical features\n\nNow we can correlate categorical features with our solution goal.\n\n**Observations.**\n\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\n- Ports of embarkation have varying survival rates for Pcla\n\n=== MARKDOWN 29 ===\n### Correlating categorical and numerical features\n\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n\n**Observations.**\n\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n\n**Decisions.**\n\n- Consider banding Fare feature.\n\n=== MARKDOWN 31 ===\n## Wrangle data\n\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n\n### Correcting by dropping features\n\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\n\n\n=== MARKDOWN 33 ===\n### Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n\n**Observations.**\n\nWhen we plot Title, Age, and Survived, we note the following observations.\n\n- Most titles band Age groups accurately. For example: Master\n\n=== CODE 34 ===\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])\n\n=== MARKDOWN 35 ===\nWe can replace many titles with a more common name or classify them as `Rare`.\n\n=== CODE 36 ===\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n\n=== MARKDOWN 37 ===\nWe can convert the categorical titles to ordinal.\n\n=== CODE 38 ===\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()\n\n=== MARKDOWN 39 ===\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\n\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: === MARKDOWN 0 ===\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\n\n=== MARKDOWN 1 ===\n# Part 2: Your coding environment\n\nIn this section, you'll train your own machine learning model to improve your predictions.  _If you've never written code before or don't have any experience with machine learning, don't worry!  We don't assume any prior experience in this tutorial._\n\n## The Notebook\n\nThe first thing to do is to create a Kaggle Notebook where you'll store all of your code.  You c\n\n=== CODE 2 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data proc\n\n=== MARKDOWN 3 ===\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We'll do that next.\n\n## Load the data\n\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\n\n![](https://i.imgur.com/OQBax9n.png)\n\nType the two lines of code below into your second code cell.  Then, once you're done, either click on the blue pl\n\n=== CODE 4 ===\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()\n\n=== MARKDOWN 5 ===\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It's very important that you see this output **in your notebook** before proceeding with the tutorial!\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\n\n=== CODE 6 ===\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()\n\n=== MARKDOWN 7 ===\nAs before, make sure that you see the output above in your notebook before continuing.  \n\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\n\n# Part 3: Your first submission\n\n=== CODE 8 ===\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\n=== MARKDOWN 9 ===\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\n\nThen, run the code below in another code cell:\n\n=== CODE 10 ===\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)\n\n=== MARKDOWN 11 ===\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\n\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\n\nBut at the end of the day, this gender-based s\n\n=== CODE 12 ===\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.f\n\n=== MARKDOWN 13 ===\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\n> Again, don't worry if this code doesn't make sense to you!  For now, we'll focus on how to generate and submit predictions.\n\nOnce you're ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \n- Ensure tha\n\n=== MARKDOWN 14 ===\n# Part 4: Learn more!\n\nIf you're interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we've presented here.  You'll also know enough to generate even better predictions!\n\n\ntool: SEARCH RESULTS (9 found)\n==================================================\n\n--- Result 1 ---\nTitle: ANSWER\n\nContent:\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80‚ÄØ% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random‚ÄØForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n**Step‚Äëby‚Äëstep recipe**\n\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \n\n2. **Impute & create missing‚Äëvalue flags**  \n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1‚ÄØif Cabin not null, else‚ÄØ0).  \n   * Optionally encode the original *Cabin* letter as a categorical feature.  \n\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \n   * **FamilySize** = `SibSp + Parch + 1`  \n   * **IsAlone** = 1‚ÄØif *FamilySize*‚ÄØ=‚ÄØ1 else‚ÄØ0  \n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \n\n   These engineered columns lifted baseline scores from ~72‚ÄØ% to ~78‚ÄØ% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \n\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35‚ÄØ% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \n\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \n   * `n_estimators` (200‚Äë1000)  \n   * `max_depth` (5‚Äë15)  \n   * `min_samples_split` / `min_samples_leaf`  \n   * `max_features` (sqrt, log2, or a fraction)  \n\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100‚ÄØ% Accuracy‚Äù notebook placed the author in the top‚ÄØ3‚ÄØ%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \n\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•‚ÄØ0.84) before uploading.  \n\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\n\n--- Result 2 ---\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\n\nContent:\nSeptember 10, 2016¬†¬†¬†¬†¬†33min read\n\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\n\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\n\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I'm writing this post, I am ranked among the top 4% of all Kagglers.\n\nThis post is the opportunity to share my solution with you.\n\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I'll follow with feature engineering and finally present the predictive model I set up.\n\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\nThe main libraries involved in this tutorial are:\n\n- **Pandas** for data manipulation and ingestion\n- **Matplotlib** and **seaborn** for data visualization\n- **Numpy** for multidimensional array computing\n- **sklearn** for machine learning and predictive modeling\n\n### Installation procedure\n\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\n\n### Nota Bene\n\nThis is my first attempt as a blogger and as a machine learning practitioner.\n\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\n\nHope you've got everything set on your computer. Let's get started.\n\n## I - Exploratory data analysis\n\nAs in different data projects, we'll first start diving into the data and build up our first intuitions.\n\nIn this section, we'll be doing four things.\n\n- Data extraction : we'll load the dataset and have a first look at it.\n- Cleaning : we'll fill in missing values.\n- Plotting : we'll create some interesting charts that'll (hopefully) spot correlations and hidden insights out of the data.\n- Assumptions : we'll formulate hypotheses from the charts.\n\nWe tweak the style of this notebook a little bit to have centered plots.\n\n```\nfrom IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n</style>\n\"\"\");\n```\n\nWe import the useful libraries.\n\n```\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\nimport pandas as pd\npd.options.display.max_columns = 100\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimport seaborn as sns\n\nimport pylab as plot\nparams = {\n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n}\nplot.rcParams.update(params)\n```\n\nTwo datasets are available: a training set and a test set.\nWe'll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\n\nWe'll see how this procedure is done at the end of this post.\n\nNow let's start by loading the training set.\n\n```\ndata = pd.read_csv('./data/train.csv')\nprint(data.shape)\n#(891, 12)\n```\n\nWe have:\n\n- 891 rows\n- 12 columns\n\nPandas allows you to have a sneak peak at your data.\n\n```\ndata.head()\n```\n\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\n\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he's dead. The is the variable we're going to predict.\n\nThe other variables describe the passengers. They are the **features**.\n\n- PassengerId: and id given to each traveler on the boat\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\n- The Name of the passeger\n- The Sex\n- The Age\n- SibSp: number of siblings and spouses traveling with the passenger\n- Parch: number of parents and children traveling with the passenger\n- The ticket number\n- The ticket Fare\n- The cabin number\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\n\nPandas allows you to a have a high-level simple statistical description of the numerical features.\nThis can be done using the describe method.\n\n```\ndata.describe()\n```\n\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\n| --- | --- | --- | --- | --- | --- | --- |\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\n\nThe count variable shows that 177 values are missing in the Age column.\n\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\n\n```\ndata['Age'] = data['Age'].fillna(data['Age'].median())\n```\n\nLet's now make some charts.\n\nLet's visualize survival based on the gender.\n\n```\ndata['Died'] = 1 - data['Survived']\ndata.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                          stacked=True, colors=['g', 'r']);\n```\n\nIt looks like male passengers are more likely to succumb.\n\nLet's plot the same graph but with ratio instead.\n\n```\ndata.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                           stacked=True, colors=['g', 'r']);\n```\n\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\n\nLet's now correlate the survival with the age variable.\n\n```\nfig = plt.figure(figsize=(25, 7))\nsns.violinplot(x='Sex', y='Age',\n               hue='Survived', data=data,\n               split=True,\n               palette={0: \"r\", 1: \"g\"}\n              );\n```\n\nAs we saw in the chart above and validate by the following:\n\n- Women survive more than men, as depicted by the larger female green histogram\n\nNow, we see that:\n\n- The age conditions the survival for male passengers:\n\n  - Younger male tend to survive\n  - A large number of passengers between 20 and 40 succumb\n- The age doesn't seem to have a direct impact on the female survival\n\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\n\nRight?\n\nLet's now focus on the Fare ticket of each passenger and see how it could impact the survival.\n\n```\nfigure = plt.figure(figsize=(25, 7))\nplt.hist([dat...\n\n--- Result 3 ---\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\nURL: https://github.com/alicevillar/titanic-kaggle\n\nContent:\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n- [Fork\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n- [Star\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n[6\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n\n# alicevillar/titanic-kaggle\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmain\n\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\n| ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\n| ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n\nThe objective of Kaggle's Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\n\n### Quick Start:\n\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\n\n### Dependencies:\n\n- [Numpy](https://numpy.org/)\n- [Pandas](https://pandas.pydata.org/)\n- [SciKit-Learn](https://scikit-learn.org/)\n- [Matplotlib](https://matplotlib.org/)\n- [Seaborn](https://seaborn.pydata.org/)\n\n### Approach\n\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\n\n### Kaggle Competition \\| Titanic Machine Learning from Disaster\n\nKaggle's challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle's [Competition Page](https://www.kaggle.com/c/titanic):\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\n\n### Results\n\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\n\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\n\n## About\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n### Topics\n\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\n\n### Resources\n\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\n\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n### Stars\n\n[**6**\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\n\n### Watchers\n\n[**1**\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\n\n### Forks\n\n[**3**\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\n\n--- Result 4 ---\nTitle: Search code, repositories, users, issues, pull requests...\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\n\nContent:\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\nmain\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n|\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n|\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n|\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\~72% to \\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n# Titanic Survival Prediction\n[](#titanic-survival-prediction)\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\n* **Detailed EDA**\nA Jupyter notebook that walks through exploratory data analysis:\n* Summary statistics\n* Missing-value patterns\n* Feature distributions and pairwise relationships\n* Correlation heatmaps\n* **Feature Engineering**\nCreation of high-signal features from raw inputs, including:\n* `Has\\_Cabin`(binary cabin indicator)\n* `FareBin`(quantile-based fare categories)\n* Group-median imputation for`Age`, then 10-year age bins\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\n* `Title`extracted and consolidated from passenger names\n* **Model Comparison**\nTraining and evaluation of multiple classifiers on the engineered feature set:\n* Random Forest\n* Support Vector Machine\n* K-Nearest Neighbors (k=3,5,7)\n* XGBoost\n* LightGBM\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\n* **Analysis &amp; Interpretation**\nInline Markdown commentary explains:\n* Why each feature matters\n* How missing data were handled\n* The rationale for model selection\n* Key takeaways and next-step recommendations\n## Repository Structure\n[](#repository-structure)\ndata/\n* train.csv # Official Kaggle training set\n* test.csv # Official Kaggle test set\nnotebooks/\n* titanic\\_analysis.ipynb\n‚Ä¢EDA, feature engineering, model training\n‚Ä¢Detailed Markdown analysis\n* README.md # Project overview and instructions\n## Contributing\n[](#contributing)\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\n## About\nPredict Titanic survival using t...\n\n--- Result 5 ---\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\n\nContent:\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\nAman Krishna\n2022-04-20T07:23:42Z\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\n\n## The art of fine-tuning a model\n\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\n\n7 min read\n\n\nApr 19, 2022\n\n\nListen\n\nShare\n\nPress enter or click to view image in full size\n\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\n\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\n\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\n\nYou can find the complete code on Github **_:_**\n\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \n\n**Machine Learning model build for survivor prediction for Kaggle's titanic competition - kaggle_titanic/Model‚Ä¶**\n\ngithub.com]\n\n## Which Model to use?\n\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\n\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\n\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\n\n## Pre-Requisite\n\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\n\n### Dropping Features\n\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\n\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\n\n### Code\n\n### Dummify Data\n\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\n\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\n\n**We will be using One-Hot encoding on our categorical features.**\n\n### Code\n\n### Split Data\n\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\n\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\n\n## Training\n\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\n\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\n\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\n\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\n\n### Code\n\n## Fine Tuning\n\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\n\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\n\n### Code\n\n### Output\n\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\n\nPress enter or click to view image in full size\n\nGrid Search Results\n\n## Refining Search Space: Max Depth & Max Samples\n\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\n\n### How?\n\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\n\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\n\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest max_Depth & max_samples\n\n## Fine Tune: Min Sample Split & Min Sample Leaf\n\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest min_samples_leaf & min_samples_split\n\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\n\n## Fine Tune: Number of Estimators\n\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest n_estimator value\n\n## Refining Search Space: Number of estima...\n\n--- Result 6 ---\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\n\nContent:\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\n\n--- Result 7 ---\nTitle: Titanic - Machine Learning from Disaster\nURL: https://www.kaggle.com/c/titanic/code\n\nContent:\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \n\n[... truncated 11780 characters ...]\ntool: ‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\n  Source: Web search - Kaggle Titanic best techniques\ntool: # Titanic Survival Prediction - Techniques Guide\n\n## Data Understanding\n**Reference notebooks for data characteristics:**\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\n- Target is imbalanced: 61.6% died, 38.4% survived\n\n## Feature Engineering (Critical for High Accuracy)\n\n### Title Extraction from Name\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\.', expand=False)`\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\n- Title is highly predictive: Master (young boys) had high survival\n\n### Family Features\n- **FamilySize** = SibSp + Parch + 1\n- **IsAlone** = 1 if FamilySize == 1, else 0\n- Family size affects survival: solo travelers and very large families had lower survival\n\n### Cabin Features\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\n- ~77% missing - use Has_Cabin binary flag\n\n### Fare and Age Binning\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\n- Binning helps tree models find splits\n\n### Name Length\n- **Name_length** = len(Name) - can be proxy for social status\n\n### Ticket Features\n- Ticket prefix extraction (some tickets have letter prefixes)\n- Ticket frequency (shared tickets indicate traveling together)\n\n## Missing Value Handling\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\n- **Embarked**: Fill with mode ('S' - Southampton)\n- **Fare**: Fill with median (by Pclass)\n- **Cabin**: Create Has_Cabin flag, don't impute\n\n## Models\n\n### Single Models (Baseline)\nFor this small tabular dataset, tree-based models work well:\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\n- **XGBoost**: Similar parameters, use early stopping\n- **Extra Trees**: n_estimators=500, max_depth=6\n- **Logistic Regression**: Good baseline, use regularization\n\n### Ensemble Approaches (Higher Accuracy)\n\n#### Voting Classifier\nCombine multiple models with soft voting:\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n- Use soft voting (probability-based) for better results\n\n#### Stacking (Best Approach)\nTwo-level stacking architecture:\n1. **First Level (Base Models)**: \n   - Random Forest\n   - Extra Trees\n   - AdaBoost\n   - Gradient Boosting\n   - SVC (with probability=True)\n   \n2. **Second Level (Meta-Classifier)**:\n   - XGBoost or Logistic Regression\n   \n3. **Out-of-Fold Predictions**:\n   - Use K-Fold (K=5) to generate out-of-fold predictions\n   - This prevents overfitting when training meta-classifier\n   - Each base model generates predictions on held-out fold\n   - Stack these predictions as features for meta-classifier\n\n## Validation Strategy\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\n- Small dataset (891 samples) - CV is critical to avoid overfitting\n- Track both train and validation scores to detect overfitting\n\n## Hyperparameter Tuning\n- Use GridSearchCV or RandomizedSearchCV\n- Key parameters to tune:\n  - Tree depth (max_depth): 3-8\n  - Number of estimators: 100-1000\n  - Learning rate (for boosting): 0.01-0.1\n  - Min samples per leaf: 1-5\n- Use cross-validation during tuning\n\n## Feature Selection\n- Use Recursive Feature Elimination (RFE) with cross-validation\n- Check feature importances from tree models\n- Most important features typically: Sex, Title, Pclass, Fare, Age\n\n## Key Insights from Top Kernels\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\n3. Title extraction captures both sex and age information effectively\n4. Family size has non-linear relationship with survival\n5. Ensemble methods consistently outperform single models\n\n## Submission Strategy\n- Generate predictions using best ensemble model\n- Consider averaging predictions from multiple models\n- Threshold at 0.5 for binary classification\n- Format: PassengerId, Survived (0 or 1)\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: Added code cell at 3\ntool: Executed cells 3-3\n==================================================\n\nCell 3:\n```\n# Extract Title from Name\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\nprint('Title distribution:')\nprint(train['Title'].value_counts())\nprint('\\nSurvival by Title:')\nprint(train.groupby('Title')['Survived'].agg(['mean', 'count']).sort_values('count', ascending=False))\n```\nOutput:\nTitle distribution:\nTitle\nMr          517\nMiss        182\nMrs         125\nMaster       40\nDr            7\nRev           6\nCol           2\nMlle          2\nMajor         2\nMs            1\nMme           1\nDon           1\nLady          1\nSir           1\nCapt          1\nCountess      1\nJonkheer      1\nName: count, dtype: int64\n\nSurvival by Title:\n              mean  count\nTitle                    \nMr        0.156673    517\nMiss      0.697802    182\nMrs       0.792000    125\nMaster    0.575000     40\nDr        0.428571      7\nRev       0.000000      6\nMlle      1.000000      2\nMajor     0.500000      2\nCol       0.500000      2\nCapt      0.000000      1\nLady      1.000000      1\nCountess  1.000000      1\nDon       0.000000      1\nJonkheer  0.000000      1\nMme       1.000000      1\nMs        1.000000      1\nSir       1.000000      1\n\ntool: ‚úì Recorded finding: Title survival rates: Mr 15.7%, Miss 69.8%, Mrs 79.2%, Master 57.5%. Title is highly predictive - Mr...\n  Source: exploration/eda.ipynb",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb'}, {'role': 'tool', 'content': '‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb'}, {'role': 'assistant', 'content': 'REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.'}, {'role': 'tool', 'content': '=== MARKDOWN 23 ===\\n## Analyze by visualizing data\\n\\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n\\n### Correlating numerical features\\n\\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\\n\\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \\n\\n=== MARKDOWN 25 ===\\n### Correlating numerical and ordinal features\\n\\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n\\n**Observations.**\\n\\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n- Pclass varies in terms of Age distribution of passengers.\\n\\n**Decisions\\n\\n=== MARKDOWN 27 ===\\n### Correlating categorical features\\n\\nNow we can correlate categorical features with our solution goal.\\n\\n**Observations.**\\n\\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n- Ports of embarkation have varying survival rates for Pcla\\n\\n=== MARKDOWN 29 ===\\n### Correlating categorical and numerical features\\n\\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n\\n**Observations.**\\n\\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n\\n**Decisions.**\\n\\n- Consider banding Fare feature.\\n\\n=== MARKDOWN 31 ===\\n## Wrangle data\\n\\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n\\n### Correcting by dropping features\\n\\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n\\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n\\n\\n=== MARKDOWN 33 ===\\n### Creating new feature extracting from existing\\n\\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n\\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n\\n**Observations.**\\n\\nWhen we plot Title, Age, and Survived, we note the following observations.\\n\\n- Most titles band Age groups accurately. For example: Master\\n\\n=== CODE 34 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset.Name.str.extract(\\' ([A-Za-z]+)\\\\.\\', expand=False)\\n\\npd.crosstab(train_df[\\'Title\\'], train_df[\\'Sex\\'])\\n\\n=== MARKDOWN 35 ===\\nWe can replace many titles with a more common name or classify them as `Rare`.\\n\\n=== CODE 36 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace([\\'Lady\\', \\'Countess\\',\\'Capt\\', \\'Col\\',\\\\\\n \\t\\'Don\\', \\'Dr\\', \\'Major\\', \\'Rev\\', \\'Sir\\', \\'Jonkheer\\', \\'Dona\\'], \\'Rare\\')\\n\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mlle\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Ms\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mme\\', \\'Mrs\\')\\n    \\ntrain_df[[\\'Title\\', \\'Survived\\']].groupby([\\'Title\\'], as_index=False).mean()\\n\\n=== MARKDOWN 37 ===\\nWe can convert the categorical titles to ordinal.\\n\\n=== CODE 38 ===\\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].map(title_mapping)\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].fillna(0)\\n\\ntrain_df.head()\\n\\n=== MARKDOWN 39 ===\\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now I have comprehensive information. Let me write the seed prompt with all the techniques I've learned.\"}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': 'REASONING: Now let me check if there are any additional techniques in the Alexis Cook tutorial that might be helpful, and also search for any advanced techniques that could help beat the 1.0 target score (which is 100% accuracy - extremely challenging).'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\\n\\n=== MARKDOWN 1 ===\\n# Part 2: Your coding environment\\n\\nIn this section, you\\'ll train your own machine learning model to improve your predictions.  _If you\\'ve never written code before or don\\'t have any experience with machine learning, don\\'t worry!  We don\\'t assume any prior experience in this tutorial._\\n\\n## The Notebook\\n\\nThe first thing to do is to create a Kaggle Notebook where you\\'ll store all of your code.  You c\\n\\n=== CODE 2 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load in \\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data proc\\n\\n=== MARKDOWN 3 ===\\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We\\'ll do that next.\\n\\n## Load the data\\n\\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\\n\\n![](https://i.imgur.com/OQBax9n.png)\\n\\nType the two lines of code below into your second code cell.  Then, once you\\'re done, either click on the blue pl\\n\\n=== CODE 4 ===\\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntrain_data.head()\\n\\n=== MARKDOWN 5 ===\\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It\\'s very important that you see this output **in your notebook** before proceeding with the tutorial!\\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\\n\\n=== CODE 6 ===\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\\ntest_data.head()\\n\\n=== MARKDOWN 7 ===\\nAs before, make sure that you see the output above in your notebook before continuing.  \\n\\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\\n\\n# Part 3: Your first submission\\n\\n=== CODE 8 ===\\nwomen = train_data.loc[train_data.Sex == \\'female\\'][\"Survived\"]\\nrate_women = sum(women)/len(women)\\n\\nprint(\"% of women who survived:\", rate_women)\\n\\n=== MARKDOWN 9 ===\\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\\n\\nThen, run the code below in another code cell:\\n\\n=== CODE 10 ===\\nmen = train_data.loc[train_data.Sex == \\'male\\'][\"Survived\"]\\nrate_men = sum(men)/len(men)\\n\\nprint(\"% of men who survived:\", rate_men)\\n\\n=== MARKDOWN 11 ===\\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\\n\\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\\n\\nBut at the end of the day, this gender-based s\\n\\n=== CODE 12 ===\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\\nX = pd.get_dummies(train_data[features])\\nX_test = pd.get_dummies(test_data[features])\\n\\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\\nmodel.f\\n\\n=== MARKDOWN 13 ===\\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\\n> Again, don\\'t worry if this code doesn\\'t make sense to you!  For now, we\\'ll focus on how to generate and submit predictions.\\n\\nOnce you\\'re ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \\n- Ensure tha\\n\\n=== MARKDOWN 14 ===\\n# Part 4: Learn more!\\n\\nIf you\\'re interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we\\'ve presented here.  You\\'ll also know enough to generate even better predictions!\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: The tutorial is basic. Let me search for advanced techniques that could help achieve very high accuracy on this problem, particularly since the target is 100% accuracy which is extremely challenging.'}, {'role': 'tool', 'content': 'SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80\\u202f% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random\\u202fForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n**Step‚Äëby‚Äëstep recipe**\\n\\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \\n\\n2. **Impute & create missing‚Äëvalue flags**  \\n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \\n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1\\u202fif Cabin not null, else\\u202f0).  \\n   * Optionally encode the original *Cabin* letter as a categorical feature.  \\n\\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \\n   * **FamilySize** = `SibSp + Parch + 1`  \\n   * **IsAlone** = 1\\u202fif *FamilySize*\\u202f=\\u202f1 else\\u202f0  \\n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \\n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \\n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \\n\\n   These engineered columns lifted baseline scores from ~72\\u202f% to ~78\\u202f% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \\n\\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35\\u202f% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \\n\\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \\n   * `n_estimators` (200‚Äë1000)  \\n   * `max_depth` (5‚Äë15)  \\n   * `min_samples_split` / `min_samples_leaf`  \\n   * `max_features` (sqrt, log2, or a fraction)  \\n\\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100\\u202f% Accuracy‚Äù notebook placed the author in the top\\u202f3\\u202f%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \\n\\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•\\u202f0.84) before uploading.  \\n\\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\\n\\n--- Result 2 ---\\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\\n\\nContent:\\nSeptember 10, 2016\\xa0\\xa0\\xa0\\xa0\\xa033min read\\n\\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\\n\\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\\n\\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I\\'m writing this post, I am ranked among the top 4% of all Kagglers.\\n\\nThis post is the opportunity to share my solution with you.\\n\\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I\\'ll follow with feature engineering and finally present the predictive model I set up.\\n\\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\\nThe main libraries involved in this tutorial are:\\n\\n- **Pandas** for data manipulation and ingestion\\n- **Matplotlib** and **seaborn** for data visualization\\n- **Numpy** for multidimensional array computing\\n- **sklearn** for machine learning and predictive modeling\\n\\n### Installation procedure\\n\\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\\n\\n### Nota Bene\\n\\nThis is my first attempt as a blogger and as a machine learning practitioner.\\n\\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\\n\\nHope you\\'ve got everything set on your computer. Let\\'s get started.\\n\\n## I - Exploratory data analysis\\n\\nAs in different data projects, we\\'ll first start diving into the data and build up our first intuitions.\\n\\nIn this section, we\\'ll be doing four things.\\n\\n- Data extraction : we\\'ll load the dataset and have a first look at it.\\n- Cleaning : we\\'ll fill in missing values.\\n- Plotting : we\\'ll create some interesting charts that\\'ll (hopefully) spot correlations and hidden insights out of the data.\\n- Assumptions : we\\'ll formulate hypotheses from the charts.\\n\\nWe tweak the style of this notebook a little bit to have centered plots.\\n\\n```\\nfrom IPython.core.display import HTML\\nHTML(\"\"\"\\n<style>\\n.output_png {\\n    display: table-cell;\\n    text-align: center;\\n    vertical-align: middle;\\n}\\n</style>\\n\"\"\");\\n```\\n\\nWe import the useful libraries.\\n\\n```\\n%matplotlib inline\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\nwarnings.filterwarnings(\\'ignore\\', category=DeprecationWarning)\\n\\nimport pandas as pd\\npd.options.display.max_columns = 100\\n\\nfrom matplotlib import pyplot as plt\\nimport numpy as np\\n\\nimport seaborn as sns\\n\\nimport pylab as plot\\nparams = {\\n    \\'axes.labelsize\\': \"large\",\\n    \\'xtick.labelsize\\': \\'x-large\\',\\n    \\'legend.fontsize\\': 20,\\n    \\'figure.dpi\\': 150,\\n    \\'figure.figsize\\': [25, 7]\\n}\\nplot.rcParams.update(params)\\n```\\n\\nTwo datasets are available: a training set and a test set.\\nWe\\'ll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\\n\\nWe\\'ll see how this procedure is done at the end of this post.\\n\\nNow let\\'s start by loading the training set.\\n\\n```\\ndata = pd.read_csv(\\'./data/train.csv\\')\\nprint(data.shape)\\n#(891, 12)\\n```\\n\\nWe have:\\n\\n- 891 rows\\n- 12 columns\\n\\nPandas allows you to have a sneak peak at your data.\\n\\n```\\ndata.head()\\n```\\n\\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\\n\\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he\\'s dead. The is the variable we\\'re going to predict.\\n\\nThe other variables describe the passengers. They are the **features**.\\n\\n- PassengerId: and id given to each traveler on the boat\\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\\n- The Name of the passeger\\n- The Sex\\n- The Age\\n- SibSp: number of siblings and spouses traveling with the passenger\\n- Parch: number of parents and children traveling with the passenger\\n- The ticket number\\n- The ticket Fare\\n- The cabin number\\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\\n\\nPandas allows you to a have a high-level simple statistical description of the numerical features.\\nThis can be done using the describe method.\\n\\n```\\ndata.describe()\\n```\\n\\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\\n\\nThe count variable shows that 177 values are missing in the Age column.\\n\\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\\n\\n```\\ndata[\\'Age\\'] = data[\\'Age\\'].fillna(data[\\'Age\\'].median())\\n```\\n\\nLet\\'s now make some charts.\\n\\nLet\\'s visualize survival based on the gender.\\n\\n```\\ndata[\\'Died\\'] = 1 - data[\\'Survived\\']\\ndata.groupby(\\'Sex\\').agg(\\'sum\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                          stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nIt looks like male passengers are more likely to succumb.\\n\\nLet\\'s plot the same graph but with ratio instead.\\n\\n```\\ndata.groupby(\\'Sex\\').agg(\\'mean\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                           stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\\n\\nLet\\'s now correlate the survival with the age variable.\\n\\n```\\nfig = plt.figure(figsize=(25, 7))\\nsns.violinplot(x=\\'Sex\\', y=\\'Age\\',\\n               hue=\\'Survived\\', data=data,\\n               split=True,\\n               palette={0: \"r\", 1: \"g\"}\\n              );\\n```\\n\\nAs we saw in the chart above and validate by the following:\\n\\n- Women survive more than men, as depicted by the larger female green histogram\\n\\nNow, we see that:\\n\\n- The age conditions the survival for male passengers:\\n\\n  - Younger male tend to survive\\n  - A large number of passengers between 20 and 40 succumb\\n- The age doesn\\'t seem to have a direct impact on the female survival\\n\\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\\n\\nRight?\\n\\nLet\\'s now focus on the Fare ticket of each passenger and see how it could impact the survival.\\n\\n```\\nfigure = plt.figure(figsize=(25, 7))\\nplt.hist([dat...\\n\\n--- Result 3 ---\\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\nURL: https://github.com/alicevillar/titanic-kaggle\\n\\nContent:\\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\\n\\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\\n\\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n- [Fork\\\\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n- [Star\\\\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n[6\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n\\n# alicevillar/titanic-kaggle\\n\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n\\nmain\\n\\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\\n\\nGo to file\\n\\nCode\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\\n| ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\\n| ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\\n| View all files |\\n\\n## Repository files navigation\\n\\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n\\nThe objective of Kaggle\\'s Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\\n\\n### Quick Start:\\n\\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\\n\\n### Dependencies:\\n\\n- [Numpy](https://numpy.org/)\\n- [Pandas](https://pandas.pydata.org/)\\n- [SciKit-Learn](https://scikit-learn.org/)\\n- [Matplotlib](https://matplotlib.org/)\\n- [Seaborn](https://seaborn.pydata.org/)\\n\\n### Approach\\n\\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\\n\\n### Kaggle Competition \\\\| Titanic Machine Learning from Disaster\\n\\nKaggle\\'s challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle\\'s [Competition Page](https://www.kaggle.com/c/titanic):\\n\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\\n\\n### Results\\n\\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\\n\\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\\n\\n## About\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n### Topics\\n\\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\\n\\n### Resources\\n\\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\\n\\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n### Stars\\n\\n[**6**\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\\n\\n### Watchers\\n\\n[**1**\\\\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\\n\\n### Forks\\n\\n[**3**\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\\n\\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\\n\\n--- Result 4 ---\\nTitle: Search code, repositories, users, issues, pull requests...\\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\n\\nContent:\\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[Skip to content](#start-of-content)\\n## Navigation Menu\\nToggle navigation\\n[](https://github.com/)\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nSearch or jump to...\\n# Search code, repositories, users, issues, pull requests...\\n</option></form>\\nSearch\\nClear\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n# Provide feedback\\n</option></form>\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancelSubmit feedback\\n# Saved searches\\n## Use saved searches to filter your results more quickly\\n</option></form>\\nName\\nQuery\\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\nCancelCreate saved search\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nResetting focus\\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\\n{{ message }}\\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\nmain\\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\nGo to file\\nCode\\nOpen more actions menu\\n## Folders and files\\n|Name|Name|\\nLast commit message\\n|\\nLast commit date\\n|\\n## Latest commit\\n## History\\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n|\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n|\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n|\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n|\\n|\\nView all files\\n|\\n## Repository files navigation\\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\~72% to \\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n# Titanic Survival Prediction\\n[](#titanic-survival-prediction)\\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\\n* **Detailed EDA**\\nA Jupyter notebook that walks through exploratory data analysis:\\n* Summary statistics\\n* Missing-value patterns\\n* Feature distributions and pairwise relationships\\n* Correlation heatmaps\\n* **Feature Engineering**\\nCreation of high-signal features from raw inputs, including:\\n* `Has\\\\_Cabin`(binary cabin indicator)\\n* `FareBin`(quantile-based fare categories)\\n* Group-median imputation for`Age`, then 10-year age bins\\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\\n* `Title`extracted and consolidated from passenger names\\n* **Model Comparison**\\nTraining and evaluation of multiple classifiers on the engineered feature set:\\n* Random Forest\\n* Support Vector Machine\\n* K-Nearest Neighbors (k=3,5,7)\\n* XGBoost\\n* LightGBM\\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\\n* **Analysis &amp; Interpretation**\\nInline Markdown commentary explains:\\n* Why each feature matters\\n* How missing data were handled\\n* The rationale for model selection\\n* Key takeaways and next-step recommendations\\n## Repository Structure\\n[](#repository-structure)\\ndata/\\n* train.csv # Official Kaggle training set\\n* test.csv # Official Kaggle test set\\nnotebooks/\\n* titanic\\\\_analysis.ipynb\\n‚Ä¢EDA, feature engineering, model training\\n‚Ä¢Detailed Markdown analysis\\n* README.md # Project overview and instructions\\n## Contributing\\n[](#contributing)\\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\\n## About\\nPredict Titanic survival using t...\\n\\n--- Result 5 ---\\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\n\\nContent:\\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\\nAman Krishna\\n2022-04-20T07:23:42Z\\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\n\\n## The art of fine-tuning a model\\n\\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\\n\\n7 min read\\n\\n\\nApr 19, 2022\\n\\n\\nListen\\n\\nShare\\n\\nPress enter or click to view image in full size\\n\\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\\n\\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\\n\\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\\n\\nYou can find the complete code on Github **_:_**\\n\\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \\n\\n**Machine Learning model build for survivor prediction for Kaggle\\'s titanic competition - kaggle_titanic/Model‚Ä¶**\\n\\ngithub.com]\\n\\n## Which Model to use?\\n\\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\\n\\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\\n\\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\\n\\n## Pre-Requisite\\n\\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\\n\\n### Dropping Features\\n\\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\\n\\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\\n\\n### Code\\n\\n### Dummify Data\\n\\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\\n\\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\\n\\n**We will be using One-Hot encoding on our categorical features.**\\n\\n### Code\\n\\n### Split Data\\n\\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\\n\\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\\n\\n## Training\\n\\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\\n\\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\\n\\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\\n\\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\\n\\n### Code\\n\\n## Fine Tuning\\n\\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\\n\\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\\n\\n### Code\\n\\n### Output\\n\\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\\n\\nPress enter or click to view image in full size\\n\\nGrid Search Results\\n\\n## Refining Search Space: Max Depth & Max Samples\\n\\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\\n\\n### How?\\n\\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\\n\\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\\n\\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest max_Depth & max_samples\\n\\n## Fine Tune: Min Sample Split & Min Sample Leaf\\n\\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest min_samples_leaf & min_samples_split\\n\\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\\n\\n## Fine Tune: Number of Estimators\\n\\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest n_estimator value\\n\\n## Refining Search Space: Number of estima...\\n\\n--- Result 6 ---\\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\\n\\nContent:\\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\\n\\n--- Result 7 ---\\nTitle: Titanic - Machine Learning from Disaster\\nURL: https://www.kaggle.com/c/titanic/code\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \\n\\n[... truncated 11780 characters ...]'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! The search confirms that achieving 100% accuracy is essentially impossible without cheating (using external data). The realistic best scores are in the 80-86% range. Let me update the seed prompt with this important context and add more specific techniques.'}, {'role': 'tool', 'content': '‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\\n  Source: Web search - Kaggle Titanic best techniques'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"# Titanic Survival Prediction - Techniques Guide\\n\\n## Data Understanding\\n**Reference notebooks for data characteristics:**\\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\\n- Target is imbalanced: 61.6% died, 38.4% survived\\n\\n## Feature Engineering (Critical for High Accuracy)\\n\\n### Title Extraction from Name\\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)`\\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\\n- Title is highly predictive: Master (young boys) had high survival\\n\\n### Family Features\\n- **FamilySize** = SibSp + Parch + 1\\n- **IsAlone** = 1 if FamilySize == 1, else 0\\n- Family size affects survival: solo travelers and very large families had lower survival\\n\\n### Cabin Features\\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\\n- ~77% missing - use Has_Cabin binary flag\\n\\n### Fare and Age Binning\\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\\n- Binning helps tree models find splits\\n\\n### Name Length\\n- **Name_length** = len(Name) - can be proxy for social status\\n\\n### Ticket Features\\n- Ticket prefix extraction (some tickets have letter prefixes)\\n- Ticket frequency (shared tickets indicate traveling together)\\n\\n## Missing Value Handling\\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\\n- **Embarked**: Fill with mode ('S' - Southampton)\\n- **Fare**: Fill with median (by Pclass)\\n- **Cabin**: Create Has_Cabin flag, don't impute\\n\\n## Models\\n\\n### Single Models (Baseline)\\nFor this small tabular dataset, tree-based models work well:\\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\\n- **XGBoost**: Similar parameters, use early stopping\\n- **Extra Trees**: n_estimators=500, max_depth=6\\n- **Logistic Regression**: Good baseline, use regularization\\n\\n### Ensemble Approaches (Higher Accuracy)\\n\\n#### Voting Classifier\\nCombine multiple models with soft voting:\\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\\n- Use soft voting (probability-based) for better results\\n\\n#### Stacking (Best Approach)\\nTwo-level stacking architecture:\\n1. **First Level (Base Models)**: \\n   - Random Forest\\n   - Extra Trees\\n   - AdaBoost\\n   - Gradient Boosting\\n   - SVC (with probability=True)\\n   \\n2. **Second Level (Meta-Classifier)**:\\n   - XGBoost or Logistic Regression\\n   \\n3. **Out-of-Fold Predictions**:\\n   - Use K-Fold (K=5) to generate out-of-fold predictions\\n   - This prevents overfitting when training meta-classifier\\n   - Each base model generates predictions on held-out fold\\n   - Stack these predictions as features for meta-classifier\\n\\n## Validation Strategy\\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\\n- Small dataset (891 samples) - CV is critical to avoid overfitting\\n- Track both train and validation scores to detect overfitting\\n\\n## Hyperparameter Tuning\\n- Use GridSearchCV or RandomizedSearchCV\\n- Key parameters to tune:\\n  - Tree depth (max_depth): 3-8\\n  - Number of estimators: 100-1000\\n  - Learning rate (for boosting): 0.01-0.1\\n  - Min samples per leaf: 1-5\\n- Use cross-validation during tuning\\n\\n## Feature Selection\\n- Use Recursive Feature Elimination (RFE) with cross-validation\\n- Check feature importances from tree models\\n- Most important features typically: Sex, Title, Pclass, Fare, Age\\n\\n## Key Insights from Top Kernels\\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\\n3. Title extraction captures both sex and age information effectively\\n4. Family size has non-linear relationship with survival\\n5. Ensemble methods consistently outperform single models\\n\\n## Submission Strategy\\n- Generate predictions using best ensemble model\\n- Consider averaging predictions from multiple models\\n- Threshold at 0.5 for binary classification\\n- Format: PassengerId, Survived (0 or 1)\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': \"REASONING: Let me add a few more cells to the EDA notebook to explore Title extraction and family size patterns, which are key features. Then I'll finalize the seed prompt.\"}, {'role': 'tool', 'content': 'Added code cell at 3'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 3-3\\n==================================================\\n\\nCell 3:\\n```\\n# Extract Title from Name\\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\\nprint('Title distribution:')\\nprint(train['Title'].value_counts())\\nprint('\\\\nSurvival by Title:')\\nprint(train.groupby('Title')['Survived'].agg(['mean', 'count']).sort_values('count', ascending=False))\\n```\\nOutput:\\nTitle distribution:\\nTitle\\nMr          517\\nMiss        182\\nMrs         125\\nMaster       40\\nDr            7\\nRev           6\\nCol           2\\nMlle          2\\nMajor         2\\nMs            1\\nMme           1\\nDon           1\\nLady          1\\nSir           1\\nCapt          1\\nCountess      1\\nJonkheer      1\\nName: count, dtype: int64\\n\\nSurvival by Title:\\n              mean  count\\nTitle                    \\nMr        0.156673    517\\nMiss      0.697802    182\\nMrs       0.792000    125\\nMaster    0.575000     40\\nDr        0.428571      7\\nRev       0.000000      6\\nMlle      1.000000      2\\nMajor     0.500000      2\\nCol       0.500000      2\\nCapt      0.000000      1\\nLady      1.000000      1\\nCountess  1.000000      1\\nDon       0.000000      1\\nJonkheer  0.000000      1\\nMme       1.000000      1\\nMs        1.000000      1\\nSir       1.000000      1\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Title survival rates: Mr 15.7%, Miss 69.8%, Mrs 79.2%, Master 57.5%. Title is highly predictive - Mr...\\n  Source: exploration/eda.ipynb'}]",
        "llm.input_tokens": 48867,
        "llm.output_tokens": 198,
        "llm.total_tokens": 49065,
        "llm.latency_ms": 4777.945995330811,
        "llm.completion": "[Tool Use: AddNotebookCell]",
        "llm.cost_usd": 0.14957099999999998
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "300d206fb97e855b",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "AddNotebookCellTool",
      "kind": "INTERNAL",
      "start_time": 1767683688751726543,
      "end_time": 1767683688754341598,
      "duration": 0.002615055,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "AddNotebookCellTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.AddNotebookCellTool object at 0x73eac37f4d50>\", \"input\": {\"cell_type\": \"code\", \"content\": \"# Family size analysis\\ntrain['FamilySize'] = train['SibSp'] + train['Parch'] + 1\\ntrain['IsAlone'] = (train['FamilySize'] == 1).astype(int)\\nprint('Survival by FamilySize:')\\nprint(train.groupby('FamilySize')['Survived'].agg(['mean', 'count']))\\nprint('\\\\nSurvival by IsAlone:')\\nprint(train.groupby('IsAlone')['Survived'].mean())\"}}",
        "tool.output": "{\"content\": \"Added code cell at 4\", \"is_error\": false}",
        "tool.duration_ms": 2.6912689208984375
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "aa61caed2fc6b1b3",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "llm.anthropic/claude-opus-4.5",
      "kind": "CLIENT",
      "start_time": 1767683689981387806,
      "end_time": 1767683693122835687,
      "duration": 3.141447881,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "llm",
        "llm.model": "anthropic/claude-opus-4.5",
        "llm.provider": "openai",
        "cascade.agent_name": "ExplorerAgent",
        "llm.max_tokens": 16000,
        "llm.prompt": "user: Welcome to autonomous exploration!\n\n\nKaggle Submissions: 0/10 used, 9 remaining today.\n## TARGET SCORE\nBeat **1.000000** (higher is better).\n\n**Paths:**\n- Data: /home/data\n- Exploration workspace: /home/code/exploration\n\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\n\n\n---\n\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\n\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\n\n## Available Competitive Intelligence\n\n- Competition description: `../research/description.md`\n- 5 top kernel notebooks in `../research/kernels/`\n\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\n\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\n\n---\n\n**CRITICAL:** All your files go in the exploration workspace.\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\n\n**Workflow:**\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\n2. Quick data check: problem type? key characteristics?\n3. WRITE seed_prompt.txt based on writeups + data findings\n4. More exploration if needed\n5. UPDATE seed_prompt.txt with additional techniques\n6. Call EndExploration() when comprehensive\n\n**File naming:**\n- Data files: Absolute paths like \"/home/data/train.csv\"\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\n  (automatically saved to exploration/ directory)\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\n\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.\ntool: # Titanic - Machine Learning from Disaster\n\n**Competition:** titanic\n**Category:** None\n**Deadline:** 2030-01-01T00:00:00Z\n**Reward:** None\n**Evaluation Metric:** Categorization Accuracy\n**Teams:** 14511\n\n---\n\n## Description\n\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\n**If you want to talk with other users about this competition, come join our Discord! We've got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\n\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n\n> #### Recommended Tutorial\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\n\n## How Kaggle‚Äôs Competitions Work\n1. **Join the Competition**\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\n1.  **Get to Work**\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n1.  **Make a Submission**\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\n1.  **Check the Leaderboard**\nSee how your model ranks against other Kagglers on our leaderboard. \n1.  **Improve Your Score**\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\n\n> #### Kaggle Lingo Video\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\n\n## What Data Will I Use in This Competition?\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\n\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\n\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\n\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n\n## How to Submit your Prediction to Kaggle\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\n\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\n\n## Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n\nThe file should have exactly 2 columns:\n- `PassengerId` (sorted in any order)\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\n\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\n\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!\n\n## A Last Word on Kaggle Notebooks\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\n\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\n\n## üèÉ‚Äç‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\n\n## Evaluation\n\n<h2>Goal</h2>\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\n<h2>Metric</h2>\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\n<h2>Submission File Format</h2>\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\n<ul>\n<li>PassengerId (sorted in any order)</li>\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\n</ul>\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\n\n## data-description\n\n<h3>Overview</h3>\n<p>The data has been split into two groups:</p>\n<ul>\n<li>training set (train.csv)</li>\n<li>test set (test.csv)</li>\n</ul>\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\n<h3>Data Dictionary</h3>\n<table style=\"width: 100%;\">\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n<h3>Variable Notes</h3>\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\n\n## Frequently Asked Questions\n\n<h2>What is a Getting Started competition?</h2>\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\n<h2>How do I create and manage a team?</h2>\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\n<p>We've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\n<h2>What are Notebooks?</h2>\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\n<h2>Why did my team disappear from the leaderboard?</h2>\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\n<h2>How do I contact Support?</h2>\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!</p>\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>\ntool: Not a directory: /home/code/exploration/../research/writeups\ntool: /home/code/exploration/../research/kernels:\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\n[DIR]  alexisbcook_titanic-tutorial/\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\n[FILE] metadata.json (1.7KB)\n[DIR]  startupsci_titanic-data-science-solutions/\ntool: /home/data:\n[FILE] description.md (13.6KB)\n[FILE] gender_submission.csv (3.2KB)\n[FILE] test.csv (28.0KB)\n[FILE] train.csv (59.8KB)\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\ntool: Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\ntool: /home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\n[FILE] kernel-metadata.json (732.0B)\ntool: /home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\n[FILE] kernel-metadata.json (687.0B)\ntool: /home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\n[FILE] kernel-metadata.json (661.0B)\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)\ntool: === MARKDOWN 0 ===\n\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don't understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\n\n=== MARKDOWN 1 ===\n<a id=\"ch1\"></a>\n# How a Data Scientist Beat the Odds\nIt's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interest\n\n=== MARKDOWN 2 ===\n<a id=\"ch2\"></a>\n# A Data Science Framework\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\n\n=== MARKDOWN 3 ===\n<a id=\"ch3\"></a>\n# Step 1: Define the Problem\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n......\n\n**Project Summary:**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\n\n=== MARKDOWN 4 ===\n<a id=\"ch4\"></a>\n# Step 3: Prepare Data for Consumption\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n\n## 3.1 Import Libraries\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n\n=== CODE 5 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". \n\n=== MARKDOWN 6 ===\n## 3.11 Load Data Modelling Libraries\n\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\n\n=== CODE 7 ===\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n=== MARKDOWN 8 ===\n## 3.2 Meet and Greet Data\n\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\n\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\n\n=== CODE 9 ===\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\ndata_raw = pd.read_csv('../input/train.csv')\n\n\n#a dataset should be broken into 3 splits: train, test, and (final) validation\n#the test file provided is the validation file for competition submission\n\n\n=== MARKDOWN 10 ===\n<a id=\"ch5\"></a>\n## 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\n\n=== CODE 11 ===\nprint('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 12 ===\n## 3.22 Clean Data\n\nNow that we know what to clean, let's execute our code.\n\n** Developer Documentation: **\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\n\n=== CODE 13 ===\n###COMPLETING: complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Em\n\n=== CODE 14 ===\n###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'\n\n=== MARKDOWN 15 ===\n## 3.23 Convert Formats\n\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\n\n** Developer Documentation: **\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\n* [Sklearn LabelEncode\n\n=== CODE 16 ===\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Em\n\n=== MARKDOWN 17 ===\n## 3.24 Da-Double Check Cleaned Data\n\nNow that we've cleaned our data, let's do a discount da-double check!\n\n=== CODE 18 ===\nprint('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')\n\n=== MARKDOWN 19 ===\n## 3.25 Split Training and Testing Data\n\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don't [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \n\n=== CODE 20 ===\n#split train and test data with function defaults\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntra\n\n=== MARKDOWN 21 ===\n<a id=\"ch6\"></a>\n# Step 4: Perform Exploratory Analysis with Statistics\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\n\n=== CODE 22 ===\n#Discrete Variable Correlation by Survival using\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].gro\n\n=== CODE 23 ===\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \n\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\n\n#to organize our graphics will use figure: https://\n\n=== CODE 24 ===\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\n\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived',\n\n=== CODE 25 ===\n#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fa\n\n=== CODE 26 ===\n#graph distribution of qualitative data: Sex\n#we know sex mattered in survival, now let's compare sex and a 2nd feature\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Compar\n\n=== CODE 27 ===\n#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\",\n\n=== CODE 28 ===\n#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()\n\n=== CODE 29 ===\n#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()\n\n\ntool: === CODE 30 ===\n#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()\n\n=== CODE 31 ===\n#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n=== CODE 32 ===\n#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorr\n\n=== MARKDOWN 33 ===\n<a id=\"ch7\"></a>\n# Step 5: Model Data\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\n\n=== CODE 34 ===\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n   \n\n=== CODE 35 ===\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\n=== MARKDOWN 36 ===\n<a id=\"ch8\"></a>\n## 5.1 Evaluate Model Performance\nLet's recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we're only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\n\n### Data Science 101: Determine a Baseline Accuracy ###\nBefore we decide how-to make our model better, let's determine if our model is even worth keeping\n\n=== CODE 37 ===\n#IMPORTANT: This is a handmade model for learning purposes only.\n#However, it is possible to create your own predictive model without a fancy algorithm :)\n\n#coin flip model with random 1/survived 0/died\n\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\nfor index, row in data1.iterrows(): \n    #random number generator: https://docs.python.org/2/library/random.html\n    if random.random() > .5:     # Random \n\n=== CODE 38 ===\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)\n\n=== CODE 39 ===\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\ndef mytree(df):\n    \n    #initialize table to store predictions\n    Model = pd.DataFrame(data = {'Predict':[]})\n    male_title = ['Master'] #survived titles\n\n    for index, row in df.iterrows():\n\n        #Question 1: Were you on the Titanic; majority died\n        Model.loc[index, 'Predict'] = 0\n\n        #Question 2: Are you female; majority survived\n        if (df.loc[index, 'Sex'] == 'female'):\n    \n\n=== CODE 40 ===\n#Plot Accuracy Summary\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float'\n\n=== MARKDOWN 41 ===\n## 5.11 Model Performance with Cross-Validation (CV)\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\n\nRemember, it's important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it's great at \"predicting\" data it's already seen, but terrible at predicting data it has not seen; which is not prediction at all. It's like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\n\nCV is basically a shortcut to split and score our model multiple tim\n\n=== MARKDOWN 42 ===\n<a id=\"ch9\"></a>\n# 5.12 Tune Model with Hyper-Parameters\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\n\nHowever, in order to tune a model, we need to actually understand it. That's why I took the time in the previous sections to show you how predictions work. Now let's learn a little bit more about our DT algorithm.\n\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\n\n>**Some ad\n\n=== CODE 43 ===\n#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score \n\n=== MARKDOWN 44 ===\n<a id=\"ch10\"></a>\n## 5.13 Tune Model with Feature Selection\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\n\n=== CODE 45 ===\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#featu\n\n=== CODE 46 ===\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph\n\n=== MARKDOWN 47 ===\n<a id=\"ch11\"></a>\n# Step 6: Validate and Implement\nThe next step is to prepare for submission using the validation data. \n\n=== CODE 48 ===\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)\n\n=== CODE 49 ===\n#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est = [\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassif\n\n\ntool: === MARKDOWN 0 ===\n# Introduction\n\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\n\n=== CODE 1 ===\n# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for t\n\n=== MARKDOWN 2 ===\n# Feature Exploration, Engineering and Cleaning \n\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\n\n=== CODE 3 ===\n# Load in the train and test datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)\n\n=== MARKDOWN 4 ===\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \n\n**Feature Engineering**\n\nHere, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \n\n[Titanic Best Working Classfier][1] : by Sina\n\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n\n=== CODE 5 ===\nfull_data = [train, test]\n\n# Some features of my own that I have added in\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0\n\n=== CODE 6 ===\n# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\n=== MARKDOWN 7 ===\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\n\n## Visualisations \n\n=== CODE 8 ===\ntrain.head(3)\n\n=== MARKDOWN 9 ===\n**Pearson Correlation Heatmap**\n\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\n\n=== CODE 10 ===\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n\n=== MARKDOWN 11 ===\n**Takeaway from the Plots**\n\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I'll still leave both features in for the purposes of this exercise.\n\n**Pairplots**\n\n\n=== CODE 12 ===\ng = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])\n\n=== MARKDOWN 13 ===\n# Ensembling & Stacking models\n\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\n\nCreating a Stacking ensemble!\n\n=== MARKDOWN 14 ===\n### Helpers via Python Classes\n\nHere we invoke the use of Python's classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\n\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\n\n=== CODE 15 ===\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n\n\n=== MARKDOWN 16 ===\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\n\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\n\n\n=== MARKDOWN 17 ===\n### Out-of-Fold Predictions\n\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\n\n=== CODE 18 ===\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_\n\n=== MARKDOWN 19 ===\n# Generating our Base First-Level Models \n\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\n\n 1. Random Forest classifier\n 2. Extra Trees classifier\n 3. AdaBoost classifer\n 4. Gradient Boosting classifer\n 5. Support Vector Machine\n\n=== MARKDOWN 20 ===\n**Parameters**\n\nJust a quick summary of the parameters that we will be listing here for completeness,\n\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\n\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\n\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\n\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \n\n=== CODE 21 ===\n# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth'\n\n=== MARKDOWN 22 ===\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\n\n=== CODE 23 ===\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\n\n=== MARKDOWN 24 ===\n**Creating NumPy arrays out of our train and test sets**\n\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\n\n=== CODE 25 ===\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data\n\n=== MARKDOWN 26 ===\n**Output of the First level Predictions** \n\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\n\n=== CODE 27 ===\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \n\n=== MARKDOWN 28 ===\n**Feature importances generated from the different classifiers**\n\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\n\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\n\n=== CODE 29 ===\nrf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)\n\n=== MARKDOWN 30 ===\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I'll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\n\n=== CODE 31 ===\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\n\n=== MARKDOWN 32 ===\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\n\n=== CODE 33 ===\ncols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })\n\n=== MARKDOWN 34 ===\n**Interactive feature importances via Plotly scatterplots**\n\nI'll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\n\n\ntool: ‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy\ntool: ‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: ‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\ntool: Created: /home/code/exploration/eda.ipynb\n\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.\ntool: Executed cells 0-0\n==================================================\n\nCell 0:\n```\nimport pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('/home/data/train.csv')\ntest = pd.read_csv('/home/data/test.csv')\n\nprint('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('\\nColumns:', train.columns.tolist())\nprint('\\nTarget distribution:')\nprint(train['Survived'].value_counts(normalize=True))\n```\nOutput:\nTrain shape: (891, 12)\nTest shape: (418, 11)\n\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n\nTarget distribution:\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\ntool: Added code cell at 1\ntool: Executed cells 1-1\n==================================================\n\nCell 1:\n```\n# Check data types and missing values\nprint('Data types:')\nprint(train.dtypes)\nprint('\\nMissing values in train:')\nprint(train.isnull().sum())\nprint('\\nMissing values in test:')\nprint(test.isnull().sum())\n```\nOutput:\nData types:\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n\nMissing values in train:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nMissing values in test:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n\ntool: Added code cell at 2\ntool: Edited cell 2. Re-run to update kernel state.\ntool: Executed cells 2-2\n==================================================\n\nCell 2:\n```\n# Key survival rates by features\nprint('Survival by Sex:')\nprint(train.groupby('Sex')['Survived'].mean())\nprint('\\nSurvival by Pclass:')\nprint(train.groupby('Pclass')['Survived'].mean())\nprint('\\nSurvival by Embarked:')\nprint(train.groupby('Embarked')['Survived'].mean())\n```\nOutput:\nSurvival by Sex:\nSex\nfemale    0.742038\nmale      0.188908\nName: Survived, dtype: float64\n\nSurvival by Pclass:\nPclass\n1    0.629630\n2    0.472826\n3    0.242363\nName: Survived, dtype: float64\n\nSurvival by Embarked:\nEmbarked\nC    0.553571\nQ    0.389610\nS    0.336957\nName: Survived, dtype: float64\n\ntool: ‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\n  Source: exploration/eda.ipynb\ntool: ‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\n  Source: exploration/eda.ipynb\ntool: === MARKDOWN 23 ===\n## Analyze by visualizing data\n\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\n\n### Correlating numerical features\n\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\n\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \n\n=== MARKDOWN 25 ===\n### Correlating numerical and ordinal features\n\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n\n**Observations.**\n\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n- Pclass varies in terms of Age distribution of passengers.\n\n**Decisions\n\n=== MARKDOWN 27 ===\n### Correlating categorical features\n\nNow we can correlate categorical features with our solution goal.\n\n**Observations.**\n\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\n- Ports of embarkation have varying survival rates for Pcla\n\n=== MARKDOWN 29 ===\n### Correlating categorical and numerical features\n\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n\n**Observations.**\n\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n\n**Decisions.**\n\n- Consider banding Fare feature.\n\n=== MARKDOWN 31 ===\n## Wrangle data\n\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n\n### Correcting by dropping features\n\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\n\n\n=== MARKDOWN 33 ===\n### Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n\n**Observations.**\n\nWhen we plot Title, Age, and Survived, we note the following observations.\n\n- Most titles band Age groups accurately. For example: Master\n\n=== CODE 34 ===\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])\n\n=== MARKDOWN 35 ===\nWe can replace many titles with a more common name or classify them as `Rare`.\n\n=== CODE 36 ===\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n\n=== MARKDOWN 37 ===\nWe can convert the categorical titles to ordinal.\n\n=== CODE 38 ===\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()\n\n=== MARKDOWN 39 ===\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\n\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: === MARKDOWN 0 ===\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\n\n=== MARKDOWN 1 ===\n# Part 2: Your coding environment\n\nIn this section, you'll train your own machine learning model to improve your predictions.  _If you've never written code before or don't have any experience with machine learning, don't worry!  We don't assume any prior experience in this tutorial._\n\n## The Notebook\n\nThe first thing to do is to create a Kaggle Notebook where you'll store all of your code.  You c\n\n=== CODE 2 ===\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data proc\n\n=== MARKDOWN 3 ===\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We'll do that next.\n\n## Load the data\n\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\n\n![](https://i.imgur.com/OQBax9n.png)\n\nType the two lines of code below into your second code cell.  Then, once you're done, either click on the blue pl\n\n=== CODE 4 ===\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()\n\n=== MARKDOWN 5 ===\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It's very important that you see this output **in your notebook** before proceeding with the tutorial!\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\n\n=== CODE 6 ===\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()\n\n=== MARKDOWN 7 ===\nAs before, make sure that you see the output above in your notebook before continuing.  \n\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\n\n# Part 3: Your first submission\n\n=== CODE 8 ===\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\n=== MARKDOWN 9 ===\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\n\nThen, run the code below in another code cell:\n\n=== CODE 10 ===\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)\n\n=== MARKDOWN 11 ===\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\n\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\n\nBut at the end of the day, this gender-based s\n\n=== CODE 12 ===\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.f\n\n=== MARKDOWN 13 ===\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\n> Again, don't worry if this code doesn't make sense to you!  For now, we'll focus on how to generate and submit predictions.\n\nOnce you're ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \n- Ensure tha\n\n=== MARKDOWN 14 ===\n# Part 4: Learn more!\n\nIf you're interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we've presented here.  You'll also know enough to generate even better predictions!\n\n\ntool: SEARCH RESULTS (9 found)\n==================================================\n\n--- Result 1 ---\nTitle: ANSWER\n\nContent:\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80‚ÄØ% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random‚ÄØForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n**Step‚Äëby‚Äëstep recipe**\n\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \n\n2. **Impute & create missing‚Äëvalue flags**  \n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1‚ÄØif Cabin not null, else‚ÄØ0).  \n   * Optionally encode the original *Cabin* letter as a categorical feature.  \n\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \n   * **FamilySize** = `SibSp + Parch + 1`  \n   * **IsAlone** = 1‚ÄØif *FamilySize*‚ÄØ=‚ÄØ1 else‚ÄØ0  \n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \n\n   These engineered columns lifted baseline scores from ~72‚ÄØ% to ~78‚ÄØ% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \n\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35‚ÄØ% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \n\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \n   * `n_estimators` (200‚Äë1000)  \n   * `max_depth` (5‚Äë15)  \n   * `min_samples_split` / `min_samples_leaf`  \n   * `max_features` (sqrt, log2, or a fraction)  \n\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100‚ÄØ% Accuracy‚Äù notebook placed the author in the top‚ÄØ3‚ÄØ%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \n\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \n\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•‚ÄØ0.84) before uploading.  \n\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\n\n--- Result 2 ---\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\n\nContent:\nSeptember 10, 2016¬†¬†¬†¬†¬†33min read\n\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\n\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\n\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I'm writing this post, I am ranked among the top 4% of all Kagglers.\n\nThis post is the opportunity to share my solution with you.\n\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I'll follow with feature engineering and finally present the predictive model I set up.\n\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\nThe main libraries involved in this tutorial are:\n\n- **Pandas** for data manipulation and ingestion\n- **Matplotlib** and **seaborn** for data visualization\n- **Numpy** for multidimensional array computing\n- **sklearn** for machine learning and predictive modeling\n\n### Installation procedure\n\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\n\n### Nota Bene\n\nThis is my first attempt as a blogger and as a machine learning practitioner.\n\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\n\nHope you've got everything set on your computer. Let's get started.\n\n## I - Exploratory data analysis\n\nAs in different data projects, we'll first start diving into the data and build up our first intuitions.\n\nIn this section, we'll be doing four things.\n\n- Data extraction : we'll load the dataset and have a first look at it.\n- Cleaning : we'll fill in missing values.\n- Plotting : we'll create some interesting charts that'll (hopefully) spot correlations and hidden insights out of the data.\n- Assumptions : we'll formulate hypotheses from the charts.\n\nWe tweak the style of this notebook a little bit to have centered plots.\n\n```\nfrom IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n</style>\n\"\"\");\n```\n\nWe import the useful libraries.\n\n```\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\nimport pandas as pd\npd.options.display.max_columns = 100\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nimport seaborn as sns\n\nimport pylab as plot\nparams = {\n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n}\nplot.rcParams.update(params)\n```\n\nTwo datasets are available: a training set and a test set.\nWe'll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\n\nWe'll see how this procedure is done at the end of this post.\n\nNow let's start by loading the training set.\n\n```\ndata = pd.read_csv('./data/train.csv')\nprint(data.shape)\n#(891, 12)\n```\n\nWe have:\n\n- 891 rows\n- 12 columns\n\nPandas allows you to have a sneak peak at your data.\n\n```\ndata.head()\n```\n\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\n\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he's dead. The is the variable we're going to predict.\n\nThe other variables describe the passengers. They are the **features**.\n\n- PassengerId: and id given to each traveler on the boat\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\n- The Name of the passeger\n- The Sex\n- The Age\n- SibSp: number of siblings and spouses traveling with the passenger\n- Parch: number of parents and children traveling with the passenger\n- The ticket number\n- The ticket Fare\n- The cabin number\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\n\nPandas allows you to a have a high-level simple statistical description of the numerical features.\nThis can be done using the describe method.\n\n```\ndata.describe()\n```\n\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\n| --- | --- | --- | --- | --- | --- | --- |\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\n\nThe count variable shows that 177 values are missing in the Age column.\n\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\n\n```\ndata['Age'] = data['Age'].fillna(data['Age'].median())\n```\n\nLet's now make some charts.\n\nLet's visualize survival based on the gender.\n\n```\ndata['Died'] = 1 - data['Survived']\ndata.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                          stacked=True, colors=['g', 'r']);\n```\n\nIt looks like male passengers are more likely to succumb.\n\nLet's plot the same graph but with ratio instead.\n\n```\ndata.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(25, 7),\n                                                           stacked=True, colors=['g', 'r']);\n```\n\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\n\nLet's now correlate the survival with the age variable.\n\n```\nfig = plt.figure(figsize=(25, 7))\nsns.violinplot(x='Sex', y='Age',\n               hue='Survived', data=data,\n               split=True,\n               palette={0: \"r\", 1: \"g\"}\n              );\n```\n\nAs we saw in the chart above and validate by the following:\n\n- Women survive more than men, as depicted by the larger female green histogram\n\nNow, we see that:\n\n- The age conditions the survival for male passengers:\n\n  - Younger male tend to survive\n  - A large number of passengers between 20 and 40 succumb\n- The age doesn't seem to have a direct impact on the female survival\n\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\n\nRight?\n\nLet's now focus on the Fare ticket of each passenger and see how it could impact the survival.\n\n```\nfigure = plt.figure(figsize=(25, 7))\nplt.hist([dat...\n\n--- Result 3 ---\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\nURL: https://github.com/alicevillar/titanic-kaggle\n\nContent:\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n- [Fork\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n- [Star\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n[6\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\n\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\n\n# alicevillar/titanic-kaggle\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmain\n\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\n| ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\n| ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\_graph\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n\nThe objective of Kaggle's Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\n\n### Quick Start:\n\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\n\n### Dependencies:\n\n- [Numpy](https://numpy.org/)\n- [Pandas](https://pandas.pydata.org/)\n- [SciKit-Learn](https://scikit-learn.org/)\n- [Matplotlib](https://matplotlib.org/)\n- [Seaborn](https://seaborn.pydata.org/)\n\n### Approach\n\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\n\n### Kaggle Competition \\| Titanic Machine Learning from Disaster\n\nKaggle's challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle's [Competition Page](https://www.kaggle.com/c/titanic):\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\n\n### Results\n\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\n\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\n\n## About\n\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\n\n### Topics\n\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\n\n### Resources\n\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\n\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\n\n### Stars\n\n[**6**\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\n\n### Watchers\n\n[**1**\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\n\n### Forks\n\n[**3**\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\n\n--- Result 4 ---\nTitle: Search code, repositories, users, issues, pull requests...\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\n\nContent:\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\~72% to \\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\nmain\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\n|\n|\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\n|\n|\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\n|\n|\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\~72% to \\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\n# Titanic Survival Prediction\n[](#titanic-survival-prediction)\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\n* **Detailed EDA**\nA Jupyter notebook that walks through exploratory data analysis:\n* Summary statistics\n* Missing-value patterns\n* Feature distributions and pairwise relationships\n* Correlation heatmaps\n* **Feature Engineering**\nCreation of high-signal features from raw inputs, including:\n* `Has\\_Cabin`(binary cabin indicator)\n* `FareBin`(quantile-based fare categories)\n* Group-median imputation for`Age`, then 10-year age bins\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\n* `Title`extracted and consolidated from passenger names\n* **Model Comparison**\nTraining and evaluation of multiple classifiers on the engineered feature set:\n* Random Forest\n* Support Vector Machine\n* K-Nearest Neighbors (k=3,5,7)\n* XGBoost\n* LightGBM\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\n* **Analysis &amp; Interpretation**\nInline Markdown commentary explains:\n* Why each feature matters\n* How missing data were handled\n* The rationale for model selection\n* Key takeaways and next-step recommendations\n## Repository Structure\n[](#repository-structure)\ndata/\n* train.csv # Official Kaggle training set\n* test.csv # Official Kaggle test set\nnotebooks/\n* titanic\\_analysis.ipynb\n‚Ä¢EDA, feature engineering, model training\n‚Ä¢Detailed Markdown analysis\n* README.md # Project overview and instructions\n## Contributing\n[](#contributing)\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\n## About\nPredict Titanic survival using t...\n\n--- Result 5 ---\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\n\nContent:\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\nAman Krishna\n2022-04-20T07:23:42Z\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\n\n## The art of fine-tuning a model\n\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\n\n7 min read\n\n\nApr 19, 2022\n\n\nListen\n\nShare\n\nPress enter or click to view image in full size\n\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\n\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\n\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\n\nYou can find the complete code on Github **_:_**\n\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \n\n**Machine Learning model build for survivor prediction for Kaggle's titanic competition - kaggle_titanic/Model‚Ä¶**\n\ngithub.com]\n\n## Which Model to use?\n\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\n\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\n\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\n\n## Pre-Requisite\n\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\n\n### Dropping Features\n\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\n\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\n\n### Code\n\n### Dummify Data\n\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\n\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\n\n**We will be using One-Hot encoding on our categorical features.**\n\n### Code\n\n### Split Data\n\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\n\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\n\n## Training\n\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\n\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\n\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\n\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\n\n### Code\n\n## Fine Tuning\n\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\n\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\n\n### Code\n\n### Output\n\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\n\nPress enter or click to view image in full size\n\nGrid Search Results\n\n## Refining Search Space: Max Depth & Max Samples\n\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\n\n### How?\n\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\n\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\n\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest max_Depth & max_samples\n\n## Fine Tune: Min Sample Split & Min Sample Leaf\n\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest min_samples_leaf & min_samples_split\n\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\n\n## Fine Tune: Number of Estimators\n\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\n\n### Code:\n\n### Output:\n\nPress enter or click to view image in full size\n\nBest n_estimator value\n\n## Refining Search Space: Number of estima...\n\n--- Result 6 ---\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\n\nContent:\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\n\n--- Result 7 ---\nTitle: Titanic - Machine Learning from Disaster\nURL: https://www.kaggle.com/c/titanic/code\n\nContent:\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \n\n[... truncated 11780 characters ...]\ntool: ‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\n  Source: Web search - Kaggle Titanic best techniques\ntool: # Titanic Survival Prediction - Techniques Guide\n\n## Data Understanding\n**Reference notebooks for data characteristics:**\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\n- Target is imbalanced: 61.6% died, 38.4% survived\n\n## Feature Engineering (Critical for High Accuracy)\n\n### Title Extraction from Name\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\.', expand=False)`\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\n- Title is highly predictive: Master (young boys) had high survival\n\n### Family Features\n- **FamilySize** = SibSp + Parch + 1\n- **IsAlone** = 1 if FamilySize == 1, else 0\n- Family size affects survival: solo travelers and very large families had lower survival\n\n### Cabin Features\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\n- ~77% missing - use Has_Cabin binary flag\n\n### Fare and Age Binning\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\n- Binning helps tree models find splits\n\n### Name Length\n- **Name_length** = len(Name) - can be proxy for social status\n\n### Ticket Features\n- Ticket prefix extraction (some tickets have letter prefixes)\n- Ticket frequency (shared tickets indicate traveling together)\n\n## Missing Value Handling\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\n- **Embarked**: Fill with mode ('S' - Southampton)\n- **Fare**: Fill with median (by Pclass)\n- **Cabin**: Create Has_Cabin flag, don't impute\n\n## Models\n\n### Single Models (Baseline)\nFor this small tabular dataset, tree-based models work well:\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\n- **XGBoost**: Similar parameters, use early stopping\n- **Extra Trees**: n_estimators=500, max_depth=6\n- **Logistic Regression**: Good baseline, use regularization\n\n### Ensemble Approaches (Higher Accuracy)\n\n#### Voting Classifier\nCombine multiple models with soft voting:\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n- Use soft voting (probability-based) for better results\n\n#### Stacking (Best Approach)\nTwo-level stacking architecture:\n1. **First Level (Base Models)**: \n   - Random Forest\n   - Extra Trees\n   - AdaBoost\n   - Gradient Boosting\n   - SVC (with probability=True)\n   \n2. **Second Level (Meta-Classifier)**:\n   - XGBoost or Logistic Regression\n   \n3. **Out-of-Fold Predictions**:\n   - Use K-Fold (K=5) to generate out-of-fold predictions\n   - This prevents overfitting when training meta-classifier\n   - Each base model generates predictions on held-out fold\n   - Stack these predictions as features for meta-classifier\n\n## Validation Strategy\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\n- Small dataset (891 samples) - CV is critical to avoid overfitting\n- Track both train and validation scores to detect overfitting\n\n## Hyperparameter Tuning\n- Use GridSearchCV or RandomizedSearchCV\n- Key parameters to tune:\n  - Tree depth (max_depth): 3-8\n  - Number of estimators: 100-1000\n  - Learning rate (for boosting): 0.01-0.1\n  - Min samples per leaf: 1-5\n- Use cross-validation during tuning\n\n## Feature Selection\n- Use Recursive Feature Elimination (RFE) with cross-validation\n- Check feature importances from tree models\n- Most important features typically: Sex, Title, Pclass, Fare, Age\n\n## Key Insights from Top Kernels\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\n3. Title extraction captures both sex and age information effectively\n4. Family size has non-linear relationship with survival\n5. Ensemble methods consistently outperform single models\n\n## Submission Strategy\n- Generate predictions using best ensemble model\n- Consider averaging predictions from multiple models\n- Threshold at 0.5 for binary classification\n- Format: PassengerId, Survived (0 or 1)\n\ntool: Wrote to /home/code/exploration/seed_prompt.txt\ntool: Added code cell at 3\ntool: Executed cells 3-3\n==================================================\n\nCell 3:\n```\n# Extract Title from Name\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\nprint('Title distribution:')\nprint(train['Title'].value_counts())\nprint('\\nSurvival by Title:')\nprint(train.groupby('Title')['Survived'].agg(['mean', 'count']).sort_values('count', ascending=False))\n```\nOutput:\nTitle distribution:\nTitle\nMr          517\nMiss        182\nMrs         125\nMaster       40\nDr            7\nRev           6\nCol           2\nMlle          2\nMajor         2\nMs            1\nMme           1\nDon           1\nLady          1\nSir           1\nCapt          1\nCountess      1\nJonkheer      1\nName: count, dtype: int64\n\nSurvival by Title:\n              mean  count\nTitle                    \nMr        0.156673    517\nMiss      0.697802    182\nMrs       0.792000    125\nMaster    0.575000     40\nDr        0.428571      7\nRev       0.000000      6\nMlle      1.000000      2\nMajor     0.500000      2\nCol       0.500000      2\nCapt      0.000000      1\nLady      1.000000      1\nCountess  1.000000      1\nDon       0.000000      1\nJonkheer  0.000000      1\nMme       1.000000      1\nMs        1.000000      1\nSir       1.000000      1\n\ntool: ‚úì Recorded finding: Title survival rates: Mr 15.7%, Miss 69.8%, Mrs 79.2%, Master 57.5%. Title is highly predictive - Mr...\n  Source: exploration/eda.ipynb\ntool: Added code cell at 4",
        "llm.messages": "[{'role': 'user', 'content': 'Welcome to autonomous exploration!\\n\\n\\nKaggle Submissions: 0/10 used, 9 remaining today.\\n## TARGET SCORE\\nBeat **1.000000** (higher is better).\\n\\n**Paths:**\\n- Data: /home/data\\n- Exploration workspace: /home/code/exploration\\n\\n**Your mission:** Research techniques to beat the target score and create seed_prompt.txt\\n\\n\\n---\\n\\n## PRE-FETCHED COMPETITIVE INTELLIGENCE\\n\\nThe following resources have been downloaded to your workspace. **READ THESE FIRST** before doing web searches - they contain winning solutions and top notebooks from this competition.\\n\\n## Available Competitive Intelligence\\n\\n- Competition description: `../research/description.md`\\n- 5 top kernel notebooks in `../research/kernels/`\\n\\n**IMPORTANT:** Start by reading the writeups in `../research/writeups/` - they contain detailed explanations of winning approaches. This will inform your exploration and reduce the need for web searches.\\n\\n**Record insights from writeups/kernels:** After reading a writeup or kernel, use `RecordFinding` to save key techniques. Set `source` to the file path (e.g., `../research/writeups/2nd-place-solution.md`). This ensures insights persist for future agents.\\n\\n---\\n\\n**CRITICAL:** All your files go in the exploration workspace.\\nWrite \"seed_prompt.txt\" (simple filename) - it will be saved to exploration/.\\n\\n**Workflow:**\\n1. READ the pre-fetched writeups in ../research/writeups/ (winning solutions!)\\n2. Quick data check: problem type? key characteristics?\\n3. WRITE seed_prompt.txt based on writeups + data findings\\n4. More exploration if needed\\n5. UPDATE seed_prompt.txt with additional techniques\\n6. Call EndExploration() when comprehensive\\n\\n**File naming:**\\n- Data files: Absolute paths like \"/home/data/train.csv\"\\n- Your files: Simple names like \"seed_prompt.txt\", \"eda.ipynb\"\\n  (automatically saved to exploration/ directory)\\n- Research files: Use \"../research/\" paths (e.g., \"../research/description.md\")\\n\\nWrite seed_prompt.txt EARLY (iteration 3-4), update as you learn.'}, {'role': 'assistant', 'content': 'REASONING: Let me start by reading the competition description and understanding the problem type, then check the pre-fetched competitive intelligence (writeups and kernels) to understand winning approaches.'}, {'role': 'tool', 'content': '# Titanic - Machine Learning from Disaster\\n\\n**Competition:** titanic\\n**Category:** None\\n**Deadline:** 2030-01-01T00:00:00Z\\n**Reward:** None\\n**Evaluation Metric:** Categorization Accuracy\\n**Teams:** 14511\\n\\n---\\n\\n## Description\\n\\n## üëãüõ≥Ô∏è Ahoy, welcome to Kaggle! You‚Äôre in the right place. \\nThis is the legendary Titanic ML competition ‚Äì the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\\n\\n**If you want to talk with other users about this competition, come join our Discord! We\\'ve got channels for competitions, job postings and career discussions, resources, and socializing with your fellow data scientists. Follow the link here:** https://discord.gg/kaggle\\n\\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\n\\nRead on or watch the video below to explore more details. Once you‚Äôre ready to start competing, click on the <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\" target=\"_blank\">\"Join Competition button</a> to create an account and gain access to the <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\">competition data</a>. Then check out <a href=\"https://www.kaggle.com/alexisbcook/titanic-tutorial\">Alexis Cook‚Äôs Titanic Tutorial</a> that walks you through step by step how to make your first submission!\\n\\n<iframe width=\"699\" height=\"368\" src=\"https://www.youtube.com/embed/8yZMXCaFshs\" title=\"YouTube video | How to Get Started with Kaggle‚Äôs Titanic Competition | Kaggle\" frameborder=\"0\" allow=\"encrypted-media\" allowfullscreen></iframe>\\n\\n## The Challenge\\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\\n\\nOn April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\\n\\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n\\nIn this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\\n\\n> #### Recommended Tutorial\\n> We highly recommend [Alexis Cook‚Äôs Titanic Tutorial](https://www.kaggle.com/alexisbcook/titanic-tutorial) that walks you through making your very first submission step by step and [this starter notebook](https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests) to get started.\\n\\n## How Kaggle‚Äôs Competitions Work\\n1. **Join the Competition**\\nRead about the challenge description, accept the Competition Rules and gain access to the competition dataset.\\n1.  **Get to Work**\\nDownload the data, build models on it locally or on Kaggle Notebooks (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\\n1.  **Make a Submission**\\nUpload your prediction as a submission on Kaggle and receive an accuracy score.\\n1.  **Check the Leaderboard**\\nSee how your model ranks against other Kagglers on our leaderboard. \\n1.  **Improve Your Score**\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a> to find lots of tutorials and insights from other competitors.\\n\\n> #### Kaggle Lingo Video\\n> You may run into unfamiliar lingo as you dig into the Kaggle discussion forums and public notebooks. Check out  Dr. Rachael Tatman‚Äôs [video on Kaggle Lingo](https://www.youtube.com/watch?v=sEJHyuWKd-s) to get up to speed!\\n\\n## What Data Will I Use in This Competition?\\nIn this competition, you‚Äôll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\\n\\n`Train.csv` will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù.\\n\\nThe `test.csv` dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.\\n\\nUsing the patterns you find in the `train.csv` data, predict whether the other 418 passengers on board (found in `test.csv`) survived.\\n\\nCheck out the <a href=\"https://www.kaggle.com/c/titanic/data\">‚ÄúData‚Äù tab</a> to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\\n\\n## How to Submit your Prediction to Kaggle\\nOnce you‚Äôre ready to make a submission and get on the leaderboard:\\n\\n1. Click on the ‚ÄúSubmit Predictions‚Äù button\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen1.png\">\\n1. Upload a CSV file in the submission file format. You‚Äôre able to submit 10 submissions a day.\\n<img width=\"699\" align=\"center\" src=\"https://storage.googleapis.com/kaggle-media/welcome/screen2.png\">\\n\\n## Submission File Format:\\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\\n\\nThe file should have exactly 2 columns:\\n- `PassengerId` (sorted in any order)\\n- `Survived` (contains your binary predictions: 1 for survived, 0 for deceased)\\n\\n## Got it! I‚Äôm ready to get started. Where do I get help if I need it?\\n- For Competition Help: <a href=\"https://www.kaggle.com/c/titanic/discussion\">Titanic Discussion Forum</a>\\n\\nKaggle doesn‚Äôt have a dedicated team to help troubleshoot your code so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!\\n\\n## A Last Word on Kaggle Notebooks\\nAs we mentioned before, Kaggle Notebooks is our no-setup, customizable, Jupyter Notebooks environment with free GPUs and a huge repository of community published data &amp; code.\\n\\nIn every competition, you‚Äôll find many Notebooks shared with incredible insights. It‚Äôs an invaluable resource worth becoming familiar with. Check out this competition‚Äôs Notebooks <a href=\"https://www.kaggle.com/c/titanic/notebooks\">here</a>.\\n\\n## üèÉ\\u200d‚ôÄReady to Compete? <a href=\"https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic\">Join the Competition Here!</a>\\n\\n## Evaluation\\n\\n<h2>Goal</h2>\\n<p>It is your job to predict if a passenger survived the sinking of the Titanic or not. <br>For each  in the test set, you must predict a 0 or 1 value for the  variable.</p>\\n<h2>Metric</h2>\\n<p>Your score is the percentage of passengers you correctly predict. This is known as <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\">accuracy</a>.</p>\\n<h2>Submission File Format</h2>\\n<p>You should submit a csv file with exactly 418 entries <b>plus</b> a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.<br><br>The file should have exactly 2 columns:</p>\\n<ul>\\n<li>PassengerId (sorted in any order)</li>\\n<li>Survived (contains your binary predictions: 1 for survived, 0 for deceased)</li>\\n</ul>\\n<pre><b>PassengerId,Survived</b><br>892,0<br>893,1<br>894,0<br>Etc.</pre>\\n<p>You can download an example submission file (gender_submission.csv) on the <a href=\"https://www.kaggle.com/c/titanic/data\">Data page</a>.</p>\\n\\n## data-description\\n\\n<h3>Overview</h3>\\n<p>The data has been split into two groups:</p>\\n<ul>\\n<li>training set (train.csv)</li>\\n<li>test set (test.csv)</li>\\n</ul>\\n<p><b> The training set </b>should be used to build your machine learning models. For the training set, we provide the outcome (also known as the ‚Äúground truth‚Äù) for each passenger. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use <a href=\"https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\" target=\"_blank\"> feature engineering </a>to create new features.</p>\\n<p><b>The test set </b>should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p>\\n<p>We also include <b>gender_submission.csv</b>, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>\\n<h3>Data Dictionary</h3>\\n<table style=\"width: 100%;\">\\n<tbody>\\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\\n<tr>\\n<td>survival</td>\\n<td>Survival</td>\\n<td>0 = No, 1 = Yes</td>\\n</tr>\\n<tr>\\n<td>pclass</td>\\n<td>Ticket class</td>\\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\\n</tr>\\n<tr>\\n<td>sex</td>\\n<td>Sex</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Age</td>\\n<td>Age in years</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>sibsp</td>\\n<td># of siblings / spouses aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>parch</td>\\n<td># of parents / children aboard the Titanic</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>ticket</td>\\n<td>Ticket number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>fare</td>\\n<td>Passenger fare</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>cabin</td>\\n<td>Cabin number</td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>embarked</td>\\n<td>Port of Embarkation</td>\\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Variable Notes</h3>\\n<p><b>pclass</b>: A proxy for socio-economic status (SES)<br /> 1st = Upper<br /> 2nd = Middle<br /> 3rd = Lower<br /><br /> <b>age</b>: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br /><br /> <b>sibsp</b>: The dataset defines family relations in this way...<br /> Sibling = brother, sister, stepbrother, stepsister<br /> Spouse = husband, wife (mistresses and fianc√©s were ignored)<br /><br /> <b>parch</b>: The dataset defines family relations in this way...<br /> Parent = mother, father<br /> Child = daughter, son, stepdaughter, stepson<br /> Some children travelled only with a nanny, therefore parch=0 for them.</p>\\n\\n## Frequently Asked Questions\\n\\n<h2>What is a Getting Started competition?</h2>\\n<p>Getting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.</p>\\n<p>Getting Started competitions are a non-competitive way to get familiar with Kaggle‚Äôs platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.</p>\\n<h2>How do I create and manage a team?</h2>\\n<p>When you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More &gt; <a href=\"https://www.kaggle.com/c/titanic/team\" target=\"_blank\">Team</a> page.</p>\\n<p>We\\'ve heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don\\'t have a teammate already, consider asking if anyone wants to team up in the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">discussion forum</a>.</p>\\n<h2>What are Notebooks?</h2>\\n<p>Kaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the <a href=\"https://www.kaggle.com/c/titanic/notebooks\" target=\"_blank\">Notebooks</a> tab to view all of the publicly shared code for the Titanic competition. For more on how to use Notebooks to learn data science, check out our <a href=\"https://www.kaggle.com/learn/overview\" target=\"&quot;_blank\">Courses</a>!</p>\\n<h2>Why did my team disappear from the leaderboard?</h2>\\n<p>To keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.</p>\\n<p>If your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.</p>\\n<p><i>\"I worked so hard to get that score! Give it back!\"</i> Read more about our decision to implement a rolling leaderboard <a href=\"https://www.kaggle.com/c/titanic/discussion/6240\" target=\"_blank\">here</a>.</p>\\n<h2>How do I contact Support?</h2>\\n<p>Kaggle does not have a dedicated support team so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you‚Äôll want to use the <a href=\"https://www.kaggle.com/c/titanic/discussion\" target=\"_blank\">Titanic discussion forum)</a>.</p>\\n<p>Support is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can‚Äôt find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help. The forums are full of useful information on the data, metric, and different approaches. We encourage you to use the forums often. If you share your knowledge, you\\'ll find that others will share a lot in turn!</p>\\n<p>If your problem persists or it seems to be effective all participants then please <a href=\"https://www.kaggle.com/contact\" target=\"_blank\">contact us</a>.</p>'}, {'role': 'tool', 'content': 'Not a directory: /home/code/exploration/../research/writeups'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels:\\n[DIR]  alexisbcook_exercise-arithmetic-and-variables/\\n[DIR]  alexisbcook_titanic-tutorial/\\n[DIR]  arthurtok_introduction-to-ensembling-stacking-in-python/\\n[DIR]  ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/\\n[FILE] metadata.json (1.7KB)\\n[DIR]  startupsci_titanic-data-science-solutions/'}, {'role': 'tool', 'content': '/home/data:\\n[FILE] description.md (13.6KB)\\n[FILE] gender_submission.csv (3.2KB)\\n[FILE] test.csv (28.0KB)\\n[FILE] train.csv (59.8KB)'}, {'role': 'assistant', 'content': \"REASONING: This is the classic Titanic survival prediction problem - binary classification with accuracy as the metric. The target score to beat is 1.0 (100% accuracy), which is extremely high. Let me read the top kernels to understand winning approaches. I'll start with the high-accuracy framework and ensembling notebooks.\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy.py'\"}, {'role': 'tool', 'content': \"Error: [Errno 2] No such file or directory: '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/arthurtok_introduction-to-ensembling-stacking-in-python.py'\"}, {'role': 'assistant', 'content': 'REASONING: Let me check the actual file structure in these kernel directories.'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy:\\n[FILE] a-data-science-framework-to-achieve-99-accuracy.ipynb (107.1KB)\\n[FILE] kernel-metadata.json (732.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python:\\n[FILE] introduction-to-ensembling-stacking-in-python.ipynb (39.3KB)\\n[FILE] kernel-metadata.json (687.0B)'}, {'role': 'tool', 'content': '/home/code/exploration/../research/kernels/startupsci_titanic-data-science-solutions:\\n[FILE] kernel-metadata.json (661.0B)\\n[FILE] titanic-data-science-solutions.ipynb (55.5KB)'}, {'role': 'assistant', 'content': \"REASONING: Let me read the key kernels. I'll use Bash to extract the content from the notebooks since they're JSON files.\"}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n\\n>Hello and Welcome to Kaggle, the online Data Science Community to learn, share, and compete. Most beginners get lost in the field, because they fall into the black box approach, using libraries and algorithms they don\\'t understand. This tutorial will give you a 1-2-year head start over your peers, by providing a framework that teaches you how-to think like a data scientist vs what to think/code. Not only will you be able to submit your first competition, but you‚Äôll be able to solve any problem\\n\\n=== MARKDOWN 1 ===\\n<a id=\"ch1\"></a>\\n# How a Data Scientist Beat the Odds\\nIt\\'s the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare\\'s mortality rate or survival analysis. Binary events create an interest\\n\\n=== MARKDOWN 2 ===\\n<a id=\"ch2\"></a>\\n# A Data Science Framework\\n1. **Define the Problem:** If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don\\'t put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the\\n\\n=== MARKDOWN 3 ===\\n<a id=\"ch3\"></a>\\n# Step 1: Define the Problem\\nFor this project, the problem statement is given to us on a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\\n\\n......\\n\\n**Project Summary:**\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the inter\\n\\n=== MARKDOWN 4 ===\\n<a id=\"ch4\"></a>\\n# Step 3: Prepare Data for Consumption\\nSince step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\\n\\n## 3.1 Import Libraries\\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \\n\\n=== CODE 5 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n\\n#load packages\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". \\n\\n=== MARKDOWN 6 ===\\n## 3.11 Load Data Modelling Libraries\\n\\nWe will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load.\\n\\n=== CODE 7 ===\\n#Common Model Algorithms\\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\\nfrom xgboost import XGBClassifier\\n\\n#Common Model Helpers\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\\nfrom sklearn import feature_selection\\n\\n=== MARKDOWN 8 ===\\n## 3.2 Meet and Greet Data\\n\\nThis is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what\\'s its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom.\\n\\nTo begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview\\n\\n=== CODE 9 ===\\n#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\\ndata_raw = pd.read_csv(\\'../input/train.csv\\')\\n\\n\\n#a dataset should be broken into 3 splits: train, test, and (final) validation\\n#the test file provided is the validation file for competition submission\\n\\n\\n=== MARKDOWN 10 ===\\n<a id=\"ch5\"></a>\\n## 3.21 The 4 C\\'s of Data Cleaning: Correcting, Completing, Creating, and Converting\\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\\n\\n1. **Correcting:** Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential out\\n\\n=== CODE 11 ===\\nprint(\\'Train columns with null values:\\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values:\\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 12 ===\\n## 3.22 Clean Data\\n\\nNow that we know what to clean, let\\'s execute our code.\\n\\n** Developer Documentation: **\\n* [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\n* [pandas.DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)\\n* [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\\n* [Indexing and Selecting Data](https://pandas.pydata.org/pandas-do\\n\\n=== CODE 13 ===\\n###COMPLETING: complete or delete missing values in train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #complete missing age with median\\n    dataset[\\'Age\\'].fillna(dataset[\\'Age\\'].median(), inplace = True)\\n\\n    #complete embarked with mode\\n    dataset[\\'Embarked\\'].fillna(dataset[\\'Em\\n\\n=== CODE 14 ===\\n###CREATE: Feature Engineering for train and test/validation dataset\\nfor dataset in data_cleaner:    \\n    #Discrete variables\\n    dataset[\\'FamilySize\\'] = dataset [\\'SibSp\\'] + dataset[\\'Parch\\'] + 1\\n\\n    dataset[\\'IsAlone\\'] = 1 #initialize to yes/1 is alone\\n    dataset[\\'IsAlone\\'].loc[dataset[\\'FamilySize\\'\\n\\n=== MARKDOWN 15 ===\\n## 3.23 Convert Formats\\n\\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\\n\\nIn this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/outcome/response/etc.) variables for data modeling.\\n\\n** Developer Documentation: **\\n* [Categorical Encoding](http://pbpython.com/categorical-encoding.html)\\n* [Sklearn LabelEncode\\n\\n=== CODE 16 ===\\n#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\\n\\n#code categorical data\\nlabel = LabelEncoder()\\nfor dataset in data_cleaner:    \\n    dataset[\\'Sex_Code\\'] = label.fit_transform(dataset[\\'Sex\\'])\\n    dataset[\\'Embarked_Code\\'] = label.fit_transform(dataset[\\'Em\\n\\n=== MARKDOWN 17 ===\\n## 3.24 Da-Double Check Cleaned Data\\n\\nNow that we\\'ve cleaned our data, let\\'s do a discount da-double check!\\n\\n=== CODE 18 ===\\nprint(\\'Train columns with null values: \\\\n\\', data1.isnull().sum())\\nprint(\"-\"*10)\\nprint (data1.info())\\nprint(\"-\"*10)\\n\\nprint(\\'Test/Validation columns with null values: \\\\n\\', data_val.isnull().sum())\\nprint(\"-\"*10)\\nprint (data_val.info())\\nprint(\"-\"*10)\\n\\ndata_raw.describe(include = \\'all\\')\\n\\n=== MARKDOWN 19 ===\\n## 3.25 Split Training and Testing Data\\n\\nAs mentioned previously, the test file provided is really validation data for competition submission. So, we will use *sklearn* function to split the training data in two datasets; 75/25 split. This is important, so we don\\'t [overfit our model](https://www.coursera.org/learn/python-machine-learning/lecture/fVStr/overfitting-and-underfitting). Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the \\n\\n=== CODE 20 ===\\n#split train and test data with function defaults\\n#random_state -> seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\\ntra\\n\\n=== MARKDOWN 21 ===\\n<a id=\"ch6\"></a>\\n# Step 4: Perform Exploratory Analysis with Statistics\\nNow that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other.\\n\\n=== CODE 22 ===\\n#Discrete Variable Correlation by Survival using\\n#group by aka pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\nfor x in data1_x:\\n    if data1[x].dtype != \\'float64\\' :\\n        print(\\'Survival Correlation by:\\', x)\\n        print(data1[[x, Target[0]]].gro\\n\\n=== CODE 23 ===\\n#IMPORTANT: Intentionally plotted different ways for learning purposes only. \\n\\n#optional plotting w/pandas: https://pandas.pydata.org/pandas-docs/stable/visualization.html\\n\\n#we will use matplotlib.pyplot: https://matplotlib.org/api/pyplot_api.html\\n\\n#to organize our graphics will use figure: https://\\n\\n=== CODE 24 ===\\n#we will use seaborn graphics for multi-variable comparison: https://seaborn.pydata.org/api.html\\n\\n#graph individual features by survival\\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\\n\\nsns.barplot(x = \\'Embarked\\', y = \\'Survived\\', data=data1, ax = saxis[0,0])\\nsns.barplot(x = \\'Pclass\\', y = \\'Survived\\',\\n\\n=== CODE 25 ===\\n#graph distribution of qualitative data: Pclass\\n#we know class mattered in survival, now let\\'s compare class and a 2nd feature\\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.boxplot(x = \\'Pclass\\', y = \\'Fare\\', hue = \\'Survived\\', data = data1, ax = axis1)\\naxis1.set_title(\\'Pclass vs Fa\\n\\n=== CODE 26 ===\\n#graph distribution of qualitative data: Sex\\n#we know sex mattered in survival, now let\\'s compare sex and a 2nd feature\\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\\n\\nsns.barplot(x = \\'Sex\\', y = \\'Survived\\', hue = \\'Embarked\\', data=data1, ax = qaxis[0])\\naxis1.set_title(\\'Sex vs Embarked Survival Compar\\n\\n=== CODE 27 ===\\n#more side-by-side comparisons\\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\\n\\n#how does family size factor with sex & survival compare\\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\\n              markers=[\"*\",\\n\\n=== CODE 28 ===\\n#how does embark port factor with class, sex, and survival compare\\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\\ne = sns.FacetGrid(data1, col = \\'Embarked\\')\\ne.map(sns.pointplot, \\'Pclass\\', \\'Survived\\', \\'Sex\\', ci=95.0, palette = \\'deep\\')\\ne.add_legend()\\n\\n=== CODE 29 ===\\n#plot distributions of age of passengers who survived or did not survive\\na = sns.FacetGrid( data1, hue = \\'Survived\\', aspect=4 )\\na.map(sns.kdeplot, \\'Age\\', shade= True )\\na.set(xlim=(0 , data1[\\'Age\\'].max()))\\na.add_legend()\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! Let me continue reading more of this notebook to get the model comparison and feature engineering details, then read the ensembling notebook.'}, {'role': 'tool', 'content': '=== CODE 30 ===\\n#histogram comparison of sex, class, and age by survival\\nh = sns.FacetGrid(data1, row = \\'Sex\\', col = \\'Pclass\\', hue = \\'Survived\\')\\nh.map(plt.hist, \\'Age\\', alpha = .75)\\nh.add_legend()\\n\\n=== CODE 31 ===\\n#pair plots of entire dataset\\npp = sns.pairplot(data1, hue = \\'Survived\\', palette = \\'deep\\', size=1.2, diag_kind = \\'kde\\', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\\npp.set(xticklabels=[])\\n\\n=== CODE 32 ===\\n#correlation heatmap of dataset\\ndef correlation_heatmap(df):\\n    _ , ax = plt.subplots(figsize =(14, 12))\\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\\n    \\n    _ = sns.heatmap(\\n        df.corr(), \\n        cmap = colormap,\\n        square=True, \\n        cbar_kws={\\'shrink\\':.9 }, \\n        ax=ax,\\n        annot=True, \\n        linewidths=0.1,vmax=1.0, linecolor=\\'white\\',\\n        annot_kws={\\'fontsize\\':12 }\\n    )\\n    \\n    plt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\n\\ncorr\\n\\n=== MARKDOWN 33 ===\\n<a id=\"ch7\"></a>\\n# Step 5: Model Data\\nData Science is a multi-disciplinary field between mathematics (i.e. statistics, linear algebra, etc.), computer science (i.e. programming languages, computer systems, etc.) and business management (i.e. communication, subject-matter knowledge, etc.). Most data scientist come from one of the three fields, so they tend to lean towards that discipline. However, data science is like a three-legged stool, with no one leg being more important than the other. So, this step will require advanced knowledge in mathematics. But don‚Äôt worry, we only need a high-level overview, which we‚Äôll cover in this Kernel. Also, thanks to computer science, a lot of the heavy lifting is done for you. So, problems that once required graduate degrees in mathematics or statistics\\n\\n=== CODE 34 ===\\n#Machine Learning Algorithm (MLA) Selection and Initialization\\nMLA = [\\n    #Ensemble Methods\\n    ensemble.AdaBoostClassifier(),\\n    ensemble.BaggingClassifier(),\\n    ensemble.ExtraTreesClassifier(),\\n    ensemble.GradientBoostingClassifier(),\\n    ensemble.RandomForestClassifier(),\\n\\n    #Gaussian Processes\\n    gaussian_process.GaussianProcessClassifier(),\\n    \\n    #GLM\\n    linear_model.LogisticRegressionCV(),\\n    linear_model.PassiveAggressiveClassifier(),\\n    linear_model.RidgeClassifierCV(),\\n   \\n\\n=== CODE 35 ===\\n#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\\nsns.barplot(x=\\'MLA Test Accuracy Mean\\', y = \\'MLA Name\\', data = MLA_compare, color = \\'m\\')\\n\\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\\nplt.title(\\'Machine Learning Algorithm Accuracy Score \\\\n\\')\\nplt.xlabel(\\'Accuracy Score (%)\\')\\nplt.ylabel(\\'Algorithm\\')\\n\\n=== MARKDOWN 36 ===\\n<a id=\"ch8\"></a>\\n## 5.1 Evaluate Model Performance\\nLet\\'s recap, with some basic data cleaning, analysis, and machine learning algorithms (MLA), we are able to predict passenger survival with ~82% accuracy. Not bad for a few lines of code. But the question we always ask is, can we do better and more importantly get an ROI (return on investment) for our time invested? For example, if we\\'re only going to increase our accuracy by 1/10th of a percent, is it really worth 3-months of development. If you work in research maybe the answer is yes, but if you work in business mostly the answer is no. So, keep that in mind when improving your model.\\n\\n### Data Science 101: Determine a Baseline Accuracy ###\\nBefore we decide how-to make our model better, let\\'s determine if our model is even worth keeping\\n\\n=== CODE 37 ===\\n#IMPORTANT: This is a handmade model for learning purposes only.\\n#However, it is possible to create your own predictive model without a fancy algorithm :)\\n\\n#coin flip model with random 1/survived 0/died\\n\\n#iterate over dataFrame rows as (index, Series) pairs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html\\nfor index, row in data1.iterrows(): \\n    #random number generator: https://docs.python.org/2/library/random.html\\n    if random.random() > .5:     # Random \\n\\n=== CODE 38 ===\\n#group by or pivot table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\\npivot_female = data1[data1.Sex==\\'female\\'].groupby([\\'Sex\\',\\'Pclass\\', \\'Embarked\\',\\'FareBin\\'])[\\'Survived\\'].mean()\\nprint(\\'Survival Decision Tree w/Female Node: \\\\n\\',pivot_female)\\n\\npivot_male = data1[data1.Sex==\\'male\\'].groupby([\\'Sex\\',\\'Title\\'])[\\'Survived\\'].mean()\\nprint(\\'\\\\n\\\\nSurvival Decision Tree w/Male Node: \\\\n\\',pivot_male)\\n\\n=== CODE 39 ===\\n#handmade data model using brain power (and Microsoft Excel Pivot Tables for quick calculations)\\ndef mytree(df):\\n    \\n    #initialize table to store predictions\\n    Model = pd.DataFrame(data = {\\'Predict\\':[]})\\n    male_title = [\\'Master\\'] #survived titles\\n\\n    for index, row in df.iterrows():\\n\\n        #Question 1: Were you on the Titanic; majority died\\n        Model.loc[index, \\'Predict\\'] = 0\\n\\n        #Question 2: Are you female; majority survived\\n        if (df.loc[index, \\'Sex\\'] == \\'female\\'):\\n    \\n\\n=== CODE 40 ===\\n#Plot Accuracy Summary\\n#Credit: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\\nimport itertools\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\'\\n\\n=== MARKDOWN 41 ===\\n## 5.11 Model Performance with Cross-Validation (CV)\\nIn step 5.0, we used [sklearn cross_validate](http://scikit-learn.org/stable/modules/cross_validation.html#multimetric-cross-validation) function to train, test, and score our model performance.\\n\\nRemember, it\\'s important we use a different subset for train data to build our model and test data to evaluate our model. Otherwise, our model will be overfitted. Meaning it\\'s great at \"predicting\" data it\\'s already seen, but terrible at predicting data it has not seen; which is not prediction at all. It\\'s like cheating on a school quiz to get 100%, but then when you go to take the exam, you fail because you never truly learned anything. The same is true with machine learning.\\n\\nCV is basically a shortcut to split and score our model multiple tim\\n\\n=== MARKDOWN 42 ===\\n<a id=\"ch9\"></a>\\n# 5.12 Tune Model with Hyper-Parameters\\nWhen we used [sklearn Decision Tree (DT) Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), we accepted all the function defaults. This leaves opportunity to see how various hyper-parameter settings will change the model accuracy.  [(Click here to learn more about parameters vs hyper-parameters.)](https://www.youtube.com/watch?v=EJtTNboTsm8)\\n\\nHowever, in order to tune a model, we need to actually understand it. That\\'s why I took the time in the previous sections to show you how predictions work. Now let\\'s learn a little bit more about our DT algorithm.\\n\\nCredit: [sklearn](http://scikit-learn.org/stable/modules/tree.html#classification)\\n\\n>**Some ad\\n\\n=== CODE 43 ===\\n#base model\\ndtree = tree.DecisionTreeClassifier(random_state = 0)\\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split)\\ndtree.fit(data1[data1_x_bin], data1[Target])\\n\\nprint(\\'BEFORE DT Parameters: \\', dtree.get_params())\\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT Test w/bin score \\n\\n=== MARKDOWN 44 ===\\n<a id=\"ch10\"></a>\\n## 5.13 Tune Model with Feature Selection\\nAs stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has several options, we will use [recursive feature elimination (RFE) with cross validation (CV)](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).\\n\\n=== CODE 45 ===\\n#base model\\nprint(\\'BEFORE DT RFE Training Shape Old: \\', data1[data1_x_bin].shape) \\nprint(\\'BEFORE DT RFE Training Columns Old: \\', data1[data1_x_bin].columns.values)\\n\\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results[\\'train_score\\'].mean()*100)) \\nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results[\\'test_score\\'].mean()*100))\\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results[\\'test_score\\'].std()*100*3))\\nprint(\\'-\\'*10)\\n\\n\\n\\n#featu\\n\\n=== CODE 46 ===\\n#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\\nimport graphviz \\ndot_data = tree.export_graphviz(dtree, out_file=None, \\n                                feature_names = data1_x_bin, class_names = True,\\n                                filled = True, rounded = True)\\ngraph = graphviz.Source(dot_data) \\ngraph\\n\\n=== MARKDOWN 47 ===\\n<a id=\"ch11\"></a>\\n# Step 6: Validate and Implement\\nThe next step is to prepare for submission using the validation data. \\n\\n=== CODE 48 ===\\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\\n#there are some 1\\'s, but enough blues and light reds to create a \"super algorithm\" by combining them\\ncorrelation_heatmap(MLA_predict)\\n\\n=== CODE 49 ===\\n#why choose one model, when you can pick them all with voting classifier\\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\\n#removed models w/o attribute \\'predict_proba\\' required for vote classifier and models with a 1.0 correlation to another model\\nvote_est = [\\n    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\\n    (\\'ada\\', ensemble.AdaBoostClassifier()),\\n    (\\'bc\\', ensemble.BaggingClassifier()),\\n    (\\'etc\\',ensemble.ExtraTreesClassif\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: Excellent! This notebook shows comprehensive feature engineering and model comparison. Let me now read the ensembling notebook for stacking techniques.'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\n# Introduction\\n\\nThis notebook is a very basic and simple introductory primer to the method of ensembling (combining) base learning models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic classifiers and then uses another model at the second-level to predict the output from the earlier first-level predictions.\\n\\nThe Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning K\\n\\n=== CODE 1 ===\\n# Load in our libraries\\nimport pandas as pd\\nimport numpy as np\\nimport re\\nimport sklearn\\nimport xgboost as xgb\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\nimport plotly.offline as py\\npy.init_notebook_mode(connected=True)\\nimport plotly.graph_objs as go\\nimport plotly.tools as tls\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Going to use these 5 base models for t\\n\\n=== MARKDOWN 2 ===\\n# Feature Exploration, Engineering and Cleaning \\n\\nNow we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features.\\n\\n=== CODE 3 ===\\n# Load in the train and test datasets\\ntrain = pd.read_csv(\\'../input/train.csv\\')\\ntest = pd.read_csv(\\'../input/test.csv\\')\\n\\n# Store our passenger ID for easy access\\nPassengerId = test[\\'PassengerId\\']\\n\\ntrain.head(3)\\n\\n=== MARKDOWN 4 ===\\nWell it is no surprise that our task is to somehow extract the information out of the categorical variables \\n\\n**Feature Engineering**\\n\\nHere, credit must be extended to Sina\\'s very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work \\n\\n[Titanic Best Working Classfier][1] : by Sina\\n\\n\\n  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\\n\\n=== CODE 5 ===\\nfull_data = [train, test]\\n\\n# Some features of my own that I have added in\\n# Gives the length of the name\\ntrain[\\'Name_length\\'] = train[\\'Name\\'].apply(len)\\ntest[\\'Name_length\\'] = test[\\'Name\\'].apply(len)\\n# Feature that tells whether a passenger had a cabin on the Titanic\\ntrain[\\'Has_Cabin\\'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\\ntest[\\'Has_Cabin\\'] = test[\"Cabin\"].apply(lambda x: 0\\n\\n=== CODE 6 ===\\n# Feature selection\\ndrop_elements = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\', \\'Cabin\\', \\'SibSp\\']\\ntrain = train.drop(drop_elements, axis = 1)\\ntrain = train.drop([\\'CategoricalAge\\', \\'CategoricalFare\\'], axis = 1)\\ntest  = test.drop(drop_elements, axis = 1)\\n\\n=== MARKDOWN 7 ===\\nAll right so now having cleaned the features and extracted relevant information and dropped the categorical columns our features should now all be numeric, a format suitable to feed into our Machine Learning models. However before we proceed let us generate some simple correlation and distribution plots of our transformed dataset to observe ho\\n\\n## Visualisations \\n\\n=== CODE 8 ===\\ntrain.head(3)\\n\\n=== MARKDOWN 9 ===\\n**Pearson Correlation Heatmap**\\n\\nlet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows\\n\\n=== CODE 10 ===\\ncolormap = plt.cm.RdBu\\nplt.figure(figsize=(14,12))\\nplt.title(\\'Pearson Correlation of Features\\', y=1.05, size=15)\\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \\n            square=True, cmap=colormap, linecolor=\\'white\\', annot=True)\\n\\n=== MARKDOWN 11 ===\\n**Takeaway from the Plots**\\n\\nOne thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn\\'t much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information. Here are two most correlated features are that of Family size and Parch (Parents and Children). I\\'ll still leave both features in for the purposes of this exercise.\\n\\n**Pairplots**\\n\\n\\n=== CODE 12 ===\\ng = sns.pairplot(train[[u\\'Survived\\', u\\'Pclass\\', u\\'Sex\\', u\\'Age\\', u\\'Parch\\', u\\'Fare\\', u\\'Embarked\\',\\n       u\\'FamilySize\\', u\\'Title\\']], hue=\\'Survived\\', palette = \\'seismic\\',size=1.2,diag_kind = \\'kde\\',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\\ng.set(xticklabels=[])\\n\\n=== MARKDOWN 13 ===\\n# Ensembling & Stacking models\\n\\nFinally after that brief whirlwind detour with regards to feature engineering and formatting, we finally arrive at the meat and gist of the this notebook.\\n\\nCreating a Stacking ensemble!\\n\\n=== MARKDOWN 14 ===\\n### Helpers via Python Classes\\n\\nHere we invoke the use of Python\\'s classes to help make it more convenient for us. For any newcomers to programming, one normally hears Classes being used in conjunction with Object-Oriented Programming (OOP). In short, a class helps to extend some code/program for creating objects (variables for old-school peeps) as well as to implement functions and methods specific to that class.\\n\\nIn the section of code below, we essentially write a class *SklearnHelper* that allows one to extend the inbuilt methods (such as train, predict and fit) common to all the Sklearn c\\n\\n=== CODE 15 ===\\n# Some useful parameters which will come in handy later on\\nntrain = train.shape[0]\\nntest = test.shape[0]\\nSEED = 0 # for reproducibility\\nNFOLDS = 5 # set folds for out-of-fold prediction\\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\\n\\n# Class to extend the Sklearn classifier\\nclass SklearnHelper(object):\\n    def __init__(self, clf, seed=0, params=None):\\n        params[\\'random_state\\'] = seed\\n\\n\\n=== MARKDOWN 16 ===\\nBear with me for those who already know this but for people who have not created classes or objects in Python before, let me explain what the code given above does. In creating my base classifiers, I will only use the models already present in the Sklearn library and therefore only extend the class for that.\\n\\n**def init** : Python standard for invoking the default constructor for the class. This means that when you want to create an object (classifier), you have to give it the parameters of clf (what sklearn classifier you want), seed (random seed) and params (parameters for the classifiers).\\n\\n\\n=== MARKDOWN 17 ===\\n### Out-of-Fold Predictions\\n\\nNow as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions.\\n\\n=== CODE 18 ===\\ndef get_oof(clf, x_train, y_train, x_test):\\n    oof_train = np.zeros((ntrain,))\\n    oof_test = np.zeros((ntest,))\\n    oof_test_skf = np.empty((NFOLDS, ntest))\\n\\n    for i, (train_index, test_index) in enumerate(kf):\\n        x_tr = x_train[train_index]\\n        y_tr = y_train[train_index]\\n        x_te = x_train[test_index]\\n\\n        clf.train(x_tr, y_tr)\\n\\n        oof_train[test_index] = clf.predict(x_\\n\\n=== MARKDOWN 19 ===\\n# Generating our Base First-Level Models \\n\\nSo now let us prepare five learning models as our first level classification. These models can all be conveniently invoked via the Sklearn library and are listed as follows:\\n\\n 1. Random Forest classifier\\n 2. Extra Trees classifier\\n 3. AdaBoost classifer\\n 4. Gradient Boosting classifer\\n 5. Support Vector Machine\\n\\n=== MARKDOWN 20 ===\\n**Parameters**\\n\\nJust a quick summary of the parameters that we will be listing here for completeness,\\n\\n**n_jobs** : Number of cores used for the training process. If set to -1, all cores are used.\\n\\n**n_estimators** : Number of classification trees in your learning model ( set to 10 per default)\\n\\n**max_depth** : Maximum depth of tree, or how much a node should be expanded. Beware if set to too high  a number would run the risk of overfitting as one would be growing the tree too deep\\n\\n**verbose** : Controls whether you want to output any text during the learning process. A value of 0 suppresses \\n\\n=== CODE 21 ===\\n# Put in our parameters for said classifiers\\n# Random Forest parameters\\nrf_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\': 500,\\n     \\'warm_start\\': True, \\n     #\\'max_features\\': 0.2,\\n    \\'max_depth\\': 6,\\n    \\'min_samples_leaf\\': 2,\\n    \\'max_features\\' : \\'sqrt\\',\\n    \\'verbose\\': 0\\n}\\n\\n# Extra Trees Parameters\\net_params = {\\n    \\'n_jobs\\': -1,\\n    \\'n_estimators\\':500,\\n    #\\'max_features\\': 0.5,\\n    \\'max_depth\\'\\n\\n=== MARKDOWN 22 ===\\nFurthermore, since having mentioned about Objects and classes within the OOP framework, let us now create 5 objects that represent our 5 learning models via our Helper Sklearn Class we defined earlier.\\n\\n=== CODE 23 ===\\n# Create 5 objects that represent our 4 models\\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=sv\\n\\n=== MARKDOWN 24 ===\\n**Creating NumPy arrays out of our train and test sets**\\n\\nGreat. Having prepared our first layer base models as such, we can now ready the training and test test data for input into our classifiers by generating NumPy arrays out of their original dataframes as follows:\\n\\n=== CODE 25 ===\\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\\ny_train = train[\\'Survived\\'].ravel()\\ntrain = train.drop([\\'Survived\\'], axis=1)\\nx_train = train.values # Creates an array of the train data\\nx_test = test.values # Creats an array of the test data\\n\\n=== MARKDOWN 26 ===\\n**Output of the First level Predictions** \\n\\nWe now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run.\\n\\n=== CODE 27 ===\\n# Create our OOF train and test predictions. These base results will be used as new features\\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \\ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) \\n\\n=== MARKDOWN 28 ===\\n**Feature importances generated from the different classifiers**\\n\\nNow having learned our the first-level classifiers, we can utilise a very nifty feature of the Sklearn models and that is to output the importances of the various features in the training and test sets with one very simple line of code.\\n\\nAs per the Sklearn documentation, most of the classifiers are built in with an attribute which returns feature importances by simply typing in **.feature_importances_**. Therefore we will invoke this very useful attribute via our function earliand plot the feature importances as such\\n\\n=== CODE 29 ===\\nrf_feature = rf.feature_importances(x_train,y_train)\\net_feature = et.feature_importances(x_train, y_train)\\nada_feature = ada.feature_importances(x_train, y_train)\\ngb_feature = gb.feature_importances(x_train,y_train)\\n\\n=== MARKDOWN 30 ===\\nSo I have not yet figured out how to assign and store the feature importances outright. Therefore I\\'ll print out the values from the code above and then simply copy and paste into Python lists as below (sorry for the lousy hack)\\n\\n=== CODE 31 ===\\nrf_features = [0.10474135,  0.21837029,  0.04432652,  0.02249159,  0.05432591,  0.02854371\\n  ,0.07570305,  0.01088129 , 0.24247496,  0.13685733 , 0.06128402]\\net_features = [ 0.12165657,  0.37098307  ,0.03129623 , 0.01591611 , 0.05525811 , 0.028157\\n  ,0.04589793 , 0.02030357 , 0.17289562 , 0.04853517,  0.08910063]\\nada_features = [0.028 ,   0.008  ,      0.012   ,     0.05866667,   0.032 ,       0.0\\n\\n=== MARKDOWN 32 ===\\nCreate a dataframe from the lists containing the feature importance data for easy plotting via the Plotly package.\\n\\n=== CODE 33 ===\\ncols = train.columns.values\\n# Create a dataframe with features\\nfeature_dataframe = pd.DataFrame( {\\'features\\': cols,\\n     \\'Random Forest feature importances\\': rf_features,\\n     \\'Extra Trees  feature importances\\': et_features,\\n      \\'AdaBoost feature importances\\': ada_features,\\n    \\'Gradient Boost feature importances\\': gb_features\\n    })\\n\\n=== MARKDOWN 34 ===\\n**Interactive feature importances via Plotly scatterplots**\\n\\nI\\'ll use the interactive Plotly package at this juncture to visualise the feature importances values of the different classifiers  via a plotly scatter plot by calling \"Scatter\" as follows:\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now let me record key findings from these kernels and also quickly explore the data to understand its characteristics. Then I'll write the seed prompt.\"}, {'role': 'tool', 'content': '‚úì Recorded finding: Key feature engineering: FamilySize = SibSp + Parch + 1, IsAlone flag, Title extraction from Name, H...\\n  Source: ../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy'}, {'role': 'tool', 'content': '‚úì Recorded finding: Stacking approach: Use 5 base models (RandomForest, ExtraTrees, AdaBoost, GradientBoosting, SVC) wit...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python'}, {'role': 'tool', 'content': \"‚úì Recorded finding: Model parameters for RF: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'. For...\\n  Source: ../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python\"}, {'role': 'assistant', 'content': 'REASONING: Let me quickly explore the data to understand its characteristics, then write the seed prompt.'}, {'role': 'tool', 'content': 'Created: /home/code/exploration/eda.ipynb\\n\\nStrong Note: OOM is unrecoverable. Use strong models - just estimate memory first.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 0-0\\n==================================================\\n\\nCell 0:\\n```\\nimport pandas as pd\\nimport numpy as np\\n\\n# Load data\\ntrain = pd.read_csv('/home/data/train.csv')\\ntest = pd.read_csv('/home/data/test.csv')\\n\\nprint('Train shape:', train.shape)\\nprint('Test shape:', test.shape)\\nprint('\\\\nColumns:', train.columns.tolist())\\nprint('\\\\nTarget distribution:')\\nprint(train['Survived'].value_counts(normalize=True))\\n```\\nOutput:\\nTrain shape: (891, 12)\\nTest shape: (418, 11)\\n\\nColumns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\\n\\nTarget distribution:\\nSurvived\\n0    0.616162\\n1    0.383838\\nName: proportion, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 1'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 1-1\\n==================================================\\n\\nCell 1:\\n```\\n# Check data types and missing values\\nprint('Data types:')\\nprint(train.dtypes)\\nprint('\\\\nMissing values in train:')\\nprint(train.isnull().sum())\\nprint('\\\\nMissing values in test:')\\nprint(test.isnull().sum())\\n```\\nOutput:\\nData types:\\nPassengerId      int64\\nSurvived         int64\\nPclass           int64\\nName            object\\nSex             object\\nAge            float64\\nSibSp            int64\\nParch            int64\\nTicket          object\\nFare           float64\\nCabin           object\\nEmbarked        object\\ndtype: object\\n\\nMissing values in train:\\nPassengerId      0\\nSurvived         0\\nPclass           0\\nName             0\\nSex              0\\nAge            177\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             0\\nCabin          687\\nEmbarked         2\\ndtype: int64\\n\\nMissing values in test:\\nPassengerId      0\\nPclass           0\\nName             0\\nSex              0\\nAge             86\\nSibSp            0\\nParch            0\\nTicket           0\\nFare             1\\nCabin          327\\nEmbarked         0\\ndtype: int64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 2'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Edited cell 2. Re-run to update kernel state.'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 2-2\\n==================================================\\n\\nCell 2:\\n```\\n# Key survival rates by features\\nprint('Survival by Sex:')\\nprint(train.groupby('Sex')['Survived'].mean())\\nprint('\\\\nSurvival by Pclass:')\\nprint(train.groupby('Pclass')['Survived'].mean())\\nprint('\\\\nSurvival by Embarked:')\\nprint(train.groupby('Embarked')['Survived'].mean())\\n```\\nOutput:\\nSurvival by Sex:\\nSex\\nfemale    0.742038\\nmale      0.188908\\nName: Survived, dtype: float64\\n\\nSurvival by Pclass:\\nPclass\\n1    0.629630\\n2    0.472826\\n3    0.242363\\nName: Survived, dtype: float64\\n\\nSurvival by Embarked:\\nEmbarked\\nC    0.553571\\nQ    0.389610\\nS    0.336957\\nName: Survived, dtype: float64\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Key survival patterns: Female survival 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: ...\\n  Source: exploration/eda.ipynb'}, {'role': 'tool', 'content': '‚úì Recorded finding: Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 t...\\n  Source: exploration/eda.ipynb'}, {'role': 'assistant', 'content': 'REASONING: Let me also check the Titanic data science solutions notebook for more feature engineering ideas, then write the seed prompt.'}, {'role': 'tool', 'content': '=== MARKDOWN 23 ===\\n## Analyze by visualizing data\\n\\nNow we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n\\n### Correlating numerical features\\n\\nLet us start by understanding correlations between numerical features and our solution goal (Survived).\\n\\nA histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have \\n\\n=== MARKDOWN 25 ===\\n### Correlating numerical and ordinal features\\n\\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n\\n**Observations.**\\n\\n- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n- Pclass varies in terms of Age distribution of passengers.\\n\\n**Decisions\\n\\n=== MARKDOWN 27 ===\\n### Correlating categorical features\\n\\nNow we can correlate categorical features with our solution goal.\\n\\n**Observations.**\\n\\n- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n- Ports of embarkation have varying survival rates for Pcla\\n\\n=== MARKDOWN 29 ===\\n### Correlating categorical and numerical features\\n\\nWe may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n\\n**Observations.**\\n\\n- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n\\n**Decisions.**\\n\\n- Consider banding Fare feature.\\n\\n=== MARKDOWN 31 ===\\n## Wrangle data\\n\\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n\\n### Correcting by dropping features\\n\\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n\\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n\\n\\n=== MARKDOWN 33 ===\\n### Creating new feature extracting from existing\\n\\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n\\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n\\n**Observations.**\\n\\nWhen we plot Title, Age, and Survived, we note the following observations.\\n\\n- Most titles band Age groups accurately. For example: Master\\n\\n=== CODE 34 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset.Name.str.extract(\\' ([A-Za-z]+)\\\\.\\', expand=False)\\n\\npd.crosstab(train_df[\\'Title\\'], train_df[\\'Sex\\'])\\n\\n=== MARKDOWN 35 ===\\nWe can replace many titles with a more common name or classify them as `Rare`.\\n\\n=== CODE 36 ===\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace([\\'Lady\\', \\'Countess\\',\\'Capt\\', \\'Col\\',\\\\\\n \\t\\'Don\\', \\'Dr\\', \\'Major\\', \\'Rev\\', \\'Sir\\', \\'Jonkheer\\', \\'Dona\\'], \\'Rare\\')\\n\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mlle\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Ms\\', \\'Miss\\')\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].replace(\\'Mme\\', \\'Mrs\\')\\n    \\ntrain_df[[\\'Title\\', \\'Survived\\']].groupby([\\'Title\\'], as_index=False).mean()\\n\\n=== MARKDOWN 37 ===\\nWe can convert the categorical titles to ordinal.\\n\\n=== CODE 38 ===\\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\\nfor dataset in combine:\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].map(title_mapping)\\n    dataset[\\'Title\\'] = dataset[\\'Title\\'].fillna(0)\\n\\ntrain_df.head()\\n\\n=== MARKDOWN 39 ===\\nNow we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.\\n\\n'}, {'role': 'assistant', 'content': \"REASONING: Now I have comprehensive information. Let me write the seed prompt with all the techniques I've learned.\"}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': 'REASONING: Now let me check if there are any additional techniques in the Alexis Cook tutorial that might be helpful, and also search for any advanced techniques that could help beat the 1.0 target score (which is 100% accuracy - extremely challenging).'}, {'role': 'tool', 'content': '=== MARKDOWN 0 ===\\nLogging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learnin\\n\\n=== MARKDOWN 1 ===\\n# Part 2: Your coding environment\\n\\nIn this section, you\\'ll train your own machine learning model to improve your predictions.  _If you\\'ve never written code before or don\\'t have any experience with machine learning, don\\'t worry!  We don\\'t assume any prior experience in this tutorial._\\n\\n## The Notebook\\n\\nThe first thing to do is to create a Kaggle Notebook where you\\'ll store all of your code.  You c\\n\\n=== CODE 2 ===\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load in \\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data proc\\n\\n=== MARKDOWN 3 ===\\nThis shows us where the competition data is stored, so that we can load the files into the notebook.  We\\'ll do that next.\\n\\n## Load the data\\n\\nThe second code cell in your notebook now appears below the three lines of output with the file locations.\\n\\n![](https://i.imgur.com/OQBax9n.png)\\n\\nType the two lines of code below into your second code cell.  Then, once you\\'re done, either click on the blue pl\\n\\n=== CODE 4 ===\\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntrain_data.head()\\n\\n=== MARKDOWN 5 ===\\nYour code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It\\'s very important that you see this output **in your notebook** before proceeding with the tutorial!\\n> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shif\\n\\n=== CODE 6 ===\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\\ntest_data.head()\\n\\n=== MARKDOWN 7 ===\\nAs before, make sure that you see the output above in your notebook before continuing.  \\n\\nOnce all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\\n\\n# Part 3: Your first submission\\n\\n=== CODE 8 ===\\nwomen = train_data.loc[train_data.Sex == \\'female\\'][\"Survived\"]\\nrate_women = sum(women)/len(women)\\n\\nprint(\"% of women who survived:\", rate_women)\\n\\n=== MARKDOWN 9 ===\\nBefore moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\\n\\nThen, run the code below in another code cell:\\n\\n=== CODE 10 ===\\nmen = train_data.loc[train_data.Sex == \\'male\\'][\"Survived\"]\\nrate_men = sum(men)/len(men)\\n\\nprint(\"% of men who survived:\", rate_men)\\n\\n=== MARKDOWN 11 ===\\nThe code above calculates the percentage of male passengers (in **train.csv**) who survived.\\n\\nFrom this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\\n\\nBut at the end of the day, this gender-based s\\n\\n=== CODE 12 ===\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\\nX = pd.get_dummies(train_data[features])\\nX_test = pd.get_dummies(test_data[features])\\n\\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\\nmodel.f\\n\\n=== MARKDOWN 13 ===\\nMake sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\\n> Again, don\\'t worry if this code doesn\\'t make sense to you!  For now, we\\'ll focus on how to generate and submit predictions.\\n\\nOnce you\\'re ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \\n- Ensure tha\\n\\n=== MARKDOWN 14 ===\\n# Part 4: Learn more!\\n\\nIf you\\'re interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we\\'ve presented here.  You\\'ll also know enough to generate even better predictions!\\n\\n'}, {'role': 'assistant', 'content': 'REASONING: The tutorial is basic. Let me search for advanced techniques that could help achieve very high accuracy on this problem, particularly since the target is 100% accuracy which is extremely challenging.'}, {'role': 'tool', 'content': 'SEARCH RESULTS (9 found)\\n==================================================\\n\\n--- Result 1 ---\\nTitle: ANSWER\\n\\nContent:\\nBased on several community tutorials and top‚Äëscoring notebooks, the most effective way to push Titanic‚Äëcompetition accuracy into the high‚Äë80\\u202f% range is to combine thorough data cleaning, targeted feature engineering, and a well‚Äëtuned tree‚Äëbased model (often Random\\u202fForest or a gradient‚Äëboosting variant) with cross‚Äëvalidated hyper‚Äëparameter search„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n**Step‚Äëby‚Äëstep recipe**\\n\\n1. **Load & inspect the data** ‚Äì read `train.csv` and `test.csv` with pandas, list missing values in *Age*, *Cabin*, *Embarked* and examine basic statistics.  \\n\\n2. **Impute & create missing‚Äëvalue flags**  \\n   * Fill missing *Age* with the median (or a model‚Äëbased estimate).  \\n   * Fill missing *Embarked* with the mode and create a binary *CabinPresent* flag (1\\u202fif Cabin not null, else\\u202f0).  \\n   * Optionally encode the original *Cabin* letter as a categorical feature.  \\n\\n3. **Feature engineering** ‚Äì the biggest accuracy gains come from engineered variables:  \\n   * **FamilySize** = `SibSp + Parch + 1`  \\n   * **IsAlone** = 1\\u202fif *FamilySize*\\u202f=\\u202f1 else\\u202f0  \\n   * **Title** extracted from the *Name* field (e.g., Mr, Mrs, Miss, Master, Rare)  \\n   * **Age bins** (e.g., child, teen, adult, senior) and **Fare bins** to reduce outlier impact  \\n   * Encode *Sex*, *Embarked*, *Title*, and *CabinPresent* as numeric (LabelEncoder or one‚Äëhot).  \\n\\n   These engineered columns lifted baseline scores from ~72\\u202f% to ~78\\u202f% in a recent repo„Äê4‚Ä†https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708„Äë.  \\n\\n4. **Model selection & baseline** ‚Äì train a **Random Forest** (or XGBoost/LightGBM) on the processed data. Random Forest alone has achieved 84.35\\u202f% accuracy in a public notebook„Äê3‚Ä†https://github.com/alicevillar/titanic-kaggle„Äë.  \\n\\n5. **Hyper‚Äëparameter fine‚Äëtuning** ‚Äì use stratified K‚Äëfold cross‚Äëvalidation (e.g., 5‚Äëfold) to search over:  \\n   * `n_estimators` (200‚Äë1000)  \\n   * `max_depth` (5‚Äë15)  \\n   * `min_samples_split` / `min_samples_leaf`  \\n   * `max_features` (sqrt, log2, or a fraction)  \\n\\n   The fine‚Äëtuned Random Forest in the ‚ÄúJourney to 100\\u202f% Accuracy‚Äù notebook placed the author in the top\\u202f3\\u202f%„Äê9‚Ä†https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7„Äë.  \\n\\n6. **Ensemble / stacking (optional)** ‚Äì blend predictions from the tuned Random Forest with a Gradient Boosting model (XGBoost/LightGBM) and a simple Logistic Regression. Weighted averaging or a meta‚Äëlearner often nudges the public‚Äëleaderboard score a few points higher, as demonstrated in multiple community solutions (e.g., 0.8134 public score)„Äê2‚Ä†https://www.ahmedbesbes.com/blog/kaggle-titanic-competition„Äë.  \\n\\n7. **Final validation & submission** ‚Äì after selecting the best hyper‚Äëparameters, train on the full training set, generate predictions for `test.csv`, and submit. Verify that the cross‚Äëvalidated accuracy on the hold‚Äëout split exceeds your target (‚â•\\u202f0.84) before uploading.  \\n\\nFollowing these concise steps‚Äîclean missing data, engineer family‚Äësize, title, and age/fare bins, encode categoricals, and fine‚Äëtune a Random Forest (or boosted‚Äëtree) model‚Äîhas consistently produced the highest accuracies reported for the Titanic Kaggle competition.\\n\\n--- Result 2 ---\\nTitle: How to score 0.8134 üèÖ in Titanic Kaggle Challenge | Ahmed BESBES\\nURL: https://www.ahmedbesbes.com/blog/kaggle-titanic-competition\\n\\nContent:\\nSeptember 10, 2016\\xa0\\xa0\\xa0\\xa0\\xa033min read\\n\\n# How to score 0.8134 üèÖ in Titanic Kaggle Challenge\\n\\nThe [Titanic challenge](https://www.kaggle.com/c/titanic/) hosted by Kaggle is a competition in which the goal is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat.\\n\\nI have been playing with the Titanic dataset for a while, and I have recently achieved an accuracy score of 0.8134 on the public leaderboard. As I\\'m writing this post, I am ranked among the top 4% of all Kagglers.\\n\\nThis post is the opportunity to share my solution with you.\\n\\nTo make this tutorial more \"academic\" so that anyone could benefit, I will first start with an exploratory data analysis (EDA) then I\\'ll follow with feature engineering and finally present the predictive model I set up.\\n\\nThroughout this jupyter notebook, I will be using Python at each level of the pipeline.\\nThe main libraries involved in this tutorial are:\\n\\n- **Pandas** for data manipulation and ingestion\\n- **Matplotlib** and **seaborn** for data visualization\\n- **Numpy** for multidimensional array computing\\n- **sklearn** for machine learning and predictive modeling\\n\\n### Installation procedure\\n\\nA very easy way to install these packages is to download and install the [Conda](http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install) distribution that encapsulates them all. This distribution is available on all platforms (Windows, Linux and Mac OSX).\\n\\n### Nota Bene\\n\\nThis is my first attempt as a blogger and as a machine learning practitioner.\\n\\nIf you have a question about the code or the hypotheses I made, do not hesitate to post a comment in the comment section below.\\nIf you also have a suggestion on how this notebook could be improved, please reach out to me.\\nThis tutorial is available on my [github](https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge) account.\\n\\nHope you\\'ve got everything set on your computer. Let\\'s get started.\\n\\n## I - Exploratory data analysis\\n\\nAs in different data projects, we\\'ll first start diving into the data and build up our first intuitions.\\n\\nIn this section, we\\'ll be doing four things.\\n\\n- Data extraction : we\\'ll load the dataset and have a first look at it.\\n- Cleaning : we\\'ll fill in missing values.\\n- Plotting : we\\'ll create some interesting charts that\\'ll (hopefully) spot correlations and hidden insights out of the data.\\n- Assumptions : we\\'ll formulate hypotheses from the charts.\\n\\nWe tweak the style of this notebook a little bit to have centered plots.\\n\\n```\\nfrom IPython.core.display import HTML\\nHTML(\"\"\"\\n<style>\\n.output_png {\\n    display: table-cell;\\n    text-align: center;\\n    vertical-align: middle;\\n}\\n</style>\\n\"\"\");\\n```\\n\\nWe import the useful libraries.\\n\\n```\\n%matplotlib inline\\n\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\nwarnings.filterwarnings(\\'ignore\\', category=DeprecationWarning)\\n\\nimport pandas as pd\\npd.options.display.max_columns = 100\\n\\nfrom matplotlib import pyplot as plt\\nimport numpy as np\\n\\nimport seaborn as sns\\n\\nimport pylab as plot\\nparams = {\\n    \\'axes.labelsize\\': \"large\",\\n    \\'xtick.labelsize\\': \\'x-large\\',\\n    \\'legend.fontsize\\': 20,\\n    \\'figure.dpi\\': 150,\\n    \\'figure.figsize\\': [25, 7]\\n}\\nplot.rcParams.update(params)\\n```\\n\\nTwo datasets are available: a training set and a test set.\\nWe\\'ll be using the training set to build our predictive model and the testing set to score it and generate an output file to submit on the Kaggle evaluation system.\\n\\nWe\\'ll see how this procedure is done at the end of this post.\\n\\nNow let\\'s start by loading the training set.\\n\\n```\\ndata = pd.read_csv(\\'./data/train.csv\\')\\nprint(data.shape)\\n#(891, 12)\\n```\\n\\nWe have:\\n\\n- 891 rows\\n- 12 columns\\n\\nPandas allows you to have a sneak peak at your data.\\n\\n```\\ndata.head()\\n```\\n\\n| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\\n\\nThe Survived column is the **target variable**. If Suvival = 1 the passenger survived, otherwise he\\'s dead. The is the variable we\\'re going to predict.\\n\\nThe other variables describe the passengers. They are the **features**.\\n\\n- PassengerId: and id given to each traveler on the boat\\n- Pclass: the passenger class. It has three possible values: 1,2,3 (first, second and third class)\\n- The Name of the passeger\\n- The Sex\\n- The Age\\n- SibSp: number of siblings and spouses traveling with the passenger\\n- Parch: number of parents and children traveling with the passenger\\n- The ticket number\\n- The ticket Fare\\n- The cabin number\\n- The embarkation. This describe three possible areas of the Titanic from which the people embark. Three possible values S,C,Q\\n\\nPandas allows you to a have a high-level simple statistical description of the numerical features.\\nThis can be done using the describe method.\\n\\n```\\ndata.describe()\\n```\\n\\n| PassengerId | Survived | Pclass | Age | SibSp | Parch | Fare |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| count | 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 |\\n| mean | 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 |\\n| std | 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 |\\n| min | 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 |\\n| 25% | 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 |\\n| 50% | 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 |\\n| 75% | 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 |\\n| max | 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 |\\n\\nThe count variable shows that 177 values are missing in the Age column.\\n\\nOne solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outliers.\\n\\n```\\ndata[\\'Age\\'] = data[\\'Age\\'].fillna(data[\\'Age\\'].median())\\n```\\n\\nLet\\'s now make some charts.\\n\\nLet\\'s visualize survival based on the gender.\\n\\n```\\ndata[\\'Died\\'] = 1 - data[\\'Survived\\']\\ndata.groupby(\\'Sex\\').agg(\\'sum\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                          stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nIt looks like male passengers are more likely to succumb.\\n\\nLet\\'s plot the same graph but with ratio instead.\\n\\n```\\ndata.groupby(\\'Sex\\').agg(\\'mean\\')[[\\'Survived\\', \\'Died\\']].plot(kind=\\'bar\\', figsize=(25, 7),\\n                                                           stacked=True, colors=[\\'g\\', \\'r\\']);\\n```\\n\\nThe Sex variable seems to be a discriminative feature. Women are more likely to survive.\\n\\nLet\\'s now correlate the survival with the age variable.\\n\\n```\\nfig = plt.figure(figsize=(25, 7))\\nsns.violinplot(x=\\'Sex\\', y=\\'Age\\',\\n               hue=\\'Survived\\', data=data,\\n               split=True,\\n               palette={0: \"r\", 1: \"g\"}\\n              );\\n```\\n\\nAs we saw in the chart above and validate by the following:\\n\\n- Women survive more than men, as depicted by the larger female green histogram\\n\\nNow, we see that:\\n\\n- The age conditions the survival for male passengers:\\n\\n  - Younger male tend to survive\\n  - A large number of passengers between 20 and 40 succumb\\n- The age doesn\\'t seem to have a direct impact on the female survival\\n\\nThese violin plots confirm that one old code of conduct that sailors and captains follow in case of threatening situations: **\"Women and children first !\"**.\\n\\nRight?\\n\\nLet\\'s now focus on the Fare ticket of each passenger and see how it could impact the survival.\\n\\n```\\nfigure = plt.figure(figsize=(25, 7))\\nplt.hist([dat...\\n\\n--- Result 3 ---\\nTitle: GitHub - alicevillar/titanic-kaggle: Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\nURL: https://github.com/alicevillar/titanic-kaggle\\n\\nContent:\\n[Skip to content](https://github.com/alicevillar/titanic-kaggle#start-of-content)\\n\\nYou signed in with another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/alicevillar/titanic-kaggle) to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[alicevillar](https://github.com/alicevillar)/ **[titanic-kaggle](https://github.com/alicevillar/titanic-kaggle)** Public\\n\\n- [Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n- [Fork\\\\\\n3](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n- [Star\\\\\\n6](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n[6\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers) [3\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks) [Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags) [Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n[Star](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle)\\n\\n[Notifications](https://github.com/login?return_to=%2Falicevillar%2Ftitanic-kaggle) You must be signed in to change notification settings\\n\\n# alicevillar/titanic-kaggle\\n\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n\\nmain\\n\\n[Branches](https://github.com/alicevillar/titanic-kaggle/branches) [Tags](https://github.com/alicevillar/titanic-kaggle/tags)\\n\\nGo to file\\n\\nCode\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| ## Latest commit<br>## History<br>[13 Commits](https://github.com/alicevillar/titanic-kaggle/commits/main/) |\\n| ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) | ### [README.md](https://github.com/alicevillar/titanic-kaggle/blob/main/README.md) |  |  |\\n| ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) | ### [Titanic\\\\_DecisionTree.ipynb](https://github.com/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) |  |  |\\n| ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) | ### [accuracy\\\\_graph\\\\_titanic.png](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png) |  |  |\\n| ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) | ### [titanic.csv](https://github.com/alicevillar/titanic-kaggle/blob/main/titanic.csv) |  |  |\\n| View all files |\\n\\n## Repository files navigation\\n\\n# Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n\\nThe objective of Kaggle\\'s Titanic Challenge was to build a classification model that could successfully predict the survival or the death of a given passenger based on a set of variables. The purpose of this repository is to document the process I went through to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN.\\n\\n### Quick Start:\\n\\n[Check out](https://nbviewer.jupyter.org/github/alicevillar/titanic-kaggle/blob/main/Titanic_DecisionTree.ipynb) a static version of the notebook with Jupyter NBViewer from the comfort of your web browser.\\n\\n### Dependencies:\\n\\n- [Numpy](https://numpy.org/)\\n- [Pandas](https://pandas.pydata.org/)\\n- [SciKit-Learn](https://scikit-learn.org/)\\n- [Matplotlib](https://matplotlib.org/)\\n- [Seaborn](https://seaborn.pydata.org/)\\n\\n### Approach\\n\\n- PART 1: Data Handling -> Importing Data with Pandas, cleaning data, data description.\\n- PART 2: Data Analysis -> Supervised ML Techniques: Decision Tree, SVM, Logistic Regression, Random Forest and KNN\\n- PART 3: Valuation of the Analysis -> Performance measurement + K-folds cross validation to evaluate results locally + Accuracy comparison graph\\n\\n### Kaggle Competition \\\\| Titanic Machine Learning from Disaster\\n\\nKaggle\\'s challenge provides information about a subset of the Titanic population and asks a predictive model that tells whether or not a given passenger survived.\\nWe are given basic explanatory variables, including passenger gender, age, passenger class, among others. More details about the competition can be found on Kaggle\\'s [Competition Page](https://www.kaggle.com/c/titanic):\\n\\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\\n\\n### Results\\n\\nIn this repository I documented the process to create a Titanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. To all these modeles I did a Valuation Analisis (Performance Measurement and K-Fold). I have found the accuracy score with Random forest (0.8435754189944135) and Decision Tree (0.8212290502793296).Finally, I created a graph to compare the accuracy of the different models.\\n\\n[![print](https://github.com/alicevillar/titanic-kaggle/raw/main/accuracy_graph_titanic.png)](https://github.com/alicevillar/titanic-kaggle/blob/main/accuracy_graph_titanic.png)\\n\\n## About\\n\\nTitanic rescue prediction using Decision Tree, SVM, Logistic Regression, Random Forest and KNN. The best accuracy score was from Random Forest: 84.35%\\n\\n### Topics\\n\\n[machine-learning](https://github.com/topics/machine-learning) [random-forest](https://github.com/topics/random-forest) [numpy](https://github.com/topics/numpy) [sklearn](https://github.com/topics/sklearn) [pandas](https://github.com/topics/pandas) [seaborn](https://github.com/topics/seaborn) [titanic-kaggle](https://github.com/topics/titanic-kaggle) [logistic-regression](https://github.com/topics/logistic-regression) [matplotlib](https://github.com/topics/matplotlib) [decision-trees](https://github.com/topics/decision-trees) [kfold-cross-validation](https://github.com/topics/kfold-cross-validation) [machine-learning-projects](https://github.com/topics/machine-learning-projects) [knn-algorithm](https://github.com/topics/knn-algorithm) [support-vector-classification](https://github.com/topics/support-vector-classification) [performance-measurements](https://github.com/topics/performance-measurements)\\n\\n### Resources\\n\\n[Readme](https://github.com/alicevillar/titanic-kaggle#readme-ov-file)\\n\\n[Activity](https://github.com/alicevillar/titanic-kaggle/activity)\\n\\n### Stars\\n\\n[**6**\\\\\\nstars](https://github.com/alicevillar/titanic-kaggle/stargazers)\\n\\n### Watchers\\n\\n[**1**\\\\\\nwatching](https://github.com/alicevillar/titanic-kaggle/watchers)\\n\\n### Forks\\n\\n[**3**\\\\\\nforks](https://github.com/alicevillar/titanic-kaggle/forks)\\n\\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Falicev...\\n\\n--- Result 4 ---\\nTitle: Search code, repositories, users, issues, pull requests...\\nURL: https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\n\\nContent:\\nGitHub - SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708: Predict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[Skip to content](#start-of-content)\\n## Navigation Menu\\nToggle navigation\\n[](https://github.com/)\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nSearch or jump to...\\n# Search code, repositories, users, issues, pull requests...\\n</option></form>\\nSearch\\nClear\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n# Provide feedback\\n</option></form>\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancelSubmit feedback\\n# Saved searches\\n## Use saved searches to filter your results more quickly\\n</option></form>\\nName\\nQuery\\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\nCancelCreate saved search\\n[Sign in](https://github.com/login?return_to=https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nAppearance settings\\nResetting focus\\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\\n{{ message }}\\n[SamanthaZhang25](https://github.com/SamanthaZhang25)/**[Kaggle-Titanic--Machine-Learning--Random-Forest-78.708](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)**Public\\n* [Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n* [Fork0](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n* [Star1](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\\\\\\\\\~72% to \\\\\\\\\\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n[1star](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/stargazers)[0forks](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/forks)[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)[Activity](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/activity)\\n[Star](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)\\n[Notifications](https://github.com/login?return_to=/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708)You must be signed in to change notification settings\\n# SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708\\nmain\\n[Branches](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[Tags](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/branches)[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/tags)\\nGo to file\\nCode\\nOpen more actions menu\\n## Folders and files\\n|Name|Name|\\nLast commit message\\n|\\nLast commit date\\n|\\n## Latest commit\\n## History\\n[5 Commits](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n[](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/commits/main/)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n[README.md](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/README.md)\\n|\\n|\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n[rf-78-708 (5).ipynb](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/rf-78-708%20(5).ipynb)\\n|\\n|\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n[test.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/test.csv)\\n|\\n|\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n[train.csv](https://github.com/SamanthaZhang25/Kaggle-Titanic--Machine-Learning--Random-Forest-78.708/blob/main/train.csv)\\n|\\n|\\n|\\nView all files\\n|\\n## Repository files navigation\\n# Kaggle-Titanic---Machine-Learning---Random-Forest-78.708-\\n[](#kaggle-titanic---machine-learning---random-forest-78708-)\\nPredict Titanic survival using targeted feature engineering (Cabin presence, FamilySize, IsAlone, Title, Age bins) and compare popular models (RF, SVM, KNN, XGBoost, LightGBM). Feature engineering lifted accuracy from \\\\~72% to \\\\~78%. Full code, notebooks, and instructions are available in the GitHub repo.\\n# Titanic Survival Prediction\\n[](#titanic-survival-prediction)\\nThis repository contains a full end-to-end analysis and modeling workflow for the classic Titanic Kaggle challenge. It includes:\\n* **Detailed EDA**\\nA Jupyter notebook that walks through exploratory data analysis:\\n* Summary statistics\\n* Missing-value patterns\\n* Feature distributions and pairwise relationships\\n* Correlation heatmaps\\n* **Feature Engineering**\\nCreation of high-signal features from raw inputs, including:\\n* `Has\\\\_Cabin`(binary cabin indicator)\\n* `FareBin`(quantile-based fare categories)\\n* Group-median imputation for`Age`, then 10-year age bins\\n* `FamilySize`and`IsAlone`derived from SibSp/Parch\\n* `Title`extracted and consolidated from passenger names\\n* **Model Comparison**\\nTraining and evaluation of multiple classifiers on the engineered feature set:\\n* Random Forest\\n* Support Vector Machine\\n* K-Nearest Neighbors (k=3,5,7)\\n* XGBoost\\n* LightGBM\\nResults are compared side-by-side with a clean bar chart, and each model‚Äôs strengths and weaknesses are discussed in detailed Markdown cells.\\n* **Analysis &amp; Interpretation**\\nInline Markdown commentary explains:\\n* Why each feature matters\\n* How missing data were handled\\n* The rationale for model selection\\n* Key takeaways and next-step recommendations\\n## Repository Structure\\n[](#repository-structure)\\ndata/\\n* train.csv # Official Kaggle training set\\n* test.csv # Official Kaggle test set\\nnotebooks/\\n* titanic\\\\_analysis.ipynb\\n‚Ä¢EDA, feature engineering, model training\\n‚Ä¢Detailed Markdown analysis\\n* README.md # Project overview and instructions\\n## Contributing\\n[](#contributing)\\nFeel free to open issues, fork the repository, or submit pull requests with enhancements‚Äîwhether it‚Äôs new feature ideas, alternative modeling approaches, or visualization improvements.\\n## About\\nPredict Titanic survival using t...\\n\\n--- Result 5 ---\\nTitle: Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\nURL: https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\n\\nContent:\\nAman Krishna Kaggle Titanic Challenge: Training & Fine-Tuning the Model https://python.plainenglish.io/kaggle-titanic-challenge-training-fine-tuning-the-model-42310439ae7\\nKaggle Titanic Challenge: Training & Fine-Tuning the Model\\nAman Krishna\\n2022-04-20T07:23:42Z\\n# Kaggle Titanic Challenge: Training & Fine-Tuning the Model\\n\\n## The art of fine-tuning a model\\n\\n[Aman Krishna](https://medium.com/@mnkrishn?source=post_page---byline--42310439ae7---------------------------------------)\\n\\n7 min read\\n\\n\\nApr 19, 2022\\n\\n\\nListen\\n\\nShare\\n\\nPress enter or click to view image in full size\\n\\nPhoto by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\\n\\n**To get into the top 5% of this competition, you need two main ingredients. First, good features that represent the data. Second, a model fine-tuned to the problem.**\\n\\n**We have already created our** [**_features_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) **and now we shall create an excellent model that got me in the top 3%.**\\n\\nYou can find the complete code on Github **_:_**\\n\\n[**kaggle_titanic/Model Training.ipynb at main ¬∑ AmanKrishna/kaggle_titanic** \\n\\n**Machine Learning model build for survivor prediction for Kaggle\\'s titanic competition - kaggle_titanic/Model‚Ä¶**\\n\\ngithub.com]\\n\\n## Which Model to use?\\n\\n**We have a very small dataset of 891 passengers.** This eliminates all the Deep learning approaches. What we are left with are simpler models like Logistic regression, Bagging Trees (Random Forest), Boosted Trees (XGBoost, AdaBoost & CatBoost), KNN (K-Nearest Neighbours), and SVMs.\\n\\nI have experimented with all of them. **For me, the one that worked the best was Random Forest.** You can play around with others for learning.\\n\\nHere I will teach you how to **fine-tune** a Random Forest tree to extract the best results. The same methodology can be applied to other models as well.\\n\\n## Pre-Requisite\\n\\nFirst, we need to set up our training and testing data by [**_feature creation_**](https://medium.com/python-in-plain-english/kaggle-titanic-challenge-create-them-features-a324ba577812) & [**_handling missing values_**](https://medium.com/python-in-plain-english/kaggle-titanic-competition-missing-values-f3280267b361) **_._** You can find the combined code on my [**_Github repo_**](https://github.com/AmanKrishna/kaggle_titanic/blob/main/notebooks/Model%20Training.ipynb).\\n\\n### Dropping Features\\n\\n**Not all features are created equal.** I experimented with a combination of features to see which one works best and which can be dropped. We definitely do not need **PassengerId** & **Name** of passengers.\\n\\nMoreover, we create **Age** & **Fare bins** in our feature engineering articles. But I found that using **Age**& **Fare** directly was far more useful.\\n\\n### Code\\n\\n### Dummify Data\\n\\nWe have many categorical features like **Sex**. Now Sex takes two values _male_ and _female_. But o **ur model cannot directly use these values.** We can handle categorical data in two ways:\\n\\n- **Label Encoding**: Where each categorical value is assigned a number like _0, 1, 2,_ etc. This is useful mostly for **Ordinal features** which have an inherent ranking. For example, if we have a feature **Review** for movie rating which takes values _Good_, _Average_ & _Bad_. We can assign _Good_: 3, _Average_: 2 & _Bad_: 1.\\n- **One-Hot Encoding:** This is used mostly for **Nominal features** where values are not related to each other. Like in our case **Sex**. Now the value _male_ is not lesser or greater than _female_. So we create 2 new features from **Sex**- **Sex_Female**- **Sex_Male** Now **Sex_Female** has a value of _1_ if the passenger was a female else it is _0_. Similarly for **Sex_Male**. This way we split the original feature into N new features where N = the Number of Unique Values of that feature.\\n\\n**We will be using One-Hot encoding on our categorical features.**\\n\\n### Code\\n\\n### Split Data\\n\\nFinally, we split our data into train & Test. We started with **12 Features**. After creating new features and adding dummies for categorical Features we finally have **1986 features**. Most of them are due to one-hot encoding of Family Names, Ticket Numbers & Cabin Numbers.\\n\\nI experimented with dropping most of them and keeping only a few. But my best result came when I used all of them.\\n\\n## Training\\n\\nWe will be using the **Random forest** model for classification. The following are the most important parameters of a Random Forest.\\n\\n- **n_estimators**: Number of trees in our **Random Forest (RF)** Value: _1 to Infinity_\\n- **max_depth**: Maximum depth of a tree in RFValue: _1 to Infinity_\\n- **max_samples**: Maximum Samples used while creating a tree in RFValue: _0.1 to 1_\\n- **max_features**: Maximum Features used while creating a tree in RFValue: _[‚Äúsqrt‚Äù, ‚Äúauto‚Äù, ‚Äúlog‚Äù]_\\n- **min_samples_split**: The minimum number of samples required to split an internal node of a tree in RFValue: _1 to infinity_\\n- **min_samples_leaf**: The minimum number of samples required to be at a leaf node of a tree in RFValue: _1 to infinity_\\n\\n**We will start with a simple Random Forest with n_estimators = 101.** First fine-tuning other hyper-parameters and then fine-tuning the n_estimators in the end.\\n\\nThe logic is that more estimators in our forest will result in a better representation of the data. Hence if our other hyper-parameters are fine-tuned for a smaller forest they will perform even better when the forest size is increased! (Not always true)\\n\\n### Code\\n\\n## Fine Tuning\\n\\nFirst, we shall fine-tune **max_depth, max_samples, max_features & criterion.** **Sklearn** offers an excellent tool **Grid Search** to search through different values of hyper-parameters & give us the best one!\\n\\n**For example**, to fine-tune **max_depth** we can search through values 2 to 20. **GridSearch** will simply use **max_depth** values 2, 3, 4 ‚Ä¶. 20 to fit the model to our training data. It will then give users the values which are best for the current data.\\n\\n### Code\\n\\n### Output\\n\\nOur Grid Search results say that out of all the combination the ones which gave the best accuracy (0.8608) are **- criterion:** _gini_ **- max_depth:** _19_ **- max_features:** _auto_ **- max_samples:** _0.5_\\n\\nPress enter or click to view image in full size\\n\\nGrid Search Results\\n\\n## Refining Search Space: Max Depth & Max Samples\\n\\nWe shall fix Criterion & Max Features and try to refine search space for Max Depth & Max samples.\\n\\n### How?\\n\\nEarlier the search space for Max Samples was 0.1 to 1 with steps of 0.1. Meaning our grid search was looking at 10 possible values for Max Samples:[0.1, 0.2, 0.3, ‚Ä¶]. The result it gave us was 0.5\\n\\nNow we will further refine our search between 0.4 to 0.6 with a step size of 0.01 i.e. now our Grid Search will look at 20 possible values[0.4, 0.41, ‚Ä¶, 0.].\\n\\nSimilarly, we will fine-tune our search for Max Depth between 18 to 25 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest max_Depth & max_samples\\n\\n## Fine Tune: Min Sample Split & Min Sample Leaf\\n\\nFor both **min_samples_leaf**& **min_sample_split,** the search space is from 2 to 21 with a step size of 1.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest min_samples_leaf & min_samples_split\\n\\n**The abrupt drop in Mean Accuracy scared me as well. But turns out the model performed better on Tests with these values rather than the default values of min sample leaf/split which gave a higher mean accuracy on training data. I think the reason is that the model is generalizing better!**\\n\\n## Fine Tune: Number of Estimators\\n\\nWe will start with a broad range for the Number of estimators. Starting from 11 all the way to 5001 with a step size of 500. Later we shall refine our search.\\n\\n### Code:\\n\\n### Output:\\n\\nPress enter or click to view image in full size\\n\\nBest n_estimator value\\n\\n## Refining Search Space: Number of estima...\\n\\n--- Result 6 ---\\nTitle: How to score top 3% in Kaggle‚Äôs ,,Titanic ‚Äî Machine Learning from Disaster‚Äù competition\\nURL: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\\n\\nContent:\\n<div><div><div><a href=\"https://anelmusic13.medium.com/?source=post_page---byline--13d056e262b1---------------------------------------\"><div><p></p></div></a></div><p>Hey, fellow machine learning enthusiasts. If you‚Äôve ever had a try at a Kaggle competition, chances are you‚Äôre already familiar with the Titanic dataset. <br/>This competition is about predicting whether a passenger will survive the Titanic disaster or not.</p><p>With relatively little effort it is possible to rank among the top 30% of participants. Unfortunately, many of the top scorers train their model on an external dataset and thus obtain a model that classifies the test data with 100% accuracy. I couldn‚Äôt tell you why someone would want to cheat in such an obvious way but what this essentially means is that you have to make an extra effort to get into the top 3%.</p><p><strong>Aim</strong> of this article:</p><ul><li>Explain step by step the end-to-end data pipeline that is needed to score among top 3%.</li><li>Discuss the thought process of a Machine Learning Engineer / Data Scientist in Data Cleaning and Feature Engineering.</li><li>Make it more difficult for future participants to stand out :)</li></ul><p><strong>You can find the complete code at:</strong></p><p><a href=\"https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis\">https://github.com/AnelMusic/Kaggle_Titanic_Advanced_DataAnalysis</a></p><h2>1. Getting the data:</h2><figure><figcaption>Import needed modules for handling tabular data, plotting and accessing common ML</figcaption></figure><figure><figcaption>Provide data paths</figcaption></figure><p>In my case the train.csv as well as test.csv are located in the current working directory. Using pandas we can read and convert the csv-files to pandas dataframes:</p><figure><figcaption>Read data csv and convert it to pandas dataframe</figcaption></figure><p>Next, we can investigate the data to get a better understanding of the available features:</p><figure><figcaption>Show train.csv pandas dataframe</figcaption></figure><h2>2. Exploratory Data Analysis</h2><p>Typically, it is not necessary to use each available feature. Many of them do not provide additional information for the model and increase the training time unnecessarily. However, a more crucial problem that is often overlooked is that additional features inevitably require more data. Now why is that?</p><p><strong>Why additional features call for additional data:</strong></p><p>If you think about it, each additional feature adds a new dimension to the feature space. This in turn increases the distance between observations because each new dimension adds a non-negative term to the calculation of the euclidean distance. Thus the feature space becomes sparse. In a sparse feature space ML algorithms tend to overfit to noise and the only way to populate your feature space is by adding additional (and rich) data.</p><p>As you can see it is essential to explore which features should be considered and which should not.</p><p>I would argue that most important skill of a Machine Learning Engineer/Data Scientist is to be unbiased, not assume things and to ask good questions.</p><p>So, let‚Äôs ask some questions:</p><h2>2.1 Question 1: Does the dataset contain missing values?</h2><p>In the very first step it is helpful to check if and how many entries are missing in the dataset.</p><figure><figcaption>Dataset missing values summary</figcaption></figure><figure><figcaption>Define function that creates missing value heatmap</figcaption></figure><figure><figcaption>Missing values heatmap</figcaption></figure><p>From the above plots, it can be seen that the training and similarly the test datasets contain features with missing values. The sparsest features are ‚Äúage‚Äù and ‚Äúcabin‚Äù.</p><p>A naive approach to solve this problem would be to remove the feature completely from the dataset. However, since we do not know how much information these they provide they further investigation is needed. Maybe we find that it would make sense to impute the missing values using sophisticated data imputation methods.</p><h2>2.1 Question 1: How many passengers survived?</h2><figure><figcaption>Check survival rate</figcaption></figure><p>If you prefer plots you can define the function below to plot a bar chart:</p><figure><figcaption>Define function for plotting bar charts</figcaption></figure><figure><figcaption>Bar chart survival rate</figcaption></figure><p>As expected the majority of passengers in the training data died and only 38% survived. This means that the training data suffers from data imbalance but it is not severe which is why I will not consider techniques like sampling to tackle the imbalance.</p><figure><figcaption>Degree of minority class imbalance [shorturl.at/fTV37]</figcaption></figure><h2>2.2 Question 2: Is the likelihood of survival dependent on gender?</h2><p>In 1912, about 110 years ago, women were generally considered to be the weaker sex and should be protected. Let‚Äôs investigate if the men of that time were so dutiful even under the fear of death.</p><figure><figcaption>Passenger count based on gender</figcaption></figure><figure><figcaption>Survival ratio based on gender</figcaption></figure><figure><figcaption>Survival rate bar chart</figcaption></figure><p>Here, we can clearly see that even though the majority of passenger were men, the majority of survivors were women. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers. This seems to confirm that the phrase ‚Äúwomen and children first‚Äù does indeed seem to have been a rule to which men adhered to.</p><h2>2.3 Question 3: Could it be that the class to which a passenger belonged correlates with the probability of survival??</h2><figure><figcaption>Passenger count with respect to class</figcaption></figure><figure><figcaption>Passenger class distribution</figcaption></figure><figure><figcaption>Bar chart passenger class vs dependent (target) variable ,,survived‚Äù</figcaption></figure><p>From the plots and tables above it becomes clear that the Pclass is an important factor to consider.</p><p><strong>Key observations:</strong></p><ul><li>Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.</li><li>Almost 63% of the passenger from class 1 survived.</li><li>Approx 50% of the class 2 passenger survived.</li></ul><p>However, it is not clear yet weather the class or the gender is the underlying and deciding factor. Which brings another important question:</p><h2>2.4 Question 4: Is the higher survival rate in Class 1 due to the class itself or due to a skewed gender distribution in which female passengers dominate?</h2><figure><figcaption>Function that plots bar chart with multiple features</figcaption></figure><figure><figcaption>Bar chart of gender vs surival rate</figcaption></figure><figure><figcaption>Percentage of male and female survivors with respect to gender</figcaption></figure><p>Here, we can see that the question raised above was justified. Irrespective of the class the most important factor when it comes to survival was gender. (At least between the two features Sex and Pclass). However, men had a significantly higher chance of survival if they bought class 1 tickets. This just shows that we should keep both features as both yield insightful information that should help our model.</p><p><strong>Key observations:</strong></p><ul><li>Survival Rate females 1. Class: 96,8%</li><li>Survival Rate females 2. Class: 92,1%</li><li>Survival Rate females 3. Class: 50%</li><li>Survival Rate male 1. Class: 36.8% <br/>(still significantly lower than 3. class females)</li></ul><h2>2.5 Question 5: Did a passengers age influence the chance of survival?</h2><figure><figcaption>Utility function for plotting a histogram and the kernel density estimate</figcaption></figure><figure><figcaption>Age distribution</figcaption></figure><figure><figcaption>Age kernel density</f...\\n\\n--- Result 7 ---\\nTitle: Titanic - Machine Learning from Disaster\\nURL: https://www.kaggle.com/c/titanic/code\\n\\nContent:\\n<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><a href=\"https://www.kaggle.com/organizations/kaggle\"></a><p><span><span><span>Kaggle </span></span><span> ¬∑ Getting Started Prediction Competition ¬∑ Ongoing</span></span></p></div><div><div><p><span></span></p><p>Start here! Predict survival on the Titanic and get familiar with ML basics</p><p></p></div><div><p></p></div></div></div><div><p></p><h2>Titanic - Machine Learning from Disaster</h2><p></p></div><div><div><p></p><h2>Notebooks</h2><p></p></div><div><ul><p>Pinned notebooks</p><li><div><div><p>Titanic Tutorial</p><p><span><span>Updated <span>3y ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/alexisbcook/titanic-tutorial/comments\">30259 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div><div><p><span>18036</span></p><p><span><span> Gold</span></span></p></div></div></li><li><div><p><span>1215</span></p><p><span><span> Gold</span></span></p></div></li><p>Unpinned notebooks</p><li><div><p>Titanic - Machine Learning from Disaster</p><p><span><span>Updated <span>6h ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/mohibulhimu/titanic-machine-learning-from-disaster/comments\">1 comment</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>15h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/abraham35/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic</p><p><span><span>Updated <span>4h ago</span></span> </span><span><span><span>Score: 0.7799</span> ¬∑ <a href=\"https://www.kaggle.com/code/maita27/titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Survived_Titanic</p><p><span><span>Updated <span>16h ago</span></span> </span><span><span><span>Score: 0.78229</span> ¬∑ <a href=\"https://www.kaggle.com/code/thangnguyen12939445/survived-titanic/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>21h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/zubairamuti/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Exercise: Arithmetic and Variables</p><p><span><span>Notebook copied with edits from <a href=\"https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\">Alexis Cook</a></span> ¬∑ <span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/muhammadabdullah1612/exercise-arithmetic-and-variables/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic Survival Prediction - Beginner Guide</p><p><span><span>Updated <span>12h ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/faizankhandeshmukh/titanic-survival-prediction-beginner-guide/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>LightGBMclassifierUm</p><p><span><span>Updated <span>13h ago</span></span> </span><span><span><span>Score: 0.77033</span> ¬∑ <a href=\"https://www.kaggle.com/code/usamamulla/lightgbmclassifierum/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_disaster </p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><a href=\"https://www.kaggle.com/code/trishoolin/titanic-disaster/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>titanic_problem</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77511</span> ¬∑ <a href=\"https://www.kaggle.com/code/karansinghchauhann/titanic-problem/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic | 83.14% Accu| Ensemble (Bagging + DT)</p><p><span><span>Updated <span>1d ago</span></span> </span><span><span><span>Score: 0.77272</span> ¬∑ <a href=\"https://www.kaggle.com/code/khushiirathod/titanic-83-14-accu-ensemble-bagging-dt/comments\">0 comments</a> ¬∑ <span><span>Titanic - Machine Learning from Disaster</span></span></span></span></p></div></li><li><div><p>Titanic - Machine Learning from Disaster - xgboost</p><p><span><span>Updated <span>8h \\n\\n[... truncated 11780 characters ...]'}, {'role': 'assistant', 'content': 'REASONING: This is very helpful! The search confirms that achieving 100% accuracy is essentially impossible without cheating (using external data). The realistic best scores are in the 80-86% range. Let me update the seed prompt with this important context and add more specific techniques.'}, {'role': 'tool', 'content': '‚úì Recorded finding: Realistic accuracy range is 80-86%. Top 3% scores around 81-84%. 100% accuracy claims typically use ...\\n  Source: Web search - Kaggle Titanic best techniques'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"# Titanic Survival Prediction - Techniques Guide\\n\\n## Data Understanding\\n**Reference notebooks for data characteristics:**\\n- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, target distribution, survival rates by feature\\n- Key findings: 891 train samples, 418 test samples, binary classification (Survived: 0/1)\\n- Target is imbalanced: 61.6% died, 38.4% survived\\n\\n## Feature Engineering (Critical for High Accuracy)\\n\\n### Title Extraction from Name\\nExtract title using regex: `Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)`\\n- Group rare titles: Replace Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona with 'Rare'\\n- Normalize: Mlle‚ÜíMiss, Ms‚ÜíMiss, Mme‚ÜíMrs\\n- Map to ordinal: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5\\n- Title is highly predictive: Master (young boys) had high survival\\n\\n### Family Features\\n- **FamilySize** = SibSp + Parch + 1\\n- **IsAlone** = 1 if FamilySize == 1, else 0\\n- Family size affects survival: solo travelers and very large families had lower survival\\n\\n### Cabin Features\\n- **Has_Cabin** = 0 if Cabin is NaN, else 1 (proxy for wealth/status)\\n- Cabin deck can be extracted from first letter (A, B, C, etc.)\\n- ~77% missing - use Has_Cabin binary flag\\n\\n### Fare and Age Binning\\n- **FareBin**: Bin fare into quartiles or custom ranges (0-7.91, 7.91-14.45, 14.45-31, 31+)\\n- **AgeBin**: Bin age into ranges (0-16, 16-32, 32-48, 48-64, 64+)\\n- Binning helps tree models find splits\\n\\n### Name Length\\n- **Name_length** = len(Name) - can be proxy for social status\\n\\n### Ticket Features\\n- Ticket prefix extraction (some tickets have letter prefixes)\\n- Ticket frequency (shared tickets indicate traveling together)\\n\\n## Missing Value Handling\\n- **Age**: Fill with median (by Pclass and Sex for better accuracy)\\n- **Embarked**: Fill with mode ('S' - Southampton)\\n- **Fare**: Fill with median (by Pclass)\\n- **Cabin**: Create Has_Cabin flag, don't impute\\n\\n## Models\\n\\n### Single Models (Baseline)\\nFor this small tabular dataset, tree-based models work well:\\n- **Random Forest**: n_estimators=500, max_depth=6, min_samples_leaf=2, max_features='sqrt'\\n- **Gradient Boosting**: n_estimators=500, max_depth=5, min_samples_leaf=2, learning_rate=0.01\\n- **XGBoost**: Similar parameters, use early stopping\\n- **Extra Trees**: n_estimators=500, max_depth=6\\n- **Logistic Regression**: Good baseline, use regularization\\n\\n### Ensemble Approaches (Higher Accuracy)\\n\\n#### Voting Classifier\\nCombine multiple models with soft voting:\\n- AdaBoost, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\\n- Use soft voting (probability-based) for better results\\n\\n#### Stacking (Best Approach)\\nTwo-level stacking architecture:\\n1. **First Level (Base Models)**: \\n   - Random Forest\\n   - Extra Trees\\n   - AdaBoost\\n   - Gradient Boosting\\n   - SVC (with probability=True)\\n   \\n2. **Second Level (Meta-Classifier)**:\\n   - XGBoost or Logistic Regression\\n   \\n3. **Out-of-Fold Predictions**:\\n   - Use K-Fold (K=5) to generate out-of-fold predictions\\n   - This prevents overfitting when training meta-classifier\\n   - Each base model generates predictions on held-out fold\\n   - Stack these predictions as features for meta-classifier\\n\\n## Validation Strategy\\n- Use Stratified K-Fold Cross-Validation (K=5 or K=10)\\n- Small dataset (891 samples) - CV is critical to avoid overfitting\\n- Track both train and validation scores to detect overfitting\\n\\n## Hyperparameter Tuning\\n- Use GridSearchCV or RandomizedSearchCV\\n- Key parameters to tune:\\n  - Tree depth (max_depth): 3-8\\n  - Number of estimators: 100-1000\\n  - Learning rate (for boosting): 0.01-0.1\\n  - Min samples per leaf: 1-5\\n- Use cross-validation during tuning\\n\\n## Feature Selection\\n- Use Recursive Feature Elimination (RFE) with cross-validation\\n- Check feature importances from tree models\\n- Most important features typically: Sex, Title, Pclass, Fare, Age\\n\\n## Key Insights from Top Kernels\\n1. Sex is the strongest predictor (females 74% survival vs males 19%)\\n2. Pclass strongly correlates with survival (1st class: 63%, 3rd class: 24%)\\n3. Title extraction captures both sex and age information effectively\\n4. Family size has non-linear relationship with survival\\n5. Ensemble methods consistently outperform single models\\n\\n## Submission Strategy\\n- Generate predictions using best ensemble model\\n- Consider averaging predictions from multiple models\\n- Threshold at 0.5 for binary classification\\n- Format: PassengerId, Survived (0 or 1)\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Wrote to /home/code/exploration/seed_prompt.txt'}, {'role': 'assistant', 'content': \"REASONING: Let me add a few more cells to the EDA notebook to explore Title extraction and family size patterns, which are key features. Then I'll finalize the seed prompt.\"}, {'role': 'tool', 'content': 'Added code cell at 3'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': \"Executed cells 3-3\\n==================================================\\n\\nCell 3:\\n```\\n# Extract Title from Name\\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\\nprint('Title distribution:')\\nprint(train['Title'].value_counts())\\nprint('\\\\nSurvival by Title:')\\nprint(train.groupby('Title')['Survived'].agg(['mean', 'count']).sort_values('count', ascending=False))\\n```\\nOutput:\\nTitle distribution:\\nTitle\\nMr          517\\nMiss        182\\nMrs         125\\nMaster       40\\nDr            7\\nRev           6\\nCol           2\\nMlle          2\\nMajor         2\\nMs            1\\nMme           1\\nDon           1\\nLady          1\\nSir           1\\nCapt          1\\nCountess      1\\nJonkheer      1\\nName: count, dtype: int64\\n\\nSurvival by Title:\\n              mean  count\\nTitle                    \\nMr        0.156673    517\\nMiss      0.697802    182\\nMrs       0.792000    125\\nMaster    0.575000     40\\nDr        0.428571      7\\nRev       0.000000      6\\nMlle      1.000000      2\\nMajor     0.500000      2\\nCol       0.500000      2\\nCapt      0.000000      1\\nLady      1.000000      1\\nCountess  1.000000      1\\nDon       0.000000      1\\nJonkheer  0.000000      1\\nMme       1.000000      1\\nMs        1.000000      1\\nSir       1.000000      1\\n\"}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': '‚úì Recorded finding: Title survival rates: Mr 15.7%, Miss 69.8%, Mrs 79.2%, Master 57.5%. Title is highly predictive - Mr...\\n  Source: exploration/eda.ipynb'}, {'role': 'assistant', 'content': 'None'}, {'role': 'tool', 'content': 'Added code cell at 4'}]",
        "llm.input_tokens": 49083,
        "llm.output_tokens": 73,
        "llm.total_tokens": 49156,
        "llm.latency_ms": 3141.4666175842285,
        "llm.completion": "[Tool Use: ExecuteCellRange]",
        "llm.cost_usd": 0.148344
      }
    },
    {
      "trace_id": "092c5ab27e73a894c4c312b5ed1c243f",
      "span_id": "8c92922b8c34f8f9",
      "parent_span_id": "7d5a7d8f2a9bd211",
      "name": "ExecuteCellRangeTool",
      "kind": "INTERNAL",
      "start_time": 1767683693123202528,
      "end_time": 1767683693150532007,
      "duration": 0.027329479,
      "status": {
        "status_code": "OK",
        "description": null
      },
      "attributes": {
        "cascade.span_type": "tool",
        "tool.name": "ExecuteCellRangeTool",
        "cascade.agent_name": "ExplorerAgent",
        "tool.input": "{\"self\": \"<agent_v7_live.agents.core.tools.notebook.ExecuteCellRangeTool object at 0x73eac37d9e10>\", \"input\": {\"start_cell\": 4, \"duration\": 30}}",
        "tool.output": "{\"content\": \"Executed cells 4-4\\n==================================================\\n\\nCell 4:\\n```\\n# Family size analysis\\ntrain['FamilySize'] = train['SibSp'] + train['Parch'] + 1\\ntrain['IsAlone'] = (train['FamilySize'] == 1).astype(int)\\nprint('Survival by FamilySize:')\\nprint(train.groupby('FamilySize')['Survived'].agg(['mean', 'count']))\\nprint('\\\\nSurvival by IsAlone:')\\nprint(train.groupby('IsAlone')['Survived'].mean())\\n```\\nOutput:\\nSurvival by FamilySize:\\n                mean  count\\nFamilySize                 \\n1           0.303538    537\\n2           0.552795    161\\n3           0.578431    102\\n4           0.724138     29\\n5           0.200000     15\\n6           0.136364     22\\n7           0.333333     12\\n8           0.000000      6\\n11          0.000000      7\\n\\nSurvival by IsAlone:\\nIsAlone\\n0    0.505650\\n1    0.303538\\nName: Survived, dtype: float64\\n\", \"is_error\": false}",
        "tool.duration_ms": 27.345657348632812
      }
    }
  ],
  "metadata": {
    "span_count": 63,
    "last_updated": "2026-01-06T07:14:55.877038"
  }
}