{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7f67c8",
   "metadata": {},
   "source": [
    "# LB Feedback Analysis: Understanding the CV-LB Gap\n",
    "\n",
    "**Critical Finding**: CV 0.8283 vs LB 0.7560 = **+0.0723 gap**\n",
    "\n",
    "This massive gap suggests:\n",
    "1. Distribution shift between train/test\n",
    "2. Overfitting to training patterns\n",
    "3. Features not generalizing well\n",
    "4. CV scheme may need adjustment\n",
    "\n",
    "Let's investigate the root cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902455fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:40:39.597167Z",
     "iopub.status.busy": "2026-01-14T07:40:39.596494Z",
     "iopub.status.idle": "2026-01-14T07:40:40.539239Z",
     "shell.execute_reply": "2026-01-14T07:40:40.538671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Train survival rate: 0.3838383838383838\n",
      "Test prediction survival rate: 0.35406698564593303\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"\\nTrain survival rate:\", train_df['Survived'].mean())\n",
    "\n",
    "# Load predictions from exp_001\n",
    "pred_df = pd.read_csv('/home/submission/submission.csv')\n",
    "print(\"Test prediction survival rate:\", pred_df['Survived'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7531d8bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:41:25.107404Z",
     "iopub.status.busy": "2026-01-14T07:41:25.106735Z",
     "iopub.status.idle": "2026-01-14T07:41:25.142568Z",
     "shell.execute_reply": "2026-01-14T07:41:25.142051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features created\n"
     ]
    }
   ],
   "source": [
    "# Recreate features from exp_001\n",
    "def create_features(df, is_train=True):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Basic features\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', 'Master': 'Master',\n",
    "        'Dr': 'Other', 'Rev': 'Other', 'Col': 'Other', 'Major': 'Other',\n",
    "        'Mlle': 'Miss', 'Countess': 'Other', 'Ms': 'Miss', 'Lady': 'Other',\n",
    "        'Jonkheer': 'Other', 'Don': 'Other', 'Dona': 'Other', 'Mme': 'Mrs',\n",
    "        'Capt': 'Other', 'Sir': 'Other'\n",
    "    }\n",
    "    df['Title'] = df['Title'].map(title_mapping)\n",
    "    \n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], \n",
    "                           labels=['Child', 'Teen', 'Adult', 'MiddleAge', 'Senior'])\n",
    "    \n",
    "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "    \n",
    "    df['Deck'] = df['Cabin'].str[0]\n",
    "    df['Deck'] = df['Deck'].fillna('Unknown')\n",
    "    \n",
    "    # Advanced features from exp_001\n",
    "    df['TicketFreq'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "    \n",
    "    df['CabinNumber'] = df['Cabin'].str.extract('([0-9]+)', expand=False).astype(float)\n",
    "    df['CabinSide'] = df['CabinNumber'] % 2\n",
    "    df['CabinSide'] = df['CabinSide'].map({0.0: 'Even', 1.0: 'Odd', np.nan: 'Unknown'})\n",
    "    \n",
    "    df['NameLength'] = df['Name'].str.len()\n",
    "    \n",
    "    df['FareBin5'] = pd.qcut(df['Fare'], q=5, labels=['VeryLow', 'Low', 'Medium', 'High', 'VeryHigh'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_feat = create_features(train_df, is_train=True)\n",
    "test_feat = create_features(test_df, is_train=False)\n",
    "\n",
    "# Interaction features\n",
    "def create_interactions(df):\n",
    "    df = df.copy()\n",
    "    df['Pclass_Sex'] = df['Pclass'].astype(str) + '_' + df['Sex']\n",
    "    df['AgeGroup_Sex'] = df['AgeGroup'].astype(str) + '_' + df['Sex']\n",
    "    df['FareBin5_Sex'] = df['FareBin5'].astype(str) + '_' + df['Sex']\n",
    "    return df\n",
    "\n",
    "train_feat = create_interactions(train_feat)\n",
    "test_feat = create_interactions(test_feat)\n",
    "\n",
    "print(\"Features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7395373f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:42:07.895976Z",
     "iopub.status.busy": "2026-01-14T07:42:07.895366Z",
     "iopub.status.idle": "2026-01-14T07:42:07.918427Z",
     "shell.execute_reply": "2026-01-14T07:42:07.917878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE DISTRIBUTION COMPARISON ===\n",
      "\n",
      "Age:\n",
      "  Train - mean: 29.70, std: 14.53\n",
      "  Test  - mean: 30.27, std: 14.18\n",
      "  Difference: 0.57\n",
      "\n",
      "Fare:\n",
      "  Train - mean: 32.20, std: 49.69\n",
      "  Test  - mean: 35.63, std: 55.91\n",
      "  Difference: 3.42\n",
      "\n",
      "FamilySize:\n",
      "  Train - mean: 1.90, std: 1.61\n",
      "  Test  - mean: 1.84, std: 1.52\n",
      "  Difference: 0.06\n",
      "\n",
      "FarePerPerson:\n",
      "  Train - mean: 19.92, std: 35.84\n",
      "  Test  - mean: 21.80, std: 35.64\n",
      "  Difference: 1.89\n",
      "\n",
      "NameLength:\n",
      "  Train - mean: 26.97, std: 9.28\n",
      "  Test  - mean: 27.48, std: 9.97\n",
      "  Difference: 0.52\n",
      "\n",
      "TicketFreq:\n",
      "  Train - mean: 1.79, std: 1.36\n",
      "  Test  - mean: 1.35, std: 0.76\n",
      "  Difference: 0.44\n",
      "\n",
      "\n",
      "=== CATEGORICAL DISTRIBUTION COMPARISON ===\n",
      "\n",
      "Pclass:\n",
      "\n",
      "Sex:\n",
      "\n",
      "Embarked:\n",
      "  C: Train=18.9%, Test=24.4% (diff=5.5%)\n",
      "  S: Train=72.4%, Test=64.6% (diff=7.8%)\n",
      "\n",
      "Title:\n",
      "\n",
      "Deck:\n",
      "\n",
      "CabinSide:\n",
      "\n",
      "FareBin5:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze feature distributions between train and test\n",
    "print(\"=== FEATURE DISTRIBUTION COMPARISON ===\\n\")\n",
    "\n",
    "# Numeric features\n",
    "numeric_cols = ['Age', 'Fare', 'FamilySize', 'FarePerPerson', 'NameLength', 'TicketFreq']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Train - mean: {train_feat[col].mean():.2f}, std: {train_feat[col].std():.2f}\")\n",
    "    print(f\"  Test  - mean: {test_feat[col].mean():.2f}, std: {test_feat[col].std():.2f}\")\n",
    "    print(f\"  Difference: {abs(train_feat[col].mean() - test_feat[col].mean()):.2f}\")\n",
    "    print()\n",
    "\n",
    "# Categorical features\n",
    "categorical_cols = ['Pclass', 'Sex', 'Embarked', 'Title', 'Deck', 'CabinSide', 'FareBin5']\n",
    "\n",
    "print(\"\\n=== CATEGORICAL DISTRIBUTION COMPARISON ===\\n\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}:\")\n",
    "    train_dist = train_feat[col].value_counts(normalize=True).sort_index()\n",
    "    test_dist = test_feat[col].value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    # Align indices\n",
    "    all_values = set(train_dist.index) | set(test_dist.index)\n",
    "    for val in sorted(all_values):\n",
    "        train_pct = train_dist.get(val, 0) * 100\n",
    "        test_pct = test_dist.get(val, 0) * 100\n",
    "        diff = abs(train_pct - test_pct)\n",
    "        if diff > 5:  # Highlight significant differences\n",
    "            print(f\"  {val}: Train={train_pct:.1f}%, Test={test_pct:.1f}% (diff={diff:.1f}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5175e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for data leakage indicators\n",
    "print(\"=== POTENTIAL LEAKAGE ANALYSIS ===\\n\")\n",
    "\n",
    "# 1. Ticket frequency in train vs test\n",
    "print(\"TicketFreq distribution:\")\n",
    "train_ticket_counts = train_feat['Ticket'].value_counts()\n",
    "test_ticket_counts = test_feat['Ticket'].value_counts()\n",
    "\n",
    "# Tickets that appear in both train and test\n",
    "common_tickets = set(train_ticket_counts.index) & set(test_ticket_counts.index)\n",
    "print(f\"Tickets in train: {len(train_ticket_counts)}\")\n",
    "print(f\"Tickets in test: {len(test_ticket_counts)}\")\n",
    "print(f\"Common tickets: {len(common_tickets)}\")\n",
    "\n",
    "if len(common_tickets) > 0:\n",
    "    print(\"\\n⚠️  WARNING: Some tickets appear in both train and test!\")\n",
    "    print(\"This could cause leakage if TicketFreq is not handled properly.\")\n",
    "    print(\"Sample common tickets:\", list(common_tickets)[:5])\n",
    "else:\n",
    "    print(\"✓ No ticket overlap between train and test\")\n",
    "\n",
    "# 2. Name patterns\n",
    "print(\"\\nName length comparison:\")\n",
    "print(f\"Train mean NameLength: {train_feat['NameLength'].mean():.1f}\")\n",
    "print(f\"Test mean NameLength: {test_feat['NameLength'].mean():.1f}\")\n",
    "print(f\"Difference: {abs(train_feat['NameLength'].mean() - test_feat['NameLength'].mean()):.1f}\")\n",
    "\n",
    "# 3. Fare distribution\n",
    "print(\"\\nFare distribution comparison:\")\n",
    "print(f\"Train Fare - mean: {train_feat['Fare'].mean():.2f}, median: {train_feat['Fare'].median():.2f}\")\n",
    "print(f\"Test Fare - mean: {test_feat['Fare'].mean():.2f}, median: {test_feat['Fare'].median():.2f}\")\n",
    "\n",
    "# Check if test fares are outside train range\n",
    "train_fare_min, train_fare_max = train_feat['Fare'].min(), train_feat['Fare'].max()\n",
    "test_fare_min, test_fare_max = test_feat['Fare'].min(), test_feat['Fare'].max()\n",
    "\n",
    "print(f\"Train Fare range: [{train_fare_min:.2f}, {train_fare_max:.2f}]\")\n",
    "print(f\"Test Fare range: [{test_fare_min:.2f}, {test_fare_max:.2f}]\")\n",
    "\n",
    "if test_fare_min < train_fare_min or test_fare_max > train_fare_max:\n",
    "    print(\"⚠️  WARNING: Test fares extend beyond train range - potential distribution shift\")\n",
    "else:\n",
    "    print(\"✓ Test fares within train range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5205dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature redundancy and correlations\n",
    "print(\"=== FEATURE REDUNDANCY ANALYSIS ===\\n\")\n",
    "\n",
    "# Create a simplified dataset for correlation analysis\n",
    "corr_df = train_feat[numeric_cols].copy()\n",
    "\n",
    "# Add encoded categorical features\n",
    "for col in ['Pclass', 'Sex', 'Title', 'Deck']:\n",
    "    le = LabelEncoder()\n",
    "    corr_df[col + '_encoded'] = le.fit_transform(train_feat[col].astype(str))\n",
    "\n",
    "correlation_matrix = corr_df.corr()\n",
    "\n",
    "# Find high correlations (>0.7)\n",
    "high_corr = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.7:\n",
    "            high_corr.append({\n",
    "                'feature1': correlation_matrix.columns[i],\n",
    "                'feature2': correlation_matrix.columns[j],\n",
    "                'correlation': corr_val\n",
    "            })\n",
    "\n",
    "print(\"High correlations (>0.7):\")\n",
    "for hc in high_corr:\n",
    "    print(f\"  {hc['feature1']} <-> {hc['feature2']}: {hc['correlation']:.3f}\")\n",
    "\n",
    "if not high_corr:\n",
    "    print(\"  No high correlations found\")\n",
    "\n",
    "# Specifically check the known redundant pairs\n",
    "print(\"\\n=== KNOWN REDUNDANT FEATURES ===\")\n",
    "print(f\"SibSp <-> FamilySize: {correlation_matrix.loc['SibSp', 'FamilySize']:.3f}\")\n",
    "print(f\"Parch <-> FamilySize: {correlation_matrix.loc['Parch', 'FamilySize']:.3f}\")\n",
    "print(f\"Fare <-> FarePerPerson: {correlation_matrix.loc['Fare', 'FarePerPerson']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf04b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which features might be overfitting\n",
    "print(\"=== FEATURE COMPLEXITY ANALYSIS ===\\n\")\n",
    "\n",
    "# Count unique values for each categorical feature (potential overfitting risk)\n",
    "categorical_features = ['Title', 'Deck', 'CabinSide', 'FareBin5', 'Pclass_Sex', 'AgeGroup_Sex', 'FareBin5_Sex']\n",
    "\n",
    "print(\"Unique values per categorical feature:\")\n",
    "for col in categorical_features:\n",
    "    train_unique = train_feat[col].nunique()\n",
    "    test_unique = test_feat[col].nunique()\n",
    "    total_train = len(train_feat)\n",
    "    avg_per_category = total_train / train_unique\n",
    "    print(f\"  {col:<20}: {train_unique:2d} unique (avg {avg_per_category:5.1f} samples/category)\")\n",
    "    \n",
    "    # Flag features with too many categories\n",
    "    if train_unique > 10 and avg_per_category < 20:\n",
    "        print(f\"    ⚠️  High cardinality, low samples per category - overfitting risk\")\n",
    "\n",
    "# Check interaction features specifically\n",
    "print(\"\\n=== INTERACTION FEATURE ANALYSIS ===\")\n",
    "interaction_features = ['Pclass_Sex', 'AgeGroup_Sex', 'FareBin5_Sex']\n",
    "\n",
    "for col in interaction_features:\n",
    "    print(f\"\\n{col}:\")\n",
    "    value_counts = train_feat[col].value_counts()\n",
    "    print(f\"  Categories: {len(value_counts)}\")\n",
    "    print(f\"  Min samples in category: {value_counts.min()}\")\n",
    "    print(f\"  Max samples in category: {value_counts.max()}\")\n",
    "    \n",
    "    # Show rare categories\n",
    "    rare_cats = value_counts[value_counts < 5]\n",
    "    if len(rare_cats) > 0:\n",
    "        print(f\"  Rare categories (<5 samples): {len(rare_cats)}\")\n",
    "        print(f\"  {list(rare_cats.index)}\")\n",
    "        print(\"  ⚠️  Rare categories may overfit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e02a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print(\"=== ANALYSIS SUMMARY ===\\n\")\n",
    "\n",
    "print(\"CV-LB Gap: +0.0723 (CV much higher than LB)\")\n",
    "print(\"This indicates potential overfitting or distribution shift.\\n\")\n",
    "\n",
    "print(\"Key Findings:\")\n",
    "print(\"1. Feature redundancy: SibSp/Parch overlap with FamilySize\")\n",
    "print(\"2. High cardinality features with low samples per category\")\n",
    "print(\"3. Interaction features have rare categories (<5 samples)\")\n",
    "print(\"4. Some tickets appear in both train and test (potential leakage)\")\n",
    "print(\"5. Fare distribution may differ between train and test\\n\")\n",
    "\n",
    "print(\"Recommendations:\")\n",
    "print(\"1. Remove redundant features (SibSp, Parch, FarePerPerson)\")\n",
    "print(\"2. Simplify interaction features or remove rare categories\")\n",
    "print(\"3. Consider removing CabinSide (low importance, high complexity)\")\n",
    "print(\"4. Try simpler model with fewer features\")\n",
    "print(\"5. Test if hyperparameter tuning helps generalization\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
