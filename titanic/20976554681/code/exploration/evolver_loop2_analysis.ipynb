{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51599553",
   "metadata": {},
   "source": [
    "# Evolver Loop 2: Feature Engineering Deep Dive\n",
    "\n",
    "This notebook validates the high-impact features identified in Loop 1 and prepares for the next experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67fe4cac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:25:53.946501Z",
     "iopub.status.busy": "2026-01-14T03:25:53.945825Z",
     "iopub.status.idle": "2026-01-14T03:25:53.957520Z",
     "shell.execute_reply": "2026-01-14T03:25:53.957016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n",
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(\"Data loaded successfully\")\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803a944",
   "metadata": {},
   "source": [
    "## 1. Validate Ticket Frequency Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00df0c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:25:53.959093Z",
     "iopub.status.busy": "2026-01-14T03:25:53.958928Z",
     "iopub.status.idle": "2026-01-14T03:25:53.974909Z",
     "shell.execute_reply": "2026-01-14T03:25:53.974447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival by Ticket Frequency:\n",
      "            Count  Survived  SurvivalRate\n",
      "TicketFreq                               \n",
      "1             481       130         0.270\n",
      "2             181        93         0.514\n",
      "3             101        66         0.653\n",
      "4              44        32         0.727\n",
      "5              21         7         0.333\n",
      "6              19         4         0.211\n",
      "7              24         5         0.208\n",
      "8              13         5         0.385\n",
      "11              7         0         0.000\n",
      "\n",
      "Shared tickets survival rate: 0.517 (410 passengers)\n",
      "Solo tickets survival rate: 0.270 (481 passengers)\n",
      "Absolute difference: 0.247\n"
     ]
    }
   ],
   "source": [
    "# Combine train and test for ticket frequency calculation\n",
    "combined = pd.concat([train, test], axis=0, sort=False)\n",
    "combined['TicketFreq'] = combined.groupby('Ticket')['Ticket'].transform('count')\n",
    "\n",
    "# Split back\n",
    "train['TicketFreq'] = combined.iloc[:len(train)]['TicketFreq']\n",
    "test['TicketFreq'] = combined.iloc[len(train):]['TicketFreq']\n",
    "\n",
    "# Analyze survival by ticket frequency\n",
    "ticket_survival = train.groupby('TicketFreq')['Survived'].agg(['count', 'sum', 'mean']).round(3)\n",
    "ticket_survival.columns = ['Count', 'Survived', 'SurvivalRate']\n",
    "print(\"Survival by Ticket Frequency:\")\n",
    "print(ticket_survival)\n",
    "\n",
    "# Focus on shared tickets (freq > 1)\n",
    "shared_tickets = train[train['TicketFreq'] > 1]\n",
    "solo_tickets = train[train['TicketFreq'] == 1]\n",
    "\n",
    "print(f\"\\nShared tickets survival rate: {shared_tickets['Survived'].mean():.3f} ({len(shared_tickets)} passengers)\")\n",
    "print(f\"Solo tickets survival rate: {solo_tickets['Survived'].mean():.3f} ({len(solo_tickets)} passengers)\")\n",
    "print(f\"Absolute difference: {shared_tickets['Survived'].mean() - solo_tickets['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba6e8f",
   "metadata": {},
   "source": [
    "## 2. Validate Cabin Side Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d7a714a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:26:41.303477Z",
     "iopub.status.busy": "2026-01-14T03:26:41.302960Z",
     "iopub.status.idle": "2026-01-14T03:26:41.316758Z",
     "shell.execute_reply": "2026-01-14T03:26:41.316250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival by Cabin Side (0=Even, 1=Odd):\n",
      "           Count  Survived  SurvivalRate\n",
      "CabinSide                               \n",
      "0.0          108        66         0.611\n",
      "1.0           88        67         0.761\n",
      "\n",
      "Even side survival rate: 0.611 (108 passengers)\n",
      "Odd side survival rate: 0.761 (88 passengers)\n",
      "Absolute difference: -0.150\n"
     ]
    }
   ],
   "source": [
    "# Extract cabin side (even/odd) from cabin numbers\n",
    "def extract_cabin_side(cabin):\n",
    "    if pd.isna(cabin):\n",
    "        return np.nan\n",
    "    # Get first cabin number if multiple\n",
    "    cabin = str(cabin).split()[0]\n",
    "    # Extract numbers\n",
    "    numbers = ''.join(filter(str.isdigit, cabin))\n",
    "    if numbers:\n",
    "        return int(numbers) % 2  # 0=even, 1=odd\n",
    "    return np.nan\n",
    "\n",
    "train['CabinSide'] = train['Cabin'].apply(extract_cabin_side)\n",
    "test['CabinSide'] = test['Cabin'].apply(extract_cabin_side)\n",
    "\n",
    "# Analyze survival by cabin side\n",
    "cabin_side_survival = train.groupby('CabinSide')['Survived'].agg(['count', 'sum', 'mean']).round(3)\n",
    "cabin_side_survival.columns = ['Count', 'Survived', 'SurvivalRate']\n",
    "print(\"Survival by Cabin Side (0=Even, 1=Odd):\")\n",
    "print(cabin_side_survival)\n",
    "\n",
    "# For passengers with cabin info\n",
    "cabin_known = train[train['CabinSide'].notna()]\n",
    "even_side = cabin_known[cabin_known['CabinSide'] == 0]\n",
    "odd_side = cabin_known[cabin_known['CabinSide'] == 1]\n",
    "\n",
    "if len(even_side) > 0 and len(odd_side) > 0:\n",
    "    print(f\"\\nEven side survival rate: {even_side['Survived'].mean():.3f} ({len(even_side)} passengers)\")\n",
    "    print(f\"Odd side survival rate: {odd_side['Survived'].mean():.3f} ({len(odd_side)} passengers)\")\n",
    "    print(f\"Absolute difference: {even_side['Survived'].mean() - odd_side['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c7657",
   "metadata": {},
   "source": [
    "## 3. Validate Name Length Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee3663a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:26:41.318473Z",
     "iopub.status.busy": "2026-01-14T03:26:41.318302Z",
     "iopub.status.idle": "2026-01-14T03:26:41.340434Z",
     "shell.execute_reply": "2026-01-14T03:26:41.339925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between NameLength and Survived: 0.332\n",
      "\n",
      "Survival by Name Length Quintile:\n",
      "NameLengthBin\n",
      "Q1    0.221\n",
      "Q2    0.301\n",
      "Q3    0.320\n",
      "Q4    0.442\n",
      "Q5    0.675\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate name length\n",
    "train['NameLength'] = train['Name'].apply(len)\n",
    "test['NameLength'] = test['Name'].apply(len)\n",
    "\n",
    "# Correlation with survival\n",
    "correlation = train['NameLength'].corr(train['Survived'])\n",
    "print(f\"Correlation between NameLength and Survived: {correlation:.3f}\")\n",
    "\n",
    "# Bin name length and analyze\n",
    "train['NameLengthBin'] = pd.qcut(train['NameLength'], 5, labels=['Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "name_length_survival = train.groupby('NameLengthBin')['Survived'].mean()\n",
    "print(\"\\nSurvival by Name Length Quintile:\")\n",
    "print(name_length_survival.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a049a54",
   "metadata": {},
   "source": [
    "## 4. Validate Fare Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3bc3b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:26:41.342224Z",
     "iopub.status.busy": "2026-01-14T03:26:41.342046Z",
     "iopub.status.idle": "2026-01-14T03:26:41.353616Z",
     "shell.execute_reply": "2026-01-14T03:26:41.353112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival by 5 Fare Bins:\n",
      "          Count  Survived  SurvivalRate\n",
      "FareBin5                               \n",
      "VeryLow     179        39         0.218\n",
      "Low         184        37         0.201\n",
      "Medium      172        73         0.424\n",
      "High        180        80         0.444\n",
      "VeryHigh    176       113         0.642\n"
     ]
    }
   ],
   "source": [
    "# Create 5-bin fare categories\n",
    "train['FareBin5'] = pd.qcut(train['Fare'], 5, labels=['VeryLow', 'Low', 'Medium', 'High', 'VeryHigh'])\n",
    "test['FareBin5'] = pd.qcut(test['Fare'], 5, labels=['VeryLow', 'Low', 'Medium', 'High', 'VeryHigh'])\n",
    "\n",
    "fare_survival = train.groupby('FareBin5')['Survived'].agg(['count', 'sum', 'mean']).round(3)\n",
    "fare_survival.columns = ['Count', 'Survived', 'SurvivalRate']\n",
    "print(\"Survival by 5 Fare Bins:\")\n",
    "print(fare_survival)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b347a0",
   "metadata": {},
   "source": [
    "## 5. Quick Model Test with New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepare features for quick test\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "\n",
    "# Add engineered features\n",
    "engineered_features = ['TicketFreq', 'CabinSide', 'NameLength', 'FareBin5']\n",
    "\n",
    "# Combine all features\n",
    "all_features = features + engineered_features\n",
    "\n",
    "# Create a copy for preprocessing\n",
    "train_test = pd.concat([train, test], axis=0, sort=False)\n",
    "\n",
    "# Fill missing values\n",
    "train_test['Age'].fillna(train_test['Age'].median(), inplace=True)\n",
    "train_test['Fare'].fillna(train_test['Fare'].median(), inplace=True)\n",
    "train_test['Embarked'].fillna(train_test['Embarked'].mode()[0], inplace=True)\n",
    "train_test['CabinSide'].fillna(-1, inplace=True)  # -1 for unknown\n",
    "\n",
    "# Encode categorical variables\n",
    "le_sex = LabelEncoder()\n",
    "train_test['Sex'] = le_sex.fit_transform(train_test['Sex'])\n",
    "\n",
    "le_embarked = LabelEncoder()\n",
    "train_test['Embarked'] = le_embarked.fit_transform(train_test['Embarked'])\n",
    "\n",
    "le_farebin = LabelEncoder()\n",
    "train_test['FareBin5'] = le_farebin.fit_transform(train_test['FareBin5'].astype(str))\n",
    "\n",
    "# Split back\n",
    "train_processed = train_test.iloc[:len(train)]\n",
    "test_processed = train_test.iloc[len(train):]\n",
    "\n",
    "# Prepare data for modeling\n",
    "X = train_processed[all_features]\n",
    "y = train['Survived']\n",
    "\n",
    "# Quick CV test\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    scores.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "print(f\"CV scores with new features: {scores}\")\n",
    "print(f\"Mean CV accuracy: {np.mean(scores):.4f} Â± {np.std(scores):.4f}\")\n",
    "print(f\"Improvement over baseline: {np.mean(scores) - 0.817:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5dbc04",
   "metadata": {},
   "source": [
    "## Summary of Findings\n",
    "\n",
    "This analysis validates the high-impact features identified in Loop 1."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
