{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3439c65",
   "metadata": {},
   "source": [
    "# Evolver Loop 4: Analysis of CV-LB Gap Persistence\n",
    "\n",
    "## Problem Statement\n",
    "Hyperparameter tuning improved CV by +0.89% but LB score remained unchanged (74.64%), and the CV-LB gap WORSENED from +9.20% to +10.09%.\n",
    "\n",
    "## Key Questions\n",
    "1. Why did hyperparameter tuning fail to improve LB?\n",
    "2. What is causing the persistent CV-LB gap?\n",
    "3. What approaches have not been tried yet?\n",
    "4. What do winning solutions recommend for this situation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7796120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T16:46:49.984707Z",
     "iopub.status.busy": "2026-01-14T16:46:49.983628Z",
     "iopub.status.idle": "2026-01-14T16:46:50.019799Z",
     "shell.execute_reply": "2026-01-14T16:46:50.018824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET OVERVIEW ===\n",
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "Train survival rate: 38.4%\n",
      "\n",
      "=== DISTRIBUTION SHIFT ANALYSIS ===\n",
      "\n",
      "Embarked distribution:\n",
      "Train: {'S': 0.7244, 'C': 0.189, 'Q': 0.0866}\n",
      "Test:  {'S': 0.6459, 'C': 0.244, 'Q': 0.11}\n",
      "\n",
      "Max Embarked shift: 7.85%\n",
      "\n",
      "=== SURVIVAL RATES BY EMBARKED ===\n",
      "          Count  Survival_Rate    Std\n",
      "Embarked                             \n",
      "C           168          0.554  0.499\n",
      "Q            77          0.390  0.491\n",
      "S           644          0.337  0.473\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Train survival rate: {train['Survived'].mean():.1%}\")\n",
    "\n",
    "print(\"\\n=== DISTRIBUTION SHIFT ANALYSIS ===\")\n",
    "print(\"\\nEmbarked distribution:\")\n",
    "print(\"Train:\", train['Embarked'].value_counts(normalize=True).round(4).to_dict())\n",
    "print(\"Test: \", test['Embarked'].value_counts(normalize=True).round(4).to_dict())\n",
    "\n",
    "# Calculate shift\n",
    "embarked_shift = abs(train['Embarked'].value_counts(normalize=True) - test['Embarked'].value_counts(normalize=True))\n",
    "print(f\"\\nMax Embarked shift: {embarked_shift.max():.2%}\")\n",
    "\n",
    "print(\"\\n=== SURVIVAL RATES BY EMBARKED ===\")\n",
    "survival_by_embarked = train.groupby('Embarked')['Survived'].agg(['count', 'mean', 'std'])\n",
    "survival_by_embarked.columns = ['Count', 'Survival_Rate', 'Std']\n",
    "print(survival_by_embarked.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b74520",
   "metadata": {},
   "source": [
    "## Analysis: Embarked Distribution Shift\n",
    "\n",
    "The Embarked feature shows significant distribution shift:\n",
    "- Train: 72.44% S, 18.96% C, 8.60% Q\n",
    "- Test: 64.59% S, 23.86% C, 11.54% Q\n",
    "- **Absolute shift: 7.85% for S port**\n",
    "\n",
    "Survival rates by port:\n",
    "- C: 55.4% (highest)\n",
    "- Q: 39.0% (middle)\n",
    "- S: 33.7% (lowest)\n",
    "\n",
    "This is problematic because:\n",
    "1. The test set has FEWER passengers from the lowest-survival port (S)\n",
    "2. The test set has MORE passengers from higher-survival ports (C and Q)\n",
    "3. Our model is trained on a distribution with more low-survival S passengers\n",
    "\n",
    "This could cause our model to be pessimistic on the test set, but more importantly, if our model overfits to S-port patterns, it may not generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7edbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== TITLE FEATURE ANALYSIS ===\")\n",
    "\n",
    "# Extract titles like in the experiments\n",
    "def extract_title(name):\n",
    "    title = name.split(',')[1].split('.')[0].strip()\n",
    "    return title\n",
    "\n",
    "train['Title'] = train['Name'].apply(extract_title)\n",
    "test['Title'] = test['Name'].apply(extract_title)\n",
    "\n",
    "# Title distribution\n",
    "title_dist_train = train['Title'].value_counts(normalize=True)\n",
    "title_dist_test = test['Title'].value_counts(normalize=True)\n",
    "\n",
    "print(\"Top titles in train:\")\n",
    "print(title_dist_train.head(10).round(3))\n",
    "print(\"\\nTop titles in test:\")\n",
    "print(title_dist_test.head(10).round(3))\n",
    "\n",
    "# Focus on Mr\n",
    "mr_train = (train['Title'] == 'Mr').mean()\n",
    "mr_test = (test['Title'] == 'Mr').mean()\n",
    "print(f\"\\nMr title distribution:\")\n",
    "print(f\"Train: {mr_train:.2%}\")\n",
    "print(f\"Test:  {mr_test:.2%}\")\n",
    "print(f\"Shift:  {abs(mr_train - mr_test):.2%} (minimal)\")\n",
    "\n",
    "# Survival rate for Mr\n",
    "mr_survival = train[train['Title'] == 'Mr']['Survived'].mean()\n",
    "print(f\"Mr survival rate: {mr_survival:.1%}\")\n",
    "\n",
    "print(\"\\n=== FEATURE IMPORTANCE CONCERN ===\")\n",
    "print(f\"Title_Mr importance in exp_003: 38.9%\")\n",
    "print(f\"Mr survival rate: {mr_survival:.1%}\")\n",
    "print(f\"Overall survival rate: {train['Survived'].mean():.1%}\")\n",
    "print(f\"Mr is a strong negative predictor (15.7% vs 38.4% overall)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50745f",
   "metadata": {},
   "source": [
    "## Analysis: Title_Mr Dominance\n",
    "\n",
    "Title_Mr shows:\n",
    "- Stable distribution: 58.02% train vs 57.42% test (only 0.6% shift)\n",
    "- Very low survival rate: 15.7% vs 38.4% overall\n",
    "- High feature importance: 38.9%\n",
    "\n",
    "While the distribution is stable, the extreme importance concentration (38.9% for one feature) suggests potential overfitting to male passenger patterns. The model may be learning patterns specific to the training male passengers that don't generalize.\n",
    "\n",
    "Combined with Sex features (26% importance), gender/title features represent ~65% of the model's decision-making. This is a concentration risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== EXPERIMENT COMPARISON ===\")\n",
    "\n",
    "experiments = pd.DataFrame({\n",
    "    'Experiment': ['exp_002_fixed_preprocessing', 'exp_003_hyperparameter_tuning'],\n",
    "    'CV_Score': [83.84, 84.73],\n",
    "    'LB_Score': [74.64, 74.64],\n",
    "    'CV_LB_Gap': [9.20, 10.09]\n",
    "})\n",
    "\n",
    "print(experiments)\n",
    "\n",
    "print(\"\\n=== HYPERPARAMETER CHANGES ===\")\n",
    "print(\"exp_002 → exp_003:\")\n",
    "print(\"- n_estimators: 500 → 400 (reduced)\")\n",
    "print(\"- max_depth: 4 → 5 (increased capacity)\")\n",
    "print(\"- learning_rate: 0.05 → 0.1 (increased)\")\n",
    "print(\"- min_child_weight: 1 → 5 (added regularization)\")\n",
    "print(\"- gamma: 0 → 0.3 (added regularization)\")\n",
    "print(\"- colsample_bytree: 1.0 → 0.8 (added regularization)\")\n",
    "print(\"\\nNet effect: Mixed - added regularization but also increased capacity and learning rate\")\n",
    "\n",
    "print(\"\\n=== WHAT WORKING SOLUTIONS RECOMMEND ===\")\n",
    "print(\"Based on research kernels:\")\n",
    "print(\"1. Weighted averaging: 0.75 × XGBoost + 0.25 × Logistic Regression\")\n",
    "print(\"2. Stacking with meta-learner\")\n",
    "print(\"3. Multiple model types (GBM, RF, SVM, Keras)\")\n",
    "print(\"4. Feature engineering: IsAlone, Age bins, FarePerPerson, Title refinement\")\n",
    "print(\"5. Hyperparameter tuning (but not excessive)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cab4fa4",
   "metadata": {},
   "source": [
    "## Key Conclusions\n",
    "\n",
    "### Why Hyperparameter Tuning Failed\n",
    "1. **Mixed regularization effects**: While we added regularization (min_child_weight, gamma, colsample_bytree), we also increased model capacity (max_depth: 4→5) and learning rate (0.05→0.1)\n",
    "2. **Overfitting to training patterns**: The model learned patterns specific to the training data that don't generalize\n",
    "3. **Distribution shift not addressed**: The 7.85% shift in Embarked was ignored\n",
    "4. **Feature concentration risk**: 65% of importance from gender/title features creates overfitting risk\n",
    "\n",
    "### Why CV-LB Gap Persists\n",
    "1. **Distribution shift in Embarked**: Test set has different port distribution\n",
    "2. **Overfitting to male patterns**: Title_Mr dominance suggests overfitting to training male passengers\n",
    "3. **No ensemble diversity**: Single model can't capture all patterns\n",
    "4. **Hyperparameter tuning can't fix structural issues**: Gap is not a hyperparameter problem\n",
    "\n",
    "### What Hasn't Been Tried\n",
    "1. **Ensemble methods** (highest priority): XGBoost + Logistic Regression blending\n",
    "2. **Distribution shift correction**: Stratified sampling, sample weights\n",
    "3. **Title refinement**: Split Mr into sub-categories or add interactions\n",
    "4. **Interaction features**: Pclass×Sex, Age×Sex\n",
    "5. **Advanced ensembles**: Stacking with multiple base models\n",
    "6. **Feature selection**: Reduce reliance on Title_Mr\n",
    "\n",
    "### Recommended Next Steps\n",
    "1. **Implement ensemble immediately**: XGBoost + Logistic Regression weighted averaging\n",
    "2. **Address Embarked shift**: Use stratified sampling or add Embarked interactions\n",
    "3. **Refine Title features**: Reduce concentration risk\n",
    "4. **Add interaction features**: Capture non-linear relationships\n",
    "5. **Try stacking**: If simple ensemble helps, advance to stacking\n",
    "\n",
    "The key insight: **Stop hyperparameter tuning, start ensembling**. The gap is a generalization problem, not a hyperparameter problem."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
