{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "004a0aae",
   "metadata": {},
   "source": [
    "# Evolver Loop 3 Analysis: Interaction Features & Misclassification Patterns\n",
    "\n",
    "This notebook investigates class-gender interaction patterns and prepares for the next experiment incorporating validated features and XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e98e9f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:47:41.674404Z",
     "iopub.status.busy": "2026-01-14T04:47:41.673737Z",
     "iopub.status.idle": "2026-01-14T04:47:43.080517Z",
     "shell.execute_reply": "2026-01-14T04:47:43.079983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Target distribution:\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d72934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:47:43.082689Z",
     "iopub.status.busy": "2026-01-14T04:47:43.082269Z",
     "iopub.status.idle": "2026-01-14T04:47:43.120104Z",
     "shell.execute_reply": "2026-01-14T04:47:43.119641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features engineered successfully\n",
      "New features added: ['TicketFreq', 'FarePerPerson', 'CabinSide', 'IsAlone', 'Deck', 'NameLength', 'FareBin5', 'Title', 'FamilySize', 'AgeGroup']\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering functions from previous analysis\n",
    "def engineer_features(df):\n",
    "    \"\"\"Engineer features for Titanic dataset\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Title extraction\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # Family features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # Age groups\n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], \n",
    "                           labels=['Child', 'Teen', 'YoungAdult', 'Adult', 'Senior'])\n",
    "    \n",
    "    # Fare per person\n",
    "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "    \n",
    "    # Deck from cabin\n",
    "    df['Deck'] = df['Cabin'].str[0]\n",
    "    df['Deck'] = df['Deck'].fillna('Unknown')\n",
    "    \n",
    "    # Ticket frequency (shared tickets)\n",
    "    combined = pd.concat([train, test], axis=0, sort=False)\n",
    "    combined['TicketFreq'] = combined.groupby('Ticket')['Ticket'].transform('count')\n",
    "    df['TicketFreq'] = combined.iloc[:len(df) if df.equals(train) else len(train):len(train)+len(df)]['TicketFreq']\n",
    "    \n",
    "    # Cabin side (odd/even)\n",
    "    def extract_cabin_side(cabin):\n",
    "        if pd.isna(cabin):\n",
    "            return np.nan\n",
    "        cabin = str(cabin).split()[0]\n",
    "        numbers = ''.join(filter(str.isdigit, cabin))\n",
    "        if numbers:\n",
    "            return int(numbers) % 2\n",
    "        return np.nan\n",
    "    \n",
    "    df['CabinSide'] = df['Cabin'].apply(extract_cabin_side)\n",
    "    \n",
    "    # Name length\n",
    "    df['NameLength'] = df['Name'].apply(len)\n",
    "    \n",
    "    # Fare binning (5 categories)\n",
    "    df['FareBin5'] = pd.qcut(df['Fare'], 5, labels=['VeryLow', 'Low', 'Medium', 'High', 'VeryHigh'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_fe = engineer_features(train)\n",
    "test_fe = engineer_features(test)\n",
    "\n",
    "print(\"Features engineered successfully\")\n",
    "print(f\"New features added: {list(set(train_fe.columns) - set(train.columns))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41914a61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:47:43.121866Z",
     "iopub.status.busy": "2026-01-14T04:47:43.121695Z",
     "iopub.status.idle": "2026-01-14T04:47:43.142328Z",
     "shell.execute_reply": "2026-01-14T04:47:43.141877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction features created:\n",
      "- Pclass_Sex\n",
      "- AgeGroup_Sex\n",
      "- FareBin5_Sex\n",
      "\n",
      "============================================================\n",
      "SURVIVAL RATES BY CLASS-GENDER INTERACTION\n",
      "============================================================\n",
      "    1_female: 96.8% survival (91/94 passengers)\n",
      "    2_female: 92.1% survival (70/76 passengers)\n",
      "    3_female: 50.0% survival (72/144 passengers)\n",
      "      1_male: 36.9% survival (45/122 passengers)\n",
      "      2_male: 15.7% survival (17/108 passengers)\n",
      "      3_male: 13.5% survival (47/347 passengers)\n",
      "\n",
      "============================================================\n",
      "PROBLEMATIC GROUPS (High misclassification risk)\n",
      "============================================================\n",
      "3rd class females: 50.0% survival (72/144)\n",
      "1st/2nd class males: 27.0% survival (62/230)\n",
      "Young males (≤25) in 2nd/3rd: 18.2% survival (30/165)\n"
     ]
    }
   ],
   "source": [
    "# Analyze class-gender interactions and misclassification patterns\n",
    "# Focus on the groups identified as problematic\n",
    "\n",
    "# Create interaction features\n",
    "interactions = []\n",
    "\n",
    "# Pclass × Sex interaction\n",
    "train_fe['Pclass_Sex'] = train_fe['Pclass'].astype(str) + '_' + train_fe['Sex']\n",
    "test_fe['Pclass_Sex'] = test_fe['Pclass'].astype(str) + '_' + test_fe['Sex']\n",
    "interactions.append('Pclass_Sex')\n",
    "\n",
    "# AgeGroup × Sex interaction\n",
    "train_fe['AgeGroup_Sex'] = train_fe['AgeGroup'].astype(str) + '_' + train_fe['Sex']\n",
    "test_fe['AgeGroup_Sex'] = test_fe['AgeGroup'].astype(str) + '_' + test_fe['Sex']\n",
    "interactions.append('AgeGroup_Sex')\n",
    "\n",
    "# FareBin5 × Sex interaction\n",
    "train_fe['FareBin5_Sex'] = train_fe['FareBin5'].astype(str) + '_' + train_fe['Sex']\n",
    "test_fe['FareBin5_Sex'] = test_fe['FareBin5'].astype(str) + '_' + test_fe['Sex']\n",
    "interactions.append('FareBin5_Sex')\n",
    "\n",
    "print(\"Interaction features created:\")\n",
    "for inter in interactions:\n",
    "    print(f\"- {inter}\")\n",
    "\n",
    "# Analyze survival rates by interaction\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SURVIVAL RATES BY CLASS-GENDER INTERACTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "survival_by_interaction = train_fe.groupby('Pclass_Sex')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "survival_by_interaction['survival_rate'] = survival_by_interaction['mean']\n",
    "survival_by_interaction = survival_by_interaction.sort_values('survival_rate', ascending=False)\n",
    "\n",
    "for idx, row in survival_by_interaction.iterrows():\n",
    "    print(f\"{idx:>12}: {row['survival_rate']:.1%} survival ({int(row['sum'])}/{int(row['count'])} passengers)\")\n",
    "\n",
    "# Identify problematic groups\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROBLEMATIC GROUPS (High misclassification risk)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Third-class females (should have high survival but often misclassified)\n",
    "third_class_females = train_fe[(train_fe['Pclass'] == 3) & (train_fe['Sex'] == 'female')]\n",
    "print(f\"3rd class females: {third_class_females['Survived'].mean():.1%} survival ({third_class_females['Survived'].sum()}/{len(third_class_females)})\")\n",
    "\n",
    "# First/second-class males (should have lower survival but some survive)\n",
    "high_class_males = train_fe[(train_fe['Pclass'].isin([1, 2])) & (train_fe['Sex'] == 'male')]\n",
    "print(f\"1st/2nd class males: {high_class_males['Survived'].mean():.1%} survival ({high_class_males['Survived'].sum()}/{len(high_class_males)})\")\n",
    "\n",
    "# Young males in 2nd/3rd class\n",
    "young_males = train_fe[(train_fe['Sex'] == 'male') & \n",
    "                      (train_fe['Age'] <= 25) & \n",
    "                      (train_fe['Pclass'].isin([2, 3]))]\n",
    "if len(young_males) > 0:\n",
    "    print(f\"Young males (≤25) in 2nd/3rd: {young_males['Survived'].mean():.1%} survival ({young_males['Survived'].sum()}/{len(young_males)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5408c380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:47:43.144043Z",
     "iopub.status.busy": "2026-01-14T04:47:43.143621Z",
     "iopub.status.idle": "2026-01-14T04:47:43.233327Z",
     "shell.execute_reply": "2026-01-14T04:47:43.232828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating clean datasets...\n",
      "Filling missing values...\n",
      "Categorical features: ['Sex', 'Embarked', 'Title', 'Deck', 'Pclass_Sex', 'AgeGroup_Sex', 'FareBin5_Sex']\n",
      "X shape: (891, 20), y shape: (891,)\n",
      "Ready for modeling!\n"
     ]
    }
   ],
   "source": [
    "# Quick test with interaction features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Prepare features\n",
    "feature_cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked',\n",
    "                'Title', 'FamilySize', 'IsAlone', 'AgeGroup', 'FarePerPerson', 'Deck',\n",
    "                'TicketFreq', 'CabinSide', 'NameLength', 'FareBin5'] + interactions\n",
    "\n",
    "print(\"Creating clean datasets...\")\n",
    "train_clean = train_fe[feature_cols + ['Survived']].copy()\n",
    "test_clean = test_fe[feature_cols].copy()\n",
    "\n",
    "# Fill missing values\n",
    "print(\"Filling missing values...\")\n",
    "numeric_cols = train_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = train_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col != 'Survived':\n",
    "        median_val = train_clean[col].median()\n",
    "        train_clean[col].fillna(median_val, inplace=True)\n",
    "        test_clean[col].fillna(median_val, inplace=True)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col != 'Survived':\n",
    "        mode_val = train_clean[col].mode()[0]\n",
    "        train_clean[col].fillna(mode_val, inplace=True)\n",
    "        test_clean[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Setup preprocessor\n",
    "categorical_features = [col for col in categorical_cols if col != 'Survived']\n",
    "print(f\"Categorical features: {categorical_features}\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_features)\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Prepare data\n",
    "X = train_clean.drop('Survived', axis=1)\n",
    "y = train_clean['Survived']\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "print(\"Ready for modeling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9db052",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:49:57.850569Z",
     "iopub.status.busy": "2026-01-14T04:49:57.849897Z",
     "iopub.status.idle": "2026-01-14T04:49:58.259164Z",
     "shell.execute_reply": "2026-01-14T04:49:58.258629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE IMPORTANCE ANALYSIS\n",
      "============================================================\n",
      "Numeric features: 11\n",
      "Categorical features: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 most important features:\n",
      " 1. Sex                  0.1325\n",
      " 2. NameLength           0.1296\n",
      " 3. Age                  0.1171\n",
      " 4. FarePerPerson        0.1041\n",
      " 5. Fare                 0.0978\n",
      " 6. Pclass_Sex           0.0973\n",
      " 7. Title                0.0697\n",
      " 8. AgeGroup_Sex         0.0475\n",
      " 9. FareBin5_Sex         0.0360\n",
      "10. Pclass               0.0353\n",
      "11. Deck                 0.0327\n",
      "12. FamilySize           0.0268\n",
      "13. Embarked             0.0236\n",
      "14. SibSp                0.0223\n",
      "15. Parch                0.0118\n",
      "\n",
      "============================================================\n",
      "INTERACTION FEATURE PERFORMANCE\n",
      "============================================================\n",
      "Pclass_Sex           Rank:  6, Importance: 0.0973\n",
      "AgeGroup_Sex         Rank:  8, Importance: 0.0475\n",
      "FareBin5_Sex         Rank:  9, Importance: 0.0360\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis with interactions\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare data for modeling\n",
    "X = train_clean.drop('Survived', axis=1)\n",
    "y = train_clean['Survived']\n",
    "\n",
    "# Define preprocessing\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit on full data for importance\n",
    "X_enc = preprocessor.fit_transform(X)\n",
    "\n",
    "rf_full = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf_full.fit(X_enc, y)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = numeric_features + categorical_features\n",
    "\n",
    "importances = rf_full.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Top 15 most important features:\")\n",
    "for i in range(min(15, len(feature_names))):\n",
    "    idx = indices[i]\n",
    "    print(f\"{i+1:2d}. {feature_names[idx]:<20} {importances[idx]:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERACTION FEATURE PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "interaction_importances = [importances[feature_names.index(inter)] for inter in interactions]\n",
    "for inter, imp in zip(interactions, interaction_importances):\n",
    "    rank = list(indices).index(feature_names.index(inter)) + 1\n",
    "    print(f\"{inter:<20} Rank: {rank:2d}, Importance: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eec5961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:51:56.323413Z",
     "iopub.status.busy": "2026-01-14T04:51:56.322610Z",
     "iopub.status.idle": "2026-01-14T04:52:00.352090Z",
     "shell.execute_reply": "2026-01-14T04:52:00.351538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL PERFORMANCE TEST\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest CV Score: 0.8305 ± 0.0167\n",
      "Individual folds: [0.8547486  0.81460674 0.80898876 0.83707865 0.83707865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline (no interactions): 0.8237 ± 0.0255\n",
      "Improvement: +0.0068\n",
      "\n",
      "Key Finding: Interaction features improve CV by +0.0068\n",
      "Best interaction: Pclass_Sex (importance: 0.0973, rank: 6)\n"
     ]
    }
   ],
   "source": [
    "# Test model performance with all features including interactions\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"MODEL PERFORMANCE TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare data\n",
    "X = train_clean.drop('Survived', axis=1)\n",
    "y = train_clean['Survived']\n",
    "\n",
    "# Cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Test with RandomForest\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf_scores = cross_val_score(rf, preprocessor.fit_transform(X), y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(f\"RandomForest CV Score: {rf_scores.mean():.4f} ± {rf_scores.std():.4f}\")\n",
    "print(f\"Individual folds: {rf_scores}\")\n",
    "\n",
    "# Compare to baseline (without interactions)\n",
    "baseline_cols = [col for col in feature_cols if col not in interactions]\n",
    "X_baseline = train_clean[baseline_cols]\n",
    "rf_baseline = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Need different preprocessor for baseline\n",
    "numeric_baseline = X_baseline.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_baseline = X_baseline.select_dtypes(include=['object']).columns.tolist()\n",
    "preprocessor_baseline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_baseline),\n",
    "        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_baseline)\n",
    "    ])\n",
    "\n",
    "baseline_scores = cross_val_score(rf_baseline, preprocessor_baseline.fit_transform(X_baseline), y, cv=skf, scoring='accuracy')\n",
    "print(f\"\\nBaseline (no interactions): {baseline_scores.mean():.4f} ± {baseline_scores.std():.4f}\")\n",
    "print(f\"Improvement: +{rf_scores.mean() - baseline_scores.mean():.4f}\")\n",
    "\n",
    "# Record findings\n",
    "print(f\"\\nKey Finding: Interaction features improve CV by +{rf_scores.mean() - baseline_scores.mean():.4f}\")\n",
    "print(f\"Best interaction: Pclass_Sex (importance: 0.0973, rank: 6)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa82ca",
   "metadata": {},
   "source": [
    "## Summary & Recommendations\n",
    "\n",
    "### Key Findings\n",
    "1. **Interaction features work**: +0.0068 CV improvement (0.8237 → 0.8305)\n",
    "2. **Pclass_Sex is most valuable**: Rank #6 in importance (0.0973), directly addresses 3rd class female misclassifications\n",
    "3. **All three interactions contribute**: AgeGroup_Sex and FareBin5_Sex also rank in top 10\n",
    "4. **Problematic groups identified**: 3rd class females (50% survival), 1st/2nd class males (27% survival), young males in 2nd/3rd (18% survival)\n",
    "\n",
    "### Next Steps\n",
    "1. **Test XGBoost** with these interaction features (evaluator's top priority)\n",
    "2. **Hyperparameter tuning** for both RandomForest and XGBoost\n",
    "3. **Additional interactions** to explore: Pclass × AgeGroup, FamilySize × Sex\n",
    "4. **Model ensembling** once we have multiple strong models\n",
    "\n",
    "### Feature Set Ready\n",
    "The validated feature set now includes:\n",
    "- Original features: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked\n",
    "- Engineered: Title, FamilySize, IsAlone, AgeGroup, FarePerPerson, Deck\n",
    "- High-impact: TicketFreq, CabinSide, NameLength, FareBin5\n",
    "- Interactions: Pclass_Sex, AgeGroup_Sex, FareBin5_Sex\n",
    "\n",
    "Total: 20 features with strong theoretical and empirical validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da41527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check what columns are actually in train_fe\n",
    "print(\"Columns in train_fe:\")\n",
    "print(train_fe.columns.tolist())\n",
    "print(f\"\\nTotal columns: {len(train_fe.columns)}\")\n",
    "\n",
    "# Check which columns from feature_cols are missing\n",
    "missing_cols = [col for col in feature_cols if col not in train_fe.columns]\n",
    "print(f\"\\nMissing columns: {missing_cols}\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(train_fe[feature_cols].dtypes.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c88dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check train_fe columns and sample data\n",
    "print(\"train_fe columns:\", train_fe.columns.tolist())\n",
    "print(\"\\ntest_fe columns:\", test_fe.columns.tolist())\n",
    "\n",
    "# Check if all feature_cols exist\n",
    "missing_in_train = [col for col in feature_cols if col not in train_fe.columns]\n",
    "missing_in_test = [col for col in feature_cols if col not in test_fe.columns]\n",
    "\n",
    "print(f\"\\nMissing in train: {missing_in_train}\")\n",
    "print(f\"Missing in test: {missing_in_test}\")\n",
    "\n",
    "# Show first few rows of key columns\n",
    "print(\"\\nSample data:\")\n",
    "print(train_fe[['Pclass', 'Sex', 'Age', 'Title', 'FamilySize', 'TicketFreq', 'CabinSide']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f043e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check feature_cols and actual columns\n",
    "print(\"feature_cols list:\", feature_cols)\n",
    "print(\"\\ntrain_fe columns:\", train_fe.columns.tolist())\n",
    "\n",
    "# Check for missing columns\n",
    "missing = [col for col in feature_cols if col not in train_fe.columns]\n",
    "print(f\"\\nMissing columns: {missing}\")\n",
    "\n",
    "# Check for any typos\n",
    "print(\"\\nChecking similar column names:\")\n",
    "for col in feature_cols:\n",
    "    if col not in train_fe.columns:\n",
    "        matches = [c for c in train_fe.columns if col.lower() in c.lower() or c.lower() in col.lower()]\n",
    "        print(f\"  '{col}' not found. Similar: {matches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844177aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple test: Check if we can access the data\n",
    "print(\"train_fe shape:\", train_fe.shape)\n",
    "print(\"test_fe shape:\", test_fe.shape)\n",
    "\n",
    "# Check a few key columns\n",
    "print(\"\\nChecking key columns:\")\n",
    "for col in ['Pclass', 'Sex', 'Age', 'Title', 'FamilySize', 'TicketFreq']:\n",
    "    if col in train_fe.columns:\n",
    "        print(f\"  {col}: OK\")\n",
    "    else:\n",
    "        print(f\"  {col}: MISSING!\")\n",
    "\n",
    "# Try to create train_clean with just a few columns\n",
    "test_cols = ['Pclass', 'Sex', 'Age', 'Survived']\n",
    "train_test = train_fe[test_cols].copy()\n",
    "print(f\"\\nTest subset created successfully: {train_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a3cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's rebuild this step by step to find the error\n",
    "\n",
    "# Step 1: Define feature columns\n",
    "feature_cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked',\n",
    "                'Title', 'FamilySize', 'IsAlone', 'AgeGroup', 'FarePerPerson', 'Deck',\n",
    "                'TicketFreq', 'CabinSide', 'NameLength', 'FareBin5'] + interactions\n",
    "\n",
    "print(\"Step 1: feature_cols defined\")\n",
    "\n",
    "# Step 2: Create clean datasets\n",
    "train_clean = train_fe[feature_cols + ['Survived']].copy()\n",
    "test_clean = test_fe[feature_cols].copy()\n",
    "print(\"Step 2: train_clean and test_clean created\")\n",
    "print(f\"  train_clean shape: {train_clean.shape}\")\n",
    "print(f\"  test_clean shape: {test_clean.shape}\")\n",
    "\n",
    "# Step 3: Identify column types\n",
    "numeric_cols = train_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = train_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Step 3: Column types identified\")\n",
    "print(f\"  Numeric cols: {len(numeric_cols)}\")\n",
    "print(f\"  Categorical cols: {len(categorical_cols)}\")\n",
    "\n",
    "# Step 4: Fill missing values\n",
    "print(\"Step 4: Filling missing values...\")\n",
    "for col in numeric_cols:\n",
    "    if col != 'Survived':\n",
    "        median_val = train_clean[col].median()\n",
    "        train_clean[col].fillna(median_val, inplace=True)\n",
    "        test_clean[col].fillna(median_val, inplace=True)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col != 'Survived':\n",
    "        mode_val = train_clean[col].mode()[0]\n",
    "        train_clean[col].fillna(mode_val, inplace=True)\n",
    "        test_clean[col].fillna(mode_val, inplace=True)\n",
    "print(\"  Missing values filled\")\n",
    "\n",
    "# Step 5: Setup preprocessor\n",
    "categorical_features = [col for col in categorical_cols if col != 'Survived']\n",
    "print(\"Step 5: Setting up preprocessor\")\n",
    "print(f\"  Categorical features: {categorical_features}\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_features)\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Step 6: Prepare X and y\n",
    "X = train_clean.drop('Survived', axis=1)\n",
    "y = train_clean['Survived']\n",
    "print(\"Step 6: X and y prepared\")\n",
    "print(f\"  X shape: {X.shape}\")\n",
    "print(f\"  y shape: {y.shape}\")\n",
    "print(f\"  X columns: {X.columns.tolist()}\")\n",
    "\n",
    "# Step 7: Test preprocessor fit\n",
    "print(\"Step 7: Testing preprocessor fit...\")\n",
    "try:\n",
    "    preprocessor.fit(X)\n",
    "    print(\"  Preprocessor fit successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"  Error: {e}\")\n",
    "    print(f\"  Error type: {type(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"Data types in train_clean:\")\n",
    "print(train_clean.dtypes)\n",
    "\n",
    "# Check unique values in AgeGroup\n",
    "print(\"\\nUnique values in AgeGroup:\")\n",
    "print(train_clean['AgeGroup'].unique())\n",
    "\n",
    "# Check for any other categorical issues\n",
    "print(\"\\nChecking for object columns:\")\n",
    "obj_cols = train_clean.select_dtypes(include=['object']).columns\n",
    "for col in obj_cols:\n",
    "    print(f\"  {col}: {train_clean[col].unique()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f210718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if AgeGroup is in categorical_features\n",
    "print(\"AgeGroup in categorical_features:\", 'AgeGroup' in categorical_features)\n",
    "print(\"AgeGroup dtype:\", train_clean['AgeGroup'].dtype)\n",
    "print(\"AgeGroup unique values:\", train_clean['AgeGroup'].unique())\n",
    "\n",
    "# The issue is that AgeGroup is a categorical (ordered) dtype but contains strings\n",
    "# Let's check all categorical features and their types\n",
    "print(\"\\nAll categorical features:\")\n",
    "for col in categorical_features:\n",
    "    print(f\"  {col}: {train_clean[col].dtype} - {train_clean[col].unique()[:3]}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
