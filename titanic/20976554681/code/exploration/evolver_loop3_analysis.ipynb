{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "004a0aae",
   "metadata": {},
   "source": [
    "# Evolver Loop 3 Analysis: Interaction Features & Misclassification Patterns\n",
    "\n",
    "This notebook investigates class-gender interaction patterns and prepares for the next experiment incorporating validated features and XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e98e9f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:10:32.152221Z",
     "iopub.status.busy": "2026-01-14T04:10:32.151558Z",
     "iopub.status.idle": "2026-01-14T04:10:33.660425Z",
     "shell.execute_reply": "2026-01-14T04:10:33.659881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Target distribution:\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d72934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:10:33.662567Z",
     "iopub.status.busy": "2026-01-14T04:10:33.662093Z",
     "iopub.status.idle": "2026-01-14T04:10:33.697568Z",
     "shell.execute_reply": "2026-01-14T04:10:33.697090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features engineered successfully\n",
      "New features added: ['FareBin5', 'CabinSide', 'Deck', 'FamilySize', 'Title', 'NameLength', 'TicketFreq', 'FarePerPerson', 'IsAlone', 'AgeGroup']\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering functions from previous analysis\n",
    "def engineer_features(df):\n",
    "    \"\"\"Engineer features for Titanic dataset\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Title extraction\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # Family features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # Age groups\n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], \n",
    "                           labels=['Child', 'Teen', 'YoungAdult', 'Adult', 'Senior'])\n",
    "    \n",
    "    # Fare per person\n",
    "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "    \n",
    "    # Deck from cabin\n",
    "    df['Deck'] = df['Cabin'].str[0]\n",
    "    df['Deck'] = df['Deck'].fillna('Unknown')\n",
    "    \n",
    "    # Ticket frequency (shared tickets)\n",
    "    combined = pd.concat([train, test], axis=0, sort=False)\n",
    "    combined['TicketFreq'] = combined.groupby('Ticket')['Ticket'].transform('count')\n",
    "    df['TicketFreq'] = combined.iloc[:len(df) if df.equals(train) else len(train):len(train)+len(df)]['TicketFreq']\n",
    "    \n",
    "    # Cabin side (odd/even)\n",
    "    def extract_cabin_side(cabin):\n",
    "        if pd.isna(cabin):\n",
    "            return np.nan\n",
    "        cabin = str(cabin).split()[0]\n",
    "        numbers = ''.join(filter(str.isdigit, cabin))\n",
    "        if numbers:\n",
    "            return int(numbers) % 2\n",
    "        return np.nan\n",
    "    \n",
    "    df['CabinSide'] = df['Cabin'].apply(extract_cabin_side)\n",
    "    \n",
    "    # Name length\n",
    "    df['NameLength'] = df['Name'].apply(len)\n",
    "    \n",
    "    # Fare binning (5 categories)\n",
    "    df['FareBin5'] = pd.qcut(df['Fare'], 5, labels=['VeryLow', 'Low', 'Medium', 'High', 'VeryHigh'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_fe = engineer_features(train)\n",
    "test_fe = engineer_features(test)\n",
    "\n",
    "print(\"Features engineered successfully\")\n",
    "print(f\"New features added: {list(set(train_fe.columns) - set(train.columns))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41914a61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:10:33.699305Z",
     "iopub.status.busy": "2026-01-14T04:10:33.699122Z",
     "iopub.status.idle": "2026-01-14T04:10:33.719090Z",
     "shell.execute_reply": "2026-01-14T04:10:33.718640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction features created:\n",
      "- Pclass_Sex\n",
      "- AgeGroup_Sex\n",
      "- FareBin5_Sex\n",
      "\n",
      "============================================================\n",
      "SURVIVAL RATES BY CLASS-GENDER INTERACTION\n",
      "============================================================\n",
      "    1_female: 96.8% survival (91/94 passengers)\n",
      "    2_female: 92.1% survival (70/76 passengers)\n",
      "    3_female: 50.0% survival (72/144 passengers)\n",
      "      1_male: 36.9% survival (45/122 passengers)\n",
      "      2_male: 15.7% survival (17/108 passengers)\n",
      "      3_male: 13.5% survival (47/347 passengers)\n",
      "\n",
      "============================================================\n",
      "PROBLEMATIC GROUPS (High misclassification risk)\n",
      "============================================================\n",
      "3rd class females: 50.0% survival (72/144)\n",
      "1st/2nd class males: 27.0% survival (62/230)\n",
      "Young males (≤25) in 2nd/3rd: 18.2% survival (30/165)\n"
     ]
    }
   ],
   "source": [
    "# Analyze class-gender interactions and misclassification patterns\n",
    "# Focus on the groups identified as problematic\n",
    "\n",
    "# Create interaction features\n",
    "interactions = []\n",
    "\n",
    "# Pclass × Sex interaction\n",
    "train_fe['Pclass_Sex'] = train_fe['Pclass'].astype(str) + '_' + train_fe['Sex']\n",
    "test_fe['Pclass_Sex'] = test_fe['Pclass'].astype(str) + '_' + test_fe['Sex']\n",
    "interactions.append('Pclass_Sex')\n",
    "\n",
    "# AgeGroup × Sex interaction\n",
    "train_fe['AgeGroup_Sex'] = train_fe['AgeGroup'].astype(str) + '_' + train_fe['Sex']\n",
    "test_fe['AgeGroup_Sex'] = test_fe['AgeGroup'].astype(str) + '_' + test_fe['Sex']\n",
    "interactions.append('AgeGroup_Sex')\n",
    "\n",
    "# FareBin5 × Sex interaction\n",
    "train_fe['FareBin5_Sex'] = train_fe['FareBin5'].astype(str) + '_' + train_fe['Sex']\n",
    "test_fe['FareBin5_Sex'] = test_fe['FareBin5'].astype(str) + '_' + test_fe['Sex']\n",
    "interactions.append('FareBin5_Sex')\n",
    "\n",
    "print(\"Interaction features created:\")\n",
    "for inter in interactions:\n",
    "    print(f\"- {inter}\")\n",
    "\n",
    "# Analyze survival rates by interaction\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SURVIVAL RATES BY CLASS-GENDER INTERACTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "survival_by_interaction = train_fe.groupby('Pclass_Sex')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "survival_by_interaction['survival_rate'] = survival_by_interaction['mean']\n",
    "survival_by_interaction = survival_by_interaction.sort_values('survival_rate', ascending=False)\n",
    "\n",
    "for idx, row in survival_by_interaction.iterrows():\n",
    "    print(f\"{idx:>12}: {row['survival_rate']:.1%} survival ({int(row['sum'])}/{int(row['count'])} passengers)\")\n",
    "\n",
    "# Identify problematic groups\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROBLEMATIC GROUPS (High misclassification risk)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Third-class females (should have high survival but often misclassified)\n",
    "third_class_females = train_fe[(train_fe['Pclass'] == 3) & (train_fe['Sex'] == 'female')]\n",
    "print(f\"3rd class females: {third_class_females['Survived'].mean():.1%} survival ({third_class_females['Survived'].sum()}/{len(third_class_females)})\")\n",
    "\n",
    "# First/second-class males (should have lower survival but some survive)\n",
    "high_class_males = train_fe[(train_fe['Pclass'].isin([1, 2])) & (train_fe['Sex'] == 'male')]\n",
    "print(f\"1st/2nd class males: {high_class_males['Survived'].mean():.1%} survival ({high_class_males['Survived'].sum()}/{len(high_class_males)})\")\n",
    "\n",
    "# Young males in 2nd/3rd class\n",
    "young_males = train_fe[(train_fe['Sex'] == 'male') & \n",
    "                      (train_fe['Age'] <= 25) & \n",
    "                      (train_fe['Pclass'].isin([2, 3]))]\n",
    "if len(young_males) > 0:\n",
    "    print(f\"Young males (≤25) in 2nd/3rd: {young_males['Survived'].mean():.1%} survival ({young_males['Survived'].sum()}/{len(young_males)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test with interaction features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Prepare features\n",
    "feature_cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked',\n",
    "                'Title', 'FamilySize', 'IsAlone', 'AgeGroup', 'FarePerPerson', 'Deck',\n",
    "                'TicketFreq', 'CabinSide', 'NameLength', 'FareBin5'] + interactions\n",
    "\n",
    "# Fill missing values\n",
    "train_clean = train_fe[feature_cols + ['Survived']].copy()\n",
    "test_clean = test_fe[feature_cols].copy()\n",
    "\n",
    "# Fill numeric missing with median, categorical with mode\n",
    "numeric_cols = train_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = train_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col != 'Survived':\n",
    "        median_val = train_clean[col].median()\n",
    "        train_clean[col].fillna(median_val, inplace=True)\n",
    "        test_clean[col].fillna(median_val, inplace=True)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col != 'Survived':\n",
    "        mode_val = train_clean[col].mode()[0]\n",
    "        train_clean[col].fillna(mode_val, inplace=True)\n",
    "        test_clean[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = [col for col in categorical_cols if col != 'Survived']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_features)\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "X = train_clean.drop('Survived', axis=1)\n",
    "y = train_clean['Survived']\n",
    "\n",
    "# Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Test with and without interactions\n",
    "scores_without = []\n",
    "scores_with = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Without interactions (baseline features only)\n",
    "    baseline_cols = [col for col in feature_cols if col not in interactions]\n",
    "    X_train_base = X_train[baseline_cols]\n",
    "    X_val_base = X_val[baseline_cols]\n",
    "    \n",
    "    preprocessor.fit(X_train_base)\n",
    "    X_train_base_enc = preprocessor.transform(X_train_base)\n",
    "    X_val_base_enc = preprocessor.transform(X_val_base)\n",
    "    \n",
    "    rf_base = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    rf_base.fit(X_train_base_enc, y_train)\n",
    "    pred_base = rf_base.predict(X_val_base_enc)\n",
    "    score_base = accuracy_score(y_val, pred_base)\n",
    "    scores_without.append(score_base)\n",
    "    \n",
    "    # With interactions\n",
    "    preprocessor.fit(X_train)\n",
    "    X_train_enc = preprocessor.transform(X_train)\n",
    "    X_val_enc = preprocessor.transform(X_val)\n",
    "    \n",
    "    rf_inter = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    rf_inter.fit(X_train_enc, y_train)\n",
    "    pred_inter = rf_inter.predict(X_val_enc)\n",
    "    score_inter = accuracy_score(y_val, pred_inter)\n",
    "    scores_with.append(score_inter)\n",
    "    \n",
    "    print(f\"Fold {fold+1}: Baseline={score_base:.4f}, With interactions={score_inter:.4f} (diff: {score_inter-score_base:+.4f})\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Average without interactions: {np.mean(scores_without):.4f} ± {np.std(scores_without):.4f}\")\n",
    "print(f\"Average with interactions: {np.mean(scores_with):.4f} ± {np.std(scores_with):.4f}\")\n",
    "print(f\"Improvement: +{np.mean(scores_with) - np.mean(scores_without):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9db052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis with interactions\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Fit on full data for importance\n",
    "preprocessor.fit(X)\n",
    "X_enc = preprocessor.transform(X)\n",
    "\n",
    "rf_full = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf_full.fit(X_enc, y)\n",
    "\n",
    "# Get feature names after encoding\n",
    "feature_names = []\n",
    "for name, transformer, columns in preprocessor.transformers_:\n",
    "    if name == 'cat':\n",
    "        # For ordinal encoder, just use column names\n",
    "        feature_names.extend(columns)\n",
    "    else:\n",
    "        # For passthrough, get remaining columns\n",
    "        passthrough_cols = [col for col in X.columns if col not in categorical_features]\n",
    "        feature_names.extend(passthrough_cols)\n",
    "\n",
    "importances = rf_full.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Top 15 most important features:\")\n",
    "for i in range(min(15, len(feature_names))):\n",
    "    idx = indices[i]\n",
    "    print(f\"{i+1:2d}. {feature_names[idx]:<20} {importances[idx]:.4f}\")\n",
    "\n",
    "# Check importance of interaction features\n",
    "print(f\"\\nInteraction feature importances:\")\n",
    "for inter in interactions:\n",
    "    if inter in feature_names:\n",
    "        idx = feature_names.index(inter)\n",
    "        print(f\"- {inter}: {importances[idx]:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {inter}: Not found in features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da41527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check what columns are actually in train_fe\n",
    "print(\"Columns in train_fe:\")\n",
    "print(train_fe.columns.tolist())\n",
    "print(f\"\\nTotal columns: {len(train_fe.columns)}\")\n",
    "\n",
    "# Check which columns from feature_cols are missing\n",
    "missing_cols = [col for col in feature_cols if col not in train_fe.columns]\n",
    "print(f\"\\nMissing columns: {missing_cols}\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(train_fe[feature_cols].dtypes.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c88dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check train_fe columns and sample data\n",
    "print(\"train_fe columns:\", train_fe.columns.tolist())\n",
    "print(\"\\ntest_fe columns:\", test_fe.columns.tolist())\n",
    "\n",
    "# Check if all feature_cols exist\n",
    "missing_in_train = [col for col in feature_cols if col not in train_fe.columns]\n",
    "missing_in_test = [col for col in feature_cols if col not in test_fe.columns]\n",
    "\n",
    "print(f\"\\nMissing in train: {missing_in_train}\")\n",
    "print(f\"Missing in test: {missing_in_test}\")\n",
    "\n",
    "# Show first few rows of key columns\n",
    "print(\"\\nSample data:\")\n",
    "print(train_fe[['Pclass', 'Sex', 'Age', 'Title', 'FamilySize', 'TicketFreq', 'CabinSide']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f043e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check feature_cols and actual columns\n",
    "print(\"feature_cols list:\", feature_cols)\n",
    "print(\"\\ntrain_fe columns:\", train_fe.columns.tolist())\n",
    "\n",
    "# Check for missing columns\n",
    "missing = [col for col in feature_cols if col not in train_fe.columns]\n",
    "print(f\"\\nMissing columns: {missing}\")\n",
    "\n",
    "# Check for any typos\n",
    "print(\"\\nChecking similar column names:\")\n",
    "for col in feature_cols:\n",
    "    if col not in train_fe.columns:\n",
    "        matches = [c for c in train_fe.columns if col.lower() in c.lower() or c.lower() in col.lower()]\n",
    "        print(f\"  '{col}' not found. Similar: {matches}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
