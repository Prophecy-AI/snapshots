{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "004a0aae",
   "metadata": {},
   "source": [
    "# Evolver Loop 3 Analysis: Interaction Features & Misclassification Patterns\n",
    "\n",
    "This notebook investigates class-gender interaction patterns and prepares for the next experiment incorporating validated features and XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d72934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering functions from previous analysis\n",
    "def engineer_features(df):\n",
    "    \"\"\"Engineer features for Titanic dataset\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Title extraction\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # Family features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # Age groups\n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], \n",
    "                           labels=['Child', 'Teen', 'YoungAdult', 'Adult', 'Senior'])\n",
    "    \n",
    "    # Fare per person\n",
    "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "    \n",
    "    # Deck from cabin\n",
    "    df['Deck'] = df['Cabin'].str[0].fillna('Unknown')\n",
    "    \n",
    "    # NEW FEATURES from validation\n",
    "    # Ticket frequency\n",
    "    ticket_counts = df['Ticket'].value_counts()\n",
    "    df['TicketFreq'] = df['Ticket'].map(ticket_counts)\n",
    "    \n",
    "    # Cabin side (odd/even)\n",
    "    df['CabinNumber'] = df['Cabin'].str.extract('(\\d+)')\n",
    "    df['CabinNumber'] = pd.to_numeric(df['CabinNumber'], errors='coerce')\n",
    "    df['CabinSide'] = df['CabinNumber'] % 2\n",
    "    df['CabinSide'] = df['CabinSide'].map({0: 'Even', 1: 'Odd', np.nan: 'Unknown'})\n",
    "    \n",
    "    # Name length\n",
    "    df['NameLength'] = df['Name'].str.len()\n",
    "    \n",
    "    # Fare binning (5 categories)\n",
    "    df['FareBin5'] = pd.qcut(df['Fare'], q=5, \n",
    "                            labels=['VeryLow', 'Low', 'Medium', 'High', 'VeryHigh'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_fe = engineer_features(train)\n",
    "test_fe = engineer_features(test)\n",
    "\n",
    "print(\"Features engineered successfully\")\n",
    "print(f\"New features added: TicketFreq, CabinSide, NameLength, FareBin5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41914a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class-gender interactions and misclassification patterns\n",
    "# Focus on the groups identified as problematic\n",
    "\n",
    "# Create interaction features\n",
    "interactions = []\n",
    "\n",
    "# Pclass × Sex interaction\n",
    "train_fe['Pclass_Sex'] = train_fe['Pclass'].astype(str) + '_' + train_fe['Sex']\n",
    "test_fe['Pclass_Sex'] = test_fe['Pclass'].astype(str) + '_' + test_fe['Sex']\n",
    "interactions.append('Pclass_Sex')\n",
    "\n",
    "# AgeGroup × Sex interaction\n",
    "train_fe['AgeGroup_Sex'] = train_fe['AgeGroup'].astype(str) + '_' + train_fe['Sex']\n",
    "test_fe['AgeGroup_Sex'] = test_fe['AgeGroup'].astype(str) + '_' + test_fe['Sex']\n",
    "interactions.append('AgeGroup_Sex')\n",
    "\n",
    "# FareBin5 × Sex interaction\n",
    "train_fe['FareBin5_Sex'] = train_fe['FareBin5'].astype(str) + '_' + train_fe['Sex']\n",
    "test_fe['FareBin5_Sex'] = test_fe['FareBin5'].astype(str) + '_' + test_fe['Sex']\n",
    "interactions.append('FareBin5_Sex')\n",
    "\n",
    "print(\"Interaction features created:\")\n",
    "for inter in interactions:\n",
    "    print(f\"- {inter}\")\n",
    "\n",
    "# Analyze survival rates by interaction\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SURVIVAL RATES BY CLASS-GENDER INTERACTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "survival_by_interaction = train_fe.groupby('Pclass_Sex')['Survived'].agg(['count', 'sum', 'mean'])\n",
    "survival_by_interaction['survival_rate'] = survival_by_interaction['mean']\n",
    "survival_by_interaction = survival_by_interaction.sort_values('survival_rate', ascending=False)\n",
    "\n",
    "for idx, row in survival_by_interaction.iterrows():\n",
    "    print(f\"{idx:>12}: {row['survival_rate']:.1%} survival ({int(row['sum'])}/{int(row['count'])} passengers)\")\n",
    "\n",
    "# Identify problematic groups\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROBLEMATIC GROUPS (High misclassification risk)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Third-class females (should have high survival but often misclassified)\n",
    "third_class_females = train_fe[(train_fe['Pclass'] == 3) & (train_fe['Sex'] == 'female')]\n",
    "print(f\"3rd class females: {third_class_females['Survived'].mean():.1%} survival ({third_class_females['Survived'].sum()}/{len(third_class_females)})\")\n",
    "\n",
    "# First/second-class males (should have lower survival but some survive)\n",
    "high_class_males = train_fe[(train_fe['Pclass'].isin([1, 2])) & (train_fe['Sex'] == 'male')]\n",
    "print(f\"1st/2nd class males: {high_class_males['Survived'].mean():.1%} survival ({high_class_males['Survived'].sum()}/{len(high_class_males)})\")\n",
    "\n",
    "# Young males in 2nd/3rd class\n",
    "young_males = train_fe[(train_fe['Sex'] == 'male') & \n",
    "                      (train_fe['Age'] <= 25) & \n",
    "                      (train_fe['Pclass'].isin([2, 3]))]\n",
    "if len(young_males) > 0:\n",
    "    print(f\"Young males (≤25) in 2nd/3rd: {young_males['Survived'].mean():.1%} survival ({young_males['Survived'].sum()}/{len(young_males)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test with interaction features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Prepare features\n",
    "feature_cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked',\n",
    "                'Title', 'FamilySize', 'IsAlone', 'AgeGroup', 'FarePerPerson', 'Deck',\n",
    "                'TicketFreq', 'CabinSide', 'NameLength', 'FareBin5'] + interactions\n",
    "\n",
    "# Fill missing values\n",
    "train_clean = train_fe[feature_cols + ['Survived']].copy()\n",
    "test_clean = test_fe[feature_cols].copy()\n",
    "\n",
    "# Fill numeric missing with median, categorical with mode\n",
    "numeric_cols = train_clean.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = train_clean.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col != 'Survived':\n",
    "        median_val = train_clean[col].median()\n",
    "        train_clean[col].fillna(median_val, inplace=True)\n",
    "        test_clean[col].fillna(median_val, inplace=True)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col != 'Survived':\n",
    "        mode_val = train_clean[col].mode()[0]\n",
    "        train_clean[col].fillna(mode_val, inplace=True)\n",
    "        test_clean[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = [col for col in categorical_cols if col != 'Survived']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_features)\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "X = train_clean.drop('Survived', axis=1)\n",
    "y = train_clean['Survived']\n",
    "\n",
    "# Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Test with and without interactions\n",
    "scores_without = []\n",
    "scores_with = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Without interactions (baseline features only)\n",
    "    baseline_cols = [col for col in feature_cols if col not in interactions]\n",
    "    X_train_base = X_train[baseline_cols]\n",
    "    X_val_base = X_val[baseline_cols]\n",
    "    \n",
    "    preprocessor.fit(X_train_base)\n",
    "    X_train_base_enc = preprocessor.transform(X_train_base)\n",
    "    X_val_base_enc = preprocessor.transform(X_val_base)\n",
    "    \n",
    "    rf_base = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    rf_base.fit(X_train_base_enc, y_train)\n",
    "    pred_base = rf_base.predict(X_val_base_enc)\n",
    "    score_base = accuracy_score(y_val, pred_base)\n",
    "    scores_without.append(score_base)\n",
    "    \n",
    "    # With interactions\n",
    "    preprocessor.fit(X_train)\n",
    "    X_train_enc = preprocessor.transform(X_train)\n",
    "    X_val_enc = preprocessor.transform(X_val)\n",
    "    \n",
    "    rf_inter = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    rf_inter.fit(X_train_enc, y_train)\n",
    "    pred_inter = rf_inter.predict(X_val_enc)\n",
    "    score_inter = accuracy_score(y_val, pred_inter)\n",
    "    scores_with.append(score_inter)\n",
    "    \n",
    "    print(f\"Fold {fold+1}: Baseline={score_base:.4f}, With interactions={score_inter:.4f} (diff: {score_inter-score_base:+.4f})\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Average without interactions: {np.mean(scores_without):.4f} ± {np.std(scores_without):.4f}\")\n",
    "print(f\"Average with interactions: {np.mean(scores_with):.4f} ± {np.std(scores_with):.4f}\")\n",
    "print(f\"Improvement: +{np.mean(scores_with) - np.mean(scores_without):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9db052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis with interactions\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Fit on full data for importance\n",
    "preprocessor.fit(X)\n",
    "X_enc = preprocessor.transform(X)\n",
    "\n",
    "rf_full = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf_full.fit(X_enc, y)\n",
    "\n",
    "# Get feature names after encoding\n",
    "feature_names = []\n",
    "for name, transformer, columns in preprocessor.transformers_:\n",
    "    if name == 'cat':\n",
    "        # For ordinal encoder, just use column names\n",
    "        feature_names.extend(columns)\n",
    "    else:\n",
    "        # For passthrough, get remaining columns\n",
    "        passthrough_cols = [col for col in X.columns if col not in categorical_features]\n",
    "        feature_names.extend(passthrough_cols)\n",
    "\n",
    "importances = rf_full.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Top 15 most important features:\")\n",
    "for i in range(min(15, len(feature_names))):\n",
    "    idx = indices[i]\n",
    "    print(f\"{i+1:2d}. {feature_names[idx]:<20} {importances[idx]:.4f}\")\n",
    "\n",
    "# Check importance of interaction features\n",
    "print(f\"\\nInteraction feature importances:\")\n",
    "for inter in interactions:\n",
    "    if inter in feature_names:\n",
    "        idx = feature_names.index(inter)\n",
    "        print(f\"- {inter}: {importances[idx]:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {inter}: Not found in features\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
