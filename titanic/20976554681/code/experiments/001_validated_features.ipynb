{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a46b29e",
   "metadata": {},
   "source": [
    "# Titanic Experiment 001: Validated Features\n",
    "\n",
    "Implementing all validated features from analysis notebooks:\n",
    "- TicketFreq (family/group patterns)\n",
    "- CabinSide (odd/even cabin location)\n",
    "- NameLength (social status)\n",
    "- FareBin5 (granular fare binning)\n",
    "- Interaction features (Pclass_Sex, AgeGroup_Sex, FareBin5_Sex)\n",
    "\n",
    "Expected CV improvement: 0.817 → 0.8305 (+0.0135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aef1a27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:37:12.326333Z",
     "iopub.status.busy": "2026-01-14T05:37:12.325582Z",
     "iopub.status.idle": "2026-01-14T05:37:13.442924Z",
     "shell.execute_reply": "2026-01-14T05:37:13.442341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83756b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:37:13.445770Z",
     "iopub.status.busy": "2026-01-14T05:37:13.445108Z",
     "iopub.status.idle": "2026-01-14T05:37:13.482929Z",
     "shell.execute_reply": "2026-01-14T05:37:13.482291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features created successfully\n",
      "New columns: ['Title', 'FamilySize', 'IsAlone', 'AgeGroup', 'FarePerPerson', 'Deck', 'TicketFreq', 'CabinNumber', 'CabinSide', 'NameLength', 'FareBin5']\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering with ALL validated features\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Extract title from name\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', 'Master': 'Master',\n",
    "        'Dr': 'Other', 'Rev': 'Other', 'Col': 'Other', 'Major': 'Other',\n",
    "        'Mlle': 'Miss', 'Countess': 'Other', 'Ms': 'Miss', 'Lady': 'Other',\n",
    "        'Jonkheer': 'Other', 'Don': 'Other', 'Dona': 'Other', 'Mme': 'Mrs',\n",
    "        'Capt': 'Other', 'Sir': 'Other'\n",
    "    }\n",
    "    df['Title'] = df['Title'].map(title_mapping)\n",
    "    \n",
    "    # 2. Family size and IsAlone\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 3. Age groups\n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], \n",
    "                           labels=['Child', 'Teen', 'Adult', 'MiddleAge', 'Senior'])\n",
    "    \n",
    "    # 4. Fare per person\n",
    "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "    \n",
    "    # 5. Deck from cabin\n",
    "    df['Deck'] = df['Cabin'].str[0]\n",
    "    df['Deck'] = df['Deck'].fillna('Unknown')\n",
    "    \n",
    "    # 6. Ticket frequency (validated feature - captures family/group patterns)\n",
    "    df['TicketFreq'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "    \n",
    "    # 7. Cabin side (validated feature - odd/even cabin location)\n",
    "    df['CabinNumber'] = df['Cabin'].str.extract('([0-9]+)', expand=False).astype(float)\n",
    "    df['CabinSide'] = df['CabinNumber'] % 2\n",
    "    df['CabinSide'] = df['CabinSide'].map({0.0: 'Even', 1.0: 'Odd', np.nan: 'Unknown'})\n",
    "    \n",
    "    # 8. Name length (validated feature - social status)\n",
    "    df['NameLength'] = df['Name'].str.len()\n",
    "    \n",
    "    # 9. Fare binning with 5 categories (validated feature - granular wealth effects)\n",
    "    df['FareBin5'] = pd.qcut(df['Fare'], q=5, labels=['VeryLow', 'Low', 'Medium', 'High', 'VeryHigh'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create features for both datasets\n",
    "train_feat = create_features(train_df)\n",
    "test_feat = create_features(test_df)\n",
    "\n",
    "print(\"Features created successfully\")\n",
    "print(\"New columns:\", [col for col in train_feat.columns if col not in train_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482b2dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:37:13.485016Z",
     "iopub.status.busy": "2026-01-14T05:37:13.484758Z",
     "iopub.status.idle": "2026-01-14T05:37:13.498392Z",
     "shell.execute_reply": "2026-01-14T05:37:13.497814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction features created\n",
      "Interaction columns: ['Pclass_Sex', 'AgeGroup_Sex', 'FareBin5_Sex']\n"
     ]
    }
   ],
   "source": [
    "# Create interaction features (validated - address class-gender misclassifications)\n",
    "def create_interactions(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Pclass_Sex interaction\n",
    "    df['Pclass_Sex'] = df['Pclass'].astype(str) + '_' + df['Sex']\n",
    "    \n",
    "    # AgeGroup_Sex interaction\n",
    "    df['AgeGroup_Sex'] = df['AgeGroup'].astype(str) + '_' + df['Sex']\n",
    "    \n",
    "    # FareBin5_Sex interaction\n",
    "    df['FareBin5_Sex'] = df['FareBin5'].astype(str) + '_' + df['Sex']\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_feat = create_interactions(train_feat)\n",
    "test_feat = create_interactions(test_feat)\n",
    "\n",
    "print(\"Interaction features created\")\n",
    "print(\"Interaction columns:\", ['Pclass_Sex', 'AgeGroup_Sex', 'FareBin5_Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b19e4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:37:13.564611Z",
     "iopub.status.busy": "2026-01-14T05:37:13.564019Z",
     "iopub.status.idle": "2026-01-14T05:37:13.572407Z",
     "shell.execute_reply": "2026-01-14T05:37:13.571777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (891, 20)\n",
      "Test features shape: (418, 20)\n",
      "\n",
      "Numeric features: ['Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'FarePerPerson', 'NameLength', 'TicketFreq']\n",
      "\n",
      "Categorical features: ['Pclass', 'Sex', 'Embarked', 'Title', 'IsAlone', 'AgeGroup', 'Deck', 'CabinSide', 'FareBin5', 'Pclass_Sex', 'AgeGroup_Sex', 'FareBin5_Sex']\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns\n",
    "numeric_features = ['Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'FarePerPerson', 'NameLength', 'TicketFreq']\n",
    "\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'IsAlone', 'AgeGroup', 'Deck', \n",
    "                       'CabinSide', 'FareBin5', 'Pclass_Sex', 'AgeGroup_Sex', 'FareBin5_Sex']\n",
    "\n",
    "# Prepare data\n",
    "X = train_feat[numeric_features + categorical_features]\n",
    "y = train_feat['Survived']\n",
    "X_test = test_feat[numeric_features + categorical_features]\n",
    "\n",
    "print(\"Training features shape:\", X.shape)\n",
    "print(\"Test features shape:\", X_test.shape)\n",
    "print(\"\\nNumeric features:\", numeric_features)\n",
    "print(\"\\nCategorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a90619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:37:13.582616Z",
     "iopub.status.busy": "2026-01-14T05:37:13.581972Z",
     "iopub.status.idle": "2026-01-14T05:37:13.587475Z",
     "shell.execute_reply": "2026-01-14T05:37:13.586891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline created\n"
     ]
    }
   ],
   "source": [
    "# Create preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create full pipeline with RandomForest\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "print(\"Pipeline created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a358439f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:37:13.592187Z",
     "iopub.status.busy": "2026-01-14T05:37:13.591639Z",
     "iopub.status.idle": "2026-01-14T05:37:15.227865Z",
     "shell.execute_reply": "2026-01-14T05:37:15.227212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.8283 ± 0.0160\n",
      "Individual fold scores: [0.8547486  0.82022472 0.80898876 0.83707865 0.82022472]\n",
      "\n",
      "Improvement over baseline: +0.0113\n",
      "Expected: +0.0135 (to reach 0.8305)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(f\"CV Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "print(f\"Individual fold scores: {cv_scores}\")\n",
    "print(f\"\\nImprovement over baseline: +{cv_scores.mean() - 0.8170:.4f}\")\n",
    "print(f\"Expected: +0.0135 (to reach 0.8305)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58daaa84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:37:15.562473Z",
     "iopub.status.busy": "2026-01-14T05:37:15.561766Z",
     "iopub.status.idle": "2026-01-14T05:37:15.846761Z",
     "shell.execute_reply": "2026-01-14T05:37:15.846228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (418, 2)\n",
      "\n",
      "First 10 predictions:\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n",
      "5          897         0\n",
      "6          898         0\n",
      "7          899         0\n",
      "8          900         1\n",
      "9          901         0\n",
      "\n",
      "Submission saved to /home/submission/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Train on full data and predict\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "print(\"Submission shape:\", submission.shape)\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(\"\\nSubmission saved to /home/submission/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b739b7fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:37:15.850776Z",
     "iopub.status.busy": "2026-01-14T05:37:15.850572Z",
     "iopub.status.idle": "2026-01-14T05:37:15.900736Z",
     "shell.execute_reply": "2026-01-14T05:37:15.900160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction distribution:\n",
      "Survived\n",
      "0    270\n",
      "1    148\n",
      "Name: count, dtype: int64\n",
      "Survival rate in predictions: 0.354\n",
      "Survival rate in training: 0.384\n",
      "\n",
      "==================================================\n",
      "TOP 15 FEATURE IMPORTANCES\n",
      "==================================================\n",
      "NameLength                     0.1052\n",
      "Age                            0.0891\n",
      "FarePerPerson                  0.0751\n",
      "Fare                           0.0706\n",
      "Sex_female                     0.0680\n",
      "Title_Mr                       0.0599\n",
      "Sex_male                       0.0541\n",
      "TicketFreq                     0.0273\n",
      "Pclass_Sex_1_female            0.0254\n",
      "FamilySize                     0.0248\n",
      "FareBin5_Sex_VeryHigh_female   0.0234\n",
      "Pclass_Sex_2_female            0.0230\n",
      "Pclass_Sex_3_male              0.0192\n",
      "Pclass_3                       0.0168\n",
      "SibSp                          0.0144\n"
     ]
    }
   ],
   "source": [
    "# Check prediction distribution and feature importance\n",
    "print(\"Prediction distribution:\")\n",
    "print(submission['Survived'].value_counts())\n",
    "print(f\"Survival rate in predictions: {submission['Survived'].mean():.3f}\")\n",
    "print(f\"Survival rate in training: {y.mean():.3f}\")\n",
    "\n",
    "# Get feature importance\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TOP 15 FEATURE IMPORTANCES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Fit preprocessor and get feature names\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Get feature names\n",
    "if hasattr(preprocessor.named_transformers_['cat']['encoder'], 'get_feature_names_out'):\n",
    "    cat_feature_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_features)\n",
    "else:\n",
    "    cat_feature_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names(categorical_features)\n",
    "\n",
    "all_feature_names = np.concatenate([numeric_features, cat_feature_names])\n",
    "\n",
    "# Get importances\n",
    "importances = clf.named_steps['classifier'].feature_importances_\n",
    "top_indices = np.argsort(importances)[::-1][:15]\n",
    "\n",
    "for idx in top_indices:\n",
    "    print(f\"{all_feature_names[idx]:<30} {importances[idx]:.4f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
