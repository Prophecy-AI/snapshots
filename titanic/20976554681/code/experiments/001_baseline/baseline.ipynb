{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35de5ab",
   "metadata": {},
   "source": [
    "# Titanic Baseline Model\n",
    "\n",
    "This notebook creates a baseline model for the Titanic competition using gradient boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(\"\\nTraining data info:\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98094ca",
   "metadata": {},
   "source": [
    "## Basic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target and features\n",
    "X = train_df.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y = train_df['Survived']\n",
    "X_test = test_df.drop(['PassengerId'], axis=1)\n",
    "\n",
    "# Combine for preprocessing\n",
    "combined = pd.concat([X, X_test], axis=0)\n",
    "\n",
    "print(\"Missing values before preprocessing:\")\n",
    "print(combined.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "# Age: fill with median\n",
    "combined['Age'].fillna(combined['Age'].median(), inplace=True)\n",
    "\n",
    "# Embarked: fill with mode\n",
    "combined['Embarked'].fillna(combined['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Fare: fill with median\n",
    "combined['Fare'].fillna(combined['Fare'].median(), inplace=True)\n",
    "\n",
    "# Cabin: create binary feature (has cabin or not)\n",
    "combined['HasCabin'] = (combined['Cabin'].notna()).astype(int)\n",
    "combined.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "print(\"Missing values after preprocessing:\")\n",
    "print(combined.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract titles from names\n",
    "combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Map rare titles to more common ones\n",
    "title_mapping = {\n",
    "    'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', 'Master': 'Master',\n",
    "    'Dr': 'Other', 'Rev': 'Other', 'Col': 'Other', 'Major': 'Other',\n",
    "    'Mlle': 'Miss', 'Countess': 'Other', 'Ms': 'Miss', 'Lady': 'Other',\n",
    "    'Jonkheer': 'Other', 'Don': 'Other', 'Dona': 'Other', 'Mme': 'Mrs',\n",
    "    'Capt': 'Other', 'Sir': 'Other'\n",
    "}\n",
    "combined['Title'] = combined['Title'].map(title_mapping)\n",
    "\n",
    "# Drop Name and Ticket (high cardinality)\n",
    "combined.drop(['Name', 'Ticket'], axis=1, inplace=True)\n",
    "\n",
    "print(\"Unique titles:\", combined['Title'].unique())\n",
    "print(\"Title counts:\", combined['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df7c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "categorical_cols = ['Sex', 'Embarked', 'Title', 'Pclass']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    combined[col] = le.fit_transform(combined[col])\n",
    "\n",
    "print(\"Final feature shapes:\")\n",
    "print(combined.shape)\n",
    "print(\"\\nFeature types:\")\n",
    "print(combined.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8547f7d7",
   "metadata": {},
   "source": [
    "## Create Family Size Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create family size feature\n",
    "combined['FamilySize'] = combined['SibSp'] + combined['Parch'] + 1\n",
    "\n",
    "# Create family size categories\n",
    "combined['FamilySizeCategory'] = pd.cut(combined['FamilySize'], \n",
    "                                       bins=[0, 1, 4, 20], \n",
    "                                       labels=['Single', 'Small', 'Large'])\n",
    "\n",
    "# Encode family size category\n",
    "le_fs = LabelEncoder()\n",
    "combined['FamilySizeCategory'] = le_fs.fit_transform(combined['FamilySizeCategory'])\n",
    "\n",
    "print(\"Family size distribution:\")\n",
    "print(combined['FamilySizeCategory'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5c37f",
   "metadata": {},
   "source": [
    "## Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c9247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split back into train and test\n",
    "X_processed = combined.iloc[:len(X), :]\n",
    "X_test_processed = combined.iloc[len(X):, :]\n",
    "\n",
    "print(f\"Processed training data shape: {X_processed.shape}\")\n",
    "print(f\"Processed test data shape: {X_test_processed.shape}\")\n",
    "\n",
    "# Verify no missing values\n",
    "print(f\"\\nMissing values in training: {X_processed.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in test: {X_test_processed.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6643a4d",
   "metadata": {},
   "source": [
    "## Model Training with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize model\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = []\n",
    "fold = 1\n",
    "\n",
    "print(\"Training with 5-fold cross-validation...\")\n",
    "for train_idx, val_idx in skf.split(X_processed, y):\n",
    "    X_train, X_val = X_processed.iloc[train_idx], X_processed.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_val)\n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    print(f\"Fold {fold}: Accuracy = {score:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "print(f\"\\nCross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean accuracy: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81356e3",
   "metadata": {},
   "source": [
    "## Train on Full Data and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d5986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on full training data\n",
    "model.fit(X_processed, y)\n",
    "\n",
    "# Generate predictions for test set\n",
    "y_pred_test = model.predict(X_test_processed)\n",
    "\n",
    "print(f\"Test predictions shape: {y_pred_test.shape}\")\n",
    "print(f\"Prediction distribution: {np.bincount(y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8082c1",
   "metadata": {},
   "source": [
    "## Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f6ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': y_pred_test\n",
    "})\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(\"\\nSubmission saved to /home/submission/submission.csv\")\n",
    "\n",
    "# Verify submission format\n",
    "print(\"\\nVerifying submission format...\")\n",
    "print(f\"Columns: {list(submission.columns)}\")\n",
    "print(f\"Number of rows: {len(submission)}\")\n",
    "print(f\"Expected rows: 418\")\n",
    "print(f\"PassengerId range: {submission['PassengerId'].min()} to {submission['PassengerId'].max()}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
