## Current Status
- Best CV score: 83.84% from exp_002_fixed_preprocessing
- Best LB score: 74.64% (exp_002)
- CV-LB gap: +9.2% (large but manageable - indicates overfitting)

## Response to Evaluator
- Technical verdict was TRUSTWORTHY - pipeline refactoring successfully eliminated data leakage
- Evaluator's top priority: Hyperparameter tuning to address overfitting - **AGREE COMPLETELY**
- The 9.2% gap is our primary constraint, not the misinterpreted 83% gap
- We must reduce model complexity and improve generalization

## Data Understanding
- Reference: `exploration/evolver_loop2_lb_feedback.ipynb` for gap analysis
- Titanic uses ACCURACY (higher is better) - CV 83.84% is good, LB 74.64% is low
- Training set: 891 samples (very small - prone to overfitting)
- Distribution shift detected: Embarked ports differ (Train: 72% S, Test: 65% S)
- Current features: Title, FamilySize, IsAlone, Age bins (5), FarePerPerson, HasCabin

## Recommended Approaches (Priority Order)

### 1. Hyperparameter Tuning for Regularization (HIGHEST PRIORITY)
**Goal**: Reduce overfitting and close CV-LB gap
- Reduce XGBoost complexity: max_depth=3-4 (from 5), learning_rate=0.05 (from 0.1)
- Add regularization: min_child_weight=3, gamma=0.1, subsample=0.8, colsample_bytree=0.8
- Reduce n_estimators to 200-300 (500 is excessive for 891 samples)
- Use early_stopping_rounds=50 with validation set
**Rationale**: Directly addresses evaluator's priority and our largest gap source

### 2. Feature Engineering Refinements
**Goal**: Improve generalization through better features
- **Interaction Features**: Add Pclass×Sex, Age×Sex, Fare×Pclass (captures non-linear relationships)
- **Title Refinement**: Split 'Other' category into 'Rare_Noble' (Don, Sir, Lady) and 'Rare_Other' (Rev, Dr, etc.)
- **Simplify Age Bins**: Reduce from 5 bins to 3-4 bins [0,16,32,100] to reduce overfitting
- **Add FamilySize**: Use actual value instead of just IsAlone flag (captures more nuance)
**Rationale**: Research shows interaction features and refined categories improve generalization

### 3. Model Diversity & Ensemble
**Goal**: Improve robustness through model combination
- Add Logistic Regression with L2 regularization (C=1.0) as simple baseline
- Try RandomForest (n_estimators=100, max_depth=4) for different bias-variance tradeoff
- Create weighted ensemble: 70% XGBoost + 20% Logistic Regression + 10% RandomForest
- Use stacking with logistic regression meta-learner
**Rationale**: Ensembles with diverse models consistently outperform single models in tabular competitions

### 4. Validation Scheme Enhancement
**Goal**: Better estimate of LB performance
- Use StratifiedKFold (n_splits=5) to maintain class distribution
- Create holdout set: 20% of training data to simulate LB
- Track both CV and holdout scores to monitor gap
- Use cross-validation for hyperparameter selection, not just single split
**Rationale**: Better validation = better hyperparameter choices = smaller CV-LB gap

## What NOT to Try
- ❌ More complex models (Neural Networks, SVM) - dataset is too small
- ❌ Extensive feature engineering without validation - risk of overfitting
- ❌ Hyperparameter tuning without cross-validation - unreliable on small dataset
- ❌ Submitting without addressing the 9.2% gap - would waste submission quota

## Validation Notes
- Primary metric: Accuracy (higher is better)
- Use 5-fold Stratified CV for all experiments
- Create 20% holdout set to estimate LB performance
- Track both CV score and CV-LB gap as key metrics
- Target: Reduce gap to <5% while maintaining CV > 82%