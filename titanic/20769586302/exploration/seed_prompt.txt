# Titanic Survival Prediction - Techniques Guide

## Data Understanding
**Reference notebooks for data characteristics:**
- `exploration/eda.ipynb` - Contains full EDA: feature distributions, missing values, target distribution, survival patterns by Sex/Pclass

**Key Data Characteristics:**
- Binary classification problem (Survived: 0/1)
- Metric: Accuracy
- Small dataset: 891 training samples, 418 test samples
- Missing values: Age (~20%), Cabin (~77%), Embarked (2 values)
- Strong predictors: Sex (74% female vs 19% male survival), Pclass (1st=63%, 3rd=24%)

## Feature Engineering (CRITICAL for this problem)
Feature engineering is the most important factor - can lift accuracy from ~72% to ~78%+.

**Essential Features to Create:**
1. **Title Extraction** - Parse Name field for titles (Mr, Mrs, Miss, Master, Dr, etc.)
   - Map rare titles to "Rare" category
   - Titles are strong survival predictors (Master = young boys, Miss = unmarried women)

2. **Family Features**
   - FamilySize = SibSp + Parch + 1
   - IsAlone = 1 if FamilySize == 1, else 0
   - Small families (2-4) have higher survival than singles or large families

3. **Cabin Features**
   - HasCabin = 1 if Cabin is not null, else 0
   - Deck = First letter of Cabin (A, B, C, D, E, F, G)
   - Having a cabin indicates higher class/survival

4. **Age Features**
   - Age binning: Child (<12), Teen (12-18), Adult (19-60), Senior (>60)
   - Impute missing ages using median by Title/Pclass/Sex groups

5. **Fare Features**
   - FarePerPerson = Fare / FamilySize
   - FareBin = Quantile-based fare categories
   - Log transform Fare to reduce skewness

6. **Ticket Features**
   - Extract ticket prefix (alphabetic part)
   - Can capture travel class nuances

## Missing Value Handling
- **Age**: Impute with median grouped by Title, Pclass, and Sex
- **Cabin**: Create HasCabin binary feature, extract Deck letter, fill missing with 'U'
- **Embarked**: Fill with mode ('S' - Southampton)
- **Fare** (test set): Fill with median

## Models
For this binary classification problem, top solutions use:

**Single Models:**
1. **Random Forest** - Robust single learner, ~84% accuracy on holdout
2. **SVM (Support Vector Machine)** - Highest F1 score (~80%)
3. **XGBoost/LightGBM** - Gradient boosting, core of top pipelines
4. **Logistic Regression** - Good baseline, interpretable

**Ensemble Strategies (KEY for top scores):**
- **Voting Ensemble** - Combine LR, RF, XGBoost, SVM predictions
- **Stacking** - Use predictions from base models as features for meta-learner
- Ensemble of Logistic Regression + XGBoost achieved top 5% leaderboard
- Stacked ensembles push scores into top 10%

## Preprocessing
- One-hot encode categorical features (Sex, Embarked, Title, Deck)
- Label encoding can work for tree models
- Standard scaling for SVM and neural networks
- Log transform skewed features (Fare)

## Validation Strategy
- Stratified K-fold cross-validation (k=5)
- Use cross-validation to tune hyperparameters
- GridSearchCV for hyperparameter tuning

## Hyperparameter Tuning
**Random Forest:**
- n_estimators: 100-200
- max_depth: 5-15
- min_samples_split: 2-5

**XGBoost:**
- learning_rate: 0.01-0.1
- max_depth: 3-7
- n_estimators: 100-300

**SVM:**
- C: 0.1-10
- kernel: 'rbf' or 'linear'
- gamma: 'scale' or 'auto'

## Key Insights from Top Solutions
1. Feature engineering matters more than model complexity
2. Title extraction from Name is one of the most predictive features
3. Family size features capture group dynamics
4. Ensemble methods consistently outperform single models
5. Cross-validation is essential for reliable model selection
