{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e8e8da",
   "metadata": {},
   "source": [
    "# Baseline Model - Titanic Survival Prediction\n",
    "\n",
    "This baseline implements:\n",
    "- Feature engineering: Title, FamilySize, IsAlone, Deck, HasCabin, AgeBin, FareBin\n",
    "- Age imputation using median by Pclass/Sex/Title\n",
    "- XGBoost with 5-fold Stratified CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e54fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Function\n",
    "def engineer_features(df, is_train=True):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Title extraction from Name\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Group rare titles\n",
    "    title_mapping = {\n",
    "        'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "        'Lady': 'Rare', 'Countess': 'Rare', 'Capt': 'Rare', 'Col': 'Rare',\n",
    "        'Don': 'Rare', 'Dr': 'Rare', 'Major': 'Rare', 'Rev': 'Rare', \n",
    "        'Sir': 'Rare', 'Jonkheer': 'Rare', 'Dona': 'Rare'\n",
    "    }\n",
    "    df['Title'] = df['Title'].replace(title_mapping)\n",
    "    \n",
    "    # 2. Family features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 3. Deck from Cabin\n",
    "    df['Deck'] = df['Cabin'].str[0].fillna('U')  # U for Unknown\n",
    "    df['HasCabin'] = df['Cabin'].notna().astype(int)\n",
    "    \n",
    "    # 4. Sex encoding\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    \n",
    "    # 5. Embarked - fill missing with mode 'S'\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    \n",
    "    # 6. Fare - fill missing with median by Pclass\n",
    "    if df['Fare'].isna().any():\n",
    "        for pclass in [1, 2, 3]:\n",
    "            median_fare = df[df['Pclass'] == pclass]['Fare'].median()\n",
    "            df.loc[(df['Fare'].isna()) & (df['Pclass'] == pclass), 'Fare'] = median_fare\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6636e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "train_fe = engineer_features(train, is_train=True)\n",
    "test_fe = engineer_features(test, is_train=False)\n",
    "\n",
    "print(\"Title distribution:\")\n",
    "print(train_fe['Title'].value_counts())\n",
    "print(\"\\nDeck distribution:\")\n",
    "print(train_fe['Deck'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ffc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age imputation using median by Pclass/Sex/Title\n",
    "def impute_age(train_df, test_df):\n",
    "    combined = pd.concat([train_df, test_df], ignore_index=True)\n",
    "    \n",
    "    # Calculate median age for each group\n",
    "    age_medians = combined.groupby(['Pclass', 'Sex', 'Title'])['Age'].median()\n",
    "    \n",
    "    def fill_age(row):\n",
    "        if pd.isna(row['Age']):\n",
    "            try:\n",
    "                return age_medians[row['Pclass'], row['Sex'], row['Title']]\n",
    "            except KeyError:\n",
    "                # Fallback to Pclass/Sex median\n",
    "                return combined[(combined['Pclass'] == row['Pclass']) & \n",
    "                               (combined['Sex'] == row['Sex'])]['Age'].median()\n",
    "        return row['Age']\n",
    "    \n",
    "    train_df['Age'] = train_df.apply(fill_age, axis=1)\n",
    "    test_df['Age'] = test_df.apply(fill_age, axis=1)\n",
    "    \n",
    "    # Final fallback for any remaining NaN\n",
    "    overall_median = combined['Age'].median()\n",
    "    train_df['Age'] = train_df['Age'].fillna(overall_median)\n",
    "    test_df['Age'] = test_df['Age'].fillna(overall_median)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_fe, test_fe = impute_age(train_fe, test_fe)\n",
    "print(f\"Age missing in train: {train_fe['Age'].isna().sum()}\")\n",
    "print(f\"Age missing in test: {test_fe['Age'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb2513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Age and Fare bins\n",
    "def create_bins(train_df, test_df):\n",
    "    # AgeBin - 5 bins\n",
    "    train_df['AgeBin'] = pd.cut(train_df['Age'], bins=5, labels=[0, 1, 2, 3, 4])\n",
    "    test_df['AgeBin'] = pd.cut(test_df['Age'], bins=5, labels=[0, 1, 2, 3, 4])\n",
    "    \n",
    "    # FareBin - 4 quantile bins (handle edge cases)\n",
    "    train_df['FareBin'] = pd.qcut(train_df['Fare'], q=4, labels=[0, 1, 2, 3], duplicates='drop')\n",
    "    \n",
    "    # For test, use same bin edges from train\n",
    "    fare_bins = pd.qcut(train_df['Fare'], q=4, retbins=True, duplicates='drop')[1]\n",
    "    test_df['FareBin'] = pd.cut(test_df['Fare'], bins=fare_bins, labels=[0, 1, 2, 3], include_lowest=True)\n",
    "    \n",
    "    # Fill any NaN in bins\n",
    "    train_df['AgeBin'] = train_df['AgeBin'].astype(float).fillna(2).astype(int)\n",
    "    test_df['AgeBin'] = test_df['AgeBin'].astype(float).fillna(2).astype(int)\n",
    "    train_df['FareBin'] = train_df['FareBin'].astype(float).fillna(1).astype(int)\n",
    "    test_df['FareBin'] = test_df['FareBin'].astype(float).fillna(1).astype(int)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_fe, test_fe = create_bins(train_fe, test_fe)\n",
    "print(\"AgeBin distribution:\")\n",
    "print(train_fe['AgeBin'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e28505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "def encode_features(train_df, test_df):\n",
    "    # Label encode Title, Embarked, Deck\n",
    "    for col in ['Title', 'Embarked', 'Deck']:\n",
    "        le = LabelEncoder()\n",
    "        combined = pd.concat([train_df[col], test_df[col]])\n",
    "        le.fit(combined)\n",
    "        train_df[col + '_Code'] = le.transform(train_df[col])\n",
    "        test_df[col + '_Code'] = le.transform(test_df[col])\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_fe, test_fe = encode_features(train_fe, test_fe)\n",
    "print(\"Encoded features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "feature_cols = [\n",
    "    'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
    "    'FamilySize', 'IsAlone', 'HasCabin',\n",
    "    'Title_Code', 'Embarked_Code', 'Deck_Code',\n",
    "    'AgeBin', 'FareBin'\n",
    "]\n",
    "\n",
    "X = train_fe[feature_cols].values\n",
    "y = train_fe['Survived'].values\n",
    "X_test = test_fe[feature_cols].values\n",
    "\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d625b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Stratified Cross-Validation with XGBoost\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # XGBoost model\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    val_pred = (val_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    oof_preds[val_idx] = val_pred_proba\n",
    "    test_preds += model.predict_proba(X_test)[:, 1] / 5\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    fold_acc = (val_pred == y_val).mean()\n",
    "    fold_scores.append(fold_acc)\n",
    "    print(f\"Fold {fold+1}: Accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "mean_acc = np.mean(fold_scores)\n",
    "std_acc = np.std(fold_scores)\n",
    "print(f\"\\nCV Accuracy: {mean_acc:.4f} Â± {std_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bfcf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importance = model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "for i in sorted_idx[:10]:\n",
    "    print(f\"  {feature_cols[i]}: {feature_importance[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b94783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "test_pred_binary = (test_preds > 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': test_pred_binary\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} predictions\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSurvival rate in predictions: {test_pred_binary.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
