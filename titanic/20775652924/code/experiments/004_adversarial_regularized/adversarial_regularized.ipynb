{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e527f881",
   "metadata": {},
   "source": [
    "# Adversarial Validation + Regularized Ensemble\n",
    "\n",
    "**Goal:** Address the CV-LB gap (+0.0645) through:\n",
    "1. Adversarial validation to identify distribution shift\n",
    "2. Stronger regularization in base models\n",
    "3. Feature selection to remove noisy features\n",
    "\n",
    "**Current best:** Voting Ensemble CV 0.8372, LB 0.7727\n",
    "**Target:** Reduce CV-LB gap, improve generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              ExtraTreesClassifier, AdaBoostClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000de668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering (same as voting ensemble)\n",
    "def extract_title(name):\n",
    "    title_search = re.search(r' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "def process_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Title extraction\n",
    "    df['Title'] = df['Name'].apply(extract_title)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', \n",
    "                                        'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # Family features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    df['FamilySize_Bin'] = pd.cut(df['FamilySize'], bins=[0, 1, 4, 11], labels=[0, 1, 2]).astype(int)\n",
    "    \n",
    "    # Cabin features\n",
    "    df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "    df['Deck'] = df['Cabin'].apply(lambda x: x[0] if pd.notna(x) else 'U')\n",
    "    \n",
    "    # Embarked - fill missing with mode\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    \n",
    "    # Fare - fill missing with median by Pclass\n",
    "    if df['Fare'].isna().any():\n",
    "        df['Fare'] = df.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_processed = process_features(train)\n",
    "test_processed = process_features(test)\n",
    "\n",
    "print(\"Features processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b98560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age imputation\n",
    "def impute_age(train_df, test_df):\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    age_medians = train_df.groupby(['Pclass', 'Sex', 'Title'])['Age'].median()\n",
    "    \n",
    "    def get_median_age(row, medians, fallback_median):\n",
    "        if pd.isna(row['Age']):\n",
    "            try:\n",
    "                return medians.loc[(row['Pclass'], row['Sex'], row['Title'])]\n",
    "            except KeyError:\n",
    "                return fallback_median\n",
    "        return row['Age']\n",
    "    \n",
    "    fallback = train_df['Age'].median()\n",
    "    train_df['Age'] = train_df.apply(lambda x: get_median_age(x, age_medians, fallback), axis=1)\n",
    "    test_df['Age'] = test_df.apply(lambda x: get_median_age(x, age_medians, fallback), axis=1)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_processed, test_processed = impute_age(train_processed, test_processed)\n",
    "\n",
    "# Age_Bin feature\n",
    "def add_age_bin(df):\n",
    "    df = df.copy()\n",
    "    df['Age_Bin'] = pd.cut(df['Age'], bins=[0, 16, 32, 48, 100], labels=[0, 1, 2, 3]).astype(int)\n",
    "    return df\n",
    "\n",
    "train_processed = add_age_bin(train_processed)\n",
    "test_processed = add_age_bin(test_processed)\n",
    "\n",
    "print(f\"Age imputed. Missing: Train={train_processed['Age'].isna().sum()}, Test={test_processed['Age'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3aa650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "def encode_features(train_df, test_df):\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    train_df['Sex'] = train_df['Sex'].map({'female': 0, 'male': 1})\n",
    "    test_df['Sex'] = test_df['Sex'].map({'female': 0, 'male': 1})\n",
    "    \n",
    "    embarked_map = {'S': 0, 'C': 1, 'Q': 2}\n",
    "    train_df['Embarked'] = train_df['Embarked'].map(embarked_map)\n",
    "    test_df['Embarked'] = test_df['Embarked'].map(embarked_map)\n",
    "    \n",
    "    title_map = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}\n",
    "    train_df['Title'] = train_df['Title'].map(title_map)\n",
    "    test_df['Title'] = test_df['Title'].map(title_map)\n",
    "    \n",
    "    deck_map = {'U': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'T': 8}\n",
    "    train_df['Deck'] = train_df['Deck'].map(deck_map)\n",
    "    test_df['Deck'] = test_df['Deck'].map(deck_map)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_encoded, test_encoded = encode_features(train_processed, test_processed)\n",
    "\n",
    "# Original feature set (same as voting ensemble exp_001)\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', \n",
    "            'Title', 'FamilySize', 'IsAlone', 'Has_Cabin', \n",
    "            'Deck', 'FamilySize_Bin', 'Age_Bin']\n",
    "\n",
    "X_train = train_encoded[features].values\n",
    "y_train = train_encoded['Survived'].values\n",
    "X_test = test_encoded[features].values\n",
    "\n",
    "print(f\"Feature matrix: Train {X_train.shape}, Test {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADVERSARIAL VALIDATION: Can we distinguish train from test?\n",
    "print(\"=\"*60)\n",
    "print(\"ADVERSARIAL VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Combine train and test\n",
    "X_combined = np.vstack([X_train, X_test])\n",
    "y_adversarial = np.array([0]*len(X_train) + [1]*len(X_test))  # 0=train, 1=test\n",
    "\n",
    "# Train classifier to distinguish train vs test\n",
    "adv_clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "adv_scores = cross_val_score(adv_clf, X_combined, y_adversarial, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(f\"\\nAdversarial AUC: {np.mean(adv_scores):.4f} (+/- {np.std(adv_scores):.4f})\")\n",
    "print(f\"  - AUC = 0.5 means no distribution shift (ideal)\")\n",
    "print(f\"  - AUC > 0.6 means significant shift (problematic)\")\n",
    "\n",
    "if np.mean(adv_scores) > 0.55:\n",
    "    print(f\"\\n⚠️ Distribution shift detected! AUC = {np.mean(adv_scores):.4f}\")\n",
    "else:\n",
    "    print(f\"\\n✓ Minimal distribution shift. AUC = {np.mean(adv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317c58da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for adversarial classification\n",
    "adv_clf.fit(X_combined, y_adversarial)\n",
    "\n",
    "adv_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': adv_clf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeatures that distinguish train from test (higher = more shift):\")\n",
    "print(adv_importance.to_string(index=False))\n",
    "\n",
    "# Identify problematic features (high importance in adversarial model)\n",
    "problematic_features = adv_importance[adv_importance['importance'] > 0.10]['feature'].tolist()\n",
    "print(f\"\\nProblematic features (importance > 0.10): {problematic_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROACH 1: Regularized Voting Ensemble (stronger regularization)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"APPROACH 1: REGULARIZED VOTING ENSEMBLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Stronger regularization than exp_001\n",
    "models_regularized = [\n",
    "    ('lr', LogisticRegression(C=0.01, max_iter=1000, random_state=42)),  # C=0.01 (was 0.1)\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=4, min_samples_leaf=8, random_state=42)),  # depth=4 (was 6)\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=50, max_depth=2, learning_rate=0.1, random_state=42)),  # depth=2 (was 3)\n",
    "    ('et', ExtraTreesClassifier(n_estimators=100, max_depth=4, min_samples_leaf=8, random_state=42)),  # depth=4 (was 6)\n",
    "    ('ada', AdaBoostClassifier(n_estimators=50, learning_rate=0.3, random_state=42)),  # reduced\n",
    "    ('svc', SVC(kernel='rbf', C=0.5, probability=True, random_state=42)),  # C=0.5 (was 1.0)\n",
    "    ('xgb', XGBClassifier(n_estimators=50, max_depth=2, learning_rate=0.1, \n",
    "                          reg_alpha=1.0, reg_lambda=2.0,  # Added L1/L2 regularization\n",
    "                          use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "]\n",
    "\n",
    "print(\"Models with stronger regularization:\")\n",
    "for name, model in models_regularized:\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946425a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold CV for regularized ensemble\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores_reg = []\n",
    "oof_predictions_reg = np.zeros(len(X_train))\n",
    "test_predictions_reg = np.zeros(len(X_test))\n",
    "\n",
    "individual_scores_reg = {name: [] for name, _ in models_regularized}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train, y_train)):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # Scale for SVC and LR\n",
    "    scaler = StandardScaler()\n",
    "    X_tr_scaled = scaler.fit_transform(X_tr)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    fold_probs = np.zeros((len(X_val), 2))\n",
    "    test_fold_probs = np.zeros((len(X_test), 2))\n",
    "    \n",
    "    for name, model in models_regularized:\n",
    "        from sklearn.base import clone\n",
    "        m = clone(model)\n",
    "        \n",
    "        if name in ['lr', 'svc']:\n",
    "            m.fit(X_tr_scaled, y_tr)\n",
    "            val_prob = m.predict_proba(X_val_scaled)\n",
    "            test_prob = m.predict_proba(X_test_scaled)\n",
    "            val_pred = m.predict(X_val_scaled)\n",
    "        else:\n",
    "            m.fit(X_tr, y_tr)\n",
    "            val_prob = m.predict_proba(X_val)\n",
    "            test_prob = m.predict_proba(X_test)\n",
    "            val_pred = m.predict(X_val)\n",
    "        \n",
    "        fold_probs += val_prob\n",
    "        test_fold_probs += test_prob\n",
    "        individual_scores_reg[name].append(accuracy_score(y_val, val_pred))\n",
    "    \n",
    "    fold_probs /= len(models_regularized)\n",
    "    test_fold_probs /= len(models_regularized)\n",
    "    \n",
    "    val_pred_ensemble = (fold_probs[:, 1] >= 0.5).astype(int)\n",
    "    oof_predictions_reg[val_idx] = val_pred_ensemble\n",
    "    test_predictions_reg += test_fold_probs[:, 1] / kfold.n_splits\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, val_pred_ensemble)\n",
    "    cv_scores_reg.append(fold_acc)\n",
    "    print(f\"Fold {fold+1}: Accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Regularized Ensemble CV: {np.mean(cv_scores_reg):.4f} (+/- {np.std(cv_scores_reg):.4f})\")\n",
    "print(f\"Previous Voting Ensemble: 0.8372 (+/- 0.0239)\")\n",
    "print(f\"Change: {np.mean(cv_scores_reg) - 0.8372:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0415c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual model performance\n",
    "print(\"\\nIndividual Model Performance (Regularized):\")\n",
    "print(\"=\"*50)\n",
    "for name, scores in individual_scores_reg.items():\n",
    "    print(f\"{name:5s}: {np.mean(scores):.4f} (+/- {np.std(scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROACH 2: Feature Selection - Remove noisy/redundant features\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"APPROACH 2: FEATURE SELECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Remove features identified as problematic or redundant:\n",
    "# - IsAlone (redundant with FamilySize)\n",
    "# - Parch (redundant with FamilySize)\n",
    "# - Deck (77% unknown, may add noise)\n",
    "# - Features with high adversarial importance (cause distribution shift)\n",
    "\n",
    "features_reduced = ['Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Embarked', \n",
    "                    'Title', 'FamilySize', 'Has_Cabin', 'FamilySize_Bin', 'Age_Bin']\n",
    "# Removed: IsAlone, Parch, Deck\n",
    "\n",
    "print(f\"Original features: {len(features)}\")\n",
    "print(f\"Reduced features: {len(features_reduced)}\")\n",
    "print(f\"Removed: IsAlone, Parch, Deck\")\n",
    "\n",
    "X_train_reduced = train_encoded[features_reduced].values\n",
    "X_test_reduced = test_encoded[features_reduced].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685b5af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV with reduced features + regularized models\n",
    "cv_scores_reduced = []\n",
    "oof_predictions_reduced = np.zeros(len(X_train_reduced))\n",
    "test_predictions_reduced = np.zeros(len(X_test_reduced))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_reduced, y_train)):\n",
    "    X_tr, X_val = X_train_reduced[train_idx], X_train_reduced[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_tr_scaled = scaler.fit_transform(X_tr)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test_reduced)\n",
    "    \n",
    "    fold_probs = np.zeros((len(X_val), 2))\n",
    "    test_fold_probs = np.zeros((len(X_test_reduced), 2))\n",
    "    \n",
    "    for name, model in models_regularized:\n",
    "        from sklearn.base import clone\n",
    "        m = clone(model)\n",
    "        \n",
    "        if name in ['lr', 'svc']:\n",
    "            m.fit(X_tr_scaled, y_tr)\n",
    "            val_prob = m.predict_proba(X_val_scaled)\n",
    "            test_prob = m.predict_proba(X_test_scaled)\n",
    "        else:\n",
    "            m.fit(X_tr, y_tr)\n",
    "            val_prob = m.predict_proba(X_val)\n",
    "            test_prob = m.predict_proba(X_test_reduced)\n",
    "        \n",
    "        fold_probs += val_prob\n",
    "        test_fold_probs += test_prob\n",
    "    \n",
    "    fold_probs /= len(models_regularized)\n",
    "    test_fold_probs /= len(models_regularized)\n",
    "    \n",
    "    val_pred_ensemble = (fold_probs[:, 1] >= 0.5).astype(int)\n",
    "    oof_predictions_reduced[val_idx] = val_pred_ensemble\n",
    "    test_predictions_reduced += test_fold_probs[:, 1] / kfold.n_splits\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, val_pred_ensemble)\n",
    "    cv_scores_reduced.append(fold_acc)\n",
    "\n",
    "print(f\"Reduced Features + Regularized CV: {np.mean(cv_scores_reduced):.4f} (+/- {np.std(cv_scores_reduced):.4f})\")\n",
    "print(f\"Regularized (all features) CV:     {np.mean(cv_scores_reg):.4f} (+/- {np.std(cv_scores_reg):.4f})\")\n",
    "print(f\"Original Voting Ensemble CV:       0.8372 (+/- 0.0239)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df2127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and choose best approach\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = {\n",
    "    'Original Voting (exp_001)': (0.8372, 0.0239),\n",
    "    'Regularized (all features)': (np.mean(cv_scores_reg), np.std(cv_scores_reg)),\n",
    "    'Regularized (reduced features)': (np.mean(cv_scores_reduced), np.std(cv_scores_reduced))\n",
    "}\n",
    "\n",
    "print(\"\\nCV Scores:\")\n",
    "for name, (mean, std) in results.items():\n",
    "    print(f\"  {name}: {mean:.4f} (+/- {std:.4f})\")\n",
    "\n",
    "# Choose best based on CV score\n",
    "best_name = max(results.keys(), key=lambda x: results[x][0])\n",
    "best_cv, best_std = results[best_name]\n",
    "\n",
    "print(f\"\\nBest approach: {best_name}\")\n",
    "print(f\"Best CV: {best_cv:.4f} (+/- {best_std:.4f})\")\n",
    "\n",
    "# Expected LB using calibration\n",
    "expected_lb = 2.55 * best_cv - 1.37\n",
    "print(f\"\\nExpected LB (using calibration): {expected_lb:.4f}\")\n",
    "print(f\"Previous best LB: 0.7727\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f30bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission using best approach\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING SUBMISSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use regularized ensemble with all features (best CV)\n",
    "if 'Regularized (all features)' in best_name or np.mean(cv_scores_reg) >= np.mean(cv_scores_reduced):\n",
    "    test_pred_binary = (test_predictions_reg >= 0.5).astype(int)\n",
    "    print(\"Using: Regularized ensemble with all features\")\n",
    "else:\n",
    "    test_pred_binary = (test_predictions_reduced >= 0.5).astype(int)\n",
    "    print(\"Using: Regularized ensemble with reduced features\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': test_pred_binary\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"\\nSubmission saved to /home/submission/submission.csv\")\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(submission['Survived'].value_counts())\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Original Voting: 255 died, 163 survived\")\n",
    "print(f\"  This model:      {(test_pred_binary == 0).sum()} died, {(test_pred_binary == 1).sum()} survived\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
