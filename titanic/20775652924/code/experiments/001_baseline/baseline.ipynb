{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a95852f",
   "metadata": {},
   "source": [
    "# Baseline Model - XGBoost with Feature Engineering\n",
    "\n",
    "Following the strategy:\n",
    "1. Title extraction from Name\n",
    "2. FamilySize and IsAlone features\n",
    "3. Has_Cabin feature\n",
    "4. Age imputation using median by Pclass, Sex, Title\n",
    "5. XGBoost with 10-fold Stratified CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea5e3a02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T07:19:14.164463Z",
     "iopub.status.busy": "2026-01-07T07:19:14.163853Z",
     "iopub.status.idle": "2026-01-07T07:19:15.209060Z",
     "shell.execute_reply": "2026-01-07T07:19:15.208469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Target distribution:\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11614db8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T07:19:15.211182Z",
     "iopub.status.busy": "2026-01-07T07:19:15.210955Z",
     "iopub.status.idle": "2026-01-07T07:19:15.236252Z",
     "shell.execute_reply": "2026-01-07T07:19:15.235656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title distribution:\n",
      "Title\n",
      "Mr        517\n",
      "Miss      185\n",
      "Mrs       126\n",
      "Master     40\n",
      "Rare       23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def extract_title(name):\n",
    "    \"\"\"Extract title from name using regex\"\"\"\n",
    "    import re\n",
    "    title_search = re.search(r' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "def process_features(df, is_train=True, age_medians=None):\n",
    "    \"\"\"Process features for train/test data\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Title extraction\n",
    "    df['Title'] = df['Name'].apply(extract_title)\n",
    "    \n",
    "    # Group rare titles\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', \n",
    "                                        'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # 2. Family features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 3. Has_Cabin feature\n",
    "    df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "    \n",
    "    # 4. Embarked - fill missing with mode\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    \n",
    "    # 5. Fare - fill missing with median by Pclass\n",
    "    if df['Fare'].isna().any():\n",
    "        df['Fare'] = df.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process train and test\n",
    "train_processed = process_features(train, is_train=True)\n",
    "test_processed = process_features(test, is_train=False)\n",
    "\n",
    "print(\"Title distribution:\")\n",
    "print(train_processed['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12eea5f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T07:19:15.238435Z",
     "iopub.status.busy": "2026-01-07T07:19:15.237758Z",
     "iopub.status.idle": "2026-01-07T07:19:15.269597Z",
     "shell.execute_reply": "2026-01-07T07:19:15.269032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation:\n",
      "Train Age missing: 0\n",
      "Test Age missing: 0\n"
     ]
    }
   ],
   "source": [
    "# Age imputation using median by Pclass, Sex, Title\n",
    "# Calculate medians from training data only\n",
    "def impute_age(train_df, test_df):\n",
    "    \"\"\"Impute age using median by Pclass, Sex, Title\"\"\"\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # Calculate medians from training data\n",
    "    age_medians = train_df.groupby(['Pclass', 'Sex', 'Title'])['Age'].median()\n",
    "    \n",
    "    # Function to get median age\n",
    "    def get_median_age(row, medians):\n",
    "        if pd.isna(row['Age']):\n",
    "            try:\n",
    "                return medians.loc[(row['Pclass'], row['Sex'], row['Title'])]\n",
    "            except KeyError:\n",
    "                # Fallback to overall median\n",
    "                return train_df['Age'].median()\n",
    "        return row['Age']\n",
    "    \n",
    "    train_df['Age'] = train_df.apply(lambda x: get_median_age(x, age_medians), axis=1)\n",
    "    test_df['Age'] = test_df.apply(lambda x: get_median_age(x, age_medians), axis=1)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_processed, test_processed = impute_age(train_processed, test_processed)\n",
    "\n",
    "print(f\"Missing values after imputation:\")\n",
    "print(f\"Train Age missing: {train_processed['Age'].isna().sum()}\")\n",
    "print(f\"Test Age missing: {test_processed['Age'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a728bdf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T07:19:15.271307Z",
     "iopub.status.busy": "2026-01-07T07:19:15.271098Z",
     "iopub.status.idle": "2026-01-07T07:19:15.283816Z",
     "shell.execute_reply": "2026-01-07T07:19:15.283217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (891, 11)\n",
      "Test matrix shape: (418, 11)\n",
      "\n",
      "Features: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize', 'IsAlone', 'Has_Cabin']\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features\n",
    "def encode_features(train_df, test_df):\n",
    "    \"\"\"Encode categorical features\"\"\"\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # Sex encoding\n",
    "    train_df['Sex'] = train_df['Sex'].map({'female': 0, 'male': 1})\n",
    "    test_df['Sex'] = test_df['Sex'].map({'female': 0, 'male': 1})\n",
    "    \n",
    "    # Embarked encoding\n",
    "    embarked_map = {'S': 0, 'C': 1, 'Q': 2}\n",
    "    train_df['Embarked'] = train_df['Embarked'].map(embarked_map)\n",
    "    test_df['Embarked'] = test_df['Embarked'].map(embarked_map)\n",
    "    \n",
    "    # Title encoding\n",
    "    title_map = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}\n",
    "    train_df['Title'] = train_df['Title'].map(title_map)\n",
    "    test_df['Title'] = test_df['Title'].map(title_map)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_encoded, test_encoded = encode_features(train_processed, test_processed)\n",
    "\n",
    "# Select features for modeling\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', \n",
    "            'Title', 'FamilySize', 'IsAlone', 'Has_Cabin']\n",
    "\n",
    "X = train_encoded[features].values\n",
    "y = train_encoded['Survived'].values\n",
    "X_test = test_encoded[features].values\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Test matrix shape: {X_test.shape}\")\n",
    "print(f\"\\nFeatures: {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7dc9a84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T07:19:15.285591Z",
     "iopub.status.busy": "2026-01-07T07:19:15.285351Z",
     "iopub.status.idle": "2026-01-07T07:19:15.919759Z",
     "shell.execute_reply": "2026-01-07T07:19:15.919207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.9000\n",
      "Fold 2: Accuracy = 0.8090\n",
      "Fold 3: Accuracy = 0.8539\n",
      "Fold 4: Accuracy = 0.8764\n",
      "Fold 5: Accuracy = 0.8090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6: Accuracy = 0.7978\n",
      "Fold 7: Accuracy = 0.8315\n",
      "Fold 8: Accuracy = 0.8090\n",
      "Fold 9: Accuracy = 0.8202\n",
      "Fold 10: Accuracy = 0.8090\n",
      "\n",
      "==================================================\n",
      "Mean CV Accuracy: 0.8316 (+/- 0.0324)\n",
      "Overall OOF Accuracy: 0.8316\n"
     ]
    }
   ],
   "source": [
    "# 10-fold Stratified Cross-Validation with XGBoost\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# XGBoost parameters from strategy\n",
    "xgb_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 4,\n",
    "    'n_estimators': 200,\n",
    "    'gamma': 0.9,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'random_state': 42,\n",
    "    'use_label_encoder': False\n",
    "}\n",
    "\n",
    "cv_scores = []\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict(X_val)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Accumulate test predictions\n",
    "    test_predictions += model.predict_proba(X_test)[:, 1] / kfold.n_splits\n",
    "    \n",
    "    # Calculate fold accuracy\n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    cv_scores.append(fold_acc)\n",
    "    print(f\"Fold {fold+1}: Accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Mean CV Accuracy: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")\n",
    "print(f\"Overall OOF Accuracy: {accuracy_score(y, oof_predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0597e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T07:19:15.921988Z",
     "iopub.status.busy": "2026-01-07T07:19:15.921533Z",
     "iopub.status.idle": "2026-01-07T07:19:15.932945Z",
     "shell.execute_reply": "2026-01-07T07:19:15.932256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to /home/submission/submission.csv\n",
      "\n",
      "Submission preview:\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n",
      "5          897         0\n",
      "6          898         0\n",
      "7          899         0\n",
      "8          900         1\n",
      "9          901         0\n",
      "\n",
      "Prediction distribution:\n",
      "Survived\n",
      "0    267\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Generate submission\n",
    "test_pred_binary = (test_predictions >= 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': test_pred_binary\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved to /home/submission/submission.csv\")\n",
    "print(f\"\\nSubmission preview:\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(submission['Survived'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300dc57b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T07:19:15.935218Z",
     "iopub.status.busy": "2026-01-07T07:19:15.934635Z",
     "iopub.status.idle": "2026-01-07T07:19:16.495517Z",
     "shell.execute_reply": "2026-01-07T07:19:16.494816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "       feature  importance\n",
      "1          Sex    0.284793\n",
      "7        Title    0.229216\n",
      "0       Pclass    0.122109\n",
      "8   FamilySize    0.076559\n",
      "10   Has_Cabin    0.063656\n",
      "4        Parch    0.043953\n",
      "3        SibSp    0.043179\n",
      "5         Fare    0.036468\n",
      "9      IsAlone    0.036092\n",
      "2          Age    0.032365\n",
      "6     Embarked    0.031610\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train final model on all data for feature importance\n",
    "final_model = xgb.XGBClassifier(**xgb_params)\n",
    "final_model.fit(X, y, verbose=False)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(importance)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
