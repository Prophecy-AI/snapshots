{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2d2170",
   "metadata": {},
   "source": [
    "# Baseline Random Forest with Feature Engineering\n",
    "\n",
    "This baseline implements:\n",
    "- Title extraction from Name\n",
    "- Family features (FamilySize, IsAlone)\n",
    "- Has_Cabin binary flag\n",
    "- Missing value imputation\n",
    "- 5-fold Stratified CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40fa91e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T07:16:27.419490Z",
     "iopub.status.busy": "2026-01-06T07:16:27.418735Z",
     "iopub.status.idle": "2026-01-06T07:16:28.697695Z",
     "shell.execute_reply": "2026-01-06T07:16:28.696923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Target distribution:\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f'Train shape: {train.shape}')\n",
    "print(f'Test shape: {test.shape}')\n",
    "print(f'\\nTarget distribution:')\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9485af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T07:16:28.700107Z",
     "iopub.status.busy": "2026-01-06T07:16:28.699832Z",
     "iopub.status.idle": "2026-01-06T07:16:28.748888Z",
     "shell.execute_reply": "2026-01-06T07:16:28.748109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete!\n",
      "Train columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title', 'FamilySize', 'IsAlone', 'Has_Cabin', 'Name_length']\n",
      "\n",
      "Missing values in train after FE:\n",
      "Cabin    687\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(df, is_train=True):\n",
    "    \"\"\"Apply feature engineering to dataframe\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Title extraction from Name\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Group rare titles\n",
    "    rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "    df['Title'] = df['Title'].replace(rare_titles, 'Rare')\n",
    "    \n",
    "    # Normalize titles\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # Map to ordinal\n",
    "    title_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}\n",
    "    df['Title'] = df['Title'].map(title_mapping).fillna(0)\n",
    "    \n",
    "    # 2. Family features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 3. Has_Cabin binary flag\n",
    "    df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "    \n",
    "    # 4. Name length\n",
    "    df['Name_length'] = df['Name'].apply(len)\n",
    "    \n",
    "    # 5. Sex encoding\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    \n",
    "    # 6. Embarked encoding\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')  # Fill with mode\n",
    "    df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "    \n",
    "    # 7. Age imputation - fill with median by Pclass and Sex\n",
    "    for pclass in [1, 2, 3]:\n",
    "        for sex in [0, 1]:\n",
    "            mask = (df['Pclass'] == pclass) & (df['Sex'] == sex)\n",
    "            median_age = df.loc[mask, 'Age'].median()\n",
    "            if pd.isna(median_age):\n",
    "                median_age = df['Age'].median()\n",
    "            df.loc[mask & df['Age'].isna(), 'Age'] = median_age\n",
    "    \n",
    "    # Fill any remaining NaN ages with overall median\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "    \n",
    "    # 8. Fare imputation\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_fe = feature_engineering(train, is_train=True)\n",
    "test_fe = feature_engineering(test, is_train=False)\n",
    "\n",
    "print('Feature engineering complete!')\n",
    "print(f'Train columns: {train_fe.columns.tolist()}')\n",
    "print(f'\\nMissing values in train after FE:')\n",
    "print(train_fe.isnull().sum()[train_fe.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affb125e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T07:16:28.751671Z",
     "iopub.status.busy": "2026-01-06T07:16:28.751109Z",
     "iopub.status.idle": "2026-01-06T07:16:28.760377Z",
     "shell.execute_reply": "2026-01-06T07:16:28.759601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (891, 12)\n",
      "y shape: (891,)\n",
      "X_test shape: (418, 12)\n",
      "\n",
      "NaN in X: 0\n",
      "NaN in X_test: 0\n"
     ]
    }
   ],
   "source": [
    "# Select features for modeling\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked',\n",
    "            'Title', 'FamilySize', 'IsAlone', 'Has_Cabin', 'Name_length']\n",
    "\n",
    "X = train_fe[features].values\n",
    "y = train_fe['Survived'].values\n",
    "X_test = test_fe[features].values\n",
    "\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "\n",
    "# Check for any NaN values\n",
    "print(f'\\nNaN in X: {np.isnan(X).sum()}')\n",
    "print(f'NaN in X_test: {np.isnan(X_test).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148b5887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T07:16:28.762713Z",
     "iopub.status.busy": "2026-01-06T07:16:28.762404Z",
     "iopub.status.idle": "2026-01-06T07:16:34.333211Z",
     "shell.execute_reply": "2026-01-06T07:16:34.332529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Stratified Cross-Validation Results:\n",
      "Fold scores: [0.83798883 0.82022472 0.79213483 0.82022472 0.83707865]\n",
      "Mean CV Accuracy: 0.8215 (+/- 0.0166)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with 5-fold Stratified CV\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Stratified K-Fold Cross Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(rf, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print('5-Fold Stratified Cross-Validation Results:')\n",
    "print(f'Fold scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0581e950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T07:16:34.335720Z",
     "iopub.status.busy": "2026-01-06T07:16:34.335207Z",
     "iopub.status.idle": "2026-01-06T07:16:35.499601Z",
     "shell.execute_reply": "2026-01-06T07:16:35.498537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "    feature  importance\n",
      "      Title    0.256882\n",
      "        Sex    0.217659\n",
      "       Fare    0.107770\n",
      "Name_length    0.087179\n",
      "     Pclass    0.085661\n",
      "        Age    0.071725\n",
      " FamilySize    0.056126\n",
      "  Has_Cabin    0.049027\n",
      "      SibSp    0.029582\n",
      "   Embarked    0.017572\n",
      "      Parch    0.013188\n",
      "    IsAlone    0.007628\n"
     ]
    }
   ],
   "source": [
    "# Train on full training data and make predictions\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Feature importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print('Feature Importances:')\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db3dc7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T07:16:35.502875Z",
     "iopub.status.busy": "2026-01-06T07:16:35.502113Z",
     "iopub.status.idle": "2026-01-06T07:16:35.659473Z",
     "shell.execute_reply": "2026-01-06T07:16:35.658525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved with 418 predictions\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n",
      "5          897         0\n",
      "6          898         1\n",
      "7          899         0\n",
      "8          900         1\n",
      "9          901         0\n",
      "\n",
      "Submission also saved to experiment folder\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "test_predictions = rf.predict(X_test)\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f'Submission saved with {len(submission)} predictions')\n",
    "print(submission.head(10))\n",
    "\n",
    "# Also save to experiment folder\n",
    "submission.to_csv('/home/code/experiments/001_baseline/submission.csv', index=False)\n",
    "print('\\nSubmission also saved to experiment folder')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
