{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24d5387",
   "metadata": {},
   "source": [
    "# Titanic Baseline - Comprehensive Feature Engineering\n",
    "\n",
    "Implementing all key features from the strategy:\n",
    "- Title extraction from Name\n",
    "- Family features (FamilySize, IsAlone)\n",
    "- Cabin features (Has_Cabin, Deck)\n",
    "- Age/Fare handling with binning\n",
    "- 10-fold Stratified CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c22e17f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T06:27:20.924801Z",
     "iopub.status.busy": "2026-01-06T06:27:20.923873Z",
     "iopub.status.idle": "2026-01-06T06:27:22.321692Z",
     "shell.execute_reply": "2026-01-06T06:27:22.320922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12), Test shape: (418, 11)\n",
      "Target distribution: {0: 0.6161616161616161, 1: 0.3838383838383838}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "print(f'Train shape: {train.shape}, Test shape: {test.shape}')\n",
    "print(f'Target distribution: {train.Survived.value_counts(normalize=True).to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67b2b5db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T06:27:22.324430Z",
     "iopub.status.busy": "2026-01-06T06:27:22.324142Z",
     "iopub.status.idle": "2026-01-06T06:27:22.371272Z",
     "shell.execute_reply": "2026-01-06T06:27:22.370619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete!\n",
      "Title distribution: {'Mr': 517, 'Miss': 185, 'Mrs': 126, 'Master': 40, 'Rare': 23}\n",
      "FamilySize distribution: {1: 537, 2: 161, 3: 102, 4: 29, 5: 15, 6: 22, 7: 12, 8: 6, 11: 7}\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering Function\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Title extraction from Name (MOST IMPORTANT)\n",
    "    df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Map rare titles and normalize\n",
    "    title_mapping = {\n",
    "        'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "        'Lady': 'Rare', 'Countess': 'Rare', 'Capt': 'Rare', \n",
    "        'Col': 'Rare', 'Don': 'Rare', 'Dr': 'Rare', \n",
    "        'Major': 'Rare', 'Rev': 'Rare', 'Sir': 'Rare', \n",
    "        'Jonkheer': 'Rare', 'Dona': 'Rare'\n",
    "    }\n",
    "    df['Title'] = df['Title'].replace(title_mapping)\n",
    "    \n",
    "    # Keep only common titles\n",
    "    common_titles = ['Mr', 'Miss', 'Mrs', 'Master', 'Rare']\n",
    "    df['Title'] = df['Title'].apply(lambda x: x if x in common_titles else 'Rare')\n",
    "    \n",
    "    # 2. Family Features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # Family size categories\n",
    "    df['FamilySizeCategory'] = pd.cut(df['FamilySize'], \n",
    "                                       bins=[0, 1, 4, 11], \n",
    "                                       labels=['Single', 'Small', 'Large'])\n",
    "    \n",
    "    # 3. Cabin Features\n",
    "    df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "    df['Deck'] = df['Cabin'].str[0].fillna('U')  # U for Unknown\n",
    "    \n",
    "    # 4. Age Handling - Fill missing with median by Pclass and Sex\n",
    "    df['Age'] = df.groupby(['Pclass', 'Sex'])['Age'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    # If still missing, use overall median\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "    \n",
    "    # Age bands\n",
    "    df['AgeBand'] = pd.cut(df['Age'], bins=[0, 16, 32, 48, 64, 100], \n",
    "                           labels=['Child', 'Young', 'Middle', 'Senior', 'Elder'])\n",
    "    \n",
    "    # 5. Fare Handling\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    df['FareBand'] = pd.qcut(df['Fare'], 4, labels=['Low', 'Medium', 'High', 'VeryHigh'], duplicates='drop')\n",
    "    \n",
    "    # 6. Embarked - fill missing with mode\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "    \n",
    "    # 7. Additional features\n",
    "    df['Name_Length'] = df['Name'].apply(len)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_fe = engineer_features(train)\n",
    "test_fe = engineer_features(test)\n",
    "\n",
    "print('Feature engineering complete!')\n",
    "print(f'Title distribution: {train_fe.Title.value_counts().to_dict()}')\n",
    "print(f'FamilySize distribution: {train_fe.FamilySize.value_counts().sort_index().to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc9d9361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T06:27:22.373504Z",
     "iopub.status.busy": "2026-01-06T06:27:22.373276Z",
     "iopub.status.idle": "2026-01-06T06:27:22.396100Z",
     "shell.execute_reply": "2026-01-06T06:27:22.395482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (891, 16)\n",
      "Features: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize', 'IsAlone', 'Has_Cabin', 'Deck', 'AgeBand', 'FareBand', 'FamilySizeCategory', 'Name_Length']\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features\n",
    "def encode_features(train_df, test_df):\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # Categorical columns to encode\n",
    "    cat_cols = ['Sex', 'Embarked', 'Title', 'Deck', 'AgeBand', 'FareBand', 'FamilySizeCategory']\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        # Fit on combined data to handle unseen categories\n",
    "        combined = pd.concat([train_df[col], test_df[col]], axis=0).astype(str)\n",
    "        le.fit(combined)\n",
    "        train_df[col] = le.transform(train_df[col].astype(str))\n",
    "        test_df[col] = le.transform(test_df[col].astype(str))\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_encoded, test_encoded = encode_features(train_fe, test_fe)\n",
    "\n",
    "# Select features for modeling\n",
    "feature_cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked',\n",
    "                'Title', 'FamilySize', 'IsAlone', 'Has_Cabin', 'Deck',\n",
    "                'AgeBand', 'FareBand', 'FamilySizeCategory', 'Name_Length']\n",
    "\n",
    "X = train_encoded[feature_cols].values\n",
    "y = train_encoded['Survived'].values\n",
    "X_test = test_encoded[feature_cols].values\n",
    "\n",
    "print(f'Feature matrix shape: {X.shape}')\n",
    "print(f'Features: {feature_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b3615d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T06:27:22.398357Z",
     "iopub.status.busy": "2026-01-06T06:27:22.398137Z",
     "iopub.status.idle": "2026-01-06T06:27:26.766765Z",
     "shell.execute_reply": "2026-01-06T06:27:26.766052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest CV Accuracy: 0.8271 ± 0.0354\n",
      "Fold scores: ['0.8778', '0.8427', '0.8427', '0.8539', '0.7865', '0.7865', '0.8764', '0.7753', '0.8090', '0.8202']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GradientBoosting CV Accuracy: 0.8248 ± 0.0301\n",
      "Fold scores: ['0.8889', '0.8202', '0.8427', '0.8539', '0.7978', '0.8090', '0.8315', '0.7753', '0.8202', '0.8090']\n"
     ]
    }
   ],
   "source": [
    "# 10-Fold Stratified Cross-Validation with RandomForest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# RandomForest baseline\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_scores = cross_val_score(rf_model, X, y, cv=skf, scoring='accuracy')\n",
    "print(f'RandomForest CV Accuracy: {rf_scores.mean():.4f} ± {rf_scores.std():.4f}')\n",
    "print(f'Fold scores: {[f\"{s:.4f}\" for s in rf_scores]}')\n",
    "\n",
    "# GradientBoosting for comparison\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_scores = cross_val_score(gb_model, X, y, cv=skf, scoring='accuracy')\n",
    "print(f'\\nGradientBoosting CV Accuracy: {gb_scores.mean():.4f} ± {gb_scores.std():.4f}')\n",
    "print(f'Fold scores: {[f\"{s:.4f}\" for s in gb_scores]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b10c0e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T06:27:26.769132Z",
     "iopub.status.busy": "2026-01-06T06:27:26.768887Z",
     "iopub.status.idle": "2026-01-06T06:27:26.993397Z",
     "shell.execute_reply": "2026-01-06T06:27:26.992369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "           feature  importance\n",
      "               Sex    0.452505\n",
      "            Pclass    0.116744\n",
      "              Fare    0.110161\n",
      "               Age    0.078512\n",
      "       Name_Length    0.056264\n",
      "              Deck    0.052439\n",
      "FamilySizeCategory    0.041883\n",
      "             Title    0.036034\n",
      "        FamilySize    0.027891\n",
      "          Embarked    0.016925\n",
      "             SibSp    0.004094\n",
      "          FareBand    0.002851\n",
      "             Parch    0.001187\n",
      "         Has_Cabin    0.000909\n",
      "           IsAlone    0.000907\n",
      "           AgeBand    0.000692\n"
     ]
    }
   ],
   "source": [
    "# Train final model on full data and make predictions\n",
    "# Using GradientBoosting as it typically performs better\n",
    "final_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "predictions = final_model.predict(X_test)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print('Feature Importance:')\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3dda88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T06:27:26.996173Z",
     "iopub.status.busy": "2026-01-06T06:27:26.995882Z",
     "iopub.status.idle": "2026-01-06T06:27:27.006973Z",
     "shell.execute_reply": "2026-01-06T06:27:27.006057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved with 418 predictions\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         0\n",
      "\n",
      "Prediction distribution: {0: 266, 1: 152}\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f'Submission saved with {len(submission)} predictions')\n",
    "print(submission.head())\n",
    "print(f'\\nPrediction distribution: {submission.Survived.value_counts().to_dict()}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
