{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24d5387",
   "metadata": {},
   "source": [
    "# Titanic Baseline - Comprehensive Feature Engineering\n",
    "\n",
    "Implementing all key features from the strategy:\n",
    "- Title extraction from Name\n",
    "- Family features (FamilySize, IsAlone)\n",
    "- Cabin features (Has_Cabin, Deck)\n",
    "- Age/Fare handling with binning\n",
    "- 10-fold Stratified CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "print(f'Train shape: {train.shape}, Test shape: {test.shape}')\n",
    "print(f'Target distribution: {train.Survived.value_counts(normalize=True).to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b2b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Function\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Title extraction from Name (MOST IMPORTANT)\n",
    "    df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Map rare titles and normalize\n",
    "    title_mapping = {\n",
    "        'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "        'Lady': 'Rare', 'Countess': 'Rare', 'Capt': 'Rare', \n",
    "        'Col': 'Rare', 'Don': 'Rare', 'Dr': 'Rare', \n",
    "        'Major': 'Rare', 'Rev': 'Rare', 'Sir': 'Rare', \n",
    "        'Jonkheer': 'Rare', 'Dona': 'Rare'\n",
    "    }\n",
    "    df['Title'] = df['Title'].replace(title_mapping)\n",
    "    \n",
    "    # Keep only common titles\n",
    "    common_titles = ['Mr', 'Miss', 'Mrs', 'Master', 'Rare']\n",
    "    df['Title'] = df['Title'].apply(lambda x: x if x in common_titles else 'Rare')\n",
    "    \n",
    "    # 2. Family Features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # Family size categories\n",
    "    df['FamilySizeCategory'] = pd.cut(df['FamilySize'], \n",
    "                                       bins=[0, 1, 4, 11], \n",
    "                                       labels=['Single', 'Small', 'Large'])\n",
    "    \n",
    "    # 3. Cabin Features\n",
    "    df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "    df['Deck'] = df['Cabin'].str[0].fillna('U')  # U for Unknown\n",
    "    \n",
    "    # 4. Age Handling - Fill missing with median by Pclass and Sex\n",
    "    df['Age'] = df.groupby(['Pclass', 'Sex'])['Age'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    # If still missing, use overall median\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "    \n",
    "    # Age bands\n",
    "    df['AgeBand'] = pd.cut(df['Age'], bins=[0, 16, 32, 48, 64, 100], \n",
    "                           labels=['Child', 'Young', 'Middle', 'Senior', 'Elder'])\n",
    "    \n",
    "    # 5. Fare Handling\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    df['FareBand'] = pd.qcut(df['Fare'], 4, labels=['Low', 'Medium', 'High', 'VeryHigh'], duplicates='drop')\n",
    "    \n",
    "    # 6. Embarked - fill missing with mode\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "    \n",
    "    # 7. Additional features\n",
    "    df['Name_Length'] = df['Name'].apply(len)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_fe = engineer_features(train)\n",
    "test_fe = engineer_features(test)\n",
    "\n",
    "print('Feature engineering complete!')\n",
    "print(f'Title distribution: {train_fe.Title.value_counts().to_dict()}')\n",
    "print(f'FamilySize distribution: {train_fe.FamilySize.value_counts().sort_index().to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "def encode_features(train_df, test_df):\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # Categorical columns to encode\n",
    "    cat_cols = ['Sex', 'Embarked', 'Title', 'Deck', 'AgeBand', 'FareBand', 'FamilySizeCategory']\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        # Fit on combined data to handle unseen categories\n",
    "        combined = pd.concat([train_df[col], test_df[col]], axis=0).astype(str)\n",
    "        le.fit(combined)\n",
    "        train_df[col] = le.transform(train_df[col].astype(str))\n",
    "        test_df[col] = le.transform(test_df[col].astype(str))\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_encoded, test_encoded = encode_features(train_fe, test_fe)\n",
    "\n",
    "# Select features for modeling\n",
    "feature_cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked',\n",
    "                'Title', 'FamilySize', 'IsAlone', 'Has_Cabin', 'Deck',\n",
    "                'AgeBand', 'FareBand', 'FamilySizeCategory', 'Name_Length']\n",
    "\n",
    "X = train_encoded[feature_cols].values\n",
    "y = train_encoded['Survived'].values\n",
    "X_test = test_encoded[feature_cols].values\n",
    "\n",
    "print(f'Feature matrix shape: {X.shape}')\n",
    "print(f'Features: {feature_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3615d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-Fold Stratified Cross-Validation with RandomForest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# RandomForest baseline\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_scores = cross_val_score(rf_model, X, y, cv=skf, scoring='accuracy')\n",
    "print(f'RandomForest CV Accuracy: {rf_scores.mean():.4f} ± {rf_scores.std():.4f}')\n",
    "print(f'Fold scores: {[f\"{s:.4f}\" for s in rf_scores]}')\n",
    "\n",
    "# GradientBoosting for comparison\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_scores = cross_val_score(gb_model, X, y, cv=skf, scoring='accuracy')\n",
    "print(f'\\nGradientBoosting CV Accuracy: {gb_scores.mean():.4f} ± {gb_scores.std():.4f}')\n",
    "print(f'Fold scores: {[f\"{s:.4f}\" for s in gb_scores]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on full data and make predictions\n",
    "# Using GradientBoosting as it typically performs better\n",
    "final_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "predictions = final_model.predict(X_test)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print('Feature Importance:')\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3dda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f'Submission saved with {len(submission)} predictions')\n",
    "print(submission.head())\n",
    "print(f'\\nPrediction distribution: {submission.Survived.value_counts().to_dict()}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
