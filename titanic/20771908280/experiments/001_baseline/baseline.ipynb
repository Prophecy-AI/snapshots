{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c50f7bb6",
   "metadata": {},
   "source": [
    "# Baseline Model for Titanic Survival Prediction\n",
    "\n",
    "This notebook implements a comprehensive baseline with:\n",
    "- Feature engineering (Title, FamilySize, IsAlone, Has_Cabin)\n",
    "- Proper missing value handling\n",
    "- 5-fold Stratified CV\n",
    "- Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b23a8c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:33.210022Z",
     "iopub.status.busy": "2026-01-07T04:15:33.209396Z",
     "iopub.status.idle": "2026-01-07T04:15:34.254662Z",
     "shell.execute_reply": "2026-01-07T04:15:34.254021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Target distribution:\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622d5d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:34.256860Z",
     "iopub.status.busy": "2026-01-07T04:15:34.256630Z",
     "iopub.status.idle": "2026-01-07T04:15:34.264185Z",
     "shell.execute_reply": "2026-01-07T04:15:34.263600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (1309, 13)\n"
     ]
    }
   ],
   "source": [
    "# Combine train and test for consistent feature engineering\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "test['Survived'] = np.nan\n",
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Combined shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359c7db9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:34.266372Z",
     "iopub.status.busy": "2026-01-07T04:15:34.265870Z",
     "iopub.status.idle": "2026-01-07T04:15:34.279289Z",
     "shell.execute_reply": "2026-01-07T04:15:34.278692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title distribution:\n",
      "Title\n",
      "Mr        757\n",
      "Miss      264\n",
      "Mrs       198\n",
      "Master     61\n",
      "Rare       29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# 1. Extract Title from Name\n",
    "def extract_title(name):\n",
    "    import re\n",
    "    match = re.search(r' ([A-Za-z]+)\\.', name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return 'Unknown'\n",
    "\n",
    "df['Title'] = df['Name'].apply(extract_title)\n",
    "\n",
    "# Group rare titles\n",
    "title_mapping = {\n",
    "    'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "    'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "    'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare', 'Capt': 'Rare',\n",
    "    'Lady': 'Rare', 'Countess': 'Rare', 'Sir': 'Rare', 'Don': 'Rare', 'Dona': 'Rare',\n",
    "    'Jonkheer': 'Rare'\n",
    "}\n",
    "df['Title'] = df['Title'].map(lambda x: title_mapping.get(x, 'Rare'))\n",
    "\n",
    "print(\"Title distribution:\")\n",
    "print(df['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250e68dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:34.281192Z",
     "iopub.status.busy": "2026-01-07T04:15:34.280931Z",
     "iopub.status.idle": "2026-01-07T04:15:34.290252Z",
     "shell.execute_reply": "2026-01-07T04:15:34.289605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FamilySize distribution:\n",
      "FamilySize\n",
      "1     790\n",
      "2     235\n",
      "3     159\n",
      "4      43\n",
      "5      22\n",
      "6      25\n",
      "7      16\n",
      "8       8\n",
      "11     11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. Family Features\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# Family size groups\n",
    "def family_size_group(size):\n",
    "    if size == 1:\n",
    "        return 0  # Alone\n",
    "    elif size <= 4:\n",
    "        return 1  # Small\n",
    "    else:\n",
    "        return 2  # Large\n",
    "\n",
    "df['FamilySizeGroup'] = df['FamilySize'].apply(family_size_group)\n",
    "\n",
    "print(\"FamilySize distribution:\")\n",
    "print(df['FamilySize'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d8ceed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:34.292043Z",
     "iopub.status.busy": "2026-01-07T04:15:34.291790Z",
     "iopub.status.idle": "2026-01-07T04:15:34.297274Z",
     "shell.execute_reply": "2026-01-07T04:15:34.296716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has_Cabin distribution:\n",
      "Has_Cabin\n",
      "0    1014\n",
      "1     295\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. Cabin Features\n",
    "df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "\n",
    "print(f\"Has_Cabin distribution:\")\n",
    "print(df['Has_Cabin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac69380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:34.298944Z",
     "iopub.status.busy": "2026-01-07T04:15:34.298704Z",
     "iopub.status.idle": "2026-01-07T04:15:34.330341Z",
     "shell.execute_reply": "2026-01-07T04:15:34.329734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Age after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# 4. Age Imputation - using median by (Sex, Pclass, Title)\n",
    "# Calculate medians from training data only\n",
    "train_mask = df['is_train'] == 1\n",
    "\n",
    "age_medians = df[train_mask].groupby(['Sex', 'Pclass', 'Title'])['Age'].median()\n",
    "\n",
    "def impute_age(row):\n",
    "    if pd.isna(row['Age']):\n",
    "        try:\n",
    "            return age_medians.loc[(row['Sex'], row['Pclass'], row['Title'])]\n",
    "        except KeyError:\n",
    "            # Fallback to Sex, Pclass median\n",
    "            try:\n",
    "                return df[train_mask].groupby(['Sex', 'Pclass'])['Age'].median().loc[(row['Sex'], row['Pclass'])]\n",
    "            except KeyError:\n",
    "                return df[train_mask]['Age'].median()\n",
    "    return row['Age']\n",
    "\n",
    "df['Age'] = df.apply(impute_age, axis=1)\n",
    "\n",
    "print(f\"Missing Age after imputation: {df['Age'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b54197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:34.332734Z",
     "iopub.status.busy": "2026-01-07T04:15:34.332155Z",
     "iopub.status.idle": "2026-01-07T04:15:34.339033Z",
     "shell.execute_reply": "2026-01-07T04:15:34.338494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgeBin distribution:\n",
      "AgeBin\n",
      "0     102\n",
      "1     179\n",
      "2    1015\n",
      "3      13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 5. Age Binning\n",
    "def age_bin(age):\n",
    "    if age <= 12:\n",
    "        return 0  # Child\n",
    "    elif age <= 19:\n",
    "        return 1  # Teen\n",
    "    elif age <= 64:\n",
    "        return 2  # Adult\n",
    "    else:\n",
    "        return 3  # Senior\n",
    "\n",
    "df['AgeBin'] = df['Age'].apply(age_bin)\n",
    "\n",
    "print(\"AgeBin distribution:\")\n",
    "print(df['AgeBin'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eed6ae4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:34.341091Z",
     "iopub.status.busy": "2026-01-07T04:15:34.340607Z",
     "iopub.status.idle": "2026-01-07T04:15:34.363664Z",
     "shell.execute_reply": "2026-01-07T04:15:34.363073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FareBin distribution:\n",
      "FareBin\n",
      "0    337\n",
      "1    321\n",
      "2    321\n",
      "3    330\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 6. Fare Handling\n",
    "# Fill missing fare with median by Pclass\n",
    "fare_medians = df[train_mask].groupby('Pclass')['Fare'].median()\n",
    "\n",
    "def impute_fare(row):\n",
    "    if pd.isna(row['Fare']):\n",
    "        return fare_medians.loc[row['Pclass']]\n",
    "    return row['Fare']\n",
    "\n",
    "df['Fare'] = df.apply(impute_fare, axis=1)\n",
    "\n",
    "# Fare binning using quantiles from training data\n",
    "fare_bins = df[train_mask]['Fare'].quantile([0, 0.25, 0.5, 0.75, 1.0]).values\n",
    "fare_bins[0] = -0.001  # Handle edge case\n",
    "fare_bins[-1] = df['Fare'].max() + 1\n",
    "\n",
    "df['FareBin'] = pd.cut(df['Fare'], bins=fare_bins, labels=[0, 1, 2, 3]).astype(int)\n",
    "\n",
    "print(\"FareBin distribution:\")\n",
    "print(df['FareBin'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde448e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:34.365765Z",
     "iopub.status.busy": "2026-01-07T04:15:34.365190Z",
     "iopub.status.idle": "2026-01-07T04:15:34.373249Z",
     "shell.execute_reply": "2026-01-07T04:15:34.372625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature encoding complete\n"
     ]
    }
   ],
   "source": [
    "# 7. Embarked - fill with mode\n",
    "df['Embarked'] = df['Embarked'].fillna('S')\n",
    "\n",
    "# Encode categorical features\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "df['Title'] = df['Title'].map({'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5})\n",
    "\n",
    "print(\"\\nFeature encoding complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b75c8c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:34.375484Z",
     "iopub.status.busy": "2026-01-07T04:15:34.374868Z",
     "iopub.status.idle": "2026-01-07T04:15:34.387528Z",
     "shell.execute_reply": "2026-01-07T04:15:34.386797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (891, 12)\n",
      "y shape: (891,)\n",
      "X_test shape: (418, 12)\n"
     ]
    }
   ],
   "source": [
    "# Select features for modeling\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', \n",
    "            'Title', 'FamilySize', 'IsAlone', 'FamilySizeGroup',\n",
    "            'Has_Cabin', 'AgeBin', 'FareBin']\n",
    "\n",
    "# Split back to train and test\n",
    "train_df = df[df['is_train'] == 1].copy()\n",
    "test_df = df[df['is_train'] == 0].copy()\n",
    "\n",
    "X = train_df[features].values\n",
    "y = train_df['Survived'].values\n",
    "X_test = test_df[features].values\n",
    "test_ids = test_df['PassengerId'].values\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bbc40d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:34.389680Z",
     "iopub.status.busy": "2026-01-07T04:15:34.389147Z",
     "iopub.status.idle": "2026-01-07T04:15:36.643439Z",
     "shell.execute_reply": "2026-01-07T04:15:36.642575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.8492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Accuracy = 0.8315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Accuracy = 0.8315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: Accuracy = 0.8315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Accuracy = 0.8371\n",
      "\n",
      "CV Accuracy: 0.8361 ± 0.0069\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold Stratified Cross-Validation with Random Forest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Random Forest with reasonable parameters\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        min_samples_split=4,\n",
    "        min_samples_leaf=2,\n",
    "        criterion='entropy',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validation predictions\n",
    "    val_pred = model.predict(X_val)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Test predictions (average across folds)\n",
    "    test_predictions += model.predict(X_test) / 5\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_acc)\n",
    "    print(f\"Fold {fold+1}: Accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "mean_cv = np.mean(fold_scores)\n",
    "std_cv = np.std(fold_scores)\n",
    "print(f\"\\nCV Accuracy: {mean_cv:.4f} ± {std_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f1922fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:36.646118Z",
     "iopub.status.busy": "2026-01-07T04:15:36.645357Z",
     "iopub.status.idle": "2026-01-07T04:15:36.656470Z",
     "shell.execute_reply": "2026-01-07T04:15:36.655726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved with 418 predictions\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "final_predictions = (test_predictions >= 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_ids.astype(int),\n",
    "    'Survived': final_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} predictions\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1388068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:15:36.658637Z",
     "iopub.status.busy": "2026-01-07T04:15:36.658401Z",
     "iopub.status.idle": "2026-01-07T04:15:38.117899Z",
     "shell.execute_reply": "2026-01-07T04:15:38.117260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "        feature  importance\n",
      "          Title    0.229102\n",
      "            Sex    0.198011\n",
      "           Fare    0.123021\n",
      "            Age    0.096276\n",
      "         Pclass    0.082613\n",
      "     FamilySize    0.061560\n",
      "      Has_Cabin    0.060400\n",
      "FamilySizeGroup    0.054683\n",
      "        FareBin    0.042847\n",
      "         AgeBin    0.025418\n",
      "       Embarked    0.018260\n",
      "        IsAlone    0.007808\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importance = model.feature_importances_\n",
    "feature_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
