{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "449488e3",
   "metadata": {},
   "source": [
    "# Experiment 002: Reduce Overfitting + Ticket Features\n",
    "\n",
    "Addressing the CV-LB gap (0.8361 CV vs 0.7799 LB = 5.6% gap):\n",
    "1. Add Ticket_Group_Size feature\n",
    "2. Use simpler/regularized models\n",
    "3. Remove potentially overfitting features (AgeBin, FareBin)\n",
    "4. Try ensemble of regularized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168152d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:35.256767Z",
     "iopub.status.busy": "2026-01-07T04:24:35.256003Z",
     "iopub.status.idle": "2026-01-07T04:24:36.292821Z",
     "shell.execute_reply": "2026-01-07T04:24:36.292168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57db26c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:36.295253Z",
     "iopub.status.busy": "2026-01-07T04:24:36.295001Z",
     "iopub.status.idle": "2026-01-07T04:24:36.303096Z",
     "shell.execute_reply": "2026-01-07T04:24:36.302498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (1309, 13)\n"
     ]
    }
   ],
   "source": [
    "# Combine train and test for consistent feature engineering\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "test['Survived'] = np.nan\n",
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Combined shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bfde243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:36.305224Z",
     "iopub.status.busy": "2026-01-07T04:24:36.304991Z",
     "iopub.status.idle": "2026-01-07T04:24:36.315767Z",
     "shell.execute_reply": "2026-01-07T04:24:36.315210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title distribution:\n",
      "Title\n",
      "Mr        757\n",
      "Miss      264\n",
      "Mrs       198\n",
      "Master     61\n",
      "Rare       29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# 1. Extract Title from Name\n",
    "import re\n",
    "def extract_title(name):\n",
    "    match = re.search(r' ([A-Za-z]+)\\.', name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return 'Unknown'\n",
    "\n",
    "df['Title'] = df['Name'].apply(extract_title)\n",
    "\n",
    "# Group rare titles\n",
    "title_mapping = {\n",
    "    'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "    'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "    'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare', 'Capt': 'Rare',\n",
    "    'Lady': 'Rare', 'Countess': 'Rare', 'Sir': 'Rare', 'Don': 'Rare', 'Dona': 'Rare',\n",
    "    'Jonkheer': 'Rare'\n",
    "}\n",
    "df['Title'] = df['Title'].map(lambda x: title_mapping.get(x, 'Rare'))\n",
    "\n",
    "print(\"Title distribution:\")\n",
    "print(df['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263a9108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:36.317563Z",
     "iopub.status.busy": "2026-01-07T04:24:36.317343Z",
     "iopub.status.idle": "2026-01-07T04:24:36.327156Z",
     "shell.execute_reply": "2026-01-07T04:24:36.326588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket_Group_Size distribution:\n",
      "Ticket_Group_Size\n",
      "1     713\n",
      "2     264\n",
      "3     147\n",
      "4      64\n",
      "5      35\n",
      "6      24\n",
      "7      35\n",
      "8      16\n",
      "11     11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. Family Features\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# 3. Cabin Features\n",
    "df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "\n",
    "# 4. NEW: Ticket Group Size - passengers sharing same ticket\n",
    "ticket_counts = df.groupby('Ticket')['PassengerId'].transform('count')\n",
    "df['Ticket_Group_Size'] = ticket_counts\n",
    "\n",
    "print(\"Ticket_Group_Size distribution:\")\n",
    "print(df['Ticket_Group_Size'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a2b71c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:36.328890Z",
     "iopub.status.busy": "2026-01-07T04:24:36.328684Z",
     "iopub.status.idle": "2026-01-07T04:24:36.359635Z",
     "shell.execute_reply": "2026-01-07T04:24:36.359096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Age after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# 5. FarePerPerson - divide fare by ticket group size\n",
    "df['FarePerPerson'] = df['Fare'] / df['Ticket_Group_Size']\n",
    "\n",
    "# 6. Age Imputation - using median by (Sex, Pclass, Title)\n",
    "train_mask = df['is_train'] == 1\n",
    "age_medians = df[train_mask].groupby(['Sex', 'Pclass', 'Title'])['Age'].median()\n",
    "\n",
    "def impute_age(row):\n",
    "    if pd.isna(row['Age']):\n",
    "        try:\n",
    "            return age_medians.loc[(row['Sex'], row['Pclass'], row['Title'])]\n",
    "        except KeyError:\n",
    "            try:\n",
    "                return df[train_mask].groupby(['Sex', 'Pclass'])['Age'].median().loc[(row['Sex'], row['Pclass'])]\n",
    "            except KeyError:\n",
    "                return df[train_mask]['Age'].median()\n",
    "    return row['Age']\n",
    "\n",
    "df['Age'] = df.apply(impute_age, axis=1)\n",
    "print(f\"Missing Age after imputation: {df['Age'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a887e13e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:36.361295Z",
     "iopub.status.busy": "2026-01-07T04:24:36.361085Z",
     "iopub.status.idle": "2026-01-07T04:24:36.380724Z",
     "shell.execute_reply": "2026-01-07T04:24:36.380170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature encoding complete\n"
     ]
    }
   ],
   "source": [
    "# 7. Fare Handling\n",
    "fare_medians = df[train_mask].groupby('Pclass')['Fare'].median()\n",
    "\n",
    "def impute_fare(row):\n",
    "    if pd.isna(row['Fare']):\n",
    "        return fare_medians.loc[row['Pclass']]\n",
    "    return row['Fare']\n",
    "\n",
    "df['Fare'] = df.apply(impute_fare, axis=1)\n",
    "df['FarePerPerson'] = df['Fare'] / df['Ticket_Group_Size']  # Recalculate after imputation\n",
    "\n",
    "# 8. Embarked - fill with mode\n",
    "df['Embarked'] = df['Embarked'].fillna('S')\n",
    "\n",
    "# Encode categorical features\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "df['Title'] = df['Title'].map({'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5})\n",
    "\n",
    "print(\"Feature encoding complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5911b25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:36.382751Z",
     "iopub.status.busy": "2026-01-07T04:24:36.382246Z",
     "iopub.status.idle": "2026-01-07T04:24:36.391093Z",
     "shell.execute_reply": "2026-01-07T04:24:36.390496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (891, 11)\n",
      "Features: ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'FamilySize', 'IsAlone', 'Has_Cabin', 'Ticket_Group_Size', 'FarePerPerson']\n"
     ]
    }
   ],
   "source": [
    "# Select SIMPLER features - removing AgeBin and FareBin to reduce overfitting\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', \n",
    "            'Title', 'FamilySize', 'IsAlone', 'Has_Cabin',\n",
    "            'Ticket_Group_Size', 'FarePerPerson']\n",
    "\n",
    "# Split back to train and test\n",
    "train_df = df[df['is_train'] == 1].copy()\n",
    "test_df = df[df['is_train'] == 0].copy()\n",
    "\n",
    "X = train_df[features].values\n",
    "y = train_df['Survived'].values\n",
    "X_test = test_df[features].values\n",
    "test_ids = test_df['PassengerId'].values\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"Features: {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a040a39b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:36.393042Z",
     "iopub.status.busy": "2026-01-07T04:24:36.392565Z",
     "iopub.status.idle": "2026-01-07T04:24:36.432989Z",
     "shell.execute_reply": "2026-01-07T04:24:36.432287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model 1: Logistic Regression (L2 regularized)\n",
      "==================================================\n",
      "Fold 1: Accuracy = 0.8212\n",
      "Fold 2: Accuracy = 0.8315\n",
      "Fold 3: Accuracy = 0.7753\n",
      "Fold 4: Accuracy = 0.8146\n",
      "Fold 5: Accuracy = 0.8258\n",
      "\n",
      "Logistic Regression CV: 0.8137 ± 0.0200\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Logistic Regression (simple, regularized)\n",
    "print(\"=\" * 50)\n",
    "print(\"Model 1: Logistic Regression (L2 regularized)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_scores_lr = []\n",
    "test_preds_lr = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Scale features for LR\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = LogisticRegression(C=0.5, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    val_pred = model.predict(X_val_scaled)\n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    fold_scores_lr.append(fold_acc)\n",
    "    test_preds_lr += model.predict_proba(X_test_scaled)[:, 1] / 5\n",
    "    print(f\"Fold {fold+1}: Accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "mean_cv_lr = np.mean(fold_scores_lr)\n",
    "std_cv_lr = np.std(fold_scores_lr)\n",
    "print(f\"\\nLogistic Regression CV: {mean_cv_lr:.4f} ± {std_cv_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f5a63b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:36.435071Z",
     "iopub.status.busy": "2026-01-07T04:24:36.434801Z",
     "iopub.status.idle": "2026-01-07T04:24:38.687832Z",
     "shell.execute_reply": "2026-01-07T04:24:38.687212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Model 2: Shallow Random Forest (max_depth=4)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.8324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Accuracy = 0.8315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Accuracy = 0.8258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: Accuracy = 0.8315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Accuracy = 0.8371\n",
      "\n",
      "Shallow RF CV: 0.8316 ± 0.0036\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Shallow Random Forest (max_depth=4)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Model 2: Shallow Random Forest (max_depth=4)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fold_scores_rf = []\n",
    "test_preds_rf = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=4,  # Shallow!\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        criterion='entropy',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    val_pred = model.predict(X_val)\n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    fold_scores_rf.append(fold_acc)\n",
    "    test_preds_rf += model.predict_proba(X_test)[:, 1] / 5\n",
    "    print(f\"Fold {fold+1}: Accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "mean_cv_rf = np.mean(fold_scores_rf)\n",
    "std_cv_rf = np.std(fold_scores_rf)\n",
    "print(f\"\\nShallow RF CV: {mean_cv_rf:.4f} ± {std_cv_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6676625d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:38.690041Z",
     "iopub.status.busy": "2026-01-07T04:24:38.689571Z",
     "iopub.status.idle": "2026-01-07T04:24:39.525427Z",
     "shell.execute_reply": "2026-01-07T04:24:39.524734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Model 3: Gradient Boosting (regularized)\n",
      "==================================================\n",
      "Fold 1: Accuracy = 0.8659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Accuracy = 0.8483\n",
      "Fold 3: Accuracy = 0.8371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: Accuracy = 0.8371\n",
      "Fold 5: Accuracy = 0.8427\n",
      "\n",
      "Gradient Boosting CV: 0.8462 ± 0.0107\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Gradient Boosting with regularization\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Model 3: Gradient Boosting (regularized)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fold_scores_gb = []\n",
    "test_preds_gb = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,  # Shallow\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    val_pred = model.predict(X_val)\n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    fold_scores_gb.append(fold_acc)\n",
    "    test_preds_gb += model.predict_proba(X_test)[:, 1] / 5\n",
    "    print(f\"Fold {fold+1}: Accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "mean_cv_gb = np.mean(fold_scores_gb)\n",
    "std_cv_gb = np.std(fold_scores_gb)\n",
    "print(f\"\\nGradient Boosting CV: {mean_cv_gb:.4f} ± {std_cv_gb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe4bac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:39.527693Z",
     "iopub.status.busy": "2026-01-07T04:24:39.527460Z",
     "iopub.status.idle": "2026-01-07T04:24:39.908701Z",
     "shell.execute_reply": "2026-01-07T04:24:39.908099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Model 4: SVC (RBF kernel)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.8380\n",
      "Fold 2: Accuracy = 0.8146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Accuracy = 0.8258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: Accuracy = 0.8371\n",
      "Fold 5: Accuracy = 0.8483\n",
      "\n",
      "SVC CV: 0.8328 ± 0.0115\n"
     ]
    }
   ],
   "source": [
    "# Test 4: SVC with RBF kernel\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Model 4: SVC (RBF kernel)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fold_scores_svc = []\n",
    "test_preds_svc = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = SVC(C=1.0, kernel='rbf', probability=True, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    val_pred = model.predict(X_val_scaled)\n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    fold_scores_svc.append(fold_acc)\n",
    "    test_preds_svc += model.predict_proba(X_test_scaled)[:, 1] / 5\n",
    "    print(f\"Fold {fold+1}: Accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "mean_cv_svc = np.mean(fold_scores_svc)\n",
    "std_cv_svc = np.std(fold_scores_svc)\n",
    "print(f\"\\nSVC CV: {mean_cv_svc:.4f} ± {std_cv_svc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3331eff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:39.910547Z",
     "iopub.status.busy": "2026-01-07T04:24:39.910327Z",
     "iopub.status.idle": "2026-01-07T04:24:39.914810Z",
     "shell.execute_reply": "2026-01-07T04:24:39.914268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SUMMARY OF INDIVIDUAL MODELS\n",
      "==================================================\n",
      "Logistic Regression: 0.8137 ± 0.0200\n",
      "Shallow RF:          0.8316 ± 0.0036\n",
      "Gradient Boosting:   0.8462 ± 0.0107\n",
      "SVC:                 0.8328 ± 0.0115\n",
      "\n",
      "Baseline RF (exp_001): 0.8361 ± 0.0069\n"
     ]
    }
   ],
   "source": [
    "# Summary of individual models\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SUMMARY OF INDIVIDUAL MODELS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Logistic Regression: {mean_cv_lr:.4f} ± {std_cv_lr:.4f}\")\n",
    "print(f\"Shallow RF:          {mean_cv_rf:.4f} ± {std_cv_rf:.4f}\")\n",
    "print(f\"Gradient Boosting:   {mean_cv_gb:.4f} ± {std_cv_gb:.4f}\")\n",
    "print(f\"SVC:                 {mean_cv_svc:.4f} ± {std_cv_svc:.4f}\")\n",
    "print(f\"\\nBaseline RF (exp_001): 0.8361 ± 0.0069\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0225c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:39.916840Z",
     "iopub.status.busy": "2026-01-07T04:24:39.916646Z",
     "iopub.status.idle": "2026-01-07T04:24:43.080951Z",
     "shell.execute_reply": "2026-01-07T04:24:43.080345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ENSEMBLE: Soft Voting (Average Probabilities)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble CV Accuracy: 0.8384\n"
     ]
    }
   ],
   "source": [
    "# Ensemble: Average predictions from all models\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ENSEMBLE: Soft Voting (Average Probabilities)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Average all model predictions\n",
    "ensemble_preds = (test_preds_lr + test_preds_rf + test_preds_gb + test_preds_svc) / 4\n",
    "ensemble_binary = (ensemble_preds >= 0.5).astype(int)\n",
    "\n",
    "# For CV score of ensemble, we need to do proper OOF\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_ensemble = np.zeros(len(X))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Scale for LR and SVC\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # Train all models\n",
    "    lr = LogisticRegression(C=0.5, max_iter=1000, random_state=42)\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, max_depth=4, min_samples_split=10,\n",
    "                                 min_samples_leaf=4, criterion='entropy', random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=3,\n",
    "                                     min_samples_split=10, min_samples_leaf=4, subsample=0.8, random_state=42)\n",
    "    gb.fit(X_train, y_train)\n",
    "    \n",
    "    svc = SVC(C=1.0, kernel='rbf', probability=True, random_state=42)\n",
    "    svc.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Average predictions\n",
    "    val_pred_proba = (lr.predict_proba(X_val_scaled)[:, 1] + \n",
    "                      rf.predict_proba(X_val)[:, 1] + \n",
    "                      gb.predict_proba(X_val)[:, 1] + \n",
    "                      svc.predict_proba(X_val_scaled)[:, 1]) / 4\n",
    "    oof_ensemble[val_idx] = val_pred_proba\n",
    "\n",
    "ensemble_oof_binary = (oof_ensemble >= 0.5).astype(int)\n",
    "ensemble_cv = accuracy_score(y, ensemble_oof_binary)\n",
    "print(f\"\\nEnsemble CV Accuracy: {ensemble_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1170083b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:43.083383Z",
     "iopub.status.busy": "2026-01-07T04:24:43.082795Z",
     "iopub.status.idle": "2026-01-07T04:24:43.091863Z",
     "shell.execute_reply": "2026-01-07T04:24:43.091280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved with 418 predictions\n",
      "Predicted survival rate: 0.390\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n",
      "5          897         0\n",
      "6          898         1\n",
      "7          899         0\n",
      "8          900         1\n",
      "9          901         0\n"
     ]
    }
   ],
   "source": [
    "# Create submission with ensemble\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_ids.astype(int),\n",
    "    'Survived': ensemble_binary\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} predictions\")\n",
    "print(f\"Predicted survival rate: {ensemble_binary.mean():.3f}\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe8ab2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:24:43.093599Z",
     "iopub.status.busy": "2026-01-07T04:24:43.093400Z",
     "iopub.status.idle": "2026-01-07T04:24:43.098136Z",
     "shell.execute_reply": "2026-01-07T04:24:43.097577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FINAL SUMMARY\n",
      "==================================================\n",
      "Previous baseline (exp_001): CV = 0.8361, LB = 0.7799\n",
      "This experiment ensemble:    CV = 0.8384\n",
      "\n",
      "Changes made:\n",
      "- Added Ticket_Group_Size and FarePerPerson features\n",
      "- Removed AgeBin and FareBin (potential overfitting)\n",
      "- Used simpler/regularized models\n",
      "- Ensemble of LR, shallow RF, GB, SVC\n",
      "\n",
      "Expected: Lower CV but hopefully better LB correlation\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Previous baseline (exp_001): CV = 0.8361, LB = 0.7799\")\n",
    "print(f\"This experiment ensemble:    CV = {ensemble_cv:.4f}\")\n",
    "print(f\"\\nChanges made:\")\n",
    "print(\"- Added Ticket_Group_Size and FarePerPerson features\")\n",
    "print(\"- Removed AgeBin and FareBin (potential overfitting)\")\n",
    "print(\"- Used simpler/regularized models\")\n",
    "print(\"- Ensemble of LR, shallow RF, GB, SVC\")\n",
    "print(f\"\\nExpected: Lower CV but hopefully better LB correlation\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
