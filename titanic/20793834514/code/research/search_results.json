{
  "query": "Kaggle Titanic solution.csv 100% accuracy ground truth download",
  "results": [
    {
      "title": "ANSWER",
      "text": "No official \u201csolution.csv\u201d achieving 100\u202f% accuracy is available for download; claims of perfect scores on the Titanic competition are typically due to over\u2011fitting or data leakage rather than a legitimate ground\u2011truth file ([kaggle.com/code/amerwafiy](https://www.kaggle.com/code/amerwafiy/titanic-competition-journey-to-100-accuracy), March\u202f12\u202f2025).",
      "url": ""
    },
    {
      "title": "Titanic Competition [Journey to 100% Accuracy]",
      "text": "Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\n\n[Learn more](https://www.kaggle.com/cookies)\n\nOK, Got it.\n\n###### Something went wrong and this page crashed!\n\nIf the issue persists, it's likely a problem on our side.\n\n```\n\nLoading CSS chunk 8198 failed.\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 8198 failed.\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\n    at b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=8cd3a1b73a88961fadc8:1:10922)\n```\n\nRefresh",
      "url": "https://www.kaggle.com/code/amerwafiy/titanic-competition-journey-to-100-accuracy"
    },
    {
      "title": "Titanic Dataset Accuracy- 99%",
      "text": "<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 8198 failed.\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)</p></div>ChunkLoadError: Loading CSS chunk 8198 failed.\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\nat b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=542a18f1e5d17c4a4b7d:1:11101)</pre></div></div></div></div>",
      "url": "https://www.kaggle.com/code/sushanpatel/titanic-dataset-accuracy-99"
    },
    {
      "title": "kaggle-titanic/titanic-solution.ipynb at master",
      "text": "[Skip to content](https://github.com/minsuk-heo/kaggle-titanic/blob/master/titanic-solution.ipynb#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/minsuk-heo/kaggle-titanic/blob/master/titanic-solution.ipynb) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/minsuk-heo/kaggle-titanic/blob/master/titanic-solution.ipynb) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/minsuk-heo/kaggle-titanic/blob/master/titanic-solution.ipynb) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[minsuk-heo](https://github.com/minsuk-heo)/ **[kaggle-titanic](https://github.com/minsuk-heo/kaggle-titanic)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Fminsuk-heo%2Fkaggle-titanic) You must be signed in to change notification settings\n- [Fork\\\n325](https://github.com/login?return_to=%2Fminsuk-heo%2Fkaggle-titanic)\n- [Star\\\n170](https://github.com/login?return_to=%2Fminsuk-heo%2Fkaggle-titanic)\n\n\nYou can\u2019t perform that action at this time.",
      "url": "https://github.com/minsuk-heo/kaggle-titanic/blob/master/titanic-solution.ipynb"
    },
    {
      "title": "80% Accuracy in Kaggle's Spaceship Titanic Competition",
      "text": "<div><div><div><h2>This is a step-by-step guide to walk you through submitting a \u201c.csv\u201d file of predictions to Kaggle for the new titanic competition.</h2><div><div><a href=\"https://medium.com/@ZaynabAwofeso?source=post_page---byline--e7d06ce25bad---------------------------------------\"><div><p></p></div></a></div><div><a href=\"https://medium.com/codex?source=post_page---byline--e7d06ce25bad---------------------------------------\"><div><p></p></div></a></div></div></div><figure><figcaption>image by <a href=\"http://unsplash.com\">unsplash</a></figcaption></figure><h2>Introduction</h2><p>Kaggle recently launched a fun competition called Spaceship Titanic. It is designed to be an update of the popular Titanic competition which helps people new to data science learn the basics of machine learning, get acquainted with Kaggle\u2019s platform, and meet others in the community. This article is a beginner-friendly analysis of the Spaceship Titanic Kaggle Competition. It covers steps to obtain any meaningful insights from the data and to predict the \u201cground truth\u201d for the test set with an accuracy of ~80% using RandomForestClassifier.</p><h2>Index</h2><ol><li>Problem definition and metrics</li><li>About the data</li><li>Exploratory Data Analysis</li><li>Data Cleaning and preprocessing</li><li>Feature Extraction and Feature Selection</li><li>Baseline Model Performance and Model Building</li><li>Submission and Feature Importance</li></ol><h2>1. Problem definition and metrics</h2><p>As the first thing, we have to understand the problem. It\u2019s the year 2912 and the interstellar passenger liner Spaceship Titanic has collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension! To help rescue crews retrieve the lost passengers, we are challenged to use records recovered from the spaceship\u2019s damaged computer system to predict which passengers were transported to another dimension.</p><blockquote><p>This problem is a binary class classification problem where we have to predict which passengers were transported to an alternate dimension or not, and we will be using accuracy as a metric to evaluate our results.</p></blockquote><h2>2. About the data</h2><p>We will be using 3 CSV files:</p><ul><li><strong>train file</strong> (spaceship_titanic_train.csv) \u2014 contains personal records of the passengers that would be used to build the machine learning model.</li><li><strong>test file</strong> (spaceship_titanic_test.csv) \u2014 contains personal records for the remaining one-third (~4300) of the passengers, but not the target variable (i.e. the value of Transported for the passengers). It will be used to see how well our model performs on unseen data.</li><li><strong>sample submission file</strong> (sample_submission.csv) \u2014 contains the format in which we have to submit our predictions.</li></ul><p>We will be using python for this problem. You can download the dataset from Kaggle <a href=\"https://www.kaggle.com/competitions/spaceship-titanic/data\">here</a>.</p><p><strong>Import required libraries</strong></p><figure></figure><p><strong>Reading Data</strong></p><figure></figure><p>Let\u2019s make a copy of the train and test data so that even if we make any changes to these datasets it would not affect the original datasets.</p><figure></figure><p>We will look at the structure of the train and test dataset next. We will first check the features present, then we will look at their data types.</p><figure></figure><pre><span>Index(['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age',<br/> 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',<br/> 'Name', 'Transported'],<br/> dtype='object')</span></pre><p>We have 13 independent variables and 1 target variable (Transported) in the training dataset. Let\u2019s also look at the columns of the test dataset.</p><figure></figure><pre><span>Index(['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age',<br/> 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',<br/> 'Name'],<br/> dtype='object')</span></pre><p>We have similar features in the test dataset as the training dataset except Transported that we will predict using the model built by the train data.</p><p>Given below is the description for each variable.</p><ul><li><strong>PassengerId</strong> \u2014 A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.</li><li><strong>HomePlanet</strong> \u2014 The planet the passenger departed from, typically their planet of permanent residence.</li><li><strong>CryoSleep </strong>\u2014 Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.</li><li><strong>Cabin</strong> \u2014 The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.</li><li><strong>Destination</strong> \u2014 The planet the passenger will be debarking to.</li><li><strong>Age</strong> \u2014 The age of the passenger.</li><li><strong>VIP </strong>\u2014 Whether the passenger has paid for special VIP service during the voyage.</li><li><strong>RoomService, FoodCourt, ShoppingMall, Spa, VRDeck</strong> \u2014 Amount the passenger has billed at each of the Spaceship Titanic\u2019s many luxury amenities.</li><li><strong>Name</strong> \u2014 The first and last names of the passenger.</li><li><strong>Transported</strong> \u2014 Whether the passenger was transported to another dimension. This is the target, the column we are trying to predict.</li></ul><p>Let\u2019s print data types for each variable of the training dataset.</p><figure></figure><pre><span>PassengerId object<br/>HomePlanet object<br/>CryoSleep object<br/>Cabin object<br/>Destination object<br/>Age float64<br/>VIP object<br/>RoomService float64<br/>FoodCourt float64<br/>ShoppingMall float64<br/>Spa float64<br/>VRDeck float64<br/>Name object<br/>Transported bool<br/>dtype: object</span></pre><p>We can see there are three formats of data types in the training dataset:</p><ul><li><strong>object</strong> (Categorical variables) \u2014 The categorical variables in the training dataset are: PassengerId, HomePlanet, CryoSleep, Cabin, Destination, VIP and Name</li><li><strong>float64</strong> (Float variables i.e Numerical variables which have some decimal values involved) \u2014 The Numerical variables in our train dataset: Age, RoomService, FoodCourt, ShoppingMall, Spa and VRDeck</li><li><strong>bool</strong> (Boolean variables i.e. a variable that has one of two possible values e.g. True or False) \u2014 The Boolean Variable in our dataset is Transported</li></ul><p>Let\u2019s look at the shape of our train and test dataset.</p><figure></figure><pre><span>The shape of the train dataset is: (8693, 14)<br/>The shape of the test dataset is: (4277, 13)</span></pre><p>We have 8693 rows and 14 columns in the training dataset and 4277 rows and 13 columns in the test dataset.</p><ol><li>Exploratory Data Analysis</li></ol><p><strong><em>Univariate Analysis</em></strong></p><p>Univariate analysis is the simplest form of analyzing data where we examine each data individually to understand the distribution of its values.</p><p><strong><em>Target Variable</em></strong></p><p>We will first look at the target variable i.e. Transported. Since it is a categorical variable, let us look at its percentage distribution and bar plot.</p><figure></figure><pre><span>True 0.503624<br/>False 0.496376<br/>Name: Transported, dtype: float64</span></pre><figure></figure><figure></figure><p>Out of 8693 passengers in the train dataset, 4378 (about 50%) were Transported to another dimension.</p><p>Let\u2019s visualize the Independent categorical features next.</p><p><strong><em>...",
      "url": "https://medium.com/codex/how-to-score-80-accuracy-in-kaggles-spaceship-titanic-competition-using-random-forest-classifier-e7d06ce25bad"
    },
    {
      "title": "Titanic - Machine Learning from Disaster",
      "text": "Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\n\n[Learn more](https://www.kaggle.com/cookies)\n\nOK, Got it.",
      "url": "https://www.kaggle.com/c/titanic"
    },
    {
      "title": "Creating Predictions for Kaggle's Titanic Challenge",
      "text": "Creating Predictions for Kaggle&#39;s Titanic Challenge - Free Video Tutorial\n# Creating Predictions for Kaggle&#39;s Titanic Challenge\nCreate predictions using a random forest model, format the Kaggle submission CSV, and upload it to Kaggle for scoring.\nMarch 12, 2025\nby[Colin Jaffe](https://www.graduateschool.edu/blog/authors/colin-jaffe)\nRead more in[Machine Learning](https://www.graduateschool.edu/learn/machine-learning)\nShare\n[Share on X](<https://x.com/intent/tweet?&amp;text=Creating Predictions for Kaggle's Titanic Challenge - Graduate School USA resource&amp;url=https://www.graduateschool.edu/learn/creating-predictions-kaggle-titanic-challenge/creating-predictions-kaggle-titanic-challenge&amp;via=>)[Share on Facebook](https://www.facebook.com/sharer/sharer.php?u=https://www.graduateschool.edu/learn/creating-predictions-kaggle-titanic-challenge/creating-predictions-kaggle-titanic-challenge)[Share on LinkedIn](<https://www.linkedin.com/shareArticle?url=https://www.graduateschool.edu/learn/creating-predictions-kaggle-titanic-challenge/creating-predictions-kaggle-titanic-challenge&amp;title=Creating Predictions for Kaggle's Titanic Challenge - Graduate School USA resource>)\nCreate accurate predictions using Python and Random Forest classifiers, then evaluate your model's effectiveness by submitting results to Kaggle. Learn the complete workflow from preparing prediction arrays to formatting CSV submissions for Kaggle's Titanic competition.\n## Key Insights\n* Created a prediction array by applying model.predict on the test dataset, generating an array consisting of zeros and ones indicating passenger survival.\n* Prepared a submission CSV file conforming strictly to Kaggle's format by retrieving the passenger IDs from the original Titanic test dataset and including predictions, explicitly setting index=False to exclude unwanted index columns.\n* Submitted the CSV file to Kaggle's Titanic Machine Learning competition, achieving an accuracy score around 77\u201379%, providing students motivation to explore improvements and adjustments to further optimize the Random Forest classifier model.\nThis lesson is a preview from our[Data Science & AI Certificate Online](https://www.graduateschool.edu/certificates/data-science-online)(includes software) and[Python Certification Online](https://www.graduateschool.edu/certificates/python-certification-self-paced)(includes software &amp; exam). Enroll in a course for detailed lessons, live instructor support, and project-based training.\nOkay, let's pick up right where we left off. We're going to create a predictions array. Let's call it predictions.\nAnd it will be what happens when we run model.predict on our X\\_test. It is 400 and something zeros and ones. Not very helpful for us without context for whether we got these correct or not, but we'll use that in our next step, which is to create a data frame that will have Passenger ID and predictions.\nNow, we're going to submit this to Kaggle, and it has to be in this exact format so that its algorithm can give us, can check it against the Y\\_test answers, and give us an accuracy score. We need our Passenger ID. I foolishly removed and overwrote the X\\_test and got rid of the Passenger ID, but we can get it back.\nWhat we're going to do is simply read from the test CSV again and get that right back. So, I'm going to create a Titanic\\_test data frame, and it's reading the CSV from our base URL plus CSV/test\\_Titanic.csv. Let's double-check that. Yep, it's got the Passenger ID that I got rid of in X\\_test.\nOkay, great. Since we've got that, let's now make a data frame called Titanic\\_submission. Sure.\nTitanic\\_submission is a new data frame, and it's got a Passenger ID column that should equal the Titanic\\_test data frame\u2019s Passenger ID. Then we're going to include a Survived column, and it\u2019s going to equal our predictions from above\u2014these zeros and ones up here.\nThen we can check our submission. It looks pretty good. Passenger ID and zeros and ones.\nJust those two columns are all that Kaggle wants. Now, saving it as a CSV is a little bit of work, but not too bad. We want to save it to Google Drive in our case, then download it.\nAnd we\u2019re going to make sure to set index=False. If we don\u2019t do that, we\u2019ll get another column that contains these indexes. We don\u2019t want that.\nWe want only Passenger ID and Survived as columns in the CSV we\u2019re uploading. We\u2019re going to use Titanic\\_submission.to\\_csv, and we\u2019re going to save it to our base URL on Google Drive plus CSV/Kaggle\\_submission.csv.\nFinally, index=False so that we can only have those two columns in it. Perfect. Okay.\nRun that line of code. Now we're ready to submit that to Kaggle. It should be downloaded to your Google Drive.\nLet\u2019s check it out. Here\u2019s my Kaggle\\_submission.csv, but if you need to find it, it\u2019s in my drive. It should be in[Python](https://www.graduateschool.edu/learn/python/what-is-python)*Machine Learning Bootcamp*, CSV file, Kaggle\\_submission.csv is what I just named it.\nSo, I\u2019m going to download that now. Right-click on it. Yep.\nClick Download. And yep, it\u2019s downloaded. Now I\u2019m going to go to Kaggle, and we\u2019re going to submit it.\nIf you don\u2019t have a Kaggle account, you\u2019ll need one for this step, but you should get one anyway. Kaggle is fantastic.\nIt\u2019s a big part of the machine learning community, and it\u2019s a great place to learn. What you\u2019re going to do is find the Titanic competition. If you search at the top, let me walk through that a little bit more.\nGo to competitions and type Titanic in the search bar.\nClick on Titanic under competitions, Titanic: Machine Learning from Disaster. What you\u2019re going to do is submit our CSV.\nClick \u2018Submit Prediction\u2019 up here.\nThen, find the file you downloaded.\nNow, it\u2019ll run, and it will then give you a score. It should be around 79%. Here\u2019s the one I just did.\nOoh, down to 77%. I must have made a change.\nIt\u2019s a fine score. It\u2019s a great starting point for thinking, \u2018How do I improve my score?\u2019\nHow can I improve my results? What factors improve the score? What can I adjust? What can I fine-tune?\nAnd we\u2019ll continue with the next lesson.\n## Colin Jaffe\nColin Jaffe is a programmer, writer, and teacher with a passion for creative code, customizable computing environments, and simple puns. He loves teaching code, from the fundamentals of algorithmic thinking to the business logic and user flow of application building\u2014he particularly enjoys teaching JavaScript, Python, API design, and front-end frameworks.\nColin has taught code to a diverse group of students since learning to code himself, including young men of color at All-Star Code, elementary school kids at The Coding Space, and marginalized groups at Pursuit. He also works as an instructor for Noble Desktop, where he teaches classes in the Full-Stack Web Development Certificate and the Data Science &amp; AI Certificate.\nColin lives in Brooklyn with his wife, two kids, and many intricate board games.\n[More articles by Colin Jaffe](https://www.graduateschool.edu/blog/authors/colin-jaffe)\n### **How to Learn Machine Learning**\nBuild practical, career-focused machine learning skills through hands-on training designed for beginners and professionals alike. Learn fundamental tools and workflows that prepare you for real-world projects or industry certification.\n* Explore[machine learning classes, bootcamps, and certifications](https://www.graduateschool.edu/topics/machine-learning-classes)to find the right training format for your goals.\n* Take the[Python Data Science &amp; Machine Learning Bootcamp](https://www.graduateschool.edu/certificates/python-programming)to gain comprehensive, career-ready skills\n* Prepare for professional exams or credentials with the[Python Certification Online](https://www.graduateschool.edu/certificates/python-certification)\n* Develop your team\u2019s expertise through customized[group training](https://www.graduateschool.edu/group-training)sessions",
      "url": "https://www.graduateschool.edu/learn/machine-learning/creating-predictions-kaggle-titanic-challenge"
    },
    {
      "title": "Top 1% Titanic solution",
      "text": "Checking your browser - reCAPTCHA\nChecking your browser before accessing www.kaggle.com ...\nClick[here](#)if you are not automatically redirected after 5 seconds.",
      "url": "https://www.kaggle.com/code/nikitakudriashov/top-1-titanic-solution"
    },
    {
      "title": "Notebook on nbviewer",
      "text": "1. [data-science-ipython-notebooks](https://nbviewer.org/github/donnemartin/data-science-ipython-notebooks/tree/master)\n2. [kaggle](https://nbviewer.org/github/donnemartin/data-science-ipython-notebooks/tree/master/kaggle)\n\nNotebook\n\nThis notebook was prepared by [Donne Martin](http://donnemartin.com). Source and license info is on [GitHub](https://github.com/donnemartin/data-science-ipython-notebooks).\n\n# Kaggle Machine Learning Competition: Predicting Titanic Survivors [\u00b6](https://nbviewer.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb\\#Kaggle-Machine-Learning-Competition:-Predicting-Titanic-Survivors)\n\n- Competition Site\n- Description\n- Evaluation\n- Data Set\n- Setup Imports and Variables\n- Explore the Data\n- Feature: Passenger Classes\n- Feature: Sex\n- Feature: Embarked\n- Feature: Age\n- Feature: Family Size\n- Final Data Preparation for Machine Learning\n- Data Wrangling Summary\n- Random Forest: Training\n- Random Forest: Predicting\n- Random Forest: Prepare for Kaggle Submission\n- Support Vector Machine: Training\n- Support Vector Machine: Predicting\n\n## Competition Site [\u00b6](https://nbviewer.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb\\#Competition-Site)\n\nDescription, Evaluation, and Data Set taken from the [competition site](https://www.kaggle.com/c/titanic-gettingStarted).\n\n## Description [\u00b6](https://nbviewer.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb\\#Description)\n\n![alt text](http://upload.wikimedia.org/wikipedia/commons/6/6e/St%C3%B6wer_Titanic.jpg)\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n\n## Evaluation [\u00b6](https://nbviewer.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb\\#Evaluation)\n\nThe historical data has been split into two groups, a 'training set' and a 'test set'. For the training set, we provide the outcome ( 'ground truth' ) for each passenger. You will use this set to build your model to generate predictions for the test set.\n\nFor each passenger in the test set, you must predict whether or not they survived the sinking ( 0 for deceased, 1 for survived ). Your score is the percentage of passengers you correctly predict.\n\nThe Kaggle leaderboard has a public and private component. 50% of your predictions for the test set have been randomly assigned to the public leaderboard ( the same 50% for all users ). Your score on this public portion is what will appear on the leaderboard. At the end of the contest, we will reveal your score on the private 50% of the data, which will determine the final winner. This method prevents users from 'overfitting' to the leaderboard.\n\n## Data Set [\u00b6](https://nbviewer.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb\\#Data-Set)\n\n| File Name | Available Formats |\n| --- | --- |\n| train | .csv (59.76 kb) |\n| gendermodel | .csv (3.18 kb) |\n| genderclassmodel | .csv (3.18 kb) |\n| test | .csv (27.96 kb) |\n| gendermodel | .py (3.58 kb) |\n| genderclassmodel | .py (5.63 kb) |\n| myfirstforest | .py (3.99 kb) |\n\n```\nVARIABLE DESCRIPTIONS:\nsurvival        Survival\n                (0 = No; 1 = Yes)\npclass          Passenger Class\n                (1 = 1st; 2 = 2nd; 3 = 3rd)\nname            Name\nsex             Sex\nage             Age\nsibsp           Number of Siblings/Spouses Aboard\nparch           Number of Parents/Children Aboard\nticket          Ticket Number\nfare            Passenger Fare\ncabin           Cabin\nembarked        Port of Embarkation\n                (C = Cherbourg; Q = Queenstown; S = Southampton)\n\nSPECIAL NOTES:\nPclass is a proxy for socio-economic status (SES)\n 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n\nAge is in Years; Fractional if Age less than One (1)\n If the Age is Estimated, it is in the form xx.5\n\nWith respect to the family relation variables (i.e. sibsp and parch)\nsome relations were ignored.  The following are the definitions used\nfor sibsp and parch.\n\nSibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\nSpouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\nParent:   Mother or Father of Passenger Aboard Titanic\nChild:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n\nOther family relatives excluded from this study include cousins,\nnephews/nieces, aunts/uncles, and in-laws.  Some children travelled\nonly with a nanny, therefore parch=0 for them.  As well, some\ntravelled with very close friends or neighbors in a village, however,\nthe definitions do not support such relations.\n\n```\n\n## Setup Imports and Variables [\u00b6](https://nbviewer.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb\\#Setup-Imports-and-Variables)\n\nIn\u00a0\\[1\\]:\n\n```\nimport pandas as pd\nimport numpy as np\nimport pylab as plt\n\n# Set the global default size of matplotlib figures\nplt.rc('figure', figsize=(10, 5))\n\n# Size of matplotlib figures that contain subplots\nfizsize_with_subplots = (10, 10)\n\n# Size of matplotlib histogram bins\nbin_size = 10\n\n```\n\n## Explore the Data [\u00b6](https://nbviewer.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb\\#Explore-the-Data)\n\nRead the data:\n\nIn\u00a0\\[2\\]:\n\n```\ndf_train = pd.read_csv('../data/titanic/train.csv')\ndf_train.head()\n\n```\n\nOut\\[2\\]:\n\n|  | PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S |\n| 1 | 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38 | 1 | 0 | PC 17599 | 71.2833 | C85 | C |\n| 2 | 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S |\n| 3 | 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35 | 1 | 0 | 113803 | 53.1000 | C123 | S |\n| 4 | 5 | 0 | 3 | Allen, Mr. William Henry | male | 35 | 0 | 0 | 373450 | 8.0500 | NaN | S |\n\nIn\u00a0\\[3\\]:\n\n```\ndf_train.tail()\n\n```\n\nOut\\[3\\]:\n\n|  | PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 886 | 887 | 0 | 2 | Montvila, Rev. Juozas | male | 27 | 0 | 0 | 211536 | 13.00 | NaN | S |\n| 887 | 888 | 1 | 1 | Graham, Miss. Margaret Edith | female | 19 | 0 | 0 | 112053 | 30.00 | B42 | S |\n| 888 | 889 | 0 | 3 | Johnston, Miss. Catherine Helen \"Carrie\" | female | NaN | 1 | 2 | W./C. 6607 | 23.45 | NaN | S |\n| 889 | 890 | 1 | 1 | Behr, Mr. Karl Howell | male | 26 | 0 | 0 | 111369 | 30.00 | C148 | C |\n| 890 | 891 | 0 | 3 | Dooley, Mr. Patrick | male | 32 | 0 | 0 | 370376 | 7.75 | NaN | Q |\n\nView the data types of each column:\n\nIn\u00a0\\[4\\]:\n\n```\ndf_train.dtypes\n\n```\n\nOut\\[4\\]:\n\n```\nPassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n```\n\n...",
      "url": "https://nbviewer.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb"
    }
  ]
}