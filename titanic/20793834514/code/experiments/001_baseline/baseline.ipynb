{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a66a07a",
   "metadata": {},
   "source": [
    "# Experiment 001: Baseline with Feature Engineering\n",
    "\n",
    "Following the seed prompt strategy:\n",
    "- Comprehensive feature engineering (Title, FamilySize, AgeBand, FareBand, Has_Cabin)\n",
    "- RandomForest baseline model\n",
    "- StratifiedKFold cross-validation (k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153737af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df, is_train=True):\n",
    "    \"\"\"Apply comprehensive feature engineering\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Title extraction from Name (MOST IMPORTANT)\n",
    "    df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Group rare titles\n",
    "    rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "    df['Title'] = df['Title'].replace(rare_titles, 'Rare')\n",
    "    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # 2. Family Features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 3. Has_Cabin feature\n",
    "    df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "    \n",
    "    # 4. Sex encoding\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    \n",
    "    # 5. Embarked - fill missing with mode 'S'\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_fe = feature_engineering(train, is_train=True)\n",
    "test_fe = feature_engineering(test, is_train=False)\n",
    "\n",
    "print(\"Title distribution:\")\n",
    "print(train_fe['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a6c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age(train_df, test_df):\n",
    "    \"\"\"Impute Age using median by Sex and Pclass combination\"\"\"\n",
    "    combined = pd.concat([train_df, test_df], ignore_index=True)\n",
    "    \n",
    "    # Calculate median age by Sex and Pclass\n",
    "    age_medians = combined.groupby(['Sex', 'Pclass'])['Age'].median()\n",
    "    \n",
    "    def fill_age(row):\n",
    "        if pd.isna(row['Age']):\n",
    "            return age_medians[(row['Sex'], row['Pclass'])]\n",
    "        return row['Age']\n",
    "    \n",
    "    train_df['Age'] = train_df.apply(fill_age, axis=1)\n",
    "    test_df['Age'] = test_df.apply(fill_age, axis=1)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# Impute Age\n",
    "train_fe, test_fe = impute_age(train_fe, test_fe)\n",
    "\n",
    "# Impute Fare (1 missing in test)\n",
    "train_fe['Fare'] = train_fe['Fare'].fillna(train_fe['Fare'].median())\n",
    "test_fe['Fare'] = test_fe['Fare'].fillna(test_fe['Fare'].median())\n",
    "\n",
    "print(f\"Missing values after imputation:\")\n",
    "print(f\"Train Age missing: {train_fe['Age'].isna().sum()}\")\n",
    "print(f\"Test Age missing: {test_fe['Age'].isna().sum()}\")\n",
    "print(f\"Test Fare missing: {test_fe['Fare'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bins(train_df, test_df):\n",
    "    \"\"\"Create Age and Fare bins\"\"\"\n",
    "    # Age bins: 0-16, 16-32, 32-48, 48-64, 64+\n",
    "    age_bins = [0, 16, 32, 48, 64, 100]\n",
    "    train_df['AgeBand'] = pd.cut(train_df['Age'], bins=age_bins, labels=[0, 1, 2, 3, 4])\n",
    "    test_df['AgeBand'] = pd.cut(test_df['Age'], bins=age_bins, labels=[0, 1, 2, 3, 4])\n",
    "    \n",
    "    # Fare bins: 4 quantiles based on training data\n",
    "    fare_bins = [-1, 7.91, 14.454, 31.0, 600]\n",
    "    train_df['FareBand'] = pd.cut(train_df['Fare'], bins=fare_bins, labels=[0, 1, 2, 3])\n",
    "    test_df['FareBand'] = pd.cut(test_df['Fare'], bins=fare_bins, labels=[0, 1, 2, 3])\n",
    "    \n",
    "    # IsChild feature\n",
    "    train_df['IsChild'] = (train_df['Age'] <= 16).astype(int)\n",
    "    test_df['IsChild'] = (test_df['Age'] <= 16).astype(int)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_fe, test_fe = create_bins(train_fe, test_fe)\n",
    "\n",
    "print(\"AgeBand distribution:\")\n",
    "print(train_fe['AgeBand'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e849fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final features\n",
    "feature_cols = ['Pclass', 'Sex', 'AgeBand', 'FareBand', 'FamilySize', 'IsAlone', 'Has_Cabin', 'IsChild']\n",
    "\n",
    "# One-hot encode Title and Embarked\n",
    "train_encoded = pd.get_dummies(train_fe[['Title', 'Embarked']], columns=['Title', 'Embarked'])\n",
    "test_encoded = pd.get_dummies(test_fe[['Title', 'Embarked']], columns=['Title', 'Embarked'])\n",
    "\n",
    "# Align columns\n",
    "train_encoded, test_encoded = train_encoded.align(test_encoded, join='outer', axis=1, fill_value=0)\n",
    "\n",
    "# Combine features\n",
    "X_train = pd.concat([train_fe[feature_cols].astype(float), train_encoded], axis=1)\n",
    "X_test = pd.concat([test_fe[feature_cols].astype(float), test_encoded], axis=1)\n",
    "y_train = train_fe['Survived']\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"\\nFeatures: {list(X_train.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb938fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation with StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# RandomForest baseline\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    criterion='entropy',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print(f\"CV Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.5f} (+/- {cv_scores.std():.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ed113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on full training data and make predictions\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': predictions.astype(int)\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "submission.to_csv('/home/code/experiments/001_baseline/submission.csv', index=False)\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(submission['Survived'].value_counts())\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed129c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(importance)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
