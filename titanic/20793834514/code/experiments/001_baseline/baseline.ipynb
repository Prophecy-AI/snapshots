{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a66a07a",
   "metadata": {},
   "source": [
    "# Experiment 001: Baseline with Feature Engineering\n",
    "\n",
    "Following the seed prompt strategy:\n",
    "- Comprehensive feature engineering (Title, FamilySize, AgeBand, FareBand, Has_Cabin)\n",
    "- RandomForest baseline model\n",
    "- StratifiedKFold cross-validation (k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153737af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:36:52.859677Z",
     "iopub.status.busy": "2026-01-07T19:36:52.858874Z",
     "iopub.status.idle": "2026-01-07T19:36:53.876364Z",
     "shell.execute_reply": "2026-01-07T19:36:53.875756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Target distribution:\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e0af2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:36:53.878621Z",
     "iopub.status.busy": "2026-01-07T19:36:53.878059Z",
     "iopub.status.idle": "2026-01-07T19:36:53.899720Z",
     "shell.execute_reply": "2026-01-07T19:36:53.899077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title distribution:\n",
      "Title\n",
      "Mr        517\n",
      "Miss      185\n",
      "Mrs       126\n",
      "Master     40\n",
      "Rare       23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(df, is_train=True):\n",
    "    \"\"\"Apply comprehensive feature engineering\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Title extraction from Name (MOST IMPORTANT)\n",
    "    df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Group rare titles\n",
    "    rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "    df['Title'] = df['Title'].replace(rare_titles, 'Rare')\n",
    "    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # 2. Family Features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 3. Has_Cabin feature\n",
    "    df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "    \n",
    "    # 4. Sex encoding\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    \n",
    "    # 5. Embarked - fill missing with mode 'S'\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_fe = feature_engineering(train, is_train=True)\n",
    "test_fe = feature_engineering(test, is_train=False)\n",
    "\n",
    "print(\"Title distribution:\")\n",
    "print(train_fe['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6a6c92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:36:53.901718Z",
     "iopub.status.busy": "2026-01-07T19:36:53.901269Z",
     "iopub.status.idle": "2026-01-07T19:36:53.929471Z",
     "shell.execute_reply": "2026-01-07T19:36:53.928934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation:\n",
      "Train Age missing: 0\n",
      "Test Age missing: 0\n",
      "Test Fare missing: 0\n"
     ]
    }
   ],
   "source": [
    "def impute_age(train_df, test_df):\n",
    "    \"\"\"Impute Age using median by Sex and Pclass combination\"\"\"\n",
    "    combined = pd.concat([train_df, test_df], ignore_index=True)\n",
    "    \n",
    "    # Calculate median age by Sex and Pclass\n",
    "    age_medians = combined.groupby(['Sex', 'Pclass'])['Age'].median()\n",
    "    \n",
    "    def fill_age(row):\n",
    "        if pd.isna(row['Age']):\n",
    "            return age_medians[(row['Sex'], row['Pclass'])]\n",
    "        return row['Age']\n",
    "    \n",
    "    train_df['Age'] = train_df.apply(fill_age, axis=1)\n",
    "    test_df['Age'] = test_df.apply(fill_age, axis=1)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# Impute Age\n",
    "train_fe, test_fe = impute_age(train_fe, test_fe)\n",
    "\n",
    "# Impute Fare (1 missing in test)\n",
    "train_fe['Fare'] = train_fe['Fare'].fillna(train_fe['Fare'].median())\n",
    "test_fe['Fare'] = test_fe['Fare'].fillna(test_fe['Fare'].median())\n",
    "\n",
    "print(f\"Missing values after imputation:\")\n",
    "print(f\"Train Age missing: {train_fe['Age'].isna().sum()}\")\n",
    "print(f\"Test Age missing: {test_fe['Age'].isna().sum()}\")\n",
    "print(f\"Test Fare missing: {test_fe['Fare'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b4a657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:36:53.931200Z",
     "iopub.status.busy": "2026-01-07T19:36:53.931000Z",
     "iopub.status.idle": "2026-01-07T19:36:53.943978Z",
     "shell.execute_reply": "2026-01-07T19:36:53.943479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgeBand distribution:\n",
      "AgeBand\n",
      "0    100\n",
      "1    493\n",
      "2    218\n",
      "3     69\n",
      "4     11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_bins(train_df, test_df):\n",
    "    \"\"\"Create Age and Fare bins\"\"\"\n",
    "    # Age bins: 0-16, 16-32, 32-48, 48-64, 64+\n",
    "    age_bins = [0, 16, 32, 48, 64, 100]\n",
    "    train_df['AgeBand'] = pd.cut(train_df['Age'], bins=age_bins, labels=[0, 1, 2, 3, 4])\n",
    "    test_df['AgeBand'] = pd.cut(test_df['Age'], bins=age_bins, labels=[0, 1, 2, 3, 4])\n",
    "    \n",
    "    # Fare bins: 4 quantiles based on training data\n",
    "    fare_bins = [-1, 7.91, 14.454, 31.0, 600]\n",
    "    train_df['FareBand'] = pd.cut(train_df['Fare'], bins=fare_bins, labels=[0, 1, 2, 3])\n",
    "    test_df['FareBand'] = pd.cut(test_df['Fare'], bins=fare_bins, labels=[0, 1, 2, 3])\n",
    "    \n",
    "    # IsChild feature\n",
    "    train_df['IsChild'] = (train_df['Age'] <= 16).astype(int)\n",
    "    test_df['IsChild'] = (test_df['Age'] <= 16).astype(int)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_fe, test_fe = create_bins(train_fe, test_fe)\n",
    "\n",
    "print(\"AgeBand distribution:\")\n",
    "print(train_fe['AgeBand'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e849fe19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:36:53.945540Z",
     "iopub.status.busy": "2026-01-07T19:36:53.945325Z",
     "iopub.status.idle": "2026-01-07T19:36:53.959946Z",
     "shell.execute_reply": "2026-01-07T19:36:53.959354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (891, 16)\n",
      "X_test shape: (418, 16)\n",
      "\n",
      "Features: ['Pclass', 'Sex', 'AgeBand', 'FareBand', 'FamilySize', 'IsAlone', 'Has_Cabin', 'IsChild', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n"
     ]
    }
   ],
   "source": [
    "# Prepare final features\n",
    "feature_cols = ['Pclass', 'Sex', 'AgeBand', 'FareBand', 'FamilySize', 'IsAlone', 'Has_Cabin', 'IsChild']\n",
    "\n",
    "# One-hot encode Title and Embarked\n",
    "train_encoded = pd.get_dummies(train_fe[['Title', 'Embarked']], columns=['Title', 'Embarked'])\n",
    "test_encoded = pd.get_dummies(test_fe[['Title', 'Embarked']], columns=['Title', 'Embarked'])\n",
    "\n",
    "# Align columns\n",
    "train_encoded, test_encoded = train_encoded.align(test_encoded, join='outer', axis=1, fill_value=0)\n",
    "\n",
    "# Combine features\n",
    "X_train = pd.concat([train_fe[feature_cols].astype(float), train_encoded], axis=1)\n",
    "X_test = pd.concat([test_fe[feature_cols].astype(float), test_encoded], axis=1)\n",
    "y_train = train_fe['Survived']\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"\\nFeatures: {list(X_train.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb938fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:36:53.961697Z",
     "iopub.status.busy": "2026-01-07T19:36:53.961505Z",
     "iopub.status.idle": "2026-01-07T19:36:54.672343Z",
     "shell.execute_reply": "2026-01-07T19:36:54.671692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy Scores: [0.83798883 0.81460674 0.8258427  0.83146067 0.83707865]\n",
      "Mean CV Accuracy: 0.82940 (+/- 0.00858)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation with StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# RandomForest baseline\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    criterion='entropy',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print(f\"CV Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.5f} (+/- {cv_scores.std():.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2ed113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:36:54.674241Z",
     "iopub.status.busy": "2026-01-07T19:36:54.674028Z",
     "iopub.status.idle": "2026-01-07T19:36:54.836585Z",
     "shell.execute_reply": "2026-01-07T19:36:54.835979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (418, 2)\n",
      "\n",
      "Prediction distribution:\n",
      "Survived\n",
      "0    255\n",
      "1    163\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 rows:\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         1\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n",
      "5          897         0\n",
      "6          898         1\n",
      "7          899         0\n",
      "8          900         1\n",
      "9          901         0\n"
     ]
    }
   ],
   "source": [
    "# Train on full training data and make predictions\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': predictions.astype(int)\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "submission.to_csv('/home/code/experiments/001_baseline/submission.csv', index=False)\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(submission['Survived'].value_counts())\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed129c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:36:54.838250Z",
     "iopub.status.busy": "2026-01-07T19:36:54.838045Z",
     "iopub.status.idle": "2026-01-07T19:36:54.848744Z",
     "shell.execute_reply": "2026-01-07T19:36:54.848085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "         feature  importance\n",
      "10      Title_Mr    0.231436\n",
      "1            Sex    0.176498\n",
      "0         Pclass    0.119680\n",
      "4     FamilySize    0.090180\n",
      "3       FareBand    0.068441\n",
      "6      Has_Cabin    0.062281\n",
      "9     Title_Miss    0.054574\n",
      "11     Title_Mrs    0.046749\n",
      "2        AgeBand    0.042069\n",
      "8   Title_Master    0.021684\n",
      "13    Embarked_C    0.018069\n",
      "15    Embarked_S    0.016684\n",
      "5        IsAlone    0.016123\n",
      "12    Title_Rare    0.013822\n",
      "7        IsChild    0.013196\n",
      "14    Embarked_Q    0.008515\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(importance)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
