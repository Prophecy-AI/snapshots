{
  "workspace_dir": "/home/code",
  "competition_id": "titanic",
  "metric_direction": false,
  "start_time": "2026-01-07T08:08:49.076619",
  "time_limit_minutes": 2100,
  "experiments": [],
  "candidates": [],
  "submissions": [],
  "strategy_history": [],
  "feedback_history": [],
  "data_findings": [
    {
      "finding": "Best submission score ~0.77990 (78%) achieved with tuned hard voting classifier. Decision tree-based algorithms converge on similar accuracy after tuning. Feature engineering critical: extract titles from names, create family size, bin age/fare.",
      "source": "../research/kernels/ldfreeman3_a-data-science-framework-to-achieve-99-accuracy",
      "agent": "explorer"
    },
    {
      "finding": "Stacking achieved 0.808 (80.8%) accuracy - top 9%. Two-level stacking: First level (RF, ExtraTrees, AdaBoost, GradientBoosting, SVC), Second level XGBoost. Key features: Name_length, Has_Cabin, FamilySize, IsAlone, Title. Uncorrelated base models produce better ensemble results.",
      "source": "../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python",
      "agent": "explorer"
    },
    {
      "finding": "Key survival rates: Female 74.2% vs Male 18.9%. Pclass 1: 63%, Pclass 2: 47%, Pclass 3: 24%. Embarked C: 55%, Q: 39%, S: 34%. Missing values: Age (177 train, 86 test), Cabin (687 train, 327 test), Embarked (2 train), Fare (1 test).",
      "source": "exploration/eda.ipynb",
      "agent": "explorer"
    }
  ],
  "web_research": [],
  "max_submissions": 10,
  "remaining_submissions": 5
}