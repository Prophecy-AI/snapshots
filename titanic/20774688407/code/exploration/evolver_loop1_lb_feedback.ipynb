{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646e2c5c",
   "metadata": {},
   "source": [
    "# Loop 1 LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- CV Score: 0.8339 (83.4%)\n",
    "- LB Score: 0.7799 (78.0%)\n",
    "- Gap: +0.054 (5.4 percentage points)\n",
    "\n",
    "## Key Questions\n",
    "1. Why is there such a large CV-LB gap?\n",
    "2. Is there distribution shift between train and test?\n",
    "3. What can we do to improve LB score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8df720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ff58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distributions between train and test\n",
    "print(\"=== Distribution Comparison ===\")\n",
    "print(\"\\nPclass distribution:\")\n",
    "print(\"Train:\", train['Pclass'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print(\"Test:\", test['Pclass'].value_counts(normalize=True).sort_index().to_dict())\n",
    "\n",
    "print(\"\\nSex distribution:\")\n",
    "print(\"Train:\", train['Sex'].value_counts(normalize=True).to_dict())\n",
    "print(\"Test:\", test['Sex'].value_counts(normalize=True).to_dict())\n",
    "\n",
    "print(\"\\nEmbarked distribution:\")\n",
    "print(\"Train:\", train['Embarked'].value_counts(normalize=True).to_dict())\n",
    "print(\"Test:\", test['Embarked'].value_counts(normalize=True).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b48a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution comparison\n",
    "print(\"\\nAge statistics:\")\n",
    "print(f\"Train: mean={train['Age'].mean():.2f}, median={train['Age'].median():.2f}, missing={train['Age'].isna().sum()}\")\n",
    "print(f\"Test: mean={test['Age'].mean():.2f}, median={test['Age'].median():.2f}, missing={test['Age'].isna().sum()}\")\n",
    "\n",
    "print(\"\\nFare statistics:\")\n",
    "print(f\"Train: mean={train['Fare'].mean():.2f}, median={train['Fare'].median():.2f}\")\n",
    "print(f\"Test: mean={test['Fare'].mean():.2f}, median={test['Fare'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d481868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title extraction to compare\n",
    "def extract_title(df):\n",
    "    df = df.copy()\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    return df\n",
    "\n",
    "train_t = extract_title(train)\n",
    "test_t = extract_title(test)\n",
    "\n",
    "print(\"\\nTitle distribution:\")\n",
    "print(\"Train:\", train_t['Title'].value_counts(normalize=True).to_dict())\n",
    "print(\"Test:\", test_t['Title'].value_counts(normalize=True).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc908be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any unusual patterns in test data\n",
    "print(\"\\n=== Potential Distribution Shift Analysis ===\")\n",
    "\n",
    "# Family size distribution\n",
    "train_t['FamilySize'] = train_t['SibSp'] + train_t['Parch'] + 1\n",
    "test_t['FamilySize'] = test_t['SibSp'] + test_t['Parch'] + 1\n",
    "\n",
    "print(\"\\nFamilySize distribution:\")\n",
    "print(\"Train:\", train_t['FamilySize'].value_counts(normalize=True).sort_index().head(8).to_dict())\n",
    "print(\"Test:\", test_t['FamilySize'].value_counts(normalize=True).sort_index().head(8).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ddbe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial validation - can we distinguish train from test?\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Prepare features for adversarial validation\n",
    "def prepare_for_adversarial(train_df, test_df):\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # Simple features\n",
    "    for df in [train_df, test_df]:\n",
    "        df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "        df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "        df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "        df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "        df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "        df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "        df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "        df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "        df['Title'] = df['Title'].map({'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Rare': 4})\n",
    "    \n",
    "    # Fill missing\n",
    "    for df in [train_df, test_df]:\n",
    "        df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "        df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "        df['Embarked'] = df['Embarked'].fillna(0)\n",
    "        df['Title'] = df['Title'].fillna(0)\n",
    "    \n",
    "    features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'Has_Cabin', 'Title']\n",
    "    \n",
    "    train_df['is_test'] = 0\n",
    "    test_df['is_test'] = 1\n",
    "    \n",
    "    combined = pd.concat([train_df[features + ['is_test']], test_df[features + ['is_test']]], ignore_index=True)\n",
    "    \n",
    "    return combined[features], combined['is_test']\n",
    "\n",
    "X_adv, y_adv = prepare_for_adversarial(train, test)\n",
    "\n",
    "# Train adversarial classifier\n",
    "rf_adv = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=42)\n",
    "adv_scores = cross_val_score(rf_adv, X_adv, y_adv, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(f\"Adversarial Validation AUC: {adv_scores.mean():.4f} (+/- {adv_scores.std():.4f})\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- AUC ~0.50 = No distribution shift (train/test are similar)\")\n",
    "print(\"- AUC >0.60 = Some distribution shift\")\n",
    "print(\"- AUC >0.70 = Significant distribution shift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for adversarial validation\n",
    "rf_adv.fit(X_adv, y_adv)\n",
    "importance_adv = pd.DataFrame({\n",
    "    'feature': X_adv.columns,\n",
    "    'importance': rf_adv.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeatures that distinguish train from test:\")\n",
    "print(importance_adv.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e620ca",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "1. **CV-LB Gap of 5.4%** is significant and suggests:\n",
    "   - Possible overfitting in CV\n",
    "   - Minor data leakage from using combined train+test for Age imputation\n",
    "   - The CV score of 83.4% is likely inflated\n",
    "\n",
    "2. **The target of 1.0 (100%) is impossible** for Titanic:\n",
    "   - Best known LB scores are 80-82%\n",
    "   - Our LB score of 77.99% is actually reasonable\n",
    "   - We should focus on incremental improvements, not perfection\n",
    "\n",
    "3. **Next Steps:**\n",
    "   - Fix data leakage: compute imputation stats from train only\n",
    "   - Try ensemble/stacking approaches (research shows 80.8% achievable)\n",
    "   - Add more features: Ticket frequency, Deck, Age/Fare bins, interactions\n",
    "   - Focus on LB score improvement, not CV inflation"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
