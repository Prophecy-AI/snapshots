{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646e2c5c",
   "metadata": {},
   "source": [
    "# Loop 1 LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- CV Score: 0.8339 (83.4%)\n",
    "- LB Score: 0.7799 (78.0%)\n",
    "- Gap: +0.054 (5.4 percentage points)\n",
    "\n",
    "## Key Questions\n",
    "1. Why is there such a large CV-LB gap?\n",
    "2. Is there distribution shift between train and test?\n",
    "3. What can we do to improve LB score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8df720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:16:34.038525Z",
     "iopub.status.busy": "2026-01-07T08:16:34.037818Z",
     "iopub.status.idle": "2026-01-07T08:16:35.162280Z",
     "shell.execute_reply": "2026-01-07T08:16:35.161378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0ff58a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:16:35.164704Z",
     "iopub.status.busy": "2026-01-07T08:16:35.164382Z",
     "iopub.status.idle": "2026-01-07T08:16:35.179610Z",
     "shell.execute_reply": "2026-01-07T08:16:35.178897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Distribution Comparison ===\n",
      "\n",
      "Pclass distribution:\n",
      "Train: {1: 0.24242424242424243, 2: 0.20650953984287318, 3: 0.5510662177328844}\n",
      "Test: {1: 0.25598086124401914, 2: 0.22248803827751196, 3: 0.5215311004784688}\n",
      "\n",
      "Sex distribution:\n",
      "Train: {'male': 0.6475869809203143, 'female': 0.35241301907968575}\n",
      "Test: {'male': 0.6363636363636364, 'female': 0.36363636363636365}\n",
      "\n",
      "Embarked distribution:\n",
      "Train: {'S': 0.7244094488188977, 'C': 0.1889763779527559, 'Q': 0.08661417322834646}\n",
      "Test: {'S': 0.645933014354067, 'C': 0.24401913875598086, 'Q': 0.11004784688995216}\n"
     ]
    }
   ],
   "source": [
    "# Compare distributions between train and test\n",
    "print(\"=== Distribution Comparison ===\")\n",
    "print(\"\\nPclass distribution:\")\n",
    "print(\"Train:\", train['Pclass'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print(\"Test:\", test['Pclass'].value_counts(normalize=True).sort_index().to_dict())\n",
    "\n",
    "print(\"\\nSex distribution:\")\n",
    "print(\"Train:\", train['Sex'].value_counts(normalize=True).to_dict())\n",
    "print(\"Test:\", test['Sex'].value_counts(normalize=True).to_dict())\n",
    "\n",
    "print(\"\\nEmbarked distribution:\")\n",
    "print(\"Train:\", train['Embarked'].value_counts(normalize=True).to_dict())\n",
    "print(\"Test:\", test['Embarked'].value_counts(normalize=True).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b48a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:16:35.182500Z",
     "iopub.status.busy": "2026-01-07T08:16:35.181696Z",
     "iopub.status.idle": "2026-01-07T08:16:35.192158Z",
     "shell.execute_reply": "2026-01-07T08:16:35.191394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Age statistics:\n",
      "Train: mean=29.70, median=28.00, missing=177\n",
      "Test: mean=30.27, median=27.00, missing=86\n",
      "\n",
      "Fare statistics:\n",
      "Train: mean=32.20, median=14.45\n",
      "Test: mean=35.63, median=14.45\n"
     ]
    }
   ],
   "source": [
    "# Age distribution comparison\n",
    "print(\"\\nAge statistics:\")\n",
    "print(f\"Train: mean={train['Age'].mean():.2f}, median={train['Age'].median():.2f}, missing={train['Age'].isna().sum()}\")\n",
    "print(f\"Test: mean={test['Age'].mean():.2f}, median={test['Age'].median():.2f}, missing={test['Age'].isna().sum()}\")\n",
    "\n",
    "print(\"\\nFare statistics:\")\n",
    "print(f\"Train: mean={train['Fare'].mean():.2f}, median={train['Fare'].median():.2f}\")\n",
    "print(f\"Test: mean={test['Fare'].mean():.2f}, median={test['Fare'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d481868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:16:35.194487Z",
     "iopub.status.busy": "2026-01-07T08:16:35.194237Z",
     "iopub.status.idle": "2026-01-07T08:16:35.210256Z",
     "shell.execute_reply": "2026-01-07T08:16:35.209576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title distribution:\n",
      "Train: {'Mr': 0.5802469135802469, 'Miss': 0.20763187429854096, 'Mrs': 0.1414141414141414, 'Master': 0.04489337822671156, 'Rare': 0.025813692480359147}\n",
      "Test: {'Mr': 0.5741626794258373, 'Miss': 0.18899521531100477, 'Mrs': 0.1722488038277512, 'Master': 0.050239234449760764, 'Rare': 0.014354066985645933}\n"
     ]
    }
   ],
   "source": [
    "# Title extraction to compare\n",
    "def extract_title(df):\n",
    "    df = df.copy()\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    return df\n",
    "\n",
    "train_t = extract_title(train)\n",
    "test_t = extract_title(test)\n",
    "\n",
    "print(\"\\nTitle distribution:\")\n",
    "print(\"Train:\", train_t['Title'].value_counts(normalize=True).to_dict())\n",
    "print(\"Test:\", test_t['Title'].value_counts(normalize=True).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc908be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:16:35.212398Z",
     "iopub.status.busy": "2026-01-07T08:16:35.212149Z",
     "iopub.status.idle": "2026-01-07T08:16:35.221453Z",
     "shell.execute_reply": "2026-01-07T08:16:35.220816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Potential Distribution Shift Analysis ===\n",
      "\n",
      "FamilySize distribution:\n",
      "Train: {1: 0.6026936026936027, 2: 0.18069584736251404, 3: 0.11447811447811448, 4: 0.03254769921436588, 5: 0.016835016835016835, 6: 0.024691358024691357, 7: 0.013468013468013467, 8: 0.006734006734006734}\n",
      "Test: {1: 0.6052631578947368, 2: 0.17703349282296652, 3: 0.13636363636363635, 4: 0.03349282296650718, 5: 0.01674641148325359, 6: 0.007177033492822967, 7: 0.009569377990430622, 8: 0.004784688995215311}\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any unusual patterns in test data\n",
    "print(\"\\n=== Potential Distribution Shift Analysis ===\")\n",
    "\n",
    "# Family size distribution\n",
    "train_t['FamilySize'] = train_t['SibSp'] + train_t['Parch'] + 1\n",
    "test_t['FamilySize'] = test_t['SibSp'] + test_t['Parch'] + 1\n",
    "\n",
    "print(\"\\nFamilySize distribution:\")\n",
    "print(\"Train:\", train_t['FamilySize'].value_counts(normalize=True).sort_index().head(8).to_dict())\n",
    "print(\"Test:\", test_t['FamilySize'].value_counts(normalize=True).sort_index().head(8).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08ddbe08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:16:35.223946Z",
     "iopub.status.busy": "2026-01-07T08:16:35.223321Z",
     "iopub.status.idle": "2026-01-07T08:16:36.132395Z",
     "shell.execute_reply": "2026-01-07T08:16:36.131701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Validation AUC: 0.7025 (+/- 0.0305)\n",
      "\n",
      "Interpretation:\n",
      "- AUC ~0.50 = No distribution shift (train/test are similar)\n",
      "- AUC >0.60 = Some distribution shift\n",
      "- AUC >0.70 = Significant distribution shift\n"
     ]
    }
   ],
   "source": [
    "# Adversarial validation - can we distinguish train from test?\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Prepare features for adversarial validation\n",
    "def prepare_for_adversarial(train_df, test_df):\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # Simple features\n",
    "    for df in [train_df, test_df]:\n",
    "        df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "        df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "        df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "        df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "        df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "        df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "        df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "        df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "        df['Title'] = df['Title'].map({'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Rare': 4})\n",
    "    \n",
    "    # Fill missing\n",
    "    for df in [train_df, test_df]:\n",
    "        df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "        df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "        df['Embarked'] = df['Embarked'].fillna(0)\n",
    "        df['Title'] = df['Title'].fillna(0)\n",
    "    \n",
    "    features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'Has_Cabin', 'Title']\n",
    "    \n",
    "    train_df['is_test'] = 0\n",
    "    test_df['is_test'] = 1\n",
    "    \n",
    "    combined = pd.concat([train_df[features + ['is_test']], test_df[features + ['is_test']]], ignore_index=True)\n",
    "    \n",
    "    return combined[features], combined['is_test']\n",
    "\n",
    "X_adv, y_adv = prepare_for_adversarial(train, test)\n",
    "\n",
    "# Train adversarial classifier\n",
    "rf_adv = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=42)\n",
    "adv_scores = cross_val_score(rf_adv, X_adv, y_adv, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(f\"Adversarial Validation AUC: {adv_scores.mean():.4f} (+/- {adv_scores.std():.4f})\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- AUC ~0.50 = No distribution shift (train/test are similar)\")\n",
    "print(\"- AUC >0.60 = Some distribution shift\")\n",
    "print(\"- AUC >0.70 = Significant distribution shift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a38b792a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:16:36.135052Z",
     "iopub.status.busy": "2026-01-07T08:16:36.134350Z",
     "iopub.status.idle": "2026-01-07T08:16:36.308899Z",
     "shell.execute_reply": "2026-01-07T08:16:36.308311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features that distinguish train from test:\n",
      "   feature  importance\n",
      "       Age    0.568987\n",
      "      Fare    0.143003\n",
      "  Embarked    0.068058\n",
      "FamilySize    0.048450\n",
      "     Parch    0.048302\n",
      "     SibSp    0.036645\n",
      "    Pclass    0.032765\n",
      "     Title    0.029074\n",
      " Has_Cabin    0.014782\n",
      "       Sex    0.009935\n"
     ]
    }
   ],
   "source": [
    "# Feature importance for adversarial validation\n",
    "rf_adv.fit(X_adv, y_adv)\n",
    "importance_adv = pd.DataFrame({\n",
    "    'feature': X_adv.columns,\n",
    "    'importance': rf_adv.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeatures that distinguish train from test:\")\n",
    "print(importance_adv.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e620ca",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "1. **CV-LB Gap of 5.4%** is significant and suggests:\n",
    "   - Possible overfitting in CV\n",
    "   - Minor data leakage from using combined train+test for Age imputation\n",
    "   - The CV score of 83.4% is likely inflated\n",
    "\n",
    "2. **The target of 1.0 (100%) is impossible** for Titanic:\n",
    "   - Best known LB scores are 80-82%\n",
    "   - Our LB score of 77.99% is actually reasonable\n",
    "   - We should focus on incremental improvements, not perfection\n",
    "\n",
    "3. **Next Steps:**\n",
    "   - Fix data leakage: compute imputation stats from train only\n",
    "   - Try ensemble/stacking approaches (research shows 80.8% achievable)\n",
    "   - Add more features: Ticket frequency, Deck, Age/Fare bins, interactions\n",
    "   - Focus on LB score improvement, not CV inflation"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
