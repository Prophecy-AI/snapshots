# Titanic Survival Prediction - Final Strategy

## Current Status
- Best CV score: 0.8361 from exp_002 and exp_003
- Best LB score: 0.7799 from exp_000 (RF with Age)
- CV-LB gap: +5.4% to +7.8% → CV is NOT reliable for LB prediction
- **Submissions: 4/10 used, 1 remaining**

## Response to Evaluator
- Technical verdict was TRUSTWORTHY. Execution was sound.
- Evaluator's top priority was to create an ensemble before submitting exp_003. **We submitted exp_003 anyway and it FAILED BADLY (LB 0.7584 - worst of all submissions).**
- Key concerns raised: XGBoost's higher CV variance and shift toward fewer survivors. **Both concerns were validated - XGBoost's pessimism hurt LB significantly.**
- Lesson learned: Should have followed evaluator's recommendation to try ensemble first.

## CRITICAL REALITY CHECK
**The target of 1.0 (100% accuracy) is IMPOSSIBLE for Titanic:**
- Best Kaggle scores are around 80-82%
- Perfect prediction is impossible due to missing information, random factors, and noise
- Our best LB (0.7799) is competitive but not top-tier
- We CANNOT beat 1.0 - this is an unrealistic target

## Data Understanding
- Reference notebooks: See `exploration/eda.ipynb` for feature analysis
- Key patterns: Title is most predictive, Sex/Pclass critical, Age causes distribution shift
- Distribution shift: Age is 56.9% of shift (adversarial validation AUC 0.7025)

## Submission History Analysis
| Experiment | CV Score | LB Score | CV-LB Gap | Notes |
|------------|----------|----------|-----------|-------|
| exp_000 (RF with Age) | 0.8339 | 0.7799 | +5.4% | **BEST LB** |
| exp_001 (Stacking) | 0.8271 | 0.7727 | +5.4% | Stacking didn't help |
| exp_002 (RF no Age) | 0.8361 | 0.7703 | +6.6% | Removing Age hurt LB |
| exp_003 (XGBoost) | 0.8361 | 0.7584 | +7.8% | **WORST LB** |

## Key Learnings
1. **CV is NOT reliable** - Higher CV often means WORSE LB
2. **exp_000 (RF with Age) is our best model** - Simple RF with good features
3. **XGBoost failed badly** - Overfits more than RF on this dataset
4. **Removing Age hurt LB** - Despite improving CV and reducing distribution shift
5. **Stacking didn't help** - Added complexity without benefit

## Final Submission Strategy
With only 1 submission remaining, we have two options:

### Option 1: Submit exp_000 again (SAFEST)
- Already achieved LB 0.7799
- No risk of regression
- But no chance of improvement

### Option 2: Submit majority_top3 ensemble (LOW RISK)
- Majority vote of exp_000, exp_001, exp_002 (excluding failed exp_003)
- Differs from exp_000 by only 2 predictions:
  - PassengerId 925: 1→0 (Mrs. Johnston, 3rd class female with family)
  - PassengerId 1304: 0→1 (Miss Henriksson, 3rd class female alone)
- Both changes seem reasonable based on domain knowledge
- Could improve LB slightly or hurt slightly

## Recommended Approach for Final Submission
**Create and submit the majority_top3 ensemble:**
1. Load predictions from exp_000, exp_001, exp_002
2. Apply majority voting (exclude exp_003 which failed)
3. This changes only 2 predictions from best model
4. Low risk, potential for small improvement

## What NOT to Try
- XGBoost or other boosting models (failed badly)
- Removing Age (hurt LB despite improving CV)
- Complex stacking (didn't help)
- Any approach that differs significantly from exp_000

## Validation Notes
- CV is NOT reliable - do not trust CV improvements
- Focus on staying close to exp_000 (best LB)
- The target of 1.0 is impossible - best realistic score is ~80-82%
