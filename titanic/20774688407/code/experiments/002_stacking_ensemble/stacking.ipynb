{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd2c0c2",
   "metadata": {},
   "source": [
    "# Experiment 002: Stacking Ensemble with Fixed Data Leakage\n",
    "\n",
    "Following the evolved strategy:\n",
    "1. Fix Age imputation to use TRAINING data only (no leakage)\n",
    "2. Add new features: Ticket_Frequency, Sex_Pclass, Age_Bin, Name_Length\n",
    "3. Implement stacking with diverse base models\n",
    "4. Reduce reliance on Age (primary source of distribution shift)\n",
    "\n",
    "Target: CV ~82%, LB ~79-80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, ExtraTreesClassifier, \n",
    "    GradientBoostingClassifier, AdaBoostClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2dac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Apply feature engineering - same as before\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Title extraction (MOST IMPORTANT)\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # 2. Family features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 3. Cabin features\n",
    "    df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "    \n",
    "    # 4. NEW: Name length (mentioned in stacking kernel)\n",
    "    df['Name_Length'] = df['Name'].apply(len)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train = engineer_features(train)\n",
    "test = engineer_features(test)\n",
    "\n",
    "print(\"Titles in train:\", train['Title'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values_no_leakage(train_df, test_df):\n",
    "    \"\"\"Fill missing values using TRAINING data statistics only (no leakage)\"\"\"\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # Age: Compute median by Title from TRAINING data only\n",
    "    title_age_median = train_df.groupby('Title')['Age'].median()\n",
    "    train_median_age = train_df['Age'].median()\n",
    "    \n",
    "    # Apply to train\n",
    "    for title in train_df['Title'].unique():\n",
    "        mask = (train_df['Title'] == title) & (train_df['Age'].isna())\n",
    "        if title in title_age_median:\n",
    "            train_df.loc[mask, 'Age'] = title_age_median[title]\n",
    "        else:\n",
    "            train_df.loc[mask, 'Age'] = train_median_age\n",
    "    \n",
    "    # Apply same values to test (using train statistics)\n",
    "    for title in test_df['Title'].unique():\n",
    "        mask = (test_df['Title'] == title) & (test_df['Age'].isna())\n",
    "        if title in title_age_median:\n",
    "            test_df.loc[mask, 'Age'] = title_age_median[title]\n",
    "        else:\n",
    "            test_df.loc[mask, 'Age'] = train_median_age\n",
    "    \n",
    "    # Embarked: Fill with mode from training data\n",
    "    embarked_mode = train_df['Embarked'].mode()[0]\n",
    "    train_df['Embarked'] = train_df['Embarked'].fillna(embarked_mode)\n",
    "    test_df['Embarked'] = test_df['Embarked'].fillna(embarked_mode)\n",
    "    \n",
    "    # Fare: Fill with median by Pclass from training data\n",
    "    for pclass in [1, 2, 3]:\n",
    "        fare_median = train_df[train_df['Pclass'] == pclass]['Fare'].median()\n",
    "        train_df.loc[(train_df['Pclass'] == pclass) & (train_df['Fare'].isna()), 'Fare'] = fare_median\n",
    "        test_df.loc[(test_df['Pclass'] == pclass) & (test_df['Fare'].isna()), 'Fare'] = fare_median\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train, test = fill_missing_values_no_leakage(train, test)\n",
    "\n",
    "print(\"Missing values after imputation:\")\n",
    "print(\"Train:\", train[['Age', 'Embarked', 'Fare']].isna().sum().to_dict())\n",
    "print(\"Test:\", test[['Age', 'Embarked', 'Fare']].isna().sum().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d99d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features(train_df, test_df):\n",
    "    \"\"\"Add new features recommended by strategy\"\"\"\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # Combine for ticket frequency calculation\n",
    "    combined = pd.concat([train_df, test_df], sort=False)\n",
    "    \n",
    "    # 1. Ticket_Frequency - count of passengers with same ticket\n",
    "    ticket_counts = combined['Ticket'].value_counts()\n",
    "    train_df['Ticket_Frequency'] = train_df['Ticket'].map(ticket_counts)\n",
    "    test_df['Ticket_Frequency'] = test_df['Ticket'].map(ticket_counts)\n",
    "    \n",
    "    # 2. Sex_Pclass interaction feature\n",
    "    train_df['Sex_Pclass'] = train_df['Sex'] + '_' + train_df['Pclass'].astype(str)\n",
    "    test_df['Sex_Pclass'] = test_df['Sex'] + '_' + test_df['Pclass'].astype(str)\n",
    "    \n",
    "    # 3. Age_Bin - broad categories to reduce sensitivity to Age distribution shift\n",
    "    # Using simple bins: Child (0-16), Adult (16-50), Senior (50+)\n",
    "    def age_bin(age):\n",
    "        if age <= 16:\n",
    "            return 'Child'\n",
    "        elif age <= 50:\n",
    "            return 'Adult'\n",
    "        else:\n",
    "            return 'Senior'\n",
    "    \n",
    "    train_df['Age_Bin'] = train_df['Age'].apply(age_bin)\n",
    "    test_df['Age_Bin'] = test_df['Age'].apply(age_bin)\n",
    "    \n",
    "    # 4. IsChild - binary feature (children had higher survival)\n",
    "    train_df['IsChild'] = (train_df['Age'] <= 16).astype(int)\n",
    "    test_df['IsChild'] = (test_df['Age'] <= 16).astype(int)\n",
    "    \n",
    "    # 5. FamilySize_Category - non-linear relationship\n",
    "    def family_category(size):\n",
    "        if size == 1:\n",
    "            return 'Alone'\n",
    "        elif size <= 4:\n",
    "            return 'Small'\n",
    "        else:\n",
    "            return 'Large'\n",
    "    \n",
    "    train_df['FamilySize_Cat'] = train_df['FamilySize'].apply(family_category)\n",
    "    test_df['FamilySize_Cat'] = test_df['FamilySize'].apply(family_category)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train, test = add_new_features(train, test)\n",
    "\n",
    "print(\"New features added:\")\n",
    "print(\"Ticket_Frequency range:\", train['Ticket_Frequency'].min(), \"-\", train['Ticket_Frequency'].max())\n",
    "print(\"Sex_Pclass values:\", train['Sex_Pclass'].unique())\n",
    "print(\"Age_Bin distribution:\", train['Age_Bin'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de97e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "def prepare_features(train_df, test_df):\n",
    "    \"\"\"Encode categorical features and select final feature set\"\"\"\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    categorical_cols = ['Sex', 'Embarked', 'Title', 'Sex_Pclass', 'Age_Bin', 'FamilySize_Cat']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        combined = pd.concat([train_df[col], test_df[col]])\n",
    "        le.fit(combined)\n",
    "        train_df[col] = le.transform(train_df[col])\n",
    "        test_df[col] = le.transform(test_df[col])\n",
    "    \n",
    "    # Select features - reduce Age importance by using Age_Bin instead of raw Age\n",
    "    # Strategy: Use Age_Bin and IsChild instead of raw Age to reduce distribution shift impact\n",
    "    features = [\n",
    "        'Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Embarked',\n",
    "        'Title', 'FamilySize', 'IsAlone', 'Has_Cabin',\n",
    "        'Name_Length', 'Ticket_Frequency', 'Sex_Pclass',\n",
    "        'Age_Bin', 'IsChild', 'FamilySize_Cat'\n",
    "    ]\n",
    "    \n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df['Survived']\n",
    "    X_test = test_df[features]\n",
    "    \n",
    "    return X_train, y_train, X_test, features\n",
    "\n",
    "X_train, y_train, X_test, features = prepare_features(train, test)\n",
    "\n",
    "print(f\"Features ({len(features)}): {features}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc973b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models for stacking (diverse algorithms)\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=6, min_samples_split=4,\n",
    "        random_state=42, n_jobs=-1\n",
    "    )),\n",
    "    ('et', ExtraTreesClassifier(\n",
    "        n_estimators=100, max_depth=6, min_samples_split=4,\n",
    "        random_state=42, n_jobs=-1\n",
    "    )),\n",
    "    ('gb', GradientBoostingClassifier(\n",
    "        n_estimators=100, max_depth=3, learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('ada', AdaBoostClassifier(\n",
    "        n_estimators=100, learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('svc', SVC(\n",
    "        kernel='rbf', C=1.0, probability=True,\n",
    "        random_state=42\n",
    "    ))\n",
    "]\n",
    "\n",
    "# Create stacking classifier with LogisticRegression as meta-learner\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Stacking classifier created with 5 base models:\")\n",
    "for name, model in base_models:\n",
    "    print(f\"  - {name}: {model.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features for SVC (important for RBF kernel)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Stratified K-Fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate stacking classifier\n",
    "print(\"Running 5-fold CV for stacking classifier...\")\n",
    "cv_scores = cross_val_score(stacking_clf, X_train_scaled, y_train, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nCV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.5f} (+/- {cv_scores.std():.5f})\")\n",
    "print(f\"Min: {cv_scores.min():.5f}, Max: {cv_scores.max():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d30809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also evaluate individual base models for comparison\n",
    "print(\"\\nIndividual base model CV scores:\")\n",
    "for name, model in base_models:\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=skf, scoring='accuracy')\n",
    "    print(f\"  {name}: {scores.mean():.5f} (+/- {scores.std():.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ec826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train stacking classifier on full training data\n",
    "print(\"Training stacking classifier on full training data...\")\n",
    "stacking_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = stacking_clf.predict(X_test_scaled)\n",
    "\n",
    "# Load original test data for PassengerId\n",
    "test_original = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_original['PassengerId'],\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"\\nSubmission saved with {len(submission)} predictions\")\n",
    "print(submission.head())\n",
    "print(f\"\\nPrediction distribution: {pd.Series(test_predictions).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6069d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT 002 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: Stacking Ensemble (RF, ET, GB, AdaBoost, SVC + LR meta)\")\n",
    "print(f\"Features: {len(features)} features\")\n",
    "print(f\"New features: Name_Length, Ticket_Frequency, Sex_Pclass, Age_Bin, IsChild, FamilySize_Cat\")\n",
    "print(f\"Data leakage fix: Age imputation from training data only\")\n",
    "print(f\"\\nCV Accuracy: {cv_scores.mean():.5f} (+/- {cv_scores.std():.5f})\")\n",
    "print(f\"Previous best CV: 0.83388\")\n",
    "print(f\"Previous best LB: 0.7799\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
