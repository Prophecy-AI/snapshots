{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3feb3caf",
   "metadata": {},
   "source": [
    "# Experiment 001: Baseline Random Forest with Feature Engineering\n",
    "\n",
    "Following the strategy:\n",
    "1. Feature engineering: Title extraction, FamilySize, IsAlone, Has_Cabin\n",
    "2. Missing value handling: Age by Title median, Embarked by mode, Fare by Pclass median\n",
    "3. Model: Random Forest with Stratified 5-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "997acb7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:13:30.491966Z",
     "iopub.status.busy": "2026-01-07T08:13:30.491237Z",
     "iopub.status.idle": "2026-01-07T08:13:31.714259Z",
     "shell.execute_reply": "2026-01-07T08:13:31.713281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Target distribution:\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9db169a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:13:31.716861Z",
     "iopub.status.busy": "2026-01-07T08:13:31.716339Z",
     "iopub.status.idle": "2026-01-07T08:13:31.741651Z",
     "shell.execute_reply": "2026-01-07T08:13:31.740738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles in train: {'Mr': 517, 'Miss': 185, 'Mrs': 126, 'Master': 40, 'Rare': 23}\n"
     ]
    }
   ],
   "source": [
    "def engineer_features(df, train_df=None):\n",
    "    \"\"\"Apply feature engineering based on strategy\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Title extraction (MOST IMPORTANT)\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # 2. Family features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 3. Cabin features\n",
    "    df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train = engineer_features(train)\n",
    "test = engineer_features(test)\n",
    "\n",
    "print(\"Titles in train:\", train['Title'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de10289e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:13:31.745111Z",
     "iopub.status.busy": "2026-01-07T08:13:31.744397Z",
     "iopub.status.idle": "2026-01-07T08:13:31.812859Z",
     "shell.execute_reply": "2026-01-07T08:13:31.812191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation:\n",
      "Train: {'Age': 0, 'Embarked': 0, 'Fare': 0}\n",
      "Test: {'Age': 0, 'Embarked': 0, 'Fare': 0}\n"
     ]
    }
   ],
   "source": [
    "def fill_missing_values(train_df, test_df):\n",
    "    \"\"\"Fill missing values using training data statistics\"\"\"\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # Combine for consistent imputation\n",
    "    combined = pd.concat([train_df, test_df], sort=False)\n",
    "    \n",
    "    # Age: Fill with median by Title (calculated from combined data)\n",
    "    title_age_median = combined.groupby('Title')['Age'].median()\n",
    "    \n",
    "    for df in [train_df, test_df]:\n",
    "        for title in df['Title'].unique():\n",
    "            mask = (df['Title'] == title) & (df['Age'].isna())\n",
    "            if title in title_age_median:\n",
    "                df.loc[mask, 'Age'] = title_age_median[title]\n",
    "            else:\n",
    "                df.loc[mask, 'Age'] = combined['Age'].median()\n",
    "    \n",
    "    # Embarked: Fill with mode from training data\n",
    "    embarked_mode = train_df['Embarked'].mode()[0]\n",
    "    train_df['Embarked'] = train_df['Embarked'].fillna(embarked_mode)\n",
    "    test_df['Embarked'] = test_df['Embarked'].fillna(embarked_mode)\n",
    "    \n",
    "    # Fare: Fill with median by Pclass from training data\n",
    "    for pclass in [1, 2, 3]:\n",
    "        fare_median = train_df[train_df['Pclass'] == pclass]['Fare'].median()\n",
    "        train_df.loc[(train_df['Pclass'] == pclass) & (train_df['Fare'].isna()), 'Fare'] = fare_median\n",
    "        test_df.loc[(test_df['Pclass'] == pclass) & (test_df['Fare'].isna()), 'Fare'] = fare_median\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train, test = fill_missing_values(train, test)\n",
    "\n",
    "print(\"Missing values after imputation:\")\n",
    "print(\"Train:\", train[['Age', 'Embarked', 'Fare']].isna().sum().to_dict())\n",
    "print(\"Test:\", test[['Age', 'Embarked', 'Fare']].isna().sum().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02aaad4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:13:31.815134Z",
     "iopub.status.busy": "2026-01-07T08:13:31.814545Z",
     "iopub.status.idle": "2026-01-07T08:13:31.829270Z",
     "shell.execute_reply": "2026-01-07T08:13:31.828577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize', 'IsAlone', 'Has_Cabin']\n",
      "X_train shape: (891, 11)\n",
      "X_test shape: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features for modeling\n",
    "def prepare_features(train_df, test_df):\n",
    "    \"\"\"Encode categorical features and select final feature set\"\"\"\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le_sex = LabelEncoder()\n",
    "    le_embarked = LabelEncoder()\n",
    "    le_title = LabelEncoder()\n",
    "    \n",
    "    # Fit on combined data to handle all categories\n",
    "    combined_sex = pd.concat([train_df['Sex'], test_df['Sex']])\n",
    "    combined_embarked = pd.concat([train_df['Embarked'], test_df['Embarked']])\n",
    "    combined_title = pd.concat([train_df['Title'], test_df['Title']])\n",
    "    \n",
    "    le_sex.fit(combined_sex)\n",
    "    le_embarked.fit(combined_embarked)\n",
    "    le_title.fit(combined_title)\n",
    "    \n",
    "    train_df['Sex'] = le_sex.transform(train_df['Sex'])\n",
    "    test_df['Sex'] = le_sex.transform(test_df['Sex'])\n",
    "    \n",
    "    train_df['Embarked'] = le_embarked.transform(train_df['Embarked'])\n",
    "    test_df['Embarked'] = le_embarked.transform(test_df['Embarked'])\n",
    "    \n",
    "    train_df['Title'] = le_title.transform(train_df['Title'])\n",
    "    test_df['Title'] = le_title.transform(test_df['Title'])\n",
    "    \n",
    "    # Select features\n",
    "    features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked',\n",
    "                'Title', 'FamilySize', 'IsAlone', 'Has_Cabin']\n",
    "    \n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df['Survived']\n",
    "    X_test = test_df[features]\n",
    "    \n",
    "    return X_train, y_train, X_test, features\n",
    "\n",
    "X_train, y_train, X_test, features = prepare_features(train, test)\n",
    "\n",
    "print(f\"Features: {features}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac19c6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:13:31.831269Z",
     "iopub.status.busy": "2026-01-07T08:13:31.831033Z",
     "iopub.status.idle": "2026-01-07T08:13:33.959338Z",
     "shell.execute_reply": "2026-01-07T08:13:33.958603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [0.84357542 0.82022472 0.8258427  0.83707865 0.84269663]\n",
      "Mean CV Accuracy: 0.83388 (+/- 0.00931)\n",
      "Min: 0.82022, Max: 0.84358\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest with Stratified 5-Fold CV\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Stratified K-Fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(f\"CV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.5f} (+/- {cv_scores.std():.5f})\")\n",
    "print(f\"Min: {cv_scores.min():.5f}, Max: {cv_scores.max():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d0085b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:13:33.961786Z",
     "iopub.status.busy": "2026-01-07T08:13:33.961261Z",
     "iopub.status.idle": "2026-01-07T08:13:34.382928Z",
     "shell.execute_reply": "2026-01-07T08:13:34.382295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "   feature  importance\n",
      "       Sex    0.297529\n",
      "     Title    0.192762\n",
      "      Fare    0.125950\n",
      "    Pclass    0.087177\n",
      "       Age    0.083613\n",
      " Has_Cabin    0.066232\n",
      "FamilySize    0.053793\n",
      "     SibSp    0.042855\n",
      "  Embarked    0.021727\n",
      "     Parch    0.017052\n",
      "   IsAlone    0.011311\n"
     ]
    }
   ],
   "source": [
    "# Train on full training data and make predictions\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(importance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b1cf00f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T08:13:34.385243Z",
     "iopub.status.busy": "2026-01-07T08:13:34.384625Z",
     "iopub.status.idle": "2026-01-07T08:13:34.443632Z",
     "shell.execute_reply": "2026-01-07T08:13:34.443021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved with 418 predictions\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n",
      "\n",
      "Prediction distribution: {0: 264, 1: 154}\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "test_predictions = rf.predict(X_test)\n",
    "\n",
    "# Load original test data for PassengerId\n",
    "test_original = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_original['PassengerId'],\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} predictions\")\n",
    "print(submission.head())\n",
    "print(f\"\\nPrediction distribution: {pd.Series(test_predictions).value_counts().to_dict()}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
