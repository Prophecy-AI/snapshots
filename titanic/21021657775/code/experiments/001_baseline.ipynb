{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087fe5e5",
   "metadata": {},
   "source": [
    "# Titanic Baseline Model - Phase 1\n",
    "\n",
    "Following the seed prompt strategy to establish baseline performance with simple preprocessing and basic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f6c113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:38:54.034426Z",
     "iopub.status.busy": "2026-01-15T06:38:54.034149Z",
     "iopub.status.idle": "2026-01-15T06:38:55.599297Z",
     "shell.execute_reply": "2026-01-15T06:38:55.598762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67109dbb",
   "metadata": {},
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d99bfe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:38:55.604306Z",
     "iopub.status.busy": "2026-01-15T06:38:55.604020Z",
     "iopub.status.idle": "2026-01-15T06:38:55.626656Z",
     "shell.execute_reply": "2026-01-15T06:38:55.626126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (891, 12)\n",
      "Test data shape: (418, 11)\n",
      "\n",
      "Training data columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(\"Training data shape:\", train_df.shape)\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "print(\"\\nTraining data columns:\", train_df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data info\n",
    "print(\"Training data info:\")\n",
    "train_df.info()\n",
    "print(\"\\nMissing values in training data:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train_df['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67acabe",
   "metadata": {},
   "source": [
    "## Basic Preprocessing\n",
    "\n",
    "Following the strategy: handle missing values, encode categorical variables, create simple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, is_train=True):\n",
    "    \"\"\"Basic preprocessing function\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create a copy to avoid SettingWithCopyWarning\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # 1. Extract Title from Name (high-impact feature from strategy)\n",
    "    df_processed['Title'] = df_processed['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Group rare titles\n",
    "    rare_titles = ['Dr', 'Rev', 'Col', 'Major', 'Countess', 'Sir', 'Lady', 'Capt', 'Don', 'Jonkheer']\n",
    "    df_processed['Title'] = df_processed['Title'].replace(rare_titles, 'Rare')\n",
    "    df_processed['Title'] = df_processed['Title'].replace('Mlle', 'Miss')\n",
    "    df_processed['Title'] = df_processed['Title'].replace('Ms', 'Miss')\n",
    "    df_processed['Title'] = df_processed['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # 2. Create FamilySize feature\n",
    "    df_processed['FamilySize'] = df_processed['SibSp'] + df_processed['Parch'] + 1\n",
    "    \n",
    "    # 3. Create IsAlone feature\n",
    "    df_processed['IsAlone'] = (df_processed['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 4. Create Age bands\n",
    "    df_processed['AgeBand'] = pd.cut(df_processed['Age'], \n",
    "                                   bins=[0, 12, 18, 35, 60, 100], \n",
    "                                   labels=['Child', 'Teen', 'YoungAdult', 'Adult', 'Senior'])\n",
    "    \n",
    "    # 5. Create Fare bands\n",
    "    df_processed['FareBand'] = pd.qcut(df_processed['Fare'], 4, labels=['Low', 'Medium', 'High', 'VeryHigh'])\n",
    "    \n",
    "    # 6. Extract Cabin deck\n",
    "    df_processed['CabinDeck'] = df_processed['Cabin'].str[0]\n",
    "    df_processed['CabinDeck'] = df_processed['CabinDeck'].fillna('Unknown')\n",
    "    \n",
    "    # 7. Create HasCabin feature\n",
    "    df_processed['HasCabin'] = (df_processed['Cabin'].notna()).astype(int)\n",
    "    \n",
    "    # Handle missing values\n",
    "    # Age: fill with median by Title\n",
    "    age_medians = df_processed.groupby('Title')['Age'].median()\n",
    "    for title, median_age in age_medians.items():\n",
    "        mask = (df_processed['Title'] == title) & (df_processed['Age'].isna())\n",
    "        df_processed.loc[mask, 'Age'] = median_age\n",
    "    \n",
    "    # Fill any remaining Age NaNs with overall median\n",
    "    df_processed['Age'] = df_processed['Age'].fillna(df_processed['Age'].median())\n",
    "    \n",
    "    # Embarked: fill with mode\n",
    "    df_processed['Embarked'] = df_processed['Embarked'].fillna(df_processed['Embarked'].mode()[0])\n",
    "    \n",
    "    # Fare: fill with median by Pclass\n",
    "    if is_train:\n",
    "        fare_medians = df_processed.groupby('Pclass')['Fare'].median()\n",
    "        for pclass, median_fare in fare_medians.items():\n",
    "            mask = (df_processed['Pclass'] == pclass) & (df_processed['Fare'].isna())\n",
    "            df_processed.loc[mask, 'Fare'] = median_fare\n",
    "    else:\n",
    "        # For test set, use training medians (we'll handle this separately)\n",
    "        df_processed['Fare'] = df_processed['Fare'].fillna(df_processed['Fare'].median())\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    # Sex: binary encoding\n",
    "    df_processed['Sex'] = df_processed['Sex'].map({'female': 1, 'male': 0})\n",
    "    \n",
    "    # Embarked: one-hot encoding\n",
    "    embarked_dummies = pd.get_dummies(df_processed['Embarked'], prefix='Embarked')\n",
    "    df_processed = pd.concat([df_processed, embarked_dummies], axis=1)\n",
    "    \n",
    "    # Title: label encoding\n",
    "    le = LabelEncoder()\n",
    "    df_processed['Title'] = le.fit_transform(df_processed['Title'])\n",
    "    \n",
    "    # AgeBand: label encoding\n",
    "    df_processed['AgeBand'] = df_processed['AgeBand'].cat.codes\n",
    "    \n",
    "    # FareBand: label encoding\n",
    "    df_processed['FareBand'] = df_processed['FareBand'].cat.codes\n",
    "    \n",
    "    # CabinDeck: label encoding\n",
    "    df_processed['CabinDeck'] = df_processed['CabinDeck'].map({\n",
    "        'Unknown': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'T': 8\n",
    "    })\n",
    "    \n",
    "    # Select features for modeling\n",
    "    feature_cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'IsAlone',\n",
    "                   'Title', 'AgeBand', 'FareBand', 'CabinDeck', 'HasCabin',\n",
    "                   'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "    \n",
    "    return df_processed[feature_cols]\n",
    "\n",
    "# Preprocess both datasets\n",
    "print(\"Preprocessing training data...\")\n",
    "X_train = preprocess_data(train_df, is_train=True)\n",
    "y_train = train_df['Survived']\n",
    "\n",
    "print(\"Preprocessing test data...\")\n",
    "X_test = preprocess_data(test_df, is_train=False)\n",
    "\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Test features shape:\", X_test.shape)\n",
    "print(\"\\nFeature columns:\", X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770715e",
   "metadata": {},
   "source": [
    "## Model Training - Baseline Models\n",
    "\n",
    "Following the strategy: start with Logistic Regression and Random Forest as baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e5826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "print(\"=== BASELINE MODELS ===\\n\")\n",
    "\n",
    "# 1. Logistic Regression (simple baseline)\n",
    "print(\"1. Logistic Regression:\")\n",
    "lr_model = LogisticRegression(random_state=RANDOM_SEED, max_iter=1000)\n",
    "lr_scores = cross_val_score(lr_model, X_train, y_train, cv=skf, scoring='accuracy')\n",
    "print(f\"CV Accuracy: {lr_scores.mean():.4f} ± {lr_scores.std():.4f}\")\n",
    "\n",
    "# 2. Random Forest (excellent default performance)\n",
    "print(\"\\n2. Random Forest:\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED, n_jobs=-1)\n",
    "rf_scores = cross_val_score(rf_model, X_train, y_train, cv=skf, scoring='accuracy')\n",
    "print(f\"CV Accuracy: {rf_scores.mean():.4f} ± {rf_scores.std():.4f}\")\n",
    "\n",
    "# Gender-only baseline for comparison\n",
    "print(\"\\n3. Gender-only baseline (female=1, male=0):\")\n",
    "gender_pred = (train_df['Sex'] == 'female').astype(int)\n",
    "gender_accuracy = accuracy_score(y_train, gender_pred)\n",
    "print(f\"Accuracy: {gender_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"Gender-only baseline: {gender_accuracy:.4f}\")\n",
    "print(f\"Logistic Regression:  {lr_scores.mean():.4f} ± {lr_scores.std():.4f}\")\n",
    "print(f\"Random Forest:        {rf_scores.mean():.4f} ± {rf_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4954a",
   "metadata": {},
   "source": [
    "## Train Final Models and Generate Predictions\n",
    "\n",
    "Train on full training data and generate predictions for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ec744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final models on full training data\n",
    "print(\"Training final models on full training data...\")\n",
    "\n",
    "# Logistic Regression\n",
    "lr_final = LogisticRegression(random_state=RANDOM_SEED, max_iter=1000)\n",
    "lr_final.fit(X_train, y_train)\n",
    "lr_pred = lr_final.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rf_final = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED, n_jobs=-1)\n",
    "rf_final.fit(X_train, y_train)\n",
    "rf_pred = rf_final.predict(X_test)\n",
    "\n",
    "print(\"Models trained successfully!\")\n",
    "\n",
    "# Feature importance from Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_final.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission files\n",
    "print(\"Creating submission files...\")\n",
    "\n",
    "# Logistic Regression submission\n",
    "lr_submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': lr_pred\n",
    "})\n",
    "lr_submission.to_csv('/home/submission/submission_lr_baseline.csv', index=False)\n",
    "\n",
    "# Random Forest submission\n",
    "rf_submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': rf_pred\n",
    "})\n",
    "rf_submission.to_csv('/home/submission/submission_rf_baseline.csv', index=False)\n",
    "\n",
    "print(\"Submission files created:\")\n",
    "print(\"- /home/submission/submission_lr_baseline.csv\")\n",
    "print(\"- /home/submission/submission_rf_baseline.csv\")\n",
    "\n",
    "# Verify submission format\n",
    "print(f\"\\nSubmission shape: {rf_submission.shape}\")\n",
    "print(\"First few rows:\")\n",
    "print(rf_submission.head())\n",
    "\n",
    "# Check for any issues\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(f\"Survived=0: {(rf_pred == 0).sum()}\")\n",
    "print(f\"Survived=1: {(rf_pred == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7d5c9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This baseline experiment implements:\n",
    "- Basic preprocessing with missing value imputation\n",
    "- Key feature engineering (Title, FamilySize, IsAlone, Age/Fare bands, Cabin features)\n",
    "- Two baseline models: Logistic Regression and Random Forest\n",
    "- 5-fold stratified cross-validation\n",
    "- Submission files for both models\n",
    "\n",
    "Next steps: Tune hyperparameters, try XGBoost, and explore ensembling."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
