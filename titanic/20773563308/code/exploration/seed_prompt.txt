# Titanic Survival Prediction - Techniques Guide

## Data Understanding
**Reference notebooks for data characteristics:**
- `exploration/eda.ipynb` - Contains EDA: feature distributions, missing values, survival rates by features

**Key Data Characteristics (from EDA):**
- Binary classification: Survived (0/1)
- 891 training samples, 418 test samples
- Target imbalance: 61.6% died, 38.4% survived
- Missing values: Age (~20%), Cabin (~77%), Embarked (0.2%), Fare (1 in test)
- Strong predictors: Sex (female 74% vs male 19% survival), Pclass, Embarked

## Feature Engineering (Critical for High Scores)

### Title Extraction from Name
Extract titles using regex pattern ` ([A-Za-z]+)\.`:
- Group rare titles: Lady, Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer, Dona → 'Rare'
- Map: Mlle/Ms → Miss, Mme → Mrs
- Final categories: Mr, Miss, Mrs, Master, Rare
- Title is highly predictive of survival

### Family Features
- **FamilySize** = SibSp + Parch + 1
- **IsAlone** = 1 if FamilySize == 1, else 0
- Family size has non-linear relationship with survival (medium families survive better)

### Cabin Features
- **Has_Cabin** = 1 if Cabin is not null, else 0 (having cabin correlates with higher class)
- Can extract deck letter from Cabin (first character)

### Name Length
- **Name_length** = len(Name) - longer names may indicate higher social status

### Binning Continuous Features
- **Age bands**: 0-16, 16-32, 32-48, 48-64, 64+ (or use pd.cut/qcut)
- **Fare bands**: Use pd.qcut(Fare, 4) for quartile-based binning

## Missing Value Imputation

### Age Imputation (Critical - 20% missing)
- Best approach: Impute using median Age grouped by Pclass and Sex
- Alternative: Random values within mean ± std
- Simple: Use overall median

### Embarked Imputation
- Fill with mode ('S' - Southampton, most common)

### Fare Imputation
- Fill with median (only 1 missing in test)

## Models

### Base Models (for ensembling)
From top kernels, these models work well:
1. **Random Forest**: n_estimators=100-500, max_depth=6-10
2. **Gradient Boosting**: learning_rate=0.1-0.25, max_depth=2-4, n_estimators=50-300
3. **XGBoost**: learning_rate=0.01-0.1, max_depth=4-6, n_estimators=200-2000
4. **Extra Trees**: Similar params to Random Forest
5. **AdaBoost**: n_estimators=100-300, learning_rate=0.1
6. **SVC**: kernel='rbf', C=1.0

### Ensembling Strategies (Key for High Scores)

#### Voting Ensemble
- Hard voting: Majority vote from multiple classifiers
- Soft voting: Average predicted probabilities (requires predict_proba)
- Top kernels achieved ~0.78 with hard voting

#### Stacking (Best Results - 0.808 LB)
1. **First level**: Train 5 diverse base models (RF, ExtraTrees, AdaBoost, GradientBoosting, SVC)
2. **Out-of-fold predictions**: Use K-fold CV to generate meta-features
3. **Second level**: XGBoost as meta-learner on first-level predictions
4. **Key insight**: More uncorrelated base models → better stacking results

### Hyperparameter Tuning
- Use GridSearchCV or RandomizedSearchCV
- Cross-validation: StratifiedKFold with k=5-10
- Scoring metric: 'accuracy' (matches competition metric)

## Validation Strategy
- Use StratifiedKFold (k=5 or 10) to maintain class distribution
- CV scores may differ from LB due to train/test distribution differences
- Focus on consistent CV improvement

## Feature Selection
Drop these columns before modeling:
- PassengerId (identifier)
- Name (after extracting Title)
- Ticket (high cardinality, limited value)
- Cabin (after extracting Has_Cabin/Deck)

Keep/Create:
- Pclass, Sex, Age (binned), SibSp, Parch, Fare (binned), Embarked
- Title, FamilySize, IsAlone, Has_Cabin

## Encoding
- Sex: female=0, male=1
- Embarked: S=0, C=1, Q=2
- Title: Mr=1, Miss=2, Mrs=3, Master=4, Rare=5
- All features should be numeric for sklearn models

## Expected Performance
- Simple models: ~0.75-0.77
- Tuned single models: ~0.77-0.78
- Voting ensemble: ~0.78
- Stacking ensemble: ~0.80-0.81
- Target: 1.0 (100% accuracy) - extremely challenging, requires perfect predictions

## Key Insights from Top Kernels
1. Feature engineering matters more than model choice for this dataset
2. Title extraction is one of the most important engineered features
3. Ensemble methods consistently outperform single models
4. Stacking with diverse, uncorrelated base models gives best results
5. Simple decision trees can match complex models after proper feature engineering
