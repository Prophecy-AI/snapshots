# Titanic Survival Prediction - Evolved Strategy (Loop 2)

## Current Status
- Best CV score: 0.8316 from exp_000 (XGBoost baseline)
- Best LB score: 0.7584 from exp_000
- **CV-LB gap: +0.0732** â†’ Significant overfitting. CV overestimates by 7.3%
- Target: 1.0 (100% accuracy) - Note: Evaluator correctly identifies this as unrealistic. Best legitimate scores are ~0.80-0.82 LB.

## Response to Evaluator
- **Technical verdict was TRUSTWORTHY.** Implementation is sound, no leakage detected.
- **Evaluator's top priority**: Submit baseline and implement ensemble methods. **DONE** - Baseline submitted, LB=0.7584.
- **Key concerns raised**: 
  1. Target of 1.0 is unrealistic - **Acknowledged.** Realistic ceiling is ~0.82-0.84 CV / 0.80-0.82 LB. We'll pursue maximum improvement.
  2. Single model approach - **Addressing this loop.** Will build voting/stacking ensemble.
  3. Unexplored features (Deck, Ticket) - **Addressing this loop.** Analysis shows strong signal.
  4. **NEW CONCERN**: CV-LB gap of +0.0732 indicates overfitting. Need to address this.

## CV-LB Gap Analysis
The +0.0732 gap suggests our model is overfitting. Potential causes identified:
- **Distribution shifts**: Embarked C is 24.4% in test vs 18.9% in train; Embarked S is 64.6% in test vs 72.4% in train
- **Title distribution**: Mrs is 17.2% in test vs 14.1% in train
- **Model complexity**: XGBoost with max_depth=4 may be too complex for 891 samples

**Strategy to reduce gap:**
1. Use simpler models in ensemble (LogisticRegression, simpler trees)
2. Stronger regularization on XGBoost
3. Focus on robust features that generalize well
4. Soft voting ensemble to reduce variance

## Data Understanding
**Reference notebooks:**
- `exploration/eda.ipynb` - Initial EDA with survival patterns
- `exploration/evolver_loop1_analysis.ipynb` - Feature engineering analysis
- `exploration/evolver_loop1_lb_feedback.ipynb` - Distribution shift analysis

**Key patterns to exploit (with evidence):**
1. **Sex** - Strongest predictor: Female 74.2% vs Male 18.9% survival
2. **Pclass** - Clear gradient: 1st=63%, 2nd=47%, 3rd=24%
3. **Title** - Captures Sex+Age+Status: Master (young boys) high survival
4. **Deck feature** - Strong signal: Deck D/E/B have 74-76% survival vs U (unknown) at 30%
5. **FamilySize** - Non-linear: Medium families (2-4) survive better than alone or large

## Recommended Approaches (Priority Order)

### Priority 1: Voting Ensemble with Diverse Models
Build soft voting ensemble to reduce variance and improve generalization:
```python
models = [
    ('lr', LogisticRegression(C=0.1, max_iter=1000)),  # Simple, regularized
    ('rf', RandomForestClassifier(n_estimators=200, max_depth=6, min_samples_leaf=4)),
    ('gb', GradientBoostingClassifier(n_estimators=100, max_depth=3, learning_rate=0.1)),
    ('et', ExtraTreesClassifier(n_estimators=200, max_depth=6, min_samples_leaf=4)),
    ('ada', AdaBoostClassifier(n_estimators=100, learning_rate=0.5)),
    ('svc', SVC(kernel='rbf', C=1.0, probability=True)),
    ('xgb', XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1))  # Simpler than baseline
]
ensemble = VotingClassifier(estimators=models, voting='soft')
```
Use **simpler hyperparameters** than baseline to reduce overfitting.

### Priority 2: Enhanced Feature Engineering (Careful Selection)
Add only robust features that should generalize:
1. **Deck** = First character of Cabin, 'U' for unknown (strong signal, simple)
2. **FamilySize_Bin** = 1 (alone), 2-4 (small), 5+ (large) - captures non-linear relationship
3. **Age_Bin** = Child (0-16), Young (16-32), Middle (32-48), Senior (48+)

**AVOID** (may cause overfitting):
- Name_Length - correlation may not generalize
- Ticket_Freq - complex pattern, may overfit
- Too many interaction features

### Priority 3: Stacking Ensemble (If Voting Improves)
If voting ensemble shows improvement, implement stacking:
- Base models: RF, ExtraTrees, AdaBoost, GradientBoosting, SVC
- Meta-learner: LogisticRegression (simple, less prone to overfit)
- Use 5-fold CV for out-of-fold predictions
- Reference: `../research/kernels/arthurtok_introduction-to-ensembling-stacking-in-python/` achieved 0.808 LB

### Priority 4: XGBoost with Stronger Regularization
If ensemble doesn't help, try XGBoost with:
- max_depth=3 (reduced from 4)
- min_child_weight=3 (add regularization)
- reg_alpha=0.1, reg_lambda=1.0 (L1/L2 regularization)
- n_estimators=100 (reduced from 200)

## What NOT to Try
- **Complex hyperparameter tuning** - Focus on ensemble diversity first
- **Neural networks** - Overkill for 891 samples
- **Name_Length feature** - May not generalize (correlation could be spurious)
- **Complex ticket features** - Too many categories, weak signal, overfit risk

## Validation Notes
- Use 10-fold Stratified CV (consistent with baseline)
- random_state=42 for reproducibility
- **Key insight**: CV-LB gap of +0.073 means we should expect LB to be ~7% lower than CV
- If CV improves by 0.01, LB might improve by ~0.007 (assuming similar gap)
- Target CV of ~0.85 to achieve LB of ~0.78-0.79

## Implementation Order for Next Experiment
1. Create exp_001 with voting ensemble + enhanced features (Deck, FamilySize_Bin, Age_Bin)
2. Use simpler model hyperparameters to reduce overfitting
3. Compare CV scores - if CV > 0.83, submit to verify LB improvement
4. If voting works, try stacking in exp_002

## Success Criteria
- CV improvement over 0.8316 baseline
- LB improvement over 0.7584 baseline
- Reduced CV-LB gap (target gap < 0.06)

## Key Insights from Research
- Stacking with diverse base models achieves 0.808+ LB (from kernels)
- Simpler models often generalize better on small datasets
- Ensemble diversity is key - use different model families
- Feature engineering matters more than model choice
- Title, Sex, Pclass are top features - already captured
