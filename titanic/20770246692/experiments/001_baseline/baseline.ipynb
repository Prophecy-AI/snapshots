{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c50f7bb6",
   "metadata": {},
   "source": [
    "# Baseline Model for Titanic Survival Prediction\n",
    "\n",
    "This notebook implements a comprehensive baseline with:\n",
    "- Feature engineering (Title, FamilySize, IsAlone, Has_Cabin)\n",
    "- Proper missing value handling\n",
    "- 5-fold Stratified CV\n",
    "- Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d5d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test for consistent feature engineering\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "test['Survived'] = np.nan\n",
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Combined shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c7db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# 1. Extract Title from Name\n",
    "def extract_title(name):\n",
    "    import re\n",
    "    match = re.search(r' ([A-Za-z]+)\\.', name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return 'Unknown'\n",
    "\n",
    "df['Title'] = df['Name'].apply(extract_title)\n",
    "\n",
    "# Group rare titles\n",
    "title_mapping = {\n",
    "    'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "    'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "    'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare', 'Capt': 'Rare',\n",
    "    'Lady': 'Rare', 'Countess': 'Rare', 'Sir': 'Rare', 'Don': 'Rare', 'Dona': 'Rare',\n",
    "    'Jonkheer': 'Rare'\n",
    "}\n",
    "df['Title'] = df['Title'].map(lambda x: title_mapping.get(x, 'Rare'))\n",
    "\n",
    "print(\"Title distribution:\")\n",
    "print(df['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Family Features\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# Family size groups\n",
    "def family_size_group(size):\n",
    "    if size == 1:\n",
    "        return 0  # Alone\n",
    "    elif size <= 4:\n",
    "        return 1  # Small\n",
    "    else:\n",
    "        return 2  # Large\n",
    "\n",
    "df['FamilySizeGroup'] = df['FamilySize'].apply(family_size_group)\n",
    "\n",
    "print(\"FamilySize distribution:\")\n",
    "print(df['FamilySize'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ceed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Cabin Features\n",
    "df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "\n",
    "print(f\"Has_Cabin distribution:\")\n",
    "print(df['Has_Cabin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac69380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Age Imputation - using median by (Sex, Pclass, Title)\n",
    "# Calculate medians from training data only\n",
    "train_mask = df['is_train'] == 1\n",
    "\n",
    "age_medians = df[train_mask].groupby(['Sex', 'Pclass', 'Title'])['Age'].median()\n",
    "\n",
    "def impute_age(row):\n",
    "    if pd.isna(row['Age']):\n",
    "        try:\n",
    "            return age_medians.loc[(row['Sex'], row['Pclass'], row['Title'])]\n",
    "        except KeyError:\n",
    "            # Fallback to Sex, Pclass median\n",
    "            try:\n",
    "                return df[train_mask].groupby(['Sex', 'Pclass'])['Age'].median().loc[(row['Sex'], row['Pclass'])]\n",
    "            except KeyError:\n",
    "                return df[train_mask]['Age'].median()\n",
    "    return row['Age']\n",
    "\n",
    "df['Age'] = df.apply(impute_age, axis=1)\n",
    "\n",
    "print(f\"Missing Age after imputation: {df['Age'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b54197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Age Binning\n",
    "def age_bin(age):\n",
    "    if age <= 12:\n",
    "        return 0  # Child\n",
    "    elif age <= 19:\n",
    "        return 1  # Teen\n",
    "    elif age <= 64:\n",
    "        return 2  # Adult\n",
    "    else:\n",
    "        return 3  # Senior\n",
    "\n",
    "df['AgeBin'] = df['Age'].apply(age_bin)\n",
    "\n",
    "print(\"AgeBin distribution:\")\n",
    "print(df['AgeBin'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Fare Handling\n",
    "# Fill missing fare with median by Pclass\n",
    "fare_medians = df[train_mask].groupby('Pclass')['Fare'].median()\n",
    "\n",
    "def impute_fare(row):\n",
    "    if pd.isna(row['Fare']):\n",
    "        return fare_medians.loc[row['Pclass']]\n",
    "    return row['Fare']\n",
    "\n",
    "df['Fare'] = df.apply(impute_fare, axis=1)\n",
    "\n",
    "# Fare binning using quantiles from training data\n",
    "fare_bins = df[train_mask]['Fare'].quantile([0, 0.25, 0.5, 0.75, 1.0]).values\n",
    "fare_bins[0] = -0.001  # Handle edge case\n",
    "fare_bins[-1] = df['Fare'].max() + 1\n",
    "\n",
    "df['FareBin'] = pd.cut(df['Fare'], bins=fare_bins, labels=[0, 1, 2, 3]).astype(int)\n",
    "\n",
    "print(\"FareBin distribution:\")\n",
    "print(df['FareBin'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde448e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Embarked - fill with mode\n",
    "df['Embarked'] = df['Embarked'].fillna('S')\n",
    "\n",
    "# Encode categorical features\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "df['Title'] = df['Title'].map({'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5})\n",
    "\n",
    "print(\"\\nFeature encoding complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', \n",
    "            'Title', 'FamilySize', 'IsAlone', 'FamilySizeGroup',\n",
    "            'Has_Cabin', 'AgeBin', 'FareBin']\n",
    "\n",
    "# Split back to train and test\n",
    "train_df = df[df['is_train'] == 1].copy()\n",
    "test_df = df[df['is_train'] == 0].copy()\n",
    "\n",
    "X = train_df[features].values\n",
    "y = train_df['Survived'].values\n",
    "X_test = test_df[features].values\n",
    "test_ids = test_df['PassengerId'].values\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc40d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Stratified Cross-Validation with Random Forest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Random Forest with reasonable parameters\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        min_samples_split=4,\n",
    "        min_samples_leaf=2,\n",
    "        criterion='entropy',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validation predictions\n",
    "    val_pred = model.predict(X_val)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Test predictions (average across folds)\n",
    "    test_predictions += model.predict(X_test) / 5\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_acc)\n",
    "    print(f\"Fold {fold+1}: Accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "mean_cv = np.mean(fold_scores)\n",
    "std_cv = np.std(fold_scores)\n",
    "print(f\"\\nCV Accuracy: {mean_cv:.4f} Â± {std_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1922fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "final_predictions = (test_predictions >= 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_ids.astype(int),\n",
    "    'Survived': final_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} predictions\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1388068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importance = model.feature_importances_\n",
    "feature_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
