{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b25db1",
   "metadata": {},
   "source": [
    "# Loop 1 LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- **CV Score**: 0.8361\n",
    "- **LB Score**: 0.7799\n",
    "- **Gap**: +0.0562 (CV is overly optimistic by ~5.6%)\n",
    "\n",
    "## Key Questions\n",
    "1. Why is CV so much higher than LB?\n",
    "2. Is there distribution shift between train and test?\n",
    "3. What can we do to close this gap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbbc894c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:21:29.920262Z",
     "iopub.status.busy": "2026-01-07T04:21:29.919621Z",
     "iopub.status.idle": "2026-01-07T04:21:30.936394Z",
     "shell.execute_reply": "2026-01-07T04:21:30.935731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "955ff3de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:21:30.938571Z",
     "iopub.status.busy": "2026-01-07T04:21:30.938333Z",
     "iopub.status.idle": "2026-01-07T04:21:30.952158Z",
     "shell.execute_reply": "2026-01-07T04:21:30.951547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Distribution Comparison ===\n",
      "\n",
      "1. Sex Distribution:\n",
      "Train: {'male': 0.6475869809203143, 'female': 0.35241301907968575}\n",
      "Test: {'male': 0.6363636363636364, 'female': 0.36363636363636365}\n",
      "\n",
      "2. Pclass Distribution:\n",
      "Train: {1: 0.24242424242424243, 2: 0.20650953984287318, 3: 0.5510662177328844}\n",
      "Test: {1: 0.25598086124401914, 2: 0.22248803827751196, 3: 0.5215311004784688}\n",
      "\n",
      "3. Age Statistics:\n",
      "Train: mean=29.7, std=14.5\n",
      "Test: mean=30.3, std=14.2\n",
      "\n",
      "4. Fare Statistics:\n",
      "Train: mean=32.2, std=49.7\n",
      "Test: mean=35.6, std=55.9\n"
     ]
    }
   ],
   "source": [
    "# Compare distributions between train and test\n",
    "print(\"=== Distribution Comparison ===\")\n",
    "\n",
    "print(\"\\n1. Sex Distribution:\")\n",
    "print(\"Train:\", train['Sex'].value_counts(normalize=True).to_dict())\n",
    "print(\"Test:\", test['Sex'].value_counts(normalize=True).to_dict())\n",
    "\n",
    "print(\"\\n2. Pclass Distribution:\")\n",
    "print(\"Train:\", train['Pclass'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print(\"Test:\", test['Pclass'].value_counts(normalize=True).sort_index().to_dict())\n",
    "\n",
    "print(\"\\n3. Age Statistics:\")\n",
    "print(f\"Train: mean={train['Age'].mean():.1f}, std={train['Age'].std():.1f}\")\n",
    "print(f\"Test: mean={test['Age'].mean():.1f}, std={test['Age'].std():.1f}\")\n",
    "\n",
    "print(\"\\n4. Fare Statistics:\")\n",
    "print(f\"Train: mean={train['Fare'].mean():.1f}, std={train['Fare'].std():.1f}\")\n",
    "print(f\"Test: mean={test['Fare'].mean():.1f}, std={test['Fare'].std():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed4d614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:21:30.954062Z",
     "iopub.status.busy": "2026-01-07T04:21:30.953797Z",
     "iopub.status.idle": "2026-01-07T04:21:30.962313Z",
     "shell.execute_reply": "2026-01-07T04:21:30.961667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted survival rate in test: 0.373\n",
      "Training survival rate: 0.384\n"
     ]
    }
   ],
   "source": [
    "# Analyze the gap more deeply\n",
    "# The CV-LB gap of 0.056 is significant\n",
    "# This suggests either:\n",
    "# 1. Overfitting to training data patterns\n",
    "# 2. Distribution shift between train and test\n",
    "# 3. Features that work well on train but not test\n",
    "\n",
    "# Let's check the actual survival rate we'd expect\n",
    "# If test has similar distribution to train, expected survival should be ~38%\n",
    "\n",
    "# Our model's predictions on test\n",
    "# From the submission, we can check what we predicted\n",
    "submission = pd.read_csv('/home/code/submission_candidates/candidate_000.csv')\n",
    "print(f\"Predicted survival rate in test: {submission['Survived'].mean():.3f}\")\n",
    "print(f\"Training survival rate: {train['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1c984c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:21:30.964123Z",
     "iopub.status.busy": "2026-01-07T04:21:30.963869Z",
     "iopub.status.idle": "2026-01-07T04:21:30.968687Z",
     "shell.execute_reply": "2026-01-07T04:21:30.968105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LB: 0.7799 accuracy = ~325 correct out of 418\n",
      "CV: 0.8361 accuracy = ~744 correct out of 891\n",
      "\n",
      "Gap: 0.0562 = 5.6% points\n",
      "\n",
      "This gap is LARGE for Titanic. Typical gaps are 0.01-0.03.\n",
      "A gap of 0.056 suggests significant overfitting or distribution shift.\n"
     ]
    }
   ],
   "source": [
    "# Let's analyze what the LB score of 0.7799 means\n",
    "# 0.7799 accuracy on 418 test samples = ~326 correct predictions\n",
    "# 0.8361 CV accuracy on 891 train samples = ~745 correct predictions (in CV)\n",
    "\n",
    "lb_score = 0.7799\n",
    "cv_score = 0.8361\n",
    "test_size = 418\n",
    "train_size = 891\n",
    "\n",
    "print(f\"LB: {lb_score:.4f} accuracy = ~{int(lb_score * test_size)} correct out of {test_size}\")\n",
    "print(f\"CV: {cv_score:.4f} accuracy = ~{int(cv_score * train_size)} correct out of {train_size}\")\n",
    "print(f\"\\nGap: {cv_score - lb_score:.4f} = {(cv_score - lb_score) * 100:.1f}% points\")\n",
    "print(f\"\\nThis gap is LARGE for Titanic. Typical gaps are 0.01-0.03.\")\n",
    "print(f\"A gap of 0.056 suggests significant overfitting or distribution shift.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "900eab22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:21:30.970393Z",
     "iopub.status.busy": "2026-01-07T04:21:30.970192Z",
     "iopub.status.idle": "2026-01-07T04:21:30.981453Z",
     "shell.execute_reply": "2026-01-07T04:21:30.980904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked Distribution:\n",
      "Train: {'S': 0.7244094488188977, 'C': 0.1889763779527559, 'Q': 0.08661417322834646}\n",
      "Test: {'S': 0.645933014354067, 'C': 0.24401913875598086, 'Q': 0.11004784688995216}\n",
      "\n",
      "SibSp Distribution:\n",
      "Train: {0: 0.6823793490460157, 1: 0.2345679012345679, 2: 0.031425364758698095, 3: 0.017957351290684626, 4: 0.020202020202020204}\n",
      "Test: {0: 0.6770334928229665, 1: 0.2631578947368421, 2: 0.03349282296650718, 3: 0.009569377990430622, 4: 0.009569377990430622}\n",
      "\n",
      "Parch Distribution:\n",
      "Train: {0: 0.7609427609427609, 1: 0.1324354657687991, 2: 0.08978675645342311, 3: 0.005611672278338945, 4: 0.004489337822671156}\n",
      "Test: {0: 0.7751196172248804, 1: 0.12440191387559808, 2: 0.07894736842105263, 3: 0.007177033492822967, 4: 0.004784688995215311}\n"
     ]
    }
   ],
   "source": [
    "# Let's check if there's a pattern in what we might be getting wrong\n",
    "# Key insight: The test set might have different characteristics\n",
    "\n",
    "# Check Embarked distribution\n",
    "print(\"Embarked Distribution:\")\n",
    "print(\"Train:\", train['Embarked'].value_counts(normalize=True).to_dict())\n",
    "print(\"Test:\", test['Embarked'].value_counts(normalize=True).to_dict())\n",
    "\n",
    "# Check SibSp/Parch distribution\n",
    "print(\"\\nSibSp Distribution:\")\n",
    "print(\"Train:\", train['SibSp'].value_counts(normalize=True).sort_index().head().to_dict())\n",
    "print(\"Test:\", test['SibSp'].value_counts(normalize=True).sort_index().head().to_dict())\n",
    "\n",
    "print(\"\\nParch Distribution:\")\n",
    "print(\"Train:\", train['Parch'].value_counts(normalize=True).sort_index().head().to_dict())\n",
    "print(\"Test:\", test['Parch'].value_counts(normalize=True).sort_index().head().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cc0f3dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:21:30.983810Z",
     "iopub.status.busy": "2026-01-07T04:21:30.983314Z",
     "iopub.status.idle": "2026-01-07T04:21:30.995339Z",
     "shell.execute_reply": "2026-01-07T04:21:30.994721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title Distribution:\n",
      "Train: {'Mr': 0.5802469135802469, 'Miss': 0.20763187429854096, 'Mrs': 0.1414141414141414, 'Master': 0.04489337822671156, 'Rare': 0.025813692480359147}\n",
      "Test: {'Mr': 0.5741626794258373, 'Miss': 0.18899521531100477, 'Mrs': 0.1722488038277512, 'Master': 0.050239234449760764, 'Rare': 0.014354066985645933}\n"
     ]
    }
   ],
   "source": [
    "# Extract Title and compare\n",
    "import re\n",
    "\n",
    "def extract_title(name):\n",
    "    match = re.search(r' ([A-Za-z]+)\\.', name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return 'Unknown'\n",
    "\n",
    "train['Title'] = train['Name'].apply(extract_title)\n",
    "test['Title'] = test['Name'].apply(extract_title)\n",
    "\n",
    "# Group rare titles\n",
    "title_mapping = {\n",
    "    'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "    'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "    'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare', 'Capt': 'Rare',\n",
    "    'Lady': 'Rare', 'Countess': 'Rare', 'Sir': 'Rare', 'Don': 'Rare', 'Dona': 'Rare',\n",
    "    'Jonkheer': 'Rare'\n",
    "}\n",
    "train['Title'] = train['Title'].map(lambda x: title_mapping.get(x, 'Rare'))\n",
    "test['Title'] = test['Title'].map(lambda x: title_mapping.get(x, 'Rare'))\n",
    "\n",
    "print(\"Title Distribution:\")\n",
    "print(\"Train:\", train['Title'].value_counts(normalize=True).to_dict())\n",
    "print(\"Test:\", test['Title'].value_counts(normalize=True).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "404ba7c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T04:21:30.997345Z",
     "iopub.status.busy": "2026-01-07T04:21:30.997062Z",
     "iopub.status.idle": "2026-01-07T04:21:31.003495Z",
     "shell.execute_reply": "2026-01-07T04:21:31.002849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender submission survival rate: 0.364\n",
      "This is the 'all females survive' baseline\n",
      "\n",
      "Our predicted survival rate: 0.373\n",
      "Difference: 0.010\n"
     ]
    }
   ],
   "source": [
    "# Key insight: The distributions look similar\n",
    "# The gap is likely due to:\n",
    "# 1. Random variation in small test set (418 samples)\n",
    "# 2. Model overfitting to training patterns\n",
    "# 3. Some edge cases in test that don't match training patterns\n",
    "\n",
    "# Let's check the gender submission baseline\n",
    "gender_sub = pd.read_csv('/home/data/gender_submission.csv')\n",
    "print(f\"Gender submission survival rate: {gender_sub['Survived'].mean():.3f}\")\n",
    "print(f\"This is the 'all females survive' baseline\")\n",
    "\n",
    "# Compare with our predictions\n",
    "print(f\"\\nOur predicted survival rate: {submission['Survived'].mean():.3f}\")\n",
    "print(f\"Difference: {submission['Survived'].mean() - gender_sub['Survived'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed8826f",
   "metadata": {},
   "source": [
    "## Analysis Summary\n",
    "\n",
    "### CV-LB Gap Interpretation\n",
    "- **Gap of +0.056 is significant** - suggests our model is overfitting to training patterns\n",
    "- The distributions between train and test look similar, so it's not obvious distribution shift\n",
    "- The gap could be due to:\n",
    "  1. Model complexity (RF with depth 6 might be overfitting)\n",
    "  2. Features that capture training-specific patterns\n",
    "  3. Random variation in the small test set\n",
    "\n",
    "### Implications for Strategy\n",
    "1. **Simpler models might generalize better** - consider reducing complexity\n",
    "2. **Ensemble diversity is key** - different models might capture different patterns\n",
    "3. **Feature selection** - some features might be overfitting\n",
    "4. **The target of 1.0 is still unrealistic** - best legitimate scores are ~0.80-0.82\n",
    "\n",
    "### Next Steps\n",
    "1. Try simpler models (Logistic Regression, shallow trees)\n",
    "2. Implement ensemble with diverse models\n",
    "3. Add ticket-based features (might help with group survival patterns)\n",
    "4. Consider regularization to reduce overfitting"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
