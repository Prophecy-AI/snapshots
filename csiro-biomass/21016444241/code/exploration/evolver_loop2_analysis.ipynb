{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "833af295",
   "metadata": {},
   "source": [
    "# Evolver Loop 2 Analysis\n",
    "\n",
    "## Current Status\n",
    "- Best CV: 0.7715 (exp_001: DINOv2-large patch + post-processing)\n",
    "- Target: 0.79\n",
    "- Gap: 0.0185\n",
    "\n",
    "## Key Questions\n",
    "1. What's causing the high fold variance (Fold 5 at 0.6634)?\n",
    "2. What are the key differences between our approach and top kernels?\n",
    "3. What's the most impactful next step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "DATA_DIR = '/home/data'\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "\n",
    "# Pivot train data\n",
    "train_pivot = train_df.pivot_table(\n",
    "    index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "    columns='target_name',\n",
    "    values='target'\n",
    ").reset_index()\n",
    "\n",
    "print(f'Train samples: {len(train_pivot)}')\n",
    "print(f'Test samples: {len(test_df[\"image_path\"].unique())}')\n",
    "print(f'\\nStates: {train_pivot[\"State\"].value_counts().to_dict()}')\n",
    "print(f'\\nSpecies: {train_pivot[\"Species\"].nunique()} unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze fold 5 issue - what makes it different?\n",
    "# Recreate the fold splits\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds = list(kf.split(train_pivot))\n",
    "\n",
    "# Analyze each fold\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(folds):\n",
    "    val_data = train_pivot.iloc[val_idx]\n",
    "    print(f'\\nFold {fold_idx + 1} ({len(val_idx)} samples):')\n",
    "    print(f'  States: {val_data[\"State\"].value_counts().to_dict()}')\n",
    "    print(f'  Species: {val_data[\"Species\"].nunique()} unique')\n",
    "    print(f'  Height mean: {val_data[\"Height_Ave_cm\"].mean():.2f}')\n",
    "    print(f'  NDVI mean: {val_data[\"Pre_GSHH_NDVI\"].mean():.3f}')\n",
    "    print(f'  Dry_Total mean: {val_data[\"Dry_Total_g\"].mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92438c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target distributions across folds\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "targets = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(folds):\n",
    "    val_data = train_pivot.iloc[val_idx]\n",
    "    for i, target in enumerate(targets):\n",
    "        ax = axes[i // 3, i % 3]\n",
    "        ax.hist(val_data[target], bins=20, alpha=0.5, label=f'Fold {fold_idx+1}')\n",
    "        ax.set_title(target)\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/fold_distributions.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1899c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image dimensions - are we losing information by resizing?\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Sample a few images\n",
    "sample_paths = train_pivot['image_path'].head(5).values\n",
    "for path in sample_paths:\n",
    "    img = Image.open(f'{DATA_DIR}/{path}')\n",
    "    print(f'{path}: {img.size} (W x H)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcf375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: Images are 2000x1000 (W x H)\n",
    "# Current approach resizes to 518x518 - significant compression\n",
    "# Top kernels use 520px patches with overlap\n",
    "\n",
    "# Calculate how many patches we'd get with 520px patches\n",
    "img_w, img_h = 2000, 1000\n",
    "patch_size = 520\n",
    "overlap = 16\n",
    "stride = patch_size - overlap\n",
    "\n",
    "n_patches_x = len(range(0, img_w, stride))\n",
    "n_patches_y = len(range(0, img_h, stride))\n",
    "total_patches = n_patches_x * n_patches_y\n",
    "\n",
    "print(f'Image size: {img_w} x {img_h}')\n",
    "print(f'Patch size: {patch_size}, overlap: {overlap}, stride: {stride}')\n",
    "print(f'Patches: {n_patches_x} x {n_patches_y} = {total_patches} patches per image')\n",
    "print(f'\\nCurrent approach: resize to 518x518 -> 1 embedding')\n",
    "print(f'Patching approach: {total_patches} patches -> {total_patches} embeddings -> average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d53c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare our approach vs top kernels\n",
    "print('='*60)\n",
    "print('COMPARISON: Our Approach vs Top Kernels')\n",
    "print('='*60)\n",
    "\n",
    "print('\\n1. IMAGE PROCESSING:')\n",
    "print('   Our approach: Resize 2000x1000 -> 518x518 (loses spatial detail)')\n",
    "print('   Top kernels: Split into 520px patches, extract per-patch embeddings')\n",
    "\n",
    "print('\\n2. MODEL SIZE:')\n",
    "print('   Our approach: DINOv2-large (1024 dims)')\n",
    "print('   Top kernels: DINOv2-giant (1536 dims)')\n",
    "\n",
    "print('\\n3. ENSEMBLE:')\n",
    "print('   Our approach: LightGBM only')\n",
    "print('   Top kernels: 4 models (GB, HistGB, CatBoost, LightGBM)')\n",
    "\n",
    "print('\\n4. TTA:')\n",
    "print('   Our approach: None')\n",
    "print('   Top kernels: H-flip, V-flip, rotations, Gaussian blur')\n",
    "\n",
    "print('\\n5. ADDITIONAL FEATURES:')\n",
    "print('   Our approach: DINOv2 embeddings + 4 tabular')\n",
    "print('   Top kernels: SigLIP embeddings + semantic text features + PCA/PLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ada1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate potential gains from each improvement\n",
    "print('='*60)\n",
    "print('ESTIMATED GAINS FROM IMPROVEMENTS')\n",
    "print('='*60)\n",
    "\n",
    "current_cv = 0.7715\n",
    "target = 0.79\n",
    "gap = target - current_cv\n",
    "\n",
    "print(f'\\nCurrent CV: {current_cv:.4f}')\n",
    "print(f'Target: {target:.4f}')\n",
    "print(f'Gap to close: {gap:.4f}')\n",
    "\n",
    "print('\\nEstimated improvements:')\n",
    "print('  1. Image patching (520px): +0.01-0.02 (preserves spatial detail)')\n",
    "print('  2. DINOv2-giant: +0.005-0.01 (more capacity)')\n",
    "print('  3. Multi-model ensemble: +0.01-0.02 (reduces variance)')\n",
    "print('  4. TTA: +0.005-0.01 (test-time robustness)')\n",
    "print('  5. SigLIP embeddings: +0.005-0.01 (complementary features)')\n",
    "\n",
    "print('\\nCombined potential: +0.035-0.06')\n",
    "print(f'Expected range: {current_cv + 0.035:.4f} - {current_cv + 0.06:.4f}')\n",
    "print('\\n=> Target of 0.79 is ACHIEVABLE with these improvements')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
