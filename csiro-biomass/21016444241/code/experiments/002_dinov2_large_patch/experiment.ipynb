{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7231af2",
   "metadata": {},
   "source": [
    "# Experiment 002: DINOv2-Large Patch Features + Post-Processing\n",
    "\n",
    "Following evolver strategy:\n",
    "1. Use DINOv2-large (1024 dims) instead of base (768 dims)\n",
    "2. Extract patch tokens (last_hidden_state[:,1:,:]) instead of just CLS\n",
    "3. Apply post-processing to enforce biomass constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "993d4c83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T02:03:04.544086Z",
     "iopub.status.busy": "2026-01-15T02:03:04.543519Z",
     "iopub.status.idle": "2026-01-15T02:03:05.928275Z",
     "shell.execute_reply": "2026-01-15T02:03:05.927817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "Memory: 85.0 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Verify GPU\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a590c42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T02:03:05.929573Z",
     "iopub.status.busy": "2026-01-15T02:03:05.929379Z",
     "iopub.status.idle": "2026-01-15T02:03:05.945868Z",
     "shell.execute_reply": "2026-01-15T02:03:05.945457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivoted train shape: (357, 11)\n",
      "Test shape: (5, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "DATA_DIR = '/home/data'\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "\n",
    "# Pivot train data to have one row per image with all targets\n",
    "train_pivot = train_df.pivot_table(\n",
    "    index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "    columns='target_name',\n",
    "    values='target'\n",
    ").reset_index()\n",
    "\n",
    "print(f'Pivoted train shape: {train_pivot.shape}')\n",
    "print(f'Test shape: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59aba151",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T02:03:05.946853Z",
     "iopub.status.busy": "2026-01-15T02:03:05.946735Z",
     "iopub.status.idle": "2026-01-15T02:03:10.969895Z",
     "shell.execute_reply": "2026-01-15T02:03:10.969404Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 02:03:06.933586: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-15 02:03:06.949476: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-15 02:03:06.953975: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f038e76d5c481c8092f2c3bf404654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/436 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05cebbbb6caf4ef5a8b8c16f0ba37478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/549 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6981f602024ed48d85349eb713d408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: facebook/dinov2-large\n",
      "Hidden size: 1024\n"
     ]
    }
   ],
   "source": [
    "# Load DINOv2-large model (1024 dims vs 768 in base)\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "model_name = 'facebook/dinov2-large'\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).cuda().eval()\n",
    "\n",
    "print(f'Model loaded: {model_name}')\n",
    "print(f'Hidden size: {model.config.hidden_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bffab1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T02:03:25.585459Z",
     "iopub.status.busy": "2026-01-15T02:03:25.584722Z",
     "iopub.status.idle": "2026-01-15T02:03:48.008894Z",
     "shell.execute_reply": "2026-01-15T02:03:48.008405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train patch embeddings with DINOv2-large...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/45 [00:00<00:31,  1.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/45 [00:01<00:25,  1.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 3/45 [00:01<00:23,  1.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 4/45 [00:02<00:21,  1.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 5/45 [00:02<00:20,  1.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 6/45 [00:03<00:20,  1.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 7/45 [00:03<00:19,  1.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 8/45 [00:04<00:18,  1.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 9/45 [00:04<00:18,  1.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 10/45 [00:05<00:17,  1.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 11/45 [00:05<00:16,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 12/45 [00:06<00:16,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 13/45 [00:06<00:16,  2.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 14/45 [00:07<00:15,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 15/45 [00:07<00:14,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 16/45 [00:08<00:14,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 17/45 [00:08<00:13,  2.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 18/45 [00:09<00:13,  2.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 19/45 [00:09<00:12,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 20/45 [00:10<00:12,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 21/45 [00:10<00:11,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 22/45 [00:11<00:11,  2.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 23/45 [00:11<00:10,  2.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 24/45 [00:12<00:10,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 25/45 [00:12<00:09,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 26/45 [00:13<00:09,  2.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 27/45 [00:13<00:08,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 28/45 [00:14<00:08,  2.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 29/45 [00:14<00:08,  2.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 30/45 [00:15<00:07,  2.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 31/45 [00:15<00:06,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 32/45 [00:16<00:06,  2.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 33/45 [00:16<00:06,  2.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 34/45 [00:17<00:05,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 35/45 [00:17<00:04,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 36/45 [00:18<00:04,  2.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 37/45 [00:18<00:03,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 38/45 [00:19<00:03,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 39/45 [00:19<00:02,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 40/45 [00:20<00:02,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 41/45 [00:20<00:01,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 42/45 [00:21<00:01,  2.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 43/45 [00:21<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 44/45 [00:22<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 45/45 [00:22<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 45/45 [00:22<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape: (357, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract PATCH-BASED embeddings (mean of patch tokens, not CLS)\n",
    "def extract_patch_embeddings(image_paths, data_dir, batch_size=8):\n",
    "    \"\"\"Extract mean of patch tokens instead of CLS token.\"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(image_paths), batch_size)):\n",
    "            batch_paths = image_paths[i:i+batch_size]\n",
    "            images = []\n",
    "            \n",
    "            for path in batch_paths:\n",
    "                img = Image.open(f'{data_dir}/{path}').convert('RGB')\n",
    "                images.append(img)\n",
    "            \n",
    "            inputs = processor(images=images, return_tensors='pt').to('cuda')\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            # Use MEAN of patch tokens (excluding CLS token at position 0)\n",
    "            # last_hidden_state shape: (batch, num_patches+1, hidden_size)\n",
    "            patch_tokens = outputs.last_hidden_state[:, 1:, :]  # Exclude CLS\n",
    "            patch_mean = patch_tokens.mean(dim=1)  # Average over patches\n",
    "            \n",
    "            embeddings.append(patch_mean.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Extract train embeddings\n",
    "print('Extracting train patch embeddings with DINOv2-large...')\n",
    "train_embeddings = extract_patch_embeddings(train_pivot['image_path'].values, DATA_DIR)\n",
    "print(f'Train embeddings shape: {train_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1200ed56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T02:03:48.010058Z",
     "iopub.status.busy": "2026-01-15T02:03:48.009935Z",
     "iopub.status.idle": "2026-01-15T02:03:48.089856Z",
     "shell.execute_reply": "2026-01-15T02:03:48.089400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test patch embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:00<00:00, 13.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape: (1, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract test embeddings\n",
    "print('Extracting test patch embeddings...')\n",
    "test_images_unique = test_df['image_path'].unique()\n",
    "test_embeddings = extract_patch_embeddings(test_images_unique, DATA_DIR)\n",
    "print(f'Test embeddings shape: {test_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature dataframe with embeddings\n",
    "emb_cols = [f'emb_{i}' for i in range(train_embeddings.shape[1])]\n",
    "train_emb_df = pd.DataFrame(train_embeddings, columns=emb_cols)\n",
    "train_emb_df['image_path'] = train_pivot['image_path'].values\n",
    "\n",
    "test_emb_df = pd.DataFrame(test_embeddings, columns=emb_cols)\n",
    "test_emb_df['image_path'] = test_images_unique\n",
    "\n",
    "print(f'Train embeddings df shape: {train_emb_df.shape}')\n",
    "print(f'Test embeddings df shape: {test_emb_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d9bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tabular features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_state = LabelEncoder()\n",
    "le_species = LabelEncoder()\n",
    "\n",
    "all_states = pd.concat([train_pivot['State'], pd.Series(['Unknown'])])\n",
    "all_species = pd.concat([train_pivot['Species'], pd.Series(['Unknown'])])\n",
    "\n",
    "le_state.fit(all_states)\n",
    "le_species.fit(all_species)\n",
    "\n",
    "train_pivot['State_enc'] = le_state.transform(train_pivot['State'])\n",
    "train_pivot['Species_enc'] = le_species.transform(train_pivot['Species'])\n",
    "\n",
    "print(f'States: {le_state.classes_}')\n",
    "print(f'Species count: {len(le_species.classes_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3582475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge embeddings with tabular features\n",
    "train_full = train_pivot.merge(train_emb_df, on='image_path')\n",
    "print(f'Train full shape: {train_full.shape}')\n",
    "\n",
    "# Define target columns and weights\n",
    "target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "target_weights = {'Dry_Green_g': 0.1, 'Dry_Dead_g': 0.1, 'Dry_Clover_g': 0.1, 'GDM_g': 0.2, 'Dry_Total_g': 0.5}\n",
    "\n",
    "# Define feature columns (1024 DINOv2-large + 4 tabular)\n",
    "feature_cols = ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'State_enc', 'Species_enc'] + emb_cols\n",
    "print(f'Number of features: {len(feature_cols)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74400d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weighted R2 metric\n",
    "def weighted_r2(y_true_dict, y_pred_dict, weights):\n",
    "    \"\"\"Calculate globally weighted R2 across all targets.\"\"\"\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_weights = []\n",
    "    \n",
    "    for target in y_true_dict.keys():\n",
    "        all_y_true.extend(y_true_dict[target])\n",
    "        all_y_pred.extend(y_pred_dict[target])\n",
    "        all_weights.extend([weights[target]] * len(y_true_dict[target]))\n",
    "    \n",
    "    all_y_true = np.array(all_y_true)\n",
    "    all_y_pred = np.array(all_y_pred)\n",
    "    all_weights = np.array(all_weights)\n",
    "    \n",
    "    y_mean = np.sum(all_weights * all_y_true) / np.sum(all_weights)\n",
    "    ss_res = np.sum(all_weights * (all_y_true - all_y_pred) ** 2)\n",
    "    ss_tot = np.sum(all_weights * (all_y_true - y_mean) ** 2)\n",
    "    \n",
    "    return 1 - ss_res / ss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing function to enforce biomass constraints\n",
    "# GDM = Dry_Green + Dry_Clover\n",
    "# Dry_Total = GDM + Dry_Dead\n",
    "def post_process_biomass(preds_dict):\n",
    "    \"\"\"Apply projection matrix to enforce biomass constraints.\"\"\"\n",
    "    # Order: Dry_Green, Dry_Clover, Dry_Dead, GDM, Dry_Total\n",
    "    ordered_cols = ['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\n",
    "    \n",
    "    # Stack predictions into matrix (5 x n_samples)\n",
    "    Y = np.vstack([preds_dict[col] for col in ordered_cols])\n",
    "    \n",
    "    # Constraint matrix C such that C @ Y = 0 for valid predictions\n",
    "    # Constraint 1: Dry_Green + Dry_Clover - GDM = 0\n",
    "    # Constraint 2: Dry_Dead + GDM - Dry_Total = 0\n",
    "    C = np.array([\n",
    "        [1, 1, 0, -1, 0],   # Dry_Green + Dry_Clover = GDM\n",
    "        [0, 0, 1, 1, -1]    # Dry_Dead + GDM = Dry_Total\n",
    "    ])\n",
    "    \n",
    "    # Projection matrix: P = I - C^T @ (C @ C^T)^-1 @ C\n",
    "    C_T = C.T\n",
    "    inv_CCt = np.linalg.inv(C @ C_T)\n",
    "    P = np.eye(5) - C_T @ inv_CCt @ C\n",
    "    \n",
    "    # Apply projection and clip to non-negative\n",
    "    Y_reconciled = (P @ Y).clip(min=0)\n",
    "    \n",
    "    # Return as dictionary\n",
    "    result = {}\n",
    "    for i, col in enumerate(ordered_cols):\n",
    "        result[col] = Y_reconciled[i]\n",
    "    \n",
    "    return result\n",
    "\n",
    "print('Post-processing function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d2f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Cross Validation with LightGBM\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "N_FOLDS = 5\n",
    "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Store OOF predictions\n",
    "oof_preds = {target: np.zeros(len(train_full)) for target in target_cols}\n",
    "oof_preds_pp = {target: np.zeros(len(train_full)) for target in target_cols}  # Post-processed\n",
    "fold_scores = []\n",
    "fold_scores_pp = []\n",
    "\n",
    "X = train_full[feature_cols].values\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f'\\n=== Fold {fold + 1} ===')\n",
    "    \n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    \n",
    "    fold_y_true = {}\n",
    "    fold_y_pred = {}\n",
    "    \n",
    "    for target in target_cols:\n",
    "        y = train_full[target].values\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'seed': 42\n",
    "        }\n",
    "        \n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "        \n",
    "        model_lgb = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=500,\n",
    "            valid_sets=[val_data],\n",
    "            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        preds = model_lgb.predict(X_val)\n",
    "        preds = np.clip(preds, 0, None)\n",
    "        \n",
    "        oof_preds[target][val_idx] = preds\n",
    "        fold_y_true[target] = y_val\n",
    "        fold_y_pred[target] = preds\n",
    "    \n",
    "    # Calculate fold R2 before post-processing\n",
    "    fold_r2 = weighted_r2(fold_y_true, fold_y_pred, target_weights)\n",
    "    fold_scores.append(fold_r2)\n",
    "    \n",
    "    # Apply post-processing\n",
    "    fold_y_pred_pp = post_process_biomass(fold_y_pred)\n",
    "    fold_r2_pp = weighted_r2(fold_y_true, fold_y_pred_pp, target_weights)\n",
    "    fold_scores_pp.append(fold_r2_pp)\n",
    "    \n",
    "    # Store post-processed predictions\n",
    "    for target in target_cols:\n",
    "        oof_preds_pp[target][val_idx] = fold_y_pred_pp[target]\n",
    "    \n",
    "    print(f'Fold {fold + 1} Weighted R2: {fold_r2:.4f} -> {fold_r2_pp:.4f} (post-processed)')\n",
    "\n",
    "print(f'\\n=== Overall CV Results ===')\n",
    "print(f'Mean Weighted R2 (raw): {np.mean(fold_scores):.4f} (+/- {np.std(fold_scores):.4f})')\n",
    "print(f'Mean Weighted R2 (post-processed): {np.mean(fold_scores_pp):.4f} (+/- {np.std(fold_scores_pp):.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209821fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall OOF weighted R2\n",
    "oof_y_true = {target: train_full[target].values for target in target_cols}\n",
    "overall_r2 = weighted_r2(oof_y_true, oof_preds, target_weights)\n",
    "overall_r2_pp = weighted_r2(oof_y_true, oof_preds_pp, target_weights)\n",
    "\n",
    "print(f'Overall OOF Weighted R2 (raw): {overall_r2:.4f}')\n",
    "print(f'Overall OOF Weighted R2 (post-processed): {overall_r2_pp:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e072c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final models on full data\n",
    "final_models = {}\n",
    "X_full = train_full[feature_cols].values\n",
    "\n",
    "for target in target_cols:\n",
    "    print(f'Training final model for {target}...')\n",
    "    y_full = train_full[target].values\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_full, label=y_full)\n",
    "    model_lgb = lgb.train(params, train_data, num_boost_round=500)\n",
    "    final_models[target] = model_lgb\n",
    "\n",
    "print('All final models trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test features\n",
    "test_features = test_emb_df.copy()\n",
    "test_features['Pre_GSHH_NDVI'] = train_pivot['Pre_GSHH_NDVI'].mean()\n",
    "test_features['Height_Ave_cm'] = train_pivot['Height_Ave_cm'].mean()\n",
    "test_features['State_enc'] = train_pivot['State_enc'].mode()[0]\n",
    "test_features['Species_enc'] = train_pivot['Species_enc'].mode()[0]\n",
    "\n",
    "X_test = test_features[feature_cols].values\n",
    "print(f'Test features shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65071d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for test set\n",
    "test_preds = {}\n",
    "for target in target_cols:\n",
    "    preds = final_models[target].predict(X_test)\n",
    "    preds = np.clip(preds, 0, None)\n",
    "    test_preds[target] = preds\n",
    "    print(f'{target}: mean={preds.mean():.2f}')\n",
    "\n",
    "# Apply post-processing\n",
    "test_preds_pp = post_process_biomass(test_preds)\n",
    "print('\\nAfter post-processing:')\n",
    "for target in target_cols:\n",
    "    print(f'{target}: mean={test_preds_pp[target].mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c6e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file with post-processed predictions\n",
    "submission_rows = []\n",
    "\n",
    "for i, img_path in enumerate(test_images_unique):\n",
    "    img_id = img_path.split('/')[-1].replace('.jpg', '')\n",
    "    \n",
    "    for target in target_cols:\n",
    "        sample_id = f'{img_id}__{target}'\n",
    "        pred_value = test_preds_pp[target][i]\n",
    "        submission_rows.append({'sample_id': sample_id, 'target': pred_value})\n",
    "\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "print(f'Submission shape: {submission_df.shape}')\n",
    "print(submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7466b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "submission_df.to_csv('/home/submission/submission.csv', index=False)\n",
    "print('Submission saved to /home/submission/submission.csv')\n",
    "\n",
    "# Verify format\n",
    "sample_sub = pd.read_csv('/home/data/sample_submission.csv')\n",
    "print(f'\\nSample submission columns: {sample_sub.columns.tolist()}')\n",
    "print(f'Our submission columns: {submission_df.columns.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print('='*60)\n",
    "print('EXPERIMENT 002 RESULTS SUMMARY')\n",
    "print('='*60)\n",
    "print(f'Model: DINOv2-large PATCH embeddings + LightGBM + Post-processing')\n",
    "print(f'Features: {len(feature_cols)} (1024 DINOv2-large patch + 4 tabular)')\n",
    "print(f'CV Folds: {N_FOLDS}')\n",
    "print(f'\\nRaw predictions:')\n",
    "print(f'  Mean CV Weighted R2: {np.mean(fold_scores):.4f} (+/- {np.std(fold_scores):.4f})')\n",
    "print(f'  Overall OOF Weighted R2: {overall_r2:.4f}')\n",
    "print(f'\\nPost-processed predictions:')\n",
    "print(f'  Mean CV Weighted R2: {np.mean(fold_scores_pp):.4f} (+/- {np.std(fold_scores_pp):.4f})')\n",
    "print(f'  Overall OOF Weighted R2: {overall_r2_pp:.4f}')\n",
    "print(f'\\nBaseline comparison: 0.7584 -> {overall_r2_pp:.4f} ({overall_r2_pp - 0.7584:+.4f})')\n",
    "print('='*60)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
