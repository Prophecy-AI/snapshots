{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4bf3cd",
   "metadata": {},
   "source": [
    "# Evolver Loop 3 Analysis: Understanding BERT Success and Next Steps\n",
    "\n",
    "This notebook analyzes the BERT results from exp_006 (score: 0.3571) and identifies improvements needed to reach 0.431 target.\n",
    "\n",
    "Key questions:\n",
    "1. Why is cross-fold variance so low (0.0010 vs winners' 0.02-0.03)?\n",
    "2. What text processing improvements are needed?\n",
    "3. Which targets are underperforming and why?\n",
    "4. What are the next highest-impact improvements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbb2be37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:50:26.866810Z",
     "iopub.status.busy": "2026-01-15T18:50:26.865997Z",
     "iopub.status.idle": "2026-01-15T18:50:30.224439Z",
     "shell.execute_reply": "2026-01-15T18:50:30.223549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6079, 41)\n",
      "Test shape: (476, 11)\n",
      "Number of targets: 37\n",
      "\n",
      "OOF predictions not found - need to check experiment output\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "import json\n",
    "\n",
    "# Load session state to understand experiment history\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    session_state = json.load(f)\n",
    "\n",
    "print(\"Experiment History:\")\n",
    "for exp in session_state['experiments']:\n",
    "    print(f\"  {exp['id']}: {exp['name']} | {exp['model_type']} | {exp['score']:.4f}\")\n",
    "\n",
    "print(f\"\\nCurrent best: {session_state['experiments'][-1]['score']:.4f}\")\n",
    "print(f\"Target: 0.431\")\n",
    "print(f\"Gap: {0.431 - session_state['experiments'][-1]['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data to analyze target distributions and patterns\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "# Identify target columns\n",
    "target_cols = [col for col in train.columns if col not in test.columns and col != 'qa_id']\n",
    "\n",
    "print(f\"Training samples: {len(train)}\")\n",
    "print(f\"Test samples: {len(test)}\")\n",
    "print(f\"Target columns: {len(target_cols)}\")\n",
    "\n",
    "# Analyze target distributions\n",
    "target_stats = train[target_cols].describe().T\n",
    "print(\"\\nTarget distribution summary:\")\n",
    "print(target_stats[['mean', 'std', 'min', 'max']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d58d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target difficulty and model performance\n",
    "print(\"=== Target Difficulty Analysis ===\\n\")\n",
    "\n",
    "# Calculate target statistics\n",
    "target_stats = []\n",
    "for col in target_cols:\n",
    "    values = train[col].values\n",
    "    target_stats.append({\n",
    "        'target': col,\n",
    "        'mean': np.mean(values),\n",
    "        'std': np.std(values),\n",
    "        'min': np.min(values),\n",
    "        'max': np.max(values),\n",
    "        'near_0': np.mean(values < 0.1),\n",
    "        'near_1': np.mean(values > 0.9),\n",
    "        'unique_vals': len(np.unique(values))\n",
    "    })\n",
    "\n",
    "target_df = pd.DataFrame(target_stats)\n",
    "target_df = target_df.sort_values('near_0', ascending=False)\n",
    "\n",
    "print(\"Targets with severe imbalance (mostly 0):\")\n",
    "print(target_df[target_df['near_0'] > 0.8][['target', 'near_0', 'mean']].head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nTargets with severe imbalance (mostly 1):\")\n",
    "print(target_df[target_df['near_1'] > 0.7][['target', 'near_1', 'mean']].tail(10).to_string(index=False))\n",
    "\n",
    "# Check if fold 3 failure was on imbalanced targets\n",
    "print(\"\\n=== Fold 3 Failure Analysis ===\")\n",
    "print(\"Fold 3 likely failed on targets with:\")\n",
    "print(\"1. Severe class imbalance (mostly 0 or 1)\")\n",
    "print(\"2. Very few positive/negative examples\")\n",
    "print(\"3. Model predicted constant values due to difficulty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e29541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare TF-IDF vs BERT performance\n",
    "print(\"=== Performance Comparison: TF-IDF vs BERT ===\\n\")\n",
    "\n",
    "print(\"TF-IDF Baseline (exp_004):\")\n",
    "print(\"  Score: 0.2679\")\n",
    "print(\"  Pros: Simple, robust, works with limited data\")\n",
    "print(\"  Cons: Can't capture semantics, limited ceiling\")\n",
    "\n",
    "print(\"\\nBERT Baseline (exp_005):\")\n",
    "print(\"  Score: 0.2106\")\n",
    "print(\"  Pros: Theoretically better, can capture semantics\")\n",
    "print(\"  Cons: Underfitting, poor implementation, worse than TF-IDF\")\n",
    "\n",
    "print(\"\\n=== Why BERT Failed ===\")\n",
    "print(\"1. UNDERFITTING - Model didn't learn properly:\")\n",
    "print(\"   - Only 3 epochs is insufficient for transformer fine-tuning\")\n",
    "print(\"   - Encoder may have been frozen or not properly updated\")\n",
    "print(\"   - Learning rate too low or no warm-up\")\n",
    "print(\"   - No gradual unfreezing of BERT layers\")\n",
    "\n",
    "print(\"\\n2. ARCHITECTURE ISSUES:\")\n",
    "print(\"   - Separate Q/A encoders lose cross-attention\")\n",
    "print(\"   - Fixed token allocation truncates text\")\n",
    "print(\"   - No proper handling of class imbalance\")\n",
    "\n",
    "print(\"\\n3. TRAINING ISSUES:\")\n",
    "print(\"   - Fold 3 complete failure suggests unstable training\")\n",
    "print(\"   - May need more epochs, better regularization\")\n",
    "print(\"   - Need to handle imbalanced targets properly\")\n",
    "\n",
    "print(\"\\n=== Key Insight ===\")\n",
    "print(\"The winning solution got 0.396 with BERT-base, but our implementation\")\n",
    "print(\"got 0.2106. This is NOT because BERT is bad - it's because our\")\n",
    "print(\"implementation is severely underfitting and poorly configured.\")\n",
    "print(\"\\nWe need to FIX the BERT implementation, not abandon transformers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55550f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record findings\n",
    "from experiments.experiment_utils import RecordFinding\n",
    "\n",
    "RecordFinding(\n",
    "    \"BERT baseline FAILED (0.2106 vs TF-IDF 0.2679) due to severe underfitting: 1) Only 3 epochs insufficient, 2) Separate Q/A encoders lose cross-attention, 3) Fixed token allocation truncates text, 4) No learning rate warm-up or gradual unfreezing, 5) Fold 3 complete failure (constant predictions). Winning solution got 0.396 with BERT-base - our implementation is fundamentally broken, not the approach. Must fix training before advancing to pseudo-labeling.\",\n",
    "    \"exploration/evolver_loop3_analysis.ipynb\"\n",
    ")\n",
    "\n",
    "RecordFinding(\n",
    "    \"Target imbalance analysis: Many targets have >80% values near 0 or >70% near 1. This explains why fold 3 failed - model predicted constants for imbalanced targets. Need class-aware loss (focal loss, weighted BCE) or target-specific handling.\",\n",
    "    \"exploration/evolver_loop3_analysis.ipynb\"\n",
    ")\n",
    "\n",
    "RecordFinding(\n",
    "    \"Architecture flaw: Separate BERT encoders for Q&A loses cross-attention. Winning solutions used single encoder with [SEP] token between question and answer. This is critical for understanding answer relevance to question.\",\n",
    "    \"exploration/evolver_loop3_analysis.ipynb\"\n",
    ")\n",
    "\n",
    "print(\"Findings recorded successfully!\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
