{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5158faf",
   "metadata": {},
   "source": [
    "# DBSCAN Post-Processing for exp_007\n",
    "\n",
    "Implement DBSCAN clustering post-processing as described in the 77th place writeup.\n",
    "This technique smooths predictions by clustering nearby values and replacing with cluster medians.\n",
    "\n",
    "Expected improvement: +0.025-0.030 (0.3612 → 0.386-0.391)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3853a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T01:58:09.212221Z",
     "iopub.status.busy": "2026-01-16T01:58:09.211490Z",
     "iopub.status.idle": "2026-01-16T01:58:09.405834Z",
     "shell.execute_reply": "2026-01-16T01:58:09.405036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF predictions shape: (6079, 30)\n",
      "Number of target columns: 30\n",
      "OOF DataFrame shape: (6079, 30)\n",
      "\n",
      "First few predictions:\n",
      "   question_asker_intent_understanding  question_body_critical  \\\n",
      "0                             0.908157                0.569118   \n",
      "1                             0.968442                0.832744   \n",
      "2                             0.862698                0.538458   \n",
      "3                             0.910688                0.556180   \n",
      "4                             0.922277                0.705731   \n",
      "\n",
      "   question_conversational  question_expect_short_answer  \\\n",
      "0                 0.039477                      0.441199   \n",
      "1                 0.001391                      0.833066   \n",
      "2                 0.002122                      0.671444   \n",
      "3                 0.042393                      0.807721   \n",
      "4                 0.000006                      0.787416   \n",
      "\n",
      "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
      "0               0.688862                               0.385393   \n",
      "1               0.970581                               0.789190   \n",
      "2               0.799627                               0.789261   \n",
      "3               0.733370                               0.816682   \n",
      "4               0.910169                               0.957709   \n",
      "\n",
      "   question_interestingness_others  question_interestingness_self  \\\n",
      "0                         0.647304                       0.611451   \n",
      "1                         0.604247                       0.633410   \n",
      "2                         0.548345                       0.464186   \n",
      "3                         0.569873                       0.526813   \n",
      "4                         0.599102                       0.502731   \n",
      "\n",
      "   question_multi_intent  question_not_really_a_question  ...  \\\n",
      "0               0.692943                    3.655243e-07  ...   \n",
      "1               0.165474                    3.404426e-08  ...   \n",
      "2               0.336533                    2.491431e-05  ...   \n",
      "3               0.202703                    5.760608e-08  ...   \n",
      "4               0.154962                    2.365628e-08  ...   \n",
      "\n",
      "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
      "0               0.841079        0.917862                     0.653298   \n",
      "1               0.908443        0.907255                     0.619757   \n",
      "2               0.775895        0.910243                     0.673180   \n",
      "3               0.843515        0.957158                     0.648866   \n",
      "4               0.859013        0.920584                     0.619310   \n",
      "\n",
      "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
      "0          0.972765          0.973591             0.852140   \n",
      "1          0.935804          0.978156             0.848772   \n",
      "2          0.944332          0.953284             0.852665   \n",
      "3          0.972251          0.975775             0.886329   \n",
      "4          0.965367          0.972221             0.845093   \n",
      "\n",
      "   answer_type_instructions  answer_type_procedure  \\\n",
      "0                  0.171964               0.099225   \n",
      "1                  0.035451               0.002313   \n",
      "2                  0.615357               0.291387   \n",
      "3                  0.028070               0.050681   \n",
      "4                  0.944030               0.079216   \n",
      "\n",
      "   answer_type_reason_explanation  answer_well_written  \n",
      "0                        0.862313             0.902011  \n",
      "1                        0.346335             0.951488  \n",
      "2                        0.463298             0.909353  \n",
      "3                        0.801651             0.933391  \n",
      "4                        0.026899             0.857417  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.stats import spearmanr\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import gc\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "# Identify target columns\n",
    "meta_cols = ['qa_id', 'question_title', 'question_body', 'question_user_name', \n",
    "             'question_user_page', 'answer', 'answer_user_name', 'answer_user_page', \n",
    "             'url', 'category', 'host']\n",
    "target_cols = [c for c in train_df.columns if c not in meta_cols]\n",
    "\n",
    "print(f\"Number of target columns: {len(target_cols)}\")\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1daf7b5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T01:58:09.408179Z",
     "iopub.status.busy": "2026-01-16T01:58:09.407639Z",
     "iopub.status.idle": "2026-01-16T01:58:09.590411Z",
     "shell.execute_reply": "2026-01-16T01:58:09.589785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 41\n",
      "First 10 columns: ['qa_id', 'question_title', 'question_body', 'question_user_name', 'question_user_page', 'answer', 'answer_user_name', 'answer_user_page', 'url', 'category']\n",
      "Last 10 columns: ['question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
      "\n",
      "Number of target columns: 30\n",
      "Target columns: ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
      "\n",
      "OOF predictions shape: (6079, 30)\n",
      "Test predictions file not found\n"
     ]
    }
   ],
   "source": [
    "# Let's check the actual columns in train.csv and understand the target structure\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "all_cols = list(train_df.columns)\n",
    "print(f\"Total columns: {len(all_cols)}\")\n",
    "print(f\"First 10 columns: {all_cols[:10]}\")\n",
    "print(f\"Last 10 columns: {all_cols[-10:]}\")\n",
    "\n",
    "# Identify target columns (excluding metadata columns)\n",
    "meta_cols = ['qa_id', 'question_title', 'question_body', 'question_user_name', \n",
    "             'question_user_page', 'answer', 'answer_user_name', 'answer_user_page', \n",
    "             'url', 'category', 'host']\n",
    "\n",
    "target_cols = [c for c in all_cols if c not in meta_cols]\n",
    "print(f\"\\nNumber of target columns: {len(target_cols)}\")\n",
    "print(f\"Target columns: {target_cols}\")\n",
    "\n",
    "# Check OOF predictions shape again\n",
    "oof_preds = np.load('/home/code/experiments/004_bert_token_type_ids/oof_predictions.npy')\n",
    "print(f\"\\nOOF predictions shape: {oof_preds.shape}\")\n",
    "\n",
    "# Check if test predictions exist and their shape\n",
    "try:\n",
    "    test_preds = np.load('/home/code/experiments/004_bert_token_type_ids/test_predictions.npy')\n",
    "    print(f\"Test predictions shape: {test_preds.shape}\")\n",
    "except:\n",
    "    print(\"Test predictions file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbdbbad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T01:58:09.592524Z",
     "iopub.status.busy": "2026-01-16T01:58:09.592097Z",
     "iopub.status.idle": "2026-01-16T01:58:09.604913Z",
     "shell.execute_reply": "2026-01-16T01:58:09.604392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF predictions shape: (6079, 30)\n",
      "OOF DataFrame shape: (6079, 30)\n",
      "\n",
      "First few predictions:\n",
      "   question_asker_intent_understanding  question_body_critical  \\\n",
      "0                             0.908157                0.569118   \n",
      "1                             0.968442                0.832744   \n",
      "2                             0.862698                0.538458   \n",
      "3                             0.910688                0.556180   \n",
      "4                             0.922277                0.705731   \n",
      "\n",
      "   question_conversational  question_expect_short_answer  \\\n",
      "0                 0.039477                      0.441199   \n",
      "1                 0.001391                      0.833066   \n",
      "2                 0.002122                      0.671444   \n",
      "3                 0.042393                      0.807721   \n",
      "4                 0.000006                      0.787416   \n",
      "\n",
      "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
      "0               0.688862                               0.385393   \n",
      "1               0.970581                               0.789190   \n",
      "2               0.799627                               0.789261   \n",
      "3               0.733370                               0.816682   \n",
      "4               0.910169                               0.957709   \n",
      "\n",
      "   question_interestingness_others  question_interestingness_self  \\\n",
      "0                         0.647304                       0.611451   \n",
      "1                         0.604247                       0.633410   \n",
      "2                         0.548345                       0.464186   \n",
      "3                         0.569873                       0.526813   \n",
      "4                         0.599102                       0.502731   \n",
      "\n",
      "   question_multi_intent  question_not_really_a_question  ...  \\\n",
      "0               0.692943                    3.655243e-07  ...   \n",
      "1               0.165474                    3.404426e-08  ...   \n",
      "2               0.336533                    2.491431e-05  ...   \n",
      "3               0.202703                    5.760608e-08  ...   \n",
      "4               0.154962                    2.365628e-08  ...   \n",
      "\n",
      "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
      "0               0.841079        0.917862                     0.653298   \n",
      "1               0.908443        0.907255                     0.619757   \n",
      "2               0.775895        0.910243                     0.673180   \n",
      "3               0.843515        0.957158                     0.648866   \n",
      "4               0.859013        0.920584                     0.619310   \n",
      "\n",
      "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
      "0          0.972765          0.973591             0.852140   \n",
      "1          0.935804          0.978156             0.848772   \n",
      "2          0.944332          0.953284             0.852665   \n",
      "3          0.972251          0.975775             0.886329   \n",
      "4          0.965367          0.972221             0.845093   \n",
      "\n",
      "   answer_type_instructions  answer_type_procedure  \\\n",
      "0                  0.171964               0.099225   \n",
      "1                  0.035451               0.002313   \n",
      "2                  0.615357               0.291387   \n",
      "3                  0.028070               0.050681   \n",
      "4                  0.944030               0.079216   \n",
      "\n",
      "   answer_type_reason_explanation  answer_well_written  \n",
      "0                        0.862313             0.902011  \n",
      "1                        0.346335             0.951488  \n",
      "2                        0.463298             0.909353  \n",
      "3                        0.801651             0.933391  \n",
      "4                        0.026899             0.857417  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load OOF predictions from exp_007\n",
    "oof_preds = np.load('/home/code/experiments/004_bert_token_type_ids/oof_predictions.npy')\n",
    "print(f\"OOF predictions shape: {oof_preds.shape}\")\n",
    "\n",
    "# Verify shape matches targets\n",
    "assert oof_preds.shape[1] == len(target_cols), f\"Shape mismatch: {oof_preds.shape[1]} vs {len(target_cols)}\"\n",
    "\n",
    "# Create DataFrame for easier handling\n",
    "oof_df = pd.DataFrame(oof_preds, columns=target_cols)\n",
    "print(f\"OOF DataFrame shape: {oof_df.shape}\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(oof_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7f39b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T01:58:09.606908Z",
     "iopub.status.busy": "2026-01-16T01:58:09.606353Z",
     "iopub.status.idle": "2026-01-16T01:58:09.677806Z",
     "shell.execute_reply": "2026-01-16T01:58:09.677225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline CV score: 0.351537\n",
      "Expected (exp_007): 0.3612008823544772\n"
     ]
    }
   ],
   "source": [
    "# Calculate baseline CV score (should match exp_007: 0.3612)\n",
    "def calculate_spearman(y_true, y_pred):\n",
    "    \"\"\"Calculate mean Spearman correlation across all targets\"\"\"\n",
    "    scores = []\n",
    "    for i, col in enumerate(target_cols):\n",
    "        score = spearmanr(y_true[col], y_pred[:, i]).correlation\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "baseline_score = calculate_spearman(train_df[target_cols], oof_preds)\n",
    "print(f\"Baseline CV score: {baseline_score:.6f}\")\n",
    "print(f\"Expected (exp_007): 0.3612008823544772\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27702e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement DBSCAN post-processing\n",
    "def dbscan_postprocess(predictions, eps_percentile=0.95, min_samples=2):\n",
    "    \"\"\"\n",
    "    Apply DBSCAN clustering to smooth predictions.\n",
    "    For each target column:\n",
    "    1. Sort predictions and compute differences\n",
    "    2. Set eps = percentile of differences (default: 95th percentile)\n",
    "    3. Apply DBSCAN clustering\n",
    "    4. Replace each cluster's predictions with cluster median\n",
    "    \"\"\"\n",
    "    processed_preds = predictions.copy()\n",
    "    \n",
    "    for i in range(predictions.shape[1]):\n",
    "        col_preds = predictions[:, i]\n",
    "        \n",
    "        # Sort predictions and compute differences\n",
    "        sorted_idx = np.argsort(col_preds)\n",
    "        sorted_preds = col_preds[sorted_idx]\n",
    "        \n",
    "        # Compute differences between consecutive sorted values\n",
    "        diffs = np.diff(sorted_preds)\n",
    "        \n",
    "        # Set eps as percentile of differences\n",
    "        if len(diffs) > 0:\n",
    "            eps = np.percentile(diffs, eps_percentile * 100)\n",
    "            \n",
    "            # Apply DBSCAN\n",
    "            # Reshape for sklearn (n_samples, n_features)\n",
    "            X = col_preds.reshape(-1, 1)\n",
    "            db = DBSCAN(eps=eps, min_samples=min_samples).fit(X)\n",
    "            \n",
    "            # Get cluster labels (-1 = noise/outliers)\n",
    "            labels = db.labels_\n",
    "            \n",
    "            # Replace each cluster's predictions with median\n",
    "            unique_labels = set(labels)\n",
    "            for label in unique_labels:\n",
    "                if label == -1:  # Skip noise points\n",
    "                    continue\n",
    "                \n",
    "                # Get indices for this cluster\n",
    "                cluster_mask = labels == label\n",
    "                if np.sum(cluster_mask) >= min_samples:\n",
    "                    # Replace with median of cluster\n",
    "                    cluster_median = np.median(col_preds[cluster_mask])\n",
    "                    processed_preds[cluster_mask, i] = cluster_median\n",
    "    \n",
    "    return processed_preds\n",
    "\n",
    "# Test with different eps percentiles\n",
    "for percentile in [0.90, 0.95, 0.98]:\n",
    "    processed = dbscan_postprocess(oof_preds, eps_percentile=percentile)\n",
    "    score = calculate_spearman(train_df[target_cols], processed)\n",
    "    print(f\"DBSCAN (eps={percentile:.2f}): {score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d50f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best percentile and apply to OOF predictions\n",
    "best_percentile = 0.95  # Based on typical results from writeup\n",
    "processed_oof = dbscan_postprocess(oof_preds, eps_percentile=best_percentile)\n",
    "\n",
    "# Calculate final score\n",
    "final_score = calculate_spearman(train_df[target_cols], processed_oof)\n",
    "print(f\"Final CV score after DBSCAN: {final_score:.6f}\")\n",
    "print(f\"Improvement: +{final_score - baseline_score:.6f}\")\n",
    "\n",
    "# Save processed OOF predictions\n",
    "np.save('/home/code/experiments/005_dbscan_postprocessing/processed_oof_predictions.npy', processed_oof)\n",
    "print(f\"\\nSaved processed OOF predictions to: /home/code/experiments/005_dbscan_postprocessing/processed_oof_predictions.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed OOF predictions\n",
    "np.save('/home/code/experiments/005_dbscan_postprocessing/processed_oof_predictions.npy', processed_oof)\n",
    "print(f\"Saved processed OOF predictions to: /home/code/experiments/005_dbscan_postprocessing/processed_oof_predictions.npy\")\n",
    "\n",
    "# Calculate per-target improvements\n",
    "print(\"\\nPer-target improvements:\")\n",
    "for i, col in enumerate(target_cols):\n",
    "    baseline_target = spearmanr(train_df[col], oof_preds[:, i]).correlation\n",
    "    processed_target = spearmanr(train_df[col], processed_oof[:, i]).correlation\n",
    "    improvement = processed_target - baseline_target\n",
    "    if abs(improvement) > 0.001:  # Only show meaningful changes\n",
    "        print(f\"{col}: {baseline_target:.4f} → {processed_target:.4f} ({improvement:+.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test predictions from exp_007 models\n",
    "# Since test_predictions.npy doesn't exist, we need to generate it\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Initialize test predictions array\n",
    "test_predictions = np.zeros((len(test_df), len(target_cols)))\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create test dataset\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=512):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Combine question title, body, and answer with separators\n",
    "        text = f\"[CLS] {row['question_title']} [SEP] {row['question_body']} [SEP] {row['answer']} [SEP]\"\n",
    "        \n",
    "        # Tokenize with token_type_ids\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=False,  # We already added [CLS] and [SEP]\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Create token_type_ids (0 for question, 1 for answer)\n",
    "        # Find positions of [SEP] tokens\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        sep_positions = (input_ids == self.tokenizer.sep_token_id).nonzero(as_tuple=True)[0]\n",
    "        \n",
    "        token_type_ids = torch.zeros_like(input_ids)\n",
    "        if len(sep_positions) >= 2:\n",
    "            # After second [SEP] is answer part\n",
    "            answer_start = sep_positions[1] + 1\n",
    "            token_type_ids[answer_start:] = 1\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'token_type_ids': token_type_ids\n",
    "        }\n",
    "\n",
    "# Create test dataset and dataloader\n",
    "test_dataset = TestDataset(test_df, tokenizer, max_length=512)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Test dataset created with {len(test_dataset)} samples\")\n",
    "print(f\"Test dataloader has {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00f4df41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:10:43.685329Z",
     "iopub.status.busy": "2026-01-16T02:10:43.684577Z",
     "iopub.status.idle": "2026-01-16T02:10:43.974178Z",
     "shell.execute_reply": "2026-01-16T02:10:43.973607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint keys: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias']\n",
      "\n",
      "Checkpoint type: <class 'collections.OrderedDict'>\n",
      "\n",
      "This appears to be a direct state dict\n",
      "Keys (first 10): ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight']\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture (same as exp_007)\n",
    "class BERTQuestionAnswering(nn.Module):\n",
    "    def __init__(self, model_name='bert-base-uncased', num_labels=30):\n",
    "        super(BERTQuestionAnswering, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Generate predictions for each fold\n",
    "fold_predictions = []\n",
    "\n",
    "for fold in range(5):\n",
    "    print(f\"\\nGenerating predictions for fold {fold}...\")\n",
    "    \n",
    "    # Load model\n",
    "    model_path = f'/home/code/experiments/004_bert_token_type_ids/best_model_fold_{fold}.pth'\n",
    "    model = BERTQuestionAnswering('bert-base-uncased', num_labels=len(target_cols))\n",
    "    \n",
    "    # Load checkpoint (direct state dict)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Generate predictions\n",
    "    fold_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            fold_pred.append(outputs.cpu().numpy())\n",
    "    \n",
    "    # Concatenate predictions\n",
    "    fold_pred = np.concatenate(fold_pred, axis=0)\n",
    "    fold_predictions.append(fold_pred)\n",
    "    \n",
    "    print(f\"Fold {fold} predictions shape: {fold_pred.shape}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Average predictions across folds\n",
    "test_predictions = np.mean(fold_predictions, axis=0)\n",
    "print(f\"\\nFinal test predictions shape: {test_predictions.shape}\")\n",
    "\n",
    "# Save test predictions\n",
    "np.save('/home/code/experiments/004_bert_token_type_ids/test_predictions.npy', test_predictions)\n",
    "np.save('/home/code/experiments/005_dbscan_postprocessing/test_predictions_before_postprocessing.npy', test_predictions)\n",
    "print(\"Test predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec8684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture (same as exp_007)\n",
    "class BERTQuestionAnswering(nn.Module):\n",
    "    def __init__(self, model_name='bert-base-uncased', num_labels=30):\n",
    "        super(BERTQuestionAnswering, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Generate predictions for each fold\n",
    "fold_predictions = []\n",
    "\n",
    "for fold in range(5):\n",
    "    print(f\"\\nGenerating predictions for fold {fold}...\")\n",
    "    \n",
    "    # Load model\n",
    "    model_path = f'/home/code/experiments/004_bert_token_type_ids/best_model_fold_{fold}.pth'\n",
    "    model = BERTQuestionAnswering('bert-base-uncased', num_labels=len(target_cols))\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Generate predictions\n",
    "    fold_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            fold_pred.append(outputs.cpu().numpy())\n",
    "    \n",
    "    # Concatenate predictions\n",
    "    fold_pred = np.concatenate(fold_pred, axis=0)\n",
    "    fold_predictions.append(fold_pred)\n",
    "    \n",
    "    print(f\"Fold {fold} predictions shape: {fold_pred.shape}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Average predictions across folds\n",
    "test_predictions = np.mean(fold_predictions, axis=0)\n",
    "print(f\"\\nFinal test predictions shape: {test_predictions.shape}\")\n",
    "\n",
    "# Save test predictions\n",
    "np.save('/home/code/experiments/004_bert_token_type_ids/test_predictions.npy', test_predictions)\n",
    "np.save('/home/code/experiments/005_dbscan_postprocessing/test_predictions_before_postprocessing.npy', test_predictions)\n",
    "print(\"Test predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e9f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "# First check sample submission format\n",
    "sample_sub = pd.read_csv('/home/data/sample_submission.csv')\n",
    "print(\"Sample submission format:\")\n",
    "print(sample_sub.head())\n",
    "print(f\"\\nColumns: {list(sample_sub.columns)}\")\n",
    "print(f\"Shape: {sample_sub.shape}\")\n",
    "\n",
    "# Verify our predictions match the expected format\n",
    "assert processed_test.shape[1] == len(target_cols), f\"Prediction shape mismatch\"\n",
    "assert len(test_df) == len(processed_test), f\"Row count mismatch\"\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'qa_id': test_df['qa_id'],\n",
    "})\n",
    "\n",
    "# Add predictions for each target column\n",
    "for i, col in enumerate(target_cols):\n",
    "    submission[col] = processed_test[:, i]\n",
    "\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"\\nSaved submission to: /home/submission/submission.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
