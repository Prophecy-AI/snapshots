{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5158faf",
   "metadata": {},
   "source": [
    "# DBSCAN Post-Processing for exp_007\n",
    "\n",
    "Implement DBSCAN clustering post-processing as described in the 77th place writeup.\n",
    "This technique smooths predictions by clustering nearby values and replacing with cluster medians.\n",
    "\n",
    "Expected improvement: +0.025-0.030 (0.3612 â†’ 0.386-0.391)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3853a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.stats import spearmanr\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "target_cols = [c for c in train_df.columns if c not in ['qa_id', 'question_title', 'question_body', 'answer']]\n",
    "\n",
    "print(f\"Number of target columns: {len(target_cols)}\")\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the actual columns in train.csv and understand the target structure\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "all_cols = list(train_df.columns)\n",
    "print(f\"Total columns: {len(all_cols)}\")\n",
    "print(f\"First 10 columns: {all_cols[:10]}\")\n",
    "print(f\"Last 10 columns: {all_cols[-10:]}\")\n",
    "\n",
    "# Identify target columns (excluding metadata columns)\n",
    "meta_cols = ['qa_id', 'question_title', 'question_body', 'question_user_name', \n",
    "             'question_user_page', 'answer', 'answer_user_name', 'answer_user_page', \n",
    "             'url', 'category', 'host']\n",
    "\n",
    "target_cols = [c for c in all_cols if c not in meta_cols]\n",
    "print(f\"\\nNumber of target columns: {len(target_cols)}\")\n",
    "print(f\"Target columns: {target_cols}\")\n",
    "\n",
    "# Check OOF predictions shape again\n",
    "oof_preds = np.load('/home/code/experiments/004_bert_token_type_ids/oof_predictions.npy')\n",
    "print(f\"\\nOOF predictions shape: {oof_preds.shape}\")\n",
    "\n",
    "# Check if test predictions exist and their shape\n",
    "try:\n",
    "    test_preds = np.load('/home/code/experiments/004_bert_token_type_ids/test_predictions.npy')\n",
    "    print(f\"Test predictions shape: {test_preds.shape}\")\n",
    "except:\n",
    "    print(\"Test predictions file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdbbad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OOF predictions from exp_007\n",
    "oof_preds = np.load('/home/code/experiments/004_bert_token_type_ids/oof_predictions.npy')\n",
    "print(f\"OOF predictions shape: {oof_preds.shape}\")\n",
    "\n",
    "# Verify shape matches targets\n",
    "assert oof_preds.shape[1] == len(target_cols), f\"Shape mismatch: {oof_preds.shape[1]} vs {len(target_cols)}\"\n",
    "\n",
    "# Create DataFrame for easier handling\n",
    "oof_df = pd.DataFrame(oof_preds, columns=target_cols)\n",
    "print(f\"OOF DataFrame shape: {oof_df.shape}\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(oof_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f39b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baseline CV score (should match exp_007: 0.3612)\n",
    "def calculate_spearman(y_true, y_pred):\n",
    "    \"\"\"Calculate mean Spearman correlation across all targets\"\"\"\n",
    "    scores = []\n",
    "    for i, col in enumerate(target_cols):\n",
    "        score = spearmanr(y_true[col], y_pred[:, i]).correlation\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "baseline_score = calculate_spearman(train_df[target_cols], oof_preds)\n",
    "print(f\"Baseline CV score: {baseline_score:.6f}\")\n",
    "print(f\"Expected (exp_007): 0.3612008823544772\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27702e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement DBSCAN post-processing\n",
    "def dbscan_postprocess(predictions, eps_percentile=0.95, min_samples=2):\n",
    "    \"\"\"\n",
    "    Apply DBSCAN clustering to smooth predictions.\n",
    "    For each target column:\n",
    "    1. Sort predictions and compute differences\n",
    "    2. Set eps = percentile of differences (default: 95th percentile)\n",
    "    3. Apply DBSCAN clustering\n",
    "    4. Replace each cluster's predictions with cluster median\n",
    "    \"\"\"\n",
    "    processed_preds = predictions.copy()\n",
    "    \n",
    "    for i in range(predictions.shape[1]):\n",
    "        col_preds = predictions[:, i]\n",
    "        \n",
    "        # Sort predictions and compute differences\n",
    "        sorted_idx = np.argsort(col_preds)\n",
    "        sorted_preds = col_preds[sorted_idx]\n",
    "        \n",
    "        # Compute differences between consecutive sorted values\n",
    "        diffs = np.diff(sorted_preds)\n",
    "        \n",
    "        # Set eps as percentile of differences\n",
    "        if len(diffs) > 0:\n",
    "            eps = np.percentile(diffs, eps_percentile * 100)\n",
    "            \n",
    "            # Apply DBSCAN\n",
    "            # Reshape for sklearn (n_samples, n_features)\n",
    "            X = col_preds.reshape(-1, 1)\n",
    "            db = DBSCAN(eps=eps, min_samples=min_samples).fit(X)\n",
    "            \n",
    "            # Get cluster labels (-1 = noise/outliers)\n",
    "            labels = db.labels_\n",
    "            \n",
    "            # Replace each cluster's predictions with median\n",
    "            unique_labels = set(labels)\n",
    "            for label in unique_labels:\n",
    "                if label == -1:  # Skip noise points\n",
    "                    continue\n",
    "                \n",
    "                # Get indices for this cluster\n",
    "                cluster_mask = labels == label\n",
    "                if np.sum(cluster_mask) >= min_samples:\n",
    "                    # Replace with median of cluster\n",
    "                    cluster_median = np.median(col_preds[cluster_mask])\n",
    "                    processed_preds[cluster_mask, i] = cluster_median\n",
    "    \n",
    "    return processed_preds\n",
    "\n",
    "# Test with different eps percentiles\n",
    "for percentile in [0.90, 0.95, 0.98]:\n",
    "    processed = dbscan_postprocess(oof_preds, eps_percentile=percentile)\n",
    "    score = calculate_spearman(train_df[target_cols], processed)\n",
    "    print(f\"DBSCAN (eps={percentile:.2f}): {score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d50f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best percentile and apply to OOF predictions\n",
    "best_percentile = 0.95  # Based on typical results from writeup\n",
    "processed_oof = dbscan_postprocess(oof_preds, eps_percentile=best_percentile)\n",
    "\n",
    "# Calculate final score\n",
    "final_score = calculate_spearman(train_df[target_cols], processed_oof)\n",
    "print(f\"Final CV score after DBSCAN: {final_score:.6f}\")\n",
    "print(f\"Improvement: +{final_score - baseline_score:.6f}\")\n",
    "\n",
    "# Save processed OOF predictions\n",
    "np.save('/home/code/experiments/005_dbscan_postprocessing/processed_oof_predictions.npy', processed_oof)\n",
    "print(f\"\\nSaved processed OOF predictions to: /home/code/experiments/005_dbscan_postprocessing/processed_oof_predictions.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test predictions from exp_007 and apply same post-processing\n",
    "test_preds = np.load('/home/code/experiments/004_bert_token_type_ids/test_predictions.npy')\n",
    "print(f\"Test predictions shape: {test_preds.shape}\")\n",
    "\n",
    "# Apply DBSCAN post-processing to test predictions\n",
    "# Note: We use the same eps_percentile as for OOF\n",
    "processed_test = dbscan_postprocess(test_preds, eps_percentile=best_percentile)\n",
    "\n",
    "# Save processed test predictions\n",
    "np.save('/home/code/experiments/005_dbscan_postprocessing/processed_test_predictions.npy', processed_test)\n",
    "print(f\"Saved processed test predictions to: /home/code/experiments/005_dbscan_postprocessing/processed_test_predictions.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e9f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "# First check sample submission format\n",
    "sample_sub = pd.read_csv('/home/data/sample_submission.csv')\n",
    "print(\"Sample submission format:\")\n",
    "print(sample_sub.head())\n",
    "print(f\"\\nColumns: {list(sample_sub.columns)}\")\n",
    "print(f\"Shape: {sample_sub.shape}\")\n",
    "\n",
    "# Verify our predictions match the expected format\n",
    "assert processed_test.shape[1] == len(target_cols), f\"Prediction shape mismatch\"\n",
    "assert len(test_df) == len(processed_test), f\"Row count mismatch\"\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'qa_id': test_df['qa_id'],\n",
    "})\n",
    "\n",
    "# Add predictions for each target column\n",
    "for i, col in enumerate(target_cols):\n",
    "    submission[col] = processed_test[:, i]\n",
    "\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"\\nSaved submission to: /home/submission/submission.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
