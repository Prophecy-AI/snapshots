{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ba4887",
   "metadata": {},
   "source": [
    "# Baseline Model for Google QUEST Challenge\n",
    "\n",
    "This notebook implements a simple baseline using TF-IDF features and a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ccd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "sample_submission = pd.read_csv('/home/data/sample_submission.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "\n",
    "# Identify target columns\n",
    "target_cols = [col for col in train.columns if col not in test.columns and col != 'qa_id']\n",
    "print(f\"Number of target columns: {len(target_cols)}\")\n",
    "print(f\"Target columns: {target_cols[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text features\n",
    "train['text'] = train['question_title'].fillna('') + ' ' + train['question_body'].fillna('') + ' ' + train['answer'].fillna('')\n",
    "test['text'] = test['question_title'].fillna('') + ' ' + test['question_body'].fillna('') + ' ' + test['answer'].fillna('')\n",
    "\n",
    "# Create TF-IDF features\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(train['text'])\n",
    "X_test_tfidf = vectorizer.transform(test['text'])\n",
    "\n",
    "print(f\"TF-IDF feature shape: {X_train_tfidf.shape}\")\n",
    "\n",
    "# Prepare target matrix\n",
    "y_train = train[target_cols].values\n",
    "print(f\"Target shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6367cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Store predictions\n",
    "oof_predictions = np.zeros_like(y_train)\n",
    "test_predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "# Train model for each target\n",
    "scores = []\n",
    "\n",
    "for target_idx, target in enumerate(target_cols):\n",
    "    print(f\"Training for target: {target} ({target_idx+1}/{len(target_cols)})\")\n",
    "    \n",
    "    target_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_tfidf)):\n",
    "        X_tr, X_val = X_train_tfidf[train_idx], X_train_tfidf[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx, target_idx], y_train[val_idx, target_idx]\n",
    "        \n",
    "        # Train Ridge regression\n",
    "        model = Ridge(alpha=1.0, random_state=42)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        \n",
    "        # Predict\n",
    "        val_pred = model.predict(X_val)\n",
    "        oof_predictions[val_idx, target_idx] = val_pred\n",
    "        \n",
    "        # Calculate RMSE for this fold\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "        target_scores.append(rmse)\n",
    "        \n",
    "        # Predict on test\n",
    "        test_pred = model.predict(X_test_tfidf)\n",
    "        test_predictions[:, target_idx] += test_pred / n_folds\n",
    "    \n",
    "    mean_score = np.mean(target_scores)\n",
    "    std_score = np.std(target_scores)\n",
    "    scores.append(mean_score)\n",
    "    print(f\"  Mean RMSE: {mean_score:.4f} Â± {std_score:.4f}\")\n",
    "\n",
    "overall_score = np.mean(scores)\n",
    "print(f\"\\nOverall Mean RMSE: {overall_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bfd1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Spearman correlation (since that's the actual metric)\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearman_scores = []\n",
    "for i, target in enumerate(target_cols):\n",
    "    corr, _ = spearmanr(y_train[:, i], oof_predictions[:, i])\n",
    "    spearman_scores.append(corr)\n",
    "    print(f\"{target}: {corr:.4f}\")\n",
    "\n",
    "mean_spearman = np.mean(spearman_scores)\n",
    "print(f\"\\nMean Spearman correlation: {mean_spearman:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c130f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'qa_id': test['qa_id']\n",
    "})\n",
    "\n",
    "for i, target in enumerate(target_cols):\n",
    "    submission[target] = test_predictions[:, i]\n",
    "\n",
    "# Ensure predictions are in [0, 1] range\n",
    "submission[target_cols] = submission[target_cols].clip(0, 1)\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"Submission columns: {submission.columns.tolist()}\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(\"\\nSubmission saved to /home/submission/submission.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
