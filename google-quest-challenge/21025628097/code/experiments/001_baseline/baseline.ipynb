{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ba4887",
   "metadata": {},
   "source": [
    "# Baseline Model for Google QUEST Challenge\n",
    "\n",
    "This notebook implements a simple baseline using TF-IDF features and a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5ccd98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T11:28:25.646723Z",
     "iopub.status.busy": "2026-01-15T11:28:25.645880Z",
     "iopub.status.idle": "2026-01-15T11:28:27.444626Z",
     "shell.execute_reply": "2026-01-15T11:28:27.443792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6079, 41)\n",
      "Test shape: (476, 11)\n",
      "Sample submission shape: (476, 31)\n",
      "Number of target columns: 30\n",
      "Target columns: ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking']...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "sample_submission = pd.read_csv('/home/data/sample_submission.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "\n",
    "# Identify target columns\n",
    "target_cols = [col for col in train.columns if col not in test.columns and col != 'qa_id']\n",
    "print(f\"Number of target columns: {len(target_cols)}\")\n",
    "print(f\"Target columns: {target_cols[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fb3e4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T11:28:27.446772Z",
     "iopub.status.busy": "2026-01-15T11:28:27.446450Z",
     "iopub.status.idle": "2026-01-15T11:28:33.073184Z",
     "shell.execute_reply": "2026-01-15T11:28:33.072562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature shape: (6079, 5000)\n",
      "Target shape: (6079, 30)\n"
     ]
    }
   ],
   "source": [
    "# Combine text features\n",
    "train['text'] = train['question_title'].fillna('') + ' ' + train['question_body'].fillna('') + ' ' + train['answer'].fillna('')\n",
    "test['text'] = test['question_title'].fillna('') + ' ' + test['question_body'].fillna('') + ' ' + test['answer'].fillna('')\n",
    "\n",
    "# Create TF-IDF features\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(train['text'])\n",
    "X_test_tfidf = vectorizer.transform(test['text'])\n",
    "\n",
    "print(f\"TF-IDF feature shape: {X_train_tfidf.shape}\")\n",
    "\n",
    "# Prepare target matrix\n",
    "y_train = train[target_cols].values\n",
    "print(f\"Target shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f6367cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T11:28:33.075897Z",
     "iopub.status.busy": "2026-01-15T11:28:33.075240Z",
     "iopub.status.idle": "2026-01-15T11:28:39.438126Z",
     "shell.execute_reply": "2026-01-15T11:28:39.437150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for target: question_asker_intent_understanding (1/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.1311 ± 0.0035\n",
      "Training for target: question_body_critical (2/30)\n",
      "  Mean RMSE: 0.1991 ± 0.0035\n",
      "Training for target: question_conversational (3/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.1641 ± 0.0090\n",
      "Training for target: question_expect_short_answer (4/30)\n",
      "  Mean RMSE: 0.3580 ± 0.0040\n",
      "Training for target: question_fact_seeking (5/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.2887 ± 0.0072\n",
      "Training for target: question_has_commonly_accepted_answer (6/30)\n",
      "  Mean RMSE: 0.3033 ± 0.0025\n",
      "Training for target: question_interestingness_others (7/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.1352 ± 0.0011\n",
      "Training for target: question_interestingness_self (8/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.1697 ± 0.0040\n",
      "Training for target: question_multi_intent (9/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.3223 ± 0.0034\n",
      "Training for target: question_not_really_a_question (10/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.0481 ± 0.0066\n",
      "Training for target: question_opinion_seeking (11/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.3438 ± 0.0032\n",
      "Training for target: question_type_choice (12/30)\n",
      "  Mean RMSE: 0.3379 ± 0.0036\n",
      "Training for target: question_type_compare (13/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.1381 ± 0.0065\n",
      "Training for target: question_type_consequence (14/30)\n",
      "  Mean RMSE: 0.0734 ± 0.0104\n",
      "Training for target: question_type_definition (15/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.1191 ± 0.0090\n",
      "Training for target: question_type_entity (16/30)\n",
      "  Mean RMSE: 0.1736 ± 0.0047\n",
      "Training for target: question_type_instructions (17/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.3175 ± 0.0063\n",
      "Training for target: question_type_procedure (18/30)\n",
      "  Mean RMSE: 0.2623 ± 0.0037\n",
      "Training for target: question_type_reason_explanation (19/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.3459 ± 0.0068\n",
      "Training for target: question_type_spelling (20/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.0183 ± 0.0066\n",
      "Training for target: question_well_written (21/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.1704 ± 0.0025\n",
      "Training for target: answer_helpful (22/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.1197 ± 0.0035\n",
      "Training for target: answer_level_of_information (23/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.1097 ± 0.0018\n",
      "Training for target: answer_plausible (24/30)\n",
      "  Mean RMSE: 0.0919 ± 0.0024\n",
      "Training for target: answer_relevance (25/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.0784 ± 0.0027\n",
      "Training for target: answer_satisfaction (26/30)\n",
      "  Mean RMSE: 0.1349 ± 0.0021\n",
      "Training for target: answer_type_instructions (27/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.3232 ± 0.0055\n",
      "Training for target: answer_type_procedure (28/30)\n",
      "  Mean RMSE: 0.2322 ± 0.0056\n",
      "Training for target: answer_type_reason_explanation (29/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.3667 ± 0.0067\n",
      "Training for target: answer_well_written (30/30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean RMSE: 0.1067 ± 0.0027\n",
      "\n",
      "Overall Mean RMSE: 0.1994\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation setup\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Store predictions\n",
    "oof_predictions = np.zeros_like(y_train)\n",
    "test_predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "# Train model for each target\n",
    "scores = []\n",
    "\n",
    "for target_idx, target in enumerate(target_cols):\n",
    "    print(f\"Training for target: {target} ({target_idx+1}/{len(target_cols)})\")\n",
    "    \n",
    "    target_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_tfidf)):\n",
    "        X_tr, X_val = X_train_tfidf[train_idx], X_train_tfidf[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx, target_idx], y_train[val_idx, target_idx]\n",
    "        \n",
    "        # Train Ridge regression\n",
    "        model = Ridge(alpha=1.0, random_state=42)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        \n",
    "        # Predict\n",
    "        val_pred = model.predict(X_val)\n",
    "        oof_predictions[val_idx, target_idx] = val_pred\n",
    "        \n",
    "        # Calculate RMSE for this fold\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "        target_scores.append(rmse)\n",
    "        \n",
    "        # Predict on test\n",
    "        test_pred = model.predict(X_test_tfidf)\n",
    "        test_predictions[:, target_idx] += test_pred / n_folds\n",
    "    \n",
    "    mean_score = np.mean(target_scores)\n",
    "    std_score = np.std(target_scores)\n",
    "    scores.append(mean_score)\n",
    "    print(f\"  Mean RMSE: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "\n",
    "overall_score = np.mean(scores)\n",
    "print(f\"\\nOverall Mean RMSE: {overall_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1bfd1b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T11:28:39.441854Z",
     "iopub.status.busy": "2026-01-15T11:28:39.440978Z",
     "iopub.status.idle": "2026-01-15T11:28:39.535523Z",
     "shell.execute_reply": "2026-01-15T11:28:39.534650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_asker_intent_understanding: 0.2594\n",
      "question_body_critical: 0.4195\n",
      "question_conversational: 0.3133\n",
      "question_expect_short_answer: 0.1564\n",
      "question_fact_seeking: 0.2499\n",
      "question_has_commonly_accepted_answer: 0.3550\n",
      "question_interestingness_others: 0.2556\n",
      "question_interestingness_self: 0.4202\n",
      "question_multi_intent: 0.3110\n",
      "question_not_really_a_question: 0.0250\n",
      "question_opinion_seeking: 0.3510\n",
      "question_type_choice: 0.4055\n",
      "question_type_compare: 0.2556\n",
      "question_type_consequence: 0.1160\n",
      "question_type_definition: 0.2950\n",
      "question_type_entity: 0.3431\n",
      "question_type_instructions: 0.6599\n",
      "question_type_procedure: 0.1915\n",
      "question_type_reason_explanation: 0.4365\n",
      "question_type_spelling: 0.0715\n",
      "question_well_written: 0.3436\n",
      "answer_helpful: 0.0869\n",
      "answer_level_of_information: 0.1636\n",
      "answer_plausible: 0.0555\n",
      "answer_relevance: 0.0566\n",
      "answer_satisfaction: 0.1151\n",
      "answer_type_instructions: 0.6509\n",
      "answer_type_procedure: 0.1633\n",
      "answer_type_reason_explanation: 0.4503\n",
      "answer_well_written: 0.0589\n",
      "\n",
      "Mean Spearman correlation: 0.2679\n"
     ]
    }
   ],
   "source": [
    "# Calculate Spearman correlation (since that's the actual metric)\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearman_scores = []\n",
    "for i, target in enumerate(target_cols):\n",
    "    corr, _ = spearmanr(y_train[:, i], oof_predictions[:, i])\n",
    "    spearman_scores.append(corr)\n",
    "    print(f\"{target}: {corr:.4f}\")\n",
    "\n",
    "mean_spearman = np.mean(spearman_scores)\n",
    "print(f\"\\nMean Spearman correlation: {mean_spearman:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c130f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T11:28:39.538527Z",
     "iopub.status.busy": "2026-01-15T11:28:39.538256Z",
     "iopub.status.idle": "2026-01-15T11:28:39.616511Z",
     "shell.execute_reply": "2026-01-15T11:28:39.615671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (476, 31)\n",
      "Submission columns: ['qa_id', 'question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
      "\n",
      "First few predictions:\n",
      "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
      "0     39                             1.000000                0.720377   \n",
      "1     46                             0.927378                0.665531   \n",
      "2     70                             0.883018                0.543829   \n",
      "3    132                             0.819738                0.394066   \n",
      "4    200                             0.957142                0.493040   \n",
      "\n",
      "   question_conversational  question_expect_short_answer  \\\n",
      "0                 0.259229                      0.781125   \n",
      "1                 0.000000                      0.742022   \n",
      "2                 0.111874                      0.670805   \n",
      "3                 0.028834                      0.685192   \n",
      "4                 0.098078                      0.900585   \n",
      "\n",
      "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
      "0               0.640870                               0.821358   \n",
      "1               0.830754                               0.881707   \n",
      "2               0.736497                               0.639532   \n",
      "3               0.704948                               0.911778   \n",
      "4               0.593332                               0.742156   \n",
      "\n",
      "   question_interestingness_others  question_interestingness_self  \\\n",
      "0                         0.637954                       0.585430   \n",
      "1                         0.552028                       0.421886   \n",
      "2                         0.678768                       0.615869   \n",
      "3                         0.510330                       0.420072   \n",
      "4                         0.639723                       0.690935   \n",
      "\n",
      "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
      "0               0.507694  ...               0.855646        0.975456   \n",
      "1               0.116895  ...               0.740580        0.938129   \n",
      "2               0.231019  ...               0.789724        0.878150   \n",
      "3               0.268376  ...               0.735834        0.932663   \n",
      "4               0.391365  ...               0.866657        0.956365   \n",
      "\n",
      "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
      "0                     0.688323          1.000000          0.984270   \n",
      "1                     0.592621          0.961554          0.974262   \n",
      "2                     0.591793          0.934219          0.906153   \n",
      "3                     0.704662          0.934886          0.958928   \n",
      "4                     0.692902          0.942955          0.922096   \n",
      "\n",
      "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
      "0             0.923777                  0.157901               0.125104   \n",
      "1             0.848163                  0.914498               0.077252   \n",
      "2             0.837260                  0.082069               0.167371   \n",
      "3             0.833615                  0.583119               0.061160   \n",
      "4             0.810256                  0.229132               0.182982   \n",
      "\n",
      "   answer_type_reason_explanation  answer_well_written  \n",
      "0                        0.979694             0.916919  \n",
      "1                        0.201031             0.849774  \n",
      "2                        0.779153             0.927433  \n",
      "3                        0.506345             0.906240  \n",
      "4                        0.745050             0.946886  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Submission saved to /home/submission/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'qa_id': test['qa_id']\n",
    "})\n",
    "\n",
    "for i, target in enumerate(target_cols):\n",
    "    submission[target] = test_predictions[:, i]\n",
    "\n",
    "# Ensure predictions are in [0, 1] range\n",
    "submission[target_cols] = submission[target_cols].clip(0, 1)\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"Submission columns: {submission.columns.tolist()}\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(\"\\nSubmission saved to /home/submission/submission.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
