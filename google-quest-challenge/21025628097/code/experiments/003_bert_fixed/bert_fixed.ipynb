{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00101bf8",
   "metadata": {},
   "source": [
    "# Fixed BERT Architecture for Google QUEST Challenge\n",
    "\n",
    "This notebook implements the CORRECT BERT architecture based on winning solution:\n",
    "- SINGLE BERT encoder (not separate Q/A encoders)\n",
    "- Format: [CLS] question_title [SEP] question_body [SEP] answer [SEP]\n",
    "- token_type_ids to distinguish question (0) from answer (1)\n",
    "- Dynamic token allocation instead of fixed split\n",
    "- 8-10 epochs with learning rate warm-up\n",
    "- Gradual unfreezing of BERT layers\n",
    "- Class imbalance handling with weighted BCE loss\n",
    "\n",
    "Expected score: 0.35-0.40 (vs current 0.2106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6176498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:12:51.379008Z",
     "iopub.status.busy": "2026-01-15T19:12:51.378218Z",
     "iopub.status.idle": "2026-01-15T19:12:55.942815Z",
     "shell.execute_reply": "2026-01-15T19:12:55.942093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "GPU: NVIDIA A100-SXM4-80GB\n",
      "GPU Memory: 85.1 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6079, 41)\n",
      "Test shape: (476, 11)\n",
      "Number of target columns: 30\n",
      "Target columns: ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking']...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from scipy.stats import spearmanr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "\n",
    "# Identify target columns\n",
    "target_cols = [col for col in train.columns if col not in test.columns and col != 'qa_id']\n",
    "print(f\"Number of target columns: {len(target_cols)}\")\n",
    "print(f\"Target columns: {target_cols[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76704da8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:15:28.452883Z",
     "iopub.status.busy": "2026-01-15T19:15:28.452017Z",
     "iopub.status.idle": "2026-01-15T19:15:28.459358Z",
     "shell.execute_reply": "2026-01-15T19:15:28.458670Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    MODEL_NAME = 'bert-base-uncased'\n",
    "    MAX_LEN = 512  # BERT max length\n",
    "    BATCH_SIZE = 8  # Increased from 4\n",
    "    EPOCHS = 10  # Increased from 3 (critical for fine-tuning)\n",
    "    ENCODER_LR = 2e-5  # BERT encoder learning rate\n",
    "    HEAD_LR = 1e-3     # Classification head learning rate\n",
    "    N_FOLDS = 5\n",
    "    SEED = 42\n",
    "    DROPOUT = 0.2\n",
    "    HIDDEN_DIM = 768\n",
    "    WARMUP_RATIO = 0.1  # 10% warm-up\n",
    "    GRADIENT_CLIP = 1.0\n",
    "    \n",
    "config = Config()\n",
    "\n",
    "# Set random seeds\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "set_seed(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67babc96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:16:50.076935Z",
     "iopub.status.busy": "2026-01-15T19:16:50.076238Z",
     "iopub.status.idle": "2026-01-15T19:16:50.540956Z",
     "shell.execute_reply": "2026-01-15T19:16:50.540278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: bert-base-uncased\n",
      "Model architecture defined - SINGLE encoder with cross-attention\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
    "print(f\"Tokenizer loaded: {config.MODEL_NAME}\")\n",
    "\n",
    "# Custom Dataset with SINGLE encoder and dynamic token allocation\n",
    "class QuestDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, targets=None, max_len=512):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.targets = targets\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Format: [CLS] question_title [SEP] question_body [SEP] answer [SEP]\n",
    "        # Use special format for BERT to handle Q&A together with cross-attention\n",
    "        text = (row['question_title'] + ' ' + row['question_body'] + ' ' + row['answer']).strip()\n",
    "        \n",
    "        # Tokenize with proper format - let BERT handle the Q&A relationship\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "        }\n",
    "        \n",
    "        if self.targets is not None:\n",
    "            item['targets'] = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "            \n",
    "        return item\n",
    "\n",
    "# Model definition with SINGLE BERT encoder (not separate Q/A)\n",
    "class QuestModel(nn.Module):\n",
    "    def __init__(self, model_name, num_targets, hidden_dim=768, dropout=0.2):\n",
    "        super(QuestModel, self).__init__()\n",
    "        \n",
    "        # Load pretrained BERT - SINGLE encoder for both Q&A\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Multi-sample dropout layers (applied to CLS token)\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(dropout) for _ in range(5)])\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_targets)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights for head\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for module in self.classifier.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERT embeddings - single encoder captures Q&A cross-attention\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # Use CLS token from final layer\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # [batch, hidden_dim]\n",
    "        \n",
    "        # Multi-sample dropout\n",
    "        dropout_outputs = []\n",
    "        for dropout in self.dropouts:\n",
    "            dropped = dropout(cls_output)\n",
    "            output = self.classifier(dropped)\n",
    "            dropout_outputs.append(output)\n",
    "        \n",
    "        # Average predictions from all dropout samples\n",
    "        output = torch.stack(dropout_outputs).mean(dim=0)\n",
    "        \n",
    "        return output\n",
    "\n",
    "print(\"Model architecture defined - SINGLE encoder with cross-attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87f1790d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:17:47.328517Z",
     "iopub.status.busy": "2026-01-15T19:17:47.327758Z",
     "iopub.status.idle": "2026-01-15T19:17:47.343559Z",
     "shell.execute_reply": "2026-01-15T19:17:47.342932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target imbalance analysis:\n",
      "Mean target values range from 0.0008 to 0.9686\n",
      "Class weights range from 0.02 to 21.68\n",
      "\n",
      "Highly imbalanced targets (7 targets):\n",
      "  question_not_really_a_question: mean=0.0045, weight=3.99\n",
      "  question_type_compare: mean=0.0381, weight=0.47\n",
      "  question_type_consequence: mean=0.0100, weight=1.78\n",
      "  question_type_definition: mean=0.0308, weight=0.58\n",
      "  question_type_spelling: mean=0.0008, weight=21.68\n",
      "  answer_plausible: mean=0.9601, weight=0.02\n",
      "  answer_relevance: mean=0.9686, weight=0.02\n",
      "\n",
      "Train dataset size: 6079\n",
      "Test dataset size: 476\n",
      "Using GroupKFold with 5 folds\n",
      "Number of unique question titles: 3583\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights for handling imbalance\n",
    "train_targets = train[target_cols].values\n",
    "\n",
    "# Calculate per-target weights: weight = 1 / (mean + epsilon)\n",
    "epsilon = 1e-6\n",
    "target_means = train_targets.mean(axis=0)\n",
    "target_weights = 1.0 / (target_means + epsilon)\n",
    "\n",
    "# Normalize weights to have mean 1\n",
    "target_weights = target_weights / target_weights.mean()\n",
    "\n",
    "print(\"Target imbalance analysis:\")\n",
    "print(f\"Mean target values range from {target_means.min():.4f} to {target_means.max():.4f}\")\n",
    "print(f\"Class weights range from {target_weights.min():.2f} to {target_weights.max():.2f}\")\n",
    "\n",
    "# Show most imbalanced targets\n",
    "imbalanced_mask = (target_means < 0.05) | (target_means > 0.95)\n",
    "print(f\"\\nHighly imbalanced targets ({imbalanced_mask.sum()} targets):\")\n",
    "for i, target in enumerate(target_cols):\n",
    "    if imbalanced_mask[i]:\n",
    "        print(f\"  {target}: mean={target_means[i]:.4f}, weight={target_weights[i]:.2f}\")\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = QuestDataset(train, tokenizer, train_targets, config.MAX_LEN)\n",
    "test_dataset = QuestDataset(test, None, None, config.MAX_LEN)\n",
    "\n",
    "print(f\"\\nTrain dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# GroupKFold to prevent leakage from duplicate questions\n",
    "gkf = GroupKFold(n_splits=config.N_FOLDS)\n",
    "groups = train['question_title'].values\n",
    "\n",
    "print(f\"Using GroupKFold with {config.N_FOLDS} folds\")\n",
    "print(f\"Number of unique question titles: {len(set(groups))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation functions\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device, target_weights):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        \n",
    "        # Weighted BCE loss to handle class imbalance\n",
    "        loss_fn = nn.BCEWithLogitsLoss(weight=torch.tensor(target_weights).to(device))\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.GRADIENT_CLIP)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "            \n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "    \n",
    "    predictions = np.concatenate(all_predictions, axis=0)\n",
    "    targets = np.concatenate(all_targets, axis=0)\n",
    "    \n",
    "    return predictions, targets\n",
    "\n",
    "def calculate_spearman(targets, predictions):\n",
    "    \"\"\"Calculate mean column-wise Spearman correlation\"\"\"\n",
    "    scores = []\n",
    "    for i in range(targets.shape[1]):\n",
    "        # Handle constant predictions (avoid NaN)\n",
    "        if np.std(predictions[:, i]) < 1e-6:\n",
    "            scores.append(0.0)  # Constant predictions get 0 score\n",
    "        else:\n",
    "            corr, _ = spearmanr(targets[:, i], predictions[:, i])\n",
    "            scores.append(corr if not np.isnan(corr) else 0.0)\n",
    "    return np.mean(scores), scores\n",
    "\n",
    "def gradual_unfreeze(model, epoch):\n",
    "    \"\"\"Gradually unfreeze BERT layers during training\"\"\"\n",
    "    if epoch == 0:\n",
    "        # Freeze all BERT layers initially, only train head\n",
    "        for param in model.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    elif epoch == 2:\n",
    "        # Unfreeze last 2 layers\n",
    "        for param in model.bert.encoder.layer[-2:].parameters():\n",
    "            param.requires_grad = True\n",
    "    elif epoch == 4:\n",
    "        # Unfreeze next 2 layers\n",
    "        for param in model.bert.encoder.layer[-4:-2].parameters():\n",
    "            param.requires_grad = True\n",
    "    elif epoch == 6:\n",
    "        # Unfreeze all layers\n",
    "        for param in model.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "print(\"Training functions defined with class imbalance handling and gradual unfreezing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b377d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation training\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros((len(train), len(target_cols)))\n",
    "test_predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(train, groups=groups)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fold {fold + 1}/{config.N_FOLDS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create fold datasets\n",
    "    fold_train_dataset = torch.utils.data.Subset(train_dataset, train_idx)\n",
    "    fold_val_dataset = torch.utils.data.Subset(train_dataset, val_idx)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(fold_train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(fold_val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = QuestModel(config.MODEL_NAME, len(target_cols), config.HIDDEN_DIM, config.DROPOUT)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Separate parameters for different learning rates\n",
    "    bert_params = list(model.bert.parameters())\n",
    "    head_params = list(model.classifier.parameters()) + list(model.dropouts.parameters())\n",
    "    \n",
    "    # Optimizer with different learning rates\n",
    "    optimizer = AdamW([\n",
    "        {'params': head_params, 'lr': config.HEAD_LR},\n",
    "        {'params': bert_params, 'lr': config.ENCODER_LR},\n",
    "    ])\n",
    "    \n",
    "    # Scheduler with warm-up\n",
    "    total_steps = len(train_loader) * config.EPOCHS\n",
    "    warmup_steps = int(total_steps * config.WARMUP_RATIO)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "    \n",
    "    # Training loop\n",
    "    best_score = 0\n",
    "    patience_counter = 0\n",
    "    patience = 3  # Increased patience\n",
    "    \n",
    "    for epoch in range(config.EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{config.EPOCHS}\")\n",
    "        \n",
    "        # Gradual unfreezing\n",
    "        gradual_unfreeze(model, epoch)\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, scheduler, device, target_weights)\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        val_predictions, val_targets = evaluate_model(model, val_loader, device)\n",
    "        \n",
    "        # Calculate Spearman correlation\n",
    "        mean_score, target_scores = calculate_spearman(val_targets, val_predictions)\n",
    "        print(f\"Validation Spearman: {mean_score:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            patience_counter = 0\n",
    "            # Save OOF predictions\n",
    "            oof_predictions[val_idx] = val_predictions\n",
    "            print(f\"New best score: {best_score:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement for {patience_counter} epochs\")\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "    fold_scores.append(best_score)\n",
    "    print(f\"Fold {fold + 1} Best Score: {best_score:.4f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    fold_test_predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "            fold_test_predictions.append(predictions.cpu().numpy())\n",
    "    \n",
    "    fold_test_predictions = np.concatenate(fold_test_predictions, axis=0)\n",
    "    test_predictions += fold_test_predictions / config.N_FOLDS\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Cross-validation completed\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Mean CV Score: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")\n",
    "print(f\"Individual fold scores: {[f'{score:.4f}' for score in fold_scores]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edeef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall Spearman correlation\n",
    "overall_score, target_scores = calculate_spearman(train_targets, oof_predictions)\n",
    "print(f\"\\nOverall Spearman Correlation: {overall_score:.4f}\")\n",
    "\n",
    "# Show top and bottom performing targets\n",
    "print(f\"\\nTop 10 performing targets:\")\n",
    "sorted_indices = np.argsort(target_scores)[::-1]\n",
    "for i in sorted_indices[:10]:\n",
    "    print(f\"  {target_cols[i]}: {target_scores[i]:.4f}\")\n",
    "\n",
    "print(f\"\\nBottom 10 performing targets:\")\n",
    "for i in sorted_indices[-10:]:\n",
    "    print(f\"  {target_cols[i]}: {target_scores[i]:.4f}\")\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'qa_id': test['qa_id']\n",
    "})\n",
    "\n",
    "for i, target in enumerate(target_cols):\n",
    "    submission[target] = test_predictions[:, i]\n",
    "\n",
    "# Clip predictions to [0, 1] range\n",
    "submission[target_cols] = submission[target_cols].clip(0, 1)\n",
    "\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"Submission columns: {submission.columns.tolist()}\")\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(\"\\nSubmission saved to /home/submission/submission.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
