{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad4e9e6",
   "metadata": {},
   "source": [
    "# BERT with Proper Q&A Token Type IDs\n",
    "\n",
    "This experiment implements the evaluator's top priority: proper text processing with separate Q&A inputs and token_type_ids.\n",
    "\n",
    "Key improvements from exp_006:\n",
    "1. Use token_type_ids to explicitly distinguish question (0) from answer (1)\n",
    "2. Format: [CLS] question_title [SEP] question_body [SEP] answer [SEP]\n",
    "3. Strategic token allocation: 26/260/210 split (title/question/answer)\n",
    "4. Keep all other improvements: 10 epochs, gradual unfreezing, class weights, multi-sample dropout\n",
    "\n",
    "Expected improvement: +0.02-0.03 (0.38-0.40 CV)\n",
    "\n",
    "Based on winning solution and evaluator feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bac1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from scipy.stats import spearmanr\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "# Identify targets\n",
    "target_cols = [col for col in train.columns if col not in test.columns and col != 'qa_id']\n",
    "print(f\"Training samples: {len(train)}\")\n",
    "print(f\"Test samples: {len(test)}\")\n",
    "print(f\"Target columns: {len(target_cols)}\")\n",
    "\n",
    "# Analyze text lengths for token allocation\n",
    "train['title_len'] = train['question_title'].astype(str).apply(len)\n",
    "train['body_len'] = train['question_body'].astype(str).apply(len)\n",
    "train['answer_len'] = train['answer'].astype(str).apply(len)\n",
    "\n",
    "print(\"\\nText length statistics (characters):\")\n",
    "print(f\"Title - 95th percentile: {train['title_len'].quantile(0.95)}\")\n",
    "print(f\"Body - 95th percentile: {train['body_len'].quantile(0.95)}\")\n",
    "print(f\"Answer - 95th percentile: {train['answer_len'].quantile(0.95)}\")\n",
    "\n",
    "# Winning solution used 26/260/210 token split\n",
    "# This covers 95%+ of titles, 85%+ of bodies, 80%+ of answers\n",
    "MAX_TITLE_TOKENS = 26\n",
    "MAX_BODY_TOKENS = 260\n",
    "MAX_ANSWER_TOKENS = 210\n",
    "MAX_TOTAL_TOKENS = 512\n",
    "\n",
    "print(f\"\\nToken allocation strategy:\")\n",
    "print(f\"Title: {MAX_TITLE_TOKENS} tokens\")\n",
    "print(f\"Body: {MAX_BODY_TOKENS} tokens\")\n",
    "print(f\"Answer: {MAX_ANSWER_TOKENS} tokens\")\n",
    "print(f\"Total: {MAX_TOTAL_TOKENS} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47bd42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    MODEL_NAME = 'bert-base-uncased'\n",
    "    MAX_LEN = 512\n",
    "    BATCH_SIZE = 8\n",
    "    EPOCHS = 10\n",
    "    ENCODER_LR = 2e-5\n",
    "    HEAD_LR = 1e-3\n",
    "    N_FOLDS = 5\n",
    "    SEED = 42\n",
    "    DROPOUT = 0.2\n",
    "    HIDDEN_DIM = 768\n",
    "    WARMUP_RATIO = 0.1\n",
    "    GRADIENT_CLIP = 1.0\n",
    "    \n",
    "config = Config()\n",
    "\n",
    "# Set random seeds\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "set_seed(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353207e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
    "print(f\"Tokenizer loaded: {config.MODEL_NAME}\")\n",
    "\n",
    "# Custom Dataset with PROPER token_type_ids for Q&A\n",
    "class QuestDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, targets=None, max_len=512):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.targets = targets\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Format: [CLS] question_title [SEP] question_body [SEP] answer [SEP]\n",
    "        # Use token_type_ids=0 for question, =1 for answer\n",
    "        \n",
    "        # Tokenize each part separately to control allocation\n",
    "        title_tokens = self.tokenizer.encode(\n",
    "            str(row['question_title']),\n",
    "            add_special_tokens=False,\n",
    "            max_length=MAX_TITLE_TOKENS,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        body_tokens = self.tokenizer.encode(\n",
    "            str(row['question_body']),\n",
    "            add_special_tokens=False,\n",
    "            max_length=MAX_BODY_TOKENS,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        answer_tokens = self.tokenizer.encode(\n",
    "            str(row['answer']),\n",
    "            add_special_tokens=False,\n",
    "            max_length=MAX_ANSWER_TOKENS,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        # Build input_ids: [CLS] title body [SEP] answer [SEP]\n",
    "        input_ids = [tokenizer.cls_token_id] + title_tokens + body_tokens + [tokenizer.sep_token_id] + answer_tokens + [tokenizer.sep_token_id]\n",
    "        \n",
    "        # Create token_type_ids: 0 for question (title+body), 1 for answer\n",
    "        token_type_ids = [0] * (1 + len(title_tokens) + len(body_tokens) + 1) + [1] * (len(answer_tokens) + 1)\n",
    "        \n",
    "        # Truncate if needed\n",
    "        if len(input_ids) > self.max_len:\n",
    "            input_ids = input_ids[:self.max_len]\n",
    "            token_type_ids = token_type_ids[:self.max_len]\n",
    "            # Ensure last token is SEP\n",
    "            input_ids[-1] = tokenizer.sep_token_id\n",
    "            token_type_ids[-1] = 1\n",
    "        \n",
    "        # Create attention mask\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        \n",
    "        # Pad to max length\n",
    "        padding_length = self.max_len - len(input_ids)\n",
    "        input_ids = input_ids + [tokenizer.pad_token_id] * padding_length\n",
    "        attention_mask = attention_mask + [0] * padding_length\n",
    "        token_type_ids = token_type_ids + [0] * padding_length\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "        }\n",
    "        \n",
    "        if self.targets is not None:\n",
    "            item['targets'] = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "            \n",
    "        return item\n",
    "\n",
    "# Model definition with token_type_ids support\n",
    "class QuestModel(nn.Module):\n",
    "    def __init__(self, model_name, num_targets, hidden_dim=768, dropout=0.2):\n",
    "        super(QuestModel, self).__init__()\n",
    "        \n",
    "        # Load pretrained BERT\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Multi-sample dropout layers\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(dropout) for _ in range(5)])\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_targets)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights for head\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for module in self.classifier.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # Get BERT embeddings with token_type_ids\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        # Use CLS token from final layer\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # [batch, hidden_dim]\n",
    "        \n",
    "        # Multi-sample dropout\n",
    "        dropout_outputs = []\n",
    "        for dropout in self.dropouts:\n",
    "            dropped = dropout(cls_output)\n",
    "            output = self.classifier(dropped)\n",
    "            dropout_outputs.append(output)\n",
    "        \n",
    "        # Average predictions from all dropout samples\n",
    "        output = torch.stack(dropout_outputs).mean(dim=0)\n",
    "        \n",
    "        return output\n",
    "\n",
    "print(\"Model architecture defined with token_type_ids support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf39287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare targets\n",
    "targets = train[target_cols].values\n",
    "\n",
    "# Calculate class weights for handling imbalance\n",
    "target_means = train[target_cols].mean()\n",
    "class_weights = []\n",
    "for target in target_cols:\n",
    "    mean = target_means[target]\n",
    "    # Weighted BCE: weight = 1 / (mean + epsilon) for positive class\n",
    "    weight = 1.0 / (mean + 1e-6)\n",
    "    class_weights.append(weight)\n",
    "\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "print(f\"Class weights calculated for {len(class_weights)} targets\")\n",
    "print(f\"Weight range: {class_weights.min():.2f} to {class_weights.max():.2f}\")\n",
    "\n",
    "# GroupKFold with question_title groups to prevent leakage\n",
    "gkf = GroupKFold(n_splits=config.N_FOLDS)\n",
    "groups = train['question_title'].values\n",
    "\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros((len(train), len(target_cols)))\n",
    "\n",
    "print(f\"\\nStarting {config.N_FOLDS}-fold GroupKFold training...\")\n",
    "print(f\"Groups (unique questions): {len(np.unique(groups))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410cf82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with gradient accumulation and LR scheduling\n",
    "def train_epoch(model, train_loader, optimizer, scheduler, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch} [Train]')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "        \n",
    "        # Weighted BCE loss\n",
    "        loss_fn = nn.BCEWithLogitsLoss(weight=class_weights.to(device))\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.GRADIENT_CLIP)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Validation function\n",
    "def validate_epoch(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc='Validation'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            \n",
    "            val_predictions.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "            val_targets.append(targets.cpu().numpy())\n",
    "    \n",
    "    val_predictions = np.concatenate(val_predictions)\n",
    "    val_targets = np.concatenate(val_targets)\n",
    "    \n",
    "    return val_predictions, val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd9a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "import gc\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(train, groups=groups)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fold {fold + 1}/{config.N_FOLDS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create fold data\n",
    "    train_fold = train.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold = train.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    train_targets_fold = targets[train_idx]\n",
    "    val_targets_fold = targets[val_idx]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = QuestDataset(train_fold, tokenizer, train_targets_fold, config.MAX_LEN)\n",
    "    val_dataset = QuestDataset(val_fold, tokenizer, val_targets_fold, config.MAX_LEN)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = QuestModel(config.MODEL_NAME, len(target_cols), config.HIDDEN_DIM, config.DROPOUT)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Optimizer with different learning rates for encoder and head\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': model.bert.parameters(), 'lr': config.ENCODER_LR},\n",
    "        {'params': model.classifier.parameters(), 'lr': config.HEAD_LR}\n",
    "    ])\n",
    "    \n",
    "    # Learning rate scheduler with warm-up\n",
    "    total_steps = len(train_loader) * config.EPOCHS\n",
    "    warmup_steps = int(total_steps * config.WARMUP_RATIO)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    best_score = 0\n",
    "    patience_counter = 0\n",
    "    patience = 2  # Early stopping patience\n",
    "    \n",
    "    for epoch in range(config.EPOCHS):\n",
    "        # Training\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, scheduler, device, epoch)\n",
    "        \n",
    "        # Validation\n",
    "        val_predictions, val_targets_epoch = validate_epoch(model, val_loader, device)\n",
    "        \n",
    "        # Calculate Spearman correlation\n",
    "        fold_scores_list = []\n",
    "        for i in range(len(target_cols)):\n",
    "            try:\n",
    "                score = spearmanr(val_targets_epoch[:, i], val_predictions[:, i]).correlation\n",
    "                if not np.isnan(score):\n",
    "                    fold_scores_list.append(score)\n",
    "            except:\n",
    "                fold_scores_list.append(0.0)\n",
    "        \n",
    "        mean_score = np.mean(fold_scores_list)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{config.EPOCHS} - Train Loss: {train_loss:.4f} - Val Score: {mean_score:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), f'/home/code/experiments/004_bert_token_type_ids/best_model_fold_{fold}.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after epoch {epoch + 1}\")\n",
    "                break\n",
    "    \n",
    "    # Load best model and get final predictions\n",
    "    model.load_state_dict(torch.load(f'/home/code/experiments/004_bert_token_type_ids/best_model_fold_{fold}.pth'))\n",
    "    val_predictions, _ = validate_epoch(model, val_loader, device)\n",
    "    \n",
    "    # Store OOF predictions\n",
    "    oof_predictions[val_idx] = val_predictions\n",
    "    \n",
    "    # Calculate final fold score\n",
    "    fold_scores_list = []\n",
    "    for i in range(len(target_cols)):\n",
    "        try:\n",
    "            score = spearmanr(val_targets_fold[:, i], val_predictions[:, i]).correlation\n",
    "            if not np.isnan(score):\n",
    "                fold_scores_list.append(score)\n",
    "        except:\n",
    "            fold_scores_list.append(0.0)\n",
    "    \n",
    "    fold_score = np.mean(fold_scores_list)\n",
    "    fold_scores.append(fold_score)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Score: {fold_score:.4f}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del model, optimizer, scheduler, train_loader, val_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Calculate overall CV score\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Cross-Validation Results\")\n",
    "print(f\"{'='*60}\")\n",
    "for i, score in enumerate(fold_scores):\n",
    "    print(f\"Fold {i + 1}: {score:.4f}\")\n",
    "\n",
    "mean_cv = np.mean(fold_scores)\n",
    "std_cv = np.std(fold_scores)\n",
    "print(f\"\\nMean CV Score: {mean_cv:.4f} Â± {std_cv:.4f}\")\n",
    "\n",
    "# Save OOF predictions\n",
    "np.save('/home/code/experiments/004_bert_token_type_ids/oof_predictions.npy', oof_predictions)\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'experiment_id': 'exp_007',\n",
    "    'model_type': 'bert_token_type_ids',\n",
    "    'cv_score': mean_cv,\n",
    "    'cv_std': std_cv,\n",
    "    'fold_scores': fold_scores,\n",
    "    'config': config.__dict__\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/004_bert_token_type_ids/results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to /home/code/experiments/004_bert_token_type_ids/results.json\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
