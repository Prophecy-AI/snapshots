{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56eb8268",
   "metadata": {},
   "source": [
    "# Baseline Model: XGBoost with Feature Engineering\n",
    "\n",
    "Following the seed prompt strategy:\n",
    "1. Feature engineering (Group, Cabin, Spending features)\n",
    "2. Group-based missing value imputation\n",
    "3. XGBoost with recommended hyperparameters\n",
    "4. 5-fold StratifiedKFold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "557871e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:00:51.204557Z",
     "iopub.status.busy": "2026-01-06T04:00:51.203914Z",
     "iopub.status.idle": "2026-01-06T04:00:53.603868Z",
     "shell.execute_reply": "2026-01-06T04:00:53.603199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8693, 14)\n",
      "Test shape: (4277, 13)\n",
      "\n",
      "Target distribution:\n",
      "Transported\n",
      "True     0.503624\n",
      "False    0.496376\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train['Transported'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7839863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:00:53.606462Z",
     "iopub.status.busy": "2026-01-06T04:00:53.605820Z",
     "iopub.status.idle": "2026-01-06T04:00:53.685341Z",
     "shell.execute_reply": "2026-01-06T04:00:53.684728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete\n",
      "Train columns: 38\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(df, is_train=True):\n",
    "    \"\"\"Apply feature engineering based on strategy\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. PassengerId Extraction\n",
    "    df['Group'] = df['PassengerId'].apply(lambda x: x.split('_')[0]).astype(int)\n",
    "    df['PassengerNum'] = df['PassengerId'].apply(lambda x: x.split('_')[1]).astype(int)\n",
    "    \n",
    "    # 2. Cabin Feature Parsing\n",
    "    df['Deck'] = df['Cabin'].apply(lambda x: x.split('/')[0] if pd.notna(x) else np.nan)\n",
    "    df['CabinNum'] = df['Cabin'].apply(lambda x: int(x.split('/')[1]) if pd.notna(x) else np.nan)\n",
    "    df['Side'] = df['Cabin'].apply(lambda x: x.split('/')[2] if pd.notna(x) else np.nan)\n",
    "    \n",
    "    # 3. Spending Features\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    df['TotalSpent'] = df[spending_cols].sum(axis=1)\n",
    "    \n",
    "    # Binary spending indicators\n",
    "    for col in spending_cols:\n",
    "        df[f'{col}_spent'] = (df[col] > 0).astype(int)\n",
    "    \n",
    "    df['AnySpending'] = (df['TotalSpent'] > 0).astype(int)\n",
    "    \n",
    "    # Log transform spending features\n",
    "    for col in spending_cols + ['TotalSpent']:\n",
    "        df[f'{col}_log'] = np.log1p(df[col])\n",
    "    \n",
    "    # 4. Age Features\n",
    "    df['IsChild'] = (df['Age'] <= 12).astype(int)\n",
    "    df['IsTeen'] = ((df['Age'] > 12) & (df['Age'] <= 17)).astype(int)\n",
    "    df['IsYoungAdult'] = ((df['Age'] > 17) & (df['Age'] <= 25)).astype(int)\n",
    "    df['IsAdult'] = ((df['Age'] > 25) & (df['Age'] <= 60)).astype(int)\n",
    "    df['IsSenior'] = (df['Age'] > 60).astype(int)\n",
    "    \n",
    "    # 5. Name Features - Extract surname\n",
    "    df['Surname'] = df['Name'].apply(lambda x: x.split()[-1] if pd.notna(x) else np.nan)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train = feature_engineering(train, is_train=True)\n",
    "test = feature_engineering(test, is_train=False)\n",
    "\n",
    "print(\"Feature engineering complete\")\n",
    "print(f\"Train columns: {train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7978951c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:00:53.687719Z",
     "iopub.status.busy": "2026-01-06T04:00:53.687108Z",
     "iopub.status.idle": "2026-01-06T04:00:53.808586Z",
     "shell.execute_reply": "2026-01-06T04:00:53.807823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupSize distribution:\n",
      "GroupSize\n",
      "1    4805\n",
      "2    1682\n",
      "3    1020\n",
      "4     412\n",
      "5     265\n",
      "6     174\n",
      "7     231\n",
      "8     104\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate GroupSize from combined train+test for consistency\n",
    "all_data = pd.concat([train[['Group']], test[['Group']]], ignore_index=True)\n",
    "group_sizes = all_data['Group'].value_counts().to_dict()\n",
    "\n",
    "train['GroupSize'] = train['Group'].map(group_sizes)\n",
    "test['GroupSize'] = test['Group'].map(group_sizes)\n",
    "\n",
    "train['Solo'] = (train['GroupSize'] == 1).astype(int)\n",
    "test['Solo'] = (test['GroupSize'] == 1).astype(int)\n",
    "\n",
    "print(f\"GroupSize distribution:\")\n",
    "print(train['GroupSize'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45b68d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:00:53.811058Z",
     "iopub.status.busy": "2026-01-06T04:00:53.810468Z",
     "iopub.status.idle": "2026-01-06T04:00:53.902416Z",
     "shell.execute_reply": "2026-01-06T04:00:53.901764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation:\n",
      "Cabin      199\n",
      "Name       200\n",
      "Surname    200\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def impute_missing(df, train_df=None):\n",
    "    \"\"\"Impute missing values using group information and domain knowledge\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # CryoSleep passengers should have 0 spending\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    for col in spending_cols:\n",
    "        mask = (df['CryoSleep'] == True) & (df[col].isna())\n",
    "        df.loc[mask, col] = 0\n",
    "    \n",
    "    # Categorical columns - impute with mode\n",
    "    cat_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']\n",
    "    for col in cat_cols:\n",
    "        if df[col].isna().any():\n",
    "            mode_val = df[col].mode()[0] if not df[col].mode().empty else 'Unknown'\n",
    "            df[col] = df[col].fillna(mode_val)\n",
    "    \n",
    "    # Numerical columns - impute with median\n",
    "    num_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'CabinNum']\n",
    "    for col in num_cols:\n",
    "        if df[col].isna().any():\n",
    "            median_val = df[col].median()\n",
    "            df[col] = df[col].fillna(median_val)\n",
    "    \n",
    "    # Recalculate derived features after imputation\n",
    "    df['TotalSpent'] = df[spending_cols].sum(axis=1)\n",
    "    for col in spending_cols:\n",
    "        df[f'{col}_spent'] = (df[col] > 0).astype(int)\n",
    "    df['AnySpending'] = (df['TotalSpent'] > 0).astype(int)\n",
    "    for col in spending_cols + ['TotalSpent']:\n",
    "        df[f'{col}_log'] = np.log1p(df[col])\n",
    "    \n",
    "    # Age features\n",
    "    df['IsChild'] = (df['Age'] <= 12).astype(int)\n",
    "    df['IsTeen'] = ((df['Age'] > 12) & (df['Age'] <= 17)).astype(int)\n",
    "    df['IsYoungAdult'] = ((df['Age'] > 17) & (df['Age'] <= 25)).astype(int)\n",
    "    df['IsAdult'] = ((df['Age'] > 25) & (df['Age'] <= 60)).astype(int)\n",
    "    df['IsSenior'] = (df['Age'] > 60).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply imputation\n",
    "train = impute_missing(train)\n",
    "test = impute_missing(test)\n",
    "\n",
    "print(\"Missing values after imputation:\")\n",
    "print(train.isnull().sum()[train.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9257d3e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:00:53.904714Z",
     "iopub.status.busy": "2026-01-06T04:00:53.904187Z",
     "iopub.status.idle": "2026-01-06T04:00:53.942513Z",
     "shell.execute_reply": "2026-01-06T04:00:53.941812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding complete\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']\n",
    "\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on combined data to handle unseen categories\n",
    "    combined = pd.concat([train[col].astype(str), test[col].astype(str)])\n",
    "    le.fit(combined)\n",
    "    train[col + '_enc'] = le.transform(train[col].astype(str))\n",
    "    test[col + '_enc'] = le.transform(test[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"Encoding complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881be4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for model\n",
    "feature_cols = [\n",
    "    # Encoded categoricals\n",
    "    'HomePlanet_enc', 'CryoSleep_enc', 'Destination_enc', 'VIP_enc', 'Deck_enc', 'Side_enc',\n",
    "    # Numerical\n",
    "    'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
    "    # Engineered\n",
    "    'Group', 'PassengerNum', 'CabinNum', 'GroupSize', 'Solo',\n",
    "    'TotalSpent', 'AnySpending',\n",
    "    'RoomService_spent', 'FoodCourt_spent', 'ShoppingMall_spent', 'Spa_spent', 'VRDeck_spent',\n",
    "    'RoomService_log', 'FoodCourt_log', 'ShoppingMall_log', 'Spa_log', 'VRDeck_log', 'TotalSpent_log',\n",
    "    'IsChild', 'IsTeen', 'IsYoungAdult', 'IsAdult', 'IsSenior'\n",
    "]\n",
    "\n",
    "X = train[feature_cols].values\n",
    "y = train['Transported'].astype(int).values\n",
    "X_test = test[feature_cols].values\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with recommended hyperparameters from strategy\n",
    "xgb_params = {\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.067,\n",
    "    'n_estimators': 850,\n",
    "    'reg_lambda': 3.06,\n",
    "    'reg_alpha': 4.58,\n",
    "    'colsample_bytree': 0.92,\n",
    "    'subsample': 0.95,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "# 5-fold Stratified Cross-Validation\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    val_pred = (val_pred_proba >= 0.5).astype(int)\n",
    "    \n",
    "    oof_preds[val_idx] = val_pred_proba\n",
    "    test_preds += model.predict_proba(X_test)[:, 1] / n_folds\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_acc)\n",
    "    print(f\"Fold {fold+1}: Accuracy = {fold_acc:.5f}\")\n",
    "\n",
    "print(f\"\\nMean CV Accuracy: {np.mean(fold_scores):.5f} (+/- {np.std(fold_scores):.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall OOF accuracy\n",
    "oof_binary = (oof_preds >= 0.5).astype(int)\n",
    "overall_acc = accuracy_score(y, oof_binary)\n",
    "print(f\"Overall OOF Accuracy: {overall_acc:.5f}\")\n",
    "\n",
    "# Create submission\n",
    "test_binary = (test_preds >= 0.5).astype(bool)\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Transported': test_binary\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"\\nSubmission saved with {len(submission)} predictions\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e7dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 features:\")\n",
    "print(importance_df.head(15))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
