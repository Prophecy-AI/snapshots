{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27edbd87",
   "metadata": {},
   "source": [
    "# Experiment 005: Threshold Tuning + CatBoost Native Categorical Handling\n",
    "\n",
    "Following strategy priorities:\n",
    "1. Threshold tuning (quick win, hasn't been tried)\n",
    "2. CatBoost native categorical handling (research suggests it outperforms label encoding)\n",
    "\n",
    "Goal: Improve LB generalization, not just CV. Current CV-LB gap is 1.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794c7146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:40:09.143387Z",
     "iopub.status.busy": "2026-01-06T04:40:09.142288Z",
     "iopub.status.idle": "2026-01-06T04:40:10.426789Z",
     "shell.execute_reply": "2026-01-06T04:40:10.426118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8693, 14), Test: (4277, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "print(f\"Train: {train.shape}, Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a946cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:40:10.429174Z",
     "iopub.status.busy": "2026-01-06T04:40:10.428627Z",
     "iopub.status.idle": "2026-01-06T04:40:10.496048Z",
     "shell.execute_reply": "2026-01-06T04:40:10.495371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic features done\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering (same as previous experiments)\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    df['Group'] = df['PassengerId'].apply(lambda x: int(x.split('_')[0]))\n",
    "    df['PassengerNum'] = df['PassengerId'].apply(lambda x: int(x.split('_')[1]))\n",
    "    df['Deck'] = df['Cabin'].apply(lambda x: x.split('/')[0] if pd.notna(x) else 'Unknown')\n",
    "    df['CabinNum'] = df['Cabin'].apply(lambda x: int(x.split('/')[1]) if pd.notna(x) else np.nan)\n",
    "    df['Side'] = df['Cabin'].apply(lambda x: x.split('/')[2] if pd.notna(x) else 'Unknown')\n",
    "    return df\n",
    "\n",
    "train = feature_engineering(train)\n",
    "test = feature_engineering(test)\n",
    "\n",
    "# GroupSize\n",
    "all_data = pd.concat([train[['Group']], test[['Group']]], ignore_index=True)\n",
    "group_sizes = all_data['Group'].value_counts().to_dict()\n",
    "for df in [train, test]:\n",
    "    df['GroupSize'] = df['Group'].map(group_sizes)\n",
    "    df['Solo'] = (df['GroupSize'] == 1).astype(int)\n",
    "print(\"Basic features done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07136ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:40:10.497992Z",
     "iopub.status.busy": "2026-01-06T04:40:10.497758Z",
     "iopub.status.idle": "2026-01-06T04:40:16.386089Z",
     "shell.execute_reply": "2026-01-06T04:40:16.385186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation done\n"
     ]
    }
   ],
   "source": [
    "# Group-based imputation\n",
    "def group_based_imputation(train_df, test_df):\n",
    "    combined = pd.concat([train_df, test_df], ignore_index=True)\n",
    "    \n",
    "    for col in ['HomePlanet', 'Deck', 'Side']:\n",
    "        group_mode = combined.groupby('Group')[col].apply(\n",
    "            lambda x: x.mode()[0] if len(x.mode()) > 0 and x.mode()[0] != 'Unknown' else 'Unknown'\n",
    "        ).to_dict()\n",
    "        \n",
    "        for df in [train_df, test_df]:\n",
    "            mask = (df[col].isna()) | (df[col] == 'Unknown')\n",
    "            df.loc[mask, col] = df.loc[mask, 'Group'].map(group_mode)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train, test = group_based_imputation(train, test)\n",
    "\n",
    "# Remaining imputation\n",
    "def impute_remaining(df):\n",
    "    df = df.copy()\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    \n",
    "    # CryoSleep passengers have 0 spending\n",
    "    for col in spending_cols:\n",
    "        mask = (df['CryoSleep'] == True) & (df[col].isna())\n",
    "        df.loc[mask, col] = 0\n",
    "    \n",
    "    # Categorical - fill with mode\n",
    "    for col in ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']:\n",
    "        if df[col].isna().any() or (df[col] == 'Unknown').any():\n",
    "            mode_val = df[col].replace('Unknown', np.nan).mode()[0]\n",
    "            df[col] = df[col].replace('Unknown', mode_val)\n",
    "            df[col] = df[col].fillna(mode_val)\n",
    "    \n",
    "    # Numerical - fill with median\n",
    "    for col in ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'CabinNum']:\n",
    "        if df[col].isna().any():\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = impute_remaining(train)\n",
    "test = impute_remaining(test)\n",
    "print(\"Imputation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d650c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:40:16.388796Z",
     "iopub.status.busy": "2026-01-06T04:40:16.388519Z",
     "iopub.status.idle": "2026-01-06T04:40:16.474463Z",
     "shell.execute_reply": "2026-01-06T04:40:16.473688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features created\n"
     ]
    }
   ],
   "source": [
    "# Create spending and interaction features\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    \n",
    "    # Spending features\n",
    "    df['TotalSpent'] = df[spending_cols].sum(axis=1)\n",
    "    for col in spending_cols:\n",
    "        df[f'{col}_ratio'] = df[col] / (df['TotalSpent'] + 1)\n",
    "        df[f'{col}_spent'] = (df[col] > 0).astype(int)\n",
    "        df[f'{col}_log'] = np.log1p(df[col])\n",
    "    \n",
    "    df['LuxurySpent'] = df['Spa'] + df['VRDeck'] + df['RoomService']\n",
    "    df['BasicSpent'] = df['FoodCourt'] + df['ShoppingMall']\n",
    "    df['LuxuryRatio'] = df['LuxurySpent'] / (df['TotalSpent'] + 1)\n",
    "    df['SpentPerAge'] = df['TotalSpent'] / (df['Age'] + 1)\n",
    "    df['SpendingBin'] = pd.cut(df['TotalSpent'], bins=[-1, 0, 500, 2000, float('inf')], labels=[0, 1, 2, 3]).astype(int)\n",
    "    df['NumSpendingCategories'] = sum(df[f'{col}_spent'] for col in spending_cols)\n",
    "    df['TotalSpent_log'] = np.log1p(df['TotalSpent'])\n",
    "    df['LuxurySpent_log'] = np.log1p(df['LuxurySpent'])\n",
    "    df['BasicSpent_log'] = np.log1p(df['BasicSpent'])\n",
    "    df['Spa_VRDeck_RoomService'] = df['Spa'] + df['VRDeck'] + df['RoomService']\n",
    "    df['FoodCourt_RoomService'] = df['FoodCourt'] + df['RoomService']\n",
    "    \n",
    "    # Interaction features (keep as strings for CatBoost native handling)\n",
    "    df['CryoSleep_HomePlanet'] = df['CryoSleep'].astype(str) + '_' + df['HomePlanet'].astype(str)\n",
    "    df['CryoSleep_Destination'] = df['CryoSleep'].astype(str) + '_' + df['Destination'].astype(str)\n",
    "    df['Deck_Side'] = df['Deck'].astype(str) + '_' + df['Side'].astype(str)\n",
    "    df['HomePlanet_Destination'] = df['HomePlanet'].astype(str) + '_' + df['Destination'].astype(str)\n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 17, 25, 40, 60, 100], \n",
    "                            labels=['Child', 'Teen', 'YoungAdult', 'Adult', 'MiddleAge', 'Senior']).astype(str)\n",
    "    df['AgeGroup_CryoSleep'] = df['AgeGroup'] + '_' + df['CryoSleep'].astype(str)\n",
    "    df['VIP_HomePlanet'] = df['VIP'].astype(str) + '_' + df['HomePlanet'].astype(str)\n",
    "    \n",
    "    # Age features\n",
    "    df['IsChild'] = (df['Age'] <= 12).astype(int)\n",
    "    df['IsTeen'] = ((df['Age'] > 12) & (df['Age'] <= 17)).astype(int)\n",
    "    df['IsYoungAdult'] = ((df['Age'] > 17) & (df['Age'] <= 25)).astype(int)\n",
    "    df['IsAdult'] = ((df['Age'] > 25) & (df['Age'] <= 60)).astype(int)\n",
    "    df['IsSenior'] = (df['Age'] > 60).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = create_features(train)\n",
    "test = create_features(test)\n",
    "print(\"All features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93cb0fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:40:16.476611Z",
     "iopub.status.busy": "2026-01-06T04:40:16.476389Z",
     "iopub.status.idle": "2026-01-06T04:40:16.507174Z",
     "shell.execute_reply": "2026-01-06T04:40:16.506539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8693, 56), Features: 56\n",
      "Categorical features: 13, Numerical: 43\n"
     ]
    }
   ],
   "source": [
    "# Define features - using native categorical handling for CatBoost\n",
    "# Categorical features (keep as strings)\n",
    "cat_features = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side',\n",
    "                'CryoSleep_HomePlanet', 'CryoSleep_Destination', 'Deck_Side',\n",
    "                'HomePlanet_Destination', 'AgeGroup', 'AgeGroup_CryoSleep', 'VIP_HomePlanet']\n",
    "\n",
    "# Numerical features\n",
    "num_features = [\n",
    "    'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
    "    'Group', 'PassengerNum', 'CabinNum', 'GroupSize', 'Solo',\n",
    "    'TotalSpent', 'LuxurySpent', 'BasicSpent', 'LuxuryRatio', 'SpentPerAge', 'SpendingBin',\n",
    "    'NumSpendingCategories', 'Spa_VRDeck_RoomService', 'FoodCourt_RoomService',\n",
    "    'RoomService_ratio', 'FoodCourt_ratio', 'ShoppingMall_ratio', 'Spa_ratio', 'VRDeck_ratio',\n",
    "    'RoomService_spent', 'FoodCourt_spent', 'ShoppingMall_spent', 'Spa_spent', 'VRDeck_spent',\n",
    "    'RoomService_log', 'FoodCourt_log', 'ShoppingMall_log', 'Spa_log', 'VRDeck_log',\n",
    "    'TotalSpent_log', 'LuxurySpent_log', 'BasicSpent_log',\n",
    "    'IsChild', 'IsTeen', 'IsYoungAdult', 'IsAdult', 'IsSenior'\n",
    "]\n",
    "\n",
    "feature_cols = cat_features + num_features\n",
    "cat_indices = list(range(len(cat_features)))  # First N columns are categorical\n",
    "\n",
    "# Convert categorical columns to string type for CatBoost\n",
    "for col in cat_features:\n",
    "    train[col] = train[col].astype(str)\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "X = train[feature_cols]\n",
    "y = train['Transported'].astype(int).values\n",
    "X_test = test[feature_cols]\n",
    "\n",
    "print(f\"X shape: {X.shape}, Features: {len(feature_cols)}\")\n",
    "print(f\"Categorical features: {len(cat_features)}, Numerical: {len(num_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "055be512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:40:16.509620Z",
     "iopub.status.busy": "2026-01-06T04:40:16.508986Z",
     "iopub.status.idle": "2026-01-06T04:41:09.141000Z",
     "shell.execute_reply": "2026-01-06T04:41:09.140244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 0.81944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: 0.80851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: 0.81484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.82911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: 0.80898\n",
      "\n",
      "CatBoost Native Cat OOF Accuracy: 0.81617 (+/- 0.00762)\n"
     ]
    }
   ],
   "source": [
    "# Train CatBoost with native categorical handling\n",
    "cat_params = {\n",
    "    'depth': 8,\n",
    "    'learning_rate': 0.051,\n",
    "    'iterations': 755,\n",
    "    'l2_leaf_reg': 3.52,\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'cat_features': cat_indices  # Native categorical handling!\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = CatBoostClassifier(**cat_params)\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=100)\n",
    "    \n",
    "    oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_preds += model.predict_proba(X_test)[:, 1] / n_folds\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_preds[val_idx] >= 0.5).astype(int))\n",
    "    fold_scores.append(fold_acc)\n",
    "    print(f\"Fold {fold+1}: {fold_acc:.5f}\")\n",
    "\n",
    "baseline_acc = accuracy_score(y, (oof_preds >= 0.5).astype(int))\n",
    "print(f\"\\nCatBoost Native Cat OOF Accuracy: {baseline_acc:.5f} (+/- {np.std(fold_scores):.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a966f5c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:41:13.946349Z",
     "iopub.status.busy": "2026-01-06T04:41:13.945313Z",
     "iopub.status.idle": "2026-01-06T04:41:13.964696Z",
     "shell.execute_reply": "2026-01-06T04:41:13.963863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== THRESHOLD TUNING ===\n",
      "Threshold 0.40: 0.81077\n",
      "Threshold 0.41: 0.81180\n",
      "Threshold 0.42: 0.81226\n",
      "Threshold 0.43: 0.81341\n",
      "Threshold 0.44: 0.81433\n",
      "Threshold 0.45: 0.81537\n",
      "Threshold 0.46: 0.81824\n",
      "Threshold 0.47: 0.81928\n",
      "Threshold 0.48: 0.81847\n",
      "Threshold 0.49: 0.81686\n",
      "Threshold 0.50: 0.81617\n",
      "Threshold 0.51: 0.81583\n",
      "Threshold 0.52: 0.81571\n",
      "Threshold 0.53: 0.81663\n",
      "Threshold 0.54: 0.81617\n",
      "Threshold 0.55: 0.81629\n",
      "Threshold 0.56: 0.81399\n",
      "Threshold 0.57: 0.81261\n",
      "Threshold 0.58: 0.81192\n",
      "Threshold 0.59: 0.81226\n",
      "\n",
      "Best threshold: 0.47 with accuracy 0.81928\n",
      "Improvement from threshold tuning: +0.00311\n"
     ]
    }
   ],
   "source": [
    "# THRESHOLD TUNING - find optimal threshold\n",
    "print(\"\\n=== THRESHOLD TUNING ===\")\n",
    "thresholds = np.arange(0.40, 0.60, 0.01)\n",
    "best_threshold = 0.5\n",
    "best_acc = 0\n",
    "\n",
    "for t in thresholds:\n",
    "    acc = accuracy_score(y, (oof_preds >= t).astype(int))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_threshold = t\n",
    "    print(f\"Threshold {t:.2f}: {acc:.5f}\")\n",
    "\n",
    "print(f\"\\nBest threshold: {best_threshold:.2f} with accuracy {best_acc:.5f}\")\n",
    "print(f\"Improvement from threshold tuning: {best_acc - baseline_acc:+.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed418d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:41:13.967001Z",
     "iopub.status.busy": "2026-01-06T04:41:13.966726Z",
     "iopub.status.idle": "2026-01-06T04:41:13.971661Z",
     "shell.execute_reply": "2026-01-06T04:41:13.970951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARISON ===\n",
      "exp_003 (tuned CatBoost, label encoding): 0.81951\n",
      "This exp (native cat, threshold=0.47): 0.81928\n",
      "Improvement: -0.00023\n"
     ]
    }
   ],
   "source": [
    "# Compare to previous best (exp_003: CV 0.81951)\n",
    "exp003_cv = 0.81951\n",
    "print(f\"\\n=== COMPARISON ===\")\n",
    "print(f\"exp_003 (tuned CatBoost, label encoding): {exp003_cv:.5f}\")\n",
    "print(f\"This exp (native cat, threshold={best_threshold:.2f}): {best_acc:.5f}\")\n",
    "print(f\"Improvement: {best_acc - exp003_cv:+.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b18cd756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:41:13.973907Z",
     "iopub.status.busy": "2026-01-06T04:41:13.973657Z",
     "iopub.status.idle": "2026-01-06T04:41:13.990564Z",
     "shell.execute_reply": "2026-01-06T04:41:13.989792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved with threshold=0.47\n",
      "Predicted transported rate: 0.5378\n",
      "Training transported rate: 0.5036\n",
      "  PassengerId  Transported\n",
      "0     0013_01         True\n",
      "1     0018_01        False\n",
      "2     0019_01         True\n",
      "3     0021_01         True\n",
      "4     0023_01         True\n"
     ]
    }
   ],
   "source": [
    "# Create submission with best threshold\n",
    "test_binary = (test_preds >= best_threshold).astype(bool)\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Transported': test_binary\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Submission saved with threshold={best_threshold:.2f}\")\n",
    "print(f\"Predicted transported rate: {test_binary.mean():.4f}\")\n",
    "print(f\"Training transported rate: {y.mean():.4f}\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa6a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The native categorical handling didn't help - let's try threshold tuning on the original label-encoded model\n",
    "# Re-train with label encoding to get OOF predictions for threshold tuning\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Reload and process data with label encoding\n",
    "train_le = pd.read_csv('/home/data/train.csv')\n",
    "test_le = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "# Apply same feature engineering\n",
    "train_le = feature_engineering(train_le)\n",
    "test_le = feature_engineering(test_le)\n",
    "\n",
    "# GroupSize\n",
    "for df in [train_le, test_le]:\n",
    "    df['GroupSize'] = df['Group'].map(group_sizes)\n",
    "    df['Solo'] = (df['GroupSize'] == 1).astype(int)\n",
    "\n",
    "train_le, test_le = group_based_imputation(train_le, test_le)\n",
    "train_le = impute_remaining(train_le)\n",
    "test_le = impute_remaining(test_le)\n",
    "train_le = create_features(train_le)\n",
    "test_le = create_features(test_le)\n",
    "\n",
    "# Label encode categorical features\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    combined = pd.concat([train_le[col].astype(str), test_le[col].astype(str)])\n",
    "    le.fit(combined)\n",
    "    train_le[col + '_enc'] = le.transform(train_le[col].astype(str))\n",
    "    test_le[col + '_enc'] = le.transform(test_le[col].astype(str))\n",
    "\n",
    "# Use encoded features\n",
    "feature_cols_le = [col + '_enc' for col in cat_features] + num_features\n",
    "X_le = train_le[feature_cols_le].values\n",
    "X_test_le = test_le[feature_cols_le].values\n",
    "\n",
    "print(f\"Label-encoded features: {len(feature_cols_le)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27768e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train label-encoded CatBoost and apply threshold tuning\n",
    "cat_params_le = {\n",
    "    'depth': 8,\n",
    "    'learning_rate': 0.051,\n",
    "    'iterations': 755,\n",
    "    'l2_leaf_reg': 3.52,\n",
    "    'random_seed': 42,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "oof_le = np.zeros(len(X_le))\n",
    "test_le_preds = np.zeros(len(X_test_le))\n",
    "fold_scores_le = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_le, y)):\n",
    "    X_train, X_val = X_le[train_idx], X_le[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = CatBoostClassifier(**cat_params_le)\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=100)\n",
    "    \n",
    "    oof_le[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_le_preds += model.predict_proba(X_test_le)[:, 1] / n_folds\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_le[val_idx] >= 0.5).astype(int))\n",
    "    fold_scores_le.append(fold_acc)\n",
    "    print(f\"Fold {fold+1}: {fold_acc:.5f}\")\n",
    "\n",
    "le_baseline_acc = accuracy_score(y, (oof_le >= 0.5).astype(int))\n",
    "print(f\"\\nLabel-Encoded CatBoost OOF Accuracy: {le_baseline_acc:.5f} (+/- {np.std(fold_scores_le):.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a8caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold tuning on label-encoded model\n",
    "print(\"\\\\n=== THRESHOLD TUNING (Label-Encoded) ===\")\n",
    "best_threshold_le = 0.5\n",
    "best_acc_le = 0\n",
    "\n",
    "for t in thresholds:\n",
    "    acc = accuracy_score(y, (oof_le >= t).astype(int))\n",
    "    if acc > best_acc_le:\n",
    "        best_acc_le = acc\n",
    "        best_threshold_le = t\n",
    "    print(f\"Threshold {t:.2f}: {acc:.5f}\")\n",
    "\n",
    "print(f\"\\\\nBest threshold: {best_threshold_le:.2f} with accuracy {best_acc_le:.5f}\")\n",
    "print(f\"Improvement from threshold tuning: {best_acc_le - le_baseline_acc:+.5f}\")\n",
    "\n",
    "# Final comparison\n",
    "print(f\"\\\\n=== FINAL COMPARISON ===\")\n",
    "print(f\"exp_003 (tuned CatBoost, threshold=0.5): 0.81951\")\n",
    "print(f\"Native cat + threshold={best_threshold:.2f}: {best_acc:.5f}\")\n",
    "print(f\"Label-encoded + threshold={best_threshold_le:.2f}: {best_acc_le:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10aae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best submission\n",
    "if best_acc_le > best_acc:\n",
    "    print(f\"Label-encoded with threshold {best_threshold_le:.2f} is best!\")\n",
    "    test_binary_final = (test_le_preds >= best_threshold_le).astype(bool)\n",
    "    final_acc = best_acc_le\n",
    "    final_threshold = best_threshold_le\n",
    "else:\n",
    "    print(f\"Native cat with threshold {best_threshold:.2f} is best!\")\n",
    "    test_binary_final = (test_preds >= best_threshold).astype(bool)\n",
    "    final_acc = best_acc\n",
    "    final_threshold = best_threshold\n",
    "\n",
    "submission_final = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Transported': test_binary_final\n",
    "})\n",
    "\n",
    "submission_final.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"\\\\nFinal submission saved with threshold={final_threshold:.2f}\")\n",
    "print(f\"Final CV accuracy: {final_acc:.5f}\")\n",
    "print(f\"Predicted transported rate: {test_binary_final.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
