{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2a5aff",
   "metadata": {},
   "source": [
    "# Experiment 010: Target Encoding + New Features\n",
    "\n",
    "Fundamentally different approach to break through CV ~0.817 plateau:\n",
    "1. Target encoding for categorical features (captures category-target relationships)\n",
    "2. Cabin region features (spatial patterns)\n",
    "3. Family size feature (family correlation)\n",
    "\n",
    "Goal: CV > 0.82089 to beat exp_003's LB of 0.8045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64423e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:26:40.980394Z",
     "iopub.status.busy": "2026-01-06T05:26:40.979578Z",
     "iopub.status.idle": "2026-01-06T05:26:42.207716Z",
     "shell.execute_reply": "2026-01-06T05:26:42.207086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_encoders available\n",
      "Train: (8693, 14), Test: (4277, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if category_encoders is available\n",
    "try:\n",
    "    from category_encoders import TargetEncoder\n",
    "    print(\"category_encoders available\")\n",
    "except ImportError:\n",
    "    print(\"Installing category_encoders...\")\n",
    "    import subprocess\n",
    "    subprocess.run(['pip', 'install', 'category_encoders', '-q'])\n",
    "    from category_encoders import TargetEncoder\n",
    "    print(\"category_encoders installed\")\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "print(f\"Train: {train.shape}, Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e8210db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:26:42.209864Z",
     "iopub.status.busy": "2026-01-06T05:26:42.209638Z",
     "iopub.status.idle": "2026-01-06T05:26:42.293754Z",
     "shell.execute_reply": "2026-01-06T05:26:42.293181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic features done\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering with NEW features\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Basic features\n",
    "    df['Group'] = df['PassengerId'].apply(lambda x: int(x.split('_')[0]))\n",
    "    df['PassengerNum'] = df['PassengerId'].apply(lambda x: int(x.split('_')[1]))\n",
    "    df['Deck'] = df['Cabin'].apply(lambda x: x.split('/')[0] if pd.notna(x) else np.nan)\n",
    "    df['CabinNum'] = df['Cabin'].apply(lambda x: int(x.split('/')[1]) if pd.notna(x) else np.nan)\n",
    "    df['Side'] = df['Cabin'].apply(lambda x: x.split('/')[2] if pd.notna(x) else np.nan)\n",
    "    \n",
    "    # NEW: Extract surname for family features\n",
    "    df['Surname'] = df['Name'].apply(lambda x: x.split()[-1] if pd.notna(x) else 'Unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = feature_engineering(train)\n",
    "test = feature_engineering(test)\n",
    "\n",
    "# GroupSize\n",
    "all_data = pd.concat([train[['Group']], test[['Group']]], ignore_index=True)\n",
    "group_sizes = all_data['Group'].value_counts().to_dict()\n",
    "for df in [train, test]:\n",
    "    df['GroupSize'] = df['Group'].map(group_sizes)\n",
    "    df['Solo'] = (df['GroupSize'] == 1).astype(int)\n",
    "\n",
    "# NEW: Family size from surname\n",
    "all_surnames = pd.concat([train['Surname'], test['Surname']])\n",
    "surname_counts = all_surnames.value_counts().to_dict()\n",
    "for df in [train, test]:\n",
    "    df['FamilySize'] = df['Surname'].map(surname_counts)\n",
    "\n",
    "print(\"Basic features done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95fa94e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:26:42.295550Z",
     "iopub.status.busy": "2026-01-06T05:26:42.295312Z",
     "iopub.status.idle": "2026-01-06T05:26:46.438904Z",
     "shell.execute_reply": "2026-01-06T05:26:46.438185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation done\n"
     ]
    }
   ],
   "source": [
    "# Group-based imputation\n",
    "def group_based_imputation(train_df, test_df):\n",
    "    combined = pd.concat([train_df, test_df], ignore_index=True)\n",
    "    for col in ['HomePlanet', 'Deck', 'Side']:\n",
    "        group_mode = combined.groupby('Group')[col].apply(\n",
    "            lambda x: x.mode()[0] if len(x.mode()) > 0 else np.nan).to_dict()\n",
    "        for df in [train_df, test_df]:\n",
    "            mask = df[col].isna()\n",
    "            df.loc[mask, col] = df.loc[mask, 'Group'].map(group_mode)\n",
    "    return train_df, test_df\n",
    "\n",
    "train, test = group_based_imputation(train, test)\n",
    "\n",
    "# Remaining imputation\n",
    "def impute_remaining(df):\n",
    "    df = df.copy()\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    for col in spending_cols:\n",
    "        mask = (df['CryoSleep'] == True) & (df[col].isna())\n",
    "        df.loc[mask, col] = 0\n",
    "    for col in ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']:\n",
    "        if df[col].isna().any():\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    for col in ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'CabinNum']:\n",
    "        if df[col].isna().any():\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "train = impute_remaining(train)\n",
    "test = impute_remaining(test)\n",
    "print(\"Imputation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb1a1601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:26:46.441244Z",
     "iopub.status.busy": "2026-01-06T05:26:46.441013Z",
     "iopub.status.idle": "2026-01-06T05:26:46.538478Z",
     "shell.execute_reply": "2026-01-06T05:26:46.537890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features created\n"
     ]
    }
   ],
   "source": [
    "# Create features including NEW cabin region features\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    \n",
    "    # Spending features\n",
    "    df['TotalSpent'] = df[spending_cols].sum(axis=1)\n",
    "    for col in spending_cols:\n",
    "        df[f'{col}_ratio'] = df[col] / (df['TotalSpent'] + 1)\n",
    "        df[f'{col}_spent'] = (df[col] > 0).astype(int)\n",
    "        df[f'{col}_log'] = np.log1p(df[col])\n",
    "    \n",
    "    df['LuxurySpent'] = df['Spa'] + df['VRDeck'] + df['RoomService']\n",
    "    df['BasicSpent'] = df['FoodCourt'] + df['ShoppingMall']\n",
    "    df['LuxuryRatio'] = df['LuxurySpent'] / (df['TotalSpent'] + 1)\n",
    "    df['SpentPerAge'] = df['TotalSpent'] / (df['Age'] + 1)\n",
    "    df['SpendingBin'] = pd.cut(df['TotalSpent'], bins=[-1, 0, 500, 2000, float('inf')], labels=[0, 1, 2, 3]).astype(int)\n",
    "    df['NumSpendingCategories'] = sum(df[f'{col}_spent'] for col in spending_cols)\n",
    "    df['TotalSpent_log'] = np.log1p(df['TotalSpent'])\n",
    "    df['LuxurySpent_log'] = np.log1p(df['LuxurySpent'])\n",
    "    df['BasicSpent_log'] = np.log1p(df['BasicSpent'])\n",
    "    df['Spa_VRDeck_RoomService'] = df['Spa'] + df['VRDeck'] + df['RoomService']\n",
    "    df['FoodCourt_RoomService'] = df['FoodCourt'] + df['RoomService']\n",
    "    \n",
    "    # Interaction features\n",
    "    df['CryoSleep_HomePlanet'] = df['CryoSleep'].astype(str) + '_' + df['HomePlanet'].astype(str)\n",
    "    df['CryoSleep_Destination'] = df['CryoSleep'].astype(str) + '_' + df['Destination'].astype(str)\n",
    "    df['Deck_Side'] = df['Deck'].astype(str) + '_' + df['Side'].astype(str)\n",
    "    df['HomePlanet_Destination'] = df['HomePlanet'].astype(str) + '_' + df['Destination'].astype(str)\n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 17, 25, 40, 60, 100], \n",
    "                            labels=['Child', 'Teen', 'YoungAdult', 'Adult', 'MiddleAge', 'Senior']).astype(str)\n",
    "    df['AgeGroup_CryoSleep'] = df['AgeGroup'] + '_' + df['CryoSleep'].astype(str)\n",
    "    df['VIP_HomePlanet'] = df['VIP'].astype(str) + '_' + df['HomePlanet'].astype(str)\n",
    "    \n",
    "    # Age features\n",
    "    df['IsChild'] = (df['Age'] <= 12).astype(int)\n",
    "    df['IsTeen'] = ((df['Age'] > 12) & (df['Age'] <= 17)).astype(int)\n",
    "    df['IsYoungAdult'] = ((df['Age'] > 17) & (df['Age'] <= 25)).astype(int)\n",
    "    df['IsAdult'] = ((df['Age'] > 25) & (df['Age'] <= 60)).astype(int)\n",
    "    df['IsSenior'] = (df['Age'] > 60).astype(int)\n",
    "    \n",
    "    # NEW: Cabin region features (from top kernel)\n",
    "    df['Cabin_region1'] = (df['CabinNum'] < 300).astype(int)\n",
    "    df['Cabin_region2'] = ((df['CabinNum'] >= 300) & (df['CabinNum'] < 600)).astype(int)\n",
    "    df['Cabin_region3'] = ((df['CabinNum'] >= 600) & (df['CabinNum'] < 900)).astype(int)\n",
    "    df['Cabin_region4'] = ((df['CabinNum'] >= 900) & (df['CabinNum'] < 1200)).astype(int)\n",
    "    df['Cabin_region5'] = ((df['CabinNum'] >= 1200) & (df['CabinNum'] < 1500)).astype(int)\n",
    "    df['Cabin_region6'] = ((df['CabinNum'] >= 1500) & (df['CabinNum'] < 1800)).astype(int)\n",
    "    df['Cabin_region7'] = (df['CabinNum'] >= 1800).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = create_features(train)\n",
    "test = create_features(test)\n",
    "print(\"Features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defb4295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:26:46.540386Z",
     "iopub.status.busy": "2026-01-06T05:26:46.540131Z",
     "iopub.status.idle": "2026-01-06T05:26:46.560227Z",
     "shell.execute_reply": "2026-01-06T05:26:46.559688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns for target encoding: 13\n",
      "Numerical features: 51\n"
     ]
    }
   ],
   "source": [
    "# Define categorical columns for target encoding\n",
    "cat_cols_for_te = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side',\n",
    "                   'CryoSleep_HomePlanet', 'CryoSleep_Destination', 'Deck_Side',\n",
    "                   'HomePlanet_Destination', 'AgeGroup', 'AgeGroup_CryoSleep', 'VIP_HomePlanet']\n",
    "\n",
    "# Convert to string for encoding\n",
    "for col in cat_cols_for_te:\n",
    "    train[col] = train[col].astype(str)\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "# Numerical features (keep as-is)\n",
    "num_features = [\n",
    "    'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
    "    'Group', 'PassengerNum', 'CabinNum', 'GroupSize', 'Solo', 'FamilySize',\n",
    "    'TotalSpent', 'LuxurySpent', 'BasicSpent', 'LuxuryRatio', 'SpentPerAge', 'SpendingBin',\n",
    "    'NumSpendingCategories', 'Spa_VRDeck_RoomService', 'FoodCourt_RoomService',\n",
    "    'RoomService_ratio', 'FoodCourt_ratio', 'ShoppingMall_ratio', 'Spa_ratio', 'VRDeck_ratio',\n",
    "    'RoomService_spent', 'FoodCourt_spent', 'ShoppingMall_spent', 'Spa_spent', 'VRDeck_spent',\n",
    "    'RoomService_log', 'FoodCourt_log', 'ShoppingMall_log', 'Spa_log', 'VRDeck_log',\n",
    "    'TotalSpent_log', 'LuxurySpent_log', 'BasicSpent_log',\n",
    "    'IsChild', 'IsTeen', 'IsYoungAdult', 'IsAdult', 'IsSenior',\n",
    "    'Cabin_region1', 'Cabin_region2', 'Cabin_region3', 'Cabin_region4',\n",
    "    'Cabin_region5', 'Cabin_region6', 'Cabin_region7'\n",
    "]\n",
    "\n",
    "y = train['Transported'].astype(int).values\n",
    "print(f\"Categorical columns for target encoding: {len(cat_cols_for_te)}\")\n",
    "print(f\"Numerical features: {len(num_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc41ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CatBoost with TARGET ENCODING (CV-based to avoid leakage)\n",
    "cat_params = {\n",
    "    'depth': 8,\n",
    "    'learning_rate': 0.051,\n",
    "    'iterations': 755,\n",
    "    'l2_leaf_reg': 3.52,\n",
    "    'random_seed': 42,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds = np.zeros(len(train))\n",
    "test_preds = np.zeros(len(test))\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train, y)):\n",
    "    # Split data\n",
    "    X_train_fold = train.iloc[train_idx].reset_index(drop=True)\n",
    "    X_val_fold = train.iloc[val_idx].reset_index(drop=True)\n",
    "    y_train_fold = y[train_idx]\n",
    "    y_val_fold = y[val_idx]\n",
    "    X_test_fold = test.reset_index(drop=True)\n",
    "    \n",
    "    # Target encoding - fit on train fold only to avoid leakage\n",
    "    te = TargetEncoder(cols=cat_cols_for_te, smoothing=1.0)\n",
    "    te.fit(X_train_fold[cat_cols_for_te], y_train_fold)\n",
    "    \n",
    "    # Transform categorical columns\n",
    "    X_train_te = te.transform(X_train_fold[cat_cols_for_te])\n",
    "    X_val_te = te.transform(X_val_fold[cat_cols_for_te])\n",
    "    X_test_te = te.transform(X_test_fold[cat_cols_for_te])\n",
    "    \n",
    "    # Combine with numerical features\n",
    "    X_train_final = pd.concat([X_train_te.reset_index(drop=True), X_train_fold[num_features].reset_index(drop=True)], axis=1)\n",
    "    X_val_final = pd.concat([X_val_te.reset_index(drop=True), X_val_fold[num_features].reset_index(drop=True)], axis=1)\n",
    "    X_test_final = pd.concat([X_test_te.reset_index(drop=True), X_test_fold[num_features].reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    # Train CatBoost\n",
    "    model = CatBoostClassifier(**cat_params)\n",
    "    model.fit(X_train_final, y_train_fold, eval_set=(X_val_final, y_val_fold), early_stopping_rounds=100)\n",
    "    \n",
    "    # Predictions\n",
    "    oof_preds[val_idx] = model.predict_proba(X_val_final)[:, 1]\n",
    "    test_preds += model.predict_proba(X_test_final)[:, 1] / n_folds\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val_fold, (oof_preds[val_idx] >= 0.5).astype(int))\n",
    "    fold_scores.append(fold_acc)\n",
    "    print(f\"Fold {fold+1}: {fold_acc:.5f}\")\n",
    "\n",
    "final_acc = accuracy_score(y, (oof_preds >= 0.5).astype(int))\n",
    "print(f\"\\nTarget Encoding CatBoost CV: {final_acc:.5f} (+/- {np.std(fold_scores):.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da523218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with previous best\n",
    "print(\"\\n=== COMPARISON ===\")\n",
    "print(f\"Target Encoding CV: {final_acc:.5f}\")\n",
    "print(f\"exp_008 (multi-seed): 0.81698\")\n",
    "print(f\"exp_003 (best LB):    0.81951\")\n",
    "print(f\"\\nImprovement over exp_008: {final_acc - 0.81698:+.5f}\")\n",
    "print(f\"Gap to exp_003:          {final_acc - 0.81951:+.5f}\")\n",
    "\n",
    "# Check if we beat the threshold needed for LB improvement\n",
    "print(f\"\\nTo beat LB 0.8045, need CV > 0.82089\")\n",
    "if final_acc > 0.82089:\n",
    "    print(\">>> SUBMIT THIS! CV exceeds threshold.\")\n",
    "else:\n",
    "    print(f\">>> CV is {0.82089 - final_acc:.5f} below threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "test_binary = (test_preds >= 0.5).astype(bool)\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Transported': test_binary\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"\\nSubmission saved\")\n",
    "print(f\"CV: {final_acc:.5f}\")\n",
    "print(f\"Predicted transported rate: {test_binary.mean():.4f}\")\n",
    "print(f\"Training transported rate: {y.mean():.4f}\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
