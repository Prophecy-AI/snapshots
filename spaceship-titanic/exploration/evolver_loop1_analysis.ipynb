{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49348659",
   "metadata": {},
   "source": [
    "# Loop 1 Analysis: Target Score Assessment & Strategy Refinement\n",
    "\n",
    "## Key Finding: Target Score of 0.9642 is Unrealistic\n",
    "\n",
    "Based on web research, the highest reported leaderboard scores for Spaceship Titanic are ~0.8066 (80.7%), achieved by top 7% solutions. The target of 0.9642 appears to be either:\n",
    "1. An error in the target specification\n",
    "2. Based on a different metric\n",
    "3. Achieved through some data leakage or special technique not documented\n",
    "\n",
    "## Current Status\n",
    "- Baseline XGBoost CV: 0.80674 (+/- 0.00469)\n",
    "- This is already competitive with top 7% solutions!\n",
    "\n",
    "## Strategy Implications\n",
    "Since we're already near the top of the leaderboard, we should:\n",
    "1. Focus on incremental improvements (0.5-1% gains)\n",
    "2. Implement ensemble of XGBoost + LightGBM + CatBoost\n",
    "3. Add interaction features\n",
    "4. Improve imputation with group-based and KNN methods\n",
    "5. Submit to get LB feedback and calibrate CV-LB gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37505d55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:05:22.111568Z",
     "iopub.status.busy": "2026-01-06T04:05:22.110555Z",
     "iopub.status.idle": "2026-01-06T04:05:22.619573Z",
     "shell.execute_reply": "2026-01-06T04:05:22.618816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8693, 14)\n",
      "Test shape: (4277, 13)\n",
      "\n",
      "Target distribution:\n",
      "Transported\n",
      "True     0.503624\n",
      "False    0.496376\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data to analyze current state\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train['Transported'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7f6f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:05:22.622458Z",
     "iopub.status.busy": "2026-01-06T04:05:22.621819Z",
     "iopub.status.idle": "2026-01-06T04:05:22.635469Z",
     "shell.execute_reply": "2026-01-06T04:05:22.634818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transported rate by spending status:\n",
      "AnySpending\n",
      "0    0.786477\n",
      "1    0.298611\n",
      "Name: Transported, dtype: float64\n",
      "\n",
      "Non-spenders: 3653 (42.0%)\n",
      "Spenders: 5040 (58.0%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze the feature importance issue from baseline\n",
    "# AnySpending had 0.82 importance - let's understand why\n",
    "\n",
    "# Calculate spending patterns\n",
    "spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "train['TotalSpent'] = train[spending_cols].sum(axis=1)\n",
    "train['AnySpending'] = (train['TotalSpent'] > 0).astype(int)\n",
    "\n",
    "# Transported rate by spending\n",
    "print(\"Transported rate by spending status:\")\n",
    "print(train.groupby('AnySpending')['Transported'].mean())\n",
    "print(f\"\\nNon-spenders: {(train['AnySpending']==0).sum()} ({(train['AnySpending']==0).mean()*100:.1f}%)\")\n",
    "print(f\"Spenders: {(train['AnySpending']==1).sum()} ({(train['AnySpending']==1).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abeb228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:05:22.638114Z",
     "iopub.status.busy": "2026-01-06T04:05:22.637440Z",
     "iopub.status.idle": "2026-01-06T04:05:22.647639Z",
     "shell.execute_reply": "2026-01-06T04:05:22.646962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CryoSleep analysis:\n",
      "CryoSleep\n",
      "False    0.328921\n",
      "True     0.817583\n",
      "Name: Transported, dtype: float64\n",
      "\n",
      "CryoSleep passengers with spending > 0:\n",
      "  Count with spending > 0: 0\n",
      "  This suggests CryoSleep=True should have 0 spending (domain knowledge)\n"
     ]
    }
   ],
   "source": [
    "# CryoSleep analysis - this is the strongest predictor\n",
    "print(\"\\nCryoSleep analysis:\")\n",
    "print(train.groupby('CryoSleep')['Transported'].mean())\n",
    "\n",
    "# CryoSleep and spending relationship\n",
    "print(\"\\nCryoSleep passengers with spending > 0:\")\n",
    "cryo_spending = train[train['CryoSleep']==True]['TotalSpent']\n",
    "print(f\"  Count with spending > 0: {(cryo_spending > 0).sum()}\")\n",
    "print(f\"  This suggests CryoSleep=True should have 0 spending (domain knowledge)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a27512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:05:22.650045Z",
     "iopub.status.busy": "2026-01-06T04:05:22.649460Z",
     "iopub.status.idle": "2026-01-06T04:05:22.678056Z",
     "shell.execute_reply": "2026-01-06T04:05:22.677355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interaction analysis: CryoSleep × HomePlanet\n",
      "                          mean  count\n",
      "CryoSleep HomePlanet                 \n",
      "False     Earth       0.320992   3106\n",
      "          Europa      0.400172   1162\n",
      "          Mars        0.276982   1047\n",
      "True      Earth       0.656295   1382\n",
      "          Europa      0.989023    911\n",
      "          Mars        0.911809    669\n",
      "\n",
      "Interaction analysis: Deck × Side\n",
      "               mean  count\n",
      "Deck Side                 \n",
      "A    P     0.435897    117\n",
      "     S     0.546763    139\n",
      "B    P     0.674221    353\n",
      "     S     0.784038    426\n",
      "C    P     0.580645    341\n",
      "     S     0.763547    406\n",
      "D    P     0.403226    248\n",
      "     S     0.465217    230\n",
      "E    P     0.342657    429\n",
      "     S     0.371365    447\n",
      "F    P     0.410987   1438\n",
      "     S     0.470501   1356\n",
      "G    P     0.448276   1276\n",
      "     S     0.583788   1283\n",
      "T    P     0.250000      4\n",
      "     S     0.000000      1\n"
     ]
    }
   ],
   "source": [
    "# Analyze potential for improvement through interaction features\n",
    "print(\"\\nInteraction analysis: CryoSleep × HomePlanet\")\n",
    "interaction = train.groupby(['CryoSleep', 'HomePlanet'])['Transported'].agg(['mean', 'count'])\n",
    "print(interaction)\n",
    "\n",
    "print(\"\\nInteraction analysis: Deck × Side\")\n",
    "# Parse cabin\n",
    "train['Deck'] = train['Cabin'].apply(lambda x: x.split('/')[0] if pd.notna(x) else np.nan)\n",
    "train['Side'] = train['Cabin'].apply(lambda x: x.split('/')[2] if pd.notna(x) else np.nan)\n",
    "interaction2 = train.groupby(['Deck', 'Side'])['Transported'].agg(['mean', 'count'])\n",
    "print(interaction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53cdf20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:05:22.680146Z",
     "iopub.status.busy": "2026-01-06T04:05:22.679919Z",
     "iopub.status.idle": "2026-01-06T04:05:22.825044Z",
     "shell.execute_reply": "2026-01-06T04:05:22.824420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group size distribution:\n",
      "count\n",
      "1    4805\n",
      "2     841\n",
      "3     340\n",
      "4     103\n",
      "5      53\n",
      "6      29\n",
      "7      33\n",
      "8      13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "HomePlanet consistency within groups (for groups with 2+ members):\n",
      "  Groups with consistent HomePlanet: 100/100 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Group-based analysis for imputation improvement\n",
    "train['Group'] = train['PassengerId'].apply(lambda x: x.split('_')[0])\n",
    "group_sizes = train['Group'].value_counts()\n",
    "\n",
    "print(\"\\nGroup size distribution:\")\n",
    "print(group_sizes.value_counts().sort_index())\n",
    "\n",
    "# Check if group members share characteristics\n",
    "print(\"\\nHomePlanet consistency within groups (for groups with 2+ members):\")\n",
    "multi_member_groups = group_sizes[group_sizes > 1].index\n",
    "group_consistency = []\n",
    "for g in list(multi_member_groups)[:100]:  # Sample 100 groups\n",
    "    group_data = train[train['Group'] == g]['HomePlanet'].dropna()\n",
    "    if len(group_data) > 1:\n",
    "        group_consistency.append(group_data.nunique() == 1)\n",
    "\n",
    "print(f\"  Groups with consistent HomePlanet: {sum(group_consistency)}/{len(group_consistency)} ({sum(group_consistency)/len(group_consistency)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40028b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T04:05:22.827702Z",
     "iopub.status.busy": "2026-01-06T04:05:22.827072Z",
     "iopub.status.idle": "2026-01-06T04:05:22.832593Z",
     "shell.execute_reply": "2026-01-06T04:05:22.832021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KEY FINDINGS FOR STRATEGY\n",
      "============================================================\n",
      "\n",
      "1. TARGET SCORE ASSESSMENT:\n",
      "   - Target of 0.9642 is unrealistic (top LB scores are ~0.8066)\n",
      "   - Our baseline of 0.80674 is already competitive!\n",
      "\n",
      "2. FEATURE IMPORTANCE ISSUE:\n",
      "   - AnySpending dominates (0.82 importance)\n",
      "   - Need more nuanced spending features and interactions\n",
      "\n",
      "3. HIGH-LEVERAGE IMPROVEMENTS:\n",
      "   a) Ensemble: XGBoost + LightGBM + CatBoost\n",
      "   b) Interaction features: CryoSleep×HomePlanet, Deck×Side\n",
      "   c) Group-based imputation (groups share characteristics)\n",
      "   d) Remove/modify AnySpending to let model learn nuances\n",
      "\n",
      "4. NEXT STEPS:\n",
      "   - Submit baseline to get LB feedback\n",
      "   - Implement 3-model ensemble\n",
      "   - Add interaction features\n"
     ]
    }
   ],
   "source": [
    "# Summary of key findings for strategy\n",
    "print(\"=\"*60)\n",
    "print(\"KEY FINDINGS FOR STRATEGY\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. TARGET SCORE ASSESSMENT:\")\n",
    "print(\"   - Target of 0.9642 is unrealistic (top LB scores are ~0.8066)\")\n",
    "print(\"   - Our baseline of 0.80674 is already competitive!\")\n",
    "print(\"\\n2. FEATURE IMPORTANCE ISSUE:\")\n",
    "print(\"   - AnySpending dominates (0.82 importance)\")\n",
    "print(\"   - Need more nuanced spending features and interactions\")\n",
    "print(\"\\n3. HIGH-LEVERAGE IMPROVEMENTS:\")\n",
    "print(\"   a) Ensemble: XGBoost + LightGBM + CatBoost\")\n",
    "print(\"   b) Interaction features: CryoSleep×HomePlanet, Deck×Side\")\n",
    "print(\"   c) Group-based imputation (groups share characteristics)\")\n",
    "print(\"   d) Remove/modify AnySpending to let model learn nuances\")\n",
    "print(\"\\n4. NEXT STEPS:\")\n",
    "print(\"   - Submit baseline to get LB feedback\")\n",
    "print(\"   - Implement 3-model ensemble\")\n",
    "print(\"   - Add interaction features\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
