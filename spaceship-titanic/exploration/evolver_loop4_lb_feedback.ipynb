{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d3a0a3",
   "metadata": {},
   "source": [
    "# Loop 4 LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- exp_003 (Tuned CatBoost): CV 0.8195 → LB 0.8045 (gap: +0.0150)\n",
    "- exp_000 (XGBoost Baseline): CV 0.8067 → LB 0.7971 (gap: +0.0097)\n",
    "\n",
    "## Key Questions\n",
    "1. Why did the CV-LB gap increase from 0.97% to 1.50%?\n",
    "2. What approaches can reduce this gap?\n",
    "3. What's the best path to beat top LB (~0.8066)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3595cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CV-LB Gap Analysis\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'model': 'XGBoost Baseline', 'cv': 0.80674, 'lb': 0.79705},\n",
    "    {'exp': 'exp_003', 'model': 'Tuned CatBoost', 'cv': 0.81951, 'lb': 0.80453}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "df['gap'] = df['cv'] - df['lb']\n",
    "df['gap_pct'] = df['gap'] / df['cv'] * 100\n",
    "\n",
    "print(\"CV-LB Gap Analysis:\")\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nAverage gap: {df['gap'].mean():.5f} ({df['gap_pct'].mean():.2f}%)\")\n",
    "print(f\"\\nObservation: Gap increased from {df.iloc[0]['gap']:.5f} to {df.iloc[1]['gap']:.5f}\")\n",
    "print(f\"This suggests the tuned model is slightly overfitting to CV folds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would different CV scores predict for LB?\n",
    "print(\"\\nLB Prediction Calibration:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Using average gap\n",
    "avg_gap = df['gap'].mean()\n",
    "print(f\"Using average gap of {avg_gap:.5f}:\")\n",
    "for cv in [0.82, 0.825, 0.83]:\n",
    "    predicted_lb = cv - avg_gap\n",
    "    print(f\"  CV {cv:.3f} → Predicted LB {predicted_lb:.4f}\")\n",
    "\n",
    "# Using conservative gap (from tuned model)\n",
    "conservative_gap = df.iloc[1]['gap']\n",
    "print(f\"\\nUsing conservative gap of {conservative_gap:.5f} (from tuned model):\")\n",
    "for cv in [0.82, 0.825, 0.83]:\n",
    "    predicted_lb = cv - conservative_gap\n",
    "    print(f\"  CV {cv:.3f} → Predicted LB {predicted_lb:.4f}\")\n",
    "\n",
    "print(f\"\\nTo beat top LB of ~0.8066, we need:\")\n",
    "print(f\"  - CV of {0.8066 + avg_gap:.4f} (using avg gap)\")\n",
    "print(f\"  - CV of {0.8066 + conservative_gap:.4f} (using conservative gap)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3177b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what's working and what's not\n",
    "print(\"\\nExperiment Trajectory Analysis:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "experiments = [\n",
    "    {'exp': 'exp_000', 'model': 'XGBoost Baseline', 'cv': 0.80674, 'lb': 0.79705, 'features': 35},\n",
    "    {'exp': 'exp_001', 'model': 'XGBoost + Features', 'cv': 0.80927, 'lb': None, 'features': 56},\n",
    "    {'exp': 'exp_002', 'model': '3-Model Ensemble', 'cv': 0.81353, 'lb': None, 'features': 56},\n",
    "    {'exp': 'exp_003', 'model': 'Tuned CatBoost', 'cv': 0.81951, 'lb': 0.80453, 'features': 56}\n",
    "]\n",
    "\n",
    "print(\"\\nCV Improvements:\")\n",
    "for i in range(1, len(experiments)):\n",
    "    prev = experiments[i-1]\n",
    "    curr = experiments[i]\n",
    "    cv_delta = curr['cv'] - prev['cv']\n",
    "    print(f\"  {prev['exp']} → {curr['exp']}: {cv_delta:+.5f} ({cv_delta/prev['cv']*100:+.2f}%)\")\n",
    "\n",
    "print(\"\\nLB Improvement:\")\n",
    "lb_delta = 0.80453 - 0.79705\n",
    "print(f\"  exp_000 → exp_003: {lb_delta:+.5f} ({lb_delta/0.79705*100:+.2f}%)\")\n",
    "print(f\"\\nKey insight: LB improved by {lb_delta:.4f} while CV improved by {0.81951-0.80674:.4f}\")\n",
    "print(f\"LB improvement rate: {lb_delta/(0.81951-0.80674)*100:.1f}% of CV improvement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957000bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unexplored approaches analysis\n",
    "print(\"\\nUnexplored Approaches:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "approaches = [\n",
    "    ('Threshold tuning', 'Quick win, default 0.5 may not be optimal', 'High'),\n",
    "    ('CatBoost native categoricals', 'Use cat_features instead of label encoding', 'Medium'),\n",
    "    ('Feature selection', 'Remove low-importance features (56 may have noise)', 'Medium'),\n",
    "    ('Stacking with meta-learner', 'Use OOF predictions as features for LR', 'Medium'),\n",
    "    ('Blend baseline + tuned', 'Average to reduce variance', 'Low'),\n",
    "    ('Pseudo-labeling', 'Use high-confidence test predictions', 'Low'),\n",
    "    ('Different CV strategy', 'Use different seeds to reduce fold overfitting', 'Medium')\n",
    "]\n",
    "\n",
    "print(f\"{'Approach':<30} {'Rationale':<50} {'Priority'}\")\n",
    "print(\"-\"*90)\n",
    "for approach, rationale, priority in approaches:\n",
    "    print(f\"{approach:<30} {rationale:<50} {priority}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priority recommendations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRIORITY RECOMMENDATIONS FOR NEXT LOOP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. THRESHOLD TUNING (Immediate)\n",
    "   - We have OOF predictions from tuned CatBoost\n",
    "   - Default threshold of 0.5 may not be optimal\n",
    "   - Target distribution is 50.36% transported\n",
    "   - Potential gain: 0.1-0.3% on CV, may translate to LB\n",
    "\n",
    "2. CATBOOST NATIVE CATEGORICAL HANDLING (High Priority)\n",
    "   - Currently using label encoding for all categoricals\n",
    "   - CatBoost's cat_features parameter can improve performance\n",
    "   - This is a known best practice we haven't tried\n",
    "   - Potential gain: 0.1-0.5%\n",
    "\n",
    "3. BLEND BASELINE + TUNED CATBOOST (Medium Priority)\n",
    "   - Baseline CatBoost: CV 0.81836, std 0.00431 (lower variance)\n",
    "   - Tuned CatBoost: CV 0.81951, std 0.00685 (higher variance)\n",
    "   - Blending may reduce the CV-LB gap\n",
    "   - Potential gain: Better LB generalization\n",
    "\n",
    "4. STACKING WITH META-LEARNER (Medium Priority)\n",
    "   - Use OOF predictions from XGBoost, LightGBM, CatBoost\n",
    "   - Train logistic regression on OOF predictions\n",
    "   - May capture complementary patterns\n",
    "   - Potential gain: 0.2-0.5%\n",
    "\n",
    "5. FEATURE SELECTION (Lower Priority)\n",
    "   - 56 features may include noise\n",
    "   - Try removing bottom 10-20% by importance\n",
    "   - May reduce overfitting and improve LB\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nTarget: Beat LB 0.8066 (top solutions)\")\n",
    "print(f\"Current best LB: 0.8045 (gap to target: {0.8066-0.8045:.4f})\")\n",
    "print(f\"Remaining submissions: 8\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
