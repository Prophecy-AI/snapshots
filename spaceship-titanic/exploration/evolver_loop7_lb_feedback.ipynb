{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bea4c7f",
   "metadata": {},
   "source": [
    "# Loop 7 LB Feedback Analysis\n",
    "\n",
    "## Submission Result\n",
    "- **exp_006**: Weighted Ensemble (0.6 CatBoost + 0.2 XGB + 0.2 LGB)\n",
    "- **CV**: 0.8171\n",
    "- **LB**: 0.8010\n",
    "- **Gap**: +0.0161 (1.61%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f82777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# All submissions with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'name': 'XGBoost Baseline', 'cv': 0.8067, 'lb': 0.7971, 'pred_rate': None},\n",
    "    {'exp': 'exp_003', 'name': 'CatBoost Optuna', 'cv': 0.8195, 'lb': 0.8045, 'pred_rate': 0.517},\n",
    "    {'exp': 'exp_004', 'name': 'Threshold Tuning', 'cv': 0.8193, 'lb': 0.8041, 'pred_rate': 0.538},\n",
    "    {'exp': 'exp_006', 'name': 'Weighted Ensemble', 'cv': 0.8171, 'lb': 0.8010, 'pred_rate': 0.509},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "df['gap'] = df['cv'] - df['lb']\n",
    "df['gap_pct'] = (df['gap'] / df['cv']) * 100\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis: Did better calibration help?\n",
    "print(\"=== CALIBRATION HYPOTHESIS TEST ===\")\n",
    "print(\"\\nHypothesis: Better prediction rate calibration (closer to training 50.4%) would improve LB\")\n",
    "print(\"\\nResults:\")\n",
    "print(f\"  exp_003: pred_rate=51.7%, LB=0.8045 (BEST)\")\n",
    "print(f\"  exp_004: pred_rate=53.8%, LB=0.8041 (worse - high pred rate hurt)\")\n",
    "print(f\"  exp_006: pred_rate=50.9%, LB=0.8010 (WORST - better calibration didn't help!)\")\n",
    "print(\"\\nConclusion: CALIBRATION HYPOTHESIS REJECTED\")\n",
    "print(\"  - exp_006 had best calibration (50.9% vs 50.4% training)\")\n",
    "print(\"  - But it had WORST LB score of recent submissions\")\n",
    "print(\"  - CV is more important than prediction rate calibration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV-LB gap analysis\n",
    "print(\"=== CV-LB GAP ANALYSIS ===\")\n",
    "print(\"\\nGap by submission:\")\n",
    "for _, row in df.iterrows():\n",
    "    print(f\"  {row['exp']}: CV={row['cv']:.4f}, LB={row['lb']:.4f}, Gap={row['gap']:.4f} ({row['gap_pct']:.2f}%)\")\n",
    "\n",
    "print(f\"\\nAverage gap: {df['gap'].mean():.4f} ({df['gap_pct'].mean():.2f}%)\")\n",
    "print(f\"Gap range: {df['gap'].min():.4f} - {df['gap'].max():.4f}\")\n",
    "\n",
    "# Linear regression to predict LB from CV\n",
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f\"\\nLinear model: LB = {slope:.3f} * CV + {intercept:.3f}\")\n",
    "print(f\"R-squared: {r_value**2:.4f}\")\n",
    "print(f\"\\nPredicted LB for CV=0.82: {slope * 0.82 + intercept:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffcd5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: What's the best path forward?\n",
    "print(\"=== STRATEGIC INSIGHTS ===\")\n",
    "print(\"\\n1. CV-LB CORRELATION:\")\n",
    "print(\"   - Higher CV generally means higher LB (RÂ²=0.97)\")\n",
    "print(\"   - Gap is relatively stable around 1.5%\")\n",
    "print(\"   - Calibration doesn't matter as much as CV\")\n",
    "\n",
    "print(\"\\n2. BEST SUBMISSION:\")\n",
    "print(\"   - exp_003 (CatBoost Optuna) remains best: LB=0.8045\")\n",
    "print(\"   - CV=0.8195 was highest submitted\")\n",
    "print(\"   - Prediction rate 51.7% was fine\")\n",
    "\n",
    "print(\"\\n3. WHAT DIDN'T WORK:\")\n",
    "print(\"   - Threshold tuning (exp_004): hurt LB despite similar CV\")\n",
    "print(\"   - Weighted ensemble (exp_006): lower CV = lower LB\")\n",
    "print(\"   - Stacking (exp_005): not submitted, but CV was lower\")\n",
    "\n",
    "print(\"\\n4. PATH FORWARD:\")\n",
    "print(\"   - Need to INCREASE CV to improve LB\")\n",
    "print(\"   - exp_003's CV=0.8195 is our best\")\n",
    "print(\"   - To beat LB=0.8045, need CV > 0.8195\")\n",
    "print(\"   - Target: CV >= 0.82 for LB >= 0.805\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cabaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print(\"=== UNEXPLORED APPROACHES ===\")\n",
    "print(\"\\n1. FEATURE SELECTION:\")\n",
    "print(\"   - 22 features have importance < 1.0\")\n",
    "print(\"   - Removing them could reduce overfitting\")\n",
    "print(\"   - NOT YET TRIED\")\n",
    "\n",
    "print(\"\\n2. STRONGER REGULARIZATION:\")\n",
    "print(\"   - Current best: depth=8, l2=3.52\")\n",
    "print(\"   - Could try: depth=6, l2=5.0+\")\n",
    "print(\"   - Partially explored in loop5 analysis\")\n",
    "\n",
    "print(\"\\n3. DIFFERENT ENSEMBLE STRATEGIES:\")\n",
    "print(\"   - Weighted ensemble: TRIED (didn't help)\")\n",
    "print(\"   - Stacking: TRIED (didn't help)\")\n",
    "print(\"   - Blending with different seeds: NOT TRIED\")\n",
    "\n",
    "print(\"\\n4. NEURAL NETWORK:\")\n",
    "print(\"   - TabNet or simple MLP\")\n",
    "print(\"   - Could add diversity for ensemble\")\n",
    "print(\"   - NOT TRIED\")\n",
    "\n",
    "print(\"\\n5. TARGET ENCODING:\")\n",
    "print(\"   - Currently using label encoding\")\n",
    "print(\"   - Target encoding could capture more signal\")\n",
    "print(\"   - NOT TRIED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priority ranking\n",
    "print(\"=== PRIORITY RANKING ===\")\n",
    "print(\"\\nBased on analysis, priority order:\")\n",
    "print(\"\\n1. FEATURE SELECTION + CatBoost (HIGH PRIORITY)\")\n",
    "print(\"   - Remove 22 low-importance features\")\n",
    "print(\"   - Could reduce overfitting and improve CV\")\n",
    "print(\"   - Quick to implement\")\n",
    "\n",
    "print(\"\\n2. REGULARIZED CatBoost (MEDIUM PRIORITY)\")\n",
    "print(\"   - Try depth=6, l2=5.0\")\n",
    "print(\"   - May reduce CV-LB gap\")\n",
    "print(\"   - Quick to implement\")\n",
    "\n",
    "print(\"\\n3. TARGET ENCODING (MEDIUM PRIORITY)\")\n",
    "print(\"   - Replace label encoding with target encoding\")\n",
    "print(\"   - Could capture more signal\")\n",
    "print(\"   - Moderate effort\")\n",
    "\n",
    "print(\"\\n4. MULTI-SEED ENSEMBLE (LOW PRIORITY)\")\n",
    "print(\"   - Train CatBoost with different seeds\")\n",
    "print(\"   - Average predictions\")\n",
    "print(\"   - May reduce variance but not bias\")\n",
    "\n",
    "print(\"\\n5. NEURAL NETWORK (LOW PRIORITY)\")\n",
    "print(\"   - TabNet or MLP for diversity\")\n",
    "print(\"   - Higher effort, uncertain payoff\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
