{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c75461",
   "metadata": {},
   "source": [
    "# Loop 10 Analysis: Post-Target Encoding Assessment\n",
    "\n",
    "## Key Questions:\n",
    "1. Why did target encoding HURT performance?\n",
    "2. What approaches remain unexplored?\n",
    "3. What's the realistic path forward?\n",
    "\n",
    "## Evaluator's Key Points:\n",
    "- Target encoding performed WORSE than label encoding (0.81560 vs 0.81698)\n",
    "- We've been stuck for 7 experiments without beating exp_003's CV of 0.81951\n",
    "- exp_003 was likely a lucky Optuna run\n",
    "- Target score (0.9642) is impossible - top LB is ~0.8066\n",
    "- Suggests: 10-fold CV + regularization to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c26e1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:30:56.436024Z",
     "iopub.status.busy": "2026-01-06T05:30:56.435251Z",
     "iopub.status.idle": "2026-01-06T05:30:57.330414Z",
     "shell.execute_reply": "2026-01-06T05:30:57.329762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission History:\n",
      "    exp      cv      lb          approach     gap  gap_pct\n",
      "exp_000 0.80674 0.79705  XGBoost baseline 0.00969     1.20\n",
      "exp_003 0.81951 0.80453   CatBoost Optuna 0.01498     1.83\n",
      "exp_004 0.81928 0.80406  Threshold tuning 0.01522     1.86\n",
      "exp_006 0.81709 0.80102 Weighted ensemble 0.01607     1.97\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load submission history for analysis\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.80674, 'lb': 0.79705, 'approach': 'XGBoost baseline'},\n",
    "    {'exp': 'exp_003', 'cv': 0.81951, 'lb': 0.80453, 'approach': 'CatBoost Optuna'},\n",
    "    {'exp': 'exp_004', 'cv': 0.81928, 'lb': 0.80406, 'approach': 'Threshold tuning'},\n",
    "    {'exp': 'exp_006', 'cv': 0.81709, 'lb': 0.80102, 'approach': 'Weighted ensemble'},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "df['gap'] = df['cv'] - df['lb']\n",
    "df['gap_pct'] = (df['gap'] / df['cv'] * 100).round(2)\n",
    "print(\"Submission History:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8defc95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:30:57.333141Z",
     "iopub.status.busy": "2026-01-06T05:30:57.332419Z",
     "iopub.status.idle": "2026-01-06T05:30:57.343247Z",
     "shell.execute_reply": "2026-01-06T05:30:57.342531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Experiments:\n",
      "    exp      cv          approach  submitted\n",
      "exp_000 0.80674  XGBoost baseline       True\n",
      "exp_001 0.80927 Advanced features      False\n",
      "exp_002 0.81353  3-model ensemble      False\n",
      "exp_003 0.81951   CatBoost Optuna       True\n",
      "exp_004 0.81928  Threshold tuning       True\n",
      "exp_005 0.81744          Stacking      False\n",
      "exp_006 0.81709 Weighted ensemble       True\n",
      "exp_007 0.81617 Feature selection      False\n",
      "exp_008 0.81698        Multi-seed      False\n",
      "exp_009 0.81560   Target encoding      False\n",
      "\n",
      "Best CV: 0.81951 (CatBoost Optuna)\n",
      "Median CV: 0.81658\n",
      "CV range: 0.80674 - 0.81951\n"
     ]
    }
   ],
   "source": [
    "# Experiment history (all 10 experiments)\n",
    "experiments = [\n",
    "    {'exp': 'exp_000', 'cv': 0.80674, 'approach': 'XGBoost baseline', 'submitted': True},\n",
    "    {'exp': 'exp_001', 'cv': 0.80927, 'approach': 'Advanced features', 'submitted': False},\n",
    "    {'exp': 'exp_002', 'cv': 0.81353, 'approach': '3-model ensemble', 'submitted': False},\n",
    "    {'exp': 'exp_003', 'cv': 0.81951, 'approach': 'CatBoost Optuna', 'submitted': True},\n",
    "    {'exp': 'exp_004', 'cv': 0.81928, 'approach': 'Threshold tuning', 'submitted': True},\n",
    "    {'exp': 'exp_005', 'cv': 0.81744, 'approach': 'Stacking', 'submitted': False},\n",
    "    {'exp': 'exp_006', 'cv': 0.81709, 'approach': 'Weighted ensemble', 'submitted': True},\n",
    "    {'exp': 'exp_007', 'cv': 0.81617, 'approach': 'Feature selection', 'submitted': False},\n",
    "    {'exp': 'exp_008', 'cv': 0.81698, 'approach': 'Multi-seed', 'submitted': False},\n",
    "    {'exp': 'exp_009', 'cv': 0.81560, 'approach': 'Target encoding', 'submitted': False},\n",
    "]\n",
    "\n",
    "exp_df = pd.DataFrame(experiments)\n",
    "print(\"\\nAll Experiments:\")\n",
    "print(exp_df.to_string(index=False))\n",
    "\n",
    "# Best CV\n",
    "print(f\"\\nBest CV: {exp_df['cv'].max():.5f} ({exp_df.loc[exp_df['cv'].idxmax(), 'approach']})\")\n",
    "print(f\"Median CV: {exp_df['cv'].median():.5f}\")\n",
    "print(f\"CV range: {exp_df['cv'].min():.5f} - {exp_df['cv'].max():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682dad2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:30:57.345237Z",
     "iopub.status.busy": "2026-01-06T05:30:57.345005Z",
     "iopub.status.idle": "2026-01-06T05:30:57.352295Z",
     "shell.execute_reply": "2026-01-06T05:30:57.351723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approaches Tried:\n",
      "\n",
      "Encoding:\n",
      "  - Label encoding (baseline)\n",
      "  - Target encoding (exp_009)\n",
      "\n",
      "Models:\n",
      "  - XGBoost\n",
      "  - LightGBM\n",
      "  - CatBoost\n",
      "  - 3-model ensemble\n",
      "\n",
      "Ensembling:\n",
      "  - Simple averaging\n",
      "  - Weighted averaging\n",
      "  - Stacking (LR meta)\n",
      "\n",
      "Hyperparameters:\n",
      "  - Optuna tuning (50 trials)\n",
      "  - Multi-seed (5 seeds)\n",
      "\n",
      "Features:\n",
      "  - 56 features\n",
      "  - Feature selection (32 features)\n",
      "  - Cabin regions\n",
      "  - Family size\n",
      "\n",
      "Validation:\n",
      "  - 5-fold StratifiedKFold\n",
      "\n",
      "Threshold:\n",
      "  - 0.5 (default)\n",
      "  - 0.47 (tuned)\n"
     ]
    }
   ],
   "source": [
    "# Analyze what approaches have been tried\n",
    "approaches_tried = {\n",
    "    'Encoding': ['Label encoding (baseline)', 'Target encoding (exp_009)'],\n",
    "    'Models': ['XGBoost', 'LightGBM', 'CatBoost', '3-model ensemble'],\n",
    "    'Ensembling': ['Simple averaging', 'Weighted averaging', 'Stacking (LR meta)'],\n",
    "    'Hyperparameters': ['Optuna tuning (50 trials)', 'Multi-seed (5 seeds)'],\n",
    "    'Features': ['56 features', 'Feature selection (32 features)', 'Cabin regions', 'Family size'],\n",
    "    'Validation': ['5-fold StratifiedKFold'],\n",
    "    'Threshold': ['0.5 (default)', '0.47 (tuned)'],\n",
    "}\n",
    "\n",
    "print(\"Approaches Tried:\")\n",
    "for category, approaches in approaches_tried.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for a in approaches:\n",
    "        print(f\"  - {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abc53d63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:30:57.354649Z",
     "iopub.status.busy": "2026-01-06T05:30:57.354030Z",
     "iopub.status.idle": "2026-01-06T05:30:57.359430Z",
     "shell.execute_reply": "2026-01-06T05:30:57.358819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Approaches NOT Yet Tried:\n",
      "\n",
      "Validation:\n",
      "  - 10-fold CV (more stable estimates)\n",
      "  - Adversarial validation (check distribution shift)\n",
      "\n",
      "Regularization:\n",
      "  - Reduced depth (6 instead of 8)\n",
      "  - Higher l2_leaf_reg (5-10 instead of 3.52)\n",
      "  - Subsample (0.8)\n",
      "  - Colsample_bylevel (0.8)\n",
      "\n",
      "Imputation:\n",
      "  - KNN imputation (mentioned in top solutions)\n",
      "\n",
      "Data Augmentation:\n",
      "  - Pseudo-labeling (use confident test predictions)\n",
      "\n",
      "Models:\n",
      "  - Neural networks (for diversity)\n"
     ]
    }
   ],
   "source": [
    "# What HASN'T been tried (from evaluator's suggestions)\n",
    "approaches_not_tried = {\n",
    "    'Validation': [\n",
    "        '10-fold CV (more stable estimates)',\n",
    "        'Adversarial validation (check distribution shift)',\n",
    "    ],\n",
    "    'Regularization': [\n",
    "        'Reduced depth (6 instead of 8)',\n",
    "        'Higher l2_leaf_reg (5-10 instead of 3.52)',\n",
    "        'Subsample (0.8)',\n",
    "        'Colsample_bylevel (0.8)',\n",
    "    ],\n",
    "    'Imputation': [\n",
    "        'KNN imputation (mentioned in top solutions)',\n",
    "    ],\n",
    "    'Data Augmentation': [\n",
    "        'Pseudo-labeling (use confident test predictions)',\n",
    "    ],\n",
    "    'Models': [\n",
    "        'Neural networks (for diversity)',\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"\\nApproaches NOT Yet Tried:\")\n",
    "for category, approaches in approaches_not_tried.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for a in approaches:\n",
    "        print(f\"  - {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf3b797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:30:57.361356Z",
     "iopub.status.busy": "2026-01-06T05:30:57.361131Z",
     "iopub.status.idle": "2026-01-06T05:30:57.765273Z",
     "shell.execute_reply": "2026-01-06T05:30:57.764623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-LB Linear Model:\n",
      "  LB = 0.547 * CV + 0.355\n",
      "  R² = 0.920\n",
      "  p-value = 0.0409\n",
      "\n",
      "Predicted LB for different CV scores:\n",
      "  CV 0.815 -> LB 0.8013\n",
      "  CV 0.817 -> LB 0.8024\n",
      "  CV 0.819 -> LB 0.8035\n",
      "  CV 0.820 -> LB 0.8040\n",
      "  CV 0.821 -> LB 0.8046\n",
      "  CV 0.822 -> LB 0.8051\n",
      "\n",
      "To beat LB 0.8045, need CV > 0.82089\n"
     ]
    }
   ],
   "source": [
    "# CV-LB relationship analysis\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "cv_scores = [0.80674, 0.81951, 0.81928, 0.81709]\n",
    "lb_scores = [0.79705, 0.80453, 0.80406, 0.80102]\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_scores, lb_scores)\n",
    "print(f\"CV-LB Linear Model:\")\n",
    "print(f\"  LB = {slope:.3f} * CV + {intercept:.3f}\")\n",
    "print(f\"  R² = {r_value**2:.3f}\")\n",
    "print(f\"  p-value = {p_value:.4f}\")\n",
    "\n",
    "# Predict LB for different CV scores\n",
    "print(f\"\\nPredicted LB for different CV scores:\")\n",
    "for cv in [0.815, 0.817, 0.819, 0.820, 0.821, 0.822]:\n",
    "    predicted_lb = slope * cv + intercept\n",
    "    print(f\"  CV {cv:.3f} -> LB {predicted_lb:.4f}\")\n",
    "\n",
    "# What CV do we need to beat exp_003's LB?\n",
    "target_lb = 0.80453\n",
    "required_cv = (target_lb - intercept) / slope\n",
    "print(f\"\\nTo beat LB 0.8045, need CV > {required_cv:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382dee30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:30:57.767900Z",
     "iopub.status.busy": "2026-01-06T05:30:57.767097Z",
     "iopub.status.idle": "2026-01-06T05:30:57.773245Z",
     "shell.execute_reply": "2026-01-06T05:30:57.772604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_009 (Target Encoding) Fold Scores:\n",
      "  Scores: [0.82404, 0.81196, 0.81484, 0.82336, 0.8038]\n",
      "  Mean: 0.81560\n",
      "  Std: 0.00754\n",
      "  Range: 0.80380 - 0.82404\n",
      "  Spread: 0.02024 (2.48%)\n",
      "\n",
      "Typical fold variance from previous experiments:\n",
      "  exp_003: std = 0.00685\n",
      "  exp_004: std = 0.00762\n",
      "  exp_008: std = 0.00498 (seed 42)\n",
      "  exp_009: std = 0.00754\n",
      "\n",
      "exp_009 has HIGH fold variance - suggests instability\n"
     ]
    }
   ],
   "source": [
    "# Fold variance analysis from exp_009 (target encoding)\n",
    "fold_scores_exp009 = [0.82404, 0.81196, 0.81484, 0.82336, 0.80380]\n",
    "print(\"exp_009 (Target Encoding) Fold Scores:\")\n",
    "print(f\"  Scores: {fold_scores_exp009}\")\n",
    "print(f\"  Mean: {np.mean(fold_scores_exp009):.5f}\")\n",
    "print(f\"  Std: {np.std(fold_scores_exp009):.5f}\")\n",
    "print(f\"  Range: {min(fold_scores_exp009):.5f} - {max(fold_scores_exp009):.5f}\")\n",
    "print(f\"  Spread: {max(fold_scores_exp009) - min(fold_scores_exp009):.5f} ({(max(fold_scores_exp009) - min(fold_scores_exp009))/np.mean(fold_scores_exp009)*100:.2f}%)\")\n",
    "\n",
    "# Compare with typical fold variance\n",
    "print(\"\\nTypical fold variance from previous experiments:\")\n",
    "print(\"  exp_003: std = 0.00685\")\n",
    "print(\"  exp_004: std = 0.00762\")\n",
    "print(\"  exp_008: std = 0.00498 (seed 42)\")\n",
    "print(f\"  exp_009: std = {np.std(fold_scores_exp009):.5f}\")\n",
    "print(\"\\nexp_009 has HIGH fold variance - suggests instability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3312ec73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:30:57.775687Z",
     "iopub.status.busy": "2026-01-06T05:30:57.775363Z",
     "iopub.status.idle": "2026-01-06T05:30:57.784675Z",
     "shell.execute_reply": "2026-01-06T05:30:57.784015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CRITICAL INSIGHT ===\n",
      "\n",
      "exp_003's CV of 0.81951 appears to be an outlier:\n",
      "  - Multi-seed analysis (5 seeds) gave max CV = 0.81629\n",
      "  - Multi-seed ensemble CV = 0.81698\n",
      "  - exp_003 was Optuna-tuned (50 trials) - may have overfit to CV folds\n",
      "\n",
      "True baseline is ~0.817 CV, not 0.82\n",
      "\n",
      "To beat exp_003's LB of 0.8045:\n",
      "  - Need CV > 0.82089 (based on linear model)\n",
      "  - Gap from true baseline: 0.00389 (+0.48%)\n",
      "\n",
      "This is a SIGNIFICANT gap that requires a fundamentally different approach.\n"
     ]
    }
   ],
   "source": [
    "# Key insight: exp_003's CV of 0.81951 is an outlier\n",
    "# Multi-seed analysis showed true baseline is ~0.817\n",
    "\n",
    "print(\"=== CRITICAL INSIGHT ===\")\n",
    "print(\"\\nexp_003's CV of 0.81951 appears to be an outlier:\")\n",
    "print(\"  - Multi-seed analysis (5 seeds) gave max CV = 0.81629\")\n",
    "print(\"  - Multi-seed ensemble CV = 0.81698\")\n",
    "print(\"  - exp_003 was Optuna-tuned (50 trials) - may have overfit to CV folds\")\n",
    "print(\"\\nTrue baseline is ~0.817 CV, not 0.82\")\n",
    "print(\"\\nTo beat exp_003's LB of 0.8045:\")\n",
    "print(f\"  - Need CV > {required_cv:.5f} (based on linear model)\")\n",
    "print(f\"  - Gap from true baseline: {required_cv - 0.817:.5f} (+{(required_cv - 0.817)/0.817*100:.2f}%)\")\n",
    "print(\"\\nThis is a SIGNIFICANT gap that requires a fundamentally different approach.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df20b1d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:30:57.786850Z",
     "iopub.status.busy": "2026-01-06T05:30:57.786611Z",
     "iopub.status.idle": "2026-01-06T05:30:57.793314Z",
     "shell.execute_reply": "2026-01-06T05:30:57.792717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVALUATOR'S RECOMMENDATION ===\n",
      "\n",
      "1. Use 10-fold CV (instead of 5-fold):\n",
      "   - More stable estimates\n",
      "   - Less variance between folds\n",
      "   - Top kernels use this\n",
      "\n",
      "2. Increase regularization:\n",
      "   - Reduce depth from 8 to 6\n",
      "   - Increase l2_leaf_reg from 3.52 to 5-10\n",
      "   - Add subsample (0.8) and colsample_bylevel (0.8)\n",
      "\n",
      "3. Use the best feature set (56 features with label encoding)\n",
      "\n",
      "Rationale:\n",
      "  - High fold variance (2.02% spread) suggests overfitting\n",
      "  - CV-LB gap is increasing (1.19% -> 1.97%)\n",
      "  - Focus on reducing overfitting, not maximizing CV\n"
     ]
    }
   ],
   "source": [
    "# Evaluator's recommendation: 10-fold CV + regularization\n",
    "print(\"=== EVALUATOR'S RECOMMENDATION ===\")\n",
    "print(\"\\n1. Use 10-fold CV (instead of 5-fold):\")\n",
    "print(\"   - More stable estimates\")\n",
    "print(\"   - Less variance between folds\")\n",
    "print(\"   - Top kernels use this\")\n",
    "print(\"\\n2. Increase regularization:\")\n",
    "print(\"   - Reduce depth from 8 to 6\")\n",
    "print(\"   - Increase l2_leaf_reg from 3.52 to 5-10\")\n",
    "print(\"   - Add subsample (0.8) and colsample_bylevel (0.8)\")\n",
    "print(\"\\n3. Use the best feature set (56 features with label encoding)\")\n",
    "print(\"\\nRationale:\")\n",
    "print(\"  - High fold variance (2.02% spread) suggests overfitting\")\n",
    "print(\"  - CV-LB gap is increasing (1.19% -> 1.97%)\")\n",
    "print(\"  - Focus on reducing overfitting, not maximizing CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "098595b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:30:57.795270Z",
     "iopub.status.busy": "2026-01-06T05:30:57.795043Z",
     "iopub.status.idle": "2026-01-06T05:30:57.803459Z",
     "shell.execute_reply": "2026-01-06T05:30:57.802824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ALTERNATIVE APPROACHES ===\n",
      "\n",
      "1. KNN Imputation (from top solutions):\n",
      "   - Our current imputation is simple (mode/median)\n",
      "   - KNN imputation may capture more complex patterns\n",
      "   - Could improve data quality\n",
      "\n",
      "2. Pseudo-labeling:\n",
      "   - Use confident test predictions to augment training data\n",
      "   - Can help with distribution shift\n",
      "   - Risk: may amplify errors if predictions are wrong\n",
      "\n",
      "3. Neural Networks:\n",
      "   - For diversity in ensembling\n",
      "   - May capture different patterns than tree models\n",
      "   - Risk: may not work well on small tabular data\n",
      "\n",
      "4. Adversarial Validation:\n",
      "   - Check if train/test distributions differ\n",
      "   - Identify features that cause distribution shift\n",
      "   - Could explain increasing CV-LB gap\n"
     ]
    }
   ],
   "source": [
    "# Alternative approaches to consider\n",
    "print(\"=== ALTERNATIVE APPROACHES ===\")\n",
    "print(\"\\n1. KNN Imputation (from top solutions):\")\n",
    "print(\"   - Our current imputation is simple (mode/median)\")\n",
    "print(\"   - KNN imputation may capture more complex patterns\")\n",
    "print(\"   - Could improve data quality\")\n",
    "print(\"\\n2. Pseudo-labeling:\")\n",
    "print(\"   - Use confident test predictions to augment training data\")\n",
    "print(\"   - Can help with distribution shift\")\n",
    "print(\"   - Risk: may amplify errors if predictions are wrong\")\n",
    "print(\"\\n3. Neural Networks:\")\n",
    "print(\"   - For diversity in ensembling\")\n",
    "print(\"   - May capture different patterns than tree models\")\n",
    "print(\"   - Risk: may not work well on small tabular data\")\n",
    "print(\"\\n4. Adversarial Validation:\")\n",
    "print(\"   - Check if train/test distributions differ\")\n",
    "print(\"   - Identify features that cause distribution shift\")\n",
    "print(\"   - Could explain increasing CV-LB gap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a6e329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:30:57.805564Z",
     "iopub.status.busy": "2026-01-06T05:30:57.805334Z",
     "iopub.status.idle": "2026-01-06T05:30:57.811788Z",
     "shell.execute_reply": "2026-01-06T05:30:57.811160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALITY CHECK ===\n",
      "\n",
      "Target score: 0.9642\n",
      "Top LB score: ~0.8066\n",
      "Our best LB: 0.8045\n",
      "\n",
      "The target of 0.9642 is IMPOSSIBLE.\n",
      "Top LB is ~0.8066, which is 96.4% accuracy.\n",
      "Our best (0.8045) is already in the top ~7%.\n",
      "\n",
      "Gap to top: 0.0021 (0.26%)\n",
      "\n",
      "This is a very small gap. We're already competitive.\n",
      "\n",
      "Focus should be on:\n",
      "  1. Reducing overfitting (CV-LB gap)\n",
      "  2. Incremental improvements toward 0.81 LB\n",
      "  3. NOT chasing an impossible target\n"
     ]
    }
   ],
   "source": [
    "# Reality check on target score\n",
    "print(\"=== REALITY CHECK ===\")\n",
    "print(\"\\nTarget score: 0.9642\")\n",
    "print(\"Top LB score: ~0.8066\")\n",
    "print(\"Our best LB: 0.8045\")\n",
    "print(\"\\nThe target of 0.9642 is IMPOSSIBLE.\")\n",
    "print(\"Top LB is ~0.8066, which is 96.4% accuracy.\")\n",
    "print(\"Our best (0.8045) is already in the top ~7%.\")\n",
    "print(\"\\nGap to top: 0.0021 (0.26%)\")\n",
    "print(\"\\nThis is a very small gap. We're already competitive.\")\n",
    "print(\"\\nFocus should be on:\")\n",
    "print(\"  1. Reducing overfitting (CV-LB gap)\")\n",
    "print(\"  2. Incremental improvements toward 0.81 LB\")\n",
    "print(\"  3. NOT chasing an impossible target\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
