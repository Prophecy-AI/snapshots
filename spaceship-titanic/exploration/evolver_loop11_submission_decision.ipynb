{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337003e5",
   "metadata": {},
   "source": [
    "# Loop 11 Submission Decision Analysis\n",
    "\n",
    "Analyzing whether to submit exp_011 based on CV-LB relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Historical CV-LB data\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.8067, 'lb': 0.7971},\n",
    "    {'exp': 'exp_003', 'cv': 0.8195, 'lb': 0.8045},\n",
    "    {'exp': 'exp_004', 'cv': 0.8193, 'lb': 0.8041},\n",
    "    {'exp': 'exp_006', 'cv': 0.8171, 'lb': 0.8010},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(\"Historical Submissions:\")\n",
    "print(df)\n",
    "print(f\"\\nCV-LB correlation: {df['cv'].corr(df['lb']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression to predict LB from CV\n",
    "from scipy.stats import linregress\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(df['cv'], df['lb'])\n",
    "print(f\"Linear model: LB = {slope:.4f} * CV + {intercept:.4f}\")\n",
    "print(f\"R-squared: {r_value**2:.4f}\")\n",
    "print(f\"Standard error: {std_err:.4f}\")\n",
    "\n",
    "# Predict LB for exp_011\n",
    "exp_011_cv = 0.82032\n",
    "predicted_lb = slope * exp_011_cv + intercept\n",
    "print(f\"\\nexp_011 CV: {exp_011_cv:.5f}\")\n",
    "print(f\"Predicted LB: {predicted_lb:.5f}\")\n",
    "print(f\"Best LB so far: 0.8045\")\n",
    "print(f\"Predicted improvement: {predicted_lb - 0.8045:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca866203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence interval for prediction\n",
    "# Using simple approach: prediction +/- 2*std_err\n",
    "ci_low = predicted_lb - 2 * std_err * (exp_011_cv - df['cv'].mean())\n",
    "ci_high = predicted_lb + 2 * std_err * (exp_011_cv - df['cv'].mean())\n",
    "\n",
    "print(f\"Predicted LB: {predicted_lb:.5f}\")\n",
    "print(f\"95% CI: [{ci_low:.5f}, {ci_high:.5f}]\")\n",
    "print(f\"\\nBest LB: 0.8045\")\n",
    "print(f\"Probability of beating best LB: {'HIGH' if predicted_lb > 0.8045 else 'LOW'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac1944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key decision factors\n",
    "print(\"=\" * 50)\n",
    "print(\"SUBMISSION DECISION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1. CV IMPROVEMENT:\")\n",
    "print(f\"   exp_011 CV: {exp_011_cv:.5f}\")\n",
    "print(f\"   exp_003 CV: 0.81951\")\n",
    "print(f\"   Improvement: +{exp_011_cv - 0.81951:.5f} (+{(exp_011_cv - 0.81951)/0.81951*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n2. PREDICTED LB:\")\n",
    "print(f\"   Predicted: {predicted_lb:.5f}\")\n",
    "print(f\"   Best LB: 0.8045\")\n",
    "print(f\"   Expected change: {predicted_lb - 0.8045:+.5f}\")\n",
    "\n",
    "print(\"\\n3. REGULARIZATION EFFECT:\")\n",
    "print(\"   - exp_011 uses stronger regularization (depth=6, l2_leaf_reg=7.0)\")\n",
    "print(\"   - Regularization IMPROVED CV (not decreased)\")\n",
    "print(\"   - This suggests we were underfitting, not overfitting\")\n",
    "print(\"   - BUT regularization might help generalization (reduce CV-LB gap)\")\n",
    "\n",
    "print(\"\\n4. SUBMISSIONS REMAINING: 6\")\n",
    "print(\"   - Can afford to test this hypothesis\")\n",
    "print(\"   - If LB improves, regularization is helping\")\n",
    "print(\"   - If LB stays same/worsens, high CV may be due to fold variance\")\n",
    "\n",
    "print(\"\\n5. RISK ASSESSMENT:\")\n",
    "print(\"   - Worst case: LB ~0.803 (similar to exp_006)\")\n",
    "print(\"   - Best case: LB ~0.806 (beat our best)\")\n",
    "print(\"   - Expected: LB ~0.804 (similar to best)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9015447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RECOMMENDATION: SUBMIT exp_011\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\"\"\n",
    "Rationale:\n",
    "1. Best CV achieved (0.82032) - exceeds all previous experiments\n",
    "2. Regularization might help with CV-LB gap\n",
    "3. We have 6 submissions remaining - can afford to test\n",
    "4. Even if LB doesn't improve, we learn about regularization effect\n",
    "5. Evaluator strongly recommends submission\n",
    "\n",
    "Expected outcome:\n",
    "- LB ~0.8042 (slightly below best 0.8045)\n",
    "- But regularization might surprise us with better generalization\n",
    "\n",
    "Next steps after submission:\n",
    "1. If LB improves: Continue with regularization approach\n",
    "2. If LB stays same: Try GroupKFold to reduce variance\n",
    "3. If LB worsens: Regularization is hurting, revert to exp_003 params\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: What if we DON'T submit and try GroupKFold first?\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ALTERNATIVE: Try GroupKFold first, then submit\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\"\"\n",
    "Pros:\n",
    "- GroupKFold might give more stable CV estimates\n",
    "- Could reduce fold variance (currently 4.4% range)\n",
    "- Might reveal if exp_011's high CV is due to lucky folds\n",
    "\n",
    "Cons:\n",
    "- Delays LB feedback on regularization effect\n",
    "- 77.3% are solo travelers - GroupKFold may not help much\n",
    "- We already have a promising result to test\n",
    "\n",
    "Verdict: Submit first, then try GroupKFold\n",
    "- LB feedback is more valuable than GroupKFold CV\n",
    "- We can try GroupKFold in parallel after submission\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
