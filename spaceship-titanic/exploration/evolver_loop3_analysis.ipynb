{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e418480",
   "metadata": {},
   "source": [
    "# Loop 3 Analysis: CatBoost vs Ensemble Performance\n",
    "\n",
    "## Key Finding from Evaluator\n",
    "The evaluator correctly identified that CatBoost alone (0.81836) outperforms the simple averaging ensemble (0.81353) by 0.48%.\n",
    "\n",
    "## Analysis Goals\n",
    "1. Verify CatBoost superiority\n",
    "2. Explore weighted ensemble options\n",
    "3. Analyze threshold tuning potential\n",
    "4. Plan next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a897e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the experiment results\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Results from exp_002 (3-model ensemble)\n",
    "results = {\n",
    "    'Model': ['XGBoost', 'LightGBM', 'CatBoost', 'Simple Avg Ensemble'],\n",
    "    'CV_Score': [0.80927, 0.80743, 0.81836, 0.81353],\n",
    "    'CV_Std': [0.00656, 0.00612, 0.00431, np.nan]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df['Rank'] = df['CV_Score'].rank(ascending=False)\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nCatBoost vs Ensemble: {0.81836 - 0.81353:.5f} = +0.48% improvement\")\n",
    "print(f\"CatBoost vs XGBoost: {0.81836 - 0.80927:.5f} = +0.91% improvement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b822ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is simple averaging worse than CatBoost?\n",
    "# When one model is significantly better, equal weighting drags it down\n",
    "\n",
    "# Let's simulate different weighting schemes\n",
    "def simulate_weighted_ensemble(weights, scores):\n",
    "    \"\"\"Simulate weighted ensemble score (approximation)\"\"\"\n",
    "    # This is a rough approximation - actual ensemble would need OOF predictions\n",
    "    return sum(w * s for w, s in zip(weights, scores))\n",
    "\n",
    "xgb_score = 0.80927\n",
    "lgb_score = 0.80743\n",
    "cat_score = 0.81836\n",
    "\n",
    "print(\"Simulated Weighted Ensemble Scores (approximation):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Different weighting schemes\n",
    "schemes = [\n",
    "    ('Equal (1/3, 1/3, 1/3)', [1/3, 1/3, 1/3]),\n",
    "    ('CatBoost heavy (0.6, 0.2, 0.2)', [0.2, 0.2, 0.6]),\n",
    "    ('CatBoost heavier (0.7, 0.15, 0.15)', [0.15, 0.15, 0.7]),\n",
    "    ('CatBoost only (0, 0, 1)', [0, 0, 1]),\n",
    "    ('Drop LightGBM (0.3, 0, 0.7)', [0.3, 0, 0.7]),\n",
    "    ('XGB+Cat only (0.3, 0, 0.7)', [0.3, 0, 0.7]),\n",
    "]\n",
    "\n",
    "for name, weights in schemes:\n",
    "    score = simulate_weighted_ensemble(weights, [xgb_score, lgb_score, cat_score])\n",
    "    print(f\"{name}: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f2f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV-LB Gap Analysis\n",
    "print(\"CV-LB Gap Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# From exp_000 submission\n",
    "cv_exp000 = 0.80674\n",
    "lb_exp000 = 0.79705\n",
    "gap = cv_exp000 - lb_exp000\n",
    "\n",
    "print(f\"exp_000: CV={cv_exp000:.5f}, LB={lb_exp000:.5f}, Gap={gap:.5f} ({gap/cv_exp000*100:.1f}% overestimate)\")\n",
    "\n",
    "# Predicted LB scores\n",
    "print(f\"\\nPredicted LB scores (assuming {gap:.5f} gap):\")\n",
    "print(f\"  CatBoost (CV=0.81836): Predicted LB ≈ {0.81836 - gap:.5f}\")\n",
    "print(f\"  Ensemble (CV=0.81353): Predicted LB ≈ {0.81353 - gap:.5f}\")\n",
    "print(f\"  XGBoost (CV=0.80927): Predicted LB ≈ {0.80927 - gap:.5f}\")\n",
    "\n",
    "print(f\"\\nTop LB scores in competition: ~0.8066\")\n",
    "print(f\"Our CatBoost predicted LB: {0.81836 - gap:.5f}\")\n",
    "print(f\"Difference from top: {(0.81836 - gap) - 0.8066:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f748bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Score Reality Check\n",
    "print(\"Target Score Reality Check:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Target score: 0.9642 (96.42% accuracy)\")\n",
    "print(f\"Top LB scores: ~0.8066 (80.66% accuracy)\")\n",
    "print(f\"Our best CV: 0.81836 (81.84% accuracy)\")\n",
    "print(f\"\\nThe target of 0.9642 is UNREALISTIC for this competition.\")\n",
    "print(f\"Top solutions achieve ~80.7% accuracy.\")\n",
    "print(f\"Our CatBoost CV of 0.81836 is EXCELLENT - likely top 5% territory.\")\n",
    "print(f\"\\nFocus should be on:\")\n",
    "print(f\"1. Maximizing CV score (currently 0.81836)\")\n",
    "print(f\"2. Ensuring good CV-LB correlation\")\n",
    "print(f\"3. Submitting best candidate to verify LB performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf86ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Steps Analysis\n",
    "print(\"Strategic Analysis - Next Steps:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. IMMEDIATE WIN: Submit CatBoost-only predictions\")\n",
    "print(\"   - CatBoost CV: 0.81836 (best individual model)\")\n",
    "print(\"   - Predicted LB: ~0.8087\")\n",
    "print(\"   - No additional work needed - just use CatBoost predictions\")\n",
    "\n",
    "print(\"\\n2. POTENTIAL IMPROVEMENTS:\")\n",
    "print(\"   a) Tune CatBoost hyperparameters (current: depth=6, lr=0.05)\")\n",
    "print(\"      - Try Optuna optimization for CatBoost specifically\")\n",
    "print(\"      - Potential gain: 0.2-0.5%\")\n",
    "print(\"   b) Weighted ensemble (0.7 CatBoost + 0.15 XGB + 0.15 LGB)\")\n",
    "print(\"      - May not beat CatBoost alone given performance gap\")\n",
    "print(\"   c) Threshold tuning\")\n",
    "print(\"      - Current: 0.5 default\")\n",
    "print(\"      - Optimize to match training distribution (~50.4%)\")\n",
    "print(\"   d) Additional feature engineering\")\n",
    "print(\"      - Name-based features (surname clustering)\")\n",
    "print(\"      - More interaction terms\")\n",
    "\n",
    "print(\"\\n3. WHAT NOT TO TRY:\")\n",
    "print(\"   - Simple averaging ensemble (already proven worse)\")\n",
    "print(\"   - LightGBM focus (underperforms both XGB and CatBoost)\")\n",
    "print(\"   - Neural networks (unlikely to beat GBMs on this tabular data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of key findings\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY OF KEY FINDINGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "findings = [\n",
    "    \"1. CatBoost (0.81836) is the BEST model, beating ensemble (0.81353) by 0.48%\",\n",
    "    \"2. Simple averaging hurts when one model dominates\",\n",
    "    \"3. CatBoost has lowest variance (std=0.00431) - most stable\",\n",
    "    \"4. CV-LB gap is ~0.97% (CV overestimates LB)\",\n",
    "    \"5. Target of 0.9642 is unrealistic - top LB is ~0.8066\",\n",
    "    \"6. Our CatBoost CV of 0.81836 is competitive with top solutions\",\n",
    "]\n",
    "\n",
    "for f in findings:\n",
    "    print(f)\n",
    "\n",
    "print(\"\\nRECOMMENDED ACTION:\")\n",
    "print(\"Create CatBoost-only submission and submit to verify LB performance\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
