{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326d16f7",
   "metadata": {},
   "source": [
    "# Loop 9 Analysis: Understanding the exp_003 Gap and Next Steps\n",
    "\n",
    "## Key Questions:\n",
    "1. Why can't we reproduce exp_003's CV of 0.81951?\n",
    "2. What's our true baseline CV?\n",
    "3. What fundamentally different approaches should we try?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load session state\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Analyze all experiments\n",
    "print(\"=== EXPERIMENT HISTORY ===\")\n",
    "for exp in state['experiments']:\n",
    "    print(f\"{exp['id']}: {exp['name'][:50]:50s} | CV: {exp['score']:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze submissions and CV-LB relationship\n",
    "print(\"\\n=== SUBMISSION ANALYSIS ===\")\n",
    "submissions = state['submissions']\n",
    "for sub in submissions:\n",
    "    gap = sub['cv_score'] - sub['lb_score']\n",
    "    gap_pct = gap / sub['cv_score'] * 100\n",
    "    print(f\"{sub['experiment_id']}: CV={sub['cv_score']:.5f}, LB={sub['lb_score']:.5f}, Gap={gap:.5f} ({gap_pct:.2f}%)\")\n",
    "\n",
    "# Calculate CV-LB model\n",
    "cv_scores = [s['cv_score'] for s in submissions]\n",
    "lb_scores = [s['lb_score'] for s in submissions]\n",
    "\n",
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_scores, lb_scores)\n",
    "print(f\"\\nLinear model: LB = {slope:.3f} * CV + {intercept:.3f} (RÂ²={r_value**2:.3f})\")\n",
    "\n",
    "# What CV do we need to beat best LB?\n",
    "best_lb = max(lb_scores)\n",
    "required_cv = (best_lb - intercept) / slope\n",
    "print(f\"\\nTo beat best LB ({best_lb:.5f}): Need CV > {required_cv:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68703f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the exp_003 mystery\n",
    "print(\"\\n=== EXP_003 MYSTERY ===\")\n",
    "print(\"exp_003 CV: 0.81951\")\n",
    "print(\"exp_008 multi-seed results:\")\n",
    "print(\"  - Seed 42: CV = 0.81617\")\n",
    "print(\"  - Seed 123: CV = 0.81548\")\n",
    "print(\"  - Seed 456: CV = 0.81629\")\n",
    "print(\"  - Seed 789: CV = 0.81606\")\n",
    "print(\"  - Seed 1000: CV = 0.81433\")\n",
    "print(\"  - Ensemble: CV = 0.81698\")\n",
    "print(\"  - Mean: 0.81567, Std: 0.00072\")\n",
    "print(\"\\nGap: 0.81951 - 0.81698 = 0.00253 (0.31%)\")\n",
    "print(\"\\nPossible explanations:\")\n",
    "print(\"1. exp_003 used Optuna tuning - may have found a lucky configuration\")\n",
    "print(\"2. exp_003's CV estimate was optimistic (lucky fold splits)\")\n",
    "print(\"3. Something in the pipeline changed between exp_003 and exp_008\")\n",
    "print(\"4. Optuna's early stopping behavior differs from fixed iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: What's our TRUE baseline?\n",
    "print(\"\\n=== TRUE BASELINE ANALYSIS ===\")\n",
    "print(\"\\nIf exp_003 was a lucky run, our true CV is ~0.817\")\n",
    "print(\"Based on CV-LB model: LB = 0.543 * 0.817 + 0.359 = 0.803\")\n",
    "print(\"This matches exp_006's LB of 0.8010 (CV=0.8171)\")\n",
    "print(\"\\nConclusion: Our true baseline is likely ~0.817 CV, ~0.803 LB\")\n",
    "print(\"exp_003's LB of 0.8045 may have been lucky too\")\n",
    "\n",
    "print(\"\\n=== WHAT WE KNOW ===\")\n",
    "print(\"1. CatBoost with depth=8, lr=0.051, iterations=755 gives CV ~0.816-0.817\")\n",
    "print(\"2. Multi-seed ensemble gives CV ~0.817\")\n",
    "print(\"3. exp_003's CV of 0.81951 is NOT reproducible\")\n",
    "print(\"4. To beat exp_003's LB (0.8045), we need CV > 0.82086\")\n",
    "print(\"5. We're stuck at CV ~0.817, need +0.4% improvement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b317e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't we tried?\n",
    "print(\"\\n=== UNEXPLORED APPROACHES ===\")\n",
    "print(\"\\n1. TARGET ENCODING (HIGH PRIORITY)\")\n",
    "print(\"   - Top kernels use target encoding\")\n",
    "print(\"   - We've only used label encoding\")\n",
    "print(\"   - Could capture category-target relationships\")\n",
    "print(\"   - Must use CV-based encoding to avoid leakage\")\n",
    "\n",
    "print(\"\\n2. 10-FOLD CV (MEDIUM PRIORITY)\")\n",
    "print(\"   - Top kernels use 10-fold CV\")\n",
    "print(\"   - More stable estimates\")\n",
    "print(\"   - May slightly improve generalization\")\n",
    "\n",
    "print(\"\\n3. KNN IMPUTATION (MEDIUM PRIORITY)\")\n",
    "print(\"   - Top kernels mention KNN imputation\")\n",
    "print(\"   - We're using mode/median imputation\")\n",
    "print(\"   - May capture more complex relationships\")\n",
    "\n",
    "print(\"\\n4. NEURAL NETWORK (LOW PRIORITY)\")\n",
    "print(\"   - For ensemble diversity\")\n",
    "print(\"   - TabNet or simple MLP\")\n",
    "print(\"   - Different inductive bias than GBDTs\")\n",
    "\n",
    "print(\"\\n5. PSEUDO-LABELING (LOW PRIORITY)\")\n",
    "print(\"   - Use high-confidence predictions on test\")\n",
    "print(\"   - Retrain with pseudo-labels\")\n",
    "print(\"   - Risky but could help\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aec931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what made exp_003 special\n",
    "print(\"\\n=== EXP_003 ANALYSIS ===\")\n",
    "print(\"\\nexp_003 used Optuna tuning with 50 trials\")\n",
    "print(\"Best params found: depth=8, lr=0.051, iterations=755, l2_leaf_reg=3.52\")\n",
    "print(\"\\nKey difference: Optuna uses early stopping during tuning\")\n",
    "print(\"This means the 'iterations=755' was found with early stopping\")\n",
    "print(\"When we re-run with fixed iterations=755, behavior may differ\")\n",
    "\n",
    "print(\"\\nHypothesis: The Optuna run had different early stopping behavior\")\n",
    "print(\"that led to a lucky CV estimate. The true CV is ~0.817.\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATION ===\")\n",
    "print(\"1. Accept that our true baseline is ~0.817 CV\")\n",
    "print(\"2. Try target encoding - fundamentally different approach\")\n",
    "print(\"3. If target encoding doesn't help, try 10-fold CV\")\n",
    "print(\"4. Focus on getting CV > 0.82 to beat exp_003's LB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab310d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what improvement we need\n",
    "print(\"\\n=== IMPROVEMENT NEEDED ===\")\n",
    "current_cv = 0.817\n",
    "target_lb = 0.8045  # exp_003's LB\n",
    "required_cv = (target_lb - intercept) / slope\n",
    "improvement_needed = required_cv - current_cv\n",
    "\n",
    "print(f\"Current CV: {current_cv:.5f}\")\n",
    "print(f\"Target LB: {target_lb:.5f}\")\n",
    "print(f\"Required CV: {required_cv:.5f}\")\n",
    "print(f\"Improvement needed: {improvement_needed:.5f} ({improvement_needed/current_cv*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nThis is a significant improvement (~0.4%)\")\n",
    "print(\"Incremental changes won't get us there\")\n",
    "print(\"Need a fundamentally different approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0169534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RECOMMENDATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. DO NOT SUBMIT exp_008 (CV=0.81698 < exp_003's CV=0.81951)\")\n",
    "print(\"   Based on CV-LB model, predicted LB ~0.802 (worse than 0.8045)\")\n",
    "\n",
    "print(\"\\n2. TRY TARGET ENCODING NEXT\")\n",
    "print(\"   - Fundamentally different from label encoding\")\n",
    "print(\"   - Top kernels use it\")\n",
    "print(\"   - Could unlock new signal\")\n",
    "\n",
    "print(\"\\n3. IF TARGET ENCODING FAILS, TRY:\")\n",
    "print(\"   - 10-fold CV (more stable estimates)\")\n",
    "print(\"   - KNN imputation (better missing value handling)\")\n",
    "print(\"   - Neural network for ensemble diversity\")\n",
    "\n",
    "print(\"\\n4. REALITY CHECK:\")\n",
    "print(\"   - Target 0.9642 is IMPOSSIBLE (top LB ~0.8066)\")\n",
    "print(\"   - Our best LB 0.8045 is already top ~7%\")\n",
    "print(\"   - Gap to top: 0.0021 (0.26%)\")\n",
    "print(\"   - We're competitive, but need breakthrough for improvement\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
