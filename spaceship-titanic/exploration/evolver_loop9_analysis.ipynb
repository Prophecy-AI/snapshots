{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326d16f7",
   "metadata": {},
   "source": [
    "# Loop 9 Analysis: Understanding the exp_003 Gap and Next Steps\n",
    "\n",
    "## Key Questions:\n",
    "1. Why can't we reproduce exp_003's CV of 0.81951?\n",
    "2. What's our true baseline CV?\n",
    "3. What fundamentally different approaches should we try?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bf84fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:22:13.932132Z",
     "iopub.status.busy": "2026-01-06T05:22:13.931269Z",
     "iopub.status.idle": "2026-01-06T05:22:14.398861Z",
     "shell.execute_reply": "2026-01-06T05:22:14.398144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPERIMENT HISTORY ===\n",
      "exp_000: XGBoost Baseline with Feature Engineering          | CV: 0.80674\n",
      "exp_001: Advanced Feature Engineering - Spending Ratios & I | CV: 0.80927\n",
      "exp_002: 3-Model Ensemble (XGBoost + LightGBM + CatBoost)   | CV: 0.81353\n",
      "exp_003: CatBoost-Only with Optuna Tuning                   | CV: 0.81951\n",
      "exp_004: Threshold Tuning + CatBoost Native Categorical     | CV: 0.81928\n",
      "exp_005: Stacking with Logistic Regression Meta-Learner     | CV: 0.81744\n",
      "exp_006: Weighted Ensemble (0.6 CatBoost + 0.2 XGB + 0.2 LG | CV: 0.81709\n",
      "exp_007: Feature Selection + CatBoost                       | CV: 0.81617\n",
      "exp_008: Multi-Seed CatBoost Ensemble (5 seeds)             | CV: 0.81698\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load session state\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Analyze all experiments\n",
    "print(\"=== EXPERIMENT HISTORY ===\")\n",
    "for exp in state['experiments']:\n",
    "    print(f\"{exp['id']}: {exp['name'][:50]:50s} | CV: {exp['score']:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3639b803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:22:14.401520Z",
     "iopub.status.busy": "2026-01-06T05:22:14.401118Z",
     "iopub.status.idle": "2026-01-06T05:22:14.790667Z",
     "shell.execute_reply": "2026-01-06T05:22:14.790028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUBMISSION ANALYSIS ===\n",
      "exp_000: CV=0.80674, LB=0.79705, Gap=0.00969 (1.20%)\n",
      "exp_003: CV=0.81951, LB=0.80453, Gap=0.01498 (1.83%)\n",
      "exp_004: CV=0.81928, LB=0.80406, Gap=0.01522 (1.86%)\n",
      "exp_006: CV=0.81709, LB=0.80102, Gap=0.01607 (1.97%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear model: LB = 0.547 * CV + 0.355 (R²=0.920)\n",
      "\n",
      "To beat best LB (0.80453): Need CV > 0.82089\n"
     ]
    }
   ],
   "source": [
    "# Analyze submissions and CV-LB relationship\n",
    "print(\"\\n=== SUBMISSION ANALYSIS ===\")\n",
    "submissions = state['submissions']\n",
    "for sub in submissions:\n",
    "    gap = sub['cv_score'] - sub['lb_score']\n",
    "    gap_pct = gap / sub['cv_score'] * 100\n",
    "    print(f\"{sub['experiment_id']}: CV={sub['cv_score']:.5f}, LB={sub['lb_score']:.5f}, Gap={gap:.5f} ({gap_pct:.2f}%)\")\n",
    "\n",
    "# Calculate CV-LB model\n",
    "cv_scores = [s['cv_score'] for s in submissions]\n",
    "lb_scores = [s['lb_score'] for s in submissions]\n",
    "\n",
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_scores, lb_scores)\n",
    "print(f\"\\nLinear model: LB = {slope:.3f} * CV + {intercept:.3f} (R²={r_value**2:.3f})\")\n",
    "\n",
    "# What CV do we need to beat best LB?\n",
    "best_lb = max(lb_scores)\n",
    "required_cv = (best_lb - intercept) / slope\n",
    "print(f\"\\nTo beat best LB ({best_lb:.5f}): Need CV > {required_cv:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68703f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:22:14.792615Z",
     "iopub.status.busy": "2026-01-06T05:22:14.792275Z",
     "iopub.status.idle": "2026-01-06T05:22:14.797160Z",
     "shell.execute_reply": "2026-01-06T05:22:14.796614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXP_003 MYSTERY ===\n",
      "exp_003 CV: 0.81951\n",
      "exp_008 multi-seed results:\n",
      "  - Seed 42: CV = 0.81617\n",
      "  - Seed 123: CV = 0.81548\n",
      "  - Seed 456: CV = 0.81629\n",
      "  - Seed 789: CV = 0.81606\n",
      "  - Seed 1000: CV = 0.81433\n",
      "  - Ensemble: CV = 0.81698\n",
      "  - Mean: 0.81567, Std: 0.00072\n",
      "\n",
      "Gap: 0.81951 - 0.81698 = 0.00253 (0.31%)\n",
      "\n",
      "Possible explanations:\n",
      "1. exp_003 used Optuna tuning - may have found a lucky configuration\n",
      "2. exp_003's CV estimate was optimistic (lucky fold splits)\n",
      "3. Something in the pipeline changed between exp_003 and exp_008\n",
      "4. Optuna's early stopping behavior differs from fixed iterations\n"
     ]
    }
   ],
   "source": [
    "# Analyze the exp_003 mystery\n",
    "print(\"\\n=== EXP_003 MYSTERY ===\")\n",
    "print(\"exp_003 CV: 0.81951\")\n",
    "print(\"exp_008 multi-seed results:\")\n",
    "print(\"  - Seed 42: CV = 0.81617\")\n",
    "print(\"  - Seed 123: CV = 0.81548\")\n",
    "print(\"  - Seed 456: CV = 0.81629\")\n",
    "print(\"  - Seed 789: CV = 0.81606\")\n",
    "print(\"  - Seed 1000: CV = 0.81433\")\n",
    "print(\"  - Ensemble: CV = 0.81698\")\n",
    "print(\"  - Mean: 0.81567, Std: 0.00072\")\n",
    "print(\"\\nGap: 0.81951 - 0.81698 = 0.00253 (0.31%)\")\n",
    "print(\"\\nPossible explanations:\")\n",
    "print(\"1. exp_003 used Optuna tuning - may have found a lucky configuration\")\n",
    "print(\"2. exp_003's CV estimate was optimistic (lucky fold splits)\")\n",
    "print(\"3. Something in the pipeline changed between exp_003 and exp_008\")\n",
    "print(\"4. Optuna's early stopping behavior differs from fixed iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2956e11a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:22:14.798943Z",
     "iopub.status.busy": "2026-01-06T05:22:14.798714Z",
     "iopub.status.idle": "2026-01-06T05:22:14.805649Z",
     "shell.execute_reply": "2026-01-06T05:22:14.805106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRUE BASELINE ANALYSIS ===\n",
      "\n",
      "If exp_003 was a lucky run, our true CV is ~0.817\n",
      "Based on CV-LB model: LB = 0.543 * 0.817 + 0.359 = 0.803\n",
      "This matches exp_006's LB of 0.8010 (CV=0.8171)\n",
      "\n",
      "Conclusion: Our true baseline is likely ~0.817 CV, ~0.803 LB\n",
      "exp_003's LB of 0.8045 may have been lucky too\n",
      "\n",
      "=== WHAT WE KNOW ===\n",
      "1. CatBoost with depth=8, lr=0.051, iterations=755 gives CV ~0.816-0.817\n",
      "2. Multi-seed ensemble gives CV ~0.817\n",
      "3. exp_003's CV of 0.81951 is NOT reproducible\n",
      "4. To beat exp_003's LB (0.8045), we need CV > 0.82086\n",
      "5. We're stuck at CV ~0.817, need +0.4% improvement\n"
     ]
    }
   ],
   "source": [
    "# Key insight: What's our TRUE baseline?\n",
    "print(\"\\n=== TRUE BASELINE ANALYSIS ===\")\n",
    "print(\"\\nIf exp_003 was a lucky run, our true CV is ~0.817\")\n",
    "print(\"Based on CV-LB model: LB = 0.543 * 0.817 + 0.359 = 0.803\")\n",
    "print(\"This matches exp_006's LB of 0.8010 (CV=0.8171)\")\n",
    "print(\"\\nConclusion: Our true baseline is likely ~0.817 CV, ~0.803 LB\")\n",
    "print(\"exp_003's LB of 0.8045 may have been lucky too\")\n",
    "\n",
    "print(\"\\n=== WHAT WE KNOW ===\")\n",
    "print(\"1. CatBoost with depth=8, lr=0.051, iterations=755 gives CV ~0.816-0.817\")\n",
    "print(\"2. Multi-seed ensemble gives CV ~0.817\")\n",
    "print(\"3. exp_003's CV of 0.81951 is NOT reproducible\")\n",
    "print(\"4. To beat exp_003's LB (0.8045), we need CV > 0.82086\")\n",
    "print(\"5. We're stuck at CV ~0.817, need +0.4% improvement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b317e999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:22:14.807350Z",
     "iopub.status.busy": "2026-01-06T05:22:14.807120Z",
     "iopub.status.idle": "2026-01-06T05:22:14.813539Z",
     "shell.execute_reply": "2026-01-06T05:22:14.813008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== UNEXPLORED APPROACHES ===\n",
      "\n",
      "1. TARGET ENCODING (HIGH PRIORITY)\n",
      "   - Top kernels use target encoding\n",
      "   - We've only used label encoding\n",
      "   - Could capture category-target relationships\n",
      "   - Must use CV-based encoding to avoid leakage\n",
      "\n",
      "2. 10-FOLD CV (MEDIUM PRIORITY)\n",
      "   - Top kernels use 10-fold CV\n",
      "   - More stable estimates\n",
      "   - May slightly improve generalization\n",
      "\n",
      "3. KNN IMPUTATION (MEDIUM PRIORITY)\n",
      "   - Top kernels mention KNN imputation\n",
      "   - We're using mode/median imputation\n",
      "   - May capture more complex relationships\n",
      "\n",
      "4. NEURAL NETWORK (LOW PRIORITY)\n",
      "   - For ensemble diversity\n",
      "   - TabNet or simple MLP\n",
      "   - Different inductive bias than GBDTs\n",
      "\n",
      "5. PSEUDO-LABELING (LOW PRIORITY)\n",
      "   - Use high-confidence predictions on test\n",
      "   - Retrain with pseudo-labels\n",
      "   - Risky but could help\n"
     ]
    }
   ],
   "source": [
    "# What approaches haven't we tried?\n",
    "print(\"\\n=== UNEXPLORED APPROACHES ===\")\n",
    "print(\"\\n1. TARGET ENCODING (HIGH PRIORITY)\")\n",
    "print(\"   - Top kernels use target encoding\")\n",
    "print(\"   - We've only used label encoding\")\n",
    "print(\"   - Could capture category-target relationships\")\n",
    "print(\"   - Must use CV-based encoding to avoid leakage\")\n",
    "\n",
    "print(\"\\n2. 10-FOLD CV (MEDIUM PRIORITY)\")\n",
    "print(\"   - Top kernels use 10-fold CV\")\n",
    "print(\"   - More stable estimates\")\n",
    "print(\"   - May slightly improve generalization\")\n",
    "\n",
    "print(\"\\n3. KNN IMPUTATION (MEDIUM PRIORITY)\")\n",
    "print(\"   - Top kernels mention KNN imputation\")\n",
    "print(\"   - We're using mode/median imputation\")\n",
    "print(\"   - May capture more complex relationships\")\n",
    "\n",
    "print(\"\\n4. NEURAL NETWORK (LOW PRIORITY)\")\n",
    "print(\"   - For ensemble diversity\")\n",
    "print(\"   - TabNet or simple MLP\")\n",
    "print(\"   - Different inductive bias than GBDTs\")\n",
    "\n",
    "print(\"\\n5. PSEUDO-LABELING (LOW PRIORITY)\")\n",
    "print(\"   - Use high-confidence predictions on test\")\n",
    "print(\"   - Retrain with pseudo-labels\")\n",
    "print(\"   - Risky but could help\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8aec931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:22:14.815095Z",
     "iopub.status.busy": "2026-01-06T05:22:14.814875Z",
     "iopub.status.idle": "2026-01-06T05:22:14.821218Z",
     "shell.execute_reply": "2026-01-06T05:22:14.820679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXP_003 ANALYSIS ===\n",
      "\n",
      "exp_003 used Optuna tuning with 50 trials\n",
      "Best params found: depth=8, lr=0.051, iterations=755, l2_leaf_reg=3.52\n",
      "\n",
      "Key difference: Optuna uses early stopping during tuning\n",
      "This means the 'iterations=755' was found with early stopping\n",
      "When we re-run with fixed iterations=755, behavior may differ\n",
      "\n",
      "Hypothesis: The Optuna run had different early stopping behavior\n",
      "that led to a lucky CV estimate. The true CV is ~0.817.\n",
      "\n",
      "=== RECOMMENDATION ===\n",
      "1. Accept that our true baseline is ~0.817 CV\n",
      "2. Try target encoding - fundamentally different approach\n",
      "3. If target encoding doesn't help, try 10-fold CV\n",
      "4. Focus on getting CV > 0.82 to beat exp_003's LB\n"
     ]
    }
   ],
   "source": [
    "# Analyze what made exp_003 special\n",
    "print(\"\\n=== EXP_003 ANALYSIS ===\")\n",
    "print(\"\\nexp_003 used Optuna tuning with 50 trials\")\n",
    "print(\"Best params found: depth=8, lr=0.051, iterations=755, l2_leaf_reg=3.52\")\n",
    "print(\"\\nKey difference: Optuna uses early stopping during tuning\")\n",
    "print(\"This means the 'iterations=755' was found with early stopping\")\n",
    "print(\"When we re-run with fixed iterations=755, behavior may differ\")\n",
    "\n",
    "print(\"\\nHypothesis: The Optuna run had different early stopping behavior\")\n",
    "print(\"that led to a lucky CV estimate. The true CV is ~0.817.\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATION ===\")\n",
    "print(\"1. Accept that our true baseline is ~0.817 CV\")\n",
    "print(\"2. Try target encoding - fundamentally different approach\")\n",
    "print(\"3. If target encoding doesn't help, try 10-fold CV\")\n",
    "print(\"4. Focus on getting CV > 0.82 to beat exp_003's LB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab310d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:22:14.822919Z",
     "iopub.status.busy": "2026-01-06T05:22:14.822694Z",
     "iopub.status.idle": "2026-01-06T05:22:14.829315Z",
     "shell.execute_reply": "2026-01-06T05:22:14.828780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== IMPROVEMENT NEEDED ===\n",
      "Current CV: 0.81700\n",
      "Target LB: 0.80450\n",
      "Required CV: 0.82084\n",
      "Improvement needed: 0.00384 (0.47%)\n",
      "\n",
      "This is a significant improvement (~0.4%)\n",
      "Incremental changes won't get us there\n",
      "Need a fundamentally different approach\n"
     ]
    }
   ],
   "source": [
    "# Calculate what improvement we need\n",
    "print(\"\\n=== IMPROVEMENT NEEDED ===\")\n",
    "current_cv = 0.817\n",
    "target_lb = 0.8045  # exp_003's LB\n",
    "required_cv = (target_lb - intercept) / slope\n",
    "improvement_needed = required_cv - current_cv\n",
    "\n",
    "print(f\"Current CV: {current_cv:.5f}\")\n",
    "print(f\"Target LB: {target_lb:.5f}\")\n",
    "print(f\"Required CV: {required_cv:.5f}\")\n",
    "print(f\"Improvement needed: {improvement_needed:.5f} ({improvement_needed/current_cv*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nThis is a significant improvement (~0.4%)\")\n",
    "print(\"Incremental changes won't get us there\")\n",
    "print(\"Need a fundamentally different approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0169534e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T05:22:14.830825Z",
     "iopub.status.busy": "2026-01-06T05:22:14.830609Z",
     "iopub.status.idle": "2026-01-06T05:22:14.836311Z",
     "shell.execute_reply": "2026-01-06T05:22:14.835808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL RECOMMENDATION\n",
      "============================================================\n",
      "\n",
      "1. DO NOT SUBMIT exp_008 (CV=0.81698 < exp_003's CV=0.81951)\n",
      "   Based on CV-LB model, predicted LB ~0.802 (worse than 0.8045)\n",
      "\n",
      "2. TRY TARGET ENCODING NEXT\n",
      "   - Fundamentally different from label encoding\n",
      "   - Top kernels use it\n",
      "   - Could unlock new signal\n",
      "\n",
      "3. IF TARGET ENCODING FAILS, TRY:\n",
      "   - 10-fold CV (more stable estimates)\n",
      "   - KNN imputation (better missing value handling)\n",
      "   - Neural network for ensemble diversity\n",
      "\n",
      "4. REALITY CHECK:\n",
      "   - Target 0.9642 is IMPOSSIBLE (top LB ~0.8066)\n",
      "   - Our best LB 0.8045 is already top ~7%\n",
      "   - Gap to top: 0.0021 (0.26%)\n",
      "   - We're competitive, but need breakthrough for improvement\n"
     ]
    }
   ],
   "source": [
    "# Final recommendation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RECOMMENDATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. DO NOT SUBMIT exp_008 (CV=0.81698 < exp_003's CV=0.81951)\")\n",
    "print(\"   Based on CV-LB model, predicted LB ~0.802 (worse than 0.8045)\")\n",
    "\n",
    "print(\"\\n2. TRY TARGET ENCODING NEXT\")\n",
    "print(\"   - Fundamentally different from label encoding\")\n",
    "print(\"   - Top kernels use it\")\n",
    "print(\"   - Could unlock new signal\")\n",
    "\n",
    "print(\"\\n3. IF TARGET ENCODING FAILS, TRY:\")\n",
    "print(\"   - 10-fold CV (more stable estimates)\")\n",
    "print(\"   - KNN imputation (better missing value handling)\")\n",
    "print(\"   - Neural network for ensemble diversity\")\n",
    "\n",
    "print(\"\\n4. REALITY CHECK:\")\n",
    "print(\"   - Target 0.9642 is IMPOSSIBLE (top LB ~0.8066)\")\n",
    "print(\"   - Our best LB 0.8045 is already top ~7%\")\n",
    "print(\"   - Gap to top: 0.0021 (0.26%)\")\n",
    "print(\"   - We're competitive, but need breakthrough for improvement\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
