{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d2bc4ae",
   "metadata": {},
   "source": [
    "# Loop 6 Analysis: Evaluating Stacking vs Alternatives\n",
    "\n",
    "## Key Questions:\n",
    "1. Should we submit exp_005 (stacking)?\n",
    "2. What's the predicted LB for exp_005 based on CV-LB gap pattern?\n",
    "3. Which alternative approach is most promising?\n",
    "\n",
    "## Evaluator's Concerns:\n",
    "- Stacking CV (0.81744) < CatBoost alone (0.81617-0.81951)\n",
    "- Predicted rate 52.8% is concerning (higher than best LB submission 51.7%)\n",
    "- CV-LB gap pattern suggests exp_005 will underperform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c857ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# CV-LB gap analysis\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.80674, 'lb': 0.79705, 'pred_rate': None},\n",
    "    {'exp': 'exp_003', 'cv': 0.81951, 'lb': 0.80453, 'pred_rate': 0.517},\n",
    "    {'exp': 'exp_004', 'cv': 0.81928, 'lb': 0.80406, 'pred_rate': 0.538},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "df['gap'] = df['cv'] - df['lb']\n",
    "df['gap_pct'] = (df['gap'] / df['cv']) * 100\n",
    "print(\"CV-LB Gap Analysis:\")\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nMean gap: {df['gap'].mean():.5f} ({df['gap_pct'].mean():.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49e4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict LB for exp_005\n",
    "exp_005_cv = 0.81744\n",
    "exp_005_pred_rate = 0.528\n",
    "\n",
    "# Using average gap\n",
    "mean_gap = df['gap'].mean()\n",
    "predicted_lb_avg = exp_005_cv - mean_gap\n",
    "\n",
    "# Using most recent gap (exp_004)\n",
    "recent_gap = df[df['exp'] == 'exp_004']['gap'].values[0]\n",
    "predicted_lb_recent = exp_005_cv - recent_gap\n",
    "\n",
    "print(f\"exp_005 CV: {exp_005_cv:.5f}\")\n",
    "print(f\"exp_005 predicted rate: {exp_005_pred_rate:.3f}\")\n",
    "print(f\"\\nPredicted LB using average gap ({mean_gap:.5f}): {predicted_lb_avg:.5f}\")\n",
    "print(f\"Predicted LB using recent gap ({recent_gap:.5f}): {predicted_lb_recent:.5f}\")\n",
    "print(f\"\\nBest LB so far (exp_003): 0.80453\")\n",
    "print(f\"\\nConclusion: exp_005 likely to score ~{predicted_lb_avg:.4f}-{predicted_lb_recent:.4f} on LB\")\n",
    "print(f\"This would be {'WORSE' if predicted_lb_avg < 0.80453 else 'BETTER'} than exp_003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932bd082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction rate vs LB performance\n",
    "print(\"Prediction Rate vs LB Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training transported rate: 50.4%\")\n",
    "print(f\"\\nexp_003: pred_rate=51.7% -> LB=0.80453 (BEST)\")\n",
    "print(f\"exp_004: pred_rate=53.8% -> LB=0.80406 (worse)\")\n",
    "print(f\"exp_005: pred_rate=52.8% -> LB=??? (predicted worse)\")\n",
    "print(f\"\\nPattern: Higher prediction rate = worse LB\")\n",
    "print(f\"exp_003 is closest to training rate and has best LB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would improve LB?\n",
    "print(\"\\nStrategies to Improve LB:\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\n1. WEIGHTED ENSEMBLE (Evaluator Option A)\")\n",
    "print(\"   - Weight CatBoost higher (0.6) since it's best single model\")\n",
    "print(\"   - May reduce prediction rate closer to training\")\n",
    "print(\"   - Quick to implement\")\n",
    "\n",
    "print(\"\\n2. FEATURE SELECTION (Evaluator Option B)\")\n",
    "print(\"   - Remove bottom 20% features by importance\")\n",
    "print(\"   - Reduces overfitting directly\")\n",
    "print(\"   - 22 features have importance < 1.0\")\n",
    "\n",
    "print(\"\\n3. REGULARIZED CATBOOST (Evaluator Option C)\")\n",
    "print(\"   - depth=6 (vs 8), l2_leaf_reg=5.0 (vs 3.52)\")\n",
    "print(\"   - subsample=0.8 for randomness\")\n",
    "print(\"   - Directly addresses overfitting\")\n",
    "\n",
    "print(\"\\n4. CALIBRATION\")\n",
    "print(\"   - Adjust predictions to match training distribution\")\n",
    "print(\"   - Could help if prediction rate is the issue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision matrix\n",
    "print(\"\\nDECISION MATRIX:\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nOption | Effort | Expected Impact | Risk\")\n",
    "print(\"-\"*50)\n",
    "print(\"Weighted Ensemble | Low | Medium | Low\")\n",
    "print(\"Feature Selection | Medium | High | Medium\")\n",
    "print(\"Regularized CatBoost | Low | Medium | Low\")\n",
    "print(\"Calibration | Low | Unknown | Medium\")\n",
    "\n",
    "print(\"\\n\\nRECOMMENDATION:\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. DO NOT submit exp_005 - predicted to underperform\")\n",
    "print(\"2. Try weighted ensemble first (quick win)\")\n",
    "print(\"3. Then try feature selection + regularization\")\n",
    "print(\"4. Submit only if CV improves AND pred_rate <= 51.7%\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
