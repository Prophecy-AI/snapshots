{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ec8094",
   "metadata": {},
   "source": [
    "# Loop 4 Analysis: Post-Optuna Tuning Assessment\n",
    "\n",
    "## Goals:\n",
    "1. Analyze the CV-LB gap and what it means for our predictions\n",
    "2. Explore threshold tuning potential\n",
    "3. Assess feature selection opportunities\n",
    "4. Evaluate stacking/pseudo-labeling potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4940656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "print(f\"Train: {train.shape}, Test: {test.shape}\")\n",
    "print(f\"Target distribution: {train['Transported'].mean():.4f} transported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd96db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze CV-LB gap\n",
    "print(\"=\" * 60)\n",
    "print(\"CV-LB GAP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# From session state\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.80674, 'lb': 0.79705, 'model': 'XGBoost Baseline'}\n",
    "]\n",
    "\n",
    "for sub in submissions:\n",
    "    gap = sub['cv'] - sub['lb']\n",
    "    gap_pct = (gap / sub['cv']) * 100\n",
    "    print(f\"{sub['model']}:\")\n",
    "    print(f\"  CV: {sub['cv']:.5f}, LB: {sub['lb']:.5f}\")\n",
    "    print(f\"  Gap: {gap:+.5f} ({gap_pct:.2f}% overestimate)\")\n",
    "    print()\n",
    "\n",
    "# Predict LB for current best\n",
    "cv_best = 0.81951\n",
    "predicted_lb = cv_best - 0.00969  # Using observed gap\n",
    "print(f\"Current best CV: {cv_best:.5f}\")\n",
    "print(f\"Predicted LB (using 0.97% gap): {predicted_lb:.5f}\")\n",
    "print(f\"\\nTop LB scores are ~0.8066\")\n",
    "print(f\"Our predicted LB would be competitive!\")\n",
    "print(f\"\\nNote: Target of 0.9642 is UNREALISTIC - impossible to achieve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651304c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze threshold tuning potential\n",
    "# Load the OOF predictions from exp_004 if available\n",
    "import os\n",
    "\n",
    "# Check what files we have\n",
    "exp_dirs = ['experiments/001_baseline', 'experiments/002_feature_engineering', \n",
    "            'experiments/003_ensemble', 'experiments/004_catboost_only']\n",
    "\n",
    "for exp_dir in exp_dirs:\n",
    "    full_path = f'/home/code/{exp_dir}'\n",
    "    if os.path.exists(full_path):\n",
    "        files = os.listdir(full_path)\n",
    "        print(f\"{exp_dir}: {files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ea223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we don't have saved OOF predictions, let's analyze threshold tuning theoretically\n",
    "# The target distribution is ~50.4% transported\n",
    "\n",
    "target_rate = train['Transported'].mean()\n",
    "print(f\"Training target rate: {target_rate:.4f}\")\n",
    "print(f\"\\nThreshold tuning analysis:\")\n",
    "print(f\"- Default threshold: 0.5\")\n",
    "print(f\"- If model is well-calibrated, threshold ~0.5 should be optimal\")\n",
    "print(f\"- If model overestimates probabilities, lower threshold helps\")\n",
    "print(f\"- If model underestimates, higher threshold helps\")\n",
    "print(f\"\\nTo properly tune threshold, we need OOF predictions.\")\n",
    "print(f\"The evaluator suggests this could give 0.1-0.3% improvement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7735938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what approaches haven't been tried\n",
    "print(\"=\" * 60)\n",
    "print(\"UNEXPLORED APPROACHES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "approaches = {\n",
    "    'Threshold tuning': 'NOT TRIED - Quick win, needs OOF predictions',\n",
    "    'Feature selection': 'NOT TRIED - 56 features may include noise',\n",
    "    'Stacking': 'NOT TRIED - Use OOF predictions as meta-features',\n",
    "    'Pseudo-labeling': 'NOT TRIED - Use high-confidence test predictions',\n",
    "    'Nested CV': 'NOT TRIED - More robust hyperparameter tuning',\n",
    "    'Different CV scheme': 'NOT TRIED - GroupKFold based on passenger groups',\n",
    "    'Target encoding': 'NOT TRIED - For high-cardinality categoricals',\n",
    "    'Name features': 'NOT TRIED - Surname clustering, family size',\n",
    "    'Neural network': 'LOW PRIORITY - GBMs typically better for small tabular data'\n",
    "}\n",
    "\n",
    "for approach, status in approaches.items():\n",
    "    print(f\"- {approach}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the variance concern from evaluator\n",
    "print(\"=\" * 60)\n",
    "print(\"VARIANCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "models = {\n",
    "    'CatBoost Baseline': {'cv': 0.81836, 'std': 0.00431},\n",
    "    'CatBoost Tuned': {'cv': 0.81951, 'std': 0.00685}\n",
    "}\n",
    "\n",
    "for name, stats in models.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  CV: {stats['cv']:.5f} (+/- {stats['std']:.5f})\")\n",
    "    print(f\"  95% CI: [{stats['cv'] - 1.96*stats['std']:.5f}, {stats['cv'] + 1.96*stats['std']:.5f}]\")\n",
    "    print()\n",
    "\n",
    "print(\"Evaluator concern: Tuned model has 59% higher variance\")\n",
    "print(\"This suggests tuned model may be less stable on unseen data\")\n",
    "print(\"\\nOptions:\")\n",
    "print(\"1. Submit tuned model to verify LB performance\")\n",
    "print(\"2. Average baseline and tuned predictions for stability\")\n",
    "print(\"3. Use baseline model (lower variance, more stable)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926486ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategic assessment\n",
    "print(\"=\" * 60)\n",
    "print(\"STRATEGIC ASSESSMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. TARGET SCORE REALITY:\")\n",
    "print(f\"   - Target: 0.9642 is IMPOSSIBLE\")\n",
    "print(f\"   - Top LB: ~0.8066 (80.7%)\")\n",
    "print(f\"   - Our best CV: 0.81951\")\n",
    "print(f\"   - Predicted LB: ~0.8098\")\n",
    "print(f\"   - We are likely in TOP 5% territory!\")\n",
    "\n",
    "print(\"\\n2. SUBMISSION STRATEGY:\")\n",
    "print(f\"   - Used: 1/10 submissions\")\n",
    "print(f\"   - Remaining: 9 submissions\")\n",
    "print(f\"   - Should submit to calibrate CV-LB gap\")\n",
    "\n",
    "print(\"\\n3. NEXT PRIORITIES:\")\n",
    "print(f\"   a) Submit exp_003 (tuned CatBoost) to get LB feedback\")\n",
    "print(f\"   b) Try threshold tuning on OOF predictions\")\n",
    "print(f\"   c) Try feature selection to reduce noise\")\n",
    "print(f\"   d) Try stacking with meta-learner\")\n",
    "\n",
    "print(\"\\n4. DIMINISHING RETURNS:\")\n",
    "print(f\"   - Optuna tuning gave only +0.14% improvement\")\n",
    "print(f\"   - Further hyperparameter tuning unlikely to help much\")\n",
    "print(f\"   - Focus should shift to feature engineering or ensembling\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
