# Seed Prompt: Spaceship Titanic - Loop 6 Strategy

## Current Status
- Best CV score: **0.81951** from tuned CatBoost (exp_003)
- Best LB score: **0.80453** from tuned CatBoost (exp_003)
- Latest submission: exp_004 (threshold 0.47) → **LB 0.80406** (WORSE than exp_003!)
- CV-LB gap: **+0.0152** (1.86% overestimate) → Gap is INCREASING
- Target: 0.9642 is **IMPOSSIBLE** - top LB is ~0.8066

## Response to Evaluator

**Technical verdict was TRUSTWORTHY with CONCERNS.** I agree with the assessment.

**Evaluator's top priority: Submit current model to validate, then focus on reducing overfitting.**
- **DONE.** We submitted exp_004 and got LB 0.80406 - WORSE than exp_003's 0.80453!
- **CONFIRMED:** Threshold tuning HURTS LB performance. The distribution shift (50.4% → 53.8%) doesn't generalize.

**Key concerns raised and outcomes:**
1. **Threshold 0.47 shifts distribution** → CONFIRMED HARMFUL. LB dropped from 0.8045 to 0.8041.
2. **CV-LB gap increasing** → CONFIRMED. Gap went from 1.20% → 1.83% → 1.86%.
3. **Native categorical didn't help** → CONFIRMED. Label encoding works fine.
4. **CV score instability** → EXPLAINED. CV varies by ~0.14% across seeds - normal variance.

**Strategic synthesis:**
- Threshold tuning is a dead end - it overfits to CV
- We need approaches that REDUCE the CV-LB gap, not maximize CV
- Focus on: stacking, feature selection, regularization, multi-seed averaging

## Data Understanding
Reference notebooks:
- `exploration/eda.ipynb` - Full EDA with feature distributions
- `exploration/evolver_loop5_lb_feedback.ipynb` - LB feedback analysis showing threshold tuning hurts

Key findings:
1. **Threshold tuning HURTS LB** - exp_004 LB=0.80406 vs exp_003 LB=0.80453
2. **CV-LB gap is 1.86% and increasing** - we're overfitting to CV
3. **22 features have importance < 1.0** - candidates for removal
4. **Top kernel uses 10-fold CV + LGBM+CatBoost ensemble with soft voting**

## Recommended Approaches (Priority Order)

### 1. STACKING WITH LOGISTIC REGRESSION META-LEARNER (Highest Priority)
**Rationale:** Top kernels use ensemble of LGBM + CatBoost with soft voting. Stacking with a simple meta-learner can reduce overfitting while combining model diversity.
**Implementation:**
```python
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

# Train base models with 5-fold CV, collect OOF predictions
# Use DIFFERENT hyperparameters for diversity:
# - CatBoost: depth=8, lr=0.051, l2=3.52 (our best)
# - LightGBM: num_leaves=31, lr=0.05, feature_fraction=0.8
# - XGBoost: max_depth=5, lr=0.067

# Stack OOF predictions
stack_features = np.column_stack([oof_xgb, oof_lgb, oof_cat])
stack_test = np.column_stack([test_xgb, test_lgb, test_cat])

# Simple logistic regression meta-learner (low complexity = less overfitting)
meta_model = LogisticRegression(C=1.0, solver='lbfgs')
meta_model.fit(stack_features, y)
final_pred = meta_model.predict_proba(stack_test)[:, 1]
```
**Expected gain:** Better LB generalization through model diversity and simple meta-learner

### 2. FEATURE SELECTION (High Priority)
**Rationale:** 22 features have importance < 1.0. Removing them may reduce overfitting and close CV-LB gap.
**Implementation:**
```python
# From evolver_loop5_analysis.ipynb, bottom features:
# ShoppingMall_spent (0.02), VIP_enc (0.03), IsSenior (0.04), IsChild (0.05)
# RoomService_spent, FoodCourt_spent, Spa_spent, VRDeck_spent, etc.

# Keep only features with importance >= 1.0
# This reduces from 56 to ~34 features
important_features = [f for f in features if importance[f] >= 1.0]
```
**Expected gain:** 0.1-0.2% on LB through reduced overfitting

### 3. STRONGER REGULARIZATION (Medium Priority)
**Rationale:** Higher l2_leaf_reg reduces overfitting. Research suggests max_depth ≤ 6 for small datasets.
**Implementation:**
```python
cat_params = {
    'depth': 6,  # Reduced from 8
    'learning_rate': 0.03,  # Lower learning rate
    'iterations': 1000,  # More iterations with lower LR
    'l2_leaf_reg': 5.0,  # Increased from 3.52
    'subsample': 0.8,  # Add randomness
    'colsample_bylevel': 0.8,  # Add randomness
    'random_seed': 42,
    'verbose': False
}
```
**Expected gain:** Smaller CV-LB gap, potentially better LB

### 4. MULTI-SEED AVERAGING (Medium Priority)
**Rationale:** CV varies by 0.14% across seeds. Averaging predictions from multiple seeds is more robust.
**Implementation:**
```python
seeds = [42, 123, 456, 789, 1000]
test_preds_all = []

for seed in seeds:
    model = CatBoostClassifier(**params, random_seed=seed)
    # Train with 5-fold CV
    test_preds_all.append(test_pred)

# Average predictions
final_pred = np.mean(test_preds_all, axis=0)
```
**Expected gain:** More stable predictions, potentially better LB

### 5. 10-FOLD CV (Lower Priority)
**Rationale:** Top kernel uses 10-fold CV. More folds = more stable CV estimate.
**Implementation:**
```python
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
```
**Expected gain:** More stable CV estimate, better calibration

## What NOT to Try
- **Threshold tuning** - PROVEN to hurt LB (exp_004 LB=0.8041 < exp_003 LB=0.8045)
- **Native categorical handling** - Already proven not to help (exp_004)
- **Simple averaging ensemble** - Already proven worse than CatBoost alone (exp_002)
- **More hyperparameter tuning** - Diminishing returns, causes overfitting
- **Chasing target of 0.9642** - IMPOSSIBLE, top LB is ~0.8066

## Validation Notes
- Use 5-fold StratifiedKFold with random_state=42 for consistency
- CV-LB gap is now ~1.86% (CV overestimates LB)
- To beat top LB of 0.8066, need CV of ~0.82+ using conservative gap
- **ALWAYS use threshold 0.5** - threshold tuning overfits

## Experiment Tracking
| Exp | Model | CV | LB | Gap | Notes |
|-----|-------|-----|-----|-----|-------|
| exp_000 | XGBoost Baseline | 0.80674 | 0.79705 | +0.97% | First submission |
| exp_001 | XGBoost + Features | 0.80927 | - | - | +0.25% from features |
| exp_002 | 3-Model Ensemble | 0.81353 | - | - | Worse than CatBoost alone |
| exp_003 | Tuned CatBoost | 0.81951 | 0.80453 | +1.50% | **BEST LB** |
| exp_004 | Threshold 0.47 | 0.81928 | 0.80406 | +1.52% | Threshold hurts LB! |

## Success Criteria
- **Immediate goal:** Beat LB 0.80453 (current best from exp_003)
- **Stretch goal:** Beat LB 0.8066 (top solutions)
- **Reality check:** We're already in top ~5% territory

## Submission Strategy
- 7 submissions remaining
- Next: Try stacking with logistic regression meta-learner
- If stacking helps: Submit and continue refining
- If stacking doesn't help: Try feature selection + regularization