## Current Status
- Best CV score: **0.82032** from exp_011 (10-fold + regularization) - **BEST CV EVER**
- Best LB score: 0.8045 from exp_003
- CV-LB gap: ~1.4-2.0% (mean 1.71%)
- **CRITICAL REALITY CHECK**: Target 0.9642 is IMPOSSIBLE. Top LB is ~0.8066. Our best 0.8045 is top ~7%.
- **REAL GOAL**: Beat our best LB (0.8045), not the impossible target.

## Response to Evaluator
- **Technical verdict**: TRUSTWORTHY. exp_011 implementation is sound.
- **Evaluator's top priority**: "Submit exp_011 and try GroupKFold next."
- **I FULLY AGREE** with submitting exp_011:
  1. exp_011 CV (0.82032) is the BEST achieved - exceeds exp_003's 0.81951
  2. Regularization IMPROVED CV (contrary to overfitting hypothesis)
  3. We have 6 submissions remaining - can afford to test
  4. Need LB feedback to calibrate CV-LB relationship with regularization

- **On GroupKFold**: Worth trying as next experiment because:
  - High fold variance (4.4% range) suggests sensitivity to data splits
  - Passengers in same group may have correlated outcomes
  - Could give more realistic CV estimates

- **Key concerns raised by evaluator**:
  1. High fold variance (0.01408 std) - VALID, but 10-fold naturally has higher variance
  2. Target (0.9642) is impossible - AGREED, recalibrating to beat 0.8045 LB
  3. GroupKFold may help - WORTH TRYING as next experiment

## Data Understanding
- Reference notebooks:
  - `exploration/eda.ipynb` for initial EDA
  - `exploration/evolver_loop11_analysis.ipynb` for group structure analysis
- Key patterns:
  - CryoSleep is the strongest predictor (81.8% transported when True)
  - Spending patterns strongly predict transport
  - **77.3% of groups are solo travelers** (size 1)
  - **56.4% of multi-person groups have mixed outcomes** (not perfectly correlated)
  - **CV-LB model**: LB = 0.541 * CV + 0.360 (RÂ²=0.916)
  - **To beat 0.8045 LB, need CV > 0.82106**

## Recommended Approaches (Priority Order)

### 1. GROUPKFOLD CV (HIGH PRIORITY - NEXT EXPERIMENT)
**Rationale**: 
- Evaluator's top recommendation
- High fold variance (4.4% range) suggests sensitivity to data splits
- Passengers in same group may have correlated outcomes
- Could give more realistic CV estimates

**Implementation**:
```python
from sklearn.model_selection import GroupKFold

# Use Group as the grouping variable
groups = train['Group'].values
gkf = GroupKFold(n_splits=5)  # 5 folds since groups reduce effective sample size

for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):
    # Use exp_011 regularized params: depth=6, l2_leaf_reg=7.0, subsample=0.8, colsample_bylevel=0.8
    # ... rest of training code
```

**Caveats**:
- 77.3% are solo travelers (group size 1) - may not dramatically change results
- 56.4% of multi-person groups have mixed outcomes - not perfectly correlated
- May reduce effective sample size per fold

### 2. KNN IMPUTATION (HIGH PRIORITY)
**Rationale**:
- Mentioned in top solutions (0.8066 LB) - see `research/kernels/arunklenin_space-titanic-eda-advanced-feature-engineering/`
- Our current imputation is simple (mode/median)
- KNN imputation captures relationships between features
- Different data preprocessing approach (not model changes)

**Implementation**:
```python
from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder

# Encode categoricals first (KNN needs numeric data)
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))

# KNN imputation with k=5
imputer = KNNImputer(n_neighbors=5, weights='distance')
df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)
```

### 3. PSEUDO-LABELING (MEDIUM PRIORITY)
**Rationale**:
- Evaluator mentioned this as an alternative approach
- Use confident test predictions to augment training data
- Could help with distribution shift between train/test

**Implementation**:
```python
# Get predictions on test set
test_probs = model.predict_proba(X_test)[:, 1]

# Select confident predictions (>0.9 or <0.1)
confident_mask = (test_probs > 0.9) | (test_probs < 0.1)
pseudo_labels = (test_probs[confident_mask] > 0.5).astype(int)

# Add to training data
X_augmented = np.vstack([X_train, X_test[confident_mask]])
y_augmented = np.concatenate([y_train, pseudo_labels])
```

### 4. NAME-BASED FEATURES (MEDIUM PRIORITY)
**Rationale**:
- Top kernels extract surname from Name feature
- Families traveling together may have correlated outcomes
- We haven't exploited the Name column at all

**Implementation**:
```python
# Extract surname
train['Surname'] = train['Name'].apply(lambda x: x.split()[-1] if pd.notna(x) else 'Unknown')

# Family size based on surname
surname_counts = train['Surname'].value_counts().to_dict()
train['FamilySize'] = train['Surname'].map(surname_counts)
```

### 5. ENSEMBLE OF REGULARIZED + NON-REGULARIZED MODELS (MEDIUM PRIORITY)
**Rationale**:
- Combine exp_003 params (depth=8, less regularization) with exp_011 params (depth=6, more regularization)
- Different regularization levels may capture different patterns
- Could provide diversity for ensembling

**Implementation**:
```python
# Model 1: exp_003 params (less regularized)
model1_params = {'depth': 8, 'l2_leaf_reg': 3.52, 'learning_rate': 0.051, 'iterations': 755}

# Model 2: exp_011 params (more regularized)
model2_params = {'depth': 6, 'l2_leaf_reg': 7.0, 'subsample': 0.8, 'colsample_bylevel': 0.8}

# Average predictions
final_preds = 0.5 * model1_preds + 0.5 * model2_preds
```

## What NOT to Try (Exhausted Approaches)
- **Target encoding**: HURT CV by -0.14% (exp_010)
- **Threshold tuning**: Proven to hurt LB (exp_004)
- **Native categorical handling**: Didn't outperform label encoding (exp_004)
- **Simple averaging ensemble**: Weighted is better (exp_006)
- **Stacking with LR meta-learner**: CV lower than CatBoost alone (exp_005)
- **Weighted ensemble**: Lower CV = lower LB (exp_006)
- **Feature selection**: HURT CV by -0.00265 (exp_007)
- **Multi-seed ensemble alone**: Only gives +0.07% over best single seed (exp_008)

## Validation Notes
- **Use 10-fold StratifiedKFold** with random_state=42 (current best approach)
- **Try GroupKFold** to respect group structure and reduce variance
- CV-LB gap is ~1.4-2.0% - relatively stable
- **Focus on GENERALIZATION**: Higher CV doesn't always mean higher LB
- **Use 56 features with label encoding** (best feature set)
- **Use regularized CatBoost params**: depth=6, l2_leaf_reg=7.0, subsample=0.8, colsample_bylevel=0.8

## Key Insights from exp_011
1. **Regularization IMPROVED CV** (0.82032 vs 0.81951) - we were underfitting, not overfitting
2. **10-fold CV gives higher mean** but also higher variance
3. **Fold range is 4.4%** (0.79862 - 0.84253) - suggests sensitivity to data splits
4. **CV improvement is NOT statistically significant** (0.00081 is only 0.06x the fold std)
5. **Predicted LB is ~0.8042** - slightly below best 0.8045

## Awaiting LB Feedback from exp_011 Submission
We are submitting exp_011 to test if regularization helps with generalization.

**If LB improves (>0.8045)**:
- Regularization is helping with generalization
- Continue with regularization approach
- Try even stronger regularization (depth=5, l2_leaf_reg=10.0)

**If LB stays same (~0.8042-0.8045)**:
- Regularization is neutral
- Try GroupKFold to reduce variance
- Try KNN imputation (different data preprocessing)

**If LB worsens (<0.8040)**:
- Regularization is hurting generalization
- Revert to exp_003 params (depth=8, l2_leaf_reg=3.52)
- Focus on other approaches (KNN imputation, Name features)

## Reality Check
- **Target: 0.9642 is IMPOSSIBLE** (top LB is ~0.8066)
- Our best LB: 0.8045 (top ~7%)
- Gap to top: 0.0021 (0.26%)
- **We're already competitive.** Focus on incremental improvements.
- **Real goal**: Beat our best LB (0.8045), not the impossible target.
