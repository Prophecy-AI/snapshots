{
  "query": "How can I improve CatBoost accuracy beyond hyperparameter tuning for binary classification?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Improving CatBoost\u2019s accuracy for a binary\u2011classification task can be done by addressing data handling, training strategy, and advanced model features\u2014steps that go beyond ordinary hyper\u2011parameter tweaking.\u202fThe recommendations below are drawn from CatBoost\u2019s own guidance and best\u2011practice articles on handling imbalanced data and common pitfalls\u30101\u2020https://www.geeksforgeeks.org/handling-imbalanced-classes-in-catboost-techniques-and-solutions\u3011\u30108\u2020https://datasciencebase.com/supervised-ml/algorithms/gradient-boosting/CatBoost/common-mistakes\u3011.\n\n**1. Let CatBoost handle categorical columns directly**  \n\u202f\u202f*Pass the column indices (or names) to the `cat_features` argument instead of label\u2011encoding or one\u2011hot\u2011encoding yourself.*  \n\u202f\u202f```python\n\u202f\u202fcat_features = [0, 2, 5]          # example indices\n\u202f\u202fmodel = CatBoostClassifier(cat_features=cat_features, \u2026)\n\u202f\u202fmodel.fit(X_train, y_train)\n\u202f\u202f```  \n\u202f\u202f(Using CatBoost\u2019s built\u2011in categorical processing preserves information and speeds up training)\u30108\u2020https://datasciencebase.com/supervised-ml/algorithms/gradient-boosting/CatBoost/common-mistakes\u3011.\n\n**2. Counter class imbalance**  \n\u202f\u202f- **Class weights**: set `class_weights` manually or enable `auto_class_weights='Balanced'`.  \n\u202f\u202f- **Sampling**: optionally oversample the minority class or use CatBoost\u2019s built\u2011in `scale_pos_weight`.  \n\u202f\u202f```python\n\u202f\u202fmodel = CatBoostClassifier(class_weights=[0.7, 0.3], auto_class_weights='Balanced')\n\u202f\u202f```  \n\u202f\u202f(These techniques prevent the model from biasing toward the majority class)\u30101\u2020https://www.geeksforgeeks.org/handling-imbalanced-classes-in-catboost-techniques-and-solutions\u3011\u30108\u2020https://datasciencebase.com/supervised-ml/algorithms/gradient-boosting/CatBoost/common-mistakes\u3011.\n\n**3. Apply early stopping with a validation set**  \n\u202f\u202fTrain with `eval_set` and `early_stopping_rounds` so training halts when the validation metric stops improving, reducing over\u2011fitting.  \n\u202f\u202f```python\n\u202f\u202fmodel.fit(X_train, y_train,\n\u202f\u202f          eval_set=(X_val, y_val),\n\u202f\u202f          early_stopping_rounds=20,\n\u202f\u202f          verbose=False)\n\u202f\u202f```  \n\u202f\u202f(This is a frequent mistake that hurts accuracy)\u30108\u2020https://datasciencebase.com/supervised-ml/algorithms/gradient-boosting/CatBoost/common-mistakes\u3011.\n\n**4. Exploit advanced CatBoost options**  \n\u202f\u202f- **Golden features**: enable `use_best_model=True` and `feature_border_type='GreedyLogSum'` to let CatBoost create useful interaction features automatically.  \n\u202f\u202f- **Tree\u2011growing policy**: try `grow_policy='Lossguide'` for deeper trees without excessive over\u2011fit.  \n\u202f\u202f- **Internal dataset order**: set `boost_from_average=True` for binary tasks.  \n\u202f\u202f- **Regularisation knobs**: tune `bagging_temperature`, `random_strength`, and `l2_leaf_reg` modestly (they are not \u201cclassic\u201d hyper\u2011parameters but affect model robustness).  \n\u202f\u202fAll of these are listed in the official parameter\u2011tuning guide\u30106\u2020https://catboost.ai/docs/en/concepts/parameter-tuning\u3011.\n\n**5. Use robust cross\u2011validation (e.g., stratified K\u2011fold) and automated search**  \n\u202f\u202fWrap the training in `StratifiedKFold` (or CatBoost\u2019s `cv` function) to obtain stable estimates and to pick the best iteration count.  \n\u202f\u202fFor automated exploration, CatBoost integrates with Optuna (`catboost.cv` + Optuna) to search the space of the advanced options above without manual trial\u2011and\u2011error\u30106\u2020https://catboost.ai/docs/en/concepts/parameter-tuning#methods-for-hyperparameter-search-by-optuna\u3011.\n\n**6. Refine features based on importance**  \n\u202f\u202fAfter an initial fit, extract `model.get_feature_importance()`; drop low\u2011importance or highly correlated features, and optionally engineer new ones (e.g., target\u2011encoding, interaction terms).  \n\u202f\u202fCleaner, more informative features often raise the validation score more than fine\u2011tuning learning\u2011rate alone.\n\n**7. If possible, enlarge or augment the training data**  \n\u202f\u202fMore diverse examples (or synthetic minority\u2011class samples via SMOTE, ADASYN, etc.) give CatBoost richer patterns to learn, which typically improves accuracy beyond what hyper\u2011parameter tweaks can achieve.\n\nFollow these steps in sequence\u2014starting with correct categorical handling and imbalance mitigation, then early stopping, advanced options, robust CV, feature pruning/engineering, and finally data enrichment\u2014to push CatBoost\u2019s binary\u2011classification accuracy beyond what plain hyper\u2011parameter tuning can deliver.",
      "url": ""
    },
    {
      "title": "Handling imbalanced classes in CatBoost: Techniques and Solutions",
      "text": "<div><div>\n <p><span>Last Updated : </span>\n <span>05 Jul, 2024</span>\n </p>\n \n \n </div><div>\n <p><span>Gradient boosting algorithms have become a cornerstone in machine learning, particularly in handling complex datasets with heterogeneous features and noisy data. One of the most prominent gradient boosting libraries is CatBoost, known for its ability to process categorical features effectively. However, like other boosting algorithms, CatBoost faces the challenge of dealing with imbalanced datasets, where one class significantly outnumbers the other. This article delves into the techniques and solutions CatBoost offers to tackle the issue of imbalanced classes.</span></p><div><p>Table of Content</p><ul><li><a href=\"#the-problem-of-imbalanced-classes\">The Problem of Imbalanced Classes</a></li><li><a href=\"#techniques-for-handling-imbalanced-data-in-catboost\">Techniques for Handling Imbalanced Data in CatBoost</a></li><ul><li><a href=\"#1-class-weights\">1. Class Weights</a></li><li><a href=\"#2-auto-class-weights\">2. Auto Class Weights</a></li><li><a href=\"#3-sampling-techniques\">3. Sampling Techniques</a></li></ul><li><a href=\"#handling-imbalanced-dataset-in-catboost-practical-example\">Handling Imbalanced Dataset in CatBoost : Practical Example</a></li><li><a href=\"#choosing-the-right-strategy\">Choosing the Right Strategy </a></li></ul></div><h2><span>The Problem of Imbalanced Classes</span></h2><p><span>Imbalanced datasets are common in many real-world applications, such as fraud detection, medical diagnosis, and customer churn prediction. In these scenarios, one class (e.g., the positive class) is significantly underrepresented compared to the other class (e.g., the negative class). This imbalance can lead to biased models that favor the majority class, resulting in poor performance on the minority class.</span></p><h2><span>Techniques for Handling Imbalanced Data in CatBoost</span></h2><p><a href=\"https://www.geeksforgeeks.org/catboost-ml/\"><span>CatBoost</span></a><span> provides several built-in mechanisms to handle imbalanced datasets. These include:</span></p><ol><li><b><strong>Class Weights</strong></b></li><li><b><strong>Auto Class Weights</strong></b></li><li><b><strong>Sampling Techniques</strong></b></li></ol><p><span>Let's walk through a practical example demonstrating how to handle an imbalanced dataset using CatBoost, and then validate its performance. We'll use a synthetic dataset and evaluate the effectiveness of different techniques.</span></p><p><b><strong>1. Dataset Preparation</strong></b></p><p><span>First, let's generate a synthetic imbalanced dataset for demonstration purposes using </span><code><span>make_classification</span></code><span> from scikit-learn:</span></p><h3><span>1. Class Weights</span></h3><p><span>Class weights are used to assign different importance to different classes. By increasing the weight of the minority class, the model is penalized more for misclassifying minority class instances, thus improving its performance on the minority class.</span></p><p><span>Output:</span></p><pre><span>Classification Report - Class Weights:</span><br/><span> precision recall f1-score support</span><p><span> 0 0.98 1.00 0.99 1868</span><br/><span> 1 0.94 0.73 0.83 132</span></p><p><span> accuracy 0.98 2000</span><br/><span> macro avg 0.96 0.87 0.91 2000</span><br/><span>weighted avg 0.98 0.98 0.98 2000</span></p></pre><h3><span>2. Auto Class Weights</span></h3><p><span>CatBoost also offers an automatic way to balance class weights using the\u00a0</span><code><span>auto_class_weights</span></code><span>\u00a0parameter. This parameter can be set to 'Balanced' to automatically calculate and assign weights based on the class distribution.</span></p><p><span>Output:</span></p><pre><span>Predictions: [0 0 0 ... 0 0 0]</span></pre><h3><span>3. Sampling Techniques</span></h3><p><span>Sampling techniques such as oversampling the minority class or undersampling the majority class can also be used to balance the dataset. These techniques can be combined with CatBoost to improve model performance.</span></p><p><b><strong>Oversampling:</strong></b></p><p><span>Output:</span></p><pre><span>Predictions: [0 0 0 ... 0 0 0]</span></pre><p><b><strong>Undersampling:</strong></b></p><p><span>Output:</span></p><pre><span>Predictions: [0 0 0 ... 0 0 0]</span></pre><h2><span>Handling Imbalanced Dataset in CatBoost : Practical Example</span></h2><p><b><strong>Problem Statement:</strong></b><span> You have a dataset from a telecom company containing customer information such as service usage patterns, customer demographics, and whether the customer churned or not. The goal is to build a model that predicts whether a customer will churn based on these features.</span></p><p><b><strong>Step-by-Step Example: Predicting Customer Purchase</strong></b></p><h4><span>1. Generate Random Dataset</span></h4><p><span>Let's generate a random dataset using Python's </span><code><span>numpy</span></code><span> and </span><code><span>pandas</span></code><span> libraries:</span></p><p><span>Output:</span></p><pre><span> Purchase</span><br/><span>0 802</span><br/><span>1 198</span><br/><span>Name: count, dtype: int64</span></pre><h4><span>2. Data Preprocessing</span></h4><p><span>Now, let's preprocess the dataset:</span></p><h4><span>3. Handling Imbalanced Classes with CatBoost</span></h4><h5><span>Using Class Weights:</span></h5><p><span>You can manually adjust the </span><code><span>class_weights</span></code><span> parameter in CatBoost to handle class imbalance:</span></p><p><span>Output:</span></p><pre><span>0:\ttest: 0.5014094\tbest: 0.5014094 (0)\ttotal: 4.61ms\tremaining: 4.6s</span><br/><span>100:\ttest: 0.4773669\tbest: 0.5684795 (1)\ttotal: 346ms\tremaining: 3.08s</span><br/><span>200:\ttest: 0.4621124\tbest: 0.5684795 (1)\ttotal: 762ms\tremaining: 3.03s</span><br/><span>300:\ttest: 0.4672525\tbest: 0.5684795 (1)\ttotal: 1.21s\tremaining: 2.81s</span><br/><span>400:\ttest: 0.4790250\tbest: 0.5684795 (1)\ttotal: 1.67s\tremaining: 2.49s</span><br/><span>500:\ttest: 0.4821754\tbest: 0.5684795 (1)\ttotal: 2.24s\tremaining: 2.23s</span><br/><span>600:\ttest: 0.4846626\tbest: 0.5684795 (1)\ttotal: 2.83s\tremaining: 1.88s</span><br/><span>700:\ttest: 0.4839993\tbest: 0.5684795 (1)\ttotal: 3.65s\tremaining: 1.56s</span><br/><span>800:\ttest: 0.4936163\tbest: 0.5684795 (1)\ttotal: 4.35s\tremaining: 1.08s</span><br/><span>900:\ttest: 0.4975958\tbest: 0.5684795 (1)\ttotal: 5.01s\tremaining: 551ms</span><br/><span>999:\ttest: 0.4985906\tbest: 0.5684795 (1)\ttotal: 5.42s\tremaining: 0us</span><p><span>bestTest = 0.5684795225</span><br/><span>bestIteration = 1</span></p><p><span>Shrink model to first 2 iterations.</span><br/><span>CatBoost with Class Weights:</span><br/><span> precision recall f1-score support</span></p><p><span> 0 0.82 0.65 0.72 163</span><br/><span> 1 0.19 0.35 0.24 37</span></p><p><span> accuracy 0.59 200</span><br/><span> macro avg 0.50 0.50 0.48 200</span><br/><span>weighted avg 0.70 0.59 0.63 200</span></p><p><span>ROC AUC Score: 0.5684795224672525</span></p></pre><h5><span>Using Auto Class Weights:</span></h5><p><span>CatBoost provides an option to automatically calculate class weights based on the training data using </span><code><span>auto_class_weights='Balanced'</span></code><span>:</span></p><p><span>Output:</span></p><pre><span>0:\ttest: 0.5014094\tbest: 0.5014094 (0)\ttotal: 7.61ms\tremaining: 7.6s</span><br/><span>100:\ttest: 0.4574697\tbest: 0.5691428 (1)\ttotal: 279ms\tremaining: 2.49s</span><br/><span>200:\ttest: 0.4793567\tbest: 0.5691428 (1)\ttotal: 503ms\tremaining: 2s</span><br/><span>300:\ttest: 0.4752114\tbest: 0.5691428 (1)\ttotal: 850ms\tremaining: 1.97s</span><br/><span>400:\ttest: 0.4757088\tbest: 0.5691428 (1)\ttotal: 1.21s\tremaining: 1.8s</span><br/><span>500:\ttest: 0.4820096\tbest: 0.5691428 (1)\ttotal: 1.53s\tremaining: 1.52s</span><br/><span>600:\ttest: 0.4785276\tbest: 0.5691428 (1)\ttotal: 2.02s\tremaining: 1.34s</span><br/><span>700:\ttest: 0.4798541\tbest: 0.5691428 (1)\ttotal: 2.31s\tremaining: ...",
      "url": "https://www.geeksforgeeks.org/handling-imbalanced-classes-in-catboost-techniques-and-solutions"
    },
    {
      "title": "Parameter tuning",
      "text": "Parameter tuning | CatBoost\nParameter tuning\n[](https://github.com/catboost/catboost/tree/master/catboost/docs/en/concepts/parameter-tuning.md)\n# Parameter tuning\n* [One-hot encoding](en/concepts/parameter-tuning#one-hot-enc)\n* [Number of trees](en/concepts/parameter-tuning#trees-number)\n* [Learning rate](en/concepts/parameter-tuning#learning-rate)\n* [Tree depth](en/concepts/parameter-tuning#tree-depth)\n* [L2 regularization](en/concepts/parameter-tuning#l2-reg)\n* [Random strength](en/concepts/parameter-tuning#rand-str)\n* [Bagging temperature](en/concepts/parameter-tuning#bagg-temp)\n* [Border count](en/concepts/parameter-tuning#border-count)\n* [Internal dataset order](en/concepts/parameter-tuning#internal-dataset-order)\n* [Tree growing policy](en/concepts/parameter-tuning#tree-growing-policy)\n* [Golden features](en/concepts/parameter-tuning#golden-features)\n* [Methods for hyperparameter search](en/concepts/parameter-tuning#defining-optimal-parameter-values)\n* [Methods for hyperparameter search by optuna](en/concepts/parameter-tuning#methods-for-hyperparameter-search-by-optuna)\nCatBoost provides a flexible interface for parameter tuning and can be configured to suit different tasks.\nThis section contains some tips on the possible parameter settings.\n## [](en/concepts/parameter-tuning#one-hot-enc)One-hot encoding\nWarning\nDo not use one-hot encoding during preprocessing. This affects both the training speed and the resulting quality.\nSometimes when categorical features don't have a lot of values, one-hot encoding works well.\nUsually one-hot encoding does not significantly improve the quality of the model. But if it is required, use the inbuilt parameters instead of preprocessing the dataset.\nParameters\n**Command-line version parameters:**`--one-hot-max-size`\n**Python parameters:**`one\\_hot\\_max\\_size`\n**R parameters:**`one\\_hot\\_max\\_size`\n#### [](en/concepts/parameter-tuning#description)Description\nUse one-hot encoding for all categorical features with a number of different values less than or equal to the given parameter value. Ctrs are not calculated for such features.\n**Default value**\nThe default value depends on various conditions:\n* N/A if training is performed on CPU in Pairwise scoring mode\nRead more about Pairwise scoring\nThe following loss functions use Pairwise scoring:\n* YetiRankPairwise\n* PairLogitPairwise\n* QueryCrossEntropy\nPairwise scoring is slightly different from regular training on pairs, since pairs are generated only internally during the training for the corresponding metrics. One-hot encoding is not available for these loss functions.\n* 255 if training is performed on GPU and the selected Ctr types require target data that is not available during the training\n* 10 if training is performed in[Ranking](en/concepts/loss-functions-ranking)mode\n* 2 if none of the conditions above is met\n## [](en/concepts/parameter-tuning#trees-number)Number of trees\nIt is recommended to check that there is no obvious underfitting or overfitting before tuning any other parameters. In order to do this it is necessary to analyze the metric value on the validation dataset and select the appropriate number of iterations.\nThis can be done by setting the number of[iterations](en/references/training-parameters/common#iterations)to a large value, using the[overfitting detector](en/concepts/overfitting-detector)parameters and turning the[use best model](en/references/training-parameters/common#use_best_model)options on. In this case the resulting model contains only the first`k`best iterations, where`k`is the iteration with the best loss value on the validation dataset.\nAlso, the metric for choosing the best model may differ from the one used for optimizing the objective value. For example, it is possible to set the optimized function to\u00a0Logloss and use the AUC function for the overfitting detector. To do so, use the[evaluation metric](en/references/training-parameters/common#eval_metric)parameter.\nParameters\n**Command-line version parameters:**`-i`,`--iterations`\n**Python parameters:**`--iterations`\n**R parameters:**`--iterations`\n#### [](en/concepts/parameter-tuning#description1)Description\nThe maximum number of trees that can be built when solving machine learning problems.\nWhen using other parameters that limit the number of iterations, the final number of trees may be less than the number specified in this parameter.\n**Command-line version parameters:**`--use-best-model`\n**Python parameters:**`--use-best-model`\n**R parameters:**`--use-best-model`\n#### [](en/concepts/parameter-tuning#description2)Description\nIf this parameter is set, the number of trees that are saved in the resulting model is defined as follows:\n1. Build the number of trees defined by the training parameters.\n2. Use the validation dataset to identify the iteration with the optimal value of the metric specified in`--eval-metric`(`--eval-metric`).\nNo trees are saved after this iteration.\nThis option requires a validation dataset to be provided.\n**Command-line version parameters:**`--eval-metric`\n**Python parameters:**`--eval-metric`\n**R parameters:**`--eval-metric`\n#### [](en/concepts/parameter-tuning#description3)Description\nThe metric used for overfitting detection (if enabled) and best model selection (if enabled). Some metrics support optional parameters (see the[Objectives and metrics](en/concepts/loss-functions)section for details on each metric).\nFormat:\n```\n`&lt;Metric&gt;[:&lt;parameter 1&gt;=&lt;value&gt;;..;&lt;parameter N&gt;=&lt;value&gt;]`\n```\n[Supported metrics](en/references/eval-metric__supported-metrics)\nExamples:\n```\n`R2`\n```\n```\n`Quantile:alpha=0.3`\n```\n**Command-line version parameters:****Overfitting detection settings**\n**Command-line version parameters:**`--od-type`\n**Python parameters:**`od\\_type`\n**R parameters:**`od\\_type`\n#### [](en/concepts/parameter-tuning#description4)Description\nThe type of the overfitting detector to use.\nPossible values:\n* IncToDec\n* Iter\n**Command-line version parameters:**`--od-pval`\n**Python parameters:**`od\\_pval`\n**R parameters:**`od\\_pval`\n#### [](en/concepts/parameter-tuning#description5)Description\nThe threshold for the\u00a0IncToDec[overfitting detector](en/concepts/overfitting-detector)type. The training is stopped when the specified value is reached. Requires that a validation dataset was input.\nFor best results, it is recommended to set a value in the range[10\u201310;10\u22122][10^{\u201310}; 10^{-2}][10\u201310;10\u22122].\nThe larger the value, the earlier overfitting is detected.\nAlert\nDo not use this parameter with the Iter overfitting detector type.\n**Command-line version parameters:**`--od-wait`\n**Python parameters:**`od\\_wait`\n**R parameters:**`od\\_wait`\n#### [](en/concepts/parameter-tuning#description6)Description\nThe number of iterations to continue the training after the iteration with the optimal metric value.\nThe purpose of this parameter differs depending on the selected overfitting detector type:\n* IncToDec\u00a0\u2014 Ignore the overfitting detector when the threshold is reached and continue learning for the specified number of iterations after the iteration with the optimal metric value.\n* Iter\u00a0\u2014 Consider the model overfitted and stop training after the specified number of iterations since the iteration with the optimal metric value.\n## [](en/concepts/parameter-tuning#learning-rate)Learning rate\nThis setting is used for reducing the gradient step. It affects the overall time of training: the smaller the value, the more iterations are required for training. Choose the value based on the performance expectations.\nBy default, the learning rate is defined automatically based on the dataset properties and the number of iterations. The automatically defined value should be close to the optimal one.\nPossible ways of adjusting the learning rate depending on the overfitting results:\n* There is no overfitting on the last iterations of training (the training does not converge)\u00a0\u2014 increase the learning rate.\n* Overfitting is detected\u00a0\u2014 decrease the learning rate.P...",
      "url": "https://catboost.ai/docs/en/concepts/parameter-tuning"
    },
    {
      "title": "Common Mistakes & Best Practices for CatBoost | DataScienceBase",
      "text": "[Skip to main content](https://datasciencebase.com/datasciencebase.com#__docusaurus_skipToContent_fallback)\n\nOn this page\n\nCatBoost is a popular gradient boosting algorithm that\u2019s particularly well-suited for handling categorical data. However, there are several common mistakes and best practices to follow when using CatBoost to ensure optimal performance.\n\n## Common Mistakes [\u200b](https://datasciencebase.com/datasciencebase.com\\#common-mistakes)\n\n### 1\\. **Ignoring Categorical Feature Handling** [\u200b](https://datasciencebase.com/datasciencebase.com\\#1-ignoring-categorical-feature-handling)\n\n- **Mistake**: Not using CatBoost\u2019s **automatic handling** of categorical features by treating categorical data as numerical features (e.g., label encoding manually).\n- **Solution**: Use CatBoost\u2019s built-in capability to handle categorical features directly by passing them through the `cat_features` parameter.\n- **Example**:\n\n\n```\ncat_features =[0,1,2]# Indexes of categorical columnsmodel = CatBoostClassifier(cat_features=cat_features)model.fit(X_train, y_train)\n```\n\n\n### 2\\. **Overfitting with Too Many Iterations** [\u200b](https://datasciencebase.com/datasciencebase.com\\#2-overfitting-with-too-many-iterations)\n\n- **Mistake**: Like other boosting algorithms, CatBoost can overfit if trained for too many iterations, especially without early stopping.\n- **Solution**: Use **early stopping** to halt training when performance on the validation set stops improving.\n- **Example**:\n\n\n```\nmodel = CatBoostClassifier(iterations=1000)model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=10)\n```\n\n\n### 3\\. **Ignoring Class Imbalance** [\u200b](https://datasciencebase.com/datasciencebase.com\\#3-ignoring-class-imbalance)\n\n- **Mistake**: Not handling imbalanced classes in classification problems, which can cause the model to favor the majority class.\n- **Solution**: Use the **class\\_weights** parameter to adjust for imbalanced datasets, or oversample the minority class.\n- **Example**:\n\n\n```\nmodel = CatBoostClassifier(class_weights=[1,5])# Give more weight to the minority classmodel.fit(X_train, y_train)\n```\n\n\n### 4\\. **Not Tuning the Learning Rate** [\u200b](https://datasciencebase.com/datasciencebase.com\\#4-not-tuning-the-learning-rate)\n\n- **Mistake**: Setting the **learning\\_rate** too high can lead to unstable models, while setting it too low may result in slow convergence.\n- **Solution**: Use a smaller learning rate (e.g., 0.01 or 0.1) combined with a larger number of iterations to maintain stability while achieving better performance.\n- **Best Practice**: Start with a learning rate of `0.1` and adjust based on validation performance.\n\n### 5\\. **Not Taking Advantage of Parameter Auto-Tuning** [\u200b](https://datasciencebase.com/datasciencebase.com\\#5-not-taking-advantage-of-parameter-auto-tuning)\n\n- **Mistake**: Ignoring CatBoost\u2019s automatic hyperparameter tuning features, which can lead to suboptimal models.\n- **Solution**: Use **grid search** or **randomized search** for hyperparameter tuning. Alternatively, CatBoost provides automatic parameter tuning ( `AutoClassWeights` for class imbalance).\n- **Example**:\n\n\n```\nmodel = CatBoostClassifier(auto_class_weights=\"Balanced\")\n```\n\n\n### 6\\. **Using Default Depth for Trees** [\u200b](https://datasciencebase.com/datasciencebase.com\\#6-using-default-depth-for-trees)\n\n- **Mistake**: Using the default tree depth may not always provide the best performance, especially for datasets with complex patterns.\n- **Solution**: Tune the `depth` parameter based on your dataset. Shallower trees (lower depth) are less likely to overfit but may miss complex relationships in the data.\n- **Example**:\n\n\n```\nmodel = CatBoostClassifier(depth=6)\n```\n\n\n### 7\\. **Not Using Cross-Validation** [\u200b](https://datasciencebase.com/datasciencebase.com\\#7-not-using-cross-validation)\n\n- **Mistake**: Training the model without cross-validation can lead to overfitting and suboptimal generalization.\n- **Solution**: Use **k-fold cross-validation** to evaluate model performance on different subsets of the data.\n- **Example**:\n\n\n```\nfrom sklearn.model_selection import cross_val_scorescores = cross_val_score(model, X, y, cv=5)print(\"Mean Accuracy:\", np.mean(scores))\n```\n\n\n### 8\\. **Forgetting to Monitor Feature Importance** [\u200b](https://datasciencebase.com/datasciencebase.com\\#8-forgetting-to-monitor-feature-importance)\n\n- **Mistake**: Not checking which features contribute most to the model, leading to suboptimal feature selection and potential overfitting.\n- **Solution**: Use **feature importance** methods like **SHAP** or **Loss-based Importance** to interpret the model and prune unnecessary features.\n- **Example**:\n\n\n```\nmodel.get_feature_importance()\n```\n\n\n## Best Practices [\u200b](https://datasciencebase.com/datasciencebase.com\\#best-practices)\n\n### 1\\. **Use CatBoost for Handling Categorical Data** [\u200b](https://datasciencebase.com/datasciencebase.com\\#1-use-catboost-for-handling-categorical-data)\n\n- One of CatBoost\u2019s main advantages is its ability to handle categorical data efficiently. Make sure to leverage this feature by identifying categorical columns in your dataset and passing them to the `cat_features` parameter.\n- **Best Practice**: Always specify the categorical features when training with mixed data types.\n- **Example**:\n\n\n```\ncat_features =[0,2,4]# Indexes of categorical columnsmodel = CatBoostClassifier(cat_features=cat_features)\n```\n\n\n### 2\\. **Regularize with Depth and L2 Regularization** [\u200b](https://datasciencebase.com/datasciencebase.com\\#2-regularize-with-depth-and-l2-regularization)\n\n- CatBoost offers various regularization techniques, including setting the tree **depth** and **L2 regularization**. Setting an appropriate tree depth can help prevent overfitting, while L2 regularization adds a penalty term to avoid large weights.\n- **Best Practice**: Regularly tune both **depth** and **l2\\_leaf\\_reg**.\n- **Example**:\n\n\n```\nmodel = CatBoostClassifier(depth=4, l2_leaf_reg=3)\n```\n\n\n### 3\\. **Leverage Early Stopping** [\u200b](https://datasciencebase.com/datasciencebase.com\\#3-leverage-early-stopping)\n\n- Early stopping is crucial in preventing overfitting and saving time. Set `early_stopping_rounds` to a reasonable value to stop training if the validation accuracy doesn\u2019t improve after a few iterations.\n- **Best Practice**: Combine early stopping with cross-validation.\n- **Example**:\n\n\n```\nmodel.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=20)\n```\n\n\n### 4\\. **Hyperparameter Tuning for Optimal Performance** [\u200b](https://datasciencebase.com/datasciencebase.com\\#4-hyperparameter-tuning-for-optimal-performance)\n\n- Use **GridSearchCV** or **RandomizedSearchCV** to fine-tune hyperparameters, such as `depth`, `learning_rate`, and `l2_leaf_reg`. CatBoost has many parameters that should be carefully tuned to avoid under- or overfitting.\n- **Best Practice**: Perform hyperparameter tuning using cross-validation to find the best combination of parameters.\n- **Example**:\n\n\n```\nfrom sklearn.model_selection import GridSearchCVparam_grid ={'iterations':[100,200],'depth':[4,6,8],'learning_rate':[0.01,0.1,0.2]}grid_search = GridSearchCV(CatBoostClassifier(), param_grid, cv=5)grid_search.fit(X_train, y_train)\n```\n\n\n### 5\\. **Monitor Feature Importance and Use SHAP Values** [\u200b](https://datasciencebase.com/datasciencebase.com\\#5-monitor-feature-importance-and-use-shap-values)\n\n- Feature importance provides valuable insights into which features contribute the most to the model\u2019s predictions. Using **SHAP values** can help explain model predictions for individual instances.\n- **Best Practice**: Always check and interpret feature importance, especially if your dataset has many features.\n- **Example**:\n\n\n```\nimport shapexplainer = shap.TreeExplainer(model)shap_values = explainer.shap_values(X_test)shap.summary_plot(shap_values, X_test)\n```\n\n\n### 6\\. **Use Ensemble Techniques for Better Performance** [\u200b](https://datasciencebase.com/datasciencebase.com\\#6-use-ensemble-t...",
      "url": "https://datasciencebase.com/supervised-ml/algorithms/gradient-boosting/CatBoost/common-mistakes"
    },
    {
      "title": "CatBoost Cross-Validation and Hyperparameter Tuning",
      "text": "CatBoost Cross-Validation and Hyperparameter Tuning - GeeksforGeeks\n**\n* [Python for Machine Learning](https://www.geeksforgeeks.org/machine-learning/python-for-machine-learning/)\n* [Machine Learning with R](https://www.geeksforgeeks.org/r-machine-learning/introduction-to-machine-learning-in-r/)\n* [Machine Learning Algorithms](https://www.geeksforgeeks.org/machine-learning/machine-learning-algorithms/)\n* [EDA](https://www.geeksforgeeks.org/data-analysis/what-is-exploratory-data-analysis/)\n* [Math for Machine Learning](https://www.geeksforgeeks.org/machine-learning/machine-learning-mathematics/)\n* [Machine Learning Interview Questions](https://www.geeksforgeeks.org/machine-learning/machine-learning-interview-questions/)\n* [ML Projects](https://www.geeksforgeeks.org/machine-learning/machine-learning-projects/)\n* [Deep Learning](https://www.geeksforgeeks.org/deep-learning/deep-learning-tutorial/)\n* [NLP](https://www.geeksforgeeks.org/nlp/natural-language-processing-nlp-tutorial/)\n* [Computer vision](https://www.geeksforgeeks.org/computer-vision/computer-vision/)\n* [Data Science](https://www.geeksforgeeks.org/data-science/data-science-for-beginners/)\n* [Artificial Intelligence](https://www.geeksforgeeks.org/artificial-intelligence/artificial-intelligence/)**\n******\nSign In\n&#x25B2;\n[Open In App](https://geeksforgeeksapp.page.link/?link=https://www.geeksforgeeks.org/catboost-cross-validation-and-hyperparameter-tuning/?type=article&id=1091691&apn=free.programming.programming&isi=1641848816&ibi=org.geeksforgeeks.GeeksforGeeksDev&efr=1)\n# CatBoost Cross-Validation and Hyperparameter Tuning\nLast Updated :06 Aug, 2025\n**\nComments\n**\nImprove\n**\n* * * **Suggest changes\n1 Likes\n**Like\n**Report\nCatBoost is a powerful gradient-boosting algorithm of[machine learning](https://www.geeksforgeeks.org/machine-learning/machine-learning/)that is very popular for its effective capability to handle categorial features of both classification and regression tasks. To maximize the potential of CatBoost, it's essential to fine-tune its hyperparameters which can be done by Cross-validation. Cross-validation is a crucial technique that allows data scientists and machine learning practitioners to rigorously assess the model's performance under different parameter configuration sets and select the most optimal hyperparameters. In this article, we are going to discuss how we can tune the hyper-parameters of CatBoost using cross-validation.\n## What is CatBoost\n[CatBoost](https://www.geeksforgeeks.org/machine-learning/catboost-ml/)or Categorical Boosting is a machine learning algorithm that was developed by Yandex, a Russian multinational IT company. This special boosting algorithm is based on the gradient boosting framework and is designed to handle categorical features more effectively than traditional gradient boosting algorithms. CatBoost incorporates techniques like ordered boosting, oblivious trees, and advanced handling of categorical variables to achieve high performance with minimal hyperparameter tuning. But for real-world datasets, it is required to perform hyperparameter tuning by which we can achieve optimized model training overhead and accurate predictions. In this article, we are going to tune its hyperparameters using Cross-validation.\n## What is Cross-Validation\n[Cross-validation](https://www.geeksforgeeks.org/machine-learning/cross-validation-machine-learning/)is a fundamental technique used in machine learning to assess a model's performance by mitigating the risk of overfitting and determining how well a model is likely to generalize to unseen data. This process involves several steps dividing the dataset into multiple subsets or folds, then training the model on the training set, and finally evaluating its performance on the remaining validation set. Two common cross-validation methods are[k-fold cross-validation](https://www.geeksforgeeks.org/videos/k-fold-cross-validation-machine-learning/)and[stratified k-fold cross-validation](https://www.geeksforgeeks.org/machine-learning/stratified-k-fold-cross-validation/), The stratified CV is going to be used in this article. There are some key-benefits of cross-validation listed below--&gt;****Robust Performance Assessment:****Cross-validation provides a more accurate estimate of a model's performance because it assesses its ability to generalize to different data subsets which helps to detect issues like[overfitting](https://www.geeksforgeeks.org/machine-learning/underfitting-and-overfitting-in-machine-learning/).\n* ****Hyperparameter Tuning:****Cross-validation is important for hyperparameter tuning. By evaluating model performance across various parameter combinations, data scientists can identify the best hyperparameters which results optimal model performance and accurate prediction.\n* ****Effective Use of Data:****Cross-validation ensures that the entire dataset is used for both training and validation which maximizes the utility of the available data.## Why to perform Hyperparameter tuning\nHyperparameter tuning is the process of systematically searching for the best hyperparameter values for a machine learning model which has several key-importance listed below:\n1. ****Improved Model Performance:****The right set of hyperparameters can significantly enhance a model's performance which leads to better accuracy and generalization to new data.\n2. ****Reduction of Overfitting:****Carefully chosen[hyperparameters](https://www.geeksforgeeks.org/machine-learning/hyperparameter-tuning/)can prevent overfitting where the model learns to fit the training data too closely and performs poorly on unseen data which leads to wrong predictions on large datasets.\n3. ****Increased Robustness:****Tuned hyperparameters make a model more resilient to variations in the data and different problem scenarios which ensures it to remain effective in various situations by reducing computational resources and training time.\n4. ****Enhanced Interpretability:****Some hyperparameters can influence the interpretability of the model and tuning them can make the model's output more understandable and actionable which leads to accurate predictions with optimized model training.## Implementation of Cross-validation for hyperparameter tuning in Catboost\n#### Installing required module\nAt first, we need to install CatBoost module to our runtime.\n```\n!pip install catboost\n```\n#### Importing required libraries\nNow we will import all required[Python](https://www.geeksforgeeks.org/python/python-programming-language-tutorial/)libraries like[Pandas](https://www.geeksforgeeks.org/pandas/pandas-tutorial/),[NumPy](https://www.geeksforgeeks.org/numpy/python-numpy/),[Matplotlib](https://www.geeksforgeeks.org/python/python-introduction-matplotlib/),[Seaborn](https://www.geeksforgeeks.org/python/introduction-to-seaborn-python/), SKlearn etc.\nPython3`\n```\nimportpandasaspdfromcatboostimportCatBoostClassifier,Poolfromsklearn.model\\_selectionimporttrain\\_test\\_splitfromsklearn.metricsimportaccuracy\\_score,f1\\_scorefromsklearn.model\\_selectionimportStratifiedKFoldfromtabulateimporttabulateimportseabornassnsimportmatplotlib.pyplotasplt\n```\n`#### Loading Dataset\nNow we will load the Titanic dataset and select relevant features for this implementation and create a list of categorial features which will be feed to the model later on.\nPython3`\n```\n# Load the Titanic dataseturl=&quot;https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv&quot;df=pd.read\\_csv(url)# Select relevant features and target variableX=df[[&#39;Pclass&#39;,&#39;Sex&#39;,&#39;Age&#39;,&#39;Fare&#39;]]y=df[&#39;Survived&#39;]# define categorial features of datasetcat\\_features=[&#39;Pclass&#39;,&#39;Sex&#39;]# List of categorical features\n```\n`\nThis code creates a DataFrame named df and loads the Titanic dataset from a specified URL. Following that, it chooses particular features, such as \"Pclass,\" \"Sex,\" \"Age,\" and \"Fare,\" and assigns them to the variable X. The variable y contain...",
      "url": "https://www.geeksforgeeks.org/machine-learning/catboost-cross-validation-and-hyperparameter-tuning"
    },
    {
      "title": "Binary classification using CatBoost",
      "text": "- [Data Science](https://www.geeksforgeeks.org/data-science-with-python-tutorial/)\n- [Data Science Projects](https://www.geeksforgeeks.org/top-data-science-projects/)\n- [Data Analysis](https://www.geeksforgeeks.org/data-analysis-tutorial/)\n- [Data Visualization](https://www.geeksforgeeks.org/python-data-visualization-tutorial/)\n- [Machine Learning](https://www.geeksforgeeks.org/machine-learning/)\n- [ML Projects](https://www.geeksforgeeks.org/machine-learning-projects/)\n- [Deep Learning](https://www.geeksforgeeks.org/deep-learning-tutorial/)\n- [NLP](https://www.geeksforgeeks.org/natural-language-processing-nlp-tutorial/)\n- [Computer Vision](https://www.geeksforgeeks.org/computer-vision/)\n- [Artificial Intelligence](https://www.geeksforgeeks.org/artificial-intelligence/)\n\nSign In\n\n\u25b2\n\n[Open In App](https://geeksforgeeksapp.page.link/?link=https://www.geeksforgeeks.org/binary-classification-using-catboost/?type%3Darticle%26id%3D1090865&apn=free.programming.programming&isi=1641848816&ibi=org.geeksforgeeks.GeeksforGeeksDev&efr=1)\n\n[Next Article:\\\n\\\nDecision Tree Algorithms\\\n\\\n![Next article icon](https://media.geeksforgeeks.org/auth-dashboard-uploads/ep_right.svg)](https://www.geeksforgeeks.org/decision-tree-algorithms/)\n\n# Binary classification using CatBoost\n\nLast Updated : 24 Apr, 2025\n\nComments\n\nImprove\n\nSuggest changes\n\nLike Article\n\nLike\n\nReport\n\nCatBoost is a high-performance, open-source gradient boosting library developed by Yandex, a Russian multinational IT company. It is designed for categorical feature support, making it particularly powerful for structured data like those often encountered in real-world datasets. In this article, we will explore CatBoost in detail, from understanding how it works to performing binary classification using a real-world dataset.\n\n## What is CatBoost\n\nCatBoost stands for \"Categorical Boosting,\" and it is a machine learning algorithm that falls under the gradient boosting framework. As its name suggests, [CatBoost](https://www.geeksforgeeks.org/catboost-ml/) has two main features, it works with categorical data and it uses gradient-boosting algorithms for inferences. Gradient boosting is an ensemble technique that combines the predictions from multiple weak learners (typically decision trees) to create a strong predictive model. What sets CatBoost apart is its ability to handle categorical features efficiently, without the need for preprocessing, and its strong performance out of the box.\n\n### How CatBoost Works\n\nTo increase [gradient boosting's](https://www.geeksforgeeks.org/ml-gradient-boosting/) precision and effectiveness, CatBoost employs a variety of strategies, such as feature engineering, decision tree optimization, and an innovative algorithm known as ordered boosting. CatBoost computes the loss function's negative gradient in relation to the current predictions at every algorithm iteration. Next, by appending a scaled version of the gradient to the existing predictions, we utilize this gradient to update the predictions. An approach based on line search that minimizes the loss function is used to determine the scaling factor.\n\nUsing a method known as gradient-based optimization, CatBoost constructs the decision trees by fitting the trees to the negative gradient of the loss function. Predictions made using this method are more accurate since the trees are able to concentrate on the areas of feature space that have the biggest effects on the loss function. Lastly, ordered boosting, a brand-new technique introduced by CatBoost, permutes the features in a certain order to optimize the learning objective function. Particularly for data sets with a lot of features, this method can lead to faster convergence and improved model correctness.\n\n### CatBoost Parameters\n\nLets dicuss few import parameter in CatBoost model:\n\n- **learning\\_rate**: This parameter controls the step size or the rate at which the model updates its predictions during each boosting iteration. A smaller [learning rate](https://www.geeksforgeeks.org/impact-of-learning-rate-on-a-model/) leads to slower convergence but can help the model generalize better. A common range for learning rates is between 0.01 and 0.3.\n- **iterations**: It specifies the number of boosting iterations or trees to build. Each iteration adds a new tree to the ensemble, and the model's predictions are updated based on the combined predictions of all the trees. Increasing the number of iterations may improve the model's performance but can also lead to overfitting.\n- **depth**: This parameter sets the maximum depth of the individual trees in the ensemble. A deeper tree can capture more complex patterns but may also lead to overfitting. You should experiment with different depth values to find the optimal balance between model complexity and performance.\n- **loss\\_function**: The [loss\\_function](https://www.geeksforgeeks.org/catboost-tree-parameters/) parameter allows you to specify the loss function used to optimize the model during training. CatBoost supports a variety of loss functions, including 'Logloss' (binary classification), 'RMSE' (regression), and custom loss functions that you can define based on your specific problem.\n- **custom\\_metric**: You can use this parameter to specify custom evaluation metrics that are not available in the default set of metrics provided by CatBoost. For example, if you have a specific metric that's important for your problem, you can define it here for model evaluation.\n- **l2\\_leaf\\_reg**: [L2 regularisation](https://www.geeksforgeeks.org/ml-implementing-l1-and-l2-regularization-using-sklearn/) term applied to leaf values. It helps control the smoothness of the learned leaf values. Higher values of l2\\_leaf\\_reg lead to smoother leaf values, which can prevent overfitting.\n- **max\\_leaves**: This parameter specifies the maximum number of leaves (terminal nodes) in each tree. Limiting the maximum number of leaves can help control the complexity of individual trees and reduce overfitting.\n\n### Implementation Binary classification using CatBoost\n\nTo get started with CatBoost, we typically need to define a problem (classification or regression), prepare the data, create a CatBoost model, train the model, and use it to make predictions.\n\n#### Define a problem :\n\nThe code example provided is a binary classification problem. Specifically, it's aimed at predicting whether a passenger survived (1) or did not survive (0) based on various features provided in the dataset. The problem can be summarised as follows:\n\nProblem Type: Binary Classification\n\nTarget Variable:\n\n- 0: The did not survive\n- 1: The passenger survived\n\nWe use sns.load\\_dataset to load the titanic dataset.\n\n#### Installing necessary libraries\n\n```\n!pip install catboost\n```\n\n#### Importing necessary libraries\n\nPython3`\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom catboost import CatBoostClassifier\n`\n\nThe [pandas](https://www.geeksforgeeks.org/pandas-tutorial/), [matplotlib](https://www.geeksforgeeks.org/python-introduction-matplotlib/), [seaborn](https://www.geeksforgeeks.org/introduction-to-seaborn-python/), [numpy](https://www.geeksforgeeks.org/python-numpy/), and catBoost libraries are imported in this code sample in order to facilitate data analysis and machine learning. The methodology for data analysis and classification is common and includes the following steps: dividing the data into training and testing sets; training a CatBoost classifier; assessing the model's accuracy; generating a confusion matrix and classification report; and using Seaborn to visualize the confusion matrix.\n\n#### Loading Dataset\n\nPython3`\n# Load the Titanic dataset\ntitanic = sns.load_dataset('titanic')\ntarget = 'survived'\n`\n\nThis code loads the built-in Seaborn dataset, which is the Titanic dataset. It desc...",
      "url": "https://www.geeksforgeeks.org/binary-classification-using-catboost"
    },
    {
      "title": "How to increase accuracy of model using catboost",
      "text": "2024 Developer survey is here and we would like to hear from you!\n[Take the 2024 Developer Survey](https://stackoverflow.com/dev-survey/start?utm_medium=referral&utm_source=stackexchange-community&utm_campaign=dev-survey-2024&utm_content=announcement-banner)\n\n##### Collectives\u2122 on Stack Overflow\n\nFind centralized, trusted content and collaborate around the technologies you use most.\n\n[Learn more about Collectives](https://stackoverflow.com/collectives)\n\n**Teams**\n\nQ&A for work\n\nConnect and share knowledge within a single location that is structured and easy to search.\n\n[Learn more about Teams](https://stackoverflow.co/teams/)\n\nGet early access and see previews of new features.\n\n[Learn more about Labs](https://stackoverflow.co/labs/)\n\n# [How to increase accuracy of model using catboost](https://stackoverflow.com/questions/60648547/how-to-increase-accuracy-of-model-using-catboost)\n\n[Ask Question](https://stackoverflow.com/questions/ask)\n\nAsked4 years, 3 months ago\n\nModified [3 years, 5 months ago](https://stackoverflow.com/questions/60648547/how-to-increase-accuracy-of-model-using-catboost?lastactivity)\n\nViewed\n8k times\n\n1\n\nI am trying to build a model for binary classification using catboost for a employee salary dataset. I have tried utmost tuning but still i am getting only 87% accuracy how can i increase it to ~98% or more?\n\nGoal is to predict the class.\n\nHere is the dataset and code:\n\nDataset:\n\n[http://archive.ics.uci.edu/ml/datasets/Adult](http://archive.ics.uci.edu/ml/datasets/Adult)\n\nCode:\n\n```\n    from catboost import CatBoostClassifier\n\n    import pandas as pd\n    import numpy as np\n    from numpy import arange\n    from tqdm import tqdm_notebook as tqdm\n    import matplotlib.pyplot as plt\n    plt.style.use('ggplot')\n    import seaborn as sns\n    from sklearn.model_selection import train_test_split\n    from sklearn import metrics, preprocessing\n\n    train = pd.read_csv('train.csv')\n    test = pd.read_csv('test.csv')\n\n    X = train.drop('class', axis=1)\n    y = train['class']\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=27)\n    test_data = test.drop('class', axis=1)\n    print(y_train.value_counts())\n    print(y_test.value_counts())\n\n    #provide categorical features to catboost\n    cat_features = ['workclass','education','marital-status','occupation','relationship','race','sex','native-country']\n\n    best_params = {\n            'bagging_temperature': 0.5,\n            'depth': 8,\n            'iterations': 1000,\n            'l2_leaf_reg': 25,\n            'learning_rate': 0.05,\n            'sampling_frequency': 'PerTreeLevel',\n            'leaf_estimation_method': 'Gradient',\n            'random_strength': 0.8,\n            'boosting_type': 'Ordered',\n            'feature_border_type': 'MaxLogSum',\n            'l2_leaf_reg': 50,\n            'max_ctr_complexity': 2,\n            'fold_len_multiplier': 2\n    }\n\n    model_cat = CatBoostClassifier(**best_params,\n                               loss_function='Logloss',\n                               eval_metric='AUC',\n                               nan_mode='Min',\n                               thread_count=8,\n                               task_type='CPU',\n                               verbose=True)\n\n    model_cat.fit(X_train, y_train,\n                              eval_set=(X_test, y_test),\n                              cat_features=cat_features,\n                              verbose_eval=300,\n                              early_stopping_rounds=500,\n                              use_best_model=True,\n                              plot=False)\n\n    model_cat.save_model(\"catmodel\")\n\n    ##Predictions\n    cat_predictions = model_cat.predict_proba(test_data)[:, 1]\n    cat_predictions_df = pd.DataFrame({'class': cat_predictions})\n\n```\n\nHere is the max accuracy i got after entire tuning..\n\n```\n     Test set class grouping:\n     <=50K    7451\n     >50K     2318\n\n      Predicted\n       Y    N\n    [[7037  799]\n     [ 414 1519]]\n\n    Precision:  0.9444369883237149\n    Recall:  0.8980347115875447\n    Accuracy:  0.8758317125601393\n    F1-score:  0.9206515339831229\n\n```\n\nSo here still i have 414 FPs and 799 FNs which are bad results.. tried out all the best\\_params from documentation and different values of it.\n\n- [machine-learning](https://stackoverflow.com/questions/tagged/machine-learning)\n- [classification](https://stackoverflow.com/questions/tagged/classification)\n- [catboost](https://stackoverflow.com/questions/tagged/catboost)\n\n[Share](https://stackoverflow.com/q/60648547)\n\n[Improve this question](https://stackoverflow.com/posts/60648547/edit)\n\nFollow\n\nasked Mar 12, 2020 at 6:15\n\n[![Hariram Manohar's user avatar](https://lh5.googleusercontent.com/-P2xi1xBNVT0/AAAAAAAAAAI/AAAAAAAAAAA/AKF05nD7F_dxHzMFDhGjP-l-OYFX9jJsWA/photo.jpg?sz=64)](https://stackoverflow.com/users/13049332/hariram-manohar)\n\n[Hariram Manohar](https://stackoverflow.com/users/13049332/hariram-manohar) Hariram Manohar\n\n8611 silver badge66 bronze badges\n\n[Add a comment](https://stackoverflow.com/questions/60648547/how-to-increase-accuracy-of-model-using-catboost)\u00a0\\|\n\n## 2 Answers 2\n\nSorted by:\n[Reset to default](https://stackoverflow.com/questions/60648547/how-to-increase-accuracy-of-model-using-catboost?answertab=scoredesc#tab-top)\n\nHighest score (default)Trending (recent votes count more)Date modified (newest first)Date created (oldest first)\n\n3\n\n@MJ209, Here is the grid search params and accuracy.\n\n```\n    params = {'depth':[3,1,2,6,4,5,7,8,9,10],\n              'iterations':[250,100,500,1000],\n              'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3],\n              'l2_leaf_reg':[3,1,5,10,100],\n              'border_count':[32,5,10,20,50,100,200],\n              'bagging_temperature':[0.03,0.09,0.25,0.75],\n              'random_strength':[0.2,0.5,0.8],\n              'max_ctr_complexity':[1,2,3,4,5] }\n\n    model = CatBoostClassifier()\n    grid_search_result = model.grid_search(params,\n                                           X=train_set,\n                                           y=train_label,\n                                           cv=5,\n                                           partition_random_seed=3,\n                                           stratified=True)\n\n```\n\ni have stopped program in middle after 36 hrs of running as it shows it will take 24 days more to complete and below is the last trace of program:\n\n150625: loss: 0.2800770 best: 0.2746405 (5345) total: 7m 22s remaining: 24d 1h 2m 7s\n\n[Share](https://stackoverflow.com/a/60756492)\n\n[Improve this answer](https://stackoverflow.com/posts/60756492/edit)\n\nFollow\n\nanswered Mar 19, 2020 at 11:41\n\n[![Hariram Manohar's user avatar](https://lh5.googleusercontent.com/-P2xi1xBNVT0/AAAAAAAAAAI/AAAAAAAAAAA/AKF05nD7F_dxHzMFDhGjP-l-OYFX9jJsWA/photo.jpg?sz=64)](https://stackoverflow.com/users/13049332/hariram-manohar)\n\n[Hariram Manohar](https://stackoverflow.com/users/13049332/hariram-manohar) Hariram Manohar\n\n8611 silver badge66 bronze badges\n\n[Add a comment](https://stackoverflow.com/questions/60648547/how-to-increase-accuracy-of-model-using-catboost)\u00a0\\|\n\n2\n\nI hope you can tune it further using **grid\\_search** method available in **_catboost.CatBoostClassifier_** library.\n\nfor more reference please find the URL: [https://catboost.ai/docs/concepts/python-reference\\_catboost\\_grid\\_search.html](https://catboost.ai/docs/concepts/python-reference_catboost_grid_search.html)\n\n[Share](https://stackoverflow.com/a/60658408)\n\n[Improve this answer](https://stackoverflow.com/posts/60658408/edit)\n\nFollow\n\n[edited Mar 12, 2020 at 16:50](https://stackoverflow.com/posts/60658408/revisions)\n\nanswered Mar 12, 2020 at 16:39\n\n[![MJ029's user avatar](https://i.sstatic.net/x1odm.jpg?s=64)](https://stackoverflow.com/users/7765289/mj029)\n\n[MJ029](https://stackoverflow.com/users/7765289/mj029) MJ029\n\n16933 silver badges1414 bronze badges\n\n2\n\n- Hi @MJ029, i have tried out what you said but it leaves me with the worst results and taken long time. i have followed this...",
      "url": "https://stackoverflow.com/questions/60648547/how-to-increase-accuracy-of-model-using-catboost"
    },
    {
      "title": "How to improve the catboostregressor?",
      "text": "2024 Developer survey is here and we would like to hear from you!\n[Take the 2024 Developer Survey](https://stackoverflow.com/dev-survey/start?utm_medium=referral&utm_source=stackexchange-community&utm_campaign=dev-survey-2024&utm_content=announcement-banner)\n\n##### Collectives\u2122 on Stack Overflow\n\nFind centralized, trusted content and collaborate around the technologies you use most.\n\n[Learn more about Collectives](https://stackoverflow.com/collectives)\n\n**Teams**\n\nQ&A for work\n\nConnect and share knowledge within a single location that is structured and easy to search.\n\n[Learn more about Teams](https://stackoverflow.co/teams/)\n\nGet early access and see previews of new features.\n\n[Learn more about Labs](https://stackoverflow.co/labs/)\n\n# [How to improve the catboostregressor? \\[closed\\]](https://stackoverflow.com/questions/66435852/how-to-improve-the-catboostregressor)\n\n[Ask Question](https://stackoverflow.com/questions/ask)\n\nAsked3 years, 3 months ago\n\nModified [2 years, 5 months ago](https://stackoverflow.com/questions/66435852/how-to-improve-the-catboostregressor?lastactivity)\n\nViewed\n11k times\n\n6\n\nI am working on a data science regression problem with around 90,000 rows on train set and 8500 on test set. There are 9 categorical columns and no missing data. for this case, I am applied a catboostregressor which given me the pretty good R2(98.51) and MAE (3.77). Other nodels LGBM, XGBOOST performed under catboost.\n\nNow I would like to increase the R2 value and decrease the MAE for more accurate results. That's what the demand too.\n\nI have tuned many times by adding 'loss\\_function': \\['MAE'\\], 'l2\\_leaf\\_reg':\\[3\\], 'random\\_strength': \\[4\\], 'bagging\\_temperature':\\[0.5\\] with different values but the performance is the same.\n\nCan anyone help me how to boost the R2 value by minimizing MAE and MSE ?\n\n- [machine-learning](https://stackoverflow.com/questions/tagged/machine-learning)\n- [data-science](https://stackoverflow.com/questions/tagged/data-science)\n- [catboost](https://stackoverflow.com/questions/tagged/catboost)\n\n[Share](https://stackoverflow.com/q/66435852)\n\n[Improve this question](https://stackoverflow.com/posts/66435852/edit)\n\nFollow\n\n[edited Mar 11, 2021 at 11:47](https://stackoverflow.com/posts/66435852/revisions)\n\nSekhar\n\nasked Mar 2, 2021 at 8:32\n\n[![Sekhar's user avatar](https://www.gravatar.com/avatar/684e15860e12474421a518e635e1f116?s=64&d=identicon&r=PG)](https://stackoverflow.com/users/948801/sekhar)\n\n[Sekhar](https://stackoverflow.com/users/948801/sekhar) Sekhar\n\n68955 gold badges1818 silver badges3737 bronze badges\n\n2\n\n- 1\n\n\n\n\n\nYou can try to tune hyperparameters for CatBoost. The second option would be to try feature engineering, maybe you can add some combination of existing features to the data that will improve the performance. You can also try MLJAR AutoML [github.com/mljar/mljar-supervised](https://github.com/mljar/mljar-supervised) it has built-in feature engineering (golden features + kmeans features)\n\n\u2013\u00a0[pplonski](https://stackoverflow.com/users/5605919/pplonski)\n\nCommentedMar 2, 2021 at 10:17\n\n- 2\n\n\n\n\n\nHi pplonski, Thank you. I did the tuning and got better score.\n\n\u2013\u00a0[Sekhar](https://stackoverflow.com/users/948801/sekhar)\n\nCommentedMar 2, 2021 at 12:09\n\n\n[Add a comment](https://stackoverflow.com/questions/66435852/how-to-improve-the-catboostregressor)\u00a0\\|\n\n## 1 Answer 1\n\nSorted by:\n[Reset to default](https://stackoverflow.com/questions/66435852/how-to-improve-the-catboostregressor?answertab=scoredesc#tab-top)\n\nHighest score (default)Trending (recent votes count more)Date modified (newest first)Date created (oldest first)\n\n12\n\n**Simple method -**\n\nYou can use Scikit-Learn's `GridSearchCV` to find the best hyperparameters for your `CatBoostRegressor` model. You can pass a dictionary of hyperparameters, and `GridSearchCV` will loop through all the hyperparameters and tell you which parameters are best. You can use it like this -\n\n```\nfrom sklearn.model_selection import GridSearchCV\n\nmodel = CatBoostRegressor()\nparameters = {'depth' : [6,8,10],\n              'learning_rate' : [0.01, 0.05, 0.1],\n              'iterations'    : [30, 50, 100]\n              }\n\ngrid = GridSearchCV(estimator=model, param_grid = parameters, cv = 2, n_jobs=-1)\ngrid.fit(X_train, y_train)\n\n```\n\n**Another method -**\n\nNow-a-days, models are complex and have a lot of parameters to tune. People are using Bayesian Optimization techniques, like Optuna, to tune hyperparameters. You can use Optuna to tune `CatBoostClassifier` like this:\n\n```\n!pip install optuna\nimport catboost\nimport optuna\n\ndef objective(trial):\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)\n\n    param = {\n        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.3),\n        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 15),\n        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n        \"bootstrap_type\": trial.suggest_categorical(\n            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n    }\n\n\n    if param[\"bootstrap_type\"] == \"Bayesian\":\n        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n        param[\"subsample\"] = trial.suggest_uniform(\"subsample\", 0.1, 1)\n\n    gbm = catboost.CatBoostClassifier(**param, iterations = 10000)\n\n    gbm.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = 0, early_stopping_rounds = 100)\n\n    preds = gbm.predict(X_val)\n    pred_labels = np.rint(preds)\n    accuracy = accuracy_score(y_val, pred_labels)\n\n    return accuracy\n\nstudy = optuna.create_study(direction = \"maximize\")\nstudy.optimize(objective, n_trials = 200, show_progress_bar = True)\n\n```\n\nThis method take a lot of time (1-2 hrs, maybe). This method is best to use when you have a lot of parameters to tune. Else, use Grid Search CV.\n\n[Share](https://stackoverflow.com/a/66437318)\n\n[Improve this answer](https://stackoverflow.com/posts/66437318/edit)\n\nFollow\n\n[edited Jan 10, 2022 at 14:19](https://stackoverflow.com/posts/66437318/revisions)\n\nanswered Mar 2, 2021 at 10:10\n\n[![Adarsh Wase's user avatar](https://i.sstatic.net/oniDF.png?s=64)](https://stackoverflow.com/users/14425501/adarsh-wase)\n\n[Adarsh Wase](https://stackoverflow.com/users/14425501/adarsh-wase) Adarsh Wase\n\n1,81633 gold badges1313 silver badges3030 bronze badges\n\n4\n\n- Hi Adarsh Wase, I have implemented as you suggested by adding few more parameters. It is an improvement. but the model running so long time. Thank you.\n\n\u2013\u00a0[Sekhar](https://stackoverflow.com/users/948801/sekhar)\n\nCommentedMar 2, 2021 at 12:06\n\n- Is it possible to let me know what are the best possible parameters to be added for better score again.\n\n\u2013\u00a0[Sekhar](https://stackoverflow.com/users/948801/sekhar)\n\nCommentedMar 2, 2021 at 12:08\n\n- There are number of parameters in catboost regressor. And all of them have equal importance, we don't know which parameter is the best. It depends on what project you are working on. Also, I think you should read catboost regressor's documentations. Here - [catboost.ai/docs/concepts/\u2026](https://catboost.ai/docs/concepts/python-reference_catboostregressor.html) By reading this, you will get enough knowledge of what hyperparameters are important to tune for your project. (Sorry for late reply)\n\n\u2013\u00a0[Adarsh Wase](https://stackoverflow.com/users/14425501/adarsh-wase)\n\nCommentedMar 3, 2021 at 13:22\n\n- What's the difference between `GridSearchCV` and the catboost built-in `grid_search`?\n\n\u2013\u00a0[sound wave](https://stackoverflow.com/users/8157304/sound-wave)\n\nCommentedJun 1, 2022 at 14:47\n\n\n[Add a comment](https://stackoverflow.com/questions/66435852/how-to-improve-the-catboostregressor)\u00a0\\|\n\n## Not the answer you're looking for? Browse other questions tagged  - [machine-learning](https://stackoverflow.com...",
      "url": "https://stackoverflow.com/questions/66435852/how-to-improve-the-catboostregressor"
    },
    {
      "title": "Parameter tuning |",
      "text": "Parameter tuning\n\n# Parameter tuning\n\n- [One-hot encoding](https://catboost.ai/docs/en/concepts/parameter-tuning#one-hot-enc)\n- [Number of trees](https://catboost.ai/docs/en/concepts/parameter-tuning#trees-number)\n- [Learning rate](https://catboost.ai/docs/en/concepts/parameter-tuning#learning-rate)\n- [Tree depth](https://catboost.ai/docs/en/concepts/parameter-tuning#tree-depth)\n- [L2 regularization](https://catboost.ai/docs/en/concepts/parameter-tuning#l2-reg)\n- [Random strength](https://catboost.ai/docs/en/concepts/parameter-tuning#rand-str)\n- [Bagging temperature](https://catboost.ai/docs/en/concepts/parameter-tuning#bagg-temp)\n- [Border count](https://catboost.ai/docs/en/concepts/parameter-tuning#border-count)\n- [Internal dataset order](https://catboost.ai/docs/en/concepts/parameter-tuning#internal-dataset-order)\n- [Tree growing policy](https://catboost.ai/docs/en/concepts/parameter-tuning#tree-growing-policy)\n- [Golden features](https://catboost.ai/docs/en/concepts/parameter-tuning#golden-features)\n- [Methods for hyperparameter search](https://catboost.ai/docs/en/concepts/parameter-tuning#defining-optimal-parameter-values)\n- [Methods for hyperparameter search by optuna](https://catboost.ai/docs/en/concepts/parameter-tuning#methods-for-hyperparameter-search-by-optuna)\n\nCatBoost provides a flexible interface for parameter tuning and can be configured to suit different tasks.\n\nThis section contains some tips on the possible parameter settings.\n\n## One-hot encoding\n\nWarning\n\nDo not use one-hot encoding during preprocessing. This affects both the training speed and the resulting quality.\n\nSometimes when categorical features don't have a lot of values, one-hot encoding works well.\n\nUsually one-hot encoding does not significantly improve the quality of the model. But if it is required, use the inbuilt parameters instead of preprocessing the dataset.\n\nParameters\n\n**Command-line version parameters:** `--one-hot-max-size`\n\n**Python parameters:** `one_hot_max_size`\n\n**R parameters:** `one_hot_max_size`\n\n#### Description\n\nUse one-hot encoding for all categorical features with a number of different values less than or equal to the given parameter value. Ctrs are not calculated for such features.\n\n**Default value**\n\nThe default value depends on various conditions:\n\n- N/A if training is performed on CPU in Pairwise scoring mode\nRead more about Pairwise scoring\n\n\n\nThe following loss functions use Pairwise scoring:\n\n\n\n- YetiRankPairwise\n- PairLogitPairwise\n- QueryCrossEntropy\n\nPairwise scoring is slightly different from regular training on pairs, since pairs are generated only internally during the training for the corresponding metrics. One-hot encoding is not available for these loss functions.\n\n- 255 if training is performed on GPU and the selected Ctr types require target data that is not available during the training\n\n- 10 if training is performed in\u00a0[Ranking](https://catboost.ai/docs/en/concepts/loss-functions-ranking) mode\n\n- 2 if none of the conditions above is met\n\n\n## Number of trees\n\nIt is recommended to check that there is no obvious underfitting or overfitting before tuning any other parameters. In order to do this it is necessary to analyze the metric value on the validation dataset and select the appropriate number of iterations.\n\nThis can be done by setting the number of\u00a0[iterations](https://catboost.ai/docs/en/references/training-parameters/common#iterations) to a large value, using the\u00a0[overfitting detector](https://catboost.ai/docs/en/concepts/overfitting-detector) parameters and turning the [use best model](https://catboost.ai/docs/en/references/training-parameters/common#use_best_model) options on. In this case the resulting model contains only the first `k` best iterations, where `k` is the iteration with the best loss value on the validation dataset.\n\nAlso, the metric for choosing the best model may differ from the one used for optimizing the objective value. For example, it is possible to set the optimized function to\u00a0Logloss and use the AUC function for the overfitting detector. To do so, use the [evaluation metric](https://catboost.ai/docs/en/references/training-parameters/common#eval_metric) parameter.\n\nParameters\n\n**Command-line version parameters:** `-i`, `--iterations`\n\n**Python parameters:** `--iterations`\n\n**R parameters:** `--iterations`\n\n#### Description\n\nThe maximum number of trees that can be built when solving machine learning problems.\n\nWhen using other parameters that limit the number of iterations, the final number of trees may be less than the number specified in this parameter.\n\n**Command-line version parameters:** `--use-best-model`\n\n**Python parameters:** `--use-best-model`\n\n**R parameters:** `--use-best-model`\n\n#### Description\n\nIf this parameter is set, the number of trees that are saved in the resulting model is defined as follows:\n\n1. Build the number of trees defined by the training parameters.\n2. Use the validation dataset to identify the iteration with the optimal value of the metric specified in \u00a0`--eval-metric` ( `--eval-metric`).\n\nNo trees are saved after this iteration.\n\nThis option requires a validation dataset to be provided.\n\n**Command-line version parameters:** `--eval-metric`\n\n**Python parameters:** `--eval-metric`\n\n**R parameters:** `--eval-metric`\n\n#### Description\n\nThe metric used for overfitting detection (if enabled) and best model selection (if enabled). Some metrics support optional parameters (see the\u00a0[Objectives and metrics](https://catboost.ai/docs/en/concepts/loss-functions) section for details on each metric).\n\nFormat:\n\n```\n<Metric>[:<parameter 1>=<value>;..;<parameter N>=<value>]\n\n```\n\n[Supported metrics](https://catboost.ai/docs/en/references/eval-metric__supported-metrics)\n\nExamples:\n\n```\nR2\n\n```\n\n```\nQuantile:alpha=0.3\n\n```\n\n**Command-line version parameters:** **Overfitting detection settings**\n\n**Command-line version parameters:** `--od-type`\n\n**Python parameters:** `od_type`\n\n**R parameters:** `od_type`\n\n#### Description\n\nThe type of the overfitting detector to use.\n\nPossible values:\n\n- IncToDec\n- Iter\n\n**Command-line version parameters:** `--od-pval`\n\n**Python parameters:** `od_pval`\n\n**R parameters:** `od_pval`\n\n#### Description\n\nThe threshold for the\u00a0IncToDec [overfitting detector](https://catboost.ai/docs/en/concepts/overfitting-detector) type. The training is stopped when the specified value is reached. Requires that a validation dataset was input.\n\nFor best results, it is recommended to set a value in the range \\[10\u201310;10\u22122\\]\\[10^{\u201310}; 10^{-2}\\]\\[10\u201310;10\u22122\\].\n\nThe larger the value, the earlier overfitting is detected.\n\nAlert\n\nDo not use this parameter with the Iter overfitting detector type.\n\n**Command-line version parameters:** `--od-wait`\n\n**Python parameters:** `od_wait`\n\n**R parameters:** `od_wait`\n\n#### Description\n\nThe number of iterations to continue the training after the iteration with the optimal metric value.\nThe purpose of this parameter differs depending on the selected overfitting detector type:\n\n- IncToDec\u00a0\u2014 Ignore the overfitting detector when the threshold is reached and continue learning for the specified number of iterations after the iteration with the optimal metric value.\n- Iter\u00a0\u2014 Consider the model overfitted and stop training after the specified number of iterations since the iteration with the optimal metric value.\n\n## Learning rate\n\nThis setting is used for reducing the gradient step. It affects the overall time of training: the smaller the value, the more iterations are required for training. Choose the value based on the performance expectations.\n\nBy default, the learning rate is defined automatically based on the dataset properties and the number of iterations. The automatically defined value should be close to the optimal one.\n\nPossible ways of adjusting the learning rate depending on the overfitting results:\n\n- There is no overfitting on the last iterations of training (the training does not converge)\u00a0\u2014 increase the learning rate.\n- Overfitting...",
      "url": "https://catboost.ai/docs/concepts/parameter-tuning"
    }
  ]
}