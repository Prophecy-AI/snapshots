{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47b7ed4",
   "metadata": {},
   "source": [
    "# Evolver Loop 73 Analysis\n",
    "\n",
    "Goal: diagnose AD distance/shrinkage design by measuring how well distance-to-training correlates with fold error, and compare distance featurizations (single + full). Use latest `submission.csv` (exp_073) predictions for per-row error analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH=Path('/home/data')\n",
    "SUB_PATH=Path('/home/submission/submission.csv')\n",
    "\n",
    "single_df=pd.read_csv(DATA_PATH/'catechol_single_solvent_yields.csv')\n",
    "full_df=pd.read_csv(DATA_PATH/'catechol_full_data_yields.csv')\n",
    "sub=pd.read_csv(SUB_PATH)\n",
    "\n",
    "print('single',single_df.shape,'full',full_df.shape,'sub',sub.shape)\n",
    "print(sub.task.value_counts())\n",
    "\n",
    "TARGETS=['Product 2','Product 3','SM']\n",
    "print('single sum(y) stats', (single_df[TARGETS].sum(1)).describe())\n",
    "print('full sum(y) stats', (full_df[TARGETS].sum(1)).describe())\n",
    "\n",
    "# load solvent tables used in experiments (lookup tables)\n",
    "spange=pd.read_csv(DATA_PATH/'spange_descriptors_lookup.csv',index_col=0)\n",
    "drfp=pd.read_csv(DATA_PATH/'drfps_catechol_lookup.csv',index_col=0)\n",
    "acs=pd.read_csv(DATA_PATH/'acs_pca_descriptors_lookup.csv',index_col=0)\n",
    "\n",
    "# Filter nonzero variance DRFP (as exp_073)\n",
    "var=drfp.var(0)\n",
    "drfp_nz=drfp.loc[:, var>0]\n",
    "\n",
    "print('spange',spange.shape,'drfp_nz',drfp_nz.shape,'acs',acs.shape)\n",
    "\n",
    "def solvent_embed(names):\n",
    "    return np.hstack([spange.loc[names].values, drfp_nz.loc[names].values, acs.loc[names].values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49264fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template split generators replicated\n",
    "\n",
    "def generate_leave_one_out_splits(X,Y):\n",
    "    all_solvents = X['SOLVENT NAME'].unique()\n",
    "    for solvent_name in sorted(all_solvents):\n",
    "        m = X['SOLVENT NAME'] != solvent_name\n",
    "        yield ( (X[m], Y[m]), (X[~m], Y[~m]) )\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X,Y):\n",
    "    all_pairs = X[['SOLVENT A NAME','SOLVENT B NAME']].drop_duplicates().sort_values(by=['SOLVENT A NAME','SOLVENT B NAME'])\n",
    "    for _,pair in all_pairs.iterrows():\n",
    "        m = (X[['SOLVENT A NAME','SOLVENT B NAME']] != pair).any(axis=1)\n",
    "        yield ( (X[m], Y[m]), (X[~m], Y[~m]) )\n",
    "\n",
    "print('single folds', sum(1 for _ in generate_leave_one_out_splits(single_df[['Residence Time','Temperature','SOLVENT NAME']], single_df[TARGETS])))\n",
    "print('full folds', sum(1 for _ in generate_leave_one_ramp_out_splits(full_df[['Residence Time','Temperature','SOLVENT A NAME','SOLVENT B NAME','SolventB%']], full_df[TARGETS])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec08667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template split generators replicated\n",
    "\n",
    "def generate_leave_one_out_splits(X,Y):\n",
    "    all_solvents = X['SOLVENT NAME'].unique()\n",
    "    for solvent_name in sorted(all_solvents):\n",
    "        m = X['SOLVENT NAME'] != solvent_name\n",
    "        yield ( (X[m], Y[m]), (X[~m], Y[~m]) )\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X,Y):\n",
    "    all_pairs = X[['SOLVENT A NAME','SOLVENT B NAME']].drop_duplicates().sort_values(by=['SOLVENT A NAME','SOLVENT B NAME'])\n",
    "    for _,pair in all_pairs.iterrows():\n",
    "        m = (X[['SOLVENT A NAME','SOLVENT B NAME']] != pair).any(axis=1)\n",
    "        yield ( (X[m], Y[m]), (X[~m], Y[~m]) )\n",
    "\n",
    "print('single folds', sum(1 for _ in generate_leave_one_out_splits(single_df[['Residence Time','Temperature','SOLVENT NAME']], single_df[TARGETS])))\n",
    "print('full folds', sum(1 for _ in generate_leave_one_ramp_out_splits(full_df[['Residence Time','Temperature','SOLVENT A NAME','SOLVENT B NAME','SolventB%']], full_df[TARGETS])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def dist_single(X):\n",
    "    return solvent_embed(X['SOLVENT NAME'])\n",
    "\n",
    "def dist_full_blend(X):\n",
    "    A=solvent_embed(X['SOLVENT A NAME'])\n",
    "    B=solvent_embed(X['SOLVENT B NAME'])\n",
    "    pct=X['SolventB%'].values.reshape(-1,1)\n",
    "    blend=(1-pct)*A + pct*B\n",
    "    return np.hstack([blend,pct])\n",
    "\n",
    "def dist_full_symm(X):\n",
    "    # canonical order by solvent name to enforce symmetry\n",
    "    Aname=X['SOLVENT A NAME'].astype(str).values\n",
    "    Bname=X['SOLVENT B NAME'].astype(str).values\n",
    "    swap = Aname > Bname\n",
    "    Aname2=Aname.copy(); Bname2=Bname.copy();\n",
    "    Aname2[swap]=Bname[swap]; Bname2[swap]=Aname[swap]\n",
    "    pct=X['SolventB%'].values.reshape(-1,1).astype(float)\n",
    "    pct2=pct.copy(); pct2[swap]=1.0-pct2[swap]\n",
    "\n",
    "    A=solvent_embed(Aname2)\n",
    "    B=solvent_embed(Bname2)\n",
    "    # symmetric features (a, b, |a-b|, a*b) + composition scalars\n",
    "    return np.hstack([\n",
    "        A, B,\n",
    "        np.abs(A-B), A*B,\n",
    "        pct2, pct2*(1-pct2)\n",
    "    ])\n",
    "\n",
    "print('dist dims single',dist_single(single_df.head(2)).shape)\n",
    "print('dist dims full blend',dist_full_blend(full_df.head(2)).shape)\n",
    "print('dist dims full symm',dist_full_symm(full_df.head(2)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8603ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-fold distance + per-fold squared error using current submission preds\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def fold_error_distance_single():\n",
    "    X=single_df[['Residence Time','Temperature','SOLVENT NAME']]\n",
    "    Y=single_df[TARGETS]\n",
    "    sub_s=sub[sub.task==0]\n",
    "    rows=[]\n",
    "    for fold_idx, ((Xtr,Ytr),(Xte,Yte)) in enumerate(generate_leave_one_out_splits(X,Y)):\n",
    "        pred=sub_s[sub_s.fold==fold_idx][['target_1','target_2','target_3']].values\n",
    "        true=Yte.values\n",
    "        se=((true-pred)**2).mean(axis=1)  # per row mean over targets\n",
    "        # distance to training in descriptor space\n",
    "        Dtr=dist_single(Xtr)\n",
    "        Dte=dist_single(Xte)\n",
    "        sc=StandardScaler().fit(Dtr)\n",
    "        nn=NearestNeighbors(n_neighbors=min(10,len(Dtr))).fit(sc.transform(Dtr))\n",
    "        d=nn.kneighbors(sc.transform(Dte), return_distance=True)[0].mean(axis=1)\n",
    "        for i in range(len(Xte)):\n",
    "            rows.append((fold_idx, Xte.iloc[i]['SOLVENT NAME'], float(d[i]), float(se[i])))\n",
    "    out=pd.DataFrame(rows, columns=['fold','solvent','dist','se'])\n",
    "    return out\n",
    "\n",
    "single_stats=fold_error_distance_single()\n",
    "print(single_stats.describe())\n",
    "print('spearman dist vs se', spearmanr(single_stats['dist'], single_stats['se']))\n",
    "\n",
    "# contribution of top distances\n",
    "q=np.quantile(single_stats['dist'], [0.5,0.7,0.8,0.9,0.95])\n",
    "print('dist quantiles',q)\n",
    "for thr in [0.7,0.8,0.9]:\n",
    "    t=np.quantile(single_stats['dist'], thr)\n",
    "    m=single_stats['dist']>=t\n",
    "    print('top',thr,'fraction',m.mean(),'MSE share', single_stats.loc[m,'se'].sum()/single_stats['se'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8087fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_error_distance_full(dist_fn):\n",
    "    X=full_df[['Residence Time','Temperature','SOLVENT A NAME','SOLVENT B NAME','SolventB%']]\n",
    "    Y=full_df[TARGETS]\n",
    "    sub_f=sub[sub.task==1]\n",
    "    rows=[]\n",
    "    for fold_idx, ((Xtr,Ytr),(Xte,Yte)) in enumerate(generate_leave_one_ramp_out_splits(X,Y)):\n",
    "        pred=sub_f[sub_f.fold==fold_idx][['target_1','target_2','target_3']].values\n",
    "        true=Yte.values\n",
    "        se=((true-pred)**2).mean(axis=1)\n",
    "        Dtr=dist_fn(Xtr)\n",
    "        Dte=dist_fn(Xte)\n",
    "        sc=StandardScaler().fit(Dtr)\n",
    "        nn=NearestNeighbors(n_neighbors=min(10,len(Dtr))).fit(sc.transform(Dtr))\n",
    "        d=nn.kneighbors(sc.transform(Dte), return_distance=True)[0].mean(axis=1)\n",
    "        for i in range(len(Xte)):\n",
    "            rows.append((fold_idx, float(d[i]), float(se[i])))\n",
    "    out=pd.DataFrame(rows, columns=['fold','dist','se'])\n",
    "    return out\n",
    "\n",
    "full_blend=fold_error_distance_full(dist_full_blend)\n",
    "full_symm=fold_error_distance_full(dist_full_symm)\n",
    "\n",
    "print('FULL blend spearman', spearmanr(full_blend['dist'], full_blend['se']))\n",
    "print('FULL symm spearman', spearmanr(full_symm['dist'], full_symm['se']))\n",
    "\n",
    "for name,dfx in [('blend',full_blend),('symm',full_symm)]:\n",
    "    print('\\n',name, dfx['dist'].describe())\n",
    "    for thr in [0.7,0.8,0.9]:\n",
    "        t=np.quantile(dfx['dist'], thr)\n",
    "        m=dfx['dist']>=t\n",
    "        print('top',thr,'fraction',m.mean(),'MSE share', dfx.loc[m,'se'].sum()/dfx['se'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940fc92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare per-fold average error vs distance to see if some folds (solvents/ramps) are the true OODs\n",
    "\n",
    "single_fold=single_stats.groupby('fold').agg(dist_mean=('dist','mean'), se_mean=('se','mean'), n=('se','size')).reset_index()\n",
    "print('single fold-level spearman', spearmanr(single_fold['dist_mean'], single_fold['se_mean']))\n",
    "\n",
    "full_fold_blend=full_blend.groupby('fold').agg(dist_mean=('dist','mean'), se_mean=('se','mean'), n=('se','size')).reset_index()\n",
    "full_fold_symm=full_symm.groupby('fold').agg(dist_mean=('dist','mean'), se_mean=('se','mean'), n=('se','size')).reset_index()\n",
    "\n",
    "print('full fold blend spearman', spearmanr(full_fold_blend['dist_mean'], full_fold_blend['se_mean']))\n",
    "print('full fold symm spearman', spearmanr(full_fold_symm['dist_mean'], full_fold_symm['se_mean']))\n",
    "\n",
    "print('worst single folds by error')\n",
    "print(single_fold.sort_values('se_mean',ascending=False).head(5))\n",
    "print('worst full folds by error (symm dist)')\n",
    "print(full_fold_symm.sort_values('se_mean',ascending=False).head(5))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
