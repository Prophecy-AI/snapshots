{
  "query": "How can applicability domain (distance to training) calibration or conformal prediction reduce out-of-distribution error for regression models, especially for chemical/solvent property prediction?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Applicability\u2011domain (AD) methods quantify how far a new compound lies from the descriptor space that was used to train a regression model.  By converting this \u201cdistance\u2011to\u2011training\u201d into a calibration step\u2014e.g., using the distance to select or re\u2011weight a calibration set, or to inflate prediction intervals\u2014one can explicitly signal when a query is out\u2011of\u2011distribution (OOD) and therefore likely to incur larger errors.  In cheminformatics this is often done with conformal prediction (CP), a distribution\u2011free framework that builds prediction intervals whose empirical coverage matches a user\u2011specified confidence level.  Because CP bases the interval size on a non\u2011conformity score (the dissimilarity of the new instance to the training data), atypical compounds receive wider intervals, effectively down\u2011weighting their point predictions and reducing the impact of OOD errors on downstream decisions ([ScienceDirect](https://www.sciencedirect.com/science/article/pii/S2667318525000030)).  Weighted extensions of CP further allow the likelihood\u2011ratio between training and test covariate distributions to be estimated, yielding valid intervals even under covariate shift ([CMU PDF](https://stat.cmu.edu/~ryantibs/papers/weightedcp.pdf)).\n\nEmpirical studies on QSAR and toxicity datasets show that CP can diagnose data drift: when the calibration set is replaced by a more recent subset that better reflects the test distribution, the observed error rates align with the nominal confidence levels, while the original calibration set leads to under\u2011covered intervals and inflated OOD error ([J\u202fCheminform\u202f2021](https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-021-00511-5.pdf)).  Hybrid frameworks that combine distance\u2011based AD measures with Bayesian uncertainty estimates and a post\u2011hoc calibration step have been shown to improve both ranking of absolute errors and interval calibration under domain\u2011shift scenarios, especially across many bioactivity and physicochemical property datasets ([J\u202fCheminform\u202f2021](https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-021-00551-x.pdf)).  Tools such as CPSign implement these ideas for cheminformatics, providing fast CP\u2011based predictors that automatically enlarge intervals for compounds far from the training manifold, thereby reducing the risk of over\u2011confident, erroneous predictions for solvent\u2011property or other chemical regression tasks ([CPSign\u202f2024](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9)).  \n\nIn practice, applying AD\u2011aware calibration or CP to a regression model for chemical/solvent properties means: (1) compute a distance metric (e.g., Mahalanobis, kernel\u2011based) between each query and the training descriptors; (2) use this distance to select a calibration subset or to weight non\u2011conformity scores; (3) generate prediction intervals that expand with increasing distance, guaranteeing the pre\u2011specified coverage even when the query lies outside the original domain.  This systematic handling of OOD inputs leads to more reliable uncertainty estimates and prevents the model from making overly confident, inaccurate predictions on novel chemicals.",
      "url": ""
    },
    {
      "title": "Conformal prediction-based machine learning in Cheminformatics: Current applications and new challenges",
      "text": "[Skip to main content](https://www.sciencedirect.com/www.sciencedirect.com#screen-reader-main-content) [Skip to article](https://www.sciencedirect.com/www.sciencedirect.com#screen-reader-main-title)\n\n- [View\u00a0**PDF**](https://www.sciencedirect.com/science/article/pii/S2667318525000030/pdfft?md5=49858d70751330b08de4ff03ea523fbe&pid=1-s2.0-S2667318525000030-main.pdf)\n- Download full issue\n\nSearch ScienceDirect\n\n## [Artificial Intelligence in the Life Sciences](https://www.sciencedirect.com/journal/artificial-intelligence-in-the-life-sciences)\n\n[Volume 7](https://www.sciencedirect.com/journal/artificial-intelligence-in-the-life-sciences/vol/7/suppl/C), June 2025, 100127\n\n# Review  Conformal prediction-based machine learning in Cheminformatics: Current applications and new challenges\n\nAuthor links open overlay panelMarioAstigarraga1, Andr\u00e9sS\u00e1nchez-Ruiz1, GonzaloColmenarejo\n\nShow more\n\nAdd to Mendeley\n\nShare\n\nCite\n\n[https://doi.org/10.1016/j.ailsci.2025.100127](https://doi.org/10.1016/j.ailsci.2025.100127) [Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&contentID=S2667318525000030&orderBeanReset=true)\n\nUnder a Creative Commons [license](http://creativecommons.org/licenses/by-nc-nd/4.0/)\n\nOpen access\n\n## Abstract\n\nConformal Prediction (CP) is a distribution-free Machine Learning (ML) framework that has been developed in the last \u223c25 years to provide well calibrated prediction subsets/intervals that include the true label with a user pre-defined probability, only requiring data exchangeability. It is based on the concept of _nonconformity_ (or dissimilarity) of the new prediction compared to previous data and their predictions, so that the prediction subset/interval size is larger for new \u201cunusual\u201d instances and smaller for \u201ctypical\u201d instances. Given its simplicity and ease of applicability, since 2012 it has been widely adopted in Cheminformatics, especially in the Quantitative Structure-Activity Relationship (QSAR) modeling and Molecular Screening areas. This rapid popularization of CP in Cheminformatics can be explained on the grounds that: (a) it can handle the applicability domain (AD) issue of ML models, of large importance in Cheminformatics due to the immense size of the chemical space; (b) it deals with classification of heavily imbalanced datasets typical in Molecular Screening; and (c) it quantifies compound-specific prediction uncertainties, especially useful as it allows to implement gain-cost strategies to accelerate drug discovery by reducing compounds to test. This comprehensive review introduces the method, provides a full appraisal of the work done in the field of Cheminformatics (with special emphasis in the QSAR and Molecular Screening arenas), and discusses its pros and cons and new challenges, especially for Deep Learning applications and nonexchangeable datasets, a very frequent situation in Cheminformatics.\n\n- Previous article in issue\n- Next article in issue\n\n## Keywords\n\nConformal prediction\n\nCheminformatics\n\nQuantitative structure-activity relationship\n\nMolecular screening\n\nMachine learning\n\nDeep learning\n\nDrug discovery\n\nLoading...\n\nRecommended articles\n\n## Data availability\n\nNo data was used for the research described in the article.\n\n[1](https://www.sciencedirect.com/www.sciencedirect.com#bfn1)\n\nThese authors contributed equally to this work.\n\n\u00a9 2025 The Authors. Published by Elsevier B.V.",
      "url": "https://www.sciencedirect.com/science/article/pii/S2667318525000030"
    },
    {
      "title": "Assessing the calibration in toxicological in vitro models with conformal prediction",
      "text": "Morger\u00a0et\u00a0al. J Cheminform (2021) 13:35 \nhttps://doi.org/10.1186/s13321-021-00511-5\nRESEARCH ARTICLE\nAssessing the\u00a0calibration in\u00a0toxicological \nin\u00a0vitro models with\u00a0conformal prediction\nAndrea Morger1, Fredrik Svensson2, Stafan Arvidsson McShane3, Niharika Gauraha3,4, Ulf Norinder3,5,6, \nOla Spjuth3\u2020 and Andrea Volkamer1*\u2020\nAbstract\nMachine learning methods are widely used in drug discovery and toxicity prediction. While showing overall good \nperformance in cross-validation studies, their predictive power (often) drops in cases where the query samples have \ndrifted from the training data\u2019s descriptor space. Thus, the assumption for applying machine learning algorithms, that \ntraining and test data stem from the same distribution, might not always be fulflled. In this work, conformal predic\u0002tion is used to assess the calibration of the models. Deviations from the expected error may indicate that training \nand test data originate from diferent distributions. Exemplifed on the Tox21 datasets, composed of chronologically \nreleased Tox21Train, Tox21Test and Tox21Score subsets, we observed that while internally valid models could be \ntrained using cross-validation on Tox21Train, predictions on the external Tox21Score data resulted in higher error rates \nthan expected. To improve the prediction on the external sets, a strategy exchanging the calibration set with more \nrecent data, such as Tox21Test, has successfully been introduced. We conclude that conformal prediction can be used \nto diagnose data drifts and other issues related to model calibration. The proposed improvement strategy\u2014exchang\u0002ing the calibration data only\u2014is convenient as it does not require retraining of the underlying model.\nKeywords: Toxicity prediction, Conformal prediction, Data drifts, Applicability domain, Calibration plots, Tox21 \ndatasets\n\u00a9 The Author(s) 2021. This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and \nthe source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material \nin this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material \nis not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the \npermitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativeco\nmmons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/\nzero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nIntroduction\nMachine learning (ML) methods are ubiquitous in drug \ndiscovery and toxicity prediction [1, 2]. In silico toxicity \nprediction is typically used to guide toxicity testing in \nearly phases of drug design [3]. With more high-quality \nstandardised data available, the (potential) impact of ML \nmethods in regulatory toxicology is growing [4]. Te col\u0002lection of available toxicity data is increasing, thanks in \npart to high-throughput screening programs such as \nToxCast [5] and Tox21 [6, 7], but also with public-private \npartnerships such as the eTOX and eTRANSAFE pro\u0002jects, which focus on the sharing of (confdential) toxicity \ndata and ML models across companies [8, 9]. In any case, \nno matter which underlying data and ML method is used, \nit is essential to know or assess if the ML model can be \nreliably used to make predictions on a new dataset.\nHence, validation of ML models is crucial to assess \ntheir predictivity. Several groups investigated random vs. \nrational selection of optimal test/training sets, e.g. using \ncluster- or activity-based splits, with the goal of better \nrefecting the true predictive power of established models \n[10\u201314]. Martin et\u00a0al. [11] showed that rational selection \nof training and test sets\u2014compared to random splits\u2014\ngenerated better statistical results on the (internal) test \nsets. However, the performance of both types of regres\u0002sion models on the\u2014artifcially created\u2014external evalua\u0002tion set was comparable.\nTus, further metrics to defne the applicability domain \n(AD), the domain in which an ML classifer can reliably \nOpen Access\nJournal of Cheminformatics\n*Correspondence: andrea.volkamer@charite.de\n\u2020\nOla Spjuth and Andrea Volkamer\u2014Shared senior authorship\n1\n In Silico Toxicology and Structural Bioinformatics, Institute of Physiology, \nCharit\u00e9 Universit\u00e4tsmedizin, Berlin, Germany\nFull list of author information is available at the end of the article\nMorger\u00a0et\u00a0al. J Cheminform (2021) 13:35 Page 2 of 14\nbe applied [15\u201321], are needed. Besides traditional met\u0002rics accounting for chemical space coverage, Sheridan \n[20] discussed uncertainty prediction regression mod\u0002els, ftted with the activity prediction errors as labels and \ndiverse AD metrics as descriptors (e.g. accounting for \nvariation among RF tree predictions, predicted activity \nranges with diferent confdence, or similarity to nearest \nneighbours). Since in classifcation models, the response/\nactivity is a categorical value, only the chemical space \nremains to defne the AD. Mathea et\u00a0al. [15] categorised \nthe available methods into novelty and confdence esti\u0002mation\u00a0 techniques. Te former consider the ft into the \nunderlying chemical descriptor space as a whole, whereas \nthe latter focus on the reliability of predictions, i.e. data \npoints may be well embedded in the descriptor space but \nabnormal regarding their class label.\nA popular method for confdence estimation is con\u0002formal prediction (CP), which has in recent years been \nwidely applied in the drug discovery and toxicity predic\u0002tion context [15, 22]. In CP, ML models are trained, and \nwith the help of an additional calibration set (inductive \nconformal prediction [23]), the predictions are calibrated, \ni.e. ranked based on previously seen observations, result\u0002ing in so-called conformal p-values or simply p-values \n(not to be confused with statistical p-values from hypoth\u0002esis testing). Te design of the CP statistical framework \nguarantees that the error rate of the predictions will not \nexceed a user-specifed signifcance level. Te control of \nthis signifcance level makes CP advantageous compared \nto traditional confdence estimation methods, such as \ndistance from the decision boundary, or ensemble mod\u0002els [15].\nML algorithms rely on the assumption that the prob\u0002ability distribution of the training data and test data \nare I.I.D. (independent and identically distributed). For \nconformal prediction, a slightly weaker assumption in \nthe form of exchangeability is assumed for producing \nwell-calibrated models [24]. Tis assumption is never\u0002theless not always fulflled, especially when training and \ntest data come from diferent sources. For example, data \ndrifts were observed between training and test data of the \nUSPS (handwritten digits) and the Statlog Satellite (satel\u0002lite image) datasets [25]. Similar observations were made \nin the toxicity prediction context when applying andro\u0002gen receptor agonism CP models trained on publicly \navailable data to an industrial dataset [26]. Some eforts \nto look at data exchangeability include studies using mar\u0002tingales to uncover exchangeability issues in an online \nsetting [25].\nIn this work, we explored how the above described con\u0002cepts of conformal prediction can be used to assess the \nquality of the model calibration when trained and applied \non various toxicological in\u00a0vitro datasets or subsets. For \nthis purpose, the freely available Tox21 datasets [27], ini\u0002tially prepared for a data challenge to encourage model \nbuilding and benchmarking toxicity prediction, were \nused. We show that conformal predict...",
      "url": "https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-021-00511-5.pdf"
    },
    {
      "title": "CPSign: conformal prediction for cheminformatics modeling",
      "text": "Search all BMC articles\n\nSearch\n\nCPSign: conformal prediction for cheminformatics modeling\n\n[Download PDF](https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-024-00870-9.pdf)\n\n[Download ePub](https://jcheminf.biomedcentral.com/counter/epub/10.1186/s13321-024-00870-9.epub)\n\n[Download PDF](https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-024-00870-9.pdf)\n\n[Download ePub](https://jcheminf.biomedcentral.com/counter/epub/10.1186/s13321-024-00870-9.epub)\n\n- Methodology\n- [Open access](https://www.springernature.com/gp/open-research/about/the-fundamentals-of-open-access-and-open-research)\n- Published: 28 June 2024\n\n# CPSign: conformal prediction for cheminformatics modeling\n\n- [Staffan Arvidsson McShane](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#auth-Staffan-Arvidsson_McShane-Aff1) [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#Aff1),\n- [Ulf Norinder](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#auth-Ulf-Norinder-Aff1-Aff2-Aff3) [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#Aff1), [2](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#Aff2), [3](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#Aff3),\n- [Jonathan Alvarsson](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#auth-Jonathan-Alvarsson-Aff1) [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#Aff1),\n- [Ernst Ahlberg](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#auth-Ernst-Ahlberg-Aff1-Aff4) [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#Aff1), [4](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#Aff4),\n- [Lars Carlsson](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#auth-Lars-Carlsson-Aff4-Aff5) [4](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#Aff4), [5](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#Aff5) &\n- \u2026\n- [Ola Spjuth](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#auth-Ola-Spjuth-Aff1) [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#Aff1)\n\nShow authors\n\n[_Journal of Cheminformatics_](https://jcheminf.biomedcentral.com/) **volume\u00a016**, Article\u00a0number:\u00a075 (2024)\n[Cite this article](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#citeas)\n\n- 1906 Accesses\n\n- 1 Altmetric\n\n- [Metrics details](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9/metrics)\n\n\n## Abstract\n\nConformal prediction has seen many applications in pharmaceutical science, being able to calibrate outputs of machine learning models and producing valid prediction intervals. We here present the open source software CPSign that is a complete implementation of conformal prediction for cheminformatics modeling. CPSign implements inductive and transductive conformal prediction for classification and regression, and probabilistic prediction with the Venn-ABERS methodology. The main chemical representation is signatures but other types of descriptors are also supported. The main modeling methodology is support vector machines (SVMs), but additional modeling methods are supported via an extension mechanism, e.g. DeepLearning4J models. We also describe features for visualizing results from conformal models including calibration and efficiency plots, as well as features to publish predictive models as REST services. We compare CPSign against other common cheminformatics modeling approaches including random forest, and a directed message-passing neural network. The results show that CPSign produces robust predictive performance with comparative predictive efficiency, with superior runtime and lower hardware requirements compared to neural network based models. CPSign has been used in several studies and is in production-use in multiple organizations. The ability to work directly with chemical input files, perform descriptor calculation and modeling with SVM in the conformal prediction framework, with a single software package having a low footprint and fast execution time makes CPSign a convenient and yet flexible package for training, deploying, and predicting on chemical data. CPSign can be downloaded from GitHub at [https://github.com/arosbio/cpsign](https://github.com/arosbio/cpsign).\n\n**Scientific contribution**\n\nCPSign provides a single software that allows users to perform data preprocessing, modeling and make predictions directly on chemical structures, using conformal and probabilistic prediction. Building and evaluating new models can be achieved at a high abstraction level, without sacrificing flexibility and predictive performance\u2014showcased with a method evaluation against contemporary modeling approaches, where CPSign performs on par with a state-of-the-art deep learning based model.\n\n## Introduction\n\nLigand-based modeling and quantitative structure-activity relationships (QSAR) are computational methods used in drug discovery to predict properties of small molecules, such as binding affinity or activity towards a protein target, and toxicity \\[ [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#ref-CR1), [2](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#ref-CR2), [3](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#ref-CR3)\\]. The approach relies on the structure and properties of known chemical structures, and commonly takes advantage of machine learning to construct predictive models. Over the years the available data in public repositories related to cheminformatics have increased, and the applications and accuracy of predictive models have expanded and improved. This has lead to an increased utilization of ligand-based modeling in drug discovery projects \\[ [4](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#ref-CR4)\\].\n\nThe predictive performance of machine learning models is commonly measured on an external test set or using cross-validation, with accuracy, AUC, F1 scores (classification), and RMSE and \\\\(\\\\mathrm {R^2}\\\\) (regression) as commonly used metrics. However this does not relay the level of confidence for individual objects predicted. When predicting two different objects, it would seem natural that the object that is most dissimilar compared to the training data would result in a larger prediction interval to reflect greater uncertainty, and vice versa. In drug discovery, where predicted objects in many cases are novel chemical structures, this is particularly important, and concepts and approaches to determine a model\u2019s applicability domain have been proposed to this end \\[ [5](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#ref-CR5)\\]. However in most cases these are ad hoc methods without a proven theoretical underpinning.\n\nConformal prediction is a framework that provides a way to generate valid prediction intervals for a wide range of machine learning algorithms \\[ [6](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#ref-CR6)\\]. Unlike traditional prediction intervals, which applies the same certainty regardless on the predicted object, conformal prediction constructs prediction intervals that are both guaranteed to be valid and based on the estimated difficulty of the predicted objects. This makes conformal prediction a powerful tool for machine learning in settings where the underlying distribution of data is unknown, and a way to address the applicability domain assessment for compounds \\[ [7](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#ref-CR7), [8](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#ref-CR8)\\].\n\nConformal prediction has been extensively used in drug discovery \\[ [9](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9#ref-CR...",
      "url": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00870-9"
    },
    {
      "title": "A hybrid framework for improving uncertainty quantification in deep learning-based QSAR regression modeling",
      "text": "Wang\u00a0et\u00a0al. J Cheminform (2021) 13:69 \nhttps://doi.org/10.1186/s13321-021-00551-x\nRESEARCH ARTICLE\nA hybrid framework for\u00a0improving \nuncertainty quantifcation in\u00a0deep \nlearning-based QSAR regression modeling\nDingyan Wang1,2,3\u2020, Jie Yu2,3\u2020, Lifan Chen2,3, Xutong Li2,3, Hualiang Jiang2,3, Kaixian Chen2,3, \nMingyue Zheng2,3* and Xiaomin Luo1,2,3*\nAbstract\nReliable uncertainty quantifcation for statistical models is crucial in various downstream applications, especially \nfor drug design and discovery where mistakes may incur a large amount of cost. This topic has therefore absorbed \nmuch attention and a plethora of methods have been proposed over the past years. The approaches that have been \nreported so far can be mainly categorized into two classes: distance-based approaches and Bayesian approaches. \nAlthough these methods have been widely used in many scenarios and shown promising performance with their \ndistinct superiorities, being overconfdent on out-of-distribution examples still poses challenges for the deployment \nof these techniques in real-world applications. In this study we investigated a number of consensus strategies in \norder to combine both distance-based and Bayesian approaches together with post-hoc calibration for improved \nuncertainty quantifcation in QSAR (Quantitative Structure\u2013Activity Relationship) regression modeling. We employed \na set of criteria to quantitatively assess the ranking and calibration ability of these models. Experiments based on 24 \nbioactivity datasets were designed to make critical comparison between the model we proposed and other well\u0002studied baseline models. Our fndings indicate that the hybrid framework proposed by us can robustly enhance the \nmodel ability of ranking absolute errors. Together with post-hoc calibration on the validation set, we show that well\u0002calibrated uncertainty quantifcation results can be obtained in domain shift settings. The complementarity between \ndiferent methods is also conceptually analyzed.\nKeywords: Uncertainty quantifcation, Quantitative structure\u2013activity relationship, Bayesian neural network, \nApplicability domain, Bayesian inference, Error prediction, Artifcial intelligence\n\u00a9 The Author(s) 2021. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or \nother third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory \nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \nlicence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativeco\nmmons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nIntroduction\nWith the increasing scale of available datasets, deep \nlearning methods have made tremendous impact in the \nchemical domain [1]. However, most works in this area \nhave focused on improving model accuracy, less atten\u0002tion has been paid for quantifying the uncertainty of \npredictions given by the model. Uncertainty quantifca\u0002tion refers to estimating the confdence level of a model \noutput. Reliable estimation of this certainty is often cru\u0002cial for high-stacks problems, especially drug design and \ndiscovery [2\u20134]. For example, in the scenario of virtual \nscreening, molecules with high predictive activity are \nchosen for further experimental verifcation. Trough \nthis process it is always expected that the molecules with \nunreliable predictions can be excluded in order to avoid \nwasting time and money [5]. However, a deterministic \nOpen Access\nJournal of Cheminformatics\n*Correspondence: myzheng@simm.ac.cn; xmluo@simm.ac.cn\n\u2020\nDingyan Wang and Jie Yu contributed equally to this work\n1\n Shanghai Key Laboratory of Forensic Medicine, Academy of Forensic \nScience, Shanghai 200063, China 3\n Drug Discovery and Design Center, State Key Laboratory of Drug \nResearch, Shanghai Institute of Materia Medica, Chinese Academy \nof Sciences, 555 Zuchongzhi Road, Shanghai 201203, China\nFull list of author information is available at the end of the article\nWang\u00a0et\u00a0al. J Cheminform (2021) 13:69 Page 2 of 17\nmodel cannot give such information. Tis example shows \nthat numerical results without a measure of veracity do \nnot contain enough information for decision making [6].\nGiven the importance of uncertainty quantifcation, \na plethora of methods have been proposed so far and \nemployed in various cheminformatics tasks such as \nmolecular property prediction [7], chemical reaction pre\u0002diction [8], material property prediction [9], NMR spec\u0002tral property prediction [10] and interatomic potential \nprediction [11]. Broadly speaking, current mainstream \nuncertainty quantifcation methods used in the chemi\u0002cal domain can be divided into two categories: distance\u0002based approaches and Bayesian approaches.\nTe core of distance-based approaches is the tradi\u0002tional concept of applicability domain (AD). AD esti\u0002mates the chemical space in which the model could give \nreliable predictions. It is generally accepted that if a test \nsample is too remote from the training set, its prediction \nis likely to be unreliable. While the common goal is the \nsame, the representation of the distance between a mol\u0002ecule and the model training set is varied across difer\u0002ent distance-based methods. Many classical methods use \nfeature space distance defned by molecular fngerprints \n[12\u201317], while some recent studies have shown that the \ndistance in latent space may yield superior performance \n[18, 19].\nBayesian approaches encompass a diverse group \nof strategies with strong theoretical guarantee which \nenjoyed a recent reconstruction as a result of the \nimprovement of computing power [20\u201322]. Te under\u0002lying assumption behind the Bayesian approach is that \nthe model weights and predictions are no longer def\u0002nite point estimates but probability distributions which \nallows uncertainties of predictions to be taken into the \nmodel naturally [23]. By ftting a defned model to the \nobserved data (training set), the posterior distribution of \nmodel weights can be theoretically obtained and used to \nmake inference. Te total uncertainty of a prediction is \nthen quantifed as its posterior variance. Interestingly, in \nBayesian modelling, the total uncertainty can be decom\u0002posed into two components: aleatoric uncertainty which \ncaptures the noise of labels and epistemic uncertainty \nwhich results from the lack of training data [7, 24]. Many \nresearches have made use of this desired property to \nidentify the main source of uncertainty for their specifc \ntasks [9, 25].\nDespite the progress mentioned above, the reliability \nand applicable conditions of both distance-based and \nBayesian methods are still limited by some challenges. \nOn the one hand, the measure of chemical space distance \nis ambiguous and the threshold for classifying reliable \npredictions is hard to defne. Also, the distance-to-model \nmetric lacks the information of stochasticity arising from \nthe data. On the other hand, although the computational \nintractability of Bayesian methods has been eased by \nseveral approximating ways [26], Bayesian approaches \nare reported to tend to make overconfdent predictions \nfor out-of-domain examples [27, 28]. In this context, \nwe make the assumption that combining both distance\u0002based and Bayesian methods represents a feasible strat\u0002egy which can minimize the intrinsic drawbacks of these \nmethod...",
      "url": "https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-021-00551-x.pdf"
    },
    {
      "title": "",
      "text": "Conformal Prediction Under Covariate Shift\nRyan J. Tibshirani\nDepartment of Statistics\nMachine Learning Department\nCarnegie Mellon University\nPittsburgh PA, 15213\nryantibs@cmu.edu\nRina Foygel Barber\nDepartment of Statistics\nUniversity of Chicago\nChicago, IL 60637\nrina@uchicago.edu\nEmmanuel J. Cand\u00e8s\nDepartment of Statistics\nDepartment of Mathematics\nStanford University\nStanford CA, 94305\ncandes@stanford.edu\nAaditya Ramdas\nDepartment of Statistics\nMachine Learning Department\nCarnegie Mellon University\nPittsburgh PA, 15213\naramdas@cmu.edu\nAbstract\nWe extend conformal prediction methodology beyond the case of exchangeable\ndata. In particular, we show that a weighted version of conformal prediction can be\nused to compute distribution-free prediction intervals for problems in which the\ntest and training covariate distributions differ, but the likelihood ratio between the\ntwo distributions is known\u2014or, in practice, can be estimated accurately from a\nset of unlabeled data (test covariate points). Our weighted extension of conformal\nprediction also applies more broadly, to settings in which the data satisfies a certain\nweighted notion of exchangeability. We discuss other potential applications of our\nnew conformal methodology, including latent variable and missing data problems.\n1 Introduction\nLet (Xi, Yi) \u2208 R\nd \u00d7R, i = 1, . . . , n denote training data, assumed to be i.i.d. from an arbitrary distri\u0002bution P. Given a desired coverage rate 1 \u2212 \u03b1 \u2208 (0, 1), consider the problem of constructing a band\nCbn : R\nd \u2192 {subsets of R}, based on the training data such that, for a new i.i.d. point (Xn+1, Yn+1),\nP\nn\nYn+1 \u2208 Cbn(Xn+1)\no\n\u2265 1 \u2212 \u03b1, (1)\nwhere this probability is taken over the n + 1 points (Xi, Yi), i = 1, . . . , n + 1 (the n training points\nand the test point). Crucially, we will require (1) to hold with no assumptions whatsoever on the\nunderlying distribution P.\nConformal prediction, a framework pioneered by Vladimir Vovk and colleagues in the 1990s, provides\na means for achieving this goal, relying only on exchangeablility of the training and test data. The\ndefinitive reference is the book by Vovk et al. [2005]; see also Shafer and Vovk [2008], Vovk et al.\n[2009], Vovk [2013], Burnaev and Vovk [2014], and http://www.alrw.net for an often-updated list\nof conformal prediction work by Vovk and colleagues. Moreover, see Lei and Wasserman [2014], Lei\net al. [2018] for recent developments in the areas of nonparametric and high-dimensional regression.\nIn this work, we extend conformal prediction beyond the setting of exchangeable data, allowing for\nprovably valid inference even when the training and test data are not drawn from the same distribution.\nWe begin by reviewing the basics of conformal prediction, in this section. In Section 2, we describe\n33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.\nan extension of conformal prediction to the setting of covariate shift, and give supporting empirical\nresults. In Section 3, we cover the mathematical details behind our conformal extension. We conclude\nin Section 4 with a short discussion.\n1.1 Quantile lemma\nBefore explaining the basic ideas behind conformal inference (i.e., conformal prediction, we will use\nthese two terms interchangeably), we introduce some notation. We denote by Quantile(\u03b2; F) the\nlevel \u03b2 quantile of a distribution F, i.e., for Z \u223c F,\nQuantile(\u03b2; F) = inf \bz : P{Z \u2264 z} \u2265 \u03b2\n\t\n.\nIn our use of quantiles, we will allow for distributions F on the augmented real line, R \u222a {\u221e}. For\nvalues v1, . . . , vn, we write v1:n = {v1, . . . , vn} to denote their multiset. Note that this is unordered,\nand allows for multiple instances of the same element; thus in the present case, if vi = vj for i 6= j,\nthen this value appears twice in v1:n. To denote quantiles of the empirical distribution of the values\nv1, . . . , vn, we abbreviate\nQuantile(\u03b2; v1:n) = Quantile\u0012\u03b2;\n1\nn\nXn\ni=1\n\u03b4vi\n\u0013\n,\nwhere \u03b4a denotes a point mass at a (i.e., the distribution that places all mass at the value a). The next\nresult is a simple but key component underlying conformal prediction. Its proof, as with all proofs in\nthis paper, is deferred to the supplement.\nLemma 1. If V1, . . . , Vn+1 are exchangeable random variables, then for any \u03b2 \u2208 (0, 1), we have\nP\nn\nVn+1 \u2264 Quantile\u03b2; V1:n \u222a {\u221e}\u0001o\u2265 \u03b2.\nFurthermore, if ties between V1, . . . , Vn+1 occur with probability zero, then the above probability is\nupper bounded by \u03b2 + 1/(n + 1).\n1.2 Conformal prediction\nWe now return to the regression setting.1 Denote Zi = (Xi, Yi), i = 1, . . . , n. In what follows, we\ndescribe the construction of a prediction band satisfying (1), using conformal inference, due to Vovk\net al. [2005]. We first choose a score function S, whose arguments consist of a point (x, y), and a\nmultiset Z.\n2\nInformally, a low value of S((x, y), Z) indicates that the point (x, y) \u201cconforms\u201d to Z,\nwhereas a high value indicates that (x, y) is atypical relative to the points in Z. For example, we\nmight choose to define S by\nS\n\n(x, y), Z\u0001= |y \u2212 \u00b5b(x)|, (2)\nwhere \u00b5b : R\nd \u2192 R is a regression function, fitted by running an algorithm A on Z. Next, at a given\nx \u2208 R\nd\n, we define Cbn(x), the conformal prediction interval3, by repeating the following procedure\nfor each y \u2208 R. We calculate the nonconformity scores\nV\n(x,y)\ni = S\n\nZi, Z1:n \u222a {(x, y)}\n\u0001\n, i = 1, . . . , n, and V\n(x,y)\nn+1 = S\n\n(x, y), Z1:n \u222a {(x, y)}\n\u0001\n, (3)\nand include y in our prediction interval Cbn(x) if\nV\n(x,y)\nn+1 \u2264 Quantile\n1 \u2212 \u03b1; V\n(x,y)\n1:n \u222a {\u221e}\u0001\n,\nwhere V\n(x,y)\n1:n = {V\n(x,y)\n1\n, . . . , V (x,y)\nn }. Importantly, the symmetry in the construction of the noncon\u0002formity scores (3) guarantees exact coverage in finite samples. The next theorem summarizes this\ncoverage result. The lower bound is a standard result from the conformal literature, see Vovk et al.\n[2005]; the upper bound, as far as we know, was first pointed out by Lei et al. [2018].\n1Throughout this paper, we focus on regression, where the response Y is continuous, for simplicity. The\nsame ideas can be applied to classification, where Y is discrete.\n2We emphasize that by defining Z to be a multiset, we are treating its points as unordered. Hence, to be\nperfectly explicit, the score function S cannot accept the points in Z in any particular order, and it must take\nthem in as unordered. The same is true of the base algorithm A used to define the fitted regression function \u00b5b, in\nthe choice of absolute residual score function (2).\n3\nFor convenience, throughout, we will refer to Cbn(x) as an \u201cinterval\u201d, even though this may actually be a\nunion of multiple nonoverlapping intervals. Similarly, for simplicity, we will refer to Cbn as a \u201cband\u201d.\n2\nTheorem 1 (Vovk et al. 2005, Lei et al. 2018). Assume that (Xi\n, Yi) \u2208 R\nd \u00d7 R, i = 1, . . . , n + 1\nare exchangeable. For any score function S, and any \u03b1 \u2208 (0, 1), define the conformal band (based\non the first n samples) at x \u2208 R\nd by\nCbn(x) = ny \u2208 R : V\n(x,y)\nn+1 \u2264 Quantile\n1 \u2212 \u03b1; V\n(x,y)\n1:n \u222a {\u221e}\u0001o\n, (4)\nwhere V\n(x,y)\ni\n, i = 1, . . . , n + 1 are as defined in (3). Then Cbn satisfies\nP\nn\nYn+1 \u2208 Cbn(Xn+1)\no\n\u2265 1 \u2212 \u03b1.\nFurthermore, if ties between V\n(Xn+1,Yn+1)\n1\n, . . . , V (Xn+1,Yn+1)\nn+1 occur with probability zero, then this\nprobability is upper bounded by 1 \u2212 \u03b1 + 1/(n + 1).\nRemark 1. Theorem 1 is stated assuming exchangeable samples (Xi, Yi), i = 1, . . . , n + 1, which\nis weaker than assuming i.i.d. samples. As we will see in what follows, it is possible to relax the\nexchangeability assumption, under an appropriate modification to the conformal procedure.\nRemark 2. If we use an appropriate random tie-breaking rule (to determine the rank of Vn+1 among\nV1, . . . , Vn+1), then the upper bounds in Lemma 1 and Theorem 1 hold in general (without assuming\nthere are no ties almost surely).\nThe result in Theorem 1, albeit simple to prove, is quite remarkable. It gives a recipe for distribution\u0002free prediction intervals, having nearly exact coverage, starting from an arbitrary score function S;\ne...",
      "url": "https://stat.cmu.edu/~ryantibs/papers/weightedcp.pdf"
    },
    {
      "title": "Development and Evaluation of Conformal Prediction Methods for QSAR",
      "text": "# Quantitative Biology > Biomolecules\n\n**arXiv:2304.00970** (q-bio)\n\n\\[Submitted on 3 Apr 2023\\]\n\n# Title:Development and Evaluation of Conformal Prediction Methods for QSAR\n\nAuthors: [Yuting Xu](https://arxiv.org/search/q-bio?searchtype=author&query=Xu,+Y), [Andy Liaw](https://arxiv.org/search/q-bio?searchtype=author&query=Liaw,+A), [Robert P. Sheridan](https://arxiv.org/search/q-bio?searchtype=author&query=Sheridan,+R+P), [Vladimir Svetnik](https://arxiv.org/search/q-bio?searchtype=author&query=Svetnik,+V)\n\nView a PDF of the paper titled Development and Evaluation of Conformal Prediction Methods for QSAR, by Yuting Xu and 3 other authors\n\n[View PDF](https://arxiv.org/pdf/2304.00970)\n\n> Abstract:The quantitative structure-activity relationship (QSAR) regression model is a commonly used technique for predicting biological activities of compounds using their molecular descriptors. Predictions from QSAR models can help, for example, to optimize molecular structure; prioritize compounds for further experimental testing; and estimate their toxicity. In addition to the accurate estimation of the activity, it is highly desirable to obtain some estimate of the uncertainty associated with the prediction, e.g., calculate a prediction interval (PI) containing the true molecular activity with a pre-specified probability, say 70%, 90% or 95%. The challenge is that most machine learning (ML) algorithms that achieve superior predictive performance require some add-on methods for estimating uncertainty of their prediction. The development of these algorithms is an active area of research by statistical and ML communities but their implementation for QSAR modeling remains limited. Conformal prediction (CP) is a promising approach. It is agnostic to the prediction algorithm and can produce valid prediction intervals under some weak assumptions on the data distribution. We proposed computationally efficient CP algorithms tailored to the most advanced ML models, including Deep Neural Networks and Gradient Boosting Machines. The validity and efficiency of proposed conformal predictors are demonstrated on a diverse collection of QSAR datasets as well as simulation studies.\n\n|     |     |\n| --- | --- |\n| Subjects: | Biomolecules (q-bio.BM); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM) |\n| Cite as: | [arXiv:2304.00970](https://arxiv.org/abs/2304.00970) \\[q-bio.BM\\] |\n|  | (or [arXiv:2304.00970v1](https://arxiv.org/abs/2304.00970v1) \\[q-bio.BM\\] for this version) |\n|  | [https://doi.org/10.48550/arXiv.2304.00970](https://doi.org/10.48550/arXiv.2304.00970)<br>Focus to learn more<br>arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Andy Liaw \\[ [view email](https://arxiv.org/show-email/08a82453/2304.00970)\\]\n\n**\\[v1\\]**\nMon, 3 Apr 2023 13:41:09 UTC (3,119 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Development and Evaluation of Conformal Prediction Methods for QSAR, by Yuting Xu and 3 other authors\n\n- [View PDF](https://arxiv.org/pdf/2304.00970)\n- [TeX Source](https://arxiv.org/src/2304.00970)\n- [Other Formats](https://arxiv.org/format/2304.00970)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\nq-bio.BM\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2304.00970&function=prev&context=q-bio.BM)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2304.00970&function=next&context=q-bio.BM)\n\n[new](https://arxiv.org/list/q-bio.BM/new) \\| [recent](https://arxiv.org/list/q-bio.BM/recent) \\| [2023-04](https://arxiv.org/list/q-bio.BM/2023-04)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2304.00970?context=cs)\n\n[cs.LG](https://arxiv.org/abs/2304.00970?context=cs.LG)\n\n[q-bio](https://arxiv.org/abs/2304.00970?context=q-bio)\n\n[q-bio.QM](https://arxiv.org/abs/2304.00970?context=q-bio.QM)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2304.00970)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2304.00970)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2304.00970)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2304.00970&description=Development and Evaluation of Conformal Prediction Methods for QSAR) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2304.00970&title=Development and Evaluation of Conformal Prediction Methods for QSAR)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2304.00970) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2304.00970"
    },
    {
      "title": "A confidence predictor for logD using conformal regression and a support-vector machine",
      "text": "Search all BMC articles\n\nSearch\n\nA confidence predictor for logD using conformal regression and a support-vector machine\n\n[Download PDF](https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-018-0271-1.pdf)\n\n[Download ePub](https://jcheminf.biomedcentral.com/counter/epub/10.1186/s13321-018-0271-1.epub)\n\n[Download PDF](https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-018-0271-1.pdf)\n\n[Download ePub](https://jcheminf.biomedcentral.com/counter/epub/10.1186/s13321-018-0271-1.epub)\n\n- Research article\n- [Open access](https://www.springernature.com/gp/open-research/about/the-fundamentals-of-open-access-and-open-research)\n- Published: 03 April 2018\n\n# A confidence predictor for logD using conformal regression and a support-vector machine\n\n- [Maris Lapins](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#auth-Maris-Lapins-Aff1) [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#Aff1),\n- [Staffan Arvidsson](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#auth-Staffan-Arvidsson-Aff1) [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#Aff1),\n- [Samuel Lampa](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#auth-Samuel-Lampa-Aff1) [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#Aff1),\n- [Arvid Berg](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#auth-Arvid-Berg-Aff1) [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#Aff1),\n- [Wesley Schaal](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#auth-Wesley-Schaal-Aff1) [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#Aff1),\n- [Jonathan Alvarsson](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#auth-Jonathan-Alvarsson-Aff1) [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#Aff1) &\n- \u2026\n- [Ola Spjuth](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#auth-Ola-Spjuth-Aff1) [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#Aff1)\n\nShow authors\n\n[_Journal of Cheminformatics_](https://jcheminf.biomedcentral.com/) **volume\u00a010**, Article\u00a0number:\u00a017 (2018)\n[Cite this article](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#citeas)\n\n- 8148 Accesses\n\n- 35 Citations\n\n- 17 Altmetric\n\n- [Metrics details](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1/metrics)\n\n\n## Abstract\n\nLipophilicity is a major determinant of ADMET properties and overall suitability of drug candidates. We have developed large-scale models to predict water\u2013octanol distribution coefficient (logD) for chemical compounds, aiding drug discovery projects. Using ACD/logD data for 1.6 million compounds from the ChEMBL database, models are created and evaluated by a support-vector machine with a linear kernel using conformal prediction methodology, outputting prediction intervals at a specified confidence level. The resulting model shows a predictive ability of \\\\(\\\\hbox {Q}^{2}=0.973\\\\) and with the best performing nonconformity measure having median prediction interval of \\\\(\\\\pm ~0.39\\\\) log units at 80% confidence and \\\\(\\\\pm ~0.60\\\\) log units at 90% confidence. The model is available as an online service via an OpenAPI interface, a web page with a molecular editor, and we also publish predictive values at 90% confidence level for 91\u00a0M PubChem structures in RDF format for download and as an URI resolver service.\n\n![](https://media.springernature.com/lw685/springer-static/image/art%3A10.1186%2Fs13321-018-0271-1/MediaObjects/13321_2018_271_Figa_HTML.gif)\n\n## Background\n\nLipophilicity plays a crucial role in determining the pharmacokinetic behavior of drugs. Hydrophilic compounds are typically well-soluble but are likely to exhibit problems with membrane permeability and are more susceptible to renal clearance. Highly lipophilic compounds tend to have low solubility, high plasma protein binding, and they are also more vulnerable to CYP450 metabolism. Furthermore, high lipophilicity has been shown to increase the likelihood of target promiscuity and general toxicity as well as more specific toxicology issues of hERG inhibition, phospholipidosis and CYP450 inhibition \\[ [1](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#ref-CR1), [2](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#ref-CR2), [3](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#ref-CR3)\\].\n\nFrom these considerations, it is suggested that optimal ADME properties and the lowest risk for adverse toxicity outcomes are expected if a compound\u2019s lipophilicity at \\\\(\\\\hbox {pH}=7.4\\\\) lies in a logD range between about 1 and 3 \\[ [2](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#ref-CR2)\\] or a logP between 2 and 4 \\[ [3](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#ref-CR3)\\]. Several studies indicate that these ranges might be even narrower depending on molecular weight, acid/base properties and/on the desired mode of action of the drug. For example, statistical analysis of AstraZeneca Caco-2 membrane permeability data suggests that the lower limit for passive diffusion is dependent on the molecular weight of compounds: a \\\\(\\\\hbox {logD}>1.7\\\\) being required for a 50% chance of high permeability for compounds with molecular weight above 350\u00a0Da, \\\\(\\\\hbox {logD}>3.1\\\\) for compounds with molecular weight above 400\u00a0Da, and \\\\(\\\\hbox {logD}>4.5\\\\) for compounds with MW above 500\u00a0Da \\[ [4](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#ref-CR4)\\].\n\nSimilarly, analysis of in-house data from Pfizer demonstrates that most of the compounds satisfying both cell permeability and in vitro clearance criteria fall into a logD range between 0 and 3 \\[ [5](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#ref-CR5)\\]. This study also suggests that higher molecular weight compounds are more constrained in the range of acceptable logD values; the top of optimum region (referred to as \u201cgolden triangle\u201d) peaking to logD of about 1.5 at MW of 500\u00a0Da.\n\nSeveral studies have found that logD or logP of above 3 gives rise to promiscuity and risk for adverse in vivo toxicological outcomes \\[ [4](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#ref-CR4), [6](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#ref-CR6), [7](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#ref-CR7)\\].\n\nFurthermore, toxicological liabilities such as hERG inhibition depend on the acid/base properties of a drug, the risk being particularly high for lipophilic bases. For neutral drugs a 30% risk for problematically high levels of hERG inhibition is estimated at \\\\(\\\\hbox {logD}=3.3\\\\) whereas for basic compounds such risk arises already at \\\\(\\\\hbox {logD}=1.4\\\\) \\[ [8](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#ref-CR8)\\].\n\nIn a study on CNS drug-likeness, Wager\u00a0\\[ [9](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1#ref-CR9)\\] concludes that the most desirable lipophilicity for blood\u2013brain barrier penetration is a \\\\(\\\\hbox{logD} \\\\le 2\\\\). A logD above 4 is unlikely for a CNS drug.\n\nTaken together, lipophilicity is one of the molecular properties to address in early stages of drug design, to increase chances of selection of compounds that would not fail in development because of poor ADMET characteristics.\n\nMany computational methods to predict logP have been described. Benchmarking of 18 of these methods has shown reasonable results for many of them, with the root mean square error of prediction (RMSEP) for a Pfizer in-house dataset of 96,000 compounds being 0.95 log units for consensus logP and slightly above 1 log unit for best individual algorithms \\[ [10](https://jcheminf.biomedcentral.com/articles/10.1186/s13321...",
      "url": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0271-1"
    },
    {
      "title": "Application of Conformal Prediction in QSAR",
      "text": "HAL Id: hal-01523068\nhttps://hal.science/hal-01523068v1\nSubmitted on 16 May 2017\nHAL is a multi-disciplinary open access\narchive for the deposit and dissemination of sci\u0002entific research documents, whether they are pub\u0002lished or not. The documents may come from\nteaching and research institutions in France or\nabroad, or from public or private research centers.\nL\u2019archive ouverte pluridisciplinaire HAL, est\ndestin\u00e9e au d\u00e9p\u00f4t et \u00e0 la diffusion de documents\nscientifiques de niveau recherche, publi\u00e9s ou non,\n\u00e9manant des \u00e9tablissements d\u2019enseignement et de\nrecherche fran\u00e7ais ou \u00e9trangers, des laboratoires\npublics ou priv\u00e9s.\nDistributed under a Creative Commons Attribution 4.0 International License\nApplication of Conformal Prediction in QSAR\nMartin Eklund, Ulf Norinder, Scott Boyer, Lars Carlsson\nTo cite this version:\nMartin Eklund, Ulf Norinder, Scott Boyer, Lars Carlsson. Application of Conformal Prediction in\nQSAR. 8th International Conference on Artificial Intelligence Applications and Innovations (AIAI),\nSep 2012, Halkidiki, Greece. pp.166-175, ff10.1007/978-3-642-33412-2_17ff. ffhal-01523068ff\nApplication of conformal prediction in QSAR\nMartin Eklund1,2,?, Ulf Norinder3, Scott Boyer2, and Lars Carlsson2\n1 Department of Pharmaceutical Biosciences, Uppsala University, P.O. Box 591,\nSE-751 24 Uppsala, Sweden\n2 AstraZeneca Research and Development, SE-431 83 M\u00a8olndal, Sweden\n3 AstraZeneca Research and Development, SE-151 85 S\u00a8odert\u00a8alje, Sweden\nAbstract. QSAR modeling is a method for predicting properties, e.g.\nthe solubility or toxicity, of chemical compounds using statistical learn\u0002ing techniques. QSAR is in widespread use within the pharmaceutical\nindustry to prioritize compounds for experimental testing or to alert for\npotential toxicity. However, predictions from a QSAR model are difficult\nto assess if their prediction intervals are unknown. In this paper we intro\u0002duce conformal prediction into the QSAR field to address this issue. We\napply support vector machine regression in combination with two non\u0002conformity measures to five datasets of different sizes to demonstrate the\nusefulness of conformal prediction in QSAR modeling. One of the non\u0002conformity measures provides prediction intervals with almost the same\nwidth as the size of the QSAR models\u2019 prediction errors, showing that\nthe prediction intervals obtained by conformal prediction are efficient\nand useful.\n1 Introduction\nElucidating the structural properties of chemical compounds required to elicit\na desired pharmacological effect (cure or alleviate a disease) and to concomi\u0002tantly avoid toxicity is a fundamental issue in drug development. Quantitative\nStructure-Activity Relationships (QSAR) is a framework for employing statisti\u0002cal learning methods to predict the pharmacological effect and the toxicity (as\nwell as other desirable properties) from chemical compounds\u2019 structures.\nFor making informed decisions based on predictions from a QSAR model,\nwe are interested in the confidence in the predictions. Substantial efforts have\nbeen devoted to research on this topic within the QSAR community over the\nlast decade and a number of methods have been suggested for estimating the\nconfidence of QSAR predictions (see e.g. [1\u20133] and references therein). These\nconfidence estimates are typically based on the very loosely defined concept of a\nQSAR model\u2019s \u201dapplicability domain\u201d (AD), which in [4] was described as \u201dthe\nresponse and chemical structure space in which the model makes predictions with\na given reliability\u201d. The assumption is that the further away a molecule is from a\nQSAR model\u2019s AD (according to some measure), the less reliable the prediction.\nThe problem with the current approaches to estimating the prediction confidence\n? martin.eklund@farmbio.uu.se\nin QSAR models is that their interpretation is cumbersome. For example, what\ndoes it mean that a chemical compound is outside the QSAR model\u2019s AD by\na certain amount according to a certain measure? How does the plethora of\ndifferent metrics used to define the AD relate to each other? What we ideally\nwould like to know is in fact that a prediction is within a given prediction interval\nwith a certain confidence (e.g. 80% or 95%).\nIn this paper we introduce conformal prediction [5, 6] into the QSAR field.\nConformal prediction uses previous data to determine prediction regions for new\npredictions. Given a confidence level (of say 80% or 95%), it produces a valid\nprediction region (i.e. a region that contains the true value with a probability\nequal to or higher than the given confidence level) under the assumptions that\nthe observed data is i.i.d. [5]. The conformal prediction framework provides a\nunified view of the different approaches to estimating a QSAR model\u2019s AD.\nMoreover, conformal prediction gives a natural and intuitive way of interpreting\nthe AD estimates as prediction intervals with a given confidence.\nThe paper is organized as follows: We give a short introduction to QSAR\nmodeling and AD estimation in Section 2. Continuing with Section 3 that con\u0002tains a description of the methods (learner, nonconformity measure) used in the\npaper and how we apply them to QSAR modeling. The results are presented in\nSection 4 and a discussion of the results in Section 5.\n2 QSAR\nA molecule can be represented by an undirected labeled graph G = (V, E, A)\n(possibly embedded in IR3if the three dimensional structure of the molecule is\ntaken into account), where the vertices V are the atoms and the edges E are the\nbonds. The atoms of a molecular graph are labeled by A, a set of atom types,\nwhich for instance can be the set of elements of the periodic table, the set of\nphysicochemical properties of atoms, or any set of atom types provided by a\nmolecular force field (see e.g. [7]).\nA descriptor function may be defined as a random variable\nd : G \u2192 IRp. (1)\nA realization xi of d applied to a molecular structure Giis called the descriptor\nvector (or simply descriptor ) of Gi (NB: we will in this paper use \u201ddescriptor\u201d\nand \u201dattribute\u201d interchangeably to refer to an element in xi). Given a training\nset (x1, y1), ...,(xn, yn), where each yi, i = 1, ..., n, is the known activity of the\nmolecule with descriptor vector xi, we can apply statistical learning methods to\nestimate a QSAR. A QSAR model fitted to (x1, y1), ...,(xn, yn) permits us to\npredict the activity of new (possibly not yet synthesized) chemical compounds.\n2.1 Applicability domain\nIt is difficult for researchers to use the predictions from a QSAR model if there is\nno information available on whether the predictions are reliable or not. A large\nnumber of approaches have been suggested in the QSAR literature to assess\nwhether a give prediction is reliable, typically by defining a QSAR\u2019s applicability\ndomain. For example:\n\u2013 Let \u02c6\u00b5 and S\u02c6 be the respective estimates of the mean vector and the covariance\nmatrix of the distribution P from which x1, ..., xn were sampled. A prediction\nof a new compound with descriptor vector xnew is regarded less reliable the\nlarger the distance D(xnew) = q(xnew \u2212 \u00b5\u02c6)\nT S\u02c6\u22121(xnew \u2212 \u00b5\u02c6) and may be\ndefined as \u201dunreliable\u201d if D(xnew) exceeds some predefined limit c. The\nhypersphere D(x) \u2264 c is thus the AD.\n\u2013 Estimate the density of P. This is often done by assuming independence\nbetween descriptors, or by projecting (x1, y1), ...,(xn, yn) to a lower dimen\u0002sional space using e.g. principal component analysis (PCA). The density\nvalue at xnew is determined and the lower this value is, the less reliable the\nprediction is. If it is lower than a predefined limit, the prediction may be\ndeemed \u201dunreliable\u201d.\n\u2013 A large number of methods are based on resampling (e.g. bootstrapping)\nfrom (x1, y1), ...,(xn, yn) to estimate the variability of the prediction of a\nnew compound xnew (see e.g. [8] for a survey of eight different resampling\nbased methods). The AD is then implicitly defined as the region in descriptor\nspace where the variability of predictions is lower than a given cutoff value.\nA reader fami...",
      "url": "https://hal.science/hal-01523068v1/document"
    }
  ]
}