# Catechol Reaction Yield Prediction - Evolved Seed Prompt (Loop 3)

## Current Status
- Best CV score: 0.08053 from exp_002 (003_simple_rf_regularized)
- Best LB score: Not yet submitted (0/5 submissions used)
- Target: 0.01727 (4.7x gap)

## Response to Evaluator
- Technical verdict was TRUSTWORTHY. Template compliance is now correct.
- Evaluator's top priority: Try per-target heterogeneous ensemble approach from dabansherwani kernel.
- Key concerns raised: 
  1. Stagnating performance (~0.080-0.081 across 3 experiments)
  2. Single feature set limitation (only Spange used)
  3. Same model for all targets
- **My response**: AGREE with all concerns. My analysis in `exploration/evolver_loop3_analysis.ipynb` confirms:
  - Per-target heterogeneous + combined features achieves **0.0662 MAE** on single solvent (vs 0.0748 current)
  - This is a **12% improvement** - significant and worth implementing
  - Best weight: 0.8 acs_pca + 0.2 spange

## Data Understanding
Reference notebooks:
- `exploration/eda.ipynb` - Basic data characteristics
- `exploration/evolver_loop1_analysis.ipynb` - Target correlations, solvent analysis
- `exploration/evolver_loop2_analysis.ipynb` - Model comparison, feature analysis
- `exploration/evolver_loop3_analysis.ipynb` - Per-target heterogeneous model testing

Key patterns to exploit:
1. **Per-target model differentiation**: SM behaves differently from Products (negative correlation -0.89)
   - SM → HistGradientBoostingRegressor (max_depth=7, max_iter=700, lr=0.04)
   - Products → ExtraTreesRegressor (n_estimators=500, min_samples_leaf=2, max_depth=10)

2. **Feature combination**: Combining acs_pca + spange with weighted averaging improves performance
   - Best weight: 0.8 acs_pca + 0.2 spange
   - This captures different aspects of solvent chemistry

3. **TTA for mixed solvents**: Chemical symmetry (A+B = B+A) should be exploited

## Recommended Approaches (Priority Order)

### 1. Per-Target Heterogeneous Model with Combined Features (HIGH PRIORITY - IMPLEMENT THIS)
**Expected improvement: 0.0805 → ~0.075 (7% improvement)**

This approach was validated in `exploration/evolver_loop3_analysis.ipynb`:
- Single solvent MAE: 0.0662 (vs current 0.0748)
- Uses different models for different targets
- Combines acs_pca + spange features with 0.8/0.2 weighting

Key implementation details:
```python
class PerTargetHeterogeneousModel(BaseModel):
    def __init__(self, data='single'):
        self.data_type = data
        self.targets = ['Product 2', 'Product 3', 'SM']
        self.models = {}
        self.scalers = {}
        
        # Load both feature sets
        self.spange = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)
        self.acs_pca = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)
        
        # Different models for different targets
        for t in self.targets:
            if t == 'SM':
                self.models[t] = {
                    'spange': HistGradientBoostingRegressor(max_depth=7, max_iter=700, learning_rate=0.04),
                    'acs': HistGradientBoostingRegressor(max_depth=7, max_iter=700, learning_rate=0.04)
                }
            else:
                self.models[t] = {
                    'spange': ExtraTreesRegressor(n_estimators=500, min_samples_leaf=2, max_depth=10, n_jobs=-1, random_state=42),
                    'acs': ExtraTreesRegressor(n_estimators=500, min_samples_leaf=2, max_depth=10, n_jobs=-1, random_state=42)
                }
```

Feature building:
- Process features: Residence Time, Temperature, inv_temp (1000/T_K), log_time, interaction
- Solvent features: Weighted mix for mixed solvents
- TTA: Train on both orderings, predict with both and average

Prediction weighting:
- 0.8 * acs_pca predictions + 0.2 * spange predictions

### 2. ExtraTrees with Optimal Regularization (BACKUP)
If per-target approach doesn't work:
- max_depth=10, min_samples_leaf=2, n_estimators=500
- Achieved 0.0687 MAE in analysis

## What NOT to Try
- Simple Random Forest with Spange only (already tried, 0.0748)
- Complex MLP+GBDT ensemble (already tried, 0.081)
- DRFP features with Ridge (0.097 MAE - worse than Spange)

## Validation Notes
- Single solvent: Leave-one-solvent-out (24 folds)
- Full data: Leave-one-ramp-out (13 folds)
- CV scheme is correct and template-compliant

## Template Compliance Reminder
- Last 3 cells must be EXACTLY as template
- Only change: `model = PerTargetHeterogeneousModel(data='single')` and `model = PerTargetHeterogeneousModel(data='full')`
- No cells after the final submission cell

## Target Score
Beat **0.017270** (lower is better). Current gap is 4.7x.
Expected improvement from per-target approach: 0.0805 → ~0.075 (7% improvement)