## Current Status
- Best CV score: 0.0623 from exp_004 (PerTarget HGB+ETR with LOO)
- Best LB score: 0.0956 from exp_004
- CV-LB gap: +53% ‚Üí LOO CV is optimistic for unseen solvents
- Target: 0.01727 (5.5x lower than best LB)
- Remaining submissions: 3

## Response to Evaluator
- Technical verdict was TRUSTWORTHY for exp_013 - template compliance is correct
- Evaluator's top priority: Implement Optuna hyperparameter optimization. **AGREE** - this is the key missing piece from top kernel
- Key concerns raised:
  1. CV is worse than exp_004 (0.0827 vs 0.0623) - **VALID** but MLP+GBDT may generalize better
  2. Fixed weights [0.4,0.2,0.2,0.2] are suboptimal - **AGREE** - need Optuna
  3. Per-target approach abandoned - **VALID** - should try hybrid
- How I'm addressing: Next experiment should combine per-target approach with Optuna optimization

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop13_analysis.ipynb` for CV-LB gap analysis
- Key patterns:
  1. More regularization made LB WORSE (0.0956 ‚Üí 0.0991) - NOT traditional overfitting
  2. Per-target models (HGB for SM, ETR for Products) achieved best CV (0.0623)
  3. TTA hurts performance - confirmed in exp_005
  4. LOO validation is REQUIRED for submission (24 folds task 0, 13 folds task 1)

## CRITICAL CONSTRAINT
**üö® DO NOT CHANGE THE VALIDATION STRATEGY IN TEMPLATE CELLS üö®**
- The template expects LOO splits with specific fold counts
- Task 0: 24 folds (one per solvent)
- Task 1: 13 folds (one per solvent ramp)
- Changing to GroupKFold breaks the submission format

## Recommended Approaches (Priority Order)

### 1. HIGHEST PRIORITY: Per-Target + Optuna Optimization
**Why**: Per-target achieved best CV (0.0623), Optuna is the key missing piece from top kernel
**Implementation**:
- Use per-target models: HGB for SM, ExtraTrees for Products (from exp_004/005)
- Add Optuna optimization for hyperparameters:
  - HGB: max_depth (3-10), learning_rate (0.01-0.3), n_estimators (100-500)
  - ETR: max_depth (5-20), n_estimators (100-500), min_samples_split (2-10)
- Use GroupKFold (5-fold) INTERNALLY for Optuna optimization (faster)
- Use LOO for final submission
- Features: Spange descriptors (proven to work)

### 2. Per-Target + MLP Hybrid
**Why**: Combine best of both approaches
**Implementation**:
- Use MLP for some targets, per-target GBDT for others
- Try: MLP for SM (may capture non-linear kinetics), ETR for Products
- Or: Ensemble of per-target + MLP with learned weights

### 3. Feature Engineering for Unseen Solvents
**Why**: The problem is NOT overfitting - we need features that generalize
**Implementation**:
- Focus on Spange descriptors (chemical properties that generalize):
  - dielectric constant, ET(30), alpha, beta, pi*, SA, SB, SP, SdP, N, n, f(n), delta
- Add Arrhenius kinetics features: 1/T, ln(t), t*T interaction
- Consider: polarity ratios, hydrogen bonding capacity

## What NOT to Try
- ‚ùå GroupKFold in template cells (breaks submission format)
- ‚ùå TTA (hurts performance - confirmed in exp_005)
- ‚ùå Simple Ridge regression (CV 0.0896, worse than PerTarget)
- ‚ùå More regularization (made LB worse in exp_006)
- ‚ùå Fixed ensemble weights without optimization

## Validation Notes
- Use LOO for submission (REQUIRED by evaluation metric)
- Use GroupKFold ONLY for internal hyperparameter tuning (OPTIONAL)
- The CV-LB gap is ~50% with LOO - this is expected for unseen solvents
- Don't chase LOO CV - focus on approaches that generalize

## Key Insight from Top Kernel
The top kernel (lishellliang) uses:
1. GroupKFold (5-fold) internally - OVERWRITES utility functions
2. MLP + XGBoost + RF + LightGBM ensemble
3. Optuna hyperparameter optimization (commented out but available)
4. Spange descriptors only
5. Learned weights via Optuna

## Experiment Template for Per-Target + Optuna
```python
# Per-Target + Optuna Optimization
import optuna
from sklearn.model_selection import GroupKFold
from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor

def objective(trial):
    # Hyperparameters to optimize
    hgb_depth = trial.suggest_int('hgb_depth', 3, 10)
    hgb_lr = trial.suggest_float('hgb_lr', 0.01, 0.3, log=True)
    hgb_iter = trial.suggest_int('hgb_iter', 100, 500)
    etr_depth = trial.suggest_int('etr_depth', 5, 20)
    etr_n_estimators = trial.suggest_int('etr_n_estimators', 100, 500)
    
    # Use GroupKFold for internal CV (faster)
    gkf = GroupKFold(n_splits=5)
    errors = []
    for train_idx, val_idx in gkf.split(X, y, groups=solvent_ids):
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]
        
        # Train per-target model with trial hyperparameters
        hgb = HistGradientBoostingRegressor(max_depth=hgb_depth, learning_rate=hgb_lr, max_iter=hgb_iter)
        etr = ExtraTreesRegressor(max_depth=etr_depth, n_estimators=etr_n_estimators)
        
        # SM uses HGB, Products use ETR
        hgb.fit(X_train, y_train[:, 2])  # SM
        etr.fit(X_train, y_train[:, :2])  # Products
        
        preds = np.column_stack([etr.predict(X_val), hgb.predict(X_val).reshape(-1, 1)])
        mae = np.mean(np.abs(preds - y_val))
        errors.append(mae)
    return np.mean(errors)

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)
best_params = study.best_params

# Then use best_params with LOO for final submission
```

## Gap Analysis
- Target: 0.01727
- Best LB: 0.0956
- Gap: 5.5x (HUGE)

This gap suggests we need fundamentally different approaches. The target IS reachable - we just need to find the right combination of:
1. Per-target models (proven best CV)
2. Optuna optimization (key missing piece)
3. Features that generalize to unseen solvents