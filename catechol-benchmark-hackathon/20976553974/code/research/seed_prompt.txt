## Current Status
- Best CV score: 0.0623 from exp_004 (005_no_tta_per_target)
- Best LB score: 0.0956 from exp_004
- CV-LB gap: +53% → LOO validation is optimistic, but relative ranking preserved
- Target: 0.01727 (still 5.5x away from best LB)

## Response to Evaluator
- Technical verdict was TRUSTWORTHY. Results can be trusted.
- Evaluator's top priority: **Replicate exp_004's EXACT dual-model ensemble architecture for full data.** AGREED - this is the critical fix.
- Key concern: exp_016 used FEATURE combination instead of PREDICTION combination. This is why full data CV was 0.0928 vs exp_004's 0.0603.
- The evaluator correctly identified that exp_004 trains SEPARATE models on spange and acs_pca features, then combines PREDICTIONS (0.8*acs_pred + 0.2*spange_pred). This is fundamentally different from combining features first.

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop16_analysis.ipynb` for architectural analysis
- Key patterns:
  - **PREDICTION combination > FEATURE combination**: exp_004 (0.0623) vs exp_016 (0.0830)
  - **Full data is the bottleneck**: exp_004 full=0.0603, exp_016 full=0.0928 (54% worse)
  - **Single solvent is already good**: exp_016 single=0.0647 (close to exp_004's 0.0659)
  - **CV-LB gap is ~50%**: Both submissions show similar gap, relative ranking preserved

## Recommended Approaches

### Priority 1: REPLICATE exp_004's EXACT Architecture (CRITICAL)
The evaluator identified the KEY architectural difference. exp_016 failed because it combined features instead of predictions.

**EXACT exp_004 architecture to replicate:**
```python
# For each target (SM, Product 2, Product 3):
# 1. Train model on spange features
model_spange = HGB/ETR()
model_spange.fit(X_spange_scaled, y_target)

# 2. Train model on acs_pca features  
model_acs = HGB/ETR()
model_acs.fit(X_acs_scaled, y_target)

# 3. Combine PREDICTIONS (NOT features!)
pred = 0.8 * model_acs.predict(X_test_acs) + 0.2 * model_spange.predict(X_test_spange)
```

**Hyperparameters from exp_004:**
- HGB for SM: max_depth=7, max_iter=700, learning_rate=0.04
- ETR for Products: n_estimators=500, max_depth=10, min_samples_leaf=2
- Feature weights: 0.8 * acs_pred + 0.2 * spange_pred

**Expected result:**
- Full data CV should match exp_004's 0.0603
- Combined CV should be ~0.0618 (0.0647 * 0.35 + 0.0603 * 0.65)

### Priority 2: Consider MLP for Single Solvent (Optional Enhancement)
exp_015 showed MLP helps single solvent (0.0638 vs 0.0659). Could try:
- Single solvent: exp_015 approach (deep + MLP + COMBINED features)
- Full data: exp_004 approach (PREDICTION combination)
- Expected: 0.0638 * 0.35 + 0.0603 * 0.65 = 0.0615

### Priority 3: Ensemble Diversity (After Fixing Architecture)
Once we recover exp_004's performance, consider:
- Stacking with meta-learner
- Adding GP predictions as additional features
- Different ensemble weights learned via validation

## What NOT to Try
- ❌ FEATURE combination (0.8*acs + 0.2*spange) - proven worse than PREDICTION combination
- ❌ GroupKFold - causes submission format errors (exp_011 failed)
- ❌ TTA (Test-Time Augmentation) - hurts mixed solvent performance (exp_004 analysis)
- ❌ Optuna hyperparameter search - found shallow models that underfit (exp_014)
- ❌ Very deep models for full data - overfits (exp_015 full=0.1027)

## Validation Notes
- Use LOO validation (24 folds for single solvent, 13 folds for full data)
- CV-LB gap is ~50% but relative ranking is preserved
- If CV improves to ~0.0615, submit to verify LB improvement
- Template compliance: Last 3 cells must match exactly, only model definition line can change

## CRITICAL IMPLEMENTATION DETAILS
The key difference between exp_004 and exp_016 is:

**exp_004 (CORRECT - CV 0.0623):**
```python
# Train separate models on each feature set
model_spange.fit(X_spange_scaled, y_target)
model_acs.fit(X_acs_scaled, y_target)
# Combine predictions
pred = 0.8 * model_acs.predict(X_test_acs) + 0.2 * model_spange.predict(X_test_spange)
```

**exp_016 (WRONG - CV 0.0830):**
```python
# Combine features first
combined = np.concatenate([0.8*acs, 0.2*spange])
# Train single model
model.fit(combined, y_target)
```

The fix is straightforward: train SEPARATE models on each feature set and combine PREDICTIONS.