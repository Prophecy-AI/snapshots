## Current Status
- Best CV score: 0.0623 from exp_004/016/017 (HGB+ETR per-target)
- Best LB score: 0.0956 from exp_004/016
- CV-LB gap: +53% (CONSISTENT across all models)
- Target: 0.01727 (5.5x away from best LB)
- **Submissions remaining: 1 (FINAL - use wisely!)**

## Response to Evaluator
- Technical verdict was CONCERNS due to cell after final cell. AGREED - must fix.
- Evaluator's top priority: Debug GroupKFold and match top kernel. PARTIALLY AGREE.
- Key concerns raised:
  1. Multi-seed ensemble made CV worse (0.0623 â†’ 0.0901) - CONFIRMED by LB (0.0956 â†’ 0.1231)
  2. GroupKFold submission failed due to fold structure mismatch - CONFIRMED
  3. lishellliang kernel REDEFINES split functions to use GroupKFold internally
- How I'm addressing: 
  - DO NOT use GroupKFold - it changes fold structure and causes submission errors
  - Focus on improving CV with LOO validation (which works)
  - Only submit if CV < 0.0623

## Critical LB Feedback Analysis

### Submission History
| Exp | CV | LB | Gap |
|-----|-----|-----|-----|
| exp_004 | 0.0623 | 0.0956 | +53% |
| exp_006 | 0.0688 | 0.0991 | +44% |
| exp_016 | 0.0623 | 0.0956 | +53% |
| exp_021 | 0.0901 | 0.1231 | +37% |

### Key Insights
1. **CV-LB correlation is 0.994** - Lower CV = Lower LB (very strong)
2. **Multi-seed ensemble HURT performance** - both CV and LB got worse
3. **Best LB (0.0956) is from best CV (0.0623)** - exp_004 architecture
4. **To beat target (0.01727), need LB improvement of 5.5x** - MASSIVE gap

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop22_lb_feedback.ipynb` for LB analysis
- Key patterns:
  1. CV-LB gap is ~50% for best models (exp_004/016)
  2. To reach target LB 0.01727 with 50% gap, need CV ~0.0115
  3. Current best CV is 0.0623 - need 82% improvement
  4. GroupKFold CANNOT be used - causes submission errors

## FINAL SUBMISSION STRATEGY

### The Reality
- We have 1 submission left
- Best LB is 0.0956 (already submitted as exp_004)
- Target is 0.01727 (5.5x better than best LB)
- 22 experiments have been run, none beat exp_004's CV

### Options
1. **Submit exp_004 again** - Guaranteed 0.0956 (already have this)
2. **Create new experiment with CV < 0.0623** - Only way to potentially improve
3. **Try fundamentally different approach** - High risk, high reward

### Recommended Approach: Stacking Meta-Learner

**Why:** We have diverse models (exp_004, exp_010, exp_008) that capture different patterns. A meta-learner could combine them optimally.

**Implementation:**
```python
class StackingModel(BaseModel):
    def __init__(self, data='single'):
        self.base_models = [
            PerTargetModel(data),      # exp_004 architecture (CV 0.0623)
            MLPGBDTEnsemble(data),     # exp_010 architecture (CV 0.0669)
            GaussianProcessModel(data), # exp_008 architecture (CV 0.0721)
        ]
        self.meta_learner = Ridge(alpha=1.0)
    
    def train_model(self, X_train, y_train):
        # Train base models and get OOF predictions
        oof_preds = []
        for model in self.base_models:
            model.train_model(X_train, y_train)
            oof_preds.append(model.predict(X_train))
        
        # Stack OOF predictions
        stacked = np.hstack(oof_preds)
        self.meta_learner.fit(stacked, y_train)
    
    def predict(self, X):
        base_preds = [m.predict(X) for m in self.base_models]
        stacked = np.hstack(base_preds)
        return self.meta_learner.predict(stacked)
```

### Alternative: CatBoost with Strong Regularization

**Why:** CatBoost often has smaller CV-LB gap due to built-in regularization.

**Implementation:**
```python
from catboost import CatBoostRegressor

class CatBoostModel(BaseModel):
    def __init__(self, data='single'):
        self.models = [
            CatBoostRegressor(
                iterations=500,
                depth=6,
                learning_rate=0.05,
                l2_leaf_reg=10,  # Strong regularization
                random_seed=42,
                verbose=False
            )
            for _ in range(3)  # One per target
        ]
```

## What NOT to Try
- âŒ Multi-seed ensemble - Made CV worse (0.0901 vs 0.0623)
- âŒ GroupKFold validation - Causes submission errors
- âŒ Stronger regularization - Already proven to hurt (exp_021)
- âŒ GNN without pre-training - CV 0.099 (much worse)
- âŒ DRFP features alone - exp_018 showed they don't help
- âŒ TTA (flip augmentation) - Hurt full data performance

## Validation Notes
- Use LOO validation (24 folds single, 13 folds full) - REQUIRED
- CV-LB gap is ~50%, so CV 0.06 â†’ LB ~0.09
- **Only submit if CV < 0.0623** - otherwise exp_004 is already our best
- Focus on approaches that REDUCE CV, not just different approaches

## Template Compliance (CRITICAL)
```python
# Last 3 cells MUST remain exactly as template
# Only change: model = YourModel(data='single')  # or 'full'
# DO NOT add cells after the "FINAL CELL"
# Notebook must end with the submission.to_csv cell
```

## Priority Order for Next Experiment

### PRIORITY 1: Stacking Meta-Learner (HIGHEST POTENTIAL)
- Combine exp_004 (HGB+ETR), exp_010 (MLP+GBDT), exp_008 (GP)
- Use Ridge as meta-learner with strong regularization
- Expected CV: Could be < 0.0623 if models are complementary

### PRIORITY 2: CatBoost with Strong Regularization
- Known for good generalization
- Use same features as exp_004 (0.8 ACS_PCA + 0.2 Spange)
- May have smaller CV-LB gap

### PRIORITY 3: Weighted Ensemble with Optimized Weights
- Use Optuna to find optimal weights for exp_004, exp_010, exp_008
- Simple averaging may not be optimal
- Could find better combination

## ðŸš¨ CRITICAL RULES ðŸš¨

1. **Only 1 submission remaining** - Make it count
2. **Only submit if CV < 0.0623** - Otherwise exp_004 is already best
3. **Template compliance is MANDATORY** - No cells after final cell
4. **Use LOO validation** - GroupKFold causes errors
5. **Focus on CV improvement** - CV-LB correlation is 0.994

## The Path Forward

The target (0.01727) requires a 5.5x improvement from best LB (0.0956). This is MASSIVE. 

**Realistic assessment:**
- With 1 submission left, we should focus on:
  1. Creating an experiment with CV < 0.0623
  2. If successful, submit it
  3. If not, exp_004 (LB 0.0956) is already our best

**Most promising direction:**
- Stacking meta-learner on diverse base models
- This could capture complementary patterns
- Expected to improve CV if models are truly diverse

**Backup:**
- If stacking doesn't beat 0.0623, don't submit
- exp_004 (LB 0.0956) is already our best verified result