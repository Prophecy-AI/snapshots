## Current Status
- Best CV score: 0.0623 from exp_004 (PerTarget HGB+ETR with Arrhenius features)
- Best LB score: 0.0956 from exp_004
- CV-LB gap: +53% ‚Üí LOO CV is optimistic for unseen solvents
- Target: 0.01727 (5.5x lower than best LB)
- Remaining submissions: 3

## Response to Evaluator
- Technical verdict was TRUSTWORTHY for exp_015 - template compliance is correct
- Evaluator's top priority: Address the full data performance bottleneck (0.1027 vs 0.0603). **AGREE** - this is the key issue
- Key concerns raised:
  1. Full data CV (0.1027) is 70% worse than exp_004 (0.0603) - **CRITICAL**
  2. Deep models (depth=None) may be overfitting - **CONFIRMED** by analysis
  3. MLP weight of 0.5 suggests equal contribution - **INTERESTING** but not the root cause
- How I'm addressing: 
  1. **ROOT CAUSE IDENTIFIED**: exp_015 is MISSING Arrhenius kinetics features (1/T, ln(t), t*T interaction)
  2. **SECONDARY CAUSE**: Unlimited depth overfits on full data
  3. **SOLUTION**: Use exp_004's approach for full data, exp_015's approach for single solvent

## CRITICAL INSIGHT FROM ANALYSIS
**WHY exp_015 FULL DATA PERFORMANCE DEGRADED:**

| Metric | exp_004 | exp_015 | Difference |
|--------|---------|---------|------------|
| Single Solvent | 0.0659 | 0.0638 | exp_015 is 3% BETTER |
| Full Data | 0.0603 | 0.1027 | exp_015 is 70% WORSE |
| Combined | 0.0623 | 0.0891 | exp_015 is 43% WORSE |

**ROOT CAUSES:**
1. **MISSING Arrhenius kinetics features** in exp_015 (1/T, ln(t), t*T interaction)
2. **Unlimited depth** in exp_015 (depth=None) vs exp_004 (depth=7/10)
3. **MLP component** may be overfitting on full data

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop15_analysis.ipynb` for detailed analysis
- Key patterns:
  1. Full data has 13 ramps with ~94 samples each (more complex, fewer groups)
  2. Single solvent has 24 solvents with ~27 samples each (simpler, more groups)
  3. Deep models overfit on full data but work well on single solvent
  4. Arrhenius kinetics features are CRITICAL for generalization

## CRITICAL CONSTRAINT
**üö® DO NOT CHANGE THE VALIDATION STRATEGY IN TEMPLATE CELLS üö®**
- The template expects LOO splits with specific fold counts
- Task 0: 24 folds (one per solvent)
- Task 1: 13 folds (one per solvent ramp)
- Changing to GroupKFold breaks the submission format

## Recommended Approaches (Priority Order)

### 1. HIGHEST PRIORITY: Hybrid Model with Task-Specific Configurations
**Why**: exp_015 is BETTER for single solvent, exp_004 is BETTER for full data. Combine the best of both!
**Implementation**:
```python
class HybridTaskModel(BaseModel):
    """Use different configurations for single vs full data."""
    
    def __init__(self, data='single'):
        self.data = data
        if data == 'single':
            # exp_015 approach: Deep models + MLP (works better for single)
            self.use_mlp = True
            self.hgb_depth = None  # Unlimited
            self.etr_depth = None  # Unlimited
        else:
            # exp_004 approach: Shallow models + NO MLP (works better for full)
            self.use_mlp = False
            self.hgb_depth = 7
            self.etr_depth = 10
        
        # CRITICAL: Add Arrhenius kinetics features for BOTH tasks
        self.use_arrhenius = True  # 1/T, ln(t), t*T interaction
```

**Expected CV**: 0.0638 * 0.35 + 0.0603 * 0.65 = 0.0615 (better than exp_004's 0.0623!)

### 2. Add Arrhenius Kinetics Features to exp_015
**Why**: exp_015 is MISSING these features that exp_004 has
**Implementation**:
```python
def _build_features(self, X):
    rt = X['Residence Time'].values.reshape(-1, 1)
    temp = X['Temperature'].values.reshape(-1, 1)
    
    # CRITICAL: Arrhenius kinetics features
    temp_k = temp + 273.15
    inv_temp = 1000.0 / temp_k  # 1/T
    log_time = np.log(rt + 1e-6)  # ln(t)
    interaction = inv_temp * log_time  # t*T interaction
    
    # ... rest of feature extraction
    return np.hstack([rt, temp, inv_temp, log_time, interaction, ...])
```

### 3. Use Shallow Models for Full Data
**Why**: Deep models (depth=None) overfit on full data
**Implementation**:
```python
# For full data only:
hgb = HistGradientBoostingRegressor(
    max_depth=7,  # NOT None
    max_iter=700,
    learning_rate=0.04,
    random_state=42
)
etr = ExtraTreesRegressor(
    n_estimators=500,
    max_depth=10,  # NOT None
    min_samples_leaf=2,
    random_state=42
)
```

### 4. Remove MLP for Full Data
**Why**: MLP may be overfitting on full data (13 ramps, ~94 samples each)
**Implementation**:
```python
if self.data == 'full':
    # Use GBDT only for full data
    final_pred = gbdt_pred
else:
    # Use MLP + GBDT for single solvent
    final_pred = 0.5 * mlp_pred + 0.5 * gbdt_pred
```

## What NOT to Try
- ‚ùå GroupKFold in template cells (breaks submission format)
- ‚ùå TTA (hurts performance - confirmed in exp_005)
- ‚ùå Deep models (depth=None) for full data (overfits)
- ‚ùå MLP for full data (may overfit)
- ‚ùå Spange-only features (exp_014 showed this is worse than COMBINED)
- ‚ùå Missing Arrhenius kinetics features (exp_015 showed this hurts full data)

## Validation Notes
- Use LOO for submission (REQUIRED by evaluation metric)
- The CV-LB gap is ~50% with LOO - this is expected for unseen solvents
- Don't chase LOO CV - focus on approaches that generalize

## Submission Strategy
With 3 submissions remaining:
1. **DO NOT submit exp_015** - CV is worse than exp_004, unlikely to improve LB
2. **Implement Hybrid Model with Task-Specific Configurations**
3. **Submit if CV improves over exp_004 (0.0623)**
4. **Keep 1-2 submissions for final iterations**

## Gap Analysis
- Target: 0.01727
- Best LB: 0.0956
- Gap: 5.5x (HUGE)

This gap suggests we need fundamentally different approaches. The target IS reachable - we just need to find the right combination of:
1. **Task-specific configurations** (deep for single, shallow for full)
2. **Arrhenius kinetics features** (CRITICAL for generalization)
3. **COMBINED features** (0.8*ACS_PCA + 0.2*Spange)
4. **Per-target models** (HGB for SM, ETR for Products)

## NEXT EXPERIMENT: exp_016
**Hybrid Model with Task-Specific Configurations**
- Single solvent: Deep models + MLP + Arrhenius features
- Full data: Shallow models + NO MLP + Arrhenius features
- Expected CV: ~0.0615 (better than exp_004's 0.0623)