{
  "query": "What is the best approach for the Catechol rearrangement benchmark dataset for predicting reaction yields with solvent effects?",
  "results": [
    {
      "title": "ANSWER",
      "text": "The Catechol rearrangement benchmark provides a dense, time\u2011resolved set of\u202f\u2248\u202f1\u202f200 transient\u2011flow experiments that span a continuous range of solvent compositions, temperatures and residence times. Because the solvent is treated as a continuous variable rather than a discrete label, the most successful strategies treat the reaction as a graph\u2011structured problem and embed the solvent properties directly into the model. In practice, a graph neural network (GNN) that encodes the molecular graph of the reactants/products together with physicochemical descriptors of the solvent (e.g., polarity, dielectric constant, Hildebrand solubility parameters) yields the lowest mean\u2011absolute error on yield prediction\u202f\u3010arxiv](https://arxiv.org/abs/2512.19530)\u3011.  \n\nBuilding on this baseline, the authors of the \u201cCatechol Benchmark\u201d paper show that performance improves further when the GNN is combined with (i)\u202ffew\u2011shot / transfer\u2011learning from larger reaction datasets, (ii)\u202factive\u2011learning loops that query the most informative solvent\u2011temperature points, and (iii)\u202fcareful feature engineering of continuous process conditions (flow rate, temperature)\u202f\u3010openreview](https://openreview.net/pdf?id=6l8q74TabE)\u3011. These techniques exploit the rich continuous nature of the data and allow a model trained on a modest subset to generalize across the full solvent space.  \n\nIn summary, the current best practice for the Catechol rearrangement benchmark is a solvent\u2011aware GNN augmented with transfer\u2011learning and active\u2011learning strategies, rather than traditional discrete\u2011solvent or simple regression models. This approach leverages the full resolution of the transient\u2011flow dataset and has been highlighted by both the original arXiv study and the Imperial\u202f+\u202fSOLVE Chemistry release of the dataset\u202f\u3010imperial](https://www.imperial.ac.uk/news/articles/2025/imperial-and-solve-chemistry-bring-chemical-reaction-data-to-machine-learning)\u3011.",
      "url": ""
    },
    {
      "title": "Learning Continuous Solvent Effects from Transient Flow Data - arXiv",
      "text": "[2512.19530] Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2512.19530\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2512.19530**(cs)\n[Submitted on 22 Dec 2025]\n# Title:Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\nAuthors:[Hongsheng Xing](https://arxiv.org/search/cs?searchtype=author&amp;query=Xing,+H),[Qiuxin Si](https://arxiv.org/search/cs?searchtype=author&amp;query=Si,+Q)\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n[View PDF](https://arxiv.org/pdf/2512.19530)[HTML (experimental)](https://arxiv.org/html/2512.19530v1)> > Abstract:\n> Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \\textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.\n> Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \\textbf{MSE of 0.0039} ($\\pm$ 0.0003), representing a 60\\% error reduction over competitive baselines and a $&gt;25\\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning. Comments:|13 pages, 6 figures|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI)|\nMSCclasses:|68T07, 92E20, 62M45|\nACMclasses:|I.2.1; I.2.6; J.2|\nCite as:|[arXiv:2512.19530](https://arxiv.org/abs/2512.19530)[cs.LG]|\n|(or[arXiv:2512.19530v1](https://arxiv.org/abs/2512.19530v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2512.19530](https://doi.org/10.48550/arXiv.2512.19530)\nFocus to learn more\narXiv-issued DOI via DataCite (pending registration)\n|\n## Submission history\nFrom: Hongsheng Xing [[view email](https://arxiv.org/show-email/9dc7457b/2512.19530)]\n**[v1]**Mon, 22 Dec 2025 16:19:01 UTC (2,198 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n* [View PDF](https://arxiv.org/pdf/2512.19530)\n* [HTML (experimental)](https://arxiv.org/html/2512.19530v1)\n* [TeX Source](https://arxiv.org/src/2512.19530)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2512.19530&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2512.19530&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2025-12](https://arxiv.org/list/cs.LG/2025-12)\nChange to browse by:\n[cs](https://arxiv.org/abs/2512.19530?context=cs)\n[cs.AI](https://arxiv.org/abs/2512.19530?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2512.19530)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2512.19530)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2512.19530)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2512.19530&amp;description=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2512.19530&amp;title=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.or...",
      "url": "https://arxiv.org/abs/2512.19530"
    },
    {
      "title": "Imperial and SOLVE Chemistry bring chemical reaction data to ...",
      "text": "Imperial and SOLVE Chemistry bring chemical reaction data to machine learning | Imperial News | Imperial College London[Skip to main content](#content)[View accessibility support page](https://www.imperial.ac.uk/about-the-site/accessibility/)\n[](https://www.imperial.ac.uk/)\nSearchSearchMenu\nSearch\n## Website navigation\nClose[](https://www.imperial.ac.uk/)\nKey linksThis section\n[Skip to section navigation](#section-nav)\n* [News](https://www.imperial.ac.uk/news/)\n* [Science](https://www.imperial.ac.uk/news/articles/?topic=Science)# Imperial and SOLVE Chemistry bring chemical reaction data to machine learning\nby[David Silverman](#authorbox)\n22 December 2025\n![Three people in lab coats](https://www.imperial.ac.uk/news/media/news-images/3000x2000-main-article-images/solve-neurips.jpg)Team members from SOLVE Chemistry\nResearchers from Imperial and its spinout company SOLVE Chemistry have presented a chemical dataset at the prestigious AI conference NeurIPS that could help accelerate the use of machine learning to solve solvent challenges in industrial chemistry.\nIndustrial chemists often use prior data to help predict reaction outcomes such as how a certain solvent or temperature setting will perform in a manufacturing process. But existing datasets are patchy &ndash; for example, they typically only include certain solvents and certain temperatures. They are therefore not powerful enough to reliably predict the best way to produce a chemical.\nThe new dataset contains comprehensive data on one industrially relevant reaction, catechol rearrangement, that could be used to effectively train machine learning algorithms to predict which solvents and conditions will give the best yields. It could also make it possible to train models that find the highest\u2011yielding options within a shortlist of more sustainable solvents or at the lowest feasible temperature.\nThe project to acquire and test the new dataset was initiated by[Professor Kim Jelfs](https://profiles.imperial.ac.uk/k.jelfs)in Imperial&rsquo;s[Department of Chemistry](https://www.imperial.ac.uk/chemistry/)and[Professor Ruth Misener](https://profiles.imperial.ac.uk/r.misener)in the[Department of Computing](https://www.imperial.ac.uk/computing/), working as part of[AIChemy](https://aichemy.ac.uk/), an EPSRC AI hub for Chemistry.[SOLVE Chemistry](https://www.solvechemistry.com/)was funded to produce the first publicly available dataset to include dense sampling of a continuous solvent and temperature space using technology developed by the company.\n> The new dataset could be used to effectively train machine learning algorithms to predict which solvents and conditions give the best yields. It could help use more sustainable solvents and lower temperatures.\n> > Imperial researchers led by PhD student[Toby Boyne](https://profiles.imperial.ac.uk/t.boyne23)then demonstrated some ways this data can be used to develop and test predictive algorithms. Mr Boyne said: &ldquo;Predicting the impacts of different solvents is already a significant challenge. By including a range of solvent classes, as well as mixtures of solvents, we hope this dataset inspires the machine learning community to develop models that better capture solvent effects, and are robust across a range of experimental conditions.&rdquo;\nTo gather the data, the researchers used automated flow chemistry techniques developed by SOLVE Chemistry, which was founded by Imperial graduates Dr Linden Schrecker and Dr Jose Pablo Folch from their EPSRC- and BASF-funded PhDs. This enabled them to gather the reaction data continuously as reactions evolved over time.\nIn the case of temperature and residence time, this allowed them to gather dense enough data points to represent the variables as continuous rather than discrete. This could make it easier for machine learning models to detect nonlinear relationships between, for example, temperature and yield.\nIn the case of solvent selection, which is traditionally a categorical variable, they obtained continuous data using solvent mixtures, which allows solvent conditions to be explored in a more varied design space. For example, instead of just testing pure water and pure ethanol, they ran reactions along continuous ramps of water-ethanol mixtures and other solvent blends.\n&ldquo;What makes a solvent good for one reaction may not be what makes it good for another reaction,&rdquo; explained SOLVE Chemistry co-founder and Chief Scientific Officer, Dr Jose Pablo Folch. &ldquo;We&rsquo;re creating a workflow that combines cutting-edge machine learning and unique data collection to quickly uncover solvent effects on reactions of commercial interest.&rdquo;\nThe team put together 1,220 data points, which for chemical data is substantial and has potential to enable an entire class of models that were not previously testable at scale in chemistry. Following their publication in NeurIPS, Gabriel Gibberd in the Department of Chemical Engineering, a graduate from Imperial's[Digital Chemistry](https://www.imperial.ac.uk/study/courses/postgraduate-taught/digital-chemistry/)MSc programme, has used the dataset to achieve an even greater machine learning performance, also accepted into NeurIPS.\n## Hackathon\nThe NeurIPS paper is accompanied by a public hackathon, designed to give researchers early access to the dataset and challenge them to build models that predict unseen reaction outcomes as accurately as possible. &ldquo;Whoever wins will have a solution that will catalyse the next frontier of research in this area,&rdquo; said Dr Linden Schrecker, SOLVE Chemistry&rsquo;s co-founder and CEO.\n[Join the Catechol Benchmark Hackathon](https://www.kaggle.com/competitions/catechol-benchmark-hackathon/overview)\n## Future developments\nThe team aims to make the dataset a springboard for new research in both chemistry and machine learning. By providing a unique, well\u2011curated dataset that combines time\u2011series, temperature-series and continuous solvent spaces, they give machine learning developers a realistic but tractable test bed for ideas in few\u2011shot learning, active learning and representation learning.\nAs researchers compete in the hackathon and build on the open data and code, the expectation is that new modelling strategies will emerge that can then be transferred to other reactions, other materials systems and industrial workflows.\n## Further reading\n[The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning (PDF)](https://arxiv.org/pdf/2506.07619)\n[Catechol Benchmark dataset](https://www.kaggle.com/datasets/aichemy/catechol-benchmark)\n[SoDaDE: Solvent Data-Driven Embeddings with Small Transformer Models (PDF)](https://arxiv.org/pdf/2509.22302?)\n[AIChemy](https://aichemy.ac.uk/)\n## Share this article\n* [](https://www.facebook.com/sharer/sharer.php?u=https://www.imperial.ac.uk/news/articles/2025/imperial-and-solve-chemistry-bring-chemical-reaction-data-to-machine-learning/)\n* [](https://www.linkedin.com/shareArticle?mini=true&url=https://www.imperial.ac.uk/news/articles/2025/imperial-and-solve-chemistry-bring-chemical-reaction-data-to-machine-learning/)\n* Copy link\n## Related tags\n* [Artificial Intelligence](https://www.imperial.ac.uk/news/articles/?tags=Artificial%20Intelligence)\n* [Engineering Chemical Eng](https://www.imperial.ac.uk/news/articles/?tags=Engineering%20Chemical%20Eng)\n* [Engineering Computing](https://www.imperial.ac.uk/news/articles/?tags=Engineering%20Computing)\n* [Enterprise](https://www.imperial.ac.uk/news/articles/?tags=Enterprise)\n* [Entrepreneurship](https://www.imperial.ac.uk/news/articles/?tags=Entrepreneurship)\n## Study subjects\n* [Chemical engineering](https://www.imperial.ac.uk/study/subjects/chemical-engineering/)\n* [Chemistry](https://www.imperial.ac.uk/study/subjects/chemistry/)\n* [Computer science](https://www.imperial.ac.uk/study/subjects/computer-science/)\nArticle text (excluding photos or graphics) &copy; Imperial College London.\nPhotos and graphics subject to third ...",
      "url": "https://www.imperial.ac.uk/news/articles/2025/imperial-and-solve-chemistry-bring-chemical-reaction-data-to-machine-learning"
    },
    {
      "title": "",
      "text": "The Catechol Benchmark: Time-series Solvent\nSelection Data for Few-shot Machine Learning\nToby Boyne1\u2217, Juan S. Campos1, Becky D. Langdon1, Jixiang Qing1, Yilin Xie1\nShiqiang Zhang1, Calvin Tsay1, Ruth Misener1, Daniel W. Davies2, Kim E. Jelfs2\nSarah Boyall3, Thomas M. Dixon3, Linden Schrecker3, Jose Pablo Folch3\u2020\nDepartment of Computing, Imperial College London, London, UK1\nDepartment of Chemistry, Imperial College London, London, UK2\nSOLVE Chemistry, London, UK3\nAbstract\n1 Machine learning has promised to change the landscape of laboratory chem\u00022 istry, with impressive results in molecular property prediction and reaction retro\u00023 synthesis. However, chemical datasets are often inaccessible to the machine\n4 learning community as they tend to require cleaning, thorough understanding of the\n5 chemistry, or are simply not available. In this paper, we introduce a novel dataset\n6 for yield prediction, providing the first-ever transient flow dataset for machine\n7 learning benchmarking, covering over 1200 process conditions. While previous\n8 datasets focus on discrete parameters, our experimental set-up allow us to sample\n9 a large number of continuous process conditions, generating new challenges for\n10 machine learning models. We focus on solvent selection, a task that is particularly\n11 difficult to model theoretically and therefore ripe for machine learning applica\u000212 tions. We showcase benchmarking for regression algorithms, transfer-learning\n13 approaches, feature engineering, and active learning, with important applications\n14 towards solvent replacement and sustainable manufacturing.\n15 1 Introduction\n16 Machine learning (ML) and artificial intelligence (AI) have showcased enormous potential in em\u000217 powering the world of the natural sciences: from famous examples such as AlphaFold for protein\n18 predictions [1], to fusion reactor control [2], disease detection [3], battery design [4], and material\n19 discovery [5], among many more. However, we seldom see the machine learning community bench\u000220 mark new methods in physical science datasets, mostly due to the difficulty in cleaning real-world\n21 data, the need for interdisciplinary understanding to correctly benchmark, and most importantly, how\n22 expensive the data can be to produce, resulting in many datasets being locked behind closed doors by\n23 large companies.\n24 AIchemy (https://aichemy.ac.uk) is an interdisciplinary UK hub with the mission of transform\u000225 ing the chemistry-AI interface via aiding the collaboration of chemists and AI researchers, as well as\n26 addressing gaps in data standards, curation, and availability for AI use. In partnership with SOLVE\n27 Chemistry (https://www.solvechemistry.com), we present a first important step into addressing\n28 the dataset gap with the introduction of a new and unique open dataset for benchmarking low-data\n29 machine learning algorithms for chemistry.\n30 Solvent selection is one of the biggest challenges for chemical manufacturing, with solvents often\n31 being the main source of waste in the manufacturing process [6]. Increased regulation on solvents and\n32 a drive to making process manufacturing more sustainable led to an interest in the discovery of greener\n\u2217\nt.boyne23@imperial.ac.uk ;\n\u2020\njose@solvechemistry.com\nSubmitted to 39th Conference on Neural Information Processing Systems (NeurIPS 2025). Do not distribute.\nFigure 1: Data was gathered on the rearrangement of allyl substituted catechol. By subjecting the\nreaction mixture to high temperatures, we begin a cascade reaction forming multiple rearrangement\nproducts. We investigate the yield of the reaction for a range of different solvents. Product 1 was not\nobserved and reacted immediately to form Product 2 and later 3.\n33 solvents and for improved solvent replacement tools. However, most of the solvent replacement tools\n34 focus purely on learning unsupervised representations of solvents, with the hope that experimentalists\n35 can find solvents with similar properties to replace those with environmental concerns. A much\n36 stronger approach would consider the interaction of a variety of different solvents with a reaction of\n37 interest to directly predict reaction yields, in such a way that the best possible solvent can be selected\n38 according to a yield-sustainability trade-off.\n39 Machine learning approaches have been shown to be a powerful tool for the prediction of chemical\n40 reaction conditions. Success has been reported in retro-synthesis [7, 8], condition recommendations\n41 [9], product predictions [10, 11], among others. While yield prediction has proven to be more difficult\n42 due to large inconsistencies in procedure and data reporting [12], we have still seen promising yield\n43 prediction results for smaller and more carefully curated datasets [13\u201316]. However, these datasets\n44 lack the continuous reaction conditions, such as temperature and residence time, that are required to\n45 scale-up processes to practical manufacturing conditions.\n46 In this paper, we release the first machine-learning-ready transient flow dataset, a framework that\n47 allows for quick and efficient screening of continuous reaction conditions. We specifically provide\n48 yield data over the uni-molecular allyl substituted catechol reaction, shown in Figure 1, with dense\n49 measurements across the residence time, temperature, and solvent space. We answer the call for\n50 more flow chemistry reaction data [17], further showcase how this type of kinetic data poses new\n51 challenges to current machine learning methods for chemistry, and identify potential solutions.\n52 1.1 Related works\n53 Reaction datasets are common in chemistry research, but their suitability for machine learning\n54 benchmarking tends to be poor. This can be a result of improper formatting or documentation,\n55 incomplete information about reaction conditions or the experimental set-up, or the lack of machine\n56 readability, leading to limited usage by the ML community. However, some effort has been made\n57 to address this, with the biggest example being the creation of the Open Reaction Database (ORD)\n58 [18], a repository containing over 2M different reactions, many of which come from US patent data\n59 (USPTO) [19]. However, the dataset falls short in some aspects, in particular with respect to machine\n60 learning readiness and data inconsistencies across reactions.\n61 ORDerly [12] allows for easy cleaning and preparation of ORD data, showing the promise of the\n62 dataset for forward and retro-synthetic prediction using transformers; however, it also shows that\n63 yield prediction cannot be done well due to data inconsistencies. Schwaller et al. [13] drew similar\n64 conclusions when using the USPTO dataset, stating that reaction conditions such as temperature,\n65 concentrations, and duration have a significant effect on yield. The assumption that every reaction in\n66 the dataset is optimized for reaction parameters proved too loose, resulting in inaccurate predictive\n67 models for yield, and highlighting the importance of creating datasets with full (including potentially\n68 sub-optimal) reaction conditions.\n69 More relevant to our work, Perera et al. [20] introduced a dataset of 5760 Suzuki-Miyaura cross\u000270 coupling reactions, Ahneman et al. [21] introduced a dataset of 3956 Buchwald\u2013Hartwig aminations,\n71 and Prieto Kullmer et al. [22] investigated screening additives for Ni-catalysed reactions, all for the\n72 purposes of yield prediction. The datasets have been used in the benchmarking of Gaussian processes\n73 and Bayesian neural networks [14], deep learning models [13], language-model-based embeddings\n2\n74 [16], data augmentation techniques [23], and Bayesian optimisation [15]. In each case, the datasets\n75 focus on discrete reaction variables, such as ligand, base, additives, or reactants at fixed temperatures\n76 and residence times. We are instead introducing a dataset rich in continuous reaction conditions (in\n77 our case temperature ...",
      "url": "https://openreview.net/pdf?id=6l8q74TabE"
    },
    {
      "title": "Chemical Reaction Prediction - CatalyzeX",
      "text": "Get our free extension to see links to code for papers anywhere online!Free add-on: code for papers everywhere!Free add-on: See code for papers anywhere!\n\n[![Chrome logo](https://www.catalyzex.com/static/images/google-chrome.svg)Add to Chrome - It's Free](https://chrome.google.com/webstore/detail/%F0%9F%92%BB-catalyzex-link-all-aim/aikkeehnlfpamidigaffhfmgbkdeheil)\n\nSearch Icon![Alert button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ffilter.cf288982.png&w=1080&q=75)\n\n# Topic: **Chemical Reaction Prediction**\n\n![Alert button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Falert_light_mode_icon.b8fca154.png&w=1080&q=75)\n\nWhat is Chemical Reaction Prediction? Chemical reaction prediction is the process of predicting the outcome of chemical reactions using machine learning models.\n\n### Papers and Code\n\n## [**Interpretable Deep Learning for Polar Mechanistic Reaction Prediction**](https://www.catalyzex.com/paper/interpretable-deep-learning-for-polar)\n\n[Github IconRequest Code](https://www.catalyzex.com/s/Chemical%20Reaction%20Prediction) Code for Similar Papers:![Code for Similar Papers](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Frelated_icon_transparent.98f57b13.png&w=96&q=75) [![Add code](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Faddcode_white.6afb879f.png&w=96&q=75)](https://www.catalyzex.com/add_code?title=Interpretable Deep Learning for Polar Mechanistic Reaction Prediction&paper_url=http://arxiv.org/abs/2504.15539)\n\n![Bookmark button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbookmark_outline.3a3e1c2c.png&w=828&q=75)\n\n![Alert button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Falert_light_mode_icon.b8fca154.png&w=1080&q=75)\n\nApr 22, 2025\n\nAuthors:[Ryan J. Miller](https://www.catalyzex.com/author/Ryan%20J.%20Miller), [Alexander E. Dashuta](https://www.catalyzex.com/author/Alexander%20E.%20Dashuta), [Brayden Rudisill](https://www.catalyzex.com/author/Brayden%20Rudisill), [David Van Vranken](https://www.catalyzex.com/author/David%20Van%20Vranken), [Pierre Baldi](https://www.catalyzex.com/author/Pierre%20Baldi)\n\nAbstract:Accurately predicting chemical reactions is essential for driving innovation in synthetic chemistry, with broad applications in medicine, manufacturing, and agriculture. At the same time, reaction prediction is a complex problem which can be both time-consuming and resource-intensive for chemists to solve. Deep learning methods offer an appealing solution by enabling high-throughput reaction prediction. However, many existing models are trained on the US Patent Office dataset and treat reactions as overall transformations: mapping reactants directly to products with limited interpretability or mechanistic insight. To address this, we introduce PMechRP (Polar Mechanistic Reaction Predictor), a system that trains machine learning models on the PMechDB dataset, which represents reactions as polar elementary steps that capture electron flow and mechanistic detail. To further expand model coverage and improve generalization, we augment PMechDB with a diverse set of combinatorially generated reactions. We train and compare a range of machine learning models, including transformer-based, graph-based, and two-step siamese architectures. Our best-performing approach was a hybrid model, which combines a 5-ensemble of Chemformer models with a two-step Siamese framework to leverage the accuracy of transformer architectures, while filtering away \"alchemical\" products using the two-step network predictions. For evaluation, we use a test split of the PMechDB dataset and additionally curate a human benchmark dataset consisting of complete mechanistic pathways extracted from an organic chemistry textbook. Our hybrid model achieves a top-10 accuracy of 94.9% on the PMechDB test set and a target recovery rate of 84.9% on the pathway dataset.\n\nVia![arxiv icon](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Farxiv.41e50dc5.png&w=128&q=75)\n\nGithub Icon [Access Paper or Ask Questions](https://www.catalyzex.com/paper/interpretable-deep-learning-for-polar)\n\n## [**Transferable Learning of Reaction Pathways from Geometric Priors**](https://www.catalyzex.com/paper/transferable-learning-of-reaction-pathways)\n\n[Github IconView Code](https://www.catalyzex.com/s/Chemical%20Reaction%20Prediction) Play IconNotebookCode for Similar Papers:![Code for Similar Papers](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Frelated_icon_transparent.98f57b13.png&w=96&q=75) [![Add code](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Faddcode_white.6afb879f.png&w=96&q=75)](https://www.catalyzex.com/add_code?title=Transferable Learning of Reaction Pathways from Geometric Priors&paper_url=http://arxiv.org/abs/2504.15370)\n\n![Bookmark button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbookmark_outline.3a3e1c2c.png&w=828&q=75)\n\n![Alert button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Falert_light_mode_icon.b8fca154.png&w=1080&q=75)\n\nApr 21, 2025\n\nAuthors:[Juno Nam](https://www.catalyzex.com/author/Juno%20Nam), [Miguel Steiner](https://www.catalyzex.com/author/Miguel%20Steiner), [Max Misterka](https://www.catalyzex.com/author/Max%20Misterka), [Soojung Yang](https://www.catalyzex.com/author/Soojung%20Yang), [Avni Singhal](https://www.catalyzex.com/author/Avni%20Singhal), [Rafael G\u00f3mez-Bombarelli](https://www.catalyzex.com/author/Rafael%20G%C3%B3mez-Bombarelli)\n\nAbstract:Identifying minimum-energy paths (MEPs) is crucial for understanding chemical reaction mechanisms but remains computationally demanding. We introduce MEPIN, a scalable machine-learning method for efficiently predicting MEPs from reactant and product configurations, without relying on transition-state geometries or pre-optimized reaction paths during training. The task is defined as predicting deviations from geometric interpolations along reaction coordinates. We address this task with a continuous reaction path model based on a symmetry-broken equivariant neural network that generates a flexible number of intermediate structures. The model is trained using an energy-based objective, with efficiency enhanced by incorporating geometric priors from geodesic interpolation as initial interpolations or pre-training objectives. Our approach generalizes across diverse chemical reactions and achieves accurate alignment with reference intrinsic reaction coordinates, as demonstrated on various small molecule reactions and \\[3+2\\] cycloadditions. Our method enables the exploration of large chemical reaction spaces with efficient, data-driven predictions of reaction pathways.\n\n_\\\\* 14 pages, 6 figures; Supporting Information in ancillary files_\n\nVia![arxiv icon](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Farxiv.41e50dc5.png&w=128&q=75)\n\nGithub Icon [Access Paper or Ask Questions](https://www.catalyzex.com/paper/transferable-learning-of-reaction-pathways)\n\n## [**Predicting Chemical Reaction Outcomes Based on Electron Movements Using Machine Learning**](https://www.catalyzex.com/paper/predicting-chemical-reaction-outcomes-based)\n\n[Github IconRequest Code](https://www.catalyzex.com/s/Chemical%20Reaction%20Prediction) Code for Similar Papers:![Code for Similar Papers](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Frelated_icon_transparent.98f57b13.png&w=96&q=75) [![Add code](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Faddcode_white.6afb879f.png&w=96&q=75)](https://www.catalyzex.com/add_code?title=Predicting Chemical Reaction Outcomes Based on Electron Movements Using Machine Learning&paper_url=http://arxiv.org/abs/2503.10197)\n\n![Bookmark button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbookmark_outline.3a3e1c2c.png&w=828&q=75)\n\n![Alert button](https://www.catalyz...",
      "url": "https://www.catalyzex.com/s/Chemical%20Reaction%20Prediction"
    },
    {
      "title": "The challenge of balancing model sensitivity and robustness in predicting yields: a benchmarking study of amide coupling reactions",
      "text": "[View\u00a0PDF\u00a0Version](https://pubs.rsc.org/en/content/articlepdf/2023/sc/d3sc03902a)[Previous\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2023/sc/d3sc03539e)[Next\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2023/sc/d3sc03641c)\n\nOpen Access Article\nThis Open Access Article is licensed under a [Creative Commons Attribution 3.0 Unported Licence](http://creativecommons.org/licenses/by/3.0/)\n\nDOI:\u00a0[10.1039/D3SC03902A](https://doi.org/10.1039/D3SC03902A)\n(Edge Article)\n[Chem. Sci.](https://doi.org/10.1039/2041-6539/2010), 2023, **14**, 10835-10846\n\n# The challenge of balancing model sensitivity and robustness in predicting yields: a benchmarking study of amide coupling reactions [\u2020](https://pubs.rsc.org/pubs.rsc.org\\#fn1)\n\nZhen\nLiu\na,\nYurii S.\nMoroz\nbcd and Olexandr\nIsayev\n\\*aaDepartment of Chemistry, Mellon College of Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA. E-mail: [olexandr@olexandrisayev.com](mailto:olexandr@olexandrisayev.com)bEnamine Ltd, Ky\u00efv, 02660, UkrainecChemspace LLC, Ky\u00efv, 02094, UkrainedTaras Shevchenko National University of Ky\u00efv, Ky\u00efv, 01601, Ukraine\n\nReceived\n27th July 2023\n, Accepted 12th September 2023\n\nFirst published on 13th September 2023\n\n## Abstract\n\nAccurate prediction of reaction yield is the holy grail for computer-assisted synthesis prediction, but current models have failed to generalize to large literature datasets. To understand the causes and inspire future design, we systematically benchmarked the yield prediction task. We carefully curated and augmented a literature dataset of 41239 amide coupling reactions, each with information on reactants, products, intermediates, yields, and reaction contexts, and provided 3D structures for the molecules. We calculated molecular features related to 2D and 3D structure information, as well as physical and electronic properties. These descriptors were paired with 4 categories of machine learning methods (linear, kernel, ensemble, and neural network), yielding valuable benchmarks about feature and model performance. Despite the excellent performance on a high-throughput experiment (HTE) dataset (R2 around 0.9), no method gave satisfactory results on the literature data. The best performance was an R2 of 0.395 \u00b1 0.020 using the stack technique. Error analysis revealed that reactivity cliff and yield uncertainty are among the main reasons for incorrect predictions. Removing reactivity cliffs and uncertain reactions boosted the R2 to 0.457 \u00b1 0.006. These results highlight that yield prediction models must be sensitive to the reactivity change due to the subtle structure variance, as well as be robust to the uncertainty associated with yield measurements.\n\n## Introduction\n\nComputer-assisted synthesis prediction (CASP) is a field of computational chemistry that aims to develop algorithms and software tools to assist chemists in predicting the outcomes of chemical reactions. CASP uses machine learning (ML) and artificial intelligence (AI) techniques to predict the feasibility, yield, and optimal conditions for a chemical reaction. Recent exploratory studies in the field of reaction predictions, show applications in retrosynthesis, [1,2](https://pubs.rsc.org/pubs.rsc.org#cit1) product prediction, [3\u20135](https://pubs.rsc.org/pubs.rsc.org#cit3) selectivity, [6](https://pubs.rsc.org/pubs.rsc.org#cit6) and other relevant tasks. [7,8](https://pubs.rsc.org/pubs.rsc.org#cit7) Accurately predicting reaction yields is one of the key objectives in CASP as many reaction-related tasks can be framed as yield optimization problems. Yield serves as the ultimate metric for selecting reagents in a single reaction or planning a synthesis pathway. However, despite its importance, predicting the theoretical yield remains challenging because the yield depends on many observable and unobservable factors throughout the reaction process, including the interaction between molecules, environment conditions, and human operations.\n\nWhile impressive yield prediction performance (R2 is around 0.9) has been achieved in many high-throughput experiment (HTE) datasets, the yield prediction R2 score on large literature datasets is usually unsatisfactory. [9\u201316](https://pubs.rsc.org/pubs.rsc.org#cit9) For example, the Doyle group reported an example of predicting reaction yields with a random forest model on the Buchwald\u2013Hartwig HTE dataset. [9](https://pubs.rsc.org/pubs.rsc.org#cit9) The dataset contains 4608 C\u2013N cross-coupling reactions and the R2 score and mean absolute error (MAE) were 0.92 and 7.8%, respectively. Since then, the dataset has become a standard benchmark dataset for many yield prediction models. Schwaller et al. reported a Yield-BERT model for reaction yield predictions. [10](https://pubs.rsc.org/pubs.rsc.org#cit10) Although the R2 score for the yield prediction task was as high as 0.94 on the Buchwald\u2013Hartwig dataset, [9](https://pubs.rsc.org/pubs.rsc.org#cit9) the performance dropped sharply (i.e., R2 around 0.2) on the literature dataset. [17,18](https://pubs.rsc.org/pubs.rsc.org#cit17) The staggering performance difference of yield prediction on the HTE dataset and the literature dataset is widespread. Recently, Grzybowski [11](https://pubs.rsc.org/pubs.rsc.org#cit11) and Glorius [15](https://pubs.rsc.org/pubs.rsc.org#cit15) studied this phenomenon, suggesting that the unsatisfactory ML performance may be due to the popular trend in the literature dataset induced by human bias in experiment design and result reporting. However, augmenting the dataset with zero or low-yield reactions did not significantly improve the performance, indicating that additional factors might degrade the model performance.\n\nTo understand the causes for failures in a large literature dataset, we systematically investigated the yield prediction task. We tested 4 categories of ML models (i.e., linear methods, kernel methods, ensemble methods, and neural networks) on an HTE yield dataset and a large literature yield dataset. We utilized a set of 4608 Buchwald\u2013Hartwig reactions from Doyle [9](https://pubs.rsc.org/pubs.rsc.org#cit9) et al. to represent the HTE dataset, given its extensive prior modeling. We curated 41239 amide coupling reactions from Reaxys [19](https://pubs.rsc.org/pubs.rsc.org#cit19) to represent the literature dataset. These reactions were chosen due to their significance in medicinal chemistry and the substantial volume of available data. While the Buchwald\u2013Hartwig reactions and the amide coupling reactions are very different, they possess characteristics inherent to the HTE and large literature datasets, respectively. The phenomena observed in the context of Buchwald\u2013Hartwig reactions and amide coupling reactions can be extrapolated to typical HTE datasets and large literature datasets, respectively. Besides the SMILES of reactants and products, the reaction context (i.e., time, temperature, reagents, condition, and solvent) was also extracted where possible from Reaxys to construct the amide coupling dataset. Please note that the reaction yields were extracted as they appeared in the Reaxys database, regardless of the reaction scale. Also, we augmented the literature dataset with reaction intermediates, optimized 3D structures of the molecules, and 2D/3D descriptors derived from the SMILES and conformers. All amide coupling reactions were catalyzed by carbodiimides to minimize irrelevant variables in this investigation. The carbodiimides include 1-ethyl-3-(3-dimethylaminopropyl)carbodiimide (EDC), N,N\u2032-dicyclohexylcarbodiimide (DCC), and N,N\u2032-diisopropylcarbodiimide (DIC). The combination of different reaction descriptors and model categories enabled a systematic yield prediction benchmark, providing insights into the key factors that influence the reaction yield prediction challenge.\n\nOur results demonstrated that most models gave unsatisfactory predictions (R2 < 0.5) in a large and diverse literature dataset even if they achieved excellent predictions (R2 \\> 0.9) on a caref...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2023/sc/d3sc03902a"
    }
  ]
}