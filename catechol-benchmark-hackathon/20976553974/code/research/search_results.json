{
  "query": "What machine learning approaches achieve MAE below 0.02 for chemical reaction yield prediction with solvent effects?",
  "results": [
    {
      "title": "ANSWER",
      "text": "The provided sources do not report any machine\u2011learning method that attains a mean absolute error below\u202f0.02 for reaction\u2011yield prediction with solvent effects (e.g., the best reported MAE is 0.71\u202fkcal\u202fmol\u207b\u00b9 for solvation\u2011free\u2011energy predictions) ([chemrxiv](https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/6524d5a4bda59ceb9a38ccec/original/machine-learning-from-quantum-chemistry-to-predict-experimental-solvent-effects-on-reaction-rates.pdf)).",
      "url": ""
    },
    {
      "title": "",
      "text": "Machine learning from quantum chemistry to\npredict experimental solvent effects on reaction\nrates\nYunsie Chung and William H. Green\u2217\nDepartment of Chemical Engineering, Massachusetts Institute of Technology, Cambridge,\nMA, 02139, U.S.A\nE-mail: whgreen@mit.edu\nAbstract\nFast and accurate prediction of solvent effects on reaction rates are crucial for kinetic\nmodeling, chemical process design, and high-throughput solvent screening. Despite the\nrecent advance in machine learning, a scarcity of reliable data has hindered the devel\u0002opment of predictive models that are generalizable for diverse reactions and solvents.\nIn this work, we generate a large set of data with the COSMO-RS method for over\n28,000 neutral reactions and 295 solvents and train a machine learning model to pre\u0002dict the solvation free energy and solvation enthalpy of activation (\u2206\u2206G\n\u2021\nsolv, \u2206\u2206H\n\u2021\nsolv)\nfor a solution phase reaction. On unseen reactions, the model achieves mean absolute\nerrors of 0.71 and 1.03 kcal/mol for \u2206\u2206G\n\u2021\nsolv and \u2206\u2206H\n\u2021\nsolv, respectively, relative to the\nCOSMO-RS calculations. The model also provides reliable predictions of relative rate\nconstants within a factor of 4 when tested on experimental data. The presented model\ncan provide nearly instantaneous predictions of kinetic solvent effects or relative rate\nconstants for a broad range of neutral closed-shell or free radical reactions and solvents\nonly based on atom-mapped reaction SMILES and solvent SMILES strings.\n1\nhttps://doi.org/10.26434/chemrxiv-2023-f20bg-v2 ORCID: https://orcid.org/0000-0002-3097-010X Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\n1 Introduction\nAccurate prediction of reaction rates is essential for modeling a variety of chemical kinetic sys\u0002tems such as pyrolysis, 1,2 polymerization,3 oxidative degradation, 4,5 and atmospheric chem\u0002istry.6 Detailed kinetic models enable one to predict key products, identify major kinetic\npathways, and optimize reaction conditions for complex chemical systems. Kinetic mech\u0002anisms often involve hundreds to tens of thousands of elementary reactions, 7 and a fast,\nhigh-throughput method to estimate reaction rates is thus needed. Ab initio methods like\nquantum mechanics/molecular mechanics (QM/MM) can provide accurate predictions of rate\nconstants, but their high computational cost has been a major limiting factor for large-scale,\nautomated predictions. As more kinetic data become available, data-driven approaches such\nas linear group contribution, 8\u201310 decision tree based rate rules, 11,12 and machine learning\n(ML) models13\u201319 have emerged as more popular choices for estimating kinetic parameters.\nSeveral ML models15\u201317 have successfully predicted barrier heights and rate constants of\ndiverse gas phase reactions only based on readily available 2D information (e.g. SMILES\nstrings) of reactants and products. However, such predictive models for liquid/solution phase\nreactions have been lightly investigated with limited applicability. 20\nSolvents can have significant impacts on reaction rates and outcomes, and it is crucial to\naccurately predict these kinetic solvent effects. Recent research efforts have been devoted\nto employing ML (e.g. deep neural network) for free energy predictions of condensed phase\nreactions.15,18,19,21\u201326 Many of these studies 18,19,21\u201323,26 combine the ML models with semi\u0002empirical or lower-level QM/MM methods to obtain the energy predictions that match the\naccuracy of higher-level QM/MM methods. For example, G\u00b4omez-Flores et al. 19 used a ML\napproach to predict the energy difference between the density functional tight-binding model\nand other higher level QM methods for a thiol-disulfide exchange reaction in water. In a\nstudy by Pan et al.,18 a ML model was trained to reproduce ab initio QM/MM poten\u0002tials in free energy simulations for the aqueous Menshutkin reaction between ammonia and\nchloromethane. Farrar and Grayson26 employed ML models to predict DFT-quality activa\u0002tion barriers for various nitro-Michael addition reactions in toluene based on the features\ngenerated from semi-empirical methods. These approaches, however, require semi-empirical\nQM/MM steps that are less suitable for instantaneous, automatic rate predictions. Fur\u0002thermore, their models are limited to a single solvent and need the 3D coordinates or QM\nfeatures of reactants and transition states as inputs, which are not readily available.\nThe ML models by Jorner et al. 24 and by Heid and Green15 are the few cases that can\npredict reaction properties in multiple solvents only based on the 2D structural information\nof molecules. Jorner et al. 24 employed a Gaussian process regression model and compared\nseveral 2D structural features to predict the barrier height of 443 SNAr reactions in different\nsolvents. In their work, the best accuracy was reached by adopting the BERT27 reaction fin\u0002gerprint. Heid and Green, 15 on the other hand, used the condensed graph of reaction (CGR)\nas an input reaction representation for a graph convolutional neural network (GCNN). They\napplied the CGR GCNN model to the same SNAr data set and were able to achieve better\n2\nhttps://doi.org/10.26434/chemrxiv-2023-f20bg-v2 ORCID: https://orcid.org/0000-0002-3097-010X Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\nbarrier height predictions compared to the other models that used the BERT fingerprint or\ndifferent reaction representations. While these models can provide fast kinetic estimations\nfor solution-phase reactions at a low computational cost, only one reaction family was con\u0002sidered with a relatively small training set. A larger data set that contains more diverse\ntypes of reactions and solvents is needed in order to train a more generalized model for\nkinetic solvent effect predictions. Moreover, both models used fixed descriptors to represent\nsolvents, but prior studies 15,28,29 revealed that the learned molecular representations based\non a graph convolutional approach outperform fixed molecular descriptors in many property\nprediction tasks.\nIn this study, we present a ML model that can predict kinetic solvent effects for a wide range\nof neutral reactions and solvents only based on atom-mapped reaction SMILES and solvent\nSMILES strings. More precisely, the model predicts the solvation free energy and solvation\nenthalpy of activation (\u2206\u2206G\n\u2021\nsolv, \u2206\u2206H\n\u2021\nsolv) for a reaction-solvent pair, which can be used\nto estimate a relative rate constant between a solution phase and a gas phase reaction or\nbetween the reaction in different solvents. Our model adopts a CGR GCNN architecture with\nseparate GCNN layers for solvent molecular encoding. A large, diverse set of training data\ncontaining over 28,000 reactions and 295 solvents is generated in this work by performing\nab initio COSMO-RS30 calculations. The performance of the model on unseen reactions is\nrigorously assessed by comparing the ML predictions with both COSMO-RS calculations\nand experimental data. A transfer learning approach and various additional features are\nexplored to further improve the model. Our ML model can provide accurate predictions of\nrelative rate constants, and together with the existing predictive models or databases for gas\nphase rate constants (e.g. RMG database 12), it can provide the estimates of absolute rate\nconstants for many different liquid phase reactions.\n2 Background on the prediction targets\nFigure 1: Potential energy diagram of a reaction in a gas phase and a solution phase.\n3\nhttps://doi.org/10.26434/chemrxiv-2023-f20bg-v2 ORCID: https://orcid.org/0000-0002-3097-010X Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\nOur ML model aims to predict the solvation free energy and solvation enthalpy of activation\n(\u2206\u2206G\n\u2021\nsolv, \u2206\u2206H\n\u2021\nsolv) at 298 K for a reaction in a solvent. Solvation free energy (\u2206Gsolv)\nand solvation enthalpy (\u2206Hsolv) are the changes in Gibbs free energy and enthalpy when a\nmolecule is transferred from an ideal gas to a solvent at a fixed condition. The \u2206\u2206G\n\u2021\nsolv\nand \u2206\u2206...",
      "url": "https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/6524d5a4bda59ceb9a38ccec/original/machine-learning-from-quantum-chemistry-to-predict-experimental-solvent-effects-on-reaction-rates.pdf"
    },
    {
      "title": "The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning",
      "text": "The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning\n# The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning\nToby Boyne1, Juan S. Campos1, Becky D. Langdon1, Jixiang Qing1, Yilin Xie1\nShiqiang Zhang1, Calvin Tsay1, Ruth Misener1, Daniel W. Davies2, Kim E. Jelfs2\nSarah Boyall3, Thomas M. Dixon3, Linden Schrecker3, Jose Pablo Folch3\u2020\nDepartment of Computing, Imperial College, London, UK1\nDepartment of Chemistry, Imperial College, London, UK2\nSOLVE Chemistry, London, UK3t.boyne23@imperial.ac.uk;\u2020jose@solvechemistry.com\n###### Abstract\nMachine learning has promised to change the landscape of laboratory chemistry, with impressive results in molecular property prediction and reaction retro-synthesis. However, chemical datasets are often inaccessible to the machine learning community as they tend to require cleaning, thorough understanding of the chemistry, or are simply not available. In this paper, we introduce a novel dataset for yield prediction, providing the first-ever transient flow dataset for machine learning benchmarking, covering over 1200 process conditions. While previous datasets focus on discrete parameters, our experimental set-up allow us to sample a large number of continuous process conditions, generating new challenges for machine learning models. We focus on solvent selection, a task that is particularly difficult to model theoretically and therefore ripe for machine learning applications. We showcase benchmarking for regression algorithms, transfer-learning approaches, feature engineering, and active learning, with important applications towards solvent replacement and sustainable manufacturing.\n## 1Introduction\nMachine learning (ML) and artificial intelligence (AI) have showcased enormous potential in empowering the world of the natural sciences: from famous examples such as AlphaFold for protein predictions> [\n[> 1\n](https://arxiv.org/html/2506.07619v1#bib.bib1)> ]\n, to fusion reactor control> [\n[> 2\n](https://arxiv.org/html/2506.07619v1#bib.bib2)> ]\n, disease detection> [\n[> 3\n](https://arxiv.org/html/2506.07619v1#bib.bib3)> ]\n, battery design> [\n[> 4\n](https://arxiv.org/html/2506.07619v1#bib.bib4)> ]\n, and material discovery> [\n[> 5\n](https://arxiv.org/html/2506.07619v1#bib.bib5)> ]\n, among many more. However, we seldom see the machine learning community benchmark new methods in physical science datasets, mostly due to the difficulty in cleaning real-world data, the need for interdisciplinary understanding to correctly benchmark, and most importantly, how expensive the data can be to produce, resulting in many datasets being locked behind closed doors by large companies.\nAIchemy ([https://aichemy.ac.uk](https://aichemy.ac.uk)) is an interdisciplinary UK hub with the mission of transforming the chemistry-AI interface via aiding the collaboration of chemists and AI researchers, as well as addressing gaps in data standards, curation, and availability for AI use. In partnership with SOLVE Chemistry ([https://www.solvechemistry.com](https://www.solvechemistry.com)), we present a first important step into addressing the dataset gap with the introduction of a new and unique open dataset for benchmarking low-data machine learning algorithms for chemistry.\nSolvent selection is one of the biggest challenges for chemical manufacturing, with solvents often being the main source of waste in the manufacturing process> [\n[> 6\n](https://arxiv.org/html/2506.07619v1#bib.bib6)> ]\n. Increased regulation on solvents and a drive to making process manufacturing more sustainable led to an interest in the discovery of greener solvents and for improved solvent replacement tools. However, most of the solvent replacement tools focus purely on learning unsupervised representations of solvents, with the hope that experimentalists can find solvents with similar properties to replace those with environmental concerns. A much stronger approach would consider the interaction of a variety of different solvents with a reaction of interest to directly predict reaction yields, in such a way that the best possible solvent can be selected according to a yield-sustainability trade-off.\nMachine learning approaches have been shown to be a powerful tool for the prediction of chemical reaction conditions. Success has been reported in retro-synthesis> [\n[> 7\n](https://arxiv.org/html/2506.07619v1#bib.bib7)> , [> 8\n](https://arxiv.org/html/2506.07619v1#bib.bib8)> ]\n, condition recommendations> [\n[> 9\n](https://arxiv.org/html/2506.07619v1#bib.bib9)> ]\n, product predictions> [\n[> 10\n](https://arxiv.org/html/2506.07619v1#bib.bib10)> , [> 11\n](https://arxiv.org/html/2506.07619v1#bib.bib11)> ]\n, among others. While yield prediction has proven to be more difficult due to large inconsistencies in procedure and data reporting> [\n[> 12\n](https://arxiv.org/html/2506.07619v1#bib.bib12)> ]\n, we have still seen promising yield prediction results for smaller and more carefully curated datasets> [\n[> 13\n](https://arxiv.org/html/2506.07619v1#bib.bib13)> , [> 14\n](https://arxiv.org/html/2506.07619v1#bib.bib14)> , [> 15\n](https://arxiv.org/html/2506.07619v1#bib.bib15)> , [> 16\n](https://arxiv.org/html/2506.07619v1#bib.bib16)> ]\n. However, these datasets lack the continuous reaction conditions, such as temperature and residence time, that are required to scale-up processes to practical manufacturing conditions.\nIn this paper, we release the first machine-learning-ready transient flow dataset, a framework that allows for quick and efficient screening of continuous reaction conditions. We specifically provide yield data over the uni-molecular allyl substituted catechol reaction, shown in Figure[1](https://arxiv.org/html/2506.07619v1#S1.F1), with dense measurements across the residence time, temperature, and solvent space. We further showcase how this type ofkinetic dataposes new challenges to current machine learning methods for chemistry, and identify how the challenges can potentially be tackled by the community.\n![Refer to caption](extracted/6524982/figures/Project2_rxn.png)Figure 1:Data was gathered on the rearrangement of allyl substituted catechol. By subjecting the reaction mixture to high temperatures, we begin a cascade reaction forming multiple rearrangement products. We investigate the yield of the reaction for a range of different solvents. Product 1 was not observed and reacted immediately to form Product 2 and later 3.\n### 1.1Related works\nReaction datasets are common in chemistry research, but their suitability for machine learning benchmarking tends to be poor. This can be a result of improper formatting or documentation, incomplete information about reaction conditions or the experimental set-up, or the lack of machine readability, leading to limited usage by the ML community. However, some effort has been made to address this, with the biggest example being the creation of the Open Reaction Database (ORD)> [\n[> 17\n](https://arxiv.org/html/2506.07619v1#bib.bib17)> ]\n, a repository containing over 2M different reactions, many of which come from US patent data (USPTO)> [\n[> 18\n](https://arxiv.org/html/2506.07619v1#bib.bib18)> ]\n. However, the dataset falls short in some aspects, in particular with respect to machine learning readiness and data inconsistencies across reactions.\nORDerly> [\n[> 12\n](https://arxiv.org/html/2506.07619v1#bib.bib12)> ]\nallows for easy cleaning and preparation of ORD data, showing the promise of the dataset for forward and retro-synthetic prediction using transformers; however, it also shows that yield prediction cannot be done well due to data inconsistencies.> Schwaller et\u00a0al. [\n[> 13\n](https://arxiv.org/html/2506.07619v1#bib.bib13)> ]\ndrew similar conclusions when using the USPTO dataset, stating that reaction conditions such as temperature, concentrations, and duration have a significant effect on yield. The assumption that every reaction in the dataset is optimized for reaction param...",
      "url": "https://arxiv.org/html/2506.07619v1"
    },
    {
      "title": "Yield Prediction via Local-to-global Reaction Representation Learning and Interaction Modeling",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/html/2411.03320v3"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2512.19530] Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2512.19530\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2512.19530**(cs)\n[Submitted on 22 Dec 2025]\n# Title:Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\nAuthors:[Hongsheng Xing](https://arxiv.org/search/cs?searchtype=author&amp;query=Xing,+H),[Qiuxin Si](https://arxiv.org/search/cs?searchtype=author&amp;query=Si,+Q)\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n[View PDF](https://arxiv.org/pdf/2512.19530)[HTML (experimental)](https://arxiv.org/html/2512.19530v1)> > Abstract:\n> Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \\textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.\n> Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \\textbf{MSE of 0.0039} ($\\pm$ 0.0003), representing a 60\\% error reduction over competitive baselines and a $&gt;25\\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning. Comments:|13 pages, 6 figures|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI)|\nMSCclasses:|68T07, 92E20, 62M45|\nACMclasses:|I.2.1; I.2.6; J.2|\nCite as:|[arXiv:2512.19530](https://arxiv.org/abs/2512.19530)[cs.LG]|\n|(or[arXiv:2512.19530v1](https://arxiv.org/abs/2512.19530v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2512.19530](https://doi.org/10.48550/arXiv.2512.19530)\nFocus to learn more\narXiv-issued DOI via DataCite (pending registration)\n|\n## Submission history\nFrom: Hongsheng Xing [[view email](https://arxiv.org/show-email/9dc7457b/2512.19530)]\n**[v1]**Mon, 22 Dec 2025 16:19:01 UTC (2,198 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n* [View PDF](https://arxiv.org/pdf/2512.19530)\n* [HTML (experimental)](https://arxiv.org/html/2512.19530v1)\n* [TeX Source](https://arxiv.org/src/2512.19530)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2512.19530&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2512.19530&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2025-12](https://arxiv.org/list/cs.LG/2025-12)\nChange to browse by:\n[cs](https://arxiv.org/abs/2512.19530?context=cs)\n[cs.AI](https://arxiv.org/abs/2512.19530?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2512.19530)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2512.19530)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2512.19530)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2512.19530&amp;description=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2512.19530&amp;title=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.or...",
      "url": "https://arxiv.org/abs/2512.19530"
    },
    {
      "title": "Estimation of multicomponent reactions\u2019 yields from networks of mechanistic steps",
      "text": "Estimation of multicomponent reactions\u2019 yields from networks of mechanistic steps\n\n[Download PDF](https://www.nature.com/articles/s41467-024-54550-1.pdf)\n\n[Download PDF](https://www.nature.com/articles/s41467-024-54550-1.pdf)\n\n### Subjects\n\n- [Cheminformatics](https://www.nature.com/subjects/cheminformatics)\n- [Synthetic chemistry methodology](https://www.nature.com/subjects/methodology)\n\n## Abstract\n\nThis work describes estimation of yields of complex, multicomponent reactions (MCRs) based on the modeled networks of mechanistic steps spanning both the main reaction pathway as well as immediate and downstream side reactions. Because experimental values of the kinetic rate constants for individual mechanistic transforms are extremely sparse, these constants are approximated here using Mayr\u2019s nucleophilicity and electrophilicity parameters fine-tuned by correction terms grounded in linear free-energy relationships. With this formalism, the model trained on the mechanistic networks of only 20 \u2013 but mechanistically- and yield-diverse MCRs \u2013 transfers well to newly discovered MCRs that are based on markedly different mechanisms and types of individual mechanistic transforms. These results suggest that mechanistic-level approach to yield estimation may be a useful alternative to models that are derived from full-reaction data and lack information about yield-lowering side reactions.\n\n### Similar content being viewed by others\n\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-024-54611-5/MediaObjects/41467_2024_54611_Fig1_HTML.png)\n\n### [Systematic, computational discovery of multicomponent and one-pot reactions](https://www.nature.com/articles/s41467-024-54611-5?fromPaywallRec=false)\n\nArticleOpen access27 November 2024\n\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs43588-022-00369-z/MediaObjects/43588_2022_369_Fig1_HTML.png)\n\n### [Chemical reaction networks and opportunities for machine learning](https://www.nature.com/articles/s43588-022-00369-z?fromPaywallRec=false)\n\nArticle16 January 2023\n\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41586-023-06854-3/MediaObjects/41586_2023_6854_Fig1_HTML.png)\n\n### [Computational prediction of complex cationic rearrangement outcomes](https://www.nature.com/articles/s41586-023-06854-3?fromPaywallRec=false)\n\nArticle15 November 2023\n\n## Introduction\n\nThe ability to predict or, at least, estimate the yields of organic reactions would be of tremendous value for synthetic chemistry, limiting the number of unproductive experiments, minimizing the use of solvents and reagents, and lowering the overall monetary and environmental cost of chemical production. Not surprisingly, there have been many attempts to develop algorithms for that purpose. In our own work, we evaluated both thermodynamic models based on optimized free-energy group contributions (assuming thermodynamic control)[1](https://www.nature.com/articles/s41467-024-54550-1#ref-CR1) as well as machine-learning, ML, methods[2](https://www.nature.com/articles/s41467-024-54550-1#ref-CR2), [3](https://www.nature.com/articles/s41467-024-54550-1#ref-CR3); others have since focused on various ML approaches. Despite some early optimism[4](https://www.nature.com/articles/s41467-024-54550-1#ref-CR4), [5](https://www.nature.com/articles/s41467-024-54550-1#ref-CR5), subsequent studies revealed relatively low correlations between experimental and predicted yield values \u2013 not only in collections of diverse reaction types[2](https://www.nature.com/articles/s41467-024-54550-1#ref-CR2), [6](https://www.nature.com/articles/s41467-024-54550-1#ref-CR6) but also within larger sets of same-type reactions[3](https://www.nature.com/articles/s41467-024-54550-1#ref-CR3), [6](https://www.nature.com/articles/s41467-024-54550-1?error=cookies_not_supported&code=a3f20b14-8359-4f22-8131-986876dd4328#ref-CR6), [7](https://www.nature.com/articles/s41467-024-54550-1?error=cookies_not_supported&code=a3f20b14-8359-4f22-8131-986876dd4328#ref-CR7), [8](https://www.nature.com/articles/s41467-024-54550-1#ref-CR8). Pondering the reason for this unsatisfactory performance, we observe that all efforts to date learned on full, substrate-to-product reactions, as typically reported in the literature and/or electronic notebooks. Such full-reaction data does not capture reactions\u2019 mechanistic intricacies \u2013 in particular, it has no explicit knowledge of possible side reactions that can lead to undesired outcomes and lower the yields. Some of this knowledge could, in principle, be captured through adequately large[9](https://www.nature.com/articles/s41467-024-54550-1#ref-CR9) numbers of examples of failed reactions but these are typically not published, and the distributions of yields in literature datasets are heavily skewed toward higher values (with a mean approaching 80%[2](https://www.nature.com/articles/s41467-024-54550-1#ref-CR2)).\n\nGiven these limitations, we recently began to teach the computer mechanistic transformations which, when applied to desired substrates, propagate large networks of mechanistic steps. In ref. [10](https://www.nature.com/articles/s41467-024-54550-1#ref-CR10)., we encoded some 400 mechanistic steps specific to carbocations, and used the network approach to predict the mechanisms of complex carbocationic rearrangements. Therein, we parametrized the heights of kinetic barriers (based on quantum-mechanical calculations) and used this knowledge of kinetics to predict products\u2019 distributions and yields. More recently, we deployed a much larger set of ~8000 general-scope mechanistic transforms (cf. below) and applied them to multiple small-molecule substrates. This effort was intended to trace mechanistic pathways defining new multicomponent reactions, MCRs, which are particularly appealing because they offer high atom-economy, minimize separation and purification operations, and can yield complex scaffolds that are often less prone to follow-up or side reactions than non-MCR reactions. Indeed, in ref. [11](https://www.nature.com/articles/s41467-024-54550-1#ref-CR11). we described how such analyses enable systematic discovery of plausible MCRs candidates, of which multiple we validated by experiment. An essential part of this effort has been the ability to estimate the yields of these MCRs \u2013 would multicomponent substrate mixtures result in a mixture of low-yielding products, or would they lead to a major product in good yield? Unfortunately, given the number and diversity of mechanistic steps in the 8000 set, QM calculations of kinetic barriers have proven prohibitive \u2013 instead, we pursued and describe here a physical-organic approach in which kinetics of mechanistic steps is approximated by using nucleophilicity and electrophilicity indices and linear free-energy relationships. We train this model on the mechanistic networks of 20 known MCRs (chosen to span a wide range of yields, Fig.\u00a0[1a, c](https://www.nature.com/articles/s41467-024-54550-1#Fig1)) and then apply it to predict the yields of our newly-discovered MCRs (Fig.\u00a0[1b, d](https://www.nature.com/articles/s41467-024-54550-1#Fig1)) that not only use different substrates but are also based on unprecedented mechanisms. Despite such fundamental mechanistical differences, the model transfers between the training and testing MCRs, achieving similar\u2013 and in the light of previous effort, quite satisfactory \u2013 performance metrics (e.g., mean absolute errors, MAE\u2009=\u200910.5% and 7.3%, respectively). These results suggest that mechanistic-level approach to yield estimation may be a useful alternative to models derived from full reaction data, although \u2013 as we also emphasize in our discussion \u2013 it is certainly pending future extensions of the 8000 rule set and validation on larger sets of mechanistic networks.\n\n**Fig. 1: Multicomponent reactions, MCRs, used to train and test the model.**\n\n[![figure 1](https://media.springernatu...",
      "url": "https://www.nature.com/articles/s41467-024-54550-1?error=cookies_not_supported&code=a3f20b14-8359-4f22-8131-986876dd4328"
    },
    {
      "title": "Predicting Chemical Reaction Yields",
      "text": "Predicting Chemical Reaction Yields | RXN yield prediction\n* * [rxn\\_yields](#)\n* [Overview](https://rxn4chemistry.github.io/rxn_yields//)\n* [Data](https://rxn4chemistry.github.io/rxn_yields/data)\n* [Training Tutorial](https://rxn4chemistry.github.io/rxn_yields/model_training)\n* [Evaluation Buchwald Hartwig](https://rxn4chemistry.github.io/rxn_yields/results_evaluation_of_buchwald_hartwig_yields_prediction)\n* [Evaluation Suzuki Miyaura](https://rxn4chemistry.github.io/rxn_yields/results_evaluation_of_suzuki_miyaura_yields_prediction)\n* [USPTO Exploration](https://rxn4chemistry.github.io/rxn_yields/uspto_data_exploration)\n# Predicting Chemical Reaction Yields\nPredicting the yield of a chemical reaction from a reaction SMILES using Transformers\nArtificial intelligence is driving one of the most important revolutions in organic chemistry. Multiple platforms, including tools for reaction prediction and synthesis planning based on machine learning, successfully became part of the organic chemists\u2019 daily laboratory, assisting in domain-specific synthetic problems. Unlike reaction prediction and retrosynthetic models, reaction yields models have been less investigated, despite the enormous potential of accurately predicting them. Reaction yields models, describing the percentage of the reactants that is converted to the desired products, could guide chemists and help them select high-yielding reactions and score synthesis routes, reducing the number of attempts. So far, yield predictions have been predominantly performed for high-throughput experiments using a categorical (one-hot) encoding of reactants, concatenated molecular fingerprints, or computed chemical descriptors. Here, we extend the application of natural language processing architectures to predict reaction properties given a text-based representation of the reaction, using an encoder transformer model combined with a regression layer. We demonstrate outstanding prediction performance on two high-throughput experiment reactions sets. An analysis of the yields reported in the open-source USPTO data set shows that their distribution differs depending on the mass scale, limiting the dataset applicability in reaction yields predictions.\nThis repository complements our studies on[predicting chemical reaction yields](https://iopscience.iop.org/article/10.1088/2632-2153/abc81d)(published in Machine Learning: Science and Technology) and[data augmentation and uncertainty estimation for yield predictions](https://doi.org/10.26434/chemrxiv.13286741)(presented at the Machine Learning for Molecules Workshop at NeurIPS 2020).\n## Install[](#Install)\nAs the library is based on the chemoinformatics toolkit[RDKit](http://www.rdkit.org)it is best installed using the[Anaconda](https://docs.conda.io/en/latest/miniconda.html)package manager. Once you have conda, you can simply run:\n```\n`conda create -n yields python=3.6 -y\nconda activate yields\nconda install -c rdkit rdkit=2020.03.3.0 -y\nconda install -c tmap tmap -y`\n```\n```\n`git clone https://github.com/rxn4chemistry/rxn\\_yields.git\ncd rxn\\_yields\npip install -e .`\n```\n**NOTE:**\nIf you are fine-tuning your own models. Make sure that the pretrained model (from which you start training) is loaded from a folder with the same structure as for our[rxnfp models](https://github.com/rxn4chemistry/rxnfp/tree/master/rxnfp/models/transformers/bert_pretrained).\n## Approach - predicting yields from reaction SMILES[](#Approach---predicting-yields-from-reaction-SMILES)\nTransformer models have recently revolutionised Natural Language Processing and were also successfully applied to task in chemistry, using a text-based representation of molecules and chemical reactions called Simplified molecular-input line-entry system (SMILES).\nSequence-2-Sequence transformers as in[Attention is all you need](http://papers.nips.cc/paper/7181-attention-is-all-you-need)were used for:\n* Chemical Reaction Prediction\n* [Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction](https://pubs.acs.org/doi/full/10.1021/acscentsci.9b00576)\n* [Carbohydrate Transformer: Predicting Regio- and Stereoselective Reactions Using Transfer Learning](http://dx.doi.org/10.26434/chemrxiv.11935635)\n* Multi-step retrosynthesis\n* [Predicting retrosynthetic pathways using a combined linguistic model and hyper-graph exploration strategy](http://dx.doi.org/10.1039/c9sc05704h)\n* [Unassisted Noise-Reduction of Chemical Reactions Data Sets](https://chemrxiv.org/articles/Unassisted_Noise-Reduction_of_Chemical_Reactions_Data_Sets/12395120/1)\nEncoder Transformers like[BERT](https://openreview.net/forum?id=SkZmKmWOWH)and[ALBERT](https://openreview.net/forum?id=H1eA7AEtvS)for:\n* Reaction fingerprints and classification\n* [Mapping the Space of Chemical Reactions using Attention-Based Neural Networks](https://chemrxiv.org/articles/Data-Driven_Chemical_Reaction_Classification_with_Attention-Based_Neural_Networks/9897365)\n* Atom rearrangements during chemical reactions\n* [Unsupervised Attention-Guided Atom-Mapping](https://chemrxiv.org/articles/Unsupervised_Attention-Guided_Atom-Mapping/12298559)\nThose studies show that Transformer models are able to learn organic chemistry and chemical reactions from SMILES.\nHere we asked the question, how well a**BERT**model would perform when applied to a**yield prediction**task:\n![](https://rxn4chemistry.github.io/rxn_yields/images/pipeline.jpg)\n**Figure:**Pipeline and task description.\nTo do so, we started with the reaction fingerprint models from the[rxnfp](https://rxn4chemistry.github.io/rxnfp/)library and added a fine-tuning regression head through[SimpleTransformers.ai](https://simpletransformers.ai). As we don't need to change the hyperparameters of the base model, we only tune the learning rate for the training and the dropout probability.\nWe explored two high-throughput experiment (HTE) data sets and then also the yields data found in the USPTO data base.\n## Buchwald-Hartwig HTE data set[](#Buchwald-Hartwig-HTE-data-set)\n### Canonical reaction representation[](#Canonical-reaction-representation)\nOne of the best studied reaction yield is the one that was published by Ahneman et al. in[Predicting reaction performance in C\u2013N cross-coupling using machine learning](https://science.sciencemag.org/content/360/6385/186.full), where the authors have used DFT-computed descriptors as inputs to different machine learning descriptors. There best model was a random forest model. More recently,[one-hot encodings](https://science.sciencemag.org/content/362/6416/eaat8603)and[multi-fingerprint features (MFF)](https://www.sciencedirect.com/science/article/pii/S2451929420300851)as input representations were investigated. Here, we show competitive results starting simply from a text-based reaction SMILES input to our models.\n![](https://rxn4chemistry.github.io/rxn_yields/images/buchwald_hartwig.jpg)\n**Figure:**a) Summary of the results on the Buchwald\u2013Hartwig data set. b) Example regression plot for the first random-split.\n### Augmentated reaction representations[](#Augmentated-reaction-representations)\nWe were able to further improve the results on this data set using data augmentation on reaction SMILES (molecule order permuations and SMILES randomisations). This extension will be presented at the NeurIPS 2020[Machine Learning for Molecules Workshop](https://nips.cc/Conferences/2020/ScheduleMultitrack?event=16136).\n![](https://rxn4chemistry.github.io/rxn_yields/images/rxn_randomizations.png)\n**Figure:**The two different data augmentation techniques investigated in the NeurIPS workshop paper.\n#### Results[](#Results)\n![](https://rxn4chemistry.github.io/rxn_yields/images/results_augm.png)\n**Figure:**a) Results on the 70/30 random splits, averaged over 10 splits. b) Comparison of DFT descriptors + RF, canonical SMILES and data augmented randomized SMILES on reduced training sets. c) Out-of-sample test sets\nOn random splits 70/30 in a), the data augmented Yield-BERT models perform better than ...",
      "url": "https://rxn4chemistry.github.io/rxn_yields"
    },
    {
      "title": "Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates",
      "text": "[Skip to main content](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#main-content)\n\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-dot-gov.svg)\n\n**Official websites use .gov**\n\nA\n**.gov** website belongs to an official\ngovernment organization in the United States.\n\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-https.svg)\n\n**Secure .gov websites use HTTPS**\n\nA **lock** (\nLock\nLocked padlock icon\n) or **https://** means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n\nSearch PMC Full-Text ArchiveSearch in PMC![Search](https://pmc.ncbi.nlm.nih.gov/static/img/usa-icons-bg/search--white.svg)\n\n- [Advanced Search](https://www.ncbi.nlm.nih.gov/pmc/advanced/)\n- [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n- [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n\nNewTry this search in PMC Beta Search\n\n- ## PERMALINK\n\n\n\nCopy\n\n\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\n\nLearn more:\n[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)\n\\|\n[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\n![Chemical Science logo](https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-chemsci.gif)\n\nChem Sci\n\n. 2024 Jan 10;15(7):2410\u20132424. doi: [10.1039/d3sc05353a](https://doi.org/10.1039/d3sc05353a)\n\n# Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates[\u2020](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/\\#fn1)\n\n[Yunsie Chung](https://pubmed.ncbi.nlm.nih.gov/?term=%22Chung%20Y%22%5BAuthor%5D)\n\n### Yunsie Chung\n\naDepartment of Chemical Engineering, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA, Email: whgreen@mit.edu\n\nFind articles by [Yunsie Chung](https://pubmed.ncbi.nlm.nih.gov/?term=%22Chung%20Y%22%5BAuthor%5D)\n\na, [William H Green](https://pubmed.ncbi.nlm.nih.gov/?term=%22Green%20WH%22%5BAuthor%5D)\n\n### William H Green\n\naDepartment of Chemical Engineering, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA, Email: whgreen@mit.edu\n\nFind articles by [William H Green](https://pubmed.ncbi.nlm.nih.gov/?term=%22Green%20WH%22%5BAuthor%5D)\n\na,\u2709\n\n- Author information\n- Article notes\n- Copyright and License information\n\naDepartment of Chemical Engineering, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA, Email: whgreen@mit.edu\n\n\u2709\n\nCorresponding author.\n\nReceived 2023 Oct 10; Accepted 2024 Jan 4; Collection date 2024 Feb 14.\n\nThis journal is \u00a9 The Royal Society of Chemistry\n\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nPMCID: PMC10866337\u00a0\u00a0PMID: [38362410](https://pubmed.ncbi.nlm.nih.gov/38362410/)\n\n## Abstract\n\nFast and accurate prediction of solvent effects on reaction rates are crucial for kinetic modeling, chemical process design, and high-throughput solvent screening. Despite the recent advance in machine learning, a scarcity of reliable data has hindered the development of predictive models that are generalizable for diverse reactions and solvents. In this work, we generate a large set of data with the COSMO-RS method for over 28\u2009000 neutral reactions and 295 solvents and train a machine learning model to predict the solvation free energy and solvation enthalpy of activation (\u0394\u0394 _G_\u2021solv, \u0394\u0394 _H_\u2021solv) for a solution phase reaction. On unseen reactions, the model achieves mean absolute errors of 0.71 and 1.03 kcal mol\u22121 for \u0394\u0394 _G_\u2021solv and \u0394\u0394 _H_\u2021solv, respectively, relative to the COSMO-RS calculations. The model also provides reliable predictions of relative rate constants within a factor of 4 when tested on experimental data. The presented model can provide nearly instantaneous predictions of kinetic solvent effects or relative rate constants for a broad range of neutral closed-shell or free radical reactions and solvents only based on atom-mapped reaction SMILES and solvent SMILES strings.\n\n* * *\n\nA machine learning model, trained on a large COSMO-RS dataset, enables accurate and rapid predictions of solvation effects on reaction rates for diverse reactions and solvents only based on atom-mapped reaction SMILES and solvent SMILES. [![graphic file with name d3sc05353a-ga.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/5ada/10866337/94a59c069033/d3sc05353a-ga.jpg)](https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=10866337_d3sc05353a-ga.jpg)\n\n## 1\\. Introduction\n\nAccurate prediction of reaction rates is essential for modeling a variety of chemical kinetic systems such as pyrolysis,[1,2](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit1) polymerization,[3](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit3) oxidative degradation,[4,5](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit4) and atmospheric chemistry.[6](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit6) Detailed kinetic models enable one to predict key products, identify major kinetic pathways, and optimize reaction conditions for complex chemical systems. Kinetic mechanisms often involve hundreds to tens of thousands of elementary reactions,[7](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit7) and a fast, high-throughput method to estimate reaction rates is thus needed. _Ab initio_ methods like quantum mechanics/molecular mechanics (QM/MM) can provide accurate predictions of rate constants, but their high computational cost has been a major limiting factor for large-scale, automated predictions. As more kinetic data become available, data-driven approaches such as linear group contribution,[8\u201310](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit8) decision tree based rate rules,[11,12](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit11) and machine learning (ML) models[13\u201319](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit13) have emerged as more popular choices for estimating kinetic parameters. Several ML models[15\u201317](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit15) have successfully predicted barrier heights and rate constants of diverse gas phase reactions only based on readily available 2D information ( _e.g._ SMILES strings) of reactants and products. However, such data-driven models for liquid/solution phase reactions have been lightly investigated with limited applicability,[20](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit20) and most approaches rely on the _ab initio_ methods with either implicit or explicit solvation models.[21,22](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit21)\n\nSolvents can have significant impacts on reaction rates and outcomes, and it is crucial to accurately predict these kinetic solvent effects. Recent research efforts have been devoted to employing ML ( _e.g._ deep neural network) for free energy predictions of condensed phase reactions.[15,18,19,23\u201328](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit15) Many of these studies[18,19,23\u201325,28](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit18) combine the ML models with semi-empirical or lower-level QM/MM methods to obtain the energy predictions that match the accuracy of higher-level QM/MM methods. For example, G\u00f3mez-Flores _et al._ [19](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit19) used a ML approach to predict the energy difference between the density functional tight-binding model and other higher level QM methods for a thiol-disulfide exchange reaction in water. In a study by Pan _et al._,[18](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit18) a ML model was trained to reproduce _ab initio_ QM/MM potentials in free energy simulations for the aqueous Menshutkin reaction between ammonia and chloromethane. Farrar and Grayson[28](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit28) employed ML models to predict DFT-quality activation barriers for various nitro-Michael ad...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337"
    },
    {
      "title": "The challenge of balancing model sensitivity and robustness in predicting yields: a benchmarking study of amide coupling reactions",
      "text": "[View\u00a0PDF\u00a0Version](https://pubs.rsc.org/en/content/articlepdf/2023/sc/d3sc03902a)[Previous\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2023/sc/d3sc03539e)[Next\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2023/sc/d3sc03641c)\n\nOpen Access Article\nThis Open Access Article is licensed under a [Creative Commons Attribution 3.0 Unported Licence](http://creativecommons.org/licenses/by/3.0/)\n\nDOI:\u00a0[10.1039/D3SC03902A](https://doi.org/10.1039/D3SC03902A)\n(Edge Article)\n[Chem. Sci.](https://doi.org/10.1039/2041-6539/2010), 2023, **14**, 10835-10846\n\n# The challenge of balancing model sensitivity and robustness in predicting yields: a benchmarking study of amide coupling reactions [\u2020](https://pubs.rsc.org/pubs.rsc.org\\#fn1)\n\nZhen\nLiu\na,\nYurii S.\nMoroz\nbcd and Olexandr\nIsayev\n\\*aaDepartment of Chemistry, Mellon College of Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA. E-mail: [olexandr@olexandrisayev.com](mailto:olexandr@olexandrisayev.com)bEnamine Ltd, Ky\u00efv, 02660, UkrainecChemspace LLC, Ky\u00efv, 02094, UkrainedTaras Shevchenko National University of Ky\u00efv, Ky\u00efv, 01601, Ukraine\n\nReceived\n27th July 2023\n, Accepted 12th September 2023\n\nFirst published on 13th September 2023\n\n## Abstract\n\nAccurate prediction of reaction yield is the holy grail for computer-assisted synthesis prediction, but current models have failed to generalize to large literature datasets. To understand the causes and inspire future design, we systematically benchmarked the yield prediction task. We carefully curated and augmented a literature dataset of 41239 amide coupling reactions, each with information on reactants, products, intermediates, yields, and reaction contexts, and provided 3D structures for the molecules. We calculated molecular features related to 2D and 3D structure information, as well as physical and electronic properties. These descriptors were paired with 4 categories of machine learning methods (linear, kernel, ensemble, and neural network), yielding valuable benchmarks about feature and model performance. Despite the excellent performance on a high-throughput experiment (HTE) dataset (R2 around 0.9), no method gave satisfactory results on the literature data. The best performance was an R2 of 0.395 \u00b1 0.020 using the stack technique. Error analysis revealed that reactivity cliff and yield uncertainty are among the main reasons for incorrect predictions. Removing reactivity cliffs and uncertain reactions boosted the R2 to 0.457 \u00b1 0.006. These results highlight that yield prediction models must be sensitive to the reactivity change due to the subtle structure variance, as well as be robust to the uncertainty associated with yield measurements.\n\n## Introduction\n\nComputer-assisted synthesis prediction (CASP) is a field of computational chemistry that aims to develop algorithms and software tools to assist chemists in predicting the outcomes of chemical reactions. CASP uses machine learning (ML) and artificial intelligence (AI) techniques to predict the feasibility, yield, and optimal conditions for a chemical reaction. Recent exploratory studies in the field of reaction predictions, show applications in retrosynthesis, [1,2](https://pubs.rsc.org/pubs.rsc.org#cit1) product prediction, [3\u20135](https://pubs.rsc.org/pubs.rsc.org#cit3) selectivity, [6](https://pubs.rsc.org/pubs.rsc.org#cit6) and other relevant tasks. [7,8](https://pubs.rsc.org/pubs.rsc.org#cit7) Accurately predicting reaction yields is one of the key objectives in CASP as many reaction-related tasks can be framed as yield optimization problems. Yield serves as the ultimate metric for selecting reagents in a single reaction or planning a synthesis pathway. However, despite its importance, predicting the theoretical yield remains challenging because the yield depends on many observable and unobservable factors throughout the reaction process, including the interaction between molecules, environment conditions, and human operations.\n\nWhile impressive yield prediction performance (R2 is around 0.9) has been achieved in many high-throughput experiment (HTE) datasets, the yield prediction R2 score on large literature datasets is usually unsatisfactory. [9\u201316](https://pubs.rsc.org/pubs.rsc.org#cit9) For example, the Doyle group reported an example of predicting reaction yields with a random forest model on the Buchwald\u2013Hartwig HTE dataset. [9](https://pubs.rsc.org/pubs.rsc.org#cit9) The dataset contains 4608 C\u2013N cross-coupling reactions and the R2 score and mean absolute error (MAE) were 0.92 and 7.8%, respectively. Since then, the dataset has become a standard benchmark dataset for many yield prediction models. Schwaller et al. reported a Yield-BERT model for reaction yield predictions. [10](https://pubs.rsc.org/pubs.rsc.org#cit10) Although the R2 score for the yield prediction task was as high as 0.94 on the Buchwald\u2013Hartwig dataset, [9](https://pubs.rsc.org/pubs.rsc.org#cit9) the performance dropped sharply (i.e., R2 around 0.2) on the literature dataset. [17,18](https://pubs.rsc.org/pubs.rsc.org#cit17) The staggering performance difference of yield prediction on the HTE dataset and the literature dataset is widespread. Recently, Grzybowski [11](https://pubs.rsc.org/pubs.rsc.org#cit11) and Glorius [15](https://pubs.rsc.org/pubs.rsc.org#cit15) studied this phenomenon, suggesting that the unsatisfactory ML performance may be due to the popular trend in the literature dataset induced by human bias in experiment design and result reporting. However, augmenting the dataset with zero or low-yield reactions did not significantly improve the performance, indicating that additional factors might degrade the model performance.\n\nTo understand the causes for failures in a large literature dataset, we systematically investigated the yield prediction task. We tested 4 categories of ML models (i.e., linear methods, kernel methods, ensemble methods, and neural networks) on an HTE yield dataset and a large literature yield dataset. We utilized a set of 4608 Buchwald\u2013Hartwig reactions from Doyle [9](https://pubs.rsc.org/pubs.rsc.org#cit9) et al. to represent the HTE dataset, given its extensive prior modeling. We curated 41239 amide coupling reactions from Reaxys [19](https://pubs.rsc.org/pubs.rsc.org#cit19) to represent the literature dataset. These reactions were chosen due to their significance in medicinal chemistry and the substantial volume of available data. While the Buchwald\u2013Hartwig reactions and the amide coupling reactions are very different, they possess characteristics inherent to the HTE and large literature datasets, respectively. The phenomena observed in the context of Buchwald\u2013Hartwig reactions and amide coupling reactions can be extrapolated to typical HTE datasets and large literature datasets, respectively. Besides the SMILES of reactants and products, the reaction context (i.e., time, temperature, reagents, condition, and solvent) was also extracted where possible from Reaxys to construct the amide coupling dataset. Please note that the reaction yields were extracted as they appeared in the Reaxys database, regardless of the reaction scale. Also, we augmented the literature dataset with reaction intermediates, optimized 3D structures of the molecules, and 2D/3D descriptors derived from the SMILES and conformers. All amide coupling reactions were catalyzed by carbodiimides to minimize irrelevant variables in this investigation. The carbodiimides include 1-ethyl-3-(3-dimethylaminopropyl)carbodiimide (EDC), N,N\u2032-dicyclohexylcarbodiimide (DCC), and N,N\u2032-diisopropylcarbodiimide (DIC). The combination of different reaction descriptors and model categories enabled a systematic yield prediction benchmark, providing insights into the key factors that influence the reaction yield prediction challenge.\n\nOur results demonstrated that most models gave unsatisfactory predictions (R2 < 0.5) in a large and diverse literature dataset even if they achieved excellent predictions (R2 \\> 0.9) on a caref...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2023/sc/d3sc03902a"
    }
  ]
}