{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff99c44",
   "metadata": {},
   "source": [
    "# Loop 4 Analysis: Diagnosing Mixed Solvent Performance Degradation\n",
    "\n",
    "## Key Issue\n",
    "Exp 004 showed:\n",
    "- Single solvent improved: 0.0748 → 0.0659 (12% better)\n",
    "- Full data degraded: 0.0836 → 0.0895 (7% worse)\n",
    "- Net result: Combined score got slightly worse\n",
    "\n",
    "Need to understand WHY mixed solvent performance degraded and how to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083c1ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:04:43.273565Z",
     "iopub.status.busy": "2026-01-14T02:04:43.273017Z",
     "iopub.status.idle": "2026-01-14T02:04:44.216144Z",
     "shell.execute_reply": "2026-01-14T02:04:44.215780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), ACS_PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "ACS_PCA_DF = load_features('acs_pca_descriptors')\n",
    "\n",
    "print(f\"Spange: {SPANGE_DF.shape}, ACS_PCA: {ACS_PCA_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c546100c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:04:44.217454Z",
     "iopub.status.busy": "2026-01-14T02:04:44.217047Z",
     "iopub.status.idle": "2026-01-14T02:04:44.232248Z",
     "shell.execute_reply": "2026-01-14T02:04:44.231881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data shape: (1227, 5)\n",
      "\n",
      "Solvent ramps:\n",
      "  Methanol + Ethylene Glycol [1,2-Ethanediol]: 122 samples\n",
      "  1,1,1,3,3,3-Hexafluoropropan-2-ol + 2-Methyltetrahydrofuran [2-MeTHF]: 124 samples\n",
      "  Cyclohexane + IPA [Propan-2-ol]: 104 samples\n",
      "  Water.Acetonitrile + Acetonitrile: 125 samples\n",
      "  Acetonitrile + Acetonitrile.Acetic Acid: 125 samples\n",
      "  2-Methyltetrahydrofuran [2-MeTHF] + Diethyl Ether [Ether]: 124 samples\n",
      "  2,2,2-Trifluoroethanol + Water.2,2,2-Trifluoroethanol: 125 samples\n",
      "  DMA [N,N-Dimethylacetamide] + Decanol: 110 samples\n",
      "  Ethanol + THF [Tetrahydrofuran]: 127 samples\n",
      "  Dihydrolevoglucosenone (Cyrene) + Ethyl Acetate: 36 samples\n",
      "  MTBE [tert-Butylmethylether] + Butanone [MEK]: 34 samples\n",
      "  tert-Butanol [2-Methylpropan-2-ol] + Dimethyl Carbonate: 36 samples\n",
      "  Methyl Propionate + Ethyl Lactate: 35 samples\n"
     ]
    }
   ],
   "source": [
    "# Load full data and analyze the ramp structure\n",
    "X_full, Y_full = load_data('full')\n",
    "\n",
    "print(\"Full data shape:\", X_full.shape)\n",
    "print(\"\\nSolvent ramps:\")\n",
    "ramps = X_full[['SOLVENT A NAME', 'SOLVENT B NAME']].drop_duplicates()\n",
    "for i, row in ramps.iterrows():\n",
    "    mask = (X_full['SOLVENT A NAME'] == row['SOLVENT A NAME']) & (X_full['SOLVENT B NAME'] == row['SOLVENT B NAME'])\n",
    "    count = mask.sum()\n",
    "    print(f\"  {row['SOLVENT A NAME']} + {row['SOLVENT B NAME']}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6bc704f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:04:44.233256Z",
     "iopub.status.busy": "2026-01-14T02:04:44.233155Z",
     "iopub.status.idle": "2026-01-14T02:04:44.237703Z",
     "shell.execute_reply": "2026-01-14T02:04:44.237321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SolventB% distribution:\n",
      "count    1227.000000\n",
      "mean        0.435865\n",
      "std         0.400336\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.330153\n",
      "75%         0.858481\n",
      "max         1.000000\n",
      "Name: SolventB%, dtype: float64\n",
      "\n",
      "Unique values: [0.0, 0.0007551958286629, 0.0011470643892773, 0.0012558138971659, 0.0013800461289313, 0.0014146983940115, 0.0014670453971028, 0.0039301499938112, 0.0044415304154707, 0.0047847161836571, 0.0048333739278409, 0.0048543852203656, 0.0049421164792773, 0.0049705000996266, 0.0050663407785638, 0.0051009908260428, 0.0051057828566375, 0.0305111311583698, 0.0305596743906471, 0.0306118950907354, 0.0306464636956026, 0.0307703956646607, 0.0308579201538992, 0.0312697983243124, 0.0318331981174409, 0.0342892903349568, 0.0343238567383758, 0.0344477807960034, 0.0346047999227302, 0.0353148740466059, 0.0374454720860986, 0.0520676588272898, 0.0620019500597866, 0.0649327278138796, 0.0694426424939573, 0.0755446161518067, 0.0781187713675148, 0.0784615188362507, 0.0786187181173761, 0.0787427837645361, 0.0787773895628152, 0.0788782616708844, 0.0811419346312067, 0.0818001628039068, 0.0821428883763624, 0.0821914808816452, 0.0822124639947394, 0.0823000776243253, 0.082328423174102, 0.0824241353441652, 0.0824587389288042, 0.0824635245353187, 0.1077358244627781, 0.1077879752953669, 0.1078224976504738, 0.1079462638011126, 0.1080546048674116, 0.1084009276694753, 0.1084449982911359, 0.1091551064397903, 0.1114604504639309, 0.1114949706260302, 0.1116187288838527, 0.1117755379321699, 0.1124846620576208, 0.1147598574677055, 0.1292150357823831, 0.1391360394543668, 0.1467141466947036, 0.152339124548164, 0.1526605940816393, 0.1553786509367175, 0.1557209392093032, 0.1558779278740731, 0.1560018273064263, 0.1560363867389671, 0.1561371237069861, 0.1582504277320818, 0.1586874748743282, 0.1594668590783239, 0.159554355329334, 0.1595826629081239, 0.1596782468485197, 0.1597128040713703, 0.1597175832697916, 0.1597650075122544, 0.1598135346166128, 0.1847603489287208, 0.1848087624108813, 0.1848608435275751, 0.1848953197379135, 0.1850189204423816, 0.1851062109944592, 0.1858837511752109, 0.1863734118273673, 0.1884763317807025, 0.1885628835991453, 0.1886864764248545, 0.1888951533409116, 0.1895512521127173, 0.1919706566822922, 0.2062592647080748, 0.2161670104089252, 0.2190899573880106, 0.2238821604274928, 0.2296734938977191, 0.2321678992934248, 0.2329253616210909, 0.2330336746085663, 0.2331574081859099, 0.2331919213625156, 0.2332440582458582, 0.2352558594030436, 0.236206604167683, 0.2362506612123789, 0.2367051810060953, 0.236733450699701, 0.236828906693394, 0.2368634176732585, 0.2368681904615094, 0.2369155512323703, 0.2369640133717106, 0.2618307296363099, 0.2618651598020871, 0.2619885954271346, 0.2620966471710295, 0.2621449956856171, 0.2624420451039509, 0.2628522711330426, 0.2634883453998597, 0.2654413892446219, 0.2654933974965426, 0.2655278254726237, 0.2656512532419369, 0.2661486242137342, 0.2690781008451991, 0.2832005752464695, 0.2930950924955402, 0.2960141371328884, 0.3009469145065295, 0.3065835450554234, 0.30958824723799, 0.3099780208863545, 0.3100861890256154, 0.3102097571247901, 0.3102442241459673, 0.3102962913067577, 0.3121584590099016, 0.3128882229756899, 0.3132988733870648, 0.3136446240976479, 0.3137527853479627, 0.3137810172284534, 0.3138763455711552, 0.3139108103995101, 0.3139155768025271, 0.3139628742419947, 0.3301526717557252, 0.3378467399126894, 0.337950150267461, 0.3379856268264812, 0.3381128141331745, 0.3382739684862051, 0.3385800489636115, 0.3386253383525415, 0.3400647962100717, 0.3417242920851592, 0.3417597694004023, 0.3418869593933166, 0.3420481171887911, 0.3427769145334528, 0.3458207124528857, 0.3599749090445847, 0.3701763542552925, 0.3731863945545312, 0.3786475344518835, 0.3840869873138819, 0.3871739081155805, 0.3879534298912608, 0.3880648981044571, 0.3881922363683478, 0.3882277550532299, 0.3882814109389044, 0.3898376629972357, 0.3913303499636058, 0.3913756929655841, 0.3917320133894648, 0.3918434816026619, 0.3918725766955979, 0.3919708198665511, 0.3920063385514343, 0.392011250709982, 0.3920599944371088, 0.4171205162826612, 0.4172239727995849, 0.4172594651882796, 0.4173867092489031, 0.4175479355452995, 0.4178541526255605, 0.4178994622144914, 0.419415049672358, 0.4209461817629268, 0.4209997990579701, 0.4210352921982482, 0.4211625389729293, 0.4220528913024275, 0.4251709659151717, 0.4392585609973903, 0.4494645585849812, 0.4524759420590201, 0.4579976522670343, 0.4633813988338539, 0.4665234888445319, 0.4672530683848214, 0.4673029411403742, 0.4674143991375848, 0.4675417256452048, 0.4675772410407436, 0.4691346404276658, 0.4706795207912055, 0.4707248587918974, 0.4710811394652938, 0.4711925951056837, 0.4712216868953582, 0.4713199189038855, 0.4713554335478407, 0.4713603451450195, 0.4714090833048516, 0.4964795286322022, 0.4965331687067596, 0.4965686769344078, 0.496695977767519, 0.4967858816657999, 0.4968074132821385, 0.4972089594793288, 0.4987589073940068, 0.5003106794151106, 0.5003461883943423, 0.5004734919275927, 0.5006347935634048, 0.5013642414557321, 0.5045131875712858, 0.5185775863252469, 0.5287881363082781, 0.5318008629571174, 0.5373271211716882, 0.5427111837381556, 0.5462268134414423, 0.5465784110704447, 0.5466282615846552, 0.5467396698937604, 0.5468669396381716, 0.5469024391947569, 0.5484669912517043, 0.5500033358529154, 0.5500486536304094, 0.5503549260124638, 0.5504047754688878, 0.5505161814118936, 0.5505452602390501, 0.5506434484468864, 0.5506789472565276, 0.5506838566546249, 0.5757721685259798, 0.5758220458281559, 0.5758757017138304, 0.5759112203987139, 0.5760385586626031, 0.5765063472996812, 0.5769295486514797, 0.5780702026305884, 0.5796006293263607, 0.5796542852120351, 0.5796898038969173, 0.5798171421608079, 0.5807081321496845, 0.5838219168927699, 0.597925247859251, 0.6081372476214975, 0.6111502901029654, 0.6166212166827337, 0.6220613278123797, 0.6255169395595096, 0.6258683803624594, 0.6260295672656063, 0.6261567802375296, 0.6261922639690798, 0.6262956952012073, 0.6278172440551941, 0.6289142973343291, 0.6293370750938705, 0.6296930380881519, 0.6298043943337738, 0.6298334601937731, 0.6299316046055575, 0.6299670875762453, 0.6299719947984583, 0.6300206894962763, 0.6552259551761167, 0.6552614738610002, 0.6553888121248894, 0.6555002803380865, 0.6555501576402627, 0.6558566007619676, 0.656279802113766, 0.6573461244782008, 0.6590045386743215, 0.6590400573592036, 0.6591673956230942, 0.6593287411384674, 0.6600583856119708, 0.6630952728206454, 0.6698473282442748, 0.676320344038916, 0.6862285156107053, 0.6891522397014622, 0.6941030634604697, 0.6997410741963931, 0.7027284569619333, 0.7032255591242401, 0.7033489201962158, 0.7033833295583831, 0.7034353097101621, 0.704961034609701, 0.7060230285288082, 0.7067782441111423, 0.7067991106065774, 0.706886237455563, 0.7069144255814572, 0.7070096063686098, 0.7070440179233971, 0.7070487769739335, 0.7070960013773754, 0.7319383113969615, 0.7319728036715203, 0.7320964623475389, 0.732204709774281, 0.7322531459708824, 0.7325507359480674, 0.7325947691194394, 0.733604523162215, 0.7355557103397757, 0.7356078189806627, 0.735642313459382, 0.7357659800107412, 0.736264318552731, 0.7391838705609474, 0.7533546559658035, 0.7632760949144808, 0.7662037342544131, 0.771014032375394, 0.7768067497080673, 0.7796509557964273, 0.7800405916563602, 0.7801487224974405, 0.7802722484708069, 0.7803067038404395, 0.7803587534693525, 0.782400961115057, 0.7833164961936612, 0.7833604840952203, 0.7837061568554153, 0.7838142945693436, 0.7838425203806904, 0.7839378284157905, 0.7839722859684298, 0.7839770513775494, 0.7840243389144456, 0.8089464414444275, 0.8089949422272087, 0.809047117368544, 0.8090816558616852, 0.8092054802137455, 0.8092929290252502, 0.8100718906984953, 0.8105683047364554, 0.8126693630709952, 0.812721541535589, 0.8128799144783043, 0.813378920730711, 0.8161551135658491, 0.8304921595366753, 0.8404268954948869, 0.8433584588335773, 0.8480387868635708, 0.8539756869394844, 0.8563092994167018, 0.8570664882543162, 0.8571747637642663, 0.8572984550278592, 0.8573329564915272, 0.8573850757665974, 0.8595773977322997, 0.8603467760481385, 0.8608452405110343, 0.8608894933283022, 0.8609689396572386, 0.861003443321349, 0.8610082151094144, 0.8610555659149277, 0.8611040179482231, 0.8861584704938535, 0.8862070363197796, 0.8862592814307685, 0.886293866243161, 0.886417856639618, 0.8868733488992226, 0.887285429002749, 0.8876350548212032, 0.889886384731945, 0.8899386331721411, 0.8899732201920615, 0.8900972185055932, 0.8909648462687019, 0.8932293417200197, 0.9077330853562188, 0.9176811480451212, 0.9206166441646494, 0.9252004079093976, 0.9312481166968494, 0.9338048122677532, 0.934195491958096, 0.9343039124719216, 0.9344277693840184, 0.934462317051095, 0.934514506123741, 0.9368573436385758, 0.9371126262083704, 0.9379793048345484, 0.9380740792280556, 0.9381031696388196, 0.9381377195147812, 0.9381424976931804, 0.938189911925408, 0.9382384288379628, 0.9635227194606554, 0.9635750346981, 0.9636096659261664, 0.963733822758943, 0.96382150636773, 0.9638425062496178, 0.9642341369426006, 0.9648050032199096, 0.9672070064661809, 0.9672593250342824, 0.9672939584828614, 0.9674181232378546, 0.9682869155992944, 0.9704067848759986, 0.9850776647291744, 0.9950390839768184, 0.997978521664773, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Analyze SolventB% distribution\n",
    "print(\"\\nSolventB% distribution:\")\n",
    "print(X_full['SolventB%'].describe())\n",
    "print(\"\\nUnique values:\", sorted(X_full['SolventB%'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e28d212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:04:48.183572Z",
     "iopub.status.busy": "2026-01-14T02:04:48.183062Z",
     "iopub.status.idle": "2026-01-14T02:04:50.701645Z",
     "shell.execute_reply": "2026-01-14T02:04:50.701201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Simple RF (no TTA) on full data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF (no TTA) MAE: 0.0716 +/- 0.0227\n"
     ]
    }
   ],
   "source": [
    "# Test different approaches for mixed solvents\n",
    "# Hypothesis: The per-target approach may be overfitting on augmented data\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def build_features_mixed(X, feature_df, flip=False):\n",
    "    rt = X['Residence Time'].values.reshape(-1, 1)\n",
    "    temp = X['Temperature'].values.reshape(-1, 1)\n",
    "    pct = X['SolventB%'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Arrhenius features\n",
    "    temp_k = temp + 273.15\n",
    "    inv_temp = 1000.0 / temp_k\n",
    "    log_time = np.log(rt + 1e-6)\n",
    "    interaction = inv_temp * log_time\n",
    "    \n",
    "    # Solvent features\n",
    "    A = feature_df.loc[X['SOLVENT A NAME']].values\n",
    "    B = feature_df.loc[X['SOLVENT B NAME']].values\n",
    "    \n",
    "    if flip:\n",
    "        solvent_feats = B * (1 - pct) + A * pct\n",
    "    else:\n",
    "        solvent_feats = A * (1 - pct) + B * pct\n",
    "    \n",
    "    return np.hstack([rt, temp, inv_temp, log_time, interaction, pct, solvent_feats])\n",
    "\n",
    "# Test 1: Simple RF without TTA\n",
    "print(\"Test 1: Simple RF (no TTA) on full data\")\n",
    "errors_rf_no_tta = []\n",
    "for (train_X, train_Y), (test_X, test_Y) in generate_leave_one_ramp_out_splits(X_full, Y_full):\n",
    "    X_train = build_features_mixed(train_X, SPANGE_DF)\n",
    "    X_test = build_features_mixed(test_X, SPANGE_DF)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train)\n",
    "    X_test_sc = scaler.transform(X_test)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=200, max_depth=8, min_samples_leaf=5, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train_sc, train_Y.values)\n",
    "    preds = model.predict(X_test_sc)\n",
    "    preds = np.clip(preds, 0, 1)\n",
    "    \n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_rf_no_tta.append(mae)\n",
    "\n",
    "print(f\"RF (no TTA) MAE: {np.mean(errors_rf_no_tta):.4f} +/- {np.std(errors_rf_no_tta):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0603fcc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:04:50.702830Z",
     "iopub.status.busy": "2026-01-14T02:04:50.702675Z",
     "iopub.status.idle": "2026-01-14T02:04:54.885936Z",
     "shell.execute_reply": "2026-01-14T02:04:54.885498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 2: Simple RF with TTA on full data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF (with TTA) MAE: 0.0932 +/- 0.0338\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Simple RF WITH TTA (training augmentation + test-time averaging)\n",
    "print(\"\\nTest 2: Simple RF with TTA on full data\")\n",
    "errors_rf_tta = []\n",
    "for (train_X, train_Y), (test_X, test_Y) in generate_leave_one_ramp_out_splits(X_full, Y_full):\n",
    "    # Training with augmentation\n",
    "    X_train_orig = build_features_mixed(train_X, SPANGE_DF, flip=False)\n",
    "    X_train_flip = build_features_mixed(train_X, SPANGE_DF, flip=True)\n",
    "    X_train = np.vstack([X_train_orig, X_train_flip])\n",
    "    y_train = np.vstack([train_Y.values, train_Y.values])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=200, max_depth=8, min_samples_leaf=5, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train_sc, y_train)\n",
    "    \n",
    "    # Test with TTA\n",
    "    X_test_orig = build_features_mixed(test_X, SPANGE_DF, flip=False)\n",
    "    X_test_flip = build_features_mixed(test_X, SPANGE_DF, flip=True)\n",
    "    \n",
    "    preds_orig = model.predict(scaler.transform(X_test_orig))\n",
    "    preds_flip = model.predict(scaler.transform(X_test_flip))\n",
    "    preds = (preds_orig + preds_flip) / 2\n",
    "    preds = np.clip(preds, 0, 1)\n",
    "    \n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_rf_tta.append(mae)\n",
    "\n",
    "print(f\"RF (with TTA) MAE: {np.mean(errors_rf_tta):.4f} +/- {np.std(errors_rf_tta):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f4708a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:04:54.887060Z",
     "iopub.status.busy": "2026-01-14T02:04:54.886954Z",
     "iopub.status.idle": "2026-01-14T02:04:56.984200Z",
     "shell.execute_reply": "2026-01-14T02:04:56.983798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 3: ExtraTrees (no TTA) on full data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees (no TTA) MAE: 0.0640 +/- 0.0213\n"
     ]
    }
   ],
   "source": [
    "# Test 3: ExtraTrees (which worked well for single solvent)\n",
    "print(\"\\nTest 3: ExtraTrees (no TTA) on full data\")\n",
    "errors_etr_no_tta = []\n",
    "for (train_X, train_Y), (test_X, test_Y) in generate_leave_one_ramp_out_splits(X_full, Y_full):\n",
    "    X_train = build_features_mixed(train_X, SPANGE_DF)\n",
    "    X_test = build_features_mixed(test_X, SPANGE_DF)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train)\n",
    "    X_test_sc = scaler.transform(X_test)\n",
    "    \n",
    "    model = ExtraTreesRegressor(n_estimators=300, max_depth=10, min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train_sc, train_Y.values)\n",
    "    preds = model.predict(X_test_sc)\n",
    "    preds = np.clip(preds, 0, 1)\n",
    "    \n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_etr_no_tta.append(mae)\n",
    "\n",
    "print(f\"ExtraTrees (no TTA) MAE: {np.mean(errors_etr_no_tta):.4f} +/- {np.std(errors_etr_no_tta):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "010873df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:04:56.985211Z",
     "iopub.status.busy": "2026-01-14T02:04:56.985112Z",
     "iopub.status.idle": "2026-01-14T02:05:07.775401Z",
     "shell.execute_reply": "2026-01-14T02:05:07.774989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 4: HistGradientBoosting on full data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting MAE: 0.0732 +/- 0.0224\n"
     ]
    }
   ],
   "source": [
    "# Test 4: HistGradientBoosting (simpler, less prone to overfitting)\n",
    "print(\"\\nTest 4: HistGradientBoosting on full data\")\n",
    "errors_hgb = []\n",
    "for (train_X, train_Y), (test_X, test_Y) in generate_leave_one_ramp_out_splits(X_full, Y_full):\n",
    "    X_train = build_features_mixed(train_X, SPANGE_DF)\n",
    "    X_test = build_features_mixed(test_X, SPANGE_DF)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train)\n",
    "    X_test_sc = scaler.transform(X_test)\n",
    "    \n",
    "    preds_all = []\n",
    "    for i in range(3):  # 3 targets\n",
    "        model = HistGradientBoostingRegressor(max_depth=5, max_iter=500, learning_rate=0.05, random_state=42)\n",
    "        model.fit(X_train_sc, train_Y.values[:, i])\n",
    "        preds_all.append(model.predict(X_test_sc))\n",
    "    \n",
    "    preds = np.column_stack(preds_all)\n",
    "    preds = np.clip(preds, 0, 1)\n",
    "    \n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_hgb.append(mae)\n",
    "\n",
    "print(f\"HistGradientBoosting MAE: {np.mean(errors_hgb):.4f} +/- {np.std(errors_hgb):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2635e6d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:05:07.776453Z",
     "iopub.status.busy": "2026-01-14T02:05:07.776345Z",
     "iopub.status.idle": "2026-01-14T02:05:12.561744Z",
     "shell.execute_reply": "2026-01-14T02:05:12.561318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 5: RF with combined features (0.8 acs + 0.2 spange)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF combined (0.8 acs + 0.2 spange) MAE: 0.0655 +/- 0.0186\n"
     ]
    }
   ],
   "source": [
    "# Test 5: Combined features (acs_pca + spange) with RF\n",
    "print(\"\\nTest 5: RF with combined features (0.8 acs + 0.2 spange)\")\n",
    "errors_combined = []\n",
    "for (train_X, train_Y), (test_X, test_Y) in generate_leave_one_ramp_out_splits(X_full, Y_full):\n",
    "    X_train_spange = build_features_mixed(train_X, SPANGE_DF)\n",
    "    X_train_acs = build_features_mixed(train_X, ACS_PCA_DF)\n",
    "    X_test_spange = build_features_mixed(test_X, SPANGE_DF)\n",
    "    X_test_acs = build_features_mixed(test_X, ACS_PCA_DF)\n",
    "    \n",
    "    scaler_spange = StandardScaler()\n",
    "    scaler_acs = StandardScaler()\n",
    "    \n",
    "    X_train_spange_sc = scaler_spange.fit_transform(X_train_spange)\n",
    "    X_train_acs_sc = scaler_acs.fit_transform(X_train_acs)\n",
    "    X_test_spange_sc = scaler_spange.transform(X_test_spange)\n",
    "    X_test_acs_sc = scaler_acs.transform(X_test_acs)\n",
    "    \n",
    "    # Train separate models\n",
    "    model_spange = RandomForestRegressor(n_estimators=200, max_depth=8, min_samples_leaf=5, random_state=42, n_jobs=-1)\n",
    "    model_acs = RandomForestRegressor(n_estimators=200, max_depth=8, min_samples_leaf=5, random_state=42, n_jobs=-1)\n",
    "    \n",
    "    model_spange.fit(X_train_spange_sc, train_Y.values)\n",
    "    model_acs.fit(X_train_acs_sc, train_Y.values)\n",
    "    \n",
    "    preds_spange = model_spange.predict(X_test_spange_sc)\n",
    "    preds_acs = model_acs.predict(X_test_acs_sc)\n",
    "    \n",
    "    # Weighted combination\n",
    "    preds = 0.8 * preds_acs + 0.2 * preds_spange\n",
    "    preds = np.clip(preds, 0, 1)\n",
    "    \n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_combined.append(mae)\n",
    "\n",
    "print(f\"RF combined (0.8 acs + 0.2 spange) MAE: {np.mean(errors_combined):.4f} +/- {np.std(errors_combined):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b2d06f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:05:18.066006Z",
     "iopub.status.busy": "2026-01-14T02:05:18.065541Z",
     "iopub.status.idle": "2026-01-14T02:05:18.069303Z",
     "shell.execute_reply": "2026-01-14T02:05:18.068961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY: Full Data (Mixed Solvents) Performance\n",
      "============================================================\n",
      "ExtraTrees (no TTA)           : 0.0640\n",
      "RF combined features          : 0.0655\n",
      "RF (no TTA)                   : 0.0716\n",
      "HistGradientBoosting          : 0.0732\n",
      "RF (with TTA)                 : 0.0932\n",
      "\n",
      "Current best (exp_003 RF): 0.0836\n",
      "Exp_004 per-target: 0.0895\n"
     ]
    }
   ],
   "source": [
    "# Summary of full data results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY: Full Data (Mixed Solvents) Performance\")\n",
    "print(\"=\"*60)\n",
    "results = [\n",
    "    ('RF (no TTA)', np.mean(errors_rf_no_tta)),\n",
    "    ('RF (with TTA)', np.mean(errors_rf_tta)),\n",
    "    ('ExtraTrees (no TTA)', np.mean(errors_etr_no_tta)),\n",
    "    ('HistGradientBoosting', np.mean(errors_hgb)),\n",
    "    ('RF combined features', np.mean(errors_combined)),\n",
    "]\n",
    "results.sort(key=lambda x: x[1])\n",
    "for name, mae in results:\n",
    "    print(f\"{name:30s}: {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nCurrent best (exp_003 RF): 0.0836\")\n",
    "print(f\"Exp_004 per-target: 0.0895\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66ea79b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:05:18.070237Z",
     "iopub.status.busy": "2026-01-14T02:05:18.070144Z",
     "iopub.status.idle": "2026-01-14T02:06:03.219694Z",
     "shell.execute_reply": "2026-01-14T02:06:03.219304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Solvent: Per-target with combined features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-target combined MAE: 0.0659 +/- 0.0321\n"
     ]
    }
   ],
   "source": [
    "# Now let's test the BEST approach for single solvent\n",
    "# to see if we can combine the best of both worlds\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def build_features_single(X, feature_df):\n",
    "    rt = X['Residence Time'].values.reshape(-1, 1)\n",
    "    temp = X['Temperature'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Arrhenius features\n",
    "    temp_k = temp + 273.15\n",
    "    inv_temp = 1000.0 / temp_k\n",
    "    log_time = np.log(rt + 1e-6)\n",
    "    interaction = inv_temp * log_time\n",
    "    \n",
    "    # Solvent features\n",
    "    solvent_feats = feature_df.loc[X['SOLVENT NAME']].values\n",
    "    \n",
    "    return np.hstack([rt, temp, inv_temp, log_time, interaction, solvent_feats])\n",
    "\n",
    "X_single, Y_single = load_data('single_solvent')\n",
    "\n",
    "# Test the best single solvent approach: per-target with combined features\n",
    "print(\"\\nSingle Solvent: Per-target with combined features\")\n",
    "errors_single_pertarget = []\n",
    "for (train_X, train_Y), (test_X, test_Y) in generate_leave_one_out_splits(X_single, Y_single):\n",
    "    X_train_spange = build_features_single(train_X, SPANGE_DF)\n",
    "    X_train_acs = build_features_single(train_X, ACS_PCA_DF)\n",
    "    X_test_spange = build_features_single(test_X, SPANGE_DF)\n",
    "    X_test_acs = build_features_single(test_X, ACS_PCA_DF)\n",
    "    \n",
    "    scaler_spange = StandardScaler()\n",
    "    scaler_acs = StandardScaler()\n",
    "    \n",
    "    X_train_spange_sc = scaler_spange.fit_transform(X_train_spange)\n",
    "    X_train_acs_sc = scaler_acs.fit_transform(X_train_acs)\n",
    "    X_test_spange_sc = scaler_spange.transform(X_test_spange)\n",
    "    X_test_acs_sc = scaler_acs.transform(X_test_acs)\n",
    "    \n",
    "    preds_all = []\n",
    "    for i, target in enumerate(['Product 2', 'Product 3', 'SM']):\n",
    "        if target == 'SM':\n",
    "            model_spange = HistGradientBoostingRegressor(max_depth=7, max_iter=700, learning_rate=0.04, random_state=42)\n",
    "            model_acs = HistGradientBoostingRegressor(max_depth=7, max_iter=700, learning_rate=0.04, random_state=42)\n",
    "        else:\n",
    "            model_spange = ExtraTreesRegressor(n_estimators=500, max_depth=10, min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "            model_acs = ExtraTreesRegressor(n_estimators=500, max_depth=10, min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "        \n",
    "        model_spange.fit(X_train_spange_sc, train_Y.values[:, i])\n",
    "        model_acs.fit(X_train_acs_sc, train_Y.values[:, i])\n",
    "        \n",
    "        p_spange = model_spange.predict(X_test_spange_sc)\n",
    "        p_acs = model_acs.predict(X_test_acs_sc)\n",
    "        p_combined = 0.8 * p_acs + 0.2 * p_spange\n",
    "        preds_all.append(p_combined)\n",
    "    \n",
    "    preds = np.column_stack(preds_all)\n",
    "    preds = np.clip(preds, 0, 1)\n",
    "    \n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_single_pertarget.append(mae)\n",
    "\n",
    "print(f\"Per-target combined MAE: {np.mean(errors_single_pertarget):.4f} +/- {np.std(errors_single_pertarget):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ccf8791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:06:03.220774Z",
     "iopub.status.busy": "2026-01-14T02:06:03.220672Z",
     "iopub.status.idle": "2026-01-14T02:06:07.388851Z",
     "shell.execute_reply": "2026-01-14T02:06:07.388401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Solvent: Simple RF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple RF MAE: 0.0757 +/- 0.0342\n"
     ]
    }
   ],
   "source": [
    "# Test simple RF on single solvent for comparison\n",
    "print(\"\\nSingle Solvent: Simple RF\")\n",
    "errors_single_rf = []\n",
    "for (train_X, train_Y), (test_X, test_Y) in generate_leave_one_out_splits(X_single, Y_single):\n",
    "    X_train = build_features_single(train_X, SPANGE_DF)\n",
    "    X_test = build_features_single(test_X, SPANGE_DF)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train)\n",
    "    X_test_sc = scaler.transform(X_test)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=200, max_depth=8, min_samples_leaf=5, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train_sc, train_Y.values)\n",
    "    preds = model.predict(X_test_sc)\n",
    "    preds = np.clip(preds, 0, 1)\n",
    "    \n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_single_rf.append(mae)\n",
    "\n",
    "print(f\"Simple RF MAE: {np.mean(errors_single_rf):.4f} +/- {np.std(errors_single_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d0422f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:06:07.390113Z",
     "iopub.status.busy": "2026-01-14T02:06:07.390015Z",
     "iopub.status.idle": "2026-01-14T02:06:07.393921Z",
     "shell.execute_reply": "2026-01-14T02:06:07.393579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL SUMMARY\n",
      "============================================================\n",
      "\n",
      "Single Solvent:\n",
      "  Per-target combined: 0.0659\n",
      "  Simple RF: 0.0757\n",
      "  Current best (exp_003): 0.0748\n",
      "  Exp_004 per-target: 0.0659\n",
      "\n",
      "Full Data (Mixed):\n",
      "  Best from tests: 0.0640\n",
      "  Current best (exp_003): 0.0836\n",
      "  Exp_004 per-target: 0.0895\n",
      "\n",
      "Potential combined score: 0.0647\n",
      "Current best combined: 0.0805\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nSingle Solvent:\")\n",
    "print(f\"  Per-target combined: {np.mean(errors_single_pertarget):.4f}\")\n",
    "print(f\"  Simple RF: {np.mean(errors_single_rf):.4f}\")\n",
    "print(f\"  Current best (exp_003): 0.0748\")\n",
    "print(f\"  Exp_004 per-target: 0.0659\")\n",
    "\n",
    "print(\"\\nFull Data (Mixed):\")\n",
    "print(f\"  Best from tests: {min([np.mean(errors_rf_no_tta), np.mean(errors_rf_tta), np.mean(errors_etr_no_tta), np.mean(errors_hgb), np.mean(errors_combined)]):.4f}\")\n",
    "print(f\"  Current best (exp_003): 0.0836\")\n",
    "print(f\"  Exp_004 per-target: 0.0895\")\n",
    "\n",
    "# Calculate combined scores\n",
    "best_single = np.mean(errors_single_pertarget)\n",
    "best_full = min([np.mean(errors_rf_no_tta), np.mean(errors_rf_tta), np.mean(errors_etr_no_tta), np.mean(errors_hgb), np.mean(errors_combined)])\n",
    "\n",
    "n_single = 656\n",
    "n_full = 1227\n",
    "combined = (best_single * n_single + best_full * n_full) / (n_single + n_full)\n",
    "print(f\"\\nPotential combined score: {combined:.4f}\")\n",
    "print(f\"Current best combined: 0.0805\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3f2cf57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:06:07.394735Z",
     "iopub.status.busy": "2026-01-14T02:06:07.394649Z",
     "iopub.status.idle": "2026-01-14T02:06:07.397754Z",
     "shell.execute_reply": "2026-01-14T02:06:07.397424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RECOMMENDED APPROACH: Hybrid Model\n",
      "============================================================\n",
      "\n",
      "1. For SINGLE SOLVENT (data='single'):\n",
      "   - Use per-target heterogeneous model\n",
      "   - HGB for SM, ExtraTrees for Products\n",
      "   - Combined features (0.8 acs + 0.2 spange)\n",
      "   - Expected MAE: ~0.066\n",
      "\n",
      "2. For FULL DATA (data='full'):\n",
      "   - Use simple RF with regularization\n",
      "   - NO TTA (it seems to hurt performance)\n",
      "   - Spange features only\n",
      "   - Expected MAE: ~0.083\n",
      "\n",
      "3. Combined expected score:\n",
      "   - (0.066 * 656 + 0.083 * 1227) / 1883 = 0.077\n",
      "   - This would be a 4% improvement over current 0.0805\n",
      "\n",
      "Expected combined: 0.0771\n"
     ]
    }
   ],
   "source": [
    "# Key insight: We need DIFFERENT approaches for single vs mixed solvents\n",
    "# Let's design a hybrid model that uses:\n",
    "# - Per-target heterogeneous for single solvents (best: 0.0659)\n",
    "# - Simple RF for mixed solvents (best: ~0.083)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDED APPROACH: Hybrid Model\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. For SINGLE SOLVENT (data='single'):\n",
    "   - Use per-target heterogeneous model\n",
    "   - HGB for SM, ExtraTrees for Products\n",
    "   - Combined features (0.8 acs + 0.2 spange)\n",
    "   - Expected MAE: ~0.066\n",
    "\n",
    "2. For FULL DATA (data='full'):\n",
    "   - Use simple RF with regularization\n",
    "   - NO TTA (it seems to hurt performance)\n",
    "   - Spange features only\n",
    "   - Expected MAE: ~0.083\n",
    "\n",
    "3. Combined expected score:\n",
    "   - (0.066 * 656 + 0.083 * 1227) / 1883 = 0.077\n",
    "   - This would be a 4% improvement over current 0.0805\n",
    "\"\"\")\n",
    "\n",
    "# Calculate\n",
    "expected_single = 0.066\n",
    "expected_full = 0.083\n",
    "expected_combined = (expected_single * 656 + expected_full * 1227) / (656 + 1227)\n",
    "print(f\"Expected combined: {expected_combined:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b0f38e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:06:33.779451Z",
     "iopub.status.busy": "2026-01-14T02:06:33.779054Z",
     "iopub.status.idle": "2026-01-14T02:06:37.954808Z",
     "shell.execute_reply": "2026-01-14T02:06:37.954406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: ExtraTrees with combined features (0.8 acs + 0.2 spange) on full data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees combined (0.8 acs + 0.2 spange) MAE: 0.0625 +/- 0.0214\n"
     ]
    }
   ],
   "source": [
    "# Test ExtraTrees with combined features for mixed solvents\n",
    "print(\"\\nTest: ExtraTrees with combined features (0.8 acs + 0.2 spange) on full data\")\n",
    "errors_etr_combined = []\n",
    "for (train_X, train_Y), (test_X, test_Y) in generate_leave_one_ramp_out_splits(X_full, Y_full):\n",
    "    X_train_spange = build_features_mixed(train_X, SPANGE_DF)\n",
    "    X_train_acs = build_features_mixed(train_X, ACS_PCA_DF)\n",
    "    X_test_spange = build_features_mixed(test_X, SPANGE_DF)\n",
    "    X_test_acs = build_features_mixed(test_X, ACS_PCA_DF)\n",
    "    \n",
    "    scaler_spange = StandardScaler()\n",
    "    scaler_acs = StandardScaler()\n",
    "    \n",
    "    X_train_spange_sc = scaler_spange.fit_transform(X_train_spange)\n",
    "    X_train_acs_sc = scaler_acs.fit_transform(X_train_acs)\n",
    "    X_test_spange_sc = scaler_spange.transform(X_test_spange)\n",
    "    X_test_acs_sc = scaler_acs.transform(X_test_acs)\n",
    "    \n",
    "    # Train separate models\n",
    "    model_spange = ExtraTreesRegressor(n_estimators=300, max_depth=10, min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "    model_acs = ExtraTreesRegressor(n_estimators=300, max_depth=10, min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "    \n",
    "    model_spange.fit(X_train_spange_sc, train_Y.values)\n",
    "    model_acs.fit(X_train_acs_sc, train_Y.values)\n",
    "    \n",
    "    preds_spange = model_spange.predict(X_test_spange_sc)\n",
    "    preds_acs = model_acs.predict(X_test_acs_sc)\n",
    "    \n",
    "    # Weighted combination\n",
    "    preds = 0.8 * preds_acs + 0.2 * preds_spange\n",
    "    preds = np.clip(preds, 0, 1)\n",
    "    \n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_etr_combined.append(mae)\n",
    "\n",
    "print(f\"ExtraTrees combined (0.8 acs + 0.2 spange) MAE: {np.mean(errors_etr_combined):.4f} +/- {np.std(errors_etr_combined):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62cb973b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:06:52.730594Z",
     "iopub.status.busy": "2026-01-14T02:06:52.730259Z",
     "iopub.status.idle": "2026-01-14T02:07:18.459199Z",
     "shell.execute_reply": "2026-01-14T02:07:18.458806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Per-target (HGB+ETR) with combined features, NO TTA on full data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-target (no TTA) MAE: 0.0603 +/- 0.0219\n"
     ]
    }
   ],
   "source": [
    "# Test per-target approach for mixed solvents WITHOUT TTA\n",
    "print(\"\\nTest: Per-target (HGB+ETR) with combined features, NO TTA on full data\")\n",
    "errors_pertarget_no_tta = []\n",
    "for (train_X, train_Y), (test_X, test_Y) in generate_leave_one_ramp_out_splits(X_full, Y_full):\n",
    "    X_train_spange = build_features_mixed(train_X, SPANGE_DF)\n",
    "    X_train_acs = build_features_mixed(train_X, ACS_PCA_DF)\n",
    "    X_test_spange = build_features_mixed(test_X, SPANGE_DF)\n",
    "    X_test_acs = build_features_mixed(test_X, ACS_PCA_DF)\n",
    "    \n",
    "    scaler_spange = StandardScaler()\n",
    "    scaler_acs = StandardScaler()\n",
    "    \n",
    "    X_train_spange_sc = scaler_spange.fit_transform(X_train_spange)\n",
    "    X_train_acs_sc = scaler_acs.fit_transform(X_train_acs)\n",
    "    X_test_spange_sc = scaler_spange.transform(X_test_spange)\n",
    "    X_test_acs_sc = scaler_acs.transform(X_test_acs)\n",
    "    \n",
    "    preds_all = []\n",
    "    for i, target in enumerate(['Product 2', 'Product 3', 'SM']):\n",
    "        if target == 'SM':\n",
    "            model_spange = HistGradientBoostingRegressor(max_depth=7, max_iter=700, learning_rate=0.04, random_state=42)\n",
    "            model_acs = HistGradientBoostingRegressor(max_depth=7, max_iter=700, learning_rate=0.04, random_state=42)\n",
    "        else:\n",
    "            model_spange = ExtraTreesRegressor(n_estimators=500, max_depth=10, min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "            model_acs = ExtraTreesRegressor(n_estimators=500, max_depth=10, min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "        \n",
    "        model_spange.fit(X_train_spange_sc, train_Y.values[:, i])\n",
    "        model_acs.fit(X_train_acs_sc, train_Y.values[:, i])\n",
    "        \n",
    "        p_spange = model_spange.predict(X_test_spange_sc)\n",
    "        p_acs = model_acs.predict(X_test_acs_sc)\n",
    "        p_combined = 0.8 * p_acs + 0.2 * p_spange\n",
    "        preds_all.append(p_combined)\n",
    "    \n",
    "    preds = np.column_stack(preds_all)\n",
    "    preds = np.clip(preds, 0, 1)\n",
    "    \n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_pertarget_no_tta.append(mae)\n",
    "\n",
    "print(f\"Per-target (no TTA) MAE: {np.mean(errors_pertarget_no_tta):.4f} +/- {np.std(errors_pertarget_no_tta):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a08b807f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:07:33.486836Z",
     "iopub.status.busy": "2026-01-14T02:07:33.486363Z",
     "iopub.status.idle": "2026-01-14T02:07:33.491215Z",
     "shell.execute_reply": "2026-01-14T02:07:33.490853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL SUMMARY - BEST APPROACHES\n",
      "======================================================================\n",
      "\n",
      "** SINGLE SOLVENT **\n",
      "  Per-target (HGB+ETR) combined features: 0.0659\n",
      "  Simple RF: 0.0757\n",
      "  Current best (exp_003): 0.0748\n",
      "\n",
      "** FULL DATA (MIXED SOLVENTS) **\n",
      "  Per-target (no TTA) combined: 0.0603  <-- BEST!\n",
      "  ExtraTrees combined: 0.0625\n",
      "  ExtraTrees (Spange only): 0.0640\n",
      "  RF combined: 0.0655\n",
      "  RF (no TTA): 0.0716\n",
      "  HGB: 0.0732\n",
      "  RF (with TTA): 0.0932  <-- TTA HURTS!\n",
      "  Current best (exp_003): 0.0836\n",
      "\n",
      "** EXPECTED COMBINED SCORE **\n",
      "  Best single: 0.0659\n",
      "  Best full: 0.0603\n",
      "  Combined: 0.0623\n",
      "  Current best: 0.0805\n",
      "  Improvement: 22.7%\n",
      "\n",
      "** KEY INSIGHT **\n",
      "  The TTA (data augmentation + test-time averaging) was HURTING performance!\n",
      "  Removing TTA and using per-target approach improves full data from 0.0895 to 0.0603!\n",
      "  This is a 33% improvement on full data alone!\n"
     ]
    }
   ],
   "source": [
    "# FINAL SUMMARY - Best approaches found\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL SUMMARY - BEST APPROACHES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n** SINGLE SOLVENT **\")\n",
    "print(f\"  Per-target (HGB+ETR) combined features: {np.mean(errors_single_pertarget):.4f}\")\n",
    "print(f\"  Simple RF: {np.mean(errors_single_rf):.4f}\")\n",
    "print(f\"  Current best (exp_003): 0.0748\")\n",
    "\n",
    "print(\"\\n** FULL DATA (MIXED SOLVENTS) **\")\n",
    "print(f\"  Per-target (no TTA) combined: {np.mean(errors_pertarget_no_tta):.4f}  <-- BEST!\")\n",
    "print(f\"  ExtraTrees combined: {np.mean(errors_etr_combined):.4f}\")\n",
    "print(f\"  ExtraTrees (Spange only): {np.mean(errors_etr_no_tta):.4f}\")\n",
    "print(f\"  RF combined: {np.mean(errors_combined):.4f}\")\n",
    "print(f\"  RF (no TTA): {np.mean(errors_rf_no_tta):.4f}\")\n",
    "print(f\"  HGB: {np.mean(errors_hgb):.4f}\")\n",
    "print(f\"  RF (with TTA): {np.mean(errors_rf_tta):.4f}  <-- TTA HURTS!\")\n",
    "print(f\"  Current best (exp_003): 0.0836\")\n",
    "\n",
    "# Calculate expected combined scores\n",
    "best_single = np.mean(errors_single_pertarget)  # 0.0659\n",
    "best_full = np.mean(errors_pertarget_no_tta)    # 0.0603\n",
    "\n",
    "n_single = 656\n",
    "n_full = 1227\n",
    "combined = (best_single * n_single + best_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(\"\\n** EXPECTED COMBINED SCORE **\")\n",
    "print(f\"  Best single: {best_single:.4f}\")\n",
    "print(f\"  Best full: {best_full:.4f}\")\n",
    "print(f\"  Combined: {combined:.4f}\")\n",
    "print(f\"  Current best: 0.0805\")\n",
    "print(f\"  Improvement: {(0.0805 - combined) / 0.0805 * 100:.1f}%\")\n",
    "\n",
    "print(\"\\n** KEY INSIGHT **\")\n",
    "print(\"  The TTA (data augmentation + test-time averaging) was HURTING performance!\")\n",
    "print(\"  Removing TTA and using per-target approach improves full data from 0.0895 to 0.0603!\")\n",
    "print(\"  This is a 33% improvement on full data alone!\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
