{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0400e240",
   "metadata": {},
   "source": [
    "# Loop 16 Analysis: Understanding the Dual-Model Ensemble Architecture\n",
    "\n",
    "**Key Finding from Evaluator:**\n",
    "- exp_004 (CV 0.0623) trains SEPARATE models on spange AND acs_pca features, then combines PREDICTIONS\n",
    "- exp_016 (CV 0.0830) combines FEATURES first, then trains single models\n",
    "\n",
    "This is a fundamental architectural difference that explains the 33% performance gap!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ceaddc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:44:53.749393Z",
     "iopub.status.busy": "2026-01-14T04:44:53.748798Z",
     "iopub.status.idle": "2026-01-14T04:44:54.084367Z",
     "shell.execute_reply": "2026-01-14T04:44:54.083979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange features: 13 dimensions\n",
      "ACS_PCA features: 5 dimensions\n",
      "\n",
      "Spange columns: ['SOLVENT NAME', 'dielectric constant', 'ET(30)', 'alpha', 'beta', 'pi*', 'SA', 'SB', 'SP', 'SdP', 'N', 'n', 'f(n)', 'delta']\n",
      "\n",
      "ACS_PCA columns: ['SOLVENT NAME', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "DATA_PATH = '/home/data'\n",
    "Spange = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv')\n",
    "ACS_PCA = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv')\n",
    "\n",
    "print(f'Spange features: {Spange.shape[1]-1} dimensions')\n",
    "print(f'ACS_PCA features: {ACS_PCA.shape[1]-1} dimensions')\n",
    "print(f'\\nSpange columns: {list(Spange.columns)}')\n",
    "print(f'\\nACS_PCA columns: {list(ACS_PCA.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838ebb46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:44:54.085729Z",
     "iopub.status.busy": "2026-01-14T04:44:54.085630Z",
     "iopub.status.idle": "2026-01-14T04:44:54.089005Z",
     "shell.execute_reply": "2026-01-14T04:44:54.088683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Analysis:\n",
      "================================================================================\n",
      "exp_004: CV=0.0623, LB=0.0956, Gap=53.5%\n",
      "  -> Per-Target (HGB+ETR) NO TTA - SEPARATE models, PREDICTION combination\n",
      "\n",
      "exp_006: CV=0.0688, LB=0.0991, Gap=44.0%\n",
      "  -> Per-Target depth=5/7 - COMBINED features\n",
      "\n",
      "exp_010: CV=0.0669, LB=N/A, Gap=N/A\n",
      "  -> MLP + GBDT Ensemble\n",
      "\n",
      "exp_013: CV=0.0827, LB=N/A, Gap=N/A\n",
      "  -> LOO Ensemble\n",
      "\n",
      "exp_014: CV=0.0834, LB=N/A, Gap=N/A\n",
      "  -> Optuna Per-Target\n",
      "\n",
      "exp_015: CV=0.0891, LB=N/A, Gap=N/A\n",
      "  -> MLP + Per-Target COMBINED\n",
      "\n",
      "exp_016: CV=0.0830, LB=N/A, Gap=N/A\n",
      "  -> Hybrid Task-Specific - COMBINED features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze experiment history\n",
    "experiments = [\n",
    "    ('exp_004', 0.0623, 0.0956, 'Per-Target (HGB+ETR) NO TTA - SEPARATE models, PREDICTION combination'),\n",
    "    ('exp_006', 0.0688, 0.0991, 'Per-Target depth=5/7 - COMBINED features'),\n",
    "    ('exp_010', 0.0669, None, 'MLP + GBDT Ensemble'),\n",
    "    ('exp_013', 0.0827, None, 'LOO Ensemble'),\n",
    "    ('exp_014', 0.0834, None, 'Optuna Per-Target'),\n",
    "    ('exp_015', 0.0891, None, 'MLP + Per-Target COMBINED'),\n",
    "    ('exp_016', 0.0830, None, 'Hybrid Task-Specific - COMBINED features'),\n",
    "]\n",
    "\n",
    "print('Experiment Analysis:')\n",
    "print('='*80)\n",
    "for exp, cv, lb, desc in experiments:\n",
    "    lb_str = f'{lb:.4f}' if lb else 'N/A'\n",
    "    gap = f'{(lb-cv)/cv*100:.1f}%' if lb else 'N/A'\n",
    "    print(f'{exp}: CV={cv:.4f}, LB={lb_str}, Gap={gap}')\n",
    "    print(f'  -> {desc}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901fb55e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:44:54.089808Z",
     "iopub.status.busy": "2026-01-14T04:44:54.089721Z",
     "iopub.status.idle": "2026-01-14T04:44:54.092995Z",
     "shell.execute_reply": "2026-01-14T04:44:54.092674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CRITICAL ARCHITECTURAL DIFFERENCE\n",
      "================================================================================\n",
      "\n",
      "exp_004 (CV 0.0623 - BEST):\n",
      "  1. Train HGB on spange features -> spange_pred\n",
      "  2. Train HGB on acs_pca features -> acs_pred\n",
      "  3. Final prediction = 0.8 * acs_pred + 0.2 * spange_pred\n",
      "\n",
      "exp_016 (CV 0.0830 - WORSE):\n",
      "  1. Combine features: combined = 0.8 * acs + 0.2 * spange\n",
      "  2. Train single HGB on combined features -> pred\n",
      "\n",
      "WHY PREDICTION COMBINATION IS BETTER:\n",
      "  - Each model specializes in its feature space\n",
      "  - Ensemble of diverse models reduces variance\n",
      "  - Feature combination loses information through averaging\n"
     ]
    }
   ],
   "source": [
    "# KEY INSIGHT: exp_004's architecture\n",
    "print('='*80)\n",
    "print('CRITICAL ARCHITECTURAL DIFFERENCE')\n",
    "print('='*80)\n",
    "print()\n",
    "print('exp_004 (CV 0.0623 - BEST):')\n",
    "print('  1. Train HGB on spange features -> spange_pred')\n",
    "print('  2. Train HGB on acs_pca features -> acs_pred')\n",
    "print('  3. Final prediction = 0.8 * acs_pred + 0.2 * spange_pred')\n",
    "print()\n",
    "print('exp_016 (CV 0.0830 - WORSE):')\n",
    "print('  1. Combine features: combined = 0.8 * acs + 0.2 * spange')\n",
    "print('  2. Train single HGB on combined features -> pred')\n",
    "print()\n",
    "print('WHY PREDICTION COMBINATION IS BETTER:')\n",
    "print('  - Each model specializes in its feature space')\n",
    "print('  - Ensemble of diverse models reduces variance')\n",
    "print('  - Feature combination loses information through averaging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fa04e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:44:54.093775Z",
     "iopub.status.busy": "2026-01-14T04:44:54.093690Z",
     "iopub.status.idle": "2026-01-14T04:44:54.096976Z",
     "shell.execute_reply": "2026-01-14T04:44:54.096678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPECTED IMPROVEMENT FROM FIXING ARCHITECTURE\n",
      "================================================================================\n",
      "\n",
      "Single Solvent:\n",
      "  exp_016: 0.0647\n",
      "  exp_004: 0.0659\n",
      "  exp_016 is -1.8% better (already good)\n",
      "\n",
      "Full Data:\n",
      "  exp_016: 0.0928\n",
      "  exp_004: 0.0603\n",
      "  exp_016 is 53.9% WORSE (need to fix!)\n",
      "\n",
      "Expected Combined if we fix full data:\n",
      "  0.0647 * 0.35 + 0.0603 * 0.65 = 0.0618\n",
      "  This would be 0.7% better than exp_004!\n"
     ]
    }
   ],
   "source": [
    "# Calculate the expected improvement\n",
    "print('='*80)\n",
    "print('EXPECTED IMPROVEMENT FROM FIXING ARCHITECTURE')\n",
    "print('='*80)\n",
    "\n",
    "# exp_016 results\n",
    "single_016 = 0.0647\n",
    "full_016 = 0.0928\n",
    "\n",
    "# exp_004 results (target)\n",
    "single_004 = 0.0659\n",
    "full_004 = 0.0603\n",
    "\n",
    "print(f'\\nSingle Solvent:')\n",
    "print(f'  exp_016: {single_016:.4f}')\n",
    "print(f'  exp_004: {single_004:.4f}')\n",
    "print(f'  exp_016 is {(single_016-single_004)/single_004*100:.1f}% better (already good)')\n",
    "\n",
    "print(f'\\nFull Data:')\n",
    "print(f'  exp_016: {full_016:.4f}')\n",
    "print(f'  exp_004: {full_004:.4f}')\n",
    "print(f'  exp_016 is {(full_016-full_004)/full_004*100:.1f}% WORSE (need to fix!)')\n",
    "\n",
    "# If we fix full data to match exp_004\n",
    "expected_combined = single_016 * 0.35 + full_004 * 0.65\n",
    "print(f'\\nExpected Combined if we fix full data:')\n",
    "print(f'  {single_016:.4f} * 0.35 + {full_004:.4f} * 0.65 = {expected_combined:.4f}')\n",
    "print(f'  This would be {(0.0623-expected_combined)/0.0623*100:.1f}% better than exp_004!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d668d56f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:44:54.097749Z",
     "iopub.status.busy": "2026-01-14T04:44:54.097656Z",
     "iopub.status.idle": "2026-01-14T04:44:54.100703Z",
     "shell.execute_reply": "2026-01-14T04:44:54.100403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CV-LB GAP ANALYSIS\n",
      "================================================================================\n",
      "exp_004: CV=0.0623, LB=0.0956, Gap=53.5%\n",
      "exp_006: CV=0.0688, LB=0.0991, Gap=44.0%\n",
      "\n",
      "The CV-LB gap is ~50% for both experiments.\n",
      "This suggests the LOO validation is optimistic.\n",
      "\n",
      "However, the RELATIVE ranking is preserved:\n",
      "  exp_004 (CV 0.0623) -> LB 0.0956\n",
      "  exp_006 (CV 0.0688) -> LB 0.0991\n",
      "  Better CV = Better LB (correlation holds)\n"
     ]
    }
   ],
   "source": [
    "# Analyze CV-LB gap\n",
    "print('='*80)\n",
    "print('CV-LB GAP ANALYSIS')\n",
    "print('='*80)\n",
    "\n",
    "submissions = [\n",
    "    ('exp_004', 0.0623, 0.0956),\n",
    "    ('exp_006', 0.0688, 0.0991),\n",
    "]\n",
    "\n",
    "for exp, cv, lb in submissions:\n",
    "    gap = (lb - cv) / cv * 100\n",
    "    print(f'{exp}: CV={cv:.4f}, LB={lb:.4f}, Gap={gap:.1f}%')\n",
    "\n",
    "print(f'\\nThe CV-LB gap is ~50% for both experiments.')\n",
    "print(f'This suggests the LOO validation is optimistic.')\n",
    "print(f'\\nHowever, the RELATIVE ranking is preserved:')\n",
    "print(f'  exp_004 (CV 0.0623) -> LB 0.0956')\n",
    "print(f'  exp_006 (CV 0.0688) -> LB 0.0991')\n",
    "print(f'  Better CV = Better LB (correlation holds)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "439eeecf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:44:54.101545Z",
     "iopub.status.busy": "2026-01-14T04:44:54.101458Z",
     "iopub.status.idle": "2026-01-14T04:44:54.104424Z",
     "shell.execute_reply": "2026-01-14T04:44:54.104107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RECOMMENDED NEXT STEPS\n",
      "================================================================================\n",
      "\n",
      "1. REPLICATE exp_004 EXACTLY for full data:\n",
      "   - Train SEPARATE models on spange and acs_pca\n",
      "   - Combine PREDICTIONS: 0.8 * acs_pred + 0.2 * spange_pred\n",
      "   - Use same hyperparameters: HGB(depth=7, iter=700, lr=0.04)\n",
      "   - Use same hyperparameters: ETR(n_estimators=500, depth=10)\n",
      "\n",
      "2. Keep exp_015 approach for single solvent:\n",
      "   - Deep models + MLP work better for single solvent\n",
      "   - CV 0.0638 vs exp_004 0.0659\n",
      "\n",
      "3. Create TRUE hybrid:\n",
      "   - Single: exp_015 approach (deep + MLP)\n",
      "   - Full: exp_004 approach (PREDICTION combination)\n",
      "   - Expected: 0.0638 * 0.35 + 0.0603 * 0.65 = 0.0615\n"
     ]
    }
   ],
   "source": [
    "# Next steps\n",
    "print('='*80)\n",
    "print('RECOMMENDED NEXT STEPS')\n",
    "print('='*80)\n",
    "print()\n",
    "print('1. REPLICATE exp_004 EXACTLY for full data:')\n",
    "print('   - Train SEPARATE models on spange and acs_pca')\n",
    "print('   - Combine PREDICTIONS: 0.8 * acs_pred + 0.2 * spange_pred')\n",
    "print('   - Use same hyperparameters: HGB(depth=7, iter=700, lr=0.04)')\n",
    "print('   - Use same hyperparameters: ETR(n_estimators=500, depth=10)')\n",
    "print()\n",
    "print('2. Keep exp_015 approach for single solvent:')\n",
    "print('   - Deep models + MLP work better for single solvent')\n",
    "print('   - CV 0.0638 vs exp_004 0.0659')\n",
    "print()\n",
    "print('3. Create TRUE hybrid:')\n",
    "print('   - Single: exp_015 approach (deep + MLP)')\n",
    "print('   - Full: exp_004 approach (PREDICTION combination)')\n",
    "print('   - Expected: 0.0638 * 0.35 + 0.0603 * 0.65 = 0.0615')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
