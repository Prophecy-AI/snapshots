{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06381952",
   "metadata": {},
   "source": [
    "# Experiment 002: Template-Compliant Ensemble with Enhanced Features\n",
    "\n",
    "This experiment:\n",
    "1. **FIXES TEMPLATE COMPLIANCE** - Last 3 cells match template exactly\n",
    "2. Uses Arrhenius kinetics + polynomial features\n",
    "3. Ensemble of MLP + XGBoost + LightGBM + RF with TTA\n",
    "4. Bagging with 5 MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf95a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:40:37.499393Z",
     "iopub.status.busy": "2026-01-14T00:40:37.498891Z",
     "iopub.status.idle": "2026-01-14T00:40:39.181209Z",
     "shell.execute_reply": "2026-01-14T00:40:39.180797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.0+cu118\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from abc import ABC\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set paths for local execution\n",
    "DATA_PATH = '/home/data'\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086bf619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:40:39.182742Z",
     "iopub.status.busy": "2026-01-14T00:40:39.182256Z",
     "iopub.status.idle": "2026-01-14T00:40:39.190377Z",
     "shell.execute_reply": "2026-01-14T00:40:39.189988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), ACS_PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# --- UTILITY FUNCTIONS (matching template) ---\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_FEATURES = [\"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_FEATURES = [\"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load feature lookups\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "ACS_PCA_DF = load_features('acs_pca_descriptors')\n",
    "print(f\"Spange: {SPANGE_DF.shape}, ACS_PCA: {ACS_PCA_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73e5342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:40:39.191383Z",
     "iopub.status.busy": "2026-01-14T00:40:39.191275Z",
     "iopub.status.idle": "2026-01-14T00:40:39.194061Z",
     "shell.execute_reply": "2026-01-14T00:40:39.193739Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- BASE CLASSES (matching template) ---\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "    def featurize(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "    def predict(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "003bf60d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:40:39.195198Z",
     "iopub.status.busy": "2026-01-14T00:40:39.194917Z",
     "iopub.status.idle": "2026-01-14T00:40:39.203937Z",
     "shell.execute_reply": "2026-01-14T00:40:39.203601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent features: torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# --- ENHANCED FEATURIZER WITH ARRHENIUS + POLYNOMIAL FEATURES ---\n",
    "class EnhancedFeaturizer(SmilesFeaturizer):\n",
    "    \"\"\"Featurizer with Arrhenius kinetics + polynomial features.\"\"\"\n",
    "    def __init__(self, mixed=False, feature_set='spange'):\n",
    "        self.mixed = mixed\n",
    "        self.feature_set = feature_set\n",
    "        if feature_set == 'spange':\n",
    "            self.featurizer = SPANGE_DF\n",
    "        else:\n",
    "            self.featurizer = ACS_PCA_DF\n",
    "        \n",
    "        # Feature dimensions:\n",
    "        # - 2 numeric (rt, temp)\n",
    "        # - 5 Arrhenius/polynomial (inv_temp, log_time, interaction, rt*temp, temp^2)\n",
    "        # - N solvent features\n",
    "        # - 1 SolventB% for mixed\n",
    "        base_feats = 2 + 5 + self.featurizer.shape[1]\n",
    "        self.feats_dim = base_feats + (1 if mixed else 0)\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        # Numeric features\n",
    "        rt = X['Residence Time'].values.astype(np.float64).reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.astype(np.float64).reshape(-1, 1)\n",
    "        \n",
    "        # Arrhenius kinetic features\n",
    "        temp_k = temp + 273.15  # Kelvin\n",
    "        inv_temp = 1000.0 / temp_k  # Inverse temperature\n",
    "        log_time = np.log(rt + 1e-6)  # Log time\n",
    "        interaction = inv_temp * log_time  # Arrhenius interaction\n",
    "        \n",
    "        # Polynomial features\n",
    "        rt_temp = rt * temp / 1000.0  # Scaled interaction\n",
    "        temp_sq = (temp / 100.0) ** 2  # Scaled squared temp\n",
    "        \n",
    "        numeric_feats = np.hstack([rt, temp, inv_temp, log_time, interaction, rt_temp, temp_sq])\n",
    "        \n",
    "        # Solvent features\n",
    "        if self.mixed:\n",
    "            A = self.featurizer.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B = self.featurizer.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            \n",
    "            if flip:\n",
    "                # Symmetry flip\n",
    "                solvent_feats = B * (1 - pct) + A * pct\n",
    "            else:\n",
    "                solvent_feats = A * (1 - pct) + B * pct\n",
    "            \n",
    "            all_feats = np.hstack([numeric_feats, pct, solvent_feats])\n",
    "        else:\n",
    "            solvent_feats = self.featurizer.loc[X[\"SOLVENT NAME\"]].values\n",
    "            all_feats = np.hstack([numeric_feats, solvent_feats])\n",
    "        \n",
    "        return torch.tensor(all_feats, dtype=torch.double)\n",
    "\n",
    "# Test\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "feat = EnhancedFeaturizer(mixed=False)\n",
    "print(f\"Single solvent features: {feat.featurize(X_test.head(3)).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "908b5c43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:40:39.204844Z",
     "iopub.status.busy": "2026-01-14T00:40:39.204753Z",
     "iopub.status.idle": "2026-01-14T00:40:39.207624Z",
     "shell.execute_reply": "2026-01-14T00:40:39.207306Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- MLP ARCHITECTURE ---\n",
    "class MLPInternal(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb9e859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:40:39.208589Z",
     "iopub.status.busy": "2026-01-14T00:40:39.208497Z",
     "iopub.status.idle": "2026-01-14T00:40:39.218512Z",
     "shell.execute_reply": "2026-01-14T00:40:39.218149Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- ENSEMBLE MODEL CLASS ---\n",
    "class EnsembleModel(nn.Module, BaseModel):\n",
    "    \"\"\"Template-compliant ensemble with TTA for mixed solvents.\"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        super().__init__()\n",
    "        self.data_type = data\n",
    "        self.featurizer = EnhancedFeaturizer(mixed=(data=='full'), feature_set='spange')\n",
    "        \n",
    "        # Bagging: 5 MLP models\n",
    "        self.n_mlp = 5\n",
    "        self.mlp_models = nn.ModuleList()\n",
    "        \n",
    "        # GBDT models\n",
    "        self.xgb_model = None\n",
    "        self.lgb_model = None\n",
    "        self.rf_model = None\n",
    "        \n",
    "        # Scaler\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Ensemble weights\n",
    "        self.weights = [0.35, 0.25, 0.25, 0.15]\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Prepare features\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = torch.tensor(y_train.values, dtype=torch.double)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = torch.cat([X_std, X_flip], dim=0)\n",
    "            y_all = torch.cat([y_vals, y_vals], dim=0)\n",
    "        else:\n",
    "            X_all = X_std\n",
    "            y_all = y_vals\n",
    "        \n",
    "        X_np = X_all.numpy()\n",
    "        y_np = y_all.numpy()\n",
    "        X_scaled = self.scaler.fit_transform(X_np)\n",
    "        \n",
    "        input_dim = X_scaled.shape[1]\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Train MLPs with bagging\n",
    "        for i in range(self.n_mlp):\n",
    "            torch.manual_seed(42 + i)\n",
    "            np.random.seed(42 + i)\n",
    "            \n",
    "            model = MLPInternal(input_dim).to(device)\n",
    "            model.train()\n",
    "            self.mlp_models.append(model)\n",
    "            \n",
    "            X_t = torch.tensor(X_scaled, dtype=torch.double).to(device)\n",
    "            y_t = torch.tensor(y_np, dtype=torch.double).to(device)\n",
    "            \n",
    "            loader = DataLoader(TensorDataset(X_t, y_t), batch_size=32, shuffle=True)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "            criterion = nn.HuberLoss()\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=20)\n",
    "            \n",
    "            for epoch in range(200):\n",
    "                epoch_loss = 0.0\n",
    "                for inputs, targets in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = criterion(model(inputs), targets)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                scheduler.step(epoch_loss / len(X_t))\n",
    "        \n",
    "        # Train XGBoost\n",
    "        self.xgb_model = MultiOutputRegressor(\n",
    "            xgb.XGBRegressor(n_estimators=500, learning_rate=0.02, max_depth=6, \n",
    "                            subsample=0.8, colsample_bytree=0.8, random_state=42, verbosity=0)\n",
    "        )\n",
    "        self.xgb_model.fit(X_scaled, y_np)\n",
    "        \n",
    "        # Train LightGBM\n",
    "        self.lgb_model = MultiOutputRegressor(\n",
    "            lgb.LGBMRegressor(n_estimators=500, learning_rate=0.02, num_leaves=31,\n",
    "                             max_depth=6, subsample=0.8, colsample_bytree=0.8, \n",
    "                             random_state=42, verbosity=-1)\n",
    "        )\n",
    "        self.lgb_model.fit(X_scaled, y_np)\n",
    "        \n",
    "        # Train RandomForest\n",
    "        self.rf_model = MultiOutputRegressor(\n",
    "            RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\n",
    "        )\n",
    "        self.rf_model.fit(X_scaled, y_np)\n",
    "\n",
    "    def predict(self, X):\n",
    "        device = next(self.mlp_models[0].parameters()).device\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            # TTA for mixed solvents\n",
    "            X_std = self.featurizer.featurize(X, flip=False)\n",
    "            X_flip = self.featurizer.featurize(X, flip=True)\n",
    "            \n",
    "            X_std_sc = self.scaler.transform(X_std.numpy())\n",
    "            X_flip_sc = self.scaler.transform(X_flip.numpy())\n",
    "            \n",
    "            # MLP with TTA\n",
    "            mlp_sum = torch.zeros((len(X), 3)).to(device)\n",
    "            with torch.no_grad():\n",
    "                for model in self.mlp_models:\n",
    "                    model.eval()\n",
    "                    p1 = model(torch.tensor(X_std_sc, dtype=torch.double).to(device))\n",
    "                    p2 = model(torch.tensor(X_flip_sc, dtype=torch.double).to(device))\n",
    "                    mlp_sum += (p1 + p2) * 0.5\n",
    "            mlp_preds = (mlp_sum / self.n_mlp).cpu().numpy()\n",
    "            \n",
    "            # GBDT with TTA\n",
    "            xgb_preds = (self.xgb_model.predict(X_std_sc) + self.xgb_model.predict(X_flip_sc)) / 2\n",
    "            lgb_preds = (self.lgb_model.predict(X_std_sc) + self.lgb_model.predict(X_flip_sc)) / 2\n",
    "            rf_preds = (self.rf_model.predict(X_std_sc) + self.rf_model.predict(X_flip_sc)) / 2\n",
    "        else:\n",
    "            X_std = self.featurizer.featurize(X)\n",
    "            X_std_sc = self.scaler.transform(X_std.numpy())\n",
    "            \n",
    "            # MLP\n",
    "            mlp_sum = torch.zeros((len(X), 3)).to(device)\n",
    "            with torch.no_grad():\n",
    "                for model in self.mlp_models:\n",
    "                    model.eval()\n",
    "                    mlp_sum += model(torch.tensor(X_std_sc, dtype=torch.double).to(device))\n",
    "            mlp_preds = (mlp_sum / self.n_mlp).cpu().numpy()\n",
    "            \n",
    "            # GBDT\n",
    "            xgb_preds = self.xgb_model.predict(X_std_sc)\n",
    "            lgb_preds = self.lgb_model.predict(X_std_sc)\n",
    "            rf_preds = self.rf_model.predict(X_std_sc)\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        final = (self.weights[0] * mlp_preds + self.weights[1] * xgb_preds + \n",
    "                 self.weights[2] * lgb_preds + self.weights[3] * rf_preds)\n",
    "        final = np.clip(final, 0, 1)\n",
    "        \n",
    "        return torch.tensor(final, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5846769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:40:39.219729Z",
     "iopub.status.busy": "2026-01-14T00:40:39.219429Z",
     "iopub.status.idle": "2026-01-14T00:41:08.236036Z",
     "shell.execute_reply": "2026-01-14T00:41:08.235629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([156, 3])\n",
      "Sample predictions: tensor([[0.2813, 0.1892, 0.2006],\n",
      "        [0.2813, 0.1892, 0.2006],\n",
      "        [0.2813, 0.1892, 0.2006]])\n",
      "Test MAE: 0.076420\n"
     ]
    }
   ],
   "source": [
    "# Quick test of the model\n",
    "print(\"Testing model...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "X_train, Y_train = X_test.iloc[:500], Y_test.iloc[:500]\n",
    "X_val, Y_val = X_test.iloc[500:], Y_test.iloc[500:]\n",
    "\n",
    "test_model = EnsembleModel(data='single')\n",
    "test_model.train_model(X_train, Y_train)\n",
    "preds = test_model.predict(X_val)\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"Sample predictions: {preds[:3]}\")\n",
    "print(f\"Test MAE: {np.mean(np.abs(preds.numpy() - Y_val.values)):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f75554",
   "metadata": {},
   "source": [
    "## Template-Compliant Cross-Validation\n",
    "\n",
    "The following 3 cells are EXACTLY as in the template, with only the model definition line changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6e43646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:41:16.552137Z",
     "iopub.status.busy": "2026-01-14T00:41:16.551684Z",
     "iopub.status.idle": "2026-01-14T00:55:40.522536Z",
     "shell.execute_reply": "2026-01-14T00:55:40.522097Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:35, 35.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [01:12, 36.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:46, 35.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [02:21, 34.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:56, 35.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [03:32, 35.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [04:08, 35.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [04:43, 35.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [05:19, 35.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [05:55, 35.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [06:32, 35.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [07:07, 35.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [07:43, 35.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [08:18, 35.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [08:54, 35.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [09:30, 35.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [10:08, 36.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [10:44, 36.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [11:20, 36.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [11:56, 36.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [12:32, 36.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [13:09, 36.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [13:47, 36.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [14:23, 36.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [14:23, 36.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = EnsembleModel(data='single') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31cd465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T00:55:54.239431Z",
     "iopub.status.busy": "2026-01-14T00:55:54.239044Z",
     "iopub.status.idle": "2026-01-14T01:23:14.395833Z",
     "shell.execute_reply": "2026-01-14T01:23:14.395421Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:03, 123.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [04:04, 121.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [06:10, 123.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [08:11, 122.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [10:14, 122.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [12:17, 122.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [14:20, 123.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [16:26, 124.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [18:29, 123.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [20:43, 126.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [22:55, 128.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [25:07, 129.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [27:20, 130.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [27:20, 126.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = EnsembleModel(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7454e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f12749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CV scores (for logging only - not part of submission)\n",
    "import os\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "submission.to_csv('/home/submission/submission.csv', index=True)\n",
    "submission.to_csv('/home/code/experiments/002_template_compliant/submission.csv', index=True)\n",
    "\n",
    "# Calculate MAE from predictions\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "# Single solvent MAE\n",
    "single_preds = submission_single_solvent[['target_1', 'target_2', 'target_3']].values\n",
    "single_mae = np.mean(np.abs(single_preds - Y_single.values))\n",
    "\n",
    "# Full data MAE  \n",
    "full_preds = submission_full_data[['target_1', 'target_2', 'target_3']].values\n",
    "full_mae = np.mean(np.abs(full_preds - Y_full.values))\n",
    "\n",
    "# Combined\n",
    "total = len(single_preds) + len(full_preds)\n",
    "combined_mae = (single_mae * len(single_preds) + full_mae * len(full_preds)) / total\n",
    "\n",
    "print(f\"\\n=== FINAL CV RESULTS ===\")\n",
    "print(f\"Single Solvent MAE: {single_mae:.6f}\")\n",
    "print(f\"Full Data MAE: {full_mae:.6f}\")\n",
    "print(f\"Combined MAE: {combined_mae:.6f}\")\n",
    "print(f\"\\nSubmission saved to /home/submission/submission.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
