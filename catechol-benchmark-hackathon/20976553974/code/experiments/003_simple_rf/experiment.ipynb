{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15453ab4",
   "metadata": {},
   "source": [
    "# Experiment 003: Simple Random Forest with Strong Regularization\n",
    "\n",
    "Based on Loop 2 analysis:\n",
    "- Simple RF (0.0742) outperforms complex MLP+GBDT ensemble (0.081)\n",
    "- Path forward is SIMPLICITY, not COMPLEXITY\n",
    "- Strong regularization: max_depth=8, min_samples_leaf=5\n",
    "\n",
    "**TEMPLATE COMPLIANCE**: Last 3 cells are EXACTLY as template, NO cells after them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779f4654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:39:20.056456Z",
     "iopub.status.busy": "2026-01-14T01:39:20.056058Z",
     "iopub.status.idle": "2026-01-14T01:39:21.433083Z",
     "shell.execute_reply": "2026-01-14T01:39:21.432665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from abc import ABC\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "torch.set_default_dtype(torch.double)\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9b5a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:39:21.434459Z",
     "iopub.status.busy": "2026-01-14T01:39:21.434301Z",
     "iopub.status.idle": "2026-01-14T01:39:21.441113Z",
     "shell.execute_reply": "2026-01-14T01:39:21.440737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Spange descriptors: (26, 13)\n"
     ]
    }
   ],
   "source": [
    "# --- UTILITY FUNCTIONS ---\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "print(f\"Loaded Spange descriptors: {SPANGE_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487be41a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:39:21.442186Z",
     "iopub.status.busy": "2026-01-14T01:39:21.442077Z",
     "iopub.status.idle": "2026-01-14T01:39:21.444841Z",
     "shell.execute_reply": "2026-01-14T01:39:21.444455Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- BASE CLASSES ---\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self): raise NotImplementedError\n",
    "    def featurize(self, X): raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self): pass\n",
    "    def train_model(self, X_train, y_train): raise NotImplementedError\n",
    "    def predict(self): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23e5b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:39:21.446054Z",
     "iopub.status.busy": "2026-01-14T01:39:21.445791Z",
     "iopub.status.idle": "2026-01-14T01:39:21.449926Z",
     "shell.execute_reply": "2026-01-14T01:39:21.449598Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- ENHANCED FEATURIZER WITH ARRHENIUS FEATURES ---\n",
    "class EnhancedFeaturizer(SmilesFeaturizer):\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.featurizer = SPANGE_DF\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        rt = X['Residence Time'].values.astype(np.float64).reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.astype(np.float64).reshape(-1, 1)\n",
    "        \n",
    "        # Arrhenius kinetic features\n",
    "        temp_k = temp + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(rt + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        \n",
    "        numeric_feats = np.hstack([rt, temp, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A = self.featurizer.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B = self.featurizer.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                solvent_feats = B * (1 - pct) + A * pct\n",
    "            else:\n",
    "                solvent_feats = A * (1 - pct) + B * pct\n",
    "            all_feats = np.hstack([numeric_feats, pct, solvent_feats])\n",
    "        else:\n",
    "            solvent_feats = self.featurizer.loc[X[\"SOLVENT NAME\"]].values\n",
    "            all_feats = np.hstack([numeric_feats, solvent_feats])\n",
    "        \n",
    "        return all_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961bbd5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:39:21.450977Z",
     "iopub.status.busy": "2026-01-14T01:39:21.450756Z",
     "iopub.status.idle": "2026-01-14T01:39:21.455486Z",
     "shell.execute_reply": "2026-01-14T01:39:21.455145Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- SIMPLE RANDOM FOREST MODEL ---\n",
    "class SimpleRFModel(BaseModel):\n",
    "    \"\"\"Simple Random Forest with strong regularization.\n",
    "    \n",
    "    Based on Loop 2 analysis: RF (0.0742) > Complex Ensemble (0.081)\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.featurizer = EnhancedFeaturizer(mixed=(data=='full'))\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Random Forest with STRONG regularization to prevent overfitting\n",
    "        self.model = MultiOutputRegressor(\n",
    "            RandomForestRegressor(\n",
    "                n_estimators=200,\n",
    "                max_depth=8,           # Limit depth\n",
    "                min_samples_leaf=5,    # Require more samples per leaf\n",
    "                min_samples_split=10,  # Require more samples to split\n",
    "                max_features='sqrt',   # Limit features per split\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_feat = self.featurizer.featurize(X_train)\n",
    "        y = y_train.values\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            # Data augmentation with flipped features for mixed solvents\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_feat, X_flip])\n",
    "            y_all = np.vstack([y, y])\n",
    "        else:\n",
    "            X_all = X_feat\n",
    "            y_all = y\n",
    "        \n",
    "        X_scaled = self.scaler.fit_transform(X_all)\n",
    "        self.model.fit(X_scaled, y_all)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.data_type == 'full':\n",
    "            # TTA for mixed solvents\n",
    "            X_std = self.featurizer.featurize(X, flip=False)\n",
    "            X_flip = self.featurizer.featurize(X, flip=True)\n",
    "            \n",
    "            X_std_sc = self.scaler.transform(X_std)\n",
    "            X_flip_sc = self.scaler.transform(X_flip)\n",
    "            \n",
    "            preds = (self.model.predict(X_std_sc) + self.model.predict(X_flip_sc)) / 2\n",
    "        else:\n",
    "            X_feat = self.featurizer.featurize(X)\n",
    "            X_scaled = self.scaler.transform(X_feat)\n",
    "            preds = self.model.predict(X_scaled)\n",
    "        \n",
    "        preds = np.clip(preds, 0, 1)\n",
    "        return torch.tensor(preds, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "825d851a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:39:21.456581Z",
     "iopub.status.busy": "2026-01-14T01:39:21.456316Z",
     "iopub.status.idle": "2026-01-14T01:39:23.000153Z",
     "shell.execute_reply": "2026-01-14T01:39:22.999792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SimpleRFModel...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: MAE = 0.1878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MAE = 0.1249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: MAE = 0.0415\n",
      "\n",
      "Quick test MAE: 0.1181\n"
     ]
    }
   ],
   "source": [
    "# --- QUICK VALIDATION TEST ---\n",
    "print(\"Testing SimpleRFModel...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "# Quick leave-one-out test on first 3 solvents\n",
    "errors = []\n",
    "split_gen = generate_leave_one_out_splits(X_test, Y_test)\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(split_gen):\n",
    "    if i >= 3: break\n",
    "    model = SimpleRFModel(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    print(f\"Fold {i}: MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nQuick test MAE: {np.mean(errors):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb0bb5",
   "metadata": {},
   "source": [
    "## Template-Compliant Cross-Validation\n",
    "\n",
    "The following 3 cells are the FINAL 3 cells - EXACTLY as in the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf90e76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:39:27.228841Z",
     "iopub.status.busy": "2026-01-14T01:39:27.228465Z",
     "iopub.status.idle": "2026-01-14T01:39:39.647223Z",
     "shell.execute_reply": "2026-01-14T01:39:39.646828Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:01,  2.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:02,  1.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:02,  1.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:03,  1.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:03,  1.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:04,  1.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:04,  1.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:05,  1.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:05,  1.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:06,  1.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:06,  1.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:07,  1.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:07,  1.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:08,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:08,  1.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:09,  1.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:09,  1.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:10,  1.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:10,  1.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:11,  1.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:11,  1.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:12,  1.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:12,  1.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SimpleRFModel(data='single') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273316e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:39:44.024147Z",
     "iopub.status.busy": "2026-01-14T01:39:44.023633Z",
     "iopub.status.idle": "2026-01-14T01:39:52.012997Z",
     "shell.execute_reply": "2026-01-14T01:39:52.012633Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:01,  1.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:02,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:03,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:03,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:04,  1.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:04,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:05,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:06,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:06,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:07,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:07,  1.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:07,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SimpleRFModel(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a318b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:39:57.174126Z",
     "iopub.status.busy": "2026-01-14T01:39:57.173966Z",
     "iopub.status.idle": "2026-01-14T01:39:57.184325Z",
     "shell.execute_reply": "2026-01-14T01:39:57.183936Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
