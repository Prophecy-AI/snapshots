{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e4e5c7",
   "metadata": {},
   "source": [
    "# Experiment 014: Per-Target + Optuna Optimization\n",
    "\n",
    "**Key approach:**\n",
    "1. Per-target models: HGB for SM, ExtraTrees for Products (best CV from exp_004)\n",
    "2. Optuna hyperparameter optimization (key missing piece from top kernel)\n",
    "3. GroupKFold (5-fold) INTERNALLY for Optuna (faster iteration)\n",
    "4. LOO for final submission (REQUIRED by evaluation metric)\n",
    "\n",
    "**Hyperparameters to optimize:**\n",
    "- HGB: max_depth, learning_rate, max_iter\n",
    "- ETR: max_depth, n_estimators, min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f996d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:08:23.659844Z",
     "iopub.status.busy": "2026-01-14T04:08:23.659450Z",
     "iopub.status.idle": "2026-01-14T04:08:25.325013Z",
     "shell.execute_reply": "2026-01-14T04:08:25.324608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from abc import ABC\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "torch.set_default_dtype(torch.double)\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa32ea7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:08:25.326219Z",
     "iopub.status.busy": "2026-01-14T04:08:25.326047Z",
     "iopub.status.idle": "2026-01-14T04:08:25.335249Z",
     "shell.execute_reply": "2026-01-14T04:08:25.334900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 14)\n"
     ]
    }
   ],
   "source": [
    "# --- UTILITY FUNCTIONS ---\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "# Load Spange descriptors\n",
    "Spange = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv')\n",
    "print(f\"Spange: {Spange.shape}\")\n",
    "Spange_dict = {row['SOLVENT NAME']: row.drop('SOLVENT NAME').values for _, row in Spange.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561b3b0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:08:25.336188Z",
     "iopub.status.busy": "2026-01-14T04:08:25.336091Z",
     "iopub.status.idle": "2026-01-14T04:08:25.339416Z",
     "shell.execute_reply": "2026-01-14T04:08:25.339078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO utility functions defined\n"
     ]
    }
   ],
   "source": [
    "# --- LOO UTILITY FUNCTIONS (REQUIRED FOR SUBMISSION) ---\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    \"\"\"Leave-One-Solvent-Out for single solvent data (24 folds).\"\"\"\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    \"\"\"Leave-One-Ramp-Out for full data (13 folds).\"\"\"\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & \n",
    "                 (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print(\"LOO utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20719881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:08:25.340329Z",
     "iopub.status.busy": "2026-01-14T04:08:25.340221Z",
     "iopub.status.idle": "2026-01-14T04:08:25.342723Z",
     "shell.execute_reply": "2026-01-14T04:08:25.342410Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- BASE CLASSES ---\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self): raise NotImplementedError\n",
    "    def featurize(self, X): raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self): pass\n",
    "    def train_model(self, X_train, y_train): raise NotImplementedError\n",
    "    def predict(self): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce63af6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:08:25.343671Z",
     "iopub.status.busy": "2026-01-14T04:08:25.343582Z",
     "iopub.status.idle": "2026-01-14T04:08:25.347327Z",
     "shell.execute_reply": "2026-01-14T04:08:25.346995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction functions defined\n"
     ]
    }
   ],
   "source": [
    "# --- FEATURE EXTRACTION ---\n",
    "def get_features_single(X):\n",
    "    \"\"\"Extract features for single solvent data.\"\"\"\n",
    "    features = []\n",
    "    for _, row in X.iterrows():\n",
    "        solvent = row['SOLVENT NAME']\n",
    "        spange = Spange_dict.get(solvent, np.zeros(13))\n",
    "        feat = np.concatenate([[row['Residence Time'], row['Temperature']], spange])\n",
    "        features.append(feat)\n",
    "    return np.array(features)\n",
    "\n",
    "def get_features_full(X):\n",
    "    \"\"\"Extract features for full (mixed solvent) data.\"\"\"\n",
    "    features = []\n",
    "    for _, row in X.iterrows():\n",
    "        solvent_a = row['SOLVENT A NAME']\n",
    "        solvent_b = row['SOLVENT B NAME']\n",
    "        pct_b = row['SolventB%'] / 100.0\n",
    "        spange_a = Spange_dict.get(solvent_a, np.zeros(13))\n",
    "        spange_b = Spange_dict.get(solvent_b, np.zeros(13))\n",
    "        spange_mix = (1 - pct_b) * spange_a + pct_b * spange_b\n",
    "        feat = np.concatenate([[row['Residence Time'], row['Temperature'], pct_b], spange_mix])\n",
    "        features.append(feat)\n",
    "    return np.array(features)\n",
    "\n",
    "print(\"Feature extraction functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6497aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:08:29.521822Z",
     "iopub.status.busy": "2026-01-14T04:08:29.521342Z",
     "iopub.status.idle": "2026-01-14T04:09:56.556120Z",
     "shell.execute_reply": "2026-01-14T04:09:56.555742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Optuna optimization for single solvent data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3155f57dcdee40e8b7a5a8a258933505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best single solvent params: {'hgb_depth': 3, 'hgb_lr': 0.09437852301949078, 'hgb_iter': 326, 'etr_depth': 20, 'etr_n_estimators': 494, 'etr_min_samples': 8}\n",
      "Best single solvent CV (GroupKFold): 0.078348\n"
     ]
    }
   ],
   "source": [
    "# --- OPTUNA OPTIMIZATION FOR SINGLE SOLVENT DATA ---\n",
    "print(\"Running Optuna optimization for single solvent data...\")\n",
    "\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_feat_single = get_features_single(X_single)\n",
    "y_single = Y_single.values\n",
    "groups_single = X_single[\"SOLVENT NAME\"].values\n",
    "\n",
    "def objective_single(trial):\n",
    "    # HGB hyperparameters (for SM - target 2)\n",
    "    hgb_depth = trial.suggest_int('hgb_depth', 3, 10)\n",
    "    hgb_lr = trial.suggest_float('hgb_lr', 0.01, 0.3, log=True)\n",
    "    hgb_iter = trial.suggest_int('hgb_iter', 100, 500)\n",
    "    \n",
    "    # ETR hyperparameters (for Products - targets 0, 1)\n",
    "    etr_depth = trial.suggest_int('etr_depth', 5, 20)\n",
    "    etr_n_estimators = trial.suggest_int('etr_n_estimators', 100, 500)\n",
    "    etr_min_samples = trial.suggest_int('etr_min_samples', 2, 10)\n",
    "    \n",
    "    # Use GroupKFold for internal CV (faster)\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    errors = []\n",
    "    \n",
    "    for train_idx, val_idx in gkf.split(X_feat_single, y_single, groups=groups_single):\n",
    "        X_train, X_val = X_feat_single[train_idx], X_feat_single[val_idx]\n",
    "        y_train, y_val = y_single[train_idx], y_single[val_idx]\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        \n",
    "        # Train HGB for SM (target 2)\n",
    "        hgb = HistGradientBoostingRegressor(\n",
    "            max_depth=hgb_depth, learning_rate=hgb_lr, max_iter=hgb_iter, random_state=42)\n",
    "        hgb.fit(X_train_scaled, y_train[:, 2])\n",
    "        \n",
    "        # Train ETR for Products (targets 0, 1)\n",
    "        etr = ExtraTreesRegressor(\n",
    "            max_depth=etr_depth, n_estimators=etr_n_estimators, \n",
    "            min_samples_split=etr_min_samples, random_state=42, n_jobs=-1)\n",
    "        etr.fit(X_train_scaled, y_train[:, :2])\n",
    "        \n",
    "        # Predict\n",
    "        pred_products = etr.predict(X_val_scaled)\n",
    "        pred_sm = hgb.predict(X_val_scaled).reshape(-1, 1)\n",
    "        preds = np.column_stack([pred_products, pred_sm])\n",
    "        preds = np.clip(preds, 0, 1)\n",
    "        \n",
    "        mae = np.mean(np.abs(preds - y_val))\n",
    "        errors.append(mae)\n",
    "    \n",
    "    return np.mean(errors)\n",
    "\n",
    "# Run Optuna\n",
    "study_single = optuna.create_study(direction='minimize')\n",
    "study_single.optimize(objective_single, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest single solvent params: {study_single.best_params}\")\n",
    "print(f\"Best single solvent CV (GroupKFold): {study_single.best_value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c3f2767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:10:00.154527Z",
     "iopub.status.busy": "2026-01-14T04:10:00.154029Z",
     "iopub.status.idle": "2026-01-14T04:11:20.651790Z",
     "shell.execute_reply": "2026-01-14T04:11:20.651420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Optuna optimization for full data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11a0f4705e94080a0458ffc96792643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best full data params: {'hgb_depth': 4, 'hgb_lr': 0.19681752326845484, 'hgb_iter': 208, 'etr_depth': 6, 'etr_n_estimators': 188, 'etr_min_samples': 3}\n",
      "Best full data CV (GroupKFold): 0.083789\n"
     ]
    }
   ],
   "source": [
    "# --- OPTUNA OPTIMIZATION FOR FULL DATA ---\n",
    "print(\"Running Optuna optimization for full data...\")\n",
    "\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "X_feat_full = get_features_full(X_full)\n",
    "y_full = Y_full.values\n",
    "groups_full = (X_full[\"SOLVENT A NAME\"].astype(str) + \"_\" + X_full[\"SOLVENT B NAME\"].astype(str)).values\n",
    "\n",
    "def objective_full(trial):\n",
    "    # HGB hyperparameters (for SM - target 2)\n",
    "    hgb_depth = trial.suggest_int('hgb_depth', 3, 10)\n",
    "    hgb_lr = trial.suggest_float('hgb_lr', 0.01, 0.3, log=True)\n",
    "    hgb_iter = trial.suggest_int('hgb_iter', 100, 500)\n",
    "    \n",
    "    # ETR hyperparameters (for Products - targets 0, 1)\n",
    "    etr_depth = trial.suggest_int('etr_depth', 5, 20)\n",
    "    etr_n_estimators = trial.suggest_int('etr_n_estimators', 100, 500)\n",
    "    etr_min_samples = trial.suggest_int('etr_min_samples', 2, 10)\n",
    "    \n",
    "    # Use GroupKFold for internal CV (faster)\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    errors = []\n",
    "    \n",
    "    for train_idx, val_idx in gkf.split(X_feat_full, y_full, groups=groups_full):\n",
    "        X_train, X_val = X_feat_full[train_idx], X_feat_full[val_idx]\n",
    "        y_train, y_val = y_full[train_idx], y_full[val_idx]\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        \n",
    "        # Train HGB for SM (target 2)\n",
    "        hgb = HistGradientBoostingRegressor(\n",
    "            max_depth=hgb_depth, learning_rate=hgb_lr, max_iter=hgb_iter, random_state=42)\n",
    "        hgb.fit(X_train_scaled, y_train[:, 2])\n",
    "        \n",
    "        # Train ETR for Products (targets 0, 1)\n",
    "        etr = ExtraTreesRegressor(\n",
    "            max_depth=etr_depth, n_estimators=etr_n_estimators, \n",
    "            min_samples_split=etr_min_samples, random_state=42, n_jobs=-1)\n",
    "        etr.fit(X_train_scaled, y_train[:, :2])\n",
    "        \n",
    "        # Predict\n",
    "        pred_products = etr.predict(X_val_scaled)\n",
    "        pred_sm = hgb.predict(X_val_scaled).reshape(-1, 1)\n",
    "        preds = np.column_stack([pred_products, pred_sm])\n",
    "        preds = np.clip(preds, 0, 1)\n",
    "        \n",
    "        mae = np.mean(np.abs(preds - y_val))\n",
    "        errors.append(mae)\n",
    "    \n",
    "    return np.mean(errors)\n",
    "\n",
    "# Run Optuna\n",
    "study_full = optuna.create_study(direction='minimize')\n",
    "study_full.optimize(objective_full, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest full data params: {study_full.best_params}\")\n",
    "print(f\"Best full data CV (GroupKFold): {study_full.best_value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "930a182e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:11:25.248088Z",
     "iopub.status.busy": "2026-01-14T04:11:25.247619Z",
     "iopub.status.idle": "2026-01-14T04:11:25.253618Z",
     "shell.execute_reply": "2026-01-14T04:11:25.253265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best single params: {'hgb_depth': 3, 'hgb_lr': 0.09437852301949078, 'hgb_iter': 326, 'etr_depth': 20, 'etr_n_estimators': 494, 'etr_min_samples': 8}\n",
      "Best full params: {'hgb_depth': 4, 'hgb_lr': 0.19681752326845484, 'hgb_iter': 208, 'etr_depth': 6, 'etr_n_estimators': 188, 'etr_min_samples': 3}\n"
     ]
    }
   ],
   "source": [
    "# --- OPTUNA-OPTIMIZED PER-TARGET MODEL ---\n",
    "class OptunaPerTargetModel(BaseModel):\n",
    "    \"\"\"Per-target model with Optuna-optimized hyperparameters.\n",
    "    \n",
    "    Uses:\n",
    "    - HGB for SM (target 2) - captures gradient patterns\n",
    "    - ETR for Products (targets 0, 1) - robust to outliers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', params=None):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.params = params or {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.hgb = None\n",
    "        self.etr = None\n",
    "    \n",
    "    def _get_features(self, X):\n",
    "        if self.data == 'single':\n",
    "            return get_features_single(X)\n",
    "        else:\n",
    "            return get_features_full(X)\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_feat = self._get_features(X_train)\n",
    "        y_np = y_train.values\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        \n",
    "        # Get hyperparameters\n",
    "        hgb_depth = self.params.get('hgb_depth', 5)\n",
    "        hgb_lr = self.params.get('hgb_lr', 0.1)\n",
    "        hgb_iter = self.params.get('hgb_iter', 200)\n",
    "        etr_depth = self.params.get('etr_depth', 10)\n",
    "        etr_n_estimators = self.params.get('etr_n_estimators', 200)\n",
    "        etr_min_samples = self.params.get('etr_min_samples', 2)\n",
    "        \n",
    "        # Train HGB for SM (target 2)\n",
    "        self.hgb = HistGradientBoostingRegressor(\n",
    "            max_depth=hgb_depth, learning_rate=hgb_lr, max_iter=hgb_iter, random_state=42)\n",
    "        self.hgb.fit(X_scaled, y_np[:, 2])\n",
    "        \n",
    "        # Train ETR for Products (targets 0, 1)\n",
    "        self.etr = ExtraTreesRegressor(\n",
    "            max_depth=etr_depth, n_estimators=etr_n_estimators,\n",
    "            min_samples_split=etr_min_samples, random_state=42, n_jobs=-1)\n",
    "        self.etr.fit(X_scaled, y_np[:, :2])\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X_feat = self._get_features(X_test)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        pred_products = self.etr.predict(X_scaled)\n",
    "        pred_sm = self.hgb.predict(X_scaled).reshape(-1, 1)\n",
    "        preds = np.column_stack([pred_products, pred_sm])\n",
    "        preds = np.clip(preds, 0, 1)\n",
    "        \n",
    "        return torch.tensor(preds)\n",
    "\n",
    "# Store best params\n",
    "best_params_single = study_single.best_params\n",
    "best_params_full = study_full.best_params\n",
    "\n",
    "print(f\"Best single params: {best_params_single}\")\n",
    "print(f\"Best full params: {best_params_full}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9de98c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:11:25.254462Z",
     "iopub.status.busy": "2026-01-14T04:11:25.254354Z",
     "iopub.status.idle": "2026-01-14T04:11:26.311179Z",
     "shell.execute_reply": "2026-01-14T04:11:26.310784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick test of OptunaPerTargetModel with LOO...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.1687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.0359\n",
      "\n",
      "Quick test MAE (3 folds): 0.1071\n"
     ]
    }
   ],
   "source": [
    "# --- QUICK VALIDATION TEST ---\n",
    "print(\"Quick test of OptunaPerTargetModel with LOO...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "errors = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X_test, Y_test)):\n",
    "    if i >= 3: break\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    model = OptunaPerTargetModel(data='single', params=best_params_single)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    print(f\"Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nQuick test MAE (3 folds): {np.mean(errors):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d02923b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:11:30.270735Z",
     "iopub.status.busy": "2026-01-14T04:11:30.270066Z",
     "iopub.status.idle": "2026-01-14T04:11:38.686723Z",
     "shell.execute_reply": "2026-01-14T04:11:38.686343Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:01,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:01,  2.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:01,  2.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:02,  2.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:02,  2.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:02,  2.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:03,  2.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:03,  2.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:03,  2.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:04,  2.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:04,  2.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:04,  2.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:05,  2.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:05,  2.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:05,  2.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:06,  2.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:06,  2.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:07,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:07,  2.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:07,  2.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:08,  2.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:08,  2.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:08,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = OptunaPerTargetModel(data='single', params=best_params_single) # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7d1ecdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:11:38.687693Z",
     "iopub.status.busy": "2026-01-14T04:11:38.687598Z",
     "iopub.status.idle": "2026-01-14T04:11:41.770068Z",
     "shell.execute_reply": "2026-01-14T04:11:41.769678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  4.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:00,  4.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:01,  4.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:01,  4.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:01,  4.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:01,  4.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:02,  4.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:02,  4.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:02,  4.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:02,  4.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:03,  4.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:03,  4.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = OptunaPerTargetModel(data='full', params=best_params_full) # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2203060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:11:41.771019Z",
     "iopub.status.busy": "2026-01-14T04:11:41.770925Z",
     "iopub.status.idle": "2026-01-14T04:11:41.780080Z",
     "shell.execute_reply": "2026-01-14T04:11:41.779748Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
