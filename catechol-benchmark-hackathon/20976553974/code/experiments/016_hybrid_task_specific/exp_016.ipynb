{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12744626",
   "metadata": {},
   "source": [
    "# Experiment 016: Hybrid Model with Task-Specific Configurations\n",
    "\n",
    "**Key insight from exp_015 analysis:**\n",
    "- Single solvent: exp_015 (0.0638) is BETTER than exp_004 (0.0659)\n",
    "- Full data: exp_004 (0.0603) is MUCH BETTER than exp_015 (0.1027)\n",
    "\n",
    "**Solution: Use different configurations for each task:**\n",
    "- Single solvent: Deep models + MLP + COMBINED features (exp_015 approach)\n",
    "- Full data: Shallow models + NO MLP + Arrhenius features (exp_004 approach)\n",
    "\n",
    "**Expected CV**: 0.0638 * 0.35 + 0.0603 * 0.65 = 0.0615 (better than exp_004's 0.0623!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811b0867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:35:26.496587Z",
     "iopub.status.busy": "2026-01-14T04:35:26.496047Z",
     "iopub.status.idle": "2026-01-14T04:35:28.138591Z",
     "shell.execute_reply": "2026-01-14T04:35:28.138172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from abc import ABC\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "torch.set_default_dtype(torch.double)\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515bd6db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:35:28.139731Z",
     "iopub.status.busy": "2026-01-14T04:35:28.139569Z",
     "iopub.status.idle": "2026-01-14T04:35:28.152423Z",
     "shell.execute_reply": "2026-01-14T04:35:28.152078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 14)\n",
      "ACS_PCA: (24, 6)\n"
     ]
    }
   ],
   "source": [
    "# --- LOAD FEATURES ---\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "# Load features\n",
    "Spange = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv')\n",
    "ACS_PCA = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv')\n",
    "\n",
    "print(f\"Spange: {Spange.shape}\")\n",
    "print(f\"ACS_PCA: {ACS_PCA.shape}\")\n",
    "\n",
    "# Create lookup dictionaries\n",
    "Spange_dict = {row['SOLVENT NAME']: row.drop('SOLVENT NAME').values.astype(float) for _, row in Spange.iterrows()}\n",
    "ACS_PCA_dict = {row['SOLVENT NAME']: row.drop('SOLVENT NAME').values.astype(float) for _, row in ACS_PCA.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da690ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:35:28.153700Z",
     "iopub.status.busy": "2026-01-14T04:35:28.153415Z",
     "iopub.status.idle": "2026-01-14T04:35:28.156712Z",
     "shell.execute_reply": "2026-01-14T04:35:28.156403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO utility functions defined\n"
     ]
    }
   ],
   "source": [
    "# --- LOO UTILITY FUNCTIONS (REQUIRED FOR SUBMISSION) ---\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    \"\"\"Leave-One-Solvent-Out for single solvent data (24 folds).\"\"\"\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    \"\"\"Leave-One-Ramp-Out for full data (13 folds).\"\"\"\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & \n",
    "                 (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print(\"LOO utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b75c9419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:35:28.157486Z",
     "iopub.status.busy": "2026-01-14T04:35:28.157399Z",
     "iopub.status.idle": "2026-01-14T04:35:28.159938Z",
     "shell.execute_reply": "2026-01-14T04:35:28.159645Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- BASE CLASSES ---\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self): raise NotImplementedError\n",
    "    def featurize(self, X): raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self): pass\n",
    "    def train_model(self, X_train, y_train): raise NotImplementedError\n",
    "    def predict(self): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830bd48b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:35:28.160846Z",
     "iopub.status.busy": "2026-01-14T04:35:28.160634Z",
     "iopub.status.idle": "2026-01-14T04:35:28.164271Z",
     "shell.execute_reply": "2026-01-14T04:35:28.163962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMLP defined\n"
     ]
    }
   ],
   "source": [
    "# --- MLP ARCHITECTURE (for single solvent only) ---\n",
    "class SimpleMLP(nn.Module):\n",
    "    \"\"\"MLP with BatchNorm + ReLU + Dropout.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 64, 32], output_dim=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.BatchNorm1d(input_dim))\n",
    "        \n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.BatchNorm1d(h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = h_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.size(0) == 1 and self.training:\n",
    "            self.eval()\n",
    "            out = self.network(x)\n",
    "            self.train()\n",
    "            return out\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"SimpleMLP defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "414c72c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:35:28.165067Z",
     "iopub.status.busy": "2026-01-14T04:35:28.164977Z",
     "iopub.status.idle": "2026-01-14T04:35:28.174922Z",
     "shell.execute_reply": "2026-01-14T04:35:28.174584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridTaskModel defined\n"
     ]
    }
   ],
   "source": [
    "# --- HYBRID TASK-SPECIFIC MODEL ---\n",
    "class HybridTaskModel(BaseModel):\n",
    "    \"\"\"Hybrid model with task-specific configurations.\n",
    "    \n",
    "    Single solvent (exp_015 approach - works better):\n",
    "    - Deep models (depth=None) + MLP\n",
    "    - COMBINED features (0.8*ACS_PCA + 0.2*Spange)\n",
    "    - MLP weight = 0.5\n",
    "    \n",
    "    Full data (exp_004 approach - works better):\n",
    "    - Shallow models (depth=7/10) + NO MLP\n",
    "    - COMBINED features + Arrhenius kinetics\n",
    "    - Per-target: HGB for SM, ETR for Products\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data='single'):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.scaler = StandardScaler()\n",
    "        self.mlp = None\n",
    "        self.hgb = None\n",
    "        self.etr = None\n",
    "        \n",
    "        # Task-specific configurations\n",
    "        if data == 'single':\n",
    "            # exp_015 approach: Deep + MLP\n",
    "            self.use_mlp = True\n",
    "            self.mlp_weight = 0.5\n",
    "            self.hgb_depth = None  # Unlimited\n",
    "            self.etr_depth = None  # Unlimited\n",
    "            self.hgb_lr = 0.1\n",
    "            self.hgb_iter = 200\n",
    "            self.etr_n_estimators = 200\n",
    "        else:\n",
    "            # exp_004 approach: Shallow + NO MLP\n",
    "            self.use_mlp = False\n",
    "            self.mlp_weight = 0.0\n",
    "            self.hgb_depth = 7  # Shallow like exp_004\n",
    "            self.etr_depth = 10  # Shallow like exp_004\n",
    "            self.hgb_lr = 0.04\n",
    "            self.hgb_iter = 700\n",
    "            self.etr_n_estimators = 500\n",
    "    \n",
    "    def _get_features(self, X):\n",
    "        \"\"\"Extract features with task-specific approach.\"\"\"\n",
    "        SPANGE_WEIGHT = 0.2\n",
    "        ACS_WEIGHT = 0.8\n",
    "        \n",
    "        features = []\n",
    "        if self.data == 'single':\n",
    "            for _, row in X.iterrows():\n",
    "                solvent = row['SOLVENT NAME']\n",
    "                spange = Spange_dict.get(solvent, np.zeros(13))\n",
    "                acs_pca = ACS_PCA_dict.get(solvent, np.zeros(5))\n",
    "                \n",
    "                rt = row['Residence Time']\n",
    "                temp = row['Temperature']\n",
    "                \n",
    "                # COMBINED features\n",
    "                combined = np.concatenate([\n",
    "                    [rt, temp],\n",
    "                    ACS_WEIGHT * acs_pca,\n",
    "                    SPANGE_WEIGHT * spange\n",
    "                ])\n",
    "                features.append(combined)\n",
    "        else:\n",
    "            # Full data: Add Arrhenius kinetics features (CRITICAL for exp_004)\n",
    "            for _, row in X.iterrows():\n",
    "                solvent_a = row['SOLVENT A NAME']\n",
    "                solvent_b = row['SOLVENT B NAME']\n",
    "                pct_b = row['SolventB%'] / 100.0\n",
    "                \n",
    "                spange_a = Spange_dict.get(solvent_a, np.zeros(13))\n",
    "                spange_b = Spange_dict.get(solvent_b, np.zeros(13))\n",
    "                acs_a = ACS_PCA_dict.get(solvent_a, np.zeros(5))\n",
    "                acs_b = ACS_PCA_dict.get(solvent_b, np.zeros(5))\n",
    "                \n",
    "                # Linear interpolation for mixed solvents\n",
    "                spange_mix = (1 - pct_b) * spange_a + pct_b * spange_b\n",
    "                acs_mix = (1 - pct_b) * acs_a + pct_b * acs_b\n",
    "                \n",
    "                rt = row['Residence Time']\n",
    "                temp = row['Temperature']\n",
    "                \n",
    "                # Arrhenius kinetics features (CRITICAL - missing in exp_015)\n",
    "                temp_k = temp + 273.15\n",
    "                inv_temp = 1000.0 / temp_k  # 1/T\n",
    "                log_time = np.log(rt + 1e-6)  # ln(t)\n",
    "                interaction = inv_temp * log_time  # t*T interaction\n",
    "                \n",
    "                # COMBINED features + Arrhenius\n",
    "                combined = np.concatenate([\n",
    "                    [rt, temp, pct_b],\n",
    "                    [inv_temp, log_time, interaction],  # Arrhenius features\n",
    "                    ACS_WEIGHT * acs_mix,\n",
    "                    SPANGE_WEIGHT * spange_mix\n",
    "                ])\n",
    "                features.append(combined)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_feat = self._get_features(X_train)\n",
    "        y_np = y_train.values\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        \n",
    "        # 1. Train MLP (only for single solvent)\n",
    "        if self.use_mlp:\n",
    "            input_dim = X_scaled.shape[1]\n",
    "            self.mlp = SimpleMLP(input_dim, hidden_dims=[128, 64, 32], output_dim=3, dropout=0.2).to(device)\n",
    "            X_tensor = torch.tensor(X_scaled, dtype=torch.double).to(device)\n",
    "            y_tensor = torch.tensor(y_np, dtype=torch.double).to(device)\n",
    "            dataset = TensorDataset(X_tensor, y_tensor)\n",
    "            loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "            optimizer = torch.optim.Adam(self.mlp.parameters(), lr=1e-3)\n",
    "            criterion = nn.MSELoss()\n",
    "            \n",
    "            self.mlp.train()\n",
    "            for epoch in range(100):\n",
    "                for batch_X, batch_y in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = self.mlp(batch_X)\n",
    "                    loss = criterion(pred, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "        \n",
    "        # 2. Train HGB for SM (target 2)\n",
    "        self.hgb = HistGradientBoostingRegressor(\n",
    "            max_depth=self.hgb_depth,\n",
    "            learning_rate=self.hgb_lr,\n",
    "            max_iter=self.hgb_iter,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.hgb.fit(X_scaled, y_np[:, 2])\n",
    "        \n",
    "        # 3. Train ETR for Products (targets 0, 1)\n",
    "        self.etr = ExtraTreesRegressor(\n",
    "            n_estimators=self.etr_n_estimators,\n",
    "            max_depth=self.etr_depth,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=2 if self.data == 'full' else 1,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        self.etr.fit(X_scaled, y_np[:, :2])\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X_feat = self._get_features(X_test)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        # GBDT predictions\n",
    "        hgb_pred_sm = self.hgb.predict(X_scaled).reshape(-1, 1)\n",
    "        etr_pred_products = self.etr.predict(X_scaled)\n",
    "        gbdt_pred = np.column_stack([etr_pred_products, hgb_pred_sm])\n",
    "        \n",
    "        if self.use_mlp:\n",
    "            # MLP prediction\n",
    "            self.mlp.eval()\n",
    "            with torch.no_grad():\n",
    "                X_tensor = torch.tensor(X_scaled, dtype=torch.double).to(device)\n",
    "                mlp_pred = self.mlp(X_tensor).cpu().numpy()\n",
    "            \n",
    "            # Weighted ensemble\n",
    "            final_pred = self.mlp_weight * mlp_pred + (1 - self.mlp_weight) * gbdt_pred\n",
    "        else:\n",
    "            # GBDT only for full data\n",
    "            final_pred = gbdt_pred\n",
    "        \n",
    "        final_pred = np.clip(final_pred, 0, 1)\n",
    "        return torch.tensor(final_pred)\n",
    "\n",
    "print(\"HybridTaskModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "712d3f5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:35:35.059662Z",
     "iopub.status.busy": "2026-01-14T04:35:35.059149Z",
     "iopub.status.idle": "2026-01-14T04:35:47.728373Z",
     "shell.execute_reply": "2026-01-14T04:35:47.727955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick test of HybridTaskModel...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.1666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.0404\n",
      "\n",
      "Single solvent quick test MAE: 0.1042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 0: MAE = 0.0764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 1: MAE = 0.1203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 2: MAE = 0.0973\n",
      "\n",
      "Full data quick test MAE: 0.0980\n"
     ]
    }
   ],
   "source": [
    "# --- QUICK VALIDATION TEST ---\n",
    "print(\"Quick test of HybridTaskModel...\")\n",
    "\n",
    "# Test single solvent\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "errors_single = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X_single, Y_single)):\n",
    "    if i >= 3: break\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    model = HybridTaskModel(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_single.append(mae)\n",
    "    print(f\"Single Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nSingle solvent quick test MAE: {np.mean(errors_single):.4f}\")\n",
    "\n",
    "# Test full data\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "errors_full = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    if i >= 3: break\n",
    "    model = HybridTaskModel(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_full.append(mae)\n",
    "    print(f\"Full Fold {i}: MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nFull data quick test MAE: {np.mean(errors_full):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b195435a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:35:53.069956Z",
     "iopub.status.busy": "2026-01-14T04:35:53.069570Z",
     "iopub.status.idle": "2026-01-14T04:37:10.622113Z",
     "shell.execute_reply": "2026-01-14T04:37:10.621705Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:03,  3.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:06,  3.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:09,  3.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:12,  3.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:15,  3.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:19,  3.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:22,  3.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:25,  3.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:28,  3.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:32,  3.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:35,  3.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:38,  3.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:41,  3.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:44,  3.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:48,  3.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:51,  3.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:54,  3.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:57,  3.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [01:01,  3.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [01:04,  3.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [01:07,  3.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [01:11,  3.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [01:14,  3.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [01:17,  3.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [01:17,  3.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = HybridTaskModel(data='single') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74da10e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:37:10.623118Z",
     "iopub.status.busy": "2026-01-14T04:37:10.623014Z",
     "iopub.status.idle": "2026-01-14T04:37:21.197137Z",
     "shell.execute_reply": "2026-01-14T04:37:21.196736Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:05,  1.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:06,  1.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:07,  1.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:08,  1.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:08,  1.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:09,  1.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:10,  1.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:10,  1.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = HybridTaskModel(data='full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8183d615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:37:21.198099Z",
     "iopub.status.busy": "2026-01-14T04:37:21.198000Z",
     "iopub.status.idle": "2026-01-14T04:37:21.207302Z",
     "shell.execute_reply": "2026-01-14T04:37:21.206941Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
