{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d79124a9",
   "metadata": {},
   "source": [
    "# Experiment 010: MLP + GBDT Ensemble (Like Top Kernel)\n",
    "\n",
    "**Key Insight from Loop 9**: Top kernel (lishellliang) uses MLP + XGBoost + RF + LightGBM ensemble.\n",
    "Our diverse ensemble (exp_009) had WORSE CV than per-target (exp_004) because we were missing MLP.\n",
    "\n",
    "**Implementation**:\n",
    "- MLP: [128, 64, 32] with BatchNorm + ReLU + Dropout(0.2), Sigmoid output\n",
    "- XGBoost: n_estimators=200, max_depth=6, learning_rate=0.05\n",
    "- RandomForest: n_estimators=200, max_depth=10\n",
    "- LightGBM: n_estimators=200, max_depth=6, learning_rate=0.05\n",
    "- Ensemble Weights: [0.35, 0.25, 0.25, 0.15] for MLP, XGB, RF, LGB\n",
    "- Features: Spange descriptors only (simpler may generalize better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e3d1fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:22:04.399535Z",
     "iopub.status.busy": "2026-01-14T03:22:04.399005Z",
     "iopub.status.idle": "2026-01-14T03:22:06.102810Z",
     "shell.execute_reply": "2026-01-14T03:22:06.102423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from abc import ABC\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "torch.set_default_dtype(torch.double)\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee88216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:22:06.103915Z",
     "iopub.status.busy": "2026-01-14T03:22:06.103770Z",
     "iopub.status.idle": "2026-01-14T03:22:06.110251Z",
     "shell.execute_reply": "2026-01-14T03:22:06.109898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13)\n"
     ]
    }
   ],
   "source": [
    "# --- UTILITY FUNCTIONS ---\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load Spange descriptors only (like top kernel)\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "print(f\"Spange: {SPANGE_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a354b3c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:22:06.111280Z",
     "iopub.status.busy": "2026-01-14T03:22:06.111186Z",
     "iopub.status.idle": "2026-01-14T03:22:06.113636Z",
     "shell.execute_reply": "2026-01-14T03:22:06.113315Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- BASE CLASSES ---\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self): raise NotImplementedError\n",
    "    def featurize(self, X): raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self): pass\n",
    "    def train_model(self, X_train, y_train): raise NotImplementedError\n",
    "    def predict(self): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b9834d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:22:06.114538Z",
     "iopub.status.busy": "2026-01-14T03:22:06.114447Z",
     "iopub.status.idle": "2026-01-14T03:22:06.117645Z",
     "shell.execute_reply": "2026-01-14T03:22:06.117319Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- MLP ARCHITECTURE (from top kernel) ---\n",
    "class EnhancedMLP(nn.Module):\n",
    "    \"\"\"MLP with BatchNorm + ReLU + Dropout, Sigmoid output.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 64, 32], output_dim=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        \n",
    "        # Input BatchNorm\n",
    "        layers.append(nn.BatchNorm1d(input_dim))\n",
    "        \n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.BatchNorm1d(h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = h_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())  # Yields are 0-1\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63897ca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:22:06.118581Z",
     "iopub.status.busy": "2026-01-14T03:22:06.118371Z",
     "iopub.status.idle": "2026-01-14T03:22:06.126803Z",
     "shell.execute_reply": "2026-01-14T03:22:06.126451Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- MLP + GBDT ENSEMBLE MODEL ---\n",
    "class MLPGBDTEnsemble(BaseModel):\n",
    "    \"\"\"Ensemble of MLP + XGBoost + RandomForest + LightGBM.\n",
    "    \n",
    "    This is what top kernels use successfully.\n",
    "    \n",
    "    Key components:\n",
    "    - MLP: Captures non-linear patterns that trees miss\n",
    "    - XGBoost: Gradient boosting\n",
    "    - RandomForest: Bagging ensemble\n",
    "    - LightGBM: Fast gradient boosting\n",
    "    \n",
    "    Ensemble weights: [0.35, 0.25, 0.25, 0.15] for MLP, XGB, RF, LGB\n",
    "    Features: Spange descriptors only (simpler may generalize better)\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.spange = SPANGE_DF\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Models\n",
    "        self.mlp = None\n",
    "        self.xgb_model = None\n",
    "        self.rf_model = None\n",
    "        self.lgb_model = None\n",
    "        \n",
    "        # Ensemble weights\n",
    "        self.weights = [0.35, 0.25, 0.25, 0.15]  # MLP, XGB, RF, LGB\n",
    "    \n",
    "    def _build_features(self, X):\n",
    "        \"\"\"Build features: Time + Temp + Spange descriptors.\"\"\"\n",
    "        rt = X['Residence Time'].values.astype(np.float64).reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.astype(np.float64).reshape(-1, 1)\n",
    "        \n",
    "        if self.mixed:\n",
    "            pct = X['SolventB%'].values.reshape(-1, 1)\n",
    "            A_spange = self.spange.loc[X['SOLVENT A NAME']].values\n",
    "            B_spange = self.spange.loc[X['SOLVENT B NAME']].values\n",
    "            spange_feats = A_spange * (1 - pct) + B_spange * pct\n",
    "            return np.hstack([rt, temp, pct, spange_feats])\n",
    "        else:\n",
    "            spange_feats = self.spange.loc[X['SOLVENT NAME']].values\n",
    "            return np.hstack([rt, temp, spange_feats])\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_feat = self._build_features(X_train)\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        y = y_train.values\n",
    "        \n",
    "        input_dim = X_scaled.shape[1]\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # 1. Train MLP\n",
    "        self.mlp = EnhancedMLP(input_dim, hidden_dims=[128, 64, 32], output_dim=3, dropout=0.2).to(device)\n",
    "        self.mlp.train()\n",
    "        \n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.double).to(device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.double).to(device)\n",
    "        \n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.mlp.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "        criterion = nn.HuberLoss()\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=20)\n",
    "        \n",
    "        for epoch in range(200):\n",
    "            epoch_loss = 0.0\n",
    "            for inputs, targets in loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.mlp(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.mlp.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item() * inputs.size(0)\n",
    "            scheduler.step(epoch_loss / len(dataset))\n",
    "        \n",
    "        # 2. Train XGBoost\n",
    "        self.xgb_model = MultiOutputRegressor(\n",
    "            xgb.XGBRegressor(\n",
    "                n_estimators=200, max_depth=6, learning_rate=0.05,\n",
    "                subsample=0.8, colsample_bytree=0.8,\n",
    "                random_state=42, verbosity=0\n",
    "            )\n",
    "        )\n",
    "        self.xgb_model.fit(X_scaled, y)\n",
    "        \n",
    "        # 3. Train RandomForest\n",
    "        self.rf_model = MultiOutputRegressor(\n",
    "            RandomForestRegressor(\n",
    "                n_estimators=200, max_depth=10, min_samples_leaf=2,\n",
    "                random_state=42, n_jobs=-1\n",
    "            )\n",
    "        )\n",
    "        self.rf_model.fit(X_scaled, y)\n",
    "        \n",
    "        # 4. Train LightGBM\n",
    "        self.lgb_model = MultiOutputRegressor(\n",
    "            lgb.LGBMRegressor(\n",
    "                n_estimators=200, max_depth=6, learning_rate=0.05,\n",
    "                subsample=0.8, colsample_bytree=0.8,\n",
    "                random_state=42, verbosity=-1\n",
    "            )\n",
    "        )\n",
    "        self.lgb_model.fit(X_scaled, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_feat = self._build_features(X)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        device = next(self.mlp.parameters()).device\n",
    "        \n",
    "        # MLP predictions\n",
    "        self.mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X_scaled, dtype=torch.double).to(device)\n",
    "            mlp_preds = self.mlp(X_tensor).cpu().numpy()\n",
    "        \n",
    "        # GBDT predictions\n",
    "        xgb_preds = self.xgb_model.predict(X_scaled)\n",
    "        rf_preds = self.rf_model.predict(X_scaled)\n",
    "        lgb_preds = self.lgb_model.predict(X_scaled)\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        final_preds = (\n",
    "            self.weights[0] * mlp_preds +\n",
    "            self.weights[1] * xgb_preds +\n",
    "            self.weights[2] * rf_preds +\n",
    "            self.weights[3] * lgb_preds\n",
    "        )\n",
    "        \n",
    "        final_preds = np.clip(final_preds, 0, 1)\n",
    "        return torch.tensor(final_preds, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd5db8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:22:06.128006Z",
     "iopub.status.busy": "2026-01-14T03:22:06.127747Z",
     "iopub.status.idle": "2026-01-14T03:22:30.209674Z",
     "shell.execute_reply": "2026-01-14T03:22:30.209241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MLPGBDTEnsemble...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.1714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.0261\n",
      "\n",
      "Quick test MAE (single): 0.1084\n"
     ]
    }
   ],
   "source": [
    "# --- QUICK VALIDATION TEST ---\n",
    "print(\"Testing MLPGBDTEnsemble...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "# Quick leave-one-out test on first 3 solvents\n",
    "errors = []\n",
    "split_gen = generate_leave_one_out_splits(X_test, Y_test)\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(split_gen):\n",
    "    if i >= 3: break\n",
    "    model = MLPGBDTEnsemble(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    print(f\"Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nQuick test MAE (single): {np.mean(errors):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc5c3a",
   "metadata": {},
   "source": [
    "## Template-Compliant Cross-Validation\n",
    "\n",
    "The following 3 cells are the FINAL 3 cells - EXACTLY as in the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2238511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:22:36.429355Z",
     "iopub.status.busy": "2026-01-14T03:22:36.428698Z",
     "iopub.status.idle": "2026-01-14T03:25:44.040406Z",
     "shell.execute_reply": "2026-01-14T03:25:44.039984Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:07,  7.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:15,  7.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:22,  7.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:30,  7.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:38,  7.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:46,  7.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:53,  7.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [01:01,  7.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [01:09,  7.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [01:17,  7.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [01:24,  7.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [01:33,  7.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [01:41,  7.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [01:48,  7.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [01:56,  7.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [02:04,  7.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [02:13,  8.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [02:21,  8.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [02:28,  7.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [02:36,  7.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [02:44,  7.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [02:52,  7.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [02:59,  7.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [03:07,  7.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [03:07,  7.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MLPGBDTEnsemble(data='single') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e53a1319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:25:44.041647Z",
     "iopub.status.busy": "2026-01-14T03:25:44.041305Z",
     "iopub.status.idle": "2026-01-14T03:28:41.680713Z",
     "shell.execute_reply": "2026-01-14T03:28:41.680314Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:13, 13.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:26, 13.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:39, 13.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:52, 13.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:05, 13.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [01:19, 13.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [01:32, 13.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [01:45, 13.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [01:58, 13.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [02:13, 13.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [02:28, 14.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [02:43, 14.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [02:57, 14.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [02:57, 13.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MLPGBDTEnsemble(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "720cf4d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:28:41.681760Z",
     "iopub.status.busy": "2026-01-14T03:28:41.681656Z",
     "iopub.status.idle": "2026-01-14T03:28:41.691405Z",
     "shell.execute_reply": "2026-01-14T03:28:41.691043Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
