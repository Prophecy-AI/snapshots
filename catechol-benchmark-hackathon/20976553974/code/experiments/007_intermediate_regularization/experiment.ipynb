{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4233174",
   "metadata": {},
   "source": [
    "# Experiment 007: Intermediate Regularization with Combined Features\n",
    "\n",
    "**Goal**: Find the sweet spot between underfitting (Ridge) and overfitting (deep trees).\n",
    "\n",
    "Based on Loop 6 analysis:\n",
    "- ETR(depth=7) is optimal: GroupKFold CV 0.0713\n",
    "- Combined features (DRFP-PCA(15) + Spange + ACS_PCA) achieve best CV: 0.0706\n",
    "- Per-target models: HGB(depth=5) for SM, ETR(depth=7) for Products\n",
    "- NO TTA\n",
    "\n",
    "**Expected**: GroupKFold CV ~0.07, potentially better LB due to less overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dabee6b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:31:06.162258Z",
     "iopub.status.busy": "2026-01-14T02:31:06.161750Z",
     "iopub.status.idle": "2026-01-14T02:31:07.529975Z",
     "shell.execute_reply": "2026-01-14T02:31:07.529534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from abc import ABC\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "torch.set_default_dtype(torch.double)\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e9e0db4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:31:07.531270Z",
     "iopub.status.busy": "2026-01-14T02:31:07.531104Z",
     "iopub.status.idle": "2026-01-14T02:31:07.558573Z",
     "shell.execute_reply": "2026-01-14T02:31:07.558207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13)\n",
      "ACS_PCA: (24, 5)\n",
      "DRFP: (24, 2048)\n"
     ]
    }
   ],
   "source": [
    "# --- UTILITY FUNCTIONS ---\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load all feature sets\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "ACS_PCA_DF = load_features('acs_pca_descriptors')\n",
    "DRFP_DF = load_features('drfps_catechol')\n",
    "\n",
    "print(f\"Spange: {SPANGE_DF.shape}\")\n",
    "print(f\"ACS_PCA: {ACS_PCA_DF.shape}\")\n",
    "print(f\"DRFP: {DRFP_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7606599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:31:07.559452Z",
     "iopub.status.busy": "2026-01-14T02:31:07.559362Z",
     "iopub.status.idle": "2026-01-14T02:31:07.562071Z",
     "shell.execute_reply": "2026-01-14T02:31:07.561744Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- BASE CLASSES ---\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self): raise NotImplementedError\n",
    "    def featurize(self, X): raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self): pass\n",
    "    def train_model(self, X_train, y_train): raise NotImplementedError\n",
    "    def predict(self): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b84fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:31:07.562956Z",
     "iopub.status.busy": "2026-01-14T02:31:07.562866Z",
     "iopub.status.idle": "2026-01-14T02:31:07.653473Z",
     "shell.execute_reply": "2026-01-14T02:31:07.650015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRFP-PCA: (24, 15)\n",
      "Explained variance: 0.949\n"
     ]
    }
   ],
   "source": [
    "# Precompute DRFP-PCA for all solvents\n",
    "# Apply PCA to reduce DRFP from 2048 to 15 dimensions\n",
    "drfp_pca = PCA(n_components=15, random_state=42)\n",
    "DRFP_PCA_VALUES = drfp_pca.fit_transform(DRFP_DF.values)\n",
    "DRFP_PCA_DF = pd.DataFrame(DRFP_PCA_VALUES, index=DRFP_DF.index)\n",
    "print(f\"DRFP-PCA: {DRFP_PCA_DF.shape}\")\n",
    "print(f\"Explained variance: {drfp_pca.explained_variance_ratio_.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e838bab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:31:07.656703Z",
     "iopub.status.busy": "2026-01-14T02:31:07.656388Z",
     "iopub.status.idle": "2026-01-14T02:31:07.741483Z",
     "shell.execute_reply": "2026-01-14T02:31:07.741091Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- INTERMEDIATE REGULARIZATION MODEL ---\n",
    "class IntermediateRegModel(BaseModel):\n",
    "    \"\"\"Per-target model with intermediate regularization and combined features.\n",
    "    \n",
    "    Key insights from Loop 6 analysis:\n",
    "    - ETR(depth=7) is optimal: GroupKFold CV 0.0713\n",
    "    - Combined features (DRFP-PCA + Spange + ACS_PCA) achieve best CV: 0.0706\n",
    "    - Per-target: HGB(depth=5) for SM, ETR(depth=7) for Products\n",
    "    - NO TTA\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.targets = ['Product 2', 'Product 3', 'SM']\n",
    "        \n",
    "        # Feature dataframes\n",
    "        self.spange = SPANGE_DF\n",
    "        self.acs_pca = ACS_PCA_DF\n",
    "        self.drfp_pca = DRFP_PCA_DF\n",
    "        \n",
    "        # Scaler\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Per-target models\n",
    "        self.models = {}\n",
    "        \n",
    "    def _build_features(self, X):\n",
    "        \"\"\"Build combined features: Arrhenius + DRFP-PCA + Spange + ACS_PCA.\"\"\"\n",
    "        rt = X['Residence Time'].values.astype(np.float64).reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.astype(np.float64).reshape(-1, 1)\n",
    "        \n",
    "        # Arrhenius kinetic features\n",
    "        temp_k = temp + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(rt + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        \n",
    "        process_feats = np.hstack([rt, temp, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            pct = X['SolventB%'].values.reshape(-1, 1)\n",
    "            \n",
    "            # Spange features (weighted mix)\n",
    "            A_spange = self.spange.loc[X['SOLVENT A NAME']].values\n",
    "            B_spange = self.spange.loc[X['SOLVENT B NAME']].values\n",
    "            spange_feats = A_spange * (1 - pct) + B_spange * pct\n",
    "            \n",
    "            # ACS_PCA features (weighted mix)\n",
    "            A_acs = self.acs_pca.loc[X['SOLVENT A NAME']].values\n",
    "            B_acs = self.acs_pca.loc[X['SOLVENT B NAME']].values\n",
    "            acs_feats = A_acs * (1 - pct) + B_acs * pct\n",
    "            \n",
    "            # DRFP-PCA features (weighted mix)\n",
    "            A_drfp = self.drfp_pca.loc[X['SOLVENT A NAME']].values\n",
    "            B_drfp = self.drfp_pca.loc[X['SOLVENT B NAME']].values\n",
    "            drfp_feats = A_drfp * (1 - pct) + B_drfp * pct\n",
    "            \n",
    "            return np.hstack([process_feats, pct, spange_feats, acs_feats, drfp_feats])\n",
    "        else:\n",
    "            spange_feats = self.spange.loc[X['SOLVENT NAME']].values\n",
    "            acs_feats = self.acs_pca.loc[X['SOLVENT NAME']].values\n",
    "            drfp_feats = self.drfp_pca.loc[X['SOLVENT NAME']].values\n",
    "            return np.hstack([process_feats, spange_feats, acs_feats, drfp_feats])\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Build features - NO AUGMENTATION!\n",
    "        X_feat = self._build_features(X_train)\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        y = y_train.values\n",
    "        \n",
    "        # Train per-target models with INTERMEDIATE regularization\n",
    "        for i, target in enumerate(self.targets):\n",
    "            y_target = y[:, i]\n",
    "            \n",
    "            if target == 'SM':\n",
    "                # HGB with depth=5 for SM (was 7)\n",
    "                model = HistGradientBoostingRegressor(\n",
    "                    max_depth=5, max_iter=500, learning_rate=0.05, random_state=42\n",
    "                )\n",
    "            else:\n",
    "                # ETR with depth=7 for Products (was 10)\n",
    "                model = ExtraTreesRegressor(\n",
    "                    n_estimators=200, max_depth=7, min_samples_leaf=2,\n",
    "                    random_state=42, n_jobs=-1\n",
    "                )\n",
    "            \n",
    "            model.fit(X_scaled, y_target)\n",
    "            self.models[target] = model\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Build features - NO TTA!\n",
    "        X_feat = self._build_features(X)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        preds_all = []\n",
    "        for target in self.targets:\n",
    "            p = self.models[target].predict(X_scaled)\n",
    "            preds_all.append(p.reshape(-1, 1))\n",
    "        \n",
    "        preds = np.hstack(preds_all)\n",
    "        preds = np.clip(preds, 0, 1)\n",
    "        return torch.tensor(preds, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a254bd1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:31:07.744738Z",
     "iopub.status.busy": "2026-01-14T02:31:07.744539Z",
     "iopub.status.idle": "2026-01-14T02:31:11.797956Z",
     "shell.execute_reply": "2026-01-14T02:31:11.797558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing IntermediateRegModel...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.1709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.0479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 (Acetonitrile): MAE = 0.0765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 (Acetonitrile.Acetic Acid): MAE = 0.1250\n",
      "\n",
      "Quick test MAE (single): 0.1062\n",
      "\n",
      "Testing on full data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: MAE = 0.0644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MAE = 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: MAE = 0.0655\n",
      "\n",
      "Quick test MAE (full): 0.0770\n"
     ]
    }
   ],
   "source": [
    "# --- QUICK VALIDATION TEST ---\n",
    "print(\"Testing IntermediateRegModel...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "# Quick leave-one-out test on first 5 solvents\n",
    "errors = []\n",
    "split_gen = generate_leave_one_out_splits(X_test, Y_test)\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(split_gen):\n",
    "    if i >= 5: break\n",
    "    model = IntermediateRegModel(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    print(f\"Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nQuick test MAE (single): {np.mean(errors):.4f}\")\n",
    "\n",
    "# Also test on full data\n",
    "print(\"\\nTesting on full data...\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "errors_full = []\n",
    "split_gen = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(split_gen):\n",
    "    if i >= 3: break\n",
    "    model = IntermediateRegModel(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_full.append(mae)\n",
    "    print(f\"Fold {i}: MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nQuick test MAE (full): {np.mean(errors_full):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706d5c83",
   "metadata": {},
   "source": [
    "## Template-Compliant Cross-Validation\n",
    "\n",
    "The following 3 cells are the FINAL 3 cells - EXACTLY as in the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e4f7ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:31:18.507437Z",
     "iopub.status.busy": "2026-01-14T02:31:18.507147Z",
     "iopub.status.idle": "2026-01-14T02:31:30.618387Z",
     "shell.execute_reply": "2026-01-14T02:31:30.617982Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:01,  1.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:02,  1.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:02,  1.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:03,  1.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:03,  1.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:04,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:04,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:05,  1.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:05,  1.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:06,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:06,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:07,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:07,  2.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:08,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:08,  1.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:09,  1.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:09,  1.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:10,  1.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:10,  1.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:11,  2.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:11,  2.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:12,  2.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:12,  1.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = IntermediateRegModel(data='single') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "299180a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:31:30.619360Z",
     "iopub.status.busy": "2026-01-14T02:31:30.619249Z",
     "iopub.status.idle": "2026-01-14T02:31:37.620535Z",
     "shell.execute_reply": "2026-01-14T02:31:37.620137Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:01,  1.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:02,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:02,  1.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:03,  1.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:03,  1.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:04,  1.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:04,  1.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:05,  1.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:05,  1.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:06,  1.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:06,  1.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:06,  1.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = IntermediateRegModel(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2b2c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:31:37.621502Z",
     "iopub.status.busy": "2026-01-14T02:31:37.621398Z",
     "iopub.status.idle": "2026-01-14T02:31:37.630810Z",
     "shell.execute_reply": "2026-01-14T02:31:37.630475Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
