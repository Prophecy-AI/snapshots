{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6327e0",
   "metadata": {},
   "source": [
    "# Experiment 018: DRFP-Based Ensemble with Prediction Combination\n",
    "\n",
    "**Key insight from research:**\n",
    "- Paper arxiv:2512.19530 shows GNN + DRFP achieves MSE 0.0039 on Catechol benchmark\n",
    "- DRFP (Differential Reaction Fingerprints) captures reaction-level information\n",
    "- May generalize better to unseen solvents than Spange/ACS_PCA\n",
    "\n",
    "**Architecture:**\n",
    "- Build on exp_004's successful dual-model ensemble\n",
    "- Add DRFP-PCA as THIRD feature set\n",
    "- Train separate models on each feature set\n",
    "- Combine PREDICTIONS: 0.35 * drfp_pred + 0.45 * acs_pred + 0.20 * spange_pred\n",
    "\n",
    "**Expected result:**\n",
    "- DRFP may capture chemical patterns that generalize better\n",
    "- Could reduce the 53% CV-LB gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ac0f41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:58:22.611868Z",
     "iopub.status.busy": "2026-01-14T04:58:22.611317Z",
     "iopub.status.idle": "2026-01-14T04:58:24.017660Z",
     "shell.execute_reply": "2026-01-14T04:58:24.017068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from abc import ABC\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "torch.set_default_dtype(torch.double)\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2254e22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:58:24.019027Z",
     "iopub.status.busy": "2026-01-14T04:58:24.018859Z",
     "iopub.status.idle": "2026-01-14T04:58:24.058687Z",
     "shell.execute_reply": "2026-01-14T04:58:24.058290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), ACS_PCA: (24, 5), DRFP: (24, 2048)\n",
      "DRFP-PCA: (24, 20), variance explained: 99.73%\n"
     ]
    }
   ],
   "source": [
    "# --- UTILITY FUNCTIONS ---\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & \n",
    "                 (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load feature dataframes\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "ACS_PCA_DF = load_features('acs_pca_descriptors')\n",
    "DRFP_DF = load_features('drfps_catechol')\n",
    "\n",
    "print(f\"Spange: {SPANGE_DF.shape}, ACS_PCA: {ACS_PCA_DF.shape}, DRFP: {DRFP_DF.shape}\")\n",
    "\n",
    "# Apply PCA to DRFP (2048 dims -> 20 dims, captures 99.73% variance)\n",
    "DRFP_PCA = PCA(n_components=20)\n",
    "DRFP_PCA_VALUES = DRFP_PCA.fit_transform(DRFP_DF)\n",
    "DRFP_PCA_DF = pd.DataFrame(DRFP_PCA_VALUES, index=DRFP_DF.index, \n",
    "                           columns=[f'drfp_pca_{i}' for i in range(20)])\n",
    "print(f\"DRFP-PCA: {DRFP_PCA_DF.shape}, variance explained: {DRFP_PCA.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022f99da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:58:24.059987Z",
     "iopub.status.busy": "2026-01-14T04:58:24.059871Z",
     "iopub.status.idle": "2026-01-14T04:58:24.063032Z",
     "shell.execute_reply": "2026-01-14T04:58:24.062670Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- BASE CLASSES ---\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self): raise NotImplementedError\n",
    "    def featurize(self, X): raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self): pass\n",
    "    def train_model(self, X_train, y_train): raise NotImplementedError\n",
    "    def predict(self): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727edf77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:58:24.064323Z",
     "iopub.status.busy": "2026-01-14T04:58:24.064173Z",
     "iopub.status.idle": "2026-01-14T04:58:24.076322Z",
     "shell.execute_reply": "2026-01-14T04:58:24.075720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRFPEnsembleModel defined\n"
     ]
    }
   ],
   "source": [
    "# --- DRFP-ENHANCED ENSEMBLE MODEL ---\n",
    "class DRFPEnsembleModel(BaseModel):\n",
    "    \"\"\"Ensemble with THREE feature sets: Spange, ACS_PCA, and DRFP-PCA.\n",
    "    \n",
    "    Architecture (building on exp_004):\n",
    "    - Train SEPARATE models on each feature set for EACH target\n",
    "    - Combine PREDICTIONS: 0.35 * drfp_pred + 0.45 * acs_pred + 0.20 * spange_pred\n",
    "    - HGB for SM (depth=7, iter=700, lr=0.04)\n",
    "    - ETR for Products (n_estimators=500, depth=10, min_samples_leaf=2)\n",
    "    - Arrhenius kinetics features (inv_temp, log_time, interaction)\n",
    "    - NO TTA\n",
    "    \n",
    "    Key hypothesis: DRFP captures reaction-level patterns that may generalize better.\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.targets = ['Product 2', 'Product 3', 'SM']\n",
    "        \n",
    "        # Load all three feature sets\n",
    "        self.spange = SPANGE_DF\n",
    "        self.acs_pca = ACS_PCA_DF\n",
    "        self.drfp_pca = DRFP_PCA_DF\n",
    "        \n",
    "        # Scalers for each feature set\n",
    "        self.scaler_spange = StandardScaler()\n",
    "        self.scaler_acs = StandardScaler()\n",
    "        self.scaler_drfp = StandardScaler()\n",
    "        \n",
    "        # Models: {target: {feature_set: model}}\n",
    "        self.models = {}\n",
    "        \n",
    "        # Feature weights for PREDICTION combination\n",
    "        # Hypothesis: DRFP may generalize better, so give it significant weight\n",
    "        self.drfp_weight = 0.35\n",
    "        self.acs_weight = 0.45\n",
    "        self.spange_weight = 0.20\n",
    "\n",
    "    def _build_features(self, X, feature_df):\n",
    "        \"\"\"Build features with Arrhenius kinetics.\"\"\"\n",
    "        rt = X['Residence Time'].values.astype(np.float64).reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.astype(np.float64).reshape(-1, 1)\n",
    "        \n",
    "        # Arrhenius kinetic features\n",
    "        temp_k = temp + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(rt + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        \n",
    "        if self.mixed:\n",
    "            pct = X['SolventB%'].values.reshape(-1, 1)\n",
    "            A = feature_df.loc[X['SOLVENT A NAME']].values\n",
    "            B = feature_df.loc[X['SOLVENT B NAME']].values\n",
    "            solvent_feats = A * (1 - pct) + B * pct\n",
    "            return np.hstack([rt, temp, inv_temp, log_time, interaction, pct, solvent_feats])\n",
    "        else:\n",
    "            solvent_feats = feature_df.loc[X['SOLVENT NAME']].values\n",
    "            return np.hstack([rt, temp, inv_temp, log_time, interaction, solvent_feats])\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Build features for all three feature sets\n",
    "        X_spange = self._build_features(X_train, self.spange)\n",
    "        X_acs = self._build_features(X_train, self.acs_pca)\n",
    "        X_drfp = self._build_features(X_train, self.drfp_pca)\n",
    "        \n",
    "        # Scale\n",
    "        X_spange_sc = self.scaler_spange.fit_transform(X_spange)\n",
    "        X_acs_sc = self.scaler_acs.fit_transform(X_acs)\n",
    "        X_drfp_sc = self.scaler_drfp.fit_transform(X_drfp)\n",
    "        \n",
    "        y = y_train.values\n",
    "        \n",
    "        # Train per-target models (SEPARATE models for each feature set)\n",
    "        for i, target in enumerate(self.targets):\n",
    "            y_target = y[:, i]\n",
    "            \n",
    "            if target == 'SM':\n",
    "                # HistGradientBoosting for SM\n",
    "                model_spange = HistGradientBoostingRegressor(\n",
    "                    max_depth=7, max_iter=700, learning_rate=0.04, random_state=42\n",
    "                )\n",
    "                model_acs = HistGradientBoostingRegressor(\n",
    "                    max_depth=7, max_iter=700, learning_rate=0.04, random_state=42\n",
    "                )\n",
    "                model_drfp = HistGradientBoostingRegressor(\n",
    "                    max_depth=7, max_iter=700, learning_rate=0.04, random_state=42\n",
    "                )\n",
    "            else:\n",
    "                # ExtraTrees for Products\n",
    "                model_spange = ExtraTreesRegressor(\n",
    "                    n_estimators=500, max_depth=10, min_samples_leaf=2,\n",
    "                    random_state=42, n_jobs=-1\n",
    "                )\n",
    "                model_acs = ExtraTreesRegressor(\n",
    "                    n_estimators=500, max_depth=10, min_samples_leaf=2,\n",
    "                    random_state=42, n_jobs=-1\n",
    "                )\n",
    "                model_drfp = ExtraTreesRegressor(\n",
    "                    n_estimators=500, max_depth=10, min_samples_leaf=2,\n",
    "                    random_state=42, n_jobs=-1\n",
    "                )\n",
    "            \n",
    "            model_spange.fit(X_spange_sc, y_target)\n",
    "            model_acs.fit(X_acs_sc, y_target)\n",
    "            model_drfp.fit(X_drfp_sc, y_target)\n",
    "            \n",
    "            self.models[target] = {\n",
    "                'spange': model_spange, \n",
    "                'acs': model_acs,\n",
    "                'drfp': model_drfp\n",
    "            }\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Build features\n",
    "        X_spange = self._build_features(X, self.spange)\n",
    "        X_acs = self._build_features(X, self.acs_pca)\n",
    "        X_drfp = self._build_features(X, self.drfp_pca)\n",
    "        \n",
    "        X_spange_sc = self.scaler_spange.transform(X_spange)\n",
    "        X_acs_sc = self.scaler_acs.transform(X_acs)\n",
    "        X_drfp_sc = self.scaler_drfp.transform(X_drfp)\n",
    "        \n",
    "        preds_all = []\n",
    "        for target in self.targets:\n",
    "            p_spange = self.models[target]['spange'].predict(X_spange_sc)\n",
    "            p_acs = self.models[target]['acs'].predict(X_acs_sc)\n",
    "            p_drfp = self.models[target]['drfp'].predict(X_drfp_sc)\n",
    "            \n",
    "            # PREDICTION combination: weighted average of all three\n",
    "            p_combined = (self.drfp_weight * p_drfp + \n",
    "                          self.acs_weight * p_acs + \n",
    "                          self.spange_weight * p_spange)\n",
    "            preds_all.append(p_combined.reshape(-1, 1))\n",
    "        \n",
    "        preds = np.hstack(preds_all)\n",
    "        preds = np.clip(preds, 0, 1)\n",
    "        return torch.tensor(preds, dtype=torch.double)\n",
    "\n",
    "print(\"DRFPEnsembleModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba0ccca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:58:24.077560Z",
     "iopub.status.busy": "2026-01-14T04:58:24.077451Z",
     "iopub.status.idle": "2026-01-14T04:58:42.483011Z",
     "shell.execute_reply": "2026-01-14T04:58:42.482638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DRFPEnsembleModel...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.1532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.0375\n",
      "\n",
      "Single solvent quick test MAE: 0.0974\n",
      "\n",
      "Testing on full data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 0: MAE = 0.0673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 1: MAE = 0.0963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 2: MAE = 0.0618\n",
      "\n",
      "Full data quick test MAE: 0.0752\n"
     ]
    }
   ],
   "source": [
    "# --- QUICK VALIDATION TEST ---\n",
    "print(\"Testing DRFPEnsembleModel...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "# Quick test on first 3 solvents\n",
    "errors = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X_test, Y_test)):\n",
    "    if i >= 3: break\n",
    "    model = DRFPEnsembleModel(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    print(f\"Single Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nSingle solvent quick test MAE: {np.mean(errors):.4f}\")\n",
    "\n",
    "# Also test on full data\n",
    "print(\"\\nTesting on full data...\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "errors_full = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    if i >= 3: break\n",
    "    model = DRFPEnsembleModel(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_full.append(mae)\n",
    "    print(f\"Full Fold {i}: MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nFull data quick test MAE: {np.mean(errors_full):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3bff4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:58:49.159458Z",
     "iopub.status.busy": "2026-01-14T04:58:49.158961Z",
     "iopub.status.idle": "2026-01-14T04:59:59.763108Z",
     "shell.execute_reply": "2026-01-14T04:59:59.762731Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:02,  2.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:05,  2.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:08,  2.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:11,  2.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:14,  2.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:17,  2.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:20,  2.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:23,  2.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:26,  2.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:29,  2.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:32,  2.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:35,  2.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:38,  2.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:41,  2.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:44,  2.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:47,  2.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:50,  2.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:53,  2.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:55,  2.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:58,  2.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [01:01,  2.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [01:04,  2.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [01:07,  2.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [01:10,  2.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [01:10,  2.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = DRFPEnsembleModel(data='single') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "831208f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:59:59.764436Z",
     "iopub.status.busy": "2026-01-14T04:59:59.764331Z",
     "iopub.status.idle": "2026-01-14T05:00:40.549055Z",
     "shell.execute_reply": "2026-01-14T05:00:40.548714Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:03,  3.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:06,  3.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:09,  3.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:12,  3.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:15,  3.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:18,  3.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:21,  3.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:25,  3.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:28,  3.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:31,  3.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:34,  3.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:37,  3.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:40,  3.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:40,  3.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = DRFPEnsembleModel(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8014dbad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:00:40.550478Z",
     "iopub.status.busy": "2026-01-14T05:00:40.550141Z",
     "iopub.status.idle": "2026-01-14T05:00:40.560127Z",
     "shell.execute_reply": "2026-01-14T05:00:40.559786Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
