{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02b2084",
   "metadata": {},
   "source": [
    "# Experiment 029: Improved GNN with GAT and Edge Features\n",
    "\n",
    "**Goal**: Implement a proper GNN approach that can break the CV-LB relationship plateau.\n",
    "\n",
    "**Key improvements over exp_020 (basic GNN, CV 0.099)**:\n",
    "1. Use Graph Attention Networks (GAT) instead of GCN\n",
    "2. Add edge features (bond type, aromaticity, conjugation)\n",
    "3. Multi-task learning across all 3 targets\n",
    "4. Proper learning rate schedule (cosine annealing)\n",
    "5. Combine molecular graph features with process conditions\n",
    "\n",
    "**Hypothesis**: GNN can learn generalizable molecular representations that transfer better to unseen solvents.\n",
    "\n",
    "**TEMPLATE COMPLIANCE**: Last 3 cells are EXACTLY as template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5616d02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:13:00.450733Z",
     "iopub.status.busy": "2026-01-14T07:13:00.450231Z",
     "iopub.status.idle": "2026-01-14T07:13:00.454061Z",
     "shell.execute_reply": "2026-01-14T07:13:00.453706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "PyTorch: 2.2.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, global_max_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from abc import ABC\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "torch.set_default_dtype(torch.double)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9e3755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:13:00.454906Z",
     "iopub.status.busy": "2026-01-14T07:13:00.454803Z",
     "iopub.status.idle": "2026-01-14T07:13:00.461474Z",
     "shell.execute_reply": "2026-01-14T07:13:00.461142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), ACS_PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# --- UTILITY FUNCTIONS ---\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load feature sets\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "ACS_PCA_DF = load_features('acs_pca_descriptors')\n",
    "print(f\"Spange: {SPANGE_DF.shape}, ACS_PCA: {ACS_PCA_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdfed517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:13:00.462252Z",
     "iopub.status.busy": "2026-01-14T07:13:00.462159Z",
     "iopub.status.idle": "2026-01-14T07:13:00.464601Z",
     "shell.execute_reply": "2026-01-14T07:13:00.464274Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- BASE CLASSES ---\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self): raise NotImplementedError\n",
    "    def featurize(self, X): raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self): pass\n",
    "    def train_model(self, X_train, y_train): raise NotImplementedError\n",
    "    def predict(self): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e489dea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:13:00.465504Z",
     "iopub.status.busy": "2026-01-14T07:13:00.465413Z",
     "iopub.status.idle": "2026-01-14T07:13:00.486968Z",
     "shell.execute_reply": "2026-01-14T07:13:00.486632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES lookup: (26, 1)\n",
      "                                           solvent smiles\n",
      "SOLVENT NAME                                             \n",
      "Cyclohexane                                      C1CCCCC1\n",
      "Ethyl Acetate                                   O=C(OCC)C\n",
      "Acetic Acid                                       CC(=O)O\n",
      "2-Methyltetrahydrofuran [2-MeTHF]              O1C(C)CCC1\n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol  C(C(F)(F)F)(C(F)(F)F)O\n",
      "Pre-computed 26 solvent graphs\n",
      "Example graph: Data(x=[6, 22], edge_index=[2, 12], edge_attr=[12, 6])\n"
     ]
    }
   ],
   "source": [
    "# --- MOLECULAR GRAPH UTILITIES ---\n",
    "\n",
    "# Load SMILES lookup\n",
    "smiles_lookup = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "print(f\"SMILES lookup: {smiles_lookup.shape}\")\n",
    "print(smiles_lookup.head())\n",
    "\n",
    "def get_atom_features(atom):\n",
    "    \"\"\"Get atom features for GNN.\"\"\"\n",
    "    # Atom type one-hot (C, N, O, F, S, Cl, Br, I, other)\n",
    "    atom_types = ['C', 'N', 'O', 'F', 'S', 'Cl', 'Br', 'I']\n",
    "    atom_type = [1 if atom.GetSymbol() == t else 0 for t in atom_types]\n",
    "    atom_type.append(1 if atom.GetSymbol() not in atom_types else 0)  # other\n",
    "    \n",
    "    # Degree (0-5)\n",
    "    degree = [1 if atom.GetDegree() == i else 0 for i in range(6)]\n",
    "    \n",
    "    # Hybridization\n",
    "    hyb = atom.GetHybridization()\n",
    "    hybridization = [\n",
    "        1 if hyb == Chem.rdchem.HybridizationType.SP else 0,\n",
    "        1 if hyb == Chem.rdchem.HybridizationType.SP2 else 0,\n",
    "        1 if hyb == Chem.rdchem.HybridizationType.SP3 else 0,\n",
    "    ]\n",
    "    \n",
    "    # Other features\n",
    "    other = [\n",
    "        atom.GetIsAromatic() * 1.0,\n",
    "        atom.GetFormalCharge() / 2.0,  # normalize\n",
    "        atom.GetNumRadicalElectrons(),\n",
    "        atom.IsInRing() * 1.0,\n",
    "    ]\n",
    "    \n",
    "    return atom_type + degree + hybridization + other  # 9 + 6 + 3 + 4 = 22 features\n",
    "\n",
    "def get_bond_features(bond):\n",
    "    \"\"\"Get bond features for GNN.\"\"\"\n",
    "    bond_type = bond.GetBondType()\n",
    "    features = [\n",
    "        1 if bond_type == Chem.rdchem.BondType.SINGLE else 0,\n",
    "        1 if bond_type == Chem.rdchem.BondType.DOUBLE else 0,\n",
    "        1 if bond_type == Chem.rdchem.BondType.TRIPLE else 0,\n",
    "        1 if bond_type == Chem.rdchem.BondType.AROMATIC else 0,\n",
    "        bond.GetIsConjugated() * 1.0,\n",
    "        bond.IsInRing() * 1.0,\n",
    "    ]\n",
    "    return features  # 6 features\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"Convert SMILES to PyG graph.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    # Get atom features\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features.append(get_atom_features(atom))\n",
    "    x = torch.tensor(atom_features, dtype=torch.double)\n",
    "    \n",
    "    # Get edge indices and features\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_index.extend([[i, j], [j, i]])  # bidirectional\n",
    "        bf = get_bond_features(bond)\n",
    "        edge_attr.extend([bf, bf])  # same features for both directions\n",
    "    \n",
    "    if len(edge_index) == 0:\n",
    "        # Single atom molecule\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.zeros((0, 6), dtype=torch.double)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.double)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "# Pre-compute graphs for all solvents\n",
    "SOLVENT_GRAPHS = {}\n",
    "for solvent_name in smiles_lookup.index:\n",
    "    smiles = smiles_lookup.loc[solvent_name, 'solvent smiles']  # Fixed column name\n",
    "    graph = smiles_to_graph(smiles)\n",
    "    if graph is not None:\n",
    "        SOLVENT_GRAPHS[solvent_name] = graph\n",
    "        \n",
    "print(f\"Pre-computed {len(SOLVENT_GRAPHS)} solvent graphs\")\n",
    "print(f\"Example graph: {list(SOLVENT_GRAPHS.values())[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a74aa3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:13:00.487962Z",
     "iopub.status.busy": "2026-01-14T07:13:00.487873Z",
     "iopub.status.idle": "2026-01-14T07:13:00.493917Z",
     "shell.execute_reply": "2026-01-14T07:13:00.493583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN model defined\n"
     ]
    }
   ],
   "source": [
    "# --- GAT-BASED GNN MODEL ---\n",
    "\n",
    "class GATEncoder(nn.Module):\n",
    "    \"\"\"Graph Attention Network encoder for molecular graphs.\"\"\"\n",
    "    def __init__(self, node_dim=22, edge_dim=6, hidden_dim=64, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Node embedding\n",
    "        self.node_embed = nn.Linear(node_dim, hidden_dim)\n",
    "        \n",
    "        # Edge embedding\n",
    "        self.edge_embed = nn.Linear(edge_dim, hidden_dim)\n",
    "        \n",
    "        # GAT layers\n",
    "        self.conv1 = GATConv(hidden_dim, hidden_dim, heads=num_heads, dropout=dropout, edge_dim=hidden_dim)\n",
    "        self.conv2 = GATConv(hidden_dim * num_heads, hidden_dim, heads=num_heads, dropout=dropout, edge_dim=hidden_dim)\n",
    "        self.conv3 = GATConv(hidden_dim * num_heads, hidden_dim, heads=1, dropout=dropout, edge_dim=hidden_dim, concat=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # Embed nodes and edges\n",
    "        x = self.node_embed(x)\n",
    "        edge_attr = self.edge_embed(edge_attr)\n",
    "        \n",
    "        # GAT layers with residual connections\n",
    "        x1 = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "        x1 = self.dropout(x1)\n",
    "        \n",
    "        x2 = F.elu(self.conv2(x1, edge_index, edge_attr))\n",
    "        x2 = self.dropout(x2)\n",
    "        \n",
    "        x3 = self.conv3(x2, edge_index, edge_attr)\n",
    "        \n",
    "        # Global pooling (mean + max)\n",
    "        x_mean = global_mean_pool(x3, batch)\n",
    "        x_max = global_max_pool(x3, batch)\n",
    "        \n",
    "        return torch.cat([x_mean, x_max], dim=1)  # 2 * hidden_dim\n",
    "\n",
    "\n",
    "class GNNYieldPredictor(nn.Module):\n",
    "    \"\"\"Full model: GNN encoder + process conditions -> yield predictions.\"\"\"\n",
    "    def __init__(self, node_dim=22, edge_dim=6, hidden_dim=64, process_dim=5, spange_dim=13):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gnn = GATEncoder(node_dim, edge_dim, hidden_dim)\n",
    "        \n",
    "        # Process condition encoder\n",
    "        self.process_encoder = nn.Sequential(\n",
    "            nn.Linear(process_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32)\n",
    "        )\n",
    "        \n",
    "        # Spange feature encoder (physics-based)\n",
    "        self.spange_encoder = nn.Sequential(\n",
    "            nn.Linear(spange_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32)\n",
    "        )\n",
    "        \n",
    "        # Combined predictor (multi-task)\n",
    "        combined_dim = 2 * hidden_dim + 32 + 32  # GNN + process + spange\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3)  # 3 targets: Product 2, Product 3, SM\n",
    "        )\n",
    "        \n",
    "    def forward(self, graph_batch, process_feats, spange_feats):\n",
    "        # Encode molecular graph\n",
    "        mol_embed = self.gnn(graph_batch.x, graph_batch.edge_index, graph_batch.edge_attr, graph_batch.batch)\n",
    "        \n",
    "        # Encode process conditions\n",
    "        proc_embed = self.process_encoder(process_feats)\n",
    "        \n",
    "        # Encode Spange features\n",
    "        spange_embed = self.spange_encoder(spange_feats)\n",
    "        \n",
    "        # Combine and predict\n",
    "        combined = torch.cat([mol_embed, proc_embed, spange_embed], dim=1)\n",
    "        output = self.predictor(combined)\n",
    "        \n",
    "        return torch.sigmoid(output)  # Yields are 0-1\n",
    "\n",
    "print(\"GNN model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a5455a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:13:00.494858Z",
     "iopub.status.busy": "2026-01-14T07:13:00.494764Z",
     "iopub.status.idle": "2026-01-14T07:13:00.503564Z",
     "shell.execute_reply": "2026-01-14T07:13:00.503215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNModel wrapper defined\n"
     ]
    }
   ],
   "source": [
    "# --- GNN MODEL WRAPPER FOR COMPETITION ---\n",
    "\n",
    "class GNNModel(BaseModel):\n",
    "    \"\"\"GNN-based yield predictor with GAT.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', hidden_dim=64, lr=1e-3, epochs=100):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "        \n",
    "        # Feature dimensions\n",
    "        self.process_dim = 6 if self.mixed else 5  # RT, Temp, inv_temp, log_time, interaction, [pct]\n",
    "        self.spange_dim = SPANGE_DF.shape[1]\n",
    "        \n",
    "        # Scalers\n",
    "        self.process_scaler = StandardScaler()\n",
    "        self.spange_scaler = StandardScaler()\n",
    "        \n",
    "        self.model = None\n",
    "        \n",
    "    def _get_solvent_graph(self, solvent_name):\n",
    "        \"\"\"Get pre-computed graph for a solvent.\"\"\"\n",
    "        if solvent_name in SOLVENT_GRAPHS:\n",
    "            return SOLVENT_GRAPHS[solvent_name]\n",
    "        else:\n",
    "            # Fallback: create empty graph\n",
    "            return Data(\n",
    "                x=torch.zeros((1, 22), dtype=torch.double),\n",
    "                edge_index=torch.zeros((2, 0), dtype=torch.long),\n",
    "                edge_attr=torch.zeros((0, 6), dtype=torch.double)\n",
    "            )\n",
    "    \n",
    "    def _build_features(self, X):\n",
    "        \"\"\"Build process and Spange features.\"\"\"\n",
    "        rt = X['Residence Time'].values.astype(np.float64).reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.astype(np.float64).reshape(-1, 1)\n",
    "        temp_k = temp + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(rt + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        \n",
    "        if self.mixed:\n",
    "            pct = X['SolventB%'].values.reshape(-1, 1)\n",
    "            process_feats = np.hstack([rt, temp, inv_temp, log_time, interaction, pct])\n",
    "            \n",
    "            # Interpolated Spange features\n",
    "            A = SPANGE_DF.loc[X['SOLVENT A NAME']].values\n",
    "            B = SPANGE_DF.loc[X['SOLVENT B NAME']].values\n",
    "            spange_feats = A * (1 - pct) + B * pct\n",
    "        else:\n",
    "            process_feats = np.hstack([rt, temp, inv_temp, log_time, interaction])\n",
    "            spange_feats = SPANGE_DF.loc[X['SOLVENT NAME']].values\n",
    "            \n",
    "        return process_feats, spange_feats\n",
    "    \n",
    "    def _get_graphs_batch(self, X):\n",
    "        \"\"\"Get batch of molecular graphs.\"\"\"\n",
    "        graphs = []\n",
    "        if self.mixed:\n",
    "            for i in range(len(X)):\n",
    "                pct = X['SolventB%'].iloc[i]\n",
    "                # Use solvent A graph (primary solvent)\n",
    "                solvent_a = X['SOLVENT A NAME'].iloc[i]\n",
    "                graphs.append(self._get_solvent_graph(solvent_a))\n",
    "        else:\n",
    "            for solvent in X['SOLVENT NAME']:\n",
    "                graphs.append(self._get_solvent_graph(solvent))\n",
    "        return Batch.from_data_list(graphs)\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Build features\n",
    "        process_feats, spange_feats = self._build_features(X_train)\n",
    "        \n",
    "        # Scale\n",
    "        process_feats = self.process_scaler.fit_transform(process_feats)\n",
    "        spange_feats = self.spange_scaler.fit_transform(spange_feats)\n",
    "        \n",
    "        # Get graphs\n",
    "        graph_batch = self._get_graphs_batch(X_train)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        process_tensor = torch.tensor(process_feats, dtype=torch.double).to(self.device)\n",
    "        spange_tensor = torch.tensor(spange_feats, dtype=torch.double).to(self.device)\n",
    "        y_tensor = torch.tensor(y_train.values, dtype=torch.double).to(self.device)\n",
    "        graph_batch = graph_batch.to(self.device)\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = GNNYieldPredictor(\n",
    "            node_dim=22, edge_dim=6, hidden_dim=self.hidden_dim,\n",
    "            process_dim=self.process_dim, spange_dim=self.spange_dim\n",
    "        ).double().to(self.device)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.epochs)\n",
    "        \n",
    "        # Training loop\n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            preds = self.model(graph_batch, process_tensor, spange_tensor)\n",
    "            \n",
    "            # MAE loss\n",
    "            loss = F.l1_loss(preds, y_tensor)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Build features\n",
    "        process_feats, spange_feats = self._build_features(X)\n",
    "        \n",
    "        # Scale\n",
    "        process_feats = self.process_scaler.transform(process_feats)\n",
    "        spange_feats = self.spange_scaler.transform(spange_feats)\n",
    "        \n",
    "        # Get graphs\n",
    "        graph_batch = self._get_graphs_batch(X)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        process_tensor = torch.tensor(process_feats, dtype=torch.double).to(self.device)\n",
    "        spange_tensor = torch.tensor(spange_feats, dtype=torch.double).to(self.device)\n",
    "        graph_batch = graph_batch.to(self.device)\n",
    "        \n",
    "        # Predict\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(graph_batch, process_tensor, spange_tensor)\n",
    "        \n",
    "        return preds.cpu()\n",
    "\n",
    "print(\"GNNModel wrapper defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32b34a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:13:00.504385Z",
     "iopub.status.busy": "2026-01-14T07:13:00.504269Z",
     "iopub.status.idle": "2026-01-14T07:13:01.905814Z",
     "shell.execute_reply": "2026-01-14T07:13:01.905437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GNN model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.2740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.1719\n",
      "\n",
      "Quick test MAE: 0.2057\n"
     ]
    }
   ],
   "source": [
    "# Quick test on a few folds\n",
    "print(\"Testing GNN model...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "errors = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X_test, Y_test)):\n",
    "    if i >= 3: break\n",
    "    \n",
    "    model = GNNModel(data='single', hidden_dim=64, lr=1e-3, epochs=50)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    print(f\"Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nQuick test MAE: {np.mean(errors):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "541734c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:13:07.097781Z",
     "iopub.status.busy": "2026-01-14T07:13:07.097243Z",
     "iopub.status.idle": "2026-01-14T07:13:21.922653Z",
     "shell.execute_reply": "2026-01-14T07:13:21.922254Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:01,  1.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:02,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:03,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:03,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:04,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:04,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:05,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:06,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:06,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:07,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:08,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:08,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:09,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:09,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:10,  1.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:11,  1.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:11,  1.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:12,  1.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:12,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:13,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:14,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:14,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:14,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNModel(data='single', hidden_dim=64, lr=1e-3, epochs=100) # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5d6706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:13:21.923780Z",
     "iopub.status.busy": "2026-01-14T07:13:21.923688Z",
     "iopub.status.idle": "2026-01-14T07:13:30.465554Z",
     "shell.execute_reply": "2026-01-14T07:13:30.465182Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:01,  1.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:02,  1.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:03,  1.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:03,  1.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:04,  1.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:05,  1.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:05,  1.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:06,  1.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:07,  1.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:07,  1.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:08,  1.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:08,  1.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNModel(data='full', hidden_dim=64, lr=1e-3, epochs=100) # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4283ed74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:13:30.466518Z",
     "iopub.status.busy": "2026-01-14T07:13:30.466423Z",
     "iopub.status.idle": "2026-01-14T07:13:30.476133Z",
     "shell.execute_reply": "2026-01-14T07:13:30.475783Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
