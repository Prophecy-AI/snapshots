{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a148a32c",
   "metadata": {},
   "source": [
    "# Experiment 019: MLP with Strong Regularization + exp_004 Ensemble\n",
    "\n",
    "**Key insight from analysis:**\n",
    "- The 53% CV-LB gap is the REAL problem\n",
    "- Tree-based models memorize training solvents, don't generalize\n",
    "- MLP with strong regularization may have smaller CV-LB gap\n",
    "\n",
    "**Architecture:**\n",
    "- Combine exp_004's proven architecture (HGB+ETR per-target) with MLP\n",
    "- MLP: [256, 128, 64] with strong dropout (0.4), weight decay (1e-3)\n",
    "- Ensemble: 0.7 * exp_004_pred + 0.3 * mlp_pred\n",
    "- Features: Spange + ACS_PCA + Arrhenius kinetics\n",
    "\n",
    "**Hypothesis:**\n",
    "- MLP may capture different patterns than trees\n",
    "- Ensemble diversity may improve generalization\n",
    "- Strong regularization helps OOD prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc51596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:08:42.571507Z",
     "iopub.status.busy": "2026-01-14T05:08:42.570970Z",
     "iopub.status.idle": "2026-01-14T05:08:44.155578Z",
     "shell.execute_reply": "2026-01-14T05:08:44.155162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from abc import ABC\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "torch.set_default_dtype(torch.double)\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318bb11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:08:44.156712Z",
     "iopub.status.busy": "2026-01-14T05:08:44.156549Z",
     "iopub.status.idle": "2026-01-14T05:08:44.164234Z",
     "shell.execute_reply": "2026-01-14T05:08:44.163807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), ACS_PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# --- UTILITY FUNCTIONS ---\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & \n",
    "                 (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load feature dataframes\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "ACS_PCA_DF = load_features('acs_pca_descriptors')\n",
    "print(f\"Spange: {SPANGE_DF.shape}, ACS_PCA: {ACS_PCA_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70910a25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:08:44.165092Z",
     "iopub.status.busy": "2026-01-14T05:08:44.164995Z",
     "iopub.status.idle": "2026-01-14T05:08:44.167459Z",
     "shell.execute_reply": "2026-01-14T05:08:44.167156Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- BASE CLASSES ---\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self): raise NotImplementedError\n",
    "    def featurize(self, X): raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self): pass\n",
    "    def train_model(self, X_train, y_train): raise NotImplementedError\n",
    "    def predict(self): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3315b2a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:08:44.168365Z",
     "iopub.status.busy": "2026-01-14T05:08:44.168154Z",
     "iopub.status.idle": "2026-01-14T05:08:44.171849Z",
     "shell.execute_reply": "2026-01-14T05:08:44.171534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegularizedMLP defined\n"
     ]
    }
   ],
   "source": [
    "# --- REGULARIZED MLP ---\n",
    "class RegularizedMLP(nn.Module):\n",
    "    \"\"\"MLP with strong regularization for better generalization.\n",
    "    \n",
    "    Key features:\n",
    "    - Dropout 0.4 between layers (strong regularization)\n",
    "    - BatchNorm for stability\n",
    "    - Weight decay applied via optimizer\n",
    "    - Sigmoid output for [0,1] range\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims=[256, 128, 64], output_dim=3, dropout=0.4):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.BatchNorm1d(input_dim))\n",
    "        \n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.BatchNorm1d(h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))  # Strong dropout\n",
    "            prev_dim = h_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())  # Output in [0, 1]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.size(0) == 1 and self.training:\n",
    "            self.eval()\n",
    "            out = self.network(x)\n",
    "            self.train()\n",
    "            return out\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"RegularizedMLP defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ff83ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:08:44.172876Z",
     "iopub.status.busy": "2026-01-14T05:08:44.172786Z",
     "iopub.status.idle": "2026-01-14T05:08:44.183997Z",
     "shell.execute_reply": "2026-01-14T05:08:44.183676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridMLPModel defined\n"
     ]
    }
   ],
   "source": [
    "# --- HYBRID MODEL: exp_004 + MLP ---\n",
    "class HybridMLPModel(BaseModel):\n",
    "    \"\"\"Combines exp_004's proven architecture with regularized MLP.\n",
    "    \n",
    "    Architecture:\n",
    "    - exp_004: Per-target HGB+ETR with prediction combination (0.8*acs + 0.2*spange)\n",
    "    - MLP: Regularized MLP with dropout=0.4, weight_decay=1e-3\n",
    "    - Ensemble: 0.7 * exp_004_pred + 0.3 * mlp_pred\n",
    "    \n",
    "    Hypothesis: MLP may capture different patterns, ensemble diversity helps generalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.targets = ['Product 2', 'Product 3', 'SM']\n",
    "        \n",
    "        # Feature dataframes\n",
    "        self.spange = SPANGE_DF\n",
    "        self.acs_pca = ACS_PCA_DF\n",
    "        \n",
    "        # Scalers\n",
    "        self.scaler_spange = StandardScaler()\n",
    "        self.scaler_acs = StandardScaler()\n",
    "        self.scaler_mlp = StandardScaler()\n",
    "        \n",
    "        # exp_004 models\n",
    "        self.models = {}\n",
    "        \n",
    "        # MLP\n",
    "        self.mlp = None\n",
    "        \n",
    "        # Ensemble weights\n",
    "        self.exp004_weight = 0.7\n",
    "        self.mlp_weight = 0.3\n",
    "\n",
    "    def _build_features(self, X, feature_df):\n",
    "        \"\"\"Build features with Arrhenius kinetics.\"\"\"\n",
    "        rt = X['Residence Time'].values.astype(np.float64).reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.astype(np.float64).reshape(-1, 1)\n",
    "        \n",
    "        # Arrhenius kinetic features\n",
    "        temp_k = temp + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(rt + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        \n",
    "        if self.mixed:\n",
    "            pct = X['SolventB%'].values.reshape(-1, 1)\n",
    "            A = feature_df.loc[X['SOLVENT A NAME']].values\n",
    "            B = feature_df.loc[X['SOLVENT B NAME']].values\n",
    "            solvent_feats = A * (1 - pct) + B * pct\n",
    "            return np.hstack([rt, temp, inv_temp, log_time, interaction, pct, solvent_feats])\n",
    "        else:\n",
    "            solvent_feats = feature_df.loc[X['SOLVENT NAME']].values\n",
    "            return np.hstack([rt, temp, inv_temp, log_time, interaction, solvent_feats])\n",
    "\n",
    "    def _build_mlp_features(self, X):\n",
    "        \"\"\"Build combined features for MLP.\"\"\"\n",
    "        rt = X['Residence Time'].values.astype(np.float64).reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.astype(np.float64).reshape(-1, 1)\n",
    "        \n",
    "        # Arrhenius kinetic features\n",
    "        temp_k = temp + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(rt + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        \n",
    "        if self.mixed:\n",
    "            pct = X['SolventB%'].values.reshape(-1, 1)\n",
    "            spange_A = self.spange.loc[X['SOLVENT A NAME']].values\n",
    "            spange_B = self.spange.loc[X['SOLVENT B NAME']].values\n",
    "            acs_A = self.acs_pca.loc[X['SOLVENT A NAME']].values\n",
    "            acs_B = self.acs_pca.loc[X['SOLVENT B NAME']].values\n",
    "            spange_mix = spange_A * (1 - pct) + spange_B * pct\n",
    "            acs_mix = acs_A * (1 - pct) + acs_B * pct\n",
    "            return np.hstack([rt, temp, inv_temp, log_time, interaction, pct, spange_mix, acs_mix])\n",
    "        else:\n",
    "            spange_feats = self.spange.loc[X['SOLVENT NAME']].values\n",
    "            acs_feats = self.acs_pca.loc[X['SOLVENT NAME']].values\n",
    "            return np.hstack([rt, temp, inv_temp, log_time, interaction, spange_feats, acs_feats])\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Build features\n",
    "        X_spange = self._build_features(X_train, self.spange)\n",
    "        X_acs = self._build_features(X_train, self.acs_pca)\n",
    "        X_mlp = self._build_mlp_features(X_train)\n",
    "        \n",
    "        # Scale\n",
    "        X_spange_sc = self.scaler_spange.fit_transform(X_spange)\n",
    "        X_acs_sc = self.scaler_acs.fit_transform(X_acs)\n",
    "        X_mlp_sc = self.scaler_mlp.fit_transform(X_mlp)\n",
    "        \n",
    "        y = y_train.values\n",
    "        \n",
    "        # --- Train exp_004 models (per-target) ---\n",
    "        for i, target in enumerate(self.targets):\n",
    "            y_target = y[:, i]\n",
    "            \n",
    "            if target == 'SM':\n",
    "                model_spange = HistGradientBoostingRegressor(\n",
    "                    max_depth=7, max_iter=700, learning_rate=0.04, random_state=42\n",
    "                )\n",
    "                model_acs = HistGradientBoostingRegressor(\n",
    "                    max_depth=7, max_iter=700, learning_rate=0.04, random_state=42\n",
    "                )\n",
    "            else:\n",
    "                model_spange = ExtraTreesRegressor(\n",
    "                    n_estimators=500, max_depth=10, min_samples_leaf=2,\n",
    "                    random_state=42, n_jobs=-1\n",
    "                )\n",
    "                model_acs = ExtraTreesRegressor(\n",
    "                    n_estimators=500, max_depth=10, min_samples_leaf=2,\n",
    "                    random_state=42, n_jobs=-1\n",
    "                )\n",
    "            \n",
    "            model_spange.fit(X_spange_sc, y_target)\n",
    "            model_acs.fit(X_acs_sc, y_target)\n",
    "            self.models[target] = {'spange': model_spange, 'acs': model_acs}\n",
    "        \n",
    "        # --- Train MLP ---\n",
    "        input_dim = X_mlp_sc.shape[1]\n",
    "        self.mlp = RegularizedMLP(input_dim, hidden_dims=[256, 128, 64], output_dim=3, dropout=0.4).to(device)\n",
    "        \n",
    "        X_tensor = torch.tensor(X_mlp_sc, dtype=torch.double).to(device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.double).to(device)\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        # Strong weight decay for regularization\n",
    "        optimizer = torch.optim.Adam(self.mlp.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        self.mlp.train()\n",
    "        for epoch in range(200):  # More epochs with early stopping potential\n",
    "            for batch_X, batch_y in loader:\n",
    "                optimizer.zero_grad()\n",
    "                pred = self.mlp(batch_X)\n",
    "                loss = criterion(pred, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Build features\n",
    "        X_spange = self._build_features(X, self.spange)\n",
    "        X_acs = self._build_features(X, self.acs_pca)\n",
    "        X_mlp = self._build_mlp_features(X)\n",
    "        \n",
    "        X_spange_sc = self.scaler_spange.transform(X_spange)\n",
    "        X_acs_sc = self.scaler_acs.transform(X_acs)\n",
    "        X_mlp_sc = self.scaler_mlp.transform(X_mlp)\n",
    "        \n",
    "        # --- exp_004 predictions ---\n",
    "        preds_exp004 = []\n",
    "        for target in self.targets:\n",
    "            p_spange = self.models[target]['spange'].predict(X_spange_sc)\n",
    "            p_acs = self.models[target]['acs'].predict(X_acs_sc)\n",
    "            p_combined = 0.8 * p_acs + 0.2 * p_spange\n",
    "            preds_exp004.append(p_combined.reshape(-1, 1))\n",
    "        preds_exp004 = np.hstack(preds_exp004)\n",
    "        \n",
    "        # --- MLP predictions ---\n",
    "        self.mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X_mlp_sc, dtype=torch.double).to(device)\n",
    "            preds_mlp = self.mlp(X_tensor).cpu().numpy()\n",
    "        \n",
    "        # --- Ensemble ---\n",
    "        final_pred = self.exp004_weight * preds_exp004 + self.mlp_weight * preds_mlp\n",
    "        final_pred = np.clip(final_pred, 0, 1)\n",
    "        \n",
    "        return torch.tensor(final_pred, dtype=torch.double)\n",
    "\n",
    "print(\"HybridMLPModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07301bcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:08:44.184903Z",
     "iopub.status.busy": "2026-01-14T05:08:44.184816Z",
     "iopub.status.idle": "2026-01-14T05:09:45.794853Z",
     "shell.execute_reply": "2026-01-14T05:09:45.794428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing HybridMLPModel...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.1483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.0361\n",
      "\n",
      "Single solvent quick test MAE: 0.0952\n",
      "\n",
      "Testing on full data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 0: MAE = 0.0526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 1: MAE = 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 2: MAE = 0.0638\n",
      "\n",
      "Full data quick test MAE: 0.0719\n"
     ]
    }
   ],
   "source": [
    "# --- QUICK VALIDATION TEST ---\n",
    "print(\"Testing HybridMLPModel...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "errors = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X_test, Y_test)):\n",
    "    if i >= 3: break\n",
    "    model = HybridMLPModel(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    print(f\"Single Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nSingle solvent quick test MAE: {np.mean(errors):.4f}\")\n",
    "\n",
    "# Test full data\n",
    "print(\"\\nTesting on full data...\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "errors_full = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    if i >= 3: break\n",
    "    model = HybridMLPModel(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_full.append(mae)\n",
    "    print(f\"Full Fold {i}: MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nFull data quick test MAE: {np.mean(errors_full):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecdb13d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:09:52.410397Z",
     "iopub.status.busy": "2026-01-14T05:09:52.409942Z",
     "iopub.status.idle": "2026-01-14T05:13:02.269217Z",
     "shell.execute_reply": "2026-01-14T05:13:02.268778Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:08,  8.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:16,  8.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:23,  7.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:31,  7.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:39,  7.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:47,  7.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:55,  7.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [01:03,  7.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [01:10,  7.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [01:18,  7.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [01:26,  7.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [01:34,  7.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [01:42,  7.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [01:50,  7.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [01:58,  7.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [02:06,  7.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [02:14,  7.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [02:22,  7.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [02:30,  7.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [02:38,  7.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [02:46,  7.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [02:54,  7.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [03:01,  7.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [03:09,  7.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [03:09,  7.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = HybridMLPModel(data='single') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b9be00d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:13:02.270359Z",
     "iopub.status.busy": "2026-01-14T05:13:02.270176Z",
     "iopub.status.idle": "2026-01-14T05:15:48.433865Z",
     "shell.execute_reply": "2026-01-14T05:15:48.433487Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:12, 12.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:24, 12.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:37, 12.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:49, 12.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:02, 12.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [01:14, 12.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [01:27, 12.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [01:40, 12.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [01:52, 12.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [02:05, 12.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [02:19, 12.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [02:32, 13.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [02:46, 13.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [02:46, 12.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = HybridMLPModel(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2022c40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:15:48.434803Z",
     "iopub.status.busy": "2026-01-14T05:15:48.434708Z",
     "iopub.status.idle": "2026-01-14T05:15:48.444312Z",
     "shell.execute_reply": "2026-01-14T05:15:48.443956Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
