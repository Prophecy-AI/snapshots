{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00235149",
   "metadata": {},
   "source": [
    "# Experiment 009: Diverse Ensemble\n",
    "\n",
    "**Key Insight from Loop 8**: More regularization made LB WORSE (0.0956 â†’ 0.0991). This means:\n",
    "1. The problem is NOT traditional overfitting\n",
    "2. We need BETTER features and model diversity\n",
    "3. Top kernels use MLP + XGBoost + RF + LightGBM ensemble\n",
    "\n",
    "**Implementation**:\n",
    "- Combine PerTarget (HGB+ETR) + RandomForest + XGBoost + LightGBM\n",
    "- Weighted averaging with weights [0.4, 0.2, 0.2, 0.2]\n",
    "- Combined features: Spange + ACS_PCA + Arrhenius kinetics\n",
    "- NO TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb54d52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:12:57.318439Z",
     "iopub.status.busy": "2026-01-14T03:12:57.317980Z",
     "iopub.status.idle": "2026-01-14T03:12:58.960715Z",
     "shell.execute_reply": "2026-01-14T03:12:58.960310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from abc import ABC\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "torch.set_default_dtype(torch.double)\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62889a19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:12:58.961875Z",
     "iopub.status.busy": "2026-01-14T03:12:58.961729Z",
     "iopub.status.idle": "2026-01-14T03:12:58.969399Z",
     "shell.execute_reply": "2026-01-14T03:12:58.969051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), ACS_PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# --- UTILITY FUNCTIONS ---\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load feature sets\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "ACS_PCA_DF = load_features('acs_pca_descriptors')\n",
    "print(f\"Spange: {SPANGE_DF.shape}, ACS_PCA: {ACS_PCA_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd2ac15d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:12:58.970648Z",
     "iopub.status.busy": "2026-01-14T03:12:58.970350Z",
     "iopub.status.idle": "2026-01-14T03:12:58.972844Z",
     "shell.execute_reply": "2026-01-14T03:12:58.972537Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- BASE CLASSES ---\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self): raise NotImplementedError\n",
    "    def featurize(self, X): raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self): pass\n",
    "    def train_model(self, X_train, y_train): raise NotImplementedError\n",
    "    def predict(self): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10fe6224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:12:58.973738Z",
     "iopub.status.busy": "2026-01-14T03:12:58.973653Z",
     "iopub.status.idle": "2026-01-14T03:12:58.981549Z",
     "shell.execute_reply": "2026-01-14T03:12:58.981228Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- DIVERSE ENSEMBLE MODEL ---\n",
    "class DiverseEnsemble(BaseModel):\n",
    "    \"\"\"Ensemble of diverse model families.\n",
    "    \n",
    "    Key insight: Top kernels use MLP + XGBoost + RF + LightGBM ensemble.\n",
    "    We combine:\n",
    "    - PerTarget (HGB for SM, ETR for Products) - our best CV model\n",
    "    - RandomForest - different model family\n",
    "    - XGBoost - gradient boosting\n",
    "    - LightGBM - another gradient boosting variant\n",
    "    \n",
    "    Weighted averaging with weights [0.4, 0.2, 0.2, 0.2]\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.targets = ['Product 2', 'Product 3', 'SM']\n",
    "        \n",
    "        # Feature dataframes\n",
    "        self.spange = SPANGE_DF\n",
    "        self.acs_pca = ACS_PCA_DF\n",
    "        \n",
    "        # Scaler\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Models for each approach\n",
    "        self.per_target_models = {}  # HGB for SM, ETR for Products\n",
    "        self.rf_model = None\n",
    "        self.xgb_model = None\n",
    "        self.lgb_model = None\n",
    "        \n",
    "        # Ensemble weights\n",
    "        self.weights = [0.4, 0.2, 0.2, 0.2]  # PerTarget, RF, XGB, LGB\n",
    "    \n",
    "    def _build_features(self, X):\n",
    "        \"\"\"Build combined features: Arrhenius + Spange + ACS_PCA.\"\"\"\n",
    "        rt = X['Residence Time'].values.astype(np.float64).reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.astype(np.float64).reshape(-1, 1)\n",
    "        \n",
    "        # Arrhenius kinetic features\n",
    "        temp_k = temp + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(rt + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        \n",
    "        process_feats = np.hstack([rt, temp, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            pct = X['SolventB%'].values.reshape(-1, 1)\n",
    "            \n",
    "            # Spange features (weighted mix)\n",
    "            A_spange = self.spange.loc[X['SOLVENT A NAME']].values\n",
    "            B_spange = self.spange.loc[X['SOLVENT B NAME']].values\n",
    "            spange_feats = A_spange * (1 - pct) + B_spange * pct\n",
    "            \n",
    "            # ACS_PCA features (weighted mix)\n",
    "            A_acs = self.acs_pca.loc[X['SOLVENT A NAME']].values\n",
    "            B_acs = self.acs_pca.loc[X['SOLVENT B NAME']].values\n",
    "            acs_feats = A_acs * (1 - pct) + B_acs * pct\n",
    "            \n",
    "            return np.hstack([process_feats, pct, spange_feats, acs_feats])\n",
    "        else:\n",
    "            spange_feats = self.spange.loc[X['SOLVENT NAME']].values\n",
    "            acs_feats = self.acs_pca.loc[X['SOLVENT NAME']].values\n",
    "            return np.hstack([process_feats, spange_feats, acs_feats])\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_feat = self._build_features(X_train)\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        y = y_train.values\n",
    "        \n",
    "        # 1. Train per-target models (HGB for SM, ETR for Products)\n",
    "        for i, target in enumerate(self.targets):\n",
    "            y_target = y[:, i]\n",
    "            if target == 'SM':\n",
    "                model = HistGradientBoostingRegressor(\n",
    "                    max_depth=7, max_iter=700, learning_rate=0.04, random_state=42\n",
    "                )\n",
    "            else:\n",
    "                model = ExtraTreesRegressor(\n",
    "                    n_estimators=500, max_depth=10, min_samples_leaf=2,\n",
    "                    random_state=42, n_jobs=-1\n",
    "                )\n",
    "            model.fit(X_scaled, y_target)\n",
    "            self.per_target_models[target] = model\n",
    "        \n",
    "        # 2. Train RandomForest\n",
    "        self.rf_model = MultiOutputRegressor(\n",
    "            RandomForestRegressor(\n",
    "                n_estimators=200, max_depth=10, min_samples_leaf=2,\n",
    "                random_state=42, n_jobs=-1\n",
    "            )\n",
    "        )\n",
    "        self.rf_model.fit(X_scaled, y)\n",
    "        \n",
    "        # 3. Train XGBoost\n",
    "        self.xgb_model = MultiOutputRegressor(\n",
    "            xgb.XGBRegressor(\n",
    "                n_estimators=300, max_depth=6, learning_rate=0.05,\n",
    "                subsample=0.8, colsample_bytree=0.8,\n",
    "                random_state=42, verbosity=0\n",
    "            )\n",
    "        )\n",
    "        self.xgb_model.fit(X_scaled, y)\n",
    "        \n",
    "        # 4. Train LightGBM\n",
    "        self.lgb_model = MultiOutputRegressor(\n",
    "            lgb.LGBMRegressor(\n",
    "                n_estimators=300, max_depth=6, learning_rate=0.05,\n",
    "                subsample=0.8, colsample_bytree=0.8,\n",
    "                random_state=42, verbosity=-1\n",
    "            )\n",
    "        )\n",
    "        self.lgb_model.fit(X_scaled, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_feat = self._build_features(X)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        # 1. Per-target predictions\n",
    "        per_target_preds = []\n",
    "        for target in self.targets:\n",
    "            p = self.per_target_models[target].predict(X_scaled)\n",
    "            per_target_preds.append(p.reshape(-1, 1))\n",
    "        per_target_preds = np.hstack(per_target_preds)\n",
    "        \n",
    "        # 2. RF predictions\n",
    "        rf_preds = self.rf_model.predict(X_scaled)\n",
    "        \n",
    "        # 3. XGB predictions\n",
    "        xgb_preds = self.xgb_model.predict(X_scaled)\n",
    "        \n",
    "        # 4. LGB predictions\n",
    "        lgb_preds = self.lgb_model.predict(X_scaled)\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        final_preds = (\n",
    "            self.weights[0] * per_target_preds +\n",
    "            self.weights[1] * rf_preds +\n",
    "            self.weights[2] * xgb_preds +\n",
    "            self.weights[3] * lgb_preds\n",
    "        )\n",
    "        \n",
    "        final_preds = np.clip(final_preds, 0, 1)\n",
    "        return torch.tensor(final_preds, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06cc7575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:12:58.982430Z",
     "iopub.status.busy": "2026-01-14T03:12:58.982213Z",
     "iopub.status.idle": "2026-01-14T03:13:16.367625Z",
     "shell.execute_reply": "2026-01-14T03:13:16.367226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DiverseEnsemble...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.1717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.0335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 (Acetonitrile): MAE = 0.1149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 (Acetonitrile.Acetic Acid): MAE = 0.1098\n",
      "\n",
      "Quick test MAE (single): 0.1096\n",
      "\n",
      "Testing on full data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: MAE = 0.0626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MAE = 0.1038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: MAE = 0.0598\n",
      "\n",
      "Quick test MAE (full): 0.0754\n"
     ]
    }
   ],
   "source": [
    "# --- QUICK VALIDATION TEST ---\n",
    "print(\"Testing DiverseEnsemble...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "# Quick leave-one-out test on first 5 solvents\n",
    "errors = []\n",
    "split_gen = generate_leave_one_out_splits(X_test, Y_test)\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(split_gen):\n",
    "    if i >= 5: break\n",
    "    model = DiverseEnsemble(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    print(f\"Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nQuick test MAE (single): {np.mean(errors):.4f}\")\n",
    "\n",
    "# Also test on full data\n",
    "print(\"\\nTesting on full data...\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "errors_full = []\n",
    "split_gen = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(split_gen):\n",
    "    if i >= 3: break\n",
    "    model = DiverseEnsemble(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_full.append(mae)\n",
    "    print(f\"Fold {i}: MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nQuick test MAE (full): {np.mean(errors_full):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957b91a",
   "metadata": {},
   "source": [
    "## Template-Compliant Cross-Validation\n",
    "\n",
    "The following 3 cells are the FINAL 3 cells - EXACTLY as in the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "533c6b61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:13:28.575425Z",
     "iopub.status.busy": "2026-01-14T03:13:28.574884Z",
     "iopub.status.idle": "2026-01-14T03:14:17.690112Z",
     "shell.execute_reply": "2026-01-14T03:14:17.689687Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:02,  2.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:04,  2.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:06,  2.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:08,  2.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:10,  2.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:12,  2.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:14,  2.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:16,  2.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:18,  2.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:20,  2.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:22,  2.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:24,  2.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:26,  2.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:28,  2.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:30,  2.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:32,  2.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:34,  2.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:37,  2.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:39,  2.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:41,  2.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:43,  2.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:45,  2.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:47,  2.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:49,  2.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:49,  2.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = DiverseEnsemble(data='single') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a0b29e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:14:17.691175Z",
     "iopub.status.busy": "2026-01-14T03:14:17.691072Z",
     "iopub.status.idle": "2026-01-14T03:14:49.179628Z",
     "shell.execute_reply": "2026-01-14T03:14:49.179237Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:02,  2.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:04,  2.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:07,  2.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:09,  2.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:12,  2.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:14,  2.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:17,  2.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:19,  2.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:21,  2.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:24,  2.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:26,  2.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:29,  2.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:31,  2.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:31,  2.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = DiverseEnsemble(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a631828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:14:49.180624Z",
     "iopub.status.busy": "2026-01-14T03:14:49.180519Z",
     "iopub.status.idle": "2026-01-14T03:14:49.190383Z",
     "shell.execute_reply": "2026-01-14T03:14:49.190036Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
