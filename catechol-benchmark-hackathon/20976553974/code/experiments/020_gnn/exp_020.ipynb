{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3027599",
   "metadata": {},
   "source": [
    "# Experiment 020: Graph Neural Network (GNN) for Molecular Property Prediction\n",
    "\n",
    "**Key insight from research:**\n",
    "- Paper arxiv:2512.19530 achieved MSE 0.0039 using GNN (25x better than tabular ensembles)\n",
    "- GNN can learn molecular structure patterns that generalize to unseen solvents\n",
    "- This is the only approach with demonstrated target-level performance\n",
    "\n",
    "**Architecture:**\n",
    "- Use RDKit to convert solvent SMILES to molecular graphs\n",
    "- Graph Convolutional Network (GCN) for molecular encoding\n",
    "- Combine molecular embeddings with process conditions (Temperature, Residence Time)\n",
    "- Per-target prediction heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17307ac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:11.255478Z",
     "iopub.status.busy": "2026-01-14T05:25:11.254956Z",
     "iopub.status.idle": "2026-01-14T05:25:13.633475Z",
     "shell.execute_reply": "2026-01-14T05:25:13.633071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from abc import ABC\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GNN imports\n",
    "from rdkit import Chem\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, global_add_pool\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "torch.set_default_dtype(torch.float32)  # PyG works better with float32\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b59a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:13.634753Z",
     "iopub.status.busy": "2026-01-14T05:25:13.634590Z",
     "iopub.status.idle": "2026-01-14T05:25:13.641174Z",
     "shell.execute_reply": "2026-01-14T05:25:13.640827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES lookup: 26 solvents\n"
     ]
    }
   ],
   "source": [
    "# --- UTILITY FUNCTIONS ---\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & \n",
    "                 (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load SMILES lookup\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "SMILES_DICT = SMILES_DF['solvent smiles'].to_dict()\n",
    "print(f\"SMILES lookup: {len(SMILES_DICT)} solvents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a262826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:13.642041Z",
     "iopub.status.busy": "2026-01-14T05:25:13.641942Z",
     "iopub.status.idle": "2026-01-14T05:25:13.644819Z",
     "shell.execute_reply": "2026-01-14T05:25:13.644484Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- BASE CLASSES ---\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self): raise NotImplementedError\n",
    "    def featurize(self, X): raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self): pass\n",
    "    def train_model(self, X_train, y_train): raise NotImplementedError\n",
    "    def predict(self): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad8ee8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:13.645809Z",
     "iopub.status.busy": "2026-01-14T05:25:13.645704Z",
     "iopub.status.idle": "2026-01-14T05:25:13.651219Z",
     "shell.execute_reply": "2026-01-14T05:25:13.650873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethanol graph: 3 atoms, 4 edges\n",
      "Water.Acetonitrile graph: 4 atoms, 4 edges\n"
     ]
    }
   ],
   "source": [
    "# --- MOLECULAR GRAPH UTILITIES ---\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"Convert SMILES string to PyTorch Geometric Data object.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        # Fallback for invalid SMILES (e.g., mixtures like \"O.CC#N\")\n",
    "        # Use first component\n",
    "        smiles_parts = smiles.split('.')\n",
    "        mol = Chem.MolFromSmiles(smiles_parts[0])\n",
    "        if mol is None:\n",
    "            # Return a simple water molecule as fallback\n",
    "            mol = Chem.MolFromSmiles('O')\n",
    "    \n",
    "    # Atom features: [atomic_num, degree, formal_charge, hybridization, aromatic]\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        features = [\n",
    "            atom.GetAtomicNum(),\n",
    "            atom.GetDegree(),\n",
    "            atom.GetFormalCharge(),\n",
    "            int(atom.GetHybridization()),\n",
    "            int(atom.GetIsAromatic())\n",
    "        ]\n",
    "        atom_features.append(features)\n",
    "    \n",
    "    x = torch.tensor(atom_features, dtype=torch.float32)\n",
    "    \n",
    "    # Edge index (bonds)\n",
    "    edge_index = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])  # Undirected\n",
    "    \n",
    "    if len(edge_index) == 0:\n",
    "        # Single atom molecule\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Test\n",
    "test_graph = smiles_to_graph('CCO')  # Ethanol\n",
    "print(f\"Ethanol graph: {test_graph.num_nodes} atoms, {test_graph.num_edges} edges\")\n",
    "test_graph = smiles_to_graph('O.CC#N')  # Water.Acetonitrile mixture\n",
    "print(f\"Water.Acetonitrile graph: {test_graph.num_nodes} atoms, {test_graph.num_edges} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6fd10a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:13.652049Z",
     "iopub.status.busy": "2026-01-14T05:25:13.651951Z",
     "iopub.status.idle": "2026-01-14T05:25:13.656441Z",
     "shell.execute_reply": "2026-01-14T05:25:13.656070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MolecularGNN defined\n"
     ]
    }
   ],
   "source": [
    "# --- GNN MODEL ---\n",
    "class MolecularGNN(nn.Module):\n",
    "    \"\"\"Graph Neural Network for molecular property prediction.\n",
    "    \n",
    "    Architecture:\n",
    "    - 3 GCN layers for molecular encoding\n",
    "    - Global mean pooling to get molecule-level embedding\n",
    "    - Combine with process conditions (Temperature, Residence Time)\n",
    "    - MLP head for prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, atom_features=5, hidden_dim=64, output_dim=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # GCN layers\n",
    "        self.conv1 = GCNConv(atom_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Process condition encoder\n",
    "        self.condition_encoder = nn.Sequential(\n",
    "            nn.Linear(3, 32),  # [RT, Temp, SolventB%]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32)\n",
    "        )\n",
    "        \n",
    "        # Prediction head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + 32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, graph_batch, conditions):\n",
    "        # Graph encoding\n",
    "        x, edge_index, batch = graph_batch.x, graph_batch.edge_index, graph_batch.batch\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        \n",
    "        # Global pooling\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_dim]\n",
    "        \n",
    "        # Condition encoding\n",
    "        cond = self.condition_encoder(conditions)  # [batch_size, 32]\n",
    "        \n",
    "        # Combine and predict\n",
    "        combined = torch.cat([x, cond], dim=1)\n",
    "        out = self.head(combined)\n",
    "        \n",
    "        return out\n",
    "\n",
    "print(\"MolecularGNN defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6626cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:13.657510Z",
     "iopub.status.busy": "2026-01-14T05:25:13.657389Z",
     "iopub.status.idle": "2026-01-14T05:25:13.666400Z",
     "shell.execute_reply": "2026-01-14T05:25:13.666038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNModel defined\n"
     ]
    }
   ],
   "source": [
    "# --- GNN MODEL WRAPPER ---\n",
    "class GNNModel(BaseModel):\n",
    "    \"\"\"GNN-based model for solvent yield prediction.\n",
    "    \n",
    "    For single solvents: Use molecular graph directly\n",
    "    For mixed solvents: Average embeddings of both solvents weighted by SolventB%\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Pre-compute graphs for all solvents\n",
    "        self.solvent_graphs = {}\n",
    "        for name, smiles in SMILES_DICT.items():\n",
    "            self.solvent_graphs[name] = smiles_to_graph(smiles)\n",
    "    \n",
    "    def _get_conditions(self, X):\n",
    "        \"\"\"Extract process conditions.\"\"\"\n",
    "        rt = X['Residence Time'].values.reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.reshape(-1, 1)\n",
    "        \n",
    "        if self.mixed:\n",
    "            pct = X['SolventB%'].values.reshape(-1, 1) / 100.0\n",
    "            return np.hstack([rt, temp, pct])\n",
    "        else:\n",
    "            return np.hstack([rt, temp, np.zeros((len(X), 1))])\n",
    "    \n",
    "    def _get_graphs(self, X):\n",
    "        \"\"\"Get molecular graphs for samples.\"\"\"\n",
    "        graphs = []\n",
    "        if self.mixed:\n",
    "            for _, row in X.iterrows():\n",
    "                # For mixed solvents, use the primary solvent (A)\n",
    "                # Could also try averaging embeddings\n",
    "                solvent = row['SOLVENT A NAME']\n",
    "                if solvent in self.solvent_graphs:\n",
    "                    graphs.append(self.solvent_graphs[solvent])\n",
    "                else:\n",
    "                    graphs.append(smiles_to_graph('O'))  # Fallback\n",
    "        else:\n",
    "            for _, row in X.iterrows():\n",
    "                solvent = row['SOLVENT NAME']\n",
    "                if solvent in self.solvent_graphs:\n",
    "                    graphs.append(self.solvent_graphs[solvent])\n",
    "                else:\n",
    "                    graphs.append(smiles_to_graph('O'))  # Fallback\n",
    "        return graphs\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Get conditions and graphs\n",
    "        conditions = self._get_conditions(X_train)\n",
    "        conditions_scaled = self.scaler.fit_transform(conditions)\n",
    "        graphs = self._get_graphs(X_train)\n",
    "        y = y_train.values\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = MolecularGNN(atom_features=5, hidden_dim=64, output_dim=3).to(device)\n",
    "        \n",
    "        # Training\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Create batches\n",
    "        batch_size = 32\n",
    "        n_samples = len(graphs)\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(100):\n",
    "            # Shuffle\n",
    "            indices = np.random.permutation(n_samples)\n",
    "            \n",
    "            for start in range(0, n_samples, batch_size):\n",
    "                end = min(start + batch_size, n_samples)\n",
    "                batch_idx = indices[start:end]\n",
    "                \n",
    "                # Batch graphs\n",
    "                batch_graphs = [graphs[i] for i in batch_idx]\n",
    "                graph_batch = Batch.from_data_list(batch_graphs).to(device)\n",
    "                \n",
    "                # Batch conditions\n",
    "                batch_cond = torch.tensor(conditions_scaled[batch_idx], dtype=torch.float32).to(device)\n",
    "                \n",
    "                # Batch targets\n",
    "                batch_y = torch.tensor(y[batch_idx], dtype=torch.float32).to(device)\n",
    "                \n",
    "                # Forward\n",
    "                optimizer.zero_grad()\n",
    "                pred = self.model(graph_batch, batch_cond)\n",
    "                loss = criterion(pred, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        conditions = self._get_conditions(X)\n",
    "        conditions_scaled = self.scaler.transform(conditions)\n",
    "        graphs = self._get_graphs(X)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            graph_batch = Batch.from_data_list(graphs).to(device)\n",
    "            cond_tensor = torch.tensor(conditions_scaled, dtype=torch.float32).to(device)\n",
    "            pred = self.model(graph_batch, cond_tensor)\n",
    "        \n",
    "        # Convert to double for template compatibility\n",
    "        return pred.cpu().double()\n",
    "\n",
    "print(\"GNNModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40428aca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:13.667442Z",
     "iopub.status.busy": "2026-01-14T05:25:13.667345Z",
     "iopub.status.idle": "2026-01-14T05:26:06.644790Z",
     "shell.execute_reply": "2026-01-14T05:26:06.644431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GNNModel...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.2505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.0502\n",
      "\n",
      "Single solvent quick test MAE: 0.1375\n",
      "\n",
      "Testing on full data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 0: MAE = 0.0840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 1: MAE = 0.1285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 2: MAE = 0.0833\n",
      "\n",
      "Full data quick test MAE: 0.0986\n"
     ]
    }
   ],
   "source": [
    "# --- QUICK VALIDATION TEST ---\n",
    "print(\"Testing GNNModel...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "errors = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X_test, Y_test)):\n",
    "    if i >= 3: break\n",
    "    model = GNNModel(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    print(f\"Single Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nSingle solvent quick test MAE: {np.mean(errors):.4f}\")\n",
    "\n",
    "# Test full data\n",
    "print(\"\\nTesting on full data...\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "errors_full = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    if i >= 3: break\n",
    "    model = GNNModel(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_full.append(mae)\n",
    "    print(f\"Full Fold {i}: MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nFull data quick test MAE: {np.mean(errors_full):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6786f926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:26:11.862361Z",
     "iopub.status.busy": "2026-01-14T05:26:11.861844Z",
     "iopub.status.idle": "2026-01-14T05:28:46.397232Z",
     "shell.execute_reply": "2026-01-14T05:28:46.396829Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:06,  6.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:12,  6.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:18,  6.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:24,  6.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:31,  6.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:37,  6.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:44,  6.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:50,  6.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:57,  6.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [01:03,  6.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [01:09,  6.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [01:16,  6.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [01:22,  6.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [01:28,  6.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [01:35,  6.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [01:41,  6.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [01:48,  6.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [01:55,  6.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [02:01,  6.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [02:08,  6.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [02:14,  6.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [02:21,  6.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [02:27,  6.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [02:34,  6.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [02:34,  6.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNModel(data='single') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b6476a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:28:46.398232Z",
     "iopub.status.busy": "2026-01-14T05:28:46.398137Z",
     "iopub.status.idle": "2026-01-14T05:31:16.356256Z",
     "shell.execute_reply": "2026-01-14T05:31:16.355890Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:11, 11.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:22, 11.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:34, 11.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:45, 11.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:56, 11.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [01:07, 11.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [01:18, 11.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [01:30, 11.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [01:41, 11.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [01:53, 11.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [02:05, 11.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [02:17, 11.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [02:29, 11.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [02:29, 11.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNModel(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc875e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:31:16.357533Z",
     "iopub.status.busy": "2026-01-14T05:31:16.357088Z",
     "iopub.status.idle": "2026-01-14T05:31:16.366528Z",
     "shell.execute_reply": "2026-01-14T05:31:16.366202Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
