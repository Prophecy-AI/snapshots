{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3027599",
   "metadata": {},
   "source": [
    "# Experiment 020: Graph Neural Network (GNN) for Molecular Property Prediction\n",
    "\n",
    "**Key insight from research:**\n",
    "- Paper arxiv:2512.19530 achieved MSE 0.0039 using GNN (25x better than tabular ensembles)\n",
    "- GNN can learn molecular structure patterns that generalize to unseen solvents\n",
    "- This is the only approach with demonstrated target-level performance\n",
    "\n",
    "**Architecture:**\n",
    "- Use RDKit to convert solvent SMILES to molecular graphs\n",
    "- Graph Convolutional Network (GCN) for molecular encoding\n",
    "- Combine molecular embeddings with process conditions (Temperature, Residence Time)\n",
    "- Per-target prediction heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17307ac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:11.255478Z",
     "iopub.status.busy": "2026-01-14T05:25:11.254956Z",
     "iopub.status.idle": "2026-01-14T05:25:13.633475Z",
     "shell.execute_reply": "2026-01-14T05:25:13.633071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from abc import ABC\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GNN imports\n",
    "from rdkit import Chem\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, global_add_pool\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "torch.set_default_dtype(torch.float32)  # PyG works better with float32\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b59a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:13.634753Z",
     "iopub.status.busy": "2026-01-14T05:25:13.634590Z",
     "iopub.status.idle": "2026-01-14T05:25:13.641174Z",
     "shell.execute_reply": "2026-01-14T05:25:13.640827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES lookup: 26 solvents\n"
     ]
    }
   ],
   "source": [
    "# --- UTILITY FUNCTIONS ---\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & \n",
    "                 (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load SMILES lookup\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "SMILES_DICT = SMILES_DF['solvent smiles'].to_dict()\n",
    "print(f\"SMILES lookup: {len(SMILES_DICT)} solvents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a262826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:13.642041Z",
     "iopub.status.busy": "2026-01-14T05:25:13.641942Z",
     "iopub.status.idle": "2026-01-14T05:25:13.644819Z",
     "shell.execute_reply": "2026-01-14T05:25:13.644484Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- BASE CLASSES ---\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self): raise NotImplementedError\n",
    "    def featurize(self, X): raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self): pass\n",
    "    def train_model(self, X_train, y_train): raise NotImplementedError\n",
    "    def predict(self): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad8ee8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:13.645809Z",
     "iopub.status.busy": "2026-01-14T05:25:13.645704Z",
     "iopub.status.idle": "2026-01-14T05:25:13.651219Z",
     "shell.execute_reply": "2026-01-14T05:25:13.650873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethanol graph: 3 atoms, 4 edges\n",
      "Water.Acetonitrile graph: 4 atoms, 4 edges\n"
     ]
    }
   ],
   "source": [
    "# --- MOLECULAR GRAPH UTILITIES ---\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"Convert SMILES string to PyTorch Geometric Data object.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        # Fallback for invalid SMILES (e.g., mixtures like \"O.CC#N\")\n",
    "        # Use first component\n",
    "        smiles_parts = smiles.split('.')\n",
    "        mol = Chem.MolFromSmiles(smiles_parts[0])\n",
    "        if mol is None:\n",
    "            # Return a simple water molecule as fallback\n",
    "            mol = Chem.MolFromSmiles('O')\n",
    "    \n",
    "    # Atom features: [atomic_num, degree, formal_charge, hybridization, aromatic]\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        features = [\n",
    "            atom.GetAtomicNum(),\n",
    "            atom.GetDegree(),\n",
    "            atom.GetFormalCharge(),\n",
    "            int(atom.GetHybridization()),\n",
    "            int(atom.GetIsAromatic())\n",
    "        ]\n",
    "        atom_features.append(features)\n",
    "    \n",
    "    x = torch.tensor(atom_features, dtype=torch.float32)\n",
    "    \n",
    "    # Edge index (bonds)\n",
    "    edge_index = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])  # Undirected\n",
    "    \n",
    "    if len(edge_index) == 0:\n",
    "        # Single atom molecule\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Test\n",
    "test_graph = smiles_to_graph('CCO')  # Ethanol\n",
    "print(f\"Ethanol graph: {test_graph.num_nodes} atoms, {test_graph.num_edges} edges\")\n",
    "test_graph = smiles_to_graph('O.CC#N')  # Water.Acetonitrile mixture\n",
    "print(f\"Water.Acetonitrile graph: {test_graph.num_nodes} atoms, {test_graph.num_edges} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6fd10a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:13.652049Z",
     "iopub.status.busy": "2026-01-14T05:25:13.651951Z",
     "iopub.status.idle": "2026-01-14T05:25:13.656441Z",
     "shell.execute_reply": "2026-01-14T05:25:13.656070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MolecularGNN defined\n"
     ]
    }
   ],
   "source": [
    "# --- GNN MODEL ---\n",
    "class MolecularGNN(nn.Module):\n",
    "    \"\"\"Graph Neural Network for molecular property prediction.\n",
    "    \n",
    "    Architecture:\n",
    "    - 3 GCN layers for molecular encoding\n",
    "    - Global mean pooling to get molecule-level embedding\n",
    "    - Combine with process conditions (Temperature, Residence Time)\n",
    "    - MLP head for prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, atom_features=5, hidden_dim=64, output_dim=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # GCN layers\n",
    "        self.conv1 = GCNConv(atom_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Process condition encoder\n",
    "        self.condition_encoder = nn.Sequential(\n",
    "            nn.Linear(3, 32),  # [RT, Temp, SolventB%]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32)\n",
    "        )\n",
    "        \n",
    "        # Prediction head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + 32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, graph_batch, conditions):\n",
    "        # Graph encoding\n",
    "        x, edge_index, batch = graph_batch.x, graph_batch.edge_index, graph_batch.batch\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        \n",
    "        # Global pooling\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_dim]\n",
    "        \n",
    "        # Condition encoding\n",
    "        cond = self.condition_encoder(conditions)  # [batch_size, 32]\n",
    "        \n",
    "        # Combine and predict\n",
    "        combined = torch.cat([x, cond], dim=1)\n",
    "        out = self.head(combined)\n",
    "        \n",
    "        return out\n",
    "\n",
    "print(\"MolecularGNN defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6626cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:13.657510Z",
     "iopub.status.busy": "2026-01-14T05:25:13.657389Z",
     "iopub.status.idle": "2026-01-14T05:25:13.666400Z",
     "shell.execute_reply": "2026-01-14T05:25:13.666038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNModel defined\n"
     ]
    }
   ],
   "source": [
    "# --- GNN MODEL WRAPPER ---\n",
    "class GNNModel(BaseModel):\n",
    "    \"\"\"GNN-based model for solvent yield prediction.\n",
    "    \n",
    "    For single solvents: Use molecular graph directly\n",
    "    For mixed solvents: Average embeddings of both solvents weighted by SolventB%\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Pre-compute graphs for all solvents\n",
    "        self.solvent_graphs = {}\n",
    "        for name, smiles in SMILES_DICT.items():\n",
    "            self.solvent_graphs[name] = smiles_to_graph(smiles)\n",
    "    \n",
    "    def _get_conditions(self, X):\n",
    "        \"\"\"Extract process conditions.\"\"\"\n",
    "        rt = X['Residence Time'].values.reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.reshape(-1, 1)\n",
    "        \n",
    "        if self.mixed:\n",
    "            pct = X['SolventB%'].values.reshape(-1, 1) / 100.0\n",
    "            return np.hstack([rt, temp, pct])\n",
    "        else:\n",
    "            return np.hstack([rt, temp, np.zeros((len(X), 1))])\n",
    "    \n",
    "    def _get_graphs(self, X):\n",
    "        \"\"\"Get molecular graphs for samples.\"\"\"\n",
    "        graphs = []\n",
    "        if self.mixed:\n",
    "            for _, row in X.iterrows():\n",
    "                # For mixed solvents, use the primary solvent (A)\n",
    "                # Could also try averaging embeddings\n",
    "                solvent = row['SOLVENT A NAME']\n",
    "                if solvent in self.solvent_graphs:\n",
    "                    graphs.append(self.solvent_graphs[solvent])\n",
    "                else:\n",
    "                    graphs.append(smiles_to_graph('O'))  # Fallback\n",
    "        else:\n",
    "            for _, row in X.iterrows():\n",
    "                solvent = row['SOLVENT NAME']\n",
    "                if solvent in self.solvent_graphs:\n",
    "                    graphs.append(self.solvent_graphs[solvent])\n",
    "                else:\n",
    "                    graphs.append(smiles_to_graph('O'))  # Fallback\n",
    "        return graphs\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Get conditions and graphs\n",
    "        conditions = self._get_conditions(X_train)\n",
    "        conditions_scaled = self.scaler.fit_transform(conditions)\n",
    "        graphs = self._get_graphs(X_train)\n",
    "        y = y_train.values\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = MolecularGNN(atom_features=5, hidden_dim=64, output_dim=3).to(device)\n",
    "        \n",
    "        # Training\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Create batches\n",
    "        batch_size = 32\n",
    "        n_samples = len(graphs)\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(100):\n",
    "            # Shuffle\n",
    "            indices = np.random.permutation(n_samples)\n",
    "            \n",
    "            for start in range(0, n_samples, batch_size):\n",
    "                end = min(start + batch_size, n_samples)\n",
    "                batch_idx = indices[start:end]\n",
    "                \n",
    "                # Batch graphs\n",
    "                batch_graphs = [graphs[i] for i in batch_idx]\n",
    "                graph_batch = Batch.from_data_list(batch_graphs).to(device)\n",
    "                \n",
    "                # Batch conditions\n",
    "                batch_cond = torch.tensor(conditions_scaled[batch_idx], dtype=torch.float32).to(device)\n",
    "                \n",
    "                # Batch targets\n",
    "                batch_y = torch.tensor(y[batch_idx], dtype=torch.float32).to(device)\n",
    "                \n",
    "                # Forward\n",
    "                optimizer.zero_grad()\n",
    "                pred = self.model(graph_batch, batch_cond)\n",
    "                loss = criterion(pred, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        conditions = self._get_conditions(X)\n",
    "        conditions_scaled = self.scaler.transform(conditions)\n",
    "        graphs = self._get_graphs(X)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            graph_batch = Batch.from_data_list(graphs).to(device)\n",
    "            cond_tensor = torch.tensor(conditions_scaled, dtype=torch.float32).to(device)\n",
    "            pred = self.model(graph_batch, cond_tensor)\n",
    "        \n",
    "        # Convert to double for template compatibility\n",
    "        return pred.cpu().double()\n",
    "\n",
    "print(\"GNNModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40428aca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:25:13.667442Z",
     "iopub.status.busy": "2026-01-14T05:25:13.667345Z",
     "iopub.status.idle": "2026-01-14T05:26:06.644790Z",
     "shell.execute_reply": "2026-01-14T05:26:06.644431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GNNModel...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.2505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.0502\n",
      "\n",
      "Single solvent quick test MAE: 0.1375\n",
      "\n",
      "Testing on full data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 0: MAE = 0.0840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 1: MAE = 0.1285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 2: MAE = 0.0833\n",
      "\n",
      "Full data quick test MAE: 0.0986\n"
     ]
    }
   ],
   "source": [
    "# --- QUICK VALIDATION TEST ---\n",
    "print(\"Testing GNNModel...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "errors = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X_test, Y_test)):\n",
    "    if i >= 3: break\n",
    "    model = GNNModel(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    print(f\"Single Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nSingle solvent quick test MAE: {np.mean(errors):.4f}\")\n",
    "\n",
    "# Test full data\n",
    "print(\"\\nTesting on full data...\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "errors_full = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    if i >= 3: break\n",
    "    model = GNNModel(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors_full.append(mae)\n",
    "    print(f\"Full Fold {i}: MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nFull data quick test MAE: {np.mean(errors_full):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6786f926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:26:11.862361Z",
     "iopub.status.busy": "2026-01-14T05:26:11.861844Z",
     "iopub.status.idle": "2026-01-14T05:28:46.397232Z",
     "shell.execute_reply": "2026-01-14T05:28:46.396829Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:06,  6.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:12,  6.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:18,  6.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:24,  6.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:31,  6.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:37,  6.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:44,  6.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:50,  6.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:57,  6.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [01:03,  6.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [01:09,  6.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [01:16,  6.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [01:22,  6.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [01:28,  6.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [01:35,  6.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [01:41,  6.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [01:48,  6.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [01:55,  6.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [02:01,  6.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [02:08,  6.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [02:14,  6.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [02:21,  6.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [02:27,  6.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [02:34,  6.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [02:34,  6.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNModel(data='single') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b6476a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:28:46.398232Z",
     "iopub.status.busy": "2026-01-14T05:28:46.398137Z",
     "iopub.status.idle": "2026-01-14T05:31:16.356256Z",
     "shell.execute_reply": "2026-01-14T05:31:16.355890Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:11, 11.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:22, 11.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:34, 11.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:45, 11.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:56, 11.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [01:07, 11.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [01:18, 11.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [01:30, 11.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [01:41, 11.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [01:53, 11.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [02:05, 11.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [02:17, 11.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [02:29, 11.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [02:29, 11.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNModel(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc875e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:31:16.357533Z",
     "iopub.status.busy": "2026-01-14T05:31:16.357088Z",
     "iopub.status.idle": "2026-01-14T05:31:16.366528Z",
     "shell.execute_reply": "2026-01-14T05:31:16.366202Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e553856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:32:15.045470Z",
     "iopub.status.busy": "2026-01-14T05:32:15.045073Z",
     "iopub.status.idle": "2026-01-14T05:32:15.074008Z",
     "shell.execute_reply": "2026-01-14T05:32:15.073608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent CV MAE: 0.1008\n",
      "Full data CV MAE: 0.0972\n",
      "\n",
      "Combined CV MAE: 0.0990\n"
     ]
    }
   ],
   "source": [
    "# Calculate CV score\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "# Single solvent CV\n",
    "single_preds = submission_single_solvent[['target_1', 'target_2', 'target_3']].values\n",
    "single_true = []\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X_single, Y_single)):\n",
    "    single_true.append(test_Y.values)\n",
    "single_true = np.vstack(single_true)\n",
    "single_mae = np.mean(np.abs(single_preds - single_true))\n",
    "print(f\"Single solvent CV MAE: {single_mae:.4f}\")\n",
    "\n",
    "# Full data CV\n",
    "full_preds = submission_full_data[['target_1', 'target_2', 'target_3']].values\n",
    "full_true = []\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    full_true.append(test_Y.values)\n",
    "full_true = np.vstack(full_true)\n",
    "full_mae = np.mean(np.abs(full_preds - full_true))\n",
    "print(f\"Full data CV MAE: {full_mae:.4f}\")\n",
    "\n",
    "# Combined\n",
    "combined_mae = (single_mae + full_mae) / 2\n",
    "print(f\"\\nCombined CV MAE: {combined_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "265eff86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:32:40.120237Z",
     "iopub.status.busy": "2026-01-14T05:32:40.119761Z",
     "iopub.status.idle": "2026-01-14T05:32:40.126486Z",
     "shell.execute_reply": "2026-01-14T05:32:40.126051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing enhanced graph...\n",
      "Ethanol: 3 atoms, 4 edges, atom_features=torch.Size([3, 13]), edge_features=torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# --- IMPROVED GNN MODEL ---\n",
    "# Let's try a more sophisticated architecture\n",
    "\n",
    "from torch_geometric.nn import GATConv, NNConv, Set2Set\n",
    "\n",
    "def smiles_to_graph_v2(smiles):\n",
    "    \"\"\"Enhanced SMILES to graph with more atom features.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        smiles_parts = smiles.split('.')\n",
    "        mol = Chem.MolFromSmiles(smiles_parts[0])\n",
    "        if mol is None:\n",
    "            mol = Chem.MolFromSmiles('O')\n",
    "    \n",
    "    # Enhanced atom features (13 features)\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        features = [\n",
    "            atom.GetAtomicNum(),\n",
    "            atom.GetDegree(),\n",
    "            atom.GetFormalCharge(),\n",
    "            int(atom.GetHybridization()),\n",
    "            int(atom.GetIsAromatic()),\n",
    "            atom.GetTotalNumHs(),\n",
    "            atom.GetNumRadicalElectrons(),\n",
    "            int(atom.IsInRing()),\n",
    "            atom.GetMass() / 100.0,  # Normalized mass\n",
    "            atom.GetExplicitValence(),\n",
    "            int(atom.GetChiralTag()),\n",
    "            atom.GetTotalValence(),\n",
    "            int(atom.GetNoImplicit())\n",
    "        ]\n",
    "        atom_features.append(features)\n",
    "    \n",
    "    x = torch.tensor(atom_features, dtype=torch.float32)\n",
    "    \n",
    "    # Edge index and edge features\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        \n",
    "        # Bond features (4 features)\n",
    "        bond_features = [\n",
    "            float(bond.GetBondTypeAsDouble()),\n",
    "            int(bond.GetIsConjugated()),\n",
    "            int(bond.IsInRing()),\n",
    "            int(bond.GetStereo())\n",
    "        ]\n",
    "        \n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])\n",
    "        edge_attr.append(bond_features)\n",
    "        edge_attr.append(bond_features)\n",
    "    \n",
    "    if len(edge_index) == 0:\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.zeros((0, 4), dtype=torch.float32)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float32)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "print(\"Testing enhanced graph...\")\n",
    "test_graph = smiles_to_graph_v2('CCO')\n",
    "print(f\"Ethanol: {test_graph.num_nodes} atoms, {test_graph.num_edges} edges, atom_features={test_graph.x.shape}, edge_features={test_graph.edge_attr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "391f4aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:33:10.875636Z",
     "iopub.status.busy": "2026-01-14T05:33:10.875123Z",
     "iopub.status.idle": "2026-01-14T05:33:10.880813Z",
     "shell.execute_reply": "2026-01-14T05:33:10.880446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImprovedMolecularGNN defined\n"
     ]
    }
   ],
   "source": [
    "# --- IMPROVED GNN WITH GAT ---\n",
    "class ImprovedMolecularGNN(nn.Module):\n",
    "    \"\"\"Graph Attention Network with edge features.\"\"\"\n",
    "    def __init__(self, atom_features=13, hidden_dim=128, output_dim=3, heads=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial embedding\n",
    "        self.atom_embed = nn.Linear(atom_features, hidden_dim)\n",
    "        \n",
    "        # GAT layers\n",
    "        self.gat1 = GATConv(hidden_dim, hidden_dim // heads, heads=heads, dropout=0.2)\n",
    "        self.gat2 = GATConv(hidden_dim, hidden_dim // heads, heads=heads, dropout=0.2)\n",
    "        self.gat3 = GATConv(hidden_dim, hidden_dim, heads=1, dropout=0.2)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        # Process condition encoder\n",
    "        self.condition_encoder = nn.Sequential(\n",
    "            nn.Linear(3, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 64)\n",
    "        )\n",
    "        \n",
    "        # Prediction head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, graph_batch, conditions):\n",
    "        x, edge_index, batch = graph_batch.x, graph_batch.edge_index, graph_batch.batch\n",
    "        \n",
    "        # Initial embedding\n",
    "        x = self.atom_embed(x)\n",
    "        \n",
    "        # GAT layers with residual connections\n",
    "        x1 = F.elu(self.bn1(self.gat1(x, edge_index)))\n",
    "        x2 = F.elu(self.bn2(self.gat2(x1, edge_index)))\n",
    "        x3 = self.bn3(self.gat3(x2, edge_index))\n",
    "        \n",
    "        # Global pooling\n",
    "        x = global_mean_pool(x3, batch)\n",
    "        \n",
    "        # Condition encoding\n",
    "        cond = self.condition_encoder(conditions)\n",
    "        \n",
    "        # Combine and predict\n",
    "        combined = torch.cat([x, cond], dim=1)\n",
    "        out = self.head(combined)\n",
    "        \n",
    "        return out\n",
    "\n",
    "print(\"ImprovedMolecularGNN defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b734e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:33:10.881661Z",
     "iopub.status.busy": "2026-01-14T05:33:10.881569Z",
     "iopub.status.idle": "2026-01-14T05:33:10.890076Z",
     "shell.execute_reply": "2026-01-14T05:33:10.889703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImprovedGNNModel defined\n"
     ]
    }
   ],
   "source": [
    "# --- IMPROVED GNN MODEL WRAPPER ---\n",
    "class ImprovedGNNModel(BaseModel):\n",
    "    \"\"\"Improved GNN with GAT, more features, and better training.\"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Pre-compute graphs for all solvents\n",
    "        self.solvent_graphs = {}\n",
    "        for name, smiles in SMILES_DICT.items():\n",
    "            self.solvent_graphs[name] = smiles_to_graph_v2(smiles)\n",
    "    \n",
    "    def _get_conditions(self, X):\n",
    "        rt = X['Residence Time'].values.reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.reshape(-1, 1)\n",
    "        \n",
    "        if self.mixed:\n",
    "            pct = X['SolventB%'].values.reshape(-1, 1) / 100.0\n",
    "            return np.hstack([rt, temp, pct])\n",
    "        else:\n",
    "            return np.hstack([rt, temp, np.zeros((len(X), 1))])\n",
    "    \n",
    "    def _get_graphs(self, X):\n",
    "        graphs = []\n",
    "        if self.mixed:\n",
    "            for _, row in X.iterrows():\n",
    "                solvent = row['SOLVENT A NAME']\n",
    "                if solvent in self.solvent_graphs:\n",
    "                    graphs.append(self.solvent_graphs[solvent])\n",
    "                else:\n",
    "                    graphs.append(smiles_to_graph_v2('O'))\n",
    "        else:\n",
    "            for _, row in X.iterrows():\n",
    "                solvent = row['SOLVENT NAME']\n",
    "                if solvent in self.solvent_graphs:\n",
    "                    graphs.append(self.solvent_graphs[solvent])\n",
    "                else:\n",
    "                    graphs.append(smiles_to_graph_v2('O'))\n",
    "        return graphs\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        conditions = self._get_conditions(X_train)\n",
    "        conditions_scaled = self.scaler.fit_transform(conditions)\n",
    "        graphs = self._get_graphs(X_train)\n",
    "        y = y_train.values\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = ImprovedMolecularGNN(atom_features=13, hidden_dim=128, output_dim=3).to(device)\n",
    "        \n",
    "        # Training with LR scheduling\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=5e-4, weight_decay=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        batch_size = 32\n",
    "        n_samples = len(graphs)\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(200):\n",
    "            indices = np.random.permutation(n_samples)\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            for start in range(0, n_samples, batch_size):\n",
    "                end = min(start + batch_size, n_samples)\n",
    "                batch_idx = indices[start:end]\n",
    "                \n",
    "                batch_graphs = [graphs[i] for i in batch_idx]\n",
    "                graph_batch = Batch.from_data_list(batch_graphs).to(device)\n",
    "                batch_cond = torch.tensor(conditions_scaled[batch_idx], dtype=torch.float32).to(device)\n",
    "                batch_y = torch.tensor(y[batch_idx], dtype=torch.float32).to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                pred = self.model(graph_batch, batch_cond)\n",
    "                loss = criterion(pred, batch_y)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "            \n",
    "            avg_loss = epoch_loss / (n_samples // batch_size + 1)\n",
    "            scheduler.step(avg_loss)\n",
    "            \n",
    "            # Early stopping\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= 40:\n",
    "                    break\n",
    "    \n",
    "    def predict(self, X):\n",
    "        conditions = self._get_conditions(X)\n",
    "        conditions_scaled = self.scaler.transform(conditions)\n",
    "        graphs = self._get_graphs(X)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            graph_batch = Batch.from_data_list(graphs).to(device)\n",
    "            cond_tensor = torch.tensor(conditions_scaled, dtype=torch.float32).to(device)\n",
    "            pred = self.model(graph_batch, cond_tensor)\n",
    "        \n",
    "        return pred.cpu().double()\n",
    "\n",
    "print(\"ImprovedGNNModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07f863cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:33:20.885770Z",
     "iopub.status.busy": "2026-01-14T05:33:20.885250Z",
     "iopub.status.idle": "2026-01-14T05:34:22.977924Z",
     "shell.execute_reply": "2026-01-14T05:34:22.977519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ImprovedGNNModel...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.1616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.0259\n",
      "\n",
      "Improved GNN quick test MAE: 0.1097\n"
     ]
    }
   ],
   "source": [
    "# Quick test of improved GNN\n",
    "print(\"Testing ImprovedGNNModel...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "errors = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X_test, Y_test)):\n",
    "    if i >= 3: break\n",
    "    model = ImprovedGNNModel(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    print(f\"Single Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nImproved GNN quick test MAE: {np.mean(errors):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75038a0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:34:46.828551Z",
     "iopub.status.busy": "2026-01-14T05:34:46.828036Z",
     "iopub.status.idle": "2026-01-14T05:34:46.846858Z",
     "shell.execute_reply": "2026-01-14T05:34:46.846506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethanol descriptors: 28 features\n",
      "Sample values: [ 4.6069e+01 -1.4000e-03  2.0230e+01  1.0000e+00  1.0000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Let's try a hybrid approach: RDKit descriptors + MLP\n",
    "# This might work better than pure GNN with limited data\n",
    "\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
    "\n",
    "def get_rdkit_descriptors(smiles):\n",
    "    \"\"\"Get comprehensive RDKit molecular descriptors.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        smiles_parts = smiles.split('.')\n",
    "        mol = Chem.MolFromSmiles(smiles_parts[0])\n",
    "        if mol is None:\n",
    "            mol = Chem.MolFromSmiles('O')\n",
    "    \n",
    "    descriptors = [\n",
    "        Descriptors.MolWt(mol),\n",
    "        Descriptors.MolLogP(mol),\n",
    "        Descriptors.TPSA(mol),\n",
    "        Descriptors.NumHDonors(mol),\n",
    "        Descriptors.NumHAcceptors(mol),\n",
    "        Descriptors.NumRotatableBonds(mol),\n",
    "        Descriptors.NumAromaticRings(mol),\n",
    "        Descriptors.NumAliphaticRings(mol),\n",
    "        Descriptors.FractionCSP3(mol),\n",
    "        rdMolDescriptors.CalcNumHeavyAtoms(mol),\n",
    "        rdMolDescriptors.CalcNumHeteroatoms(mol),\n",
    "        Descriptors.NumValenceElectrons(mol),\n",
    "        Descriptors.MaxPartialCharge(mol) if Descriptors.MaxPartialCharge(mol) is not None else 0,\n",
    "        Descriptors.MinPartialCharge(mol) if Descriptors.MinPartialCharge(mol) is not None else 0,\n",
    "        Descriptors.MaxAbsPartialCharge(mol) if Descriptors.MaxAbsPartialCharge(mol) is not None else 0,\n",
    "        Descriptors.BalabanJ(mol) if Descriptors.BalabanJ(mol) != 0 else 0,\n",
    "        Descriptors.BertzCT(mol),\n",
    "        Descriptors.Chi0(mol),\n",
    "        Descriptors.Chi1(mol),\n",
    "        Descriptors.HallKierAlpha(mol),\n",
    "        Descriptors.Kappa1(mol),\n",
    "        Descriptors.Kappa2(mol),\n",
    "        Descriptors.LabuteASA(mol),\n",
    "        Descriptors.PEOE_VSA1(mol),\n",
    "        Descriptors.PEOE_VSA2(mol),\n",
    "        Descriptors.SMR_VSA1(mol),\n",
    "        Descriptors.SlogP_VSA1(mol),\n",
    "        Descriptors.EState_VSA1(mol),\n",
    "    ]\n",
    "    \n",
    "    # Replace NaN/inf with 0\n",
    "    descriptors = [0 if (d is None or np.isnan(d) or np.isinf(d)) else d for d in descriptors]\n",
    "    return np.array(descriptors)\n",
    "\n",
    "# Test\n",
    "test_desc = get_rdkit_descriptors('CCO')\n",
    "print(f\"Ethanol descriptors: {len(test_desc)} features\")\n",
    "print(f\"Sample values: {test_desc[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0da3553d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:35:02.434663Z",
     "iopub.status.busy": "2026-01-14T05:35:02.434191Z",
     "iopub.status.idle": "2026-01-14T05:35:02.459957Z",
     "shell.execute_reply": "2026-01-14T05:35:02.459308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed RDKit descriptors for 26 solvents\n",
      "RDKitMLPModel defined\n"
     ]
    }
   ],
   "source": [
    "# Pre-compute RDKit descriptors for all solvents\n",
    "RDKIT_DESC_DICT = {}\n",
    "for name, smiles in SMILES_DICT.items():\n",
    "    RDKIT_DESC_DICT[name] = get_rdkit_descriptors(smiles)\n",
    "print(f\"Computed RDKit descriptors for {len(RDKIT_DESC_DICT)} solvents\")\n",
    "\n",
    "# --- HYBRID MODEL: RDKit Descriptors + MLP ---\n",
    "class RDKitMLPModel(BaseModel):\n",
    "    \"\"\"MLP using RDKit molecular descriptors.\"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def _get_features(self, X):\n",
    "        features = []\n",
    "        if self.mixed:\n",
    "            for _, row in X.iterrows():\n",
    "                solvent_a = row['SOLVENT A NAME']\n",
    "                solvent_b = row['SOLVENT B NAME']\n",
    "                pct_b = row['SolventB%'] / 100.0\n",
    "                \n",
    "                desc_a = RDKIT_DESC_DICT.get(solvent_a, np.zeros(28))\n",
    "                desc_b = RDKIT_DESC_DICT.get(solvent_b, np.zeros(28))\n",
    "                \n",
    "                # Weighted average of descriptors\n",
    "                desc_mix = (1 - pct_b) * desc_a + pct_b * desc_b\n",
    "                \n",
    "                feat = np.concatenate([\n",
    "                    [row['Residence Time'], row['Temperature'], pct_b],\n",
    "                    desc_mix\n",
    "                ])\n",
    "                features.append(feat)\n",
    "        else:\n",
    "            for _, row in X.iterrows():\n",
    "                solvent = row['SOLVENT NAME']\n",
    "                desc = RDKIT_DESC_DICT.get(solvent, np.zeros(28))\n",
    "                \n",
    "                feat = np.concatenate([\n",
    "                    [row['Residence Time'], row['Temperature']],\n",
    "                    desc\n",
    "                ])\n",
    "                features.append(feat)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_feat = self._get_features(X_train)\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        y = y_train.values\n",
    "        \n",
    "        input_dim = X_scaled.shape[1]\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 3),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(200):\n",
    "            optimizer.zero_grad()\n",
    "            pred = self.model(X_tensor)\n",
    "            loss = criterion(pred, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_feat = self._get_features(X)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "            pred = self.model(X_tensor)\n",
    "        \n",
    "        return pred.cpu().double()\n",
    "\n",
    "print(\"RDKitMLPModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f934bab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:35:10.521078Z",
     "iopub.status.busy": "2026-01-14T05:35:10.520593Z",
     "iopub.status.idle": "2026-01-14T05:35:11.511084Z",
     "shell.execute_reply": "2026-01-14T05:35:11.510726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RDKitMLPModel...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.2035\n",
      "Single Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.0344\n",
      "Single Fold 3 (Acetonitrile): MAE = 0.0783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 4 (Acetonitrile.Acetic Acid): MAE = 0.1746\n",
      "\n",
      "RDKit MLP quick test MAE: 0.1248\n"
     ]
    }
   ],
   "source": [
    "# Quick test of RDKit MLP\n",
    "print(\"Testing RDKitMLPModel...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "errors = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X_test, Y_test)):\n",
    "    if i >= 5: break\n",
    "    model = RDKitMLPModel(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    print(f\"Single Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nRDKit MLP quick test MAE: {np.mean(errors):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0060f658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:35:28.367879Z",
     "iopub.status.busy": "2026-01-14T05:35:28.367572Z",
     "iopub.status.idle": "2026-01-14T05:35:28.395643Z",
     "shell.execute_reply": "2026-01-14T05:35:28.395269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Morgan fingerprints for 26 solvents\n",
      "Ethanol fingerprint: 1024 bits, 6 bits set\n"
     ]
    }
   ],
   "source": [
    "# Let's try Morgan fingerprints - these are known to work well for molecular property prediction\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "def get_morgan_fingerprint(smiles, radius=2, n_bits=1024):\n",
    "    \"\"\"Get Morgan fingerprint as numpy array.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        smiles_parts = smiles.split('.')\n",
    "        mol = Chem.MolFromSmiles(smiles_parts[0])\n",
    "        if mol is None:\n",
    "            mol = Chem.MolFromSmiles('O')\n",
    "    \n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    return np.array(fp)\n",
    "\n",
    "# Pre-compute fingerprints for all solvents\n",
    "MORGAN_FP_DICT = {}\n",
    "for name, smiles in SMILES_DICT.items():\n",
    "    MORGAN_FP_DICT[name] = get_morgan_fingerprint(smiles)\n",
    "print(f\"Computed Morgan fingerprints for {len(MORGAN_FP_DICT)} solvents\")\n",
    "\n",
    "# Test\n",
    "test_fp = get_morgan_fingerprint('CCO')\n",
    "print(f\"Ethanol fingerprint: {len(test_fp)} bits, {np.sum(test_fp)} bits set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "269b9201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:35:44.127809Z",
     "iopub.status.busy": "2026-01-14T05:35:44.127260Z",
     "iopub.status.idle": "2026-01-14T05:35:45.182203Z",
     "shell.execute_reply": "2026-01-14T05:35:45.181829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MorganMLPModel defined\n",
      "\n",
      "Testing MorganMLPModel...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MAE = 0.2630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 1 (2,2,2-Trifluoroethanol): MAE = 0.1127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 2 (2-Methyltetrahydrofuran [2-MeTHF]): MAE = 0.0600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 3 (Acetonitrile): MAE = 0.0662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 4 (Acetonitrile.Acetic Acid): MAE = 0.1890\n",
      "\n",
      "Morgan MLP quick test MAE: 0.1382\n"
     ]
    }
   ],
   "source": [
    "# --- MORGAN FINGERPRINT + MLP MODEL ---\n",
    "class MorganMLPModel(BaseModel):\n",
    "    \"\"\"MLP using Morgan fingerprints + RDKit descriptors.\"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def _get_features(self, X):\n",
    "        features = []\n",
    "        if self.mixed:\n",
    "            for _, row in X.iterrows():\n",
    "                solvent_a = row['SOLVENT A NAME']\n",
    "                solvent_b = row['SOLVENT B NAME']\n",
    "                pct_b = row['SolventB%'] / 100.0\n",
    "                \n",
    "                fp_a = MORGAN_FP_DICT.get(solvent_a, np.zeros(1024))\n",
    "                fp_b = MORGAN_FP_DICT.get(solvent_b, np.zeros(1024))\n",
    "                desc_a = RDKIT_DESC_DICT.get(solvent_a, np.zeros(28))\n",
    "                desc_b = RDKIT_DESC_DICT.get(solvent_b, np.zeros(28))\n",
    "                \n",
    "                # Weighted average\n",
    "                fp_mix = (1 - pct_b) * fp_a + pct_b * fp_b\n",
    "                desc_mix = (1 - pct_b) * desc_a + pct_b * desc_b\n",
    "                \n",
    "                feat = np.concatenate([\n",
    "                    [row['Residence Time'], row['Temperature'], pct_b],\n",
    "                    desc_mix,\n",
    "                    fp_mix\n",
    "                ])\n",
    "                features.append(feat)\n",
    "        else:\n",
    "            for _, row in X.iterrows():\n",
    "                solvent = row['SOLVENT NAME']\n",
    "                fp = MORGAN_FP_DICT.get(solvent, np.zeros(1024))\n",
    "                desc = RDKIT_DESC_DICT.get(solvent, np.zeros(28))\n",
    "                \n",
    "                feat = np.concatenate([\n",
    "                    [row['Residence Time'], row['Temperature']],\n",
    "                    desc,\n",
    "                    fp\n",
    "                ])\n",
    "                features.append(feat)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_feat = self._get_features(X_train)\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        y = y_train.values\n",
    "        \n",
    "        input_dim = X_scaled.shape[1]\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(200):\n",
    "            optimizer.zero_grad()\n",
    "            pred = self.model(X_tensor)\n",
    "            loss = criterion(pred, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_feat = self._get_features(X)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "            pred = self.model(X_tensor)\n",
    "        \n",
    "        return pred.cpu().double()\n",
    "\n",
    "print(\"MorganMLPModel defined\")\n",
    "\n",
    "# Quick test\n",
    "print(\"\\nTesting MorganMLPModel...\")\n",
    "X_test, Y_test = load_data(\"single_solvent\")\n",
    "\n",
    "errors = []\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X_test, Y_test)):\n",
    "    if i >= 5: break\n",
    "    model = MorganMLPModel(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mae = np.mean(np.abs(preds - test_Y.values))\n",
    "    errors.append(mae)\n",
    "    solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    print(f\"Single Fold {i} ({solvent}): MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nMorgan MLP quick test MAE: {np.mean(errors):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a9ee170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:35:55.689872Z",
     "iopub.status.busy": "2026-01-14T05:35:55.689377Z",
     "iopub.status.idle": "2026-01-14T05:35:55.693970Z",
     "shell.execute_reply": "2026-01-14T05:35:55.693573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange descriptors: (26, 13)\n",
      "['dielectric constant', 'ET(30)', 'alpha', 'beta', 'pi*', 'SA', 'SB', 'SP', 'SdP', 'N', 'n', 'f(n)', 'delta']\n"
     ]
    }
   ],
   "source": [
    "# Let's go back to our best approach - Spange descriptors + MLP with improvements\n",
    "# Load Spange descriptors\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "print(f\"Spange descriptors: {SPANGE_DF.shape}\")\n",
    "print(SPANGE_DF.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb972770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:36:20.347403Z",
     "iopub.status.busy": "2026-01-14T05:36:20.346888Z",
     "iopub.status.idle": "2026-01-14T05:36:20.354596Z",
     "shell.execute_reply": "2026-01-14T05:36:20.354227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnhancedSpangeMLPModel defined\n"
     ]
    }
   ],
   "source": [
    "# --- ENHANCED MLP WITH SPANGE DESCRIPTORS ---\n",
    "# This is our best approach with improvements: 300 epochs, LR scheduling, gradient clipping\n",
    "\n",
    "class EnhancedSpangeMLPModel(BaseModel):\n",
    "    \"\"\"Enhanced MLP using Spange descriptors with better training.\"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def _get_features(self, X):\n",
    "        features = []\n",
    "        if self.mixed:\n",
    "            for _, row in X.iterrows():\n",
    "                solvent_a = row['SOLVENT A NAME']\n",
    "                solvent_b = row['SOLVENT B NAME']\n",
    "                pct_b = row['SolventB%'] / 100.0\n",
    "                \n",
    "                desc_a = SPANGE_DF.loc[solvent_a].values if solvent_a in SPANGE_DF.index else np.zeros(13)\n",
    "                desc_b = SPANGE_DF.loc[solvent_b].values if solvent_b in SPANGE_DF.index else np.zeros(13)\n",
    "                \n",
    "                # Weighted average\n",
    "                desc_mix = (1 - pct_b) * desc_a + pct_b * desc_b\n",
    "                \n",
    "                feat = np.concatenate([\n",
    "                    [row['Residence Time'], row['Temperature'], pct_b],\n",
    "                    desc_mix\n",
    "                ])\n",
    "                features.append(feat)\n",
    "        else:\n",
    "            for _, row in X.iterrows():\n",
    "                solvent = row['SOLVENT NAME']\n",
    "                desc = SPANGE_DF.loc[solvent].values if solvent in SPANGE_DF.index else np.zeros(13)\n",
    "                \n",
    "                feat = np.concatenate([\n",
    "                    [row['Residence Time'], row['Temperature']],\n",
    "                    desc\n",
    "                ])\n",
    "                features.append(feat)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_feat = self._get_features(X_train)\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        y = y_train.values\n",
    "        \n",
    "        input_dim = X_scaled.shape[1]\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 3),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=30)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(300):\n",
    "            optimizer.zero_grad()\n",
    "            pred = self.model(X_tensor)\n",
    "            loss = criterion(pred, y_tensor)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss.item())\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_feat = self._get_features(X)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "            pred = self.model(X_tensor)\n",
    "        \n",
    "        return pred.cpu().double()\n",
    "\n",
    "print(\"EnhancedSpangeMLPModel defined\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
