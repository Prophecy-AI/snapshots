{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b2f758",
   "metadata": {},
   "source": [
    "# Loop 5 Strategic Analysis\n",
    "\n",
    "## Situation Summary\n",
    "- **Target**: 0.023 (lower is better)\n",
    "- **Best LB**: 0.0972 (exp_003)\n",
    "- **Best CV**: 0.0105 (exp_003)\n",
    "- **CV-LB Gap**: ~9x ratio consistently\n",
    "- **Submissions used**: 3/5 (2 remaining)\n",
    "\n",
    "## Key Observations\n",
    "1. Deep Residual MLP FAILED badly (0.0519 vs 0.0105 baseline) - complexity hurts\n",
    "2. CV improvements translate poorly to LB (5.4% CV → 1% LB)\n",
    "3. The 9x CV-LB gap is consistent across all submissions\n",
    "4. To beat target 0.023, need LB improvement of 76% from current 0.0972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd46b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:40:34.450235Z",
     "iopub.status.busy": "2026-01-08T07:40:34.449487Z",
     "iopub.status.idle": "2026-01-08T07:40:34.901259Z",
     "shell.execute_reply": "2026-01-08T07:40:34.900510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUBMISSION HISTORY ===\n",
      "    exp                               name     cv     lb  cv_lb_ratio\n",
      "exp_000  MLP Baseline (Spange + Arrhenius) 0.0111 0.0982     8.846847\n",
      "exp_001      LightGBM (Spange + Arrhenius) 0.0123 0.1065     8.658537\n",
      "exp_003 Combined Spange + DRFP + Arrhenius 0.0105 0.0972     9.257143\n",
      "\n",
      "Average CV-LB ratio: 8.92x\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Submission history analysis\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'name': 'MLP Baseline (Spange + Arrhenius)', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'name': 'LightGBM (Spange + Arrhenius)', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'name': 'Combined Spange + DRFP + Arrhenius', 'cv': 0.0105, 'lb': 0.0972},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "df['cv_lb_ratio'] = df['lb'] / df['cv']\n",
    "print('=== SUBMISSION HISTORY ===')\n",
    "print(df.to_string(index=False))\n",
    "print(f'\\nAverage CV-LB ratio: {df[\"cv_lb_ratio\"].mean():.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "299b2fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:40:34.904133Z",
     "iopub.status.busy": "2026-01-08T07:40:34.903285Z",
     "iopub.status.idle": "2026-01-08T07:40:34.909344Z",
     "shell.execute_reply": "2026-01-08T07:40:34.908639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TARGET ANALYSIS ===\n",
      "Target LB: 0.023\n",
      "Best LB: 0.0972\n",
      "Gap to target: 0.0742 (322.6% above target)\n",
      "Improvement needed: 76.3%\n",
      "\n",
      "=== WHAT CV WOULD WE NEED? ===\n",
      "Using avg ratio (8.9x): CV = 0.00258\n",
      "Current best CV: 0.0105\n",
      "CV improvement needed: 75.4%\n"
     ]
    }
   ],
   "source": [
    "# Target analysis\n",
    "target = 0.023\n",
    "best_lb = 0.0972\n",
    "best_cv = 0.0105\n",
    "avg_ratio = 8.9\n",
    "\n",
    "print('=== TARGET ANALYSIS ===')\n",
    "print(f'Target LB: {target}')\n",
    "print(f'Best LB: {best_lb}')\n",
    "print(f'Gap to target: {best_lb - target:.4f} ({(best_lb - target) / target * 100:.1f}% above target)')\n",
    "print(f'Improvement needed: {(best_lb - target) / best_lb * 100:.1f}%')\n",
    "\n",
    "print('\\n=== WHAT CV WOULD WE NEED? ===')\n",
    "required_cv = target / avg_ratio\n",
    "print(f'Using avg ratio ({avg_ratio}x): CV = {required_cv:.5f}')\n",
    "print(f'Current best CV: {best_cv}')\n",
    "print(f'CV improvement needed: {(best_cv - required_cv) / best_cv * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85d4d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:40:34.912005Z",
     "iopub.status.busy": "2026-01-08T07:40:34.911308Z",
     "iopub.status.idle": "2026-01-08T07:40:34.921106Z",
     "shell.execute_reply": "2026-01-08T07:40:34.920466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPERIMENT HISTORY ===\n",
      "exp_000: Baseline MLP              CV=0.011081 LB=0.0982   [submitted]\n",
      "exp_001: LightGBM                  CV=0.012297 LB=0.1065   [submitted]\n",
      "exp_002: DRFP MLP with PCA         CV=0.016948 LB=N/A      [not submitted]\n",
      "exp_003: Combined Spange+DRFP      CV=0.010501 LB=0.0972   [submitted]\n",
      "exp_004: Deep Residual MLP         CV=0.051912 LB=N/A      [FAILED]\n"
     ]
    }
   ],
   "source": [
    "# Experiment history\n",
    "experiments = [\n",
    "    {'id': 'exp_000', 'name': 'Baseline MLP', 'cv': 0.011081, 'lb': 0.0982, 'status': 'submitted'},\n",
    "    {'id': 'exp_001', 'name': 'LightGBM', 'cv': 0.012297, 'lb': 0.1065, 'status': 'submitted'},\n",
    "    {'id': 'exp_002', 'name': 'DRFP MLP with PCA', 'cv': 0.016948, 'lb': None, 'status': 'not submitted'},\n",
    "    {'id': 'exp_003', 'name': 'Combined Spange+DRFP', 'cv': 0.010501, 'lb': 0.0972, 'status': 'submitted'},\n",
    "    {'id': 'exp_004', 'name': 'Deep Residual MLP', 'cv': 0.051912, 'lb': None, 'status': 'FAILED'},\n",
    "]\n",
    "\n",
    "print('=== EXPERIMENT HISTORY ===')\n",
    "for exp in experiments:\n",
    "    status = exp['status']\n",
    "    lb_str = f\"{exp['lb']:.4f}\" if exp['lb'] else 'N/A'\n",
    "    print(f\"{exp['id']}: {exp['name']:25s} CV={exp['cv']:.6f} LB={lb_str:8s} [{status}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff650b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:40:34.923608Z",
     "iopub.status.busy": "2026-01-08T07:40:34.923032Z",
     "iopub.status.idle": "2026-01-08T07:40:34.931348Z",
     "shell.execute_reply": "2026-01-08T07:40:34.930692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== APPROACHES TRIED ===\n",
      "\n",
      "1. FEATURES:\n",
      "   ✓ Spange descriptors (13 features) - WORKS WELL\n",
      "   ✓ DRFP with PCA (100 components) - WORSE than Spange\n",
      "   ✓ DRFP with variance selection (122 features) - SLIGHT IMPROVEMENT\n",
      "   ✓ Combined Spange + DRFP - BEST SO FAR\n",
      "   ✓ Arrhenius kinetics (1/T, ln(t), interaction) - ESSENTIAL\n",
      "\n",
      "2. MODELS:\n",
      "   ✓ MLP [128, 128, 64] with dropout 0.2 - BASELINE\n",
      "   ✓ MLP [256, 128, 64] with dropout 0.3 - SLIGHTLY BETTER\n",
      "   ✓ LightGBM - WORSE than MLP\n",
      "   ✗ Deep Residual MLP [512, 256, 128, 64] - FAILED BADLY\n",
      "\n",
      "3. TECHNIQUES:\n",
      "   ✓ Data augmentation (flip A/B for mixtures) - ESSENTIAL\n",
      "   ✓ TTA (average both orderings) - ESSENTIAL\n",
      "   ✓ Bagging (3-5 models) - HELPS\n",
      "   ✓ HuberLoss - HELPS\n",
      "   ✓ Gradient clipping - HELPS\n"
     ]
    }
   ],
   "source": [
    "# What approaches have been tried?\n",
    "print('=== APPROACHES TRIED ===')\n",
    "print('\\n1. FEATURES:')\n",
    "print('   ✓ Spange descriptors (13 features) - WORKS WELL')\n",
    "print('   ✓ DRFP with PCA (100 components) - WORSE than Spange')\n",
    "print('   ✓ DRFP with variance selection (122 features) - SLIGHT IMPROVEMENT')\n",
    "print('   ✓ Combined Spange + DRFP - BEST SO FAR')\n",
    "print('   ✓ Arrhenius kinetics (1/T, ln(t), interaction) - ESSENTIAL')\n",
    "\n",
    "print('\\n2. MODELS:')\n",
    "print('   ✓ MLP [128, 128, 64] with dropout 0.2 - BASELINE')\n",
    "print('   ✓ MLP [256, 128, 64] with dropout 0.3 - SLIGHTLY BETTER')\n",
    "print('   ✓ LightGBM - WORSE than MLP')\n",
    "print('   ✗ Deep Residual MLP [512, 256, 128, 64] - FAILED BADLY')\n",
    "\n",
    "print('\\n3. TECHNIQUES:')\n",
    "print('   ✓ Data augmentation (flip A/B for mixtures) - ESSENTIAL')\n",
    "print('   ✓ TTA (average both orderings) - ESSENTIAL')\n",
    "print('   ✓ Bagging (3-5 models) - HELPS')\n",
    "print('   ✓ HuberLoss - HELPS')\n",
    "print('   ✓ Gradient clipping - HELPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f594622f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:40:34.933630Z",
     "iopub.status.busy": "2026-01-08T07:40:34.933116Z",
     "iopub.status.idle": "2026-01-08T07:40:34.940250Z",
     "shell.execute_reply": "2026-01-08T07:40:34.939620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== APPROACHES NOT YET TRIED ===\n",
      "\n",
      "1. FEATURES:\n",
      "   - ACS PCA descriptors (alternative to Spange)\n",
      "   - Fragprints (concatenation of fragments + fingerprints)\n",
      "   - Per-target feature selection\n",
      "   - Polynomial features / interactions\n",
      "\n",
      "2. MODELS:\n",
      "   - Gaussian Processes with domain-specific kernels\n",
      "   - Per-target models (different model for SM vs Products)\n",
      "   - Attention mechanisms (without full GNN)\n",
      "   - Simpler architectures (even smaller networks)\n",
      "\n",
      "3. TECHNIQUES:\n",
      "   - Larger ensembles (10-20 models with SAME architecture)\n",
      "   - Different loss functions (MSE, MAE, quantile)\n",
      "   - Learning rate warmup\n",
      "   - Stochastic Weight Averaging (SWA)\n",
      "   - Snapshot ensembles\n"
     ]
    }
   ],
   "source": [
    "# What hasn't been tried?\n",
    "print('=== APPROACHES NOT YET TRIED ===')\n",
    "print('\\n1. FEATURES:')\n",
    "print('   - ACS PCA descriptors (alternative to Spange)')\n",
    "print('   - Fragprints (concatenation of fragments + fingerprints)')\n",
    "print('   - Per-target feature selection')\n",
    "print('   - Polynomial features / interactions')\n",
    "\n",
    "print('\\n2. MODELS:')\n",
    "print('   - Gaussian Processes with domain-specific kernels')\n",
    "print('   - Per-target models (different model for SM vs Products)')\n",
    "print('   - Attention mechanisms (without full GNN)')\n",
    "print('   - Simpler architectures (even smaller networks)')\n",
    "\n",
    "print('\\n3. TECHNIQUES:')\n",
    "print('   - Larger ensembles (10-20 models with SAME architecture)')\n",
    "print('   - Different loss functions (MSE, MAE, quantile)')\n",
    "print('   - Learning rate warmup')\n",
    "print('   - Stochastic Weight Averaging (SWA)')\n",
    "print('   - Snapshot ensembles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45dcc6d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:40:34.942620Z",
     "iopub.status.busy": "2026-01-08T07:40:34.942128Z",
     "iopub.status.idle": "2026-01-08T07:40:34.949101Z",
     "shell.execute_reply": "2026-01-08T07:40:34.948444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CRITICAL INSIGHT: CV-LB GAP ===\n",
      "\n",
      "The 9x CV-LB gap is the fundamental problem.\n",
      "\n",
      "Possible causes:\n",
      "1. Model variance: Different random seeds on Kaggle produce different results\n",
      "2. Distribution shift: Test solvents have different characteristics\n",
      "3. Overfitting to CV: Model memorizes training patterns that don't generalize\n",
      "\n",
      "Evidence:\n",
      "- LightGBM (deterministic) had WORSE LB than MLP (stochastic)\n",
      "- This suggests the gap is NOT just about variance\n",
      "- The gap may be inherent to the leave-one-solvent-out problem\n",
      "\n",
      "Implication:\n",
      "- Improving local CV may not help much\n",
      "- Need to focus on approaches that generalize better to unseen solvents\n",
      "- Or accept that the target (0.023) may be unrealistic for MLP-based approaches\n"
     ]
    }
   ],
   "source": [
    "# Key insight: The CV-LB gap\n",
    "print('=== CRITICAL INSIGHT: CV-LB GAP ===')\n",
    "print('\\nThe 9x CV-LB gap is the fundamental problem.')\n",
    "print('\\nPossible causes:')\n",
    "print('1. Model variance: Different random seeds on Kaggle produce different results')\n",
    "print('2. Distribution shift: Test solvents have different characteristics')\n",
    "print('3. Overfitting to CV: Model memorizes training patterns that don\\'t generalize')\n",
    "print('\\nEvidence:')\n",
    "print('- LightGBM (deterministic) had WORSE LB than MLP (stochastic)')\n",
    "print('- This suggests the gap is NOT just about variance')\n",
    "print('- The gap may be inherent to the leave-one-solvent-out problem')\n",
    "print('\\nImplication:')\n",
    "print('- Improving local CV may not help much')\n",
    "print('- Need to focus on approaches that generalize better to unseen solvents')\n",
    "print('- Or accept that the target (0.023) may be unrealistic for MLP-based approaches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8c6b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:40:34.951323Z",
     "iopub.status.busy": "2026-01-08T07:40:34.950858Z",
     "iopub.status.idle": "2026-01-08T07:40:34.957648Z",
     "shell.execute_reply": "2026-01-08T07:40:34.956989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GNN BENCHMARK REFERENCE ===\n",
      "\n",
      "The GNN benchmark (arXiv 2512.19530) achieved MSE 0.0039\n",
      "\n",
      "Key differences from our approach:\n",
      "1. Used Graph Attention Networks with molecular graph message-passing\n",
      "2. DRFP features 2048-dim (we use 122 high-variance)\n",
      "3. Mixture-aware continuous solvent representation\n",
      "4. Transfer learning from larger chemical datasets\n",
      "\n",
      "What this tells us:\n",
      "- The problem IS solvable with much better accuracy\n",
      "- But requires fundamentally different architecture (GNN)\n",
      "- Simple MLP may have a ceiling around 0.01 CV / 0.09 LB\n"
     ]
    }
   ],
   "source": [
    "# What the GNN benchmark achieved\n",
    "print('=== GNN BENCHMARK REFERENCE ===')\n",
    "print('\\nThe GNN benchmark (arXiv 2512.19530) achieved MSE 0.0039')\n",
    "print('\\nKey differences from our approach:')\n",
    "print('1. Used Graph Attention Networks with molecular graph message-passing')\n",
    "print('2. DRFP features 2048-dim (we use 122 high-variance)')\n",
    "print('3. Mixture-aware continuous solvent representation')\n",
    "print('4. Transfer learning from larger chemical datasets')\n",
    "print('\\nWhat this tells us:')\n",
    "print('- The problem IS solvable with much better accuracy')\n",
    "print('- But requires fundamentally different architecture (GNN)')\n",
    "print('- Simple MLP may have a ceiling around 0.01 CV / 0.09 LB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccaa4e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:40:34.959945Z",
     "iopub.status.busy": "2026-01-08T07:40:34.959321Z",
     "iopub.status.idle": "2026-01-08T07:40:34.966346Z",
     "shell.execute_reply": "2026-01-08T07:40:34.965684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STRATEGIC OPTIONS ===\n",
      "\n",
      "Option A: Continue with MLP improvements\n",
      "  - Try larger ensembles (10-20 models)\n",
      "  - Try per-target models\n",
      "  - Try different feature combinations\n",
      "  - Expected improvement: 5-10% (still far from target)\n",
      "\n",
      "Option B: Implement simplified GNN/attention\n",
      "  - Add attention layer to MLP\n",
      "  - Use graph-based features\n",
      "  - Risk: May not fit competition template\n",
      "  - Expected improvement: Unknown, high variance\n",
      "\n",
      "Option C: Focus on variance reduction\n",
      "  - Larger ensembles with same architecture\n",
      "  - Multiple random seeds, average predictions\n",
      "  - Snapshot ensembles\n",
      "  - Expected improvement: May reduce CV-LB gap\n",
      "\n",
      "Option D: Accept current best and optimize submission\n",
      "  - Our best LB (0.0972) is already competitive\n",
      "  - Focus on ensuring reproducibility\n",
      "  - Risk: May not beat target\n"
     ]
    }
   ],
   "source": [
    "# Strategic options\n",
    "print('=== STRATEGIC OPTIONS ===')\n",
    "print('\\nOption A: Continue with MLP improvements')\n",
    "print('  - Try larger ensembles (10-20 models)')\n",
    "print('  - Try per-target models')\n",
    "print('  - Try different feature combinations')\n",
    "print('  - Expected improvement: 5-10% (still far from target)')\n",
    "\n",
    "print('\\nOption B: Implement simplified GNN/attention')\n",
    "print('  - Add attention layer to MLP')\n",
    "print('  - Use graph-based features')\n",
    "print('  - Risk: May not fit competition template')\n",
    "print('  - Expected improvement: Unknown, high variance')\n",
    "\n",
    "print('\\nOption C: Focus on variance reduction')\n",
    "print('  - Larger ensembles with same architecture')\n",
    "print('  - Multiple random seeds, average predictions')\n",
    "print('  - Snapshot ensembles')\n",
    "print('  - Expected improvement: May reduce CV-LB gap')\n",
    "\n",
    "print('\\nOption D: Accept current best and optimize submission')\n",
    "print('  - Our best LB (0.0972) is already competitive')\n",
    "print('  - Focus on ensuring reproducibility')\n",
    "print('  - Risk: May not beat target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fcc5cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:40:34.968961Z",
     "iopub.status.busy": "2026-01-08T07:40:34.968235Z",
     "iopub.status.idle": "2026-01-08T07:40:34.976181Z",
     "shell.execute_reply": "2026-01-08T07:40:34.975533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RECOMMENDATION ===\n",
      "\n",
      "Given the evaluator feedback and experiment results:\n",
      "\n",
      "1. ABANDON deep/complex architectures - they hurt, not help\n",
      "\n",
      "2. RETURN to the best working approach (exp_003):\n",
      "   - Combined Spange + DRFP + Arrhenius features\n",
      "   - Simple MLP [256, 128, 64]\n",
      "   - 5 models bagged\n",
      "\n",
      "3. TRY variance reduction:\n",
      "   - Increase ensemble size to 10-15 models (same architecture)\n",
      "   - Use more epochs (300-400)\n",
      "   - This may reduce CV-LB gap\n",
      "\n",
      "4. TRY per-target models:\n",
      "   - Different models for SM vs Product 2 vs Product 3\n",
      "   - May capture different patterns\n",
      "\n",
      "5. CONSIDER alternative features:\n",
      "   - ACS PCA descriptors (mentioned in competition data)\n",
      "   - Weighted combination of Spange + ACS\n",
      "\n",
      "6. SUBMIT to validate:\n",
      "   - With 2 submissions remaining, use one to test variance reduction\n",
      "   - Save one for final best model\n"
     ]
    }
   ],
   "source": [
    "# Recommendation\n",
    "print('=== RECOMMENDATION ===')\n",
    "print('\\nGiven the evaluator feedback and experiment results:')\n",
    "print('\\n1. ABANDON deep/complex architectures - they hurt, not help')\n",
    "print('\\n2. RETURN to the best working approach (exp_003):')\n",
    "print('   - Combined Spange + DRFP + Arrhenius features')\n",
    "print('   - Simple MLP [256, 128, 64]')\n",
    "print('   - 5 models bagged')\n",
    "print('\\n3. TRY variance reduction:')\n",
    "print('   - Increase ensemble size to 10-15 models (same architecture)')\n",
    "print('   - Use more epochs (300-400)')\n",
    "print('   - This may reduce CV-LB gap')\n",
    "print('\\n4. TRY per-target models:')\n",
    "print('   - Different models for SM vs Product 2 vs Product 3')\n",
    "print('   - May capture different patterns')\n",
    "print('\\n5. CONSIDER alternative features:')\n",
    "print('   - ACS PCA descriptors (mentioned in competition data)')\n",
    "print('   - Weighted combination of Spange + ACS')\n",
    "print('\\n6. SUBMIT to validate:')\n",
    "print('   - With 2 submissions remaining, use one to test variance reduction')\n",
    "print('   - Save one for final best model')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
