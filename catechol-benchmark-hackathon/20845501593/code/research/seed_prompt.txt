## Current Status
- Best CV score: 0.009004 from exp_012 (MLP[32,16] + LightGBM ensemble)
- Best LB score: 0.0913 from exp_012
- CV-LB gap: ~10x (LB = 4.05*CV + 0.0551, R²=0.95)
- Target: 0.0333
- Submissions remaining: 4

## Response to Evaluator

**Technical verdict was TRUSTWORTHY** for completed experiments. The evaluator correctly noted that exp_017 (attention model) was NOT EXECUTED.

**Evaluator's top priority**: Execute the attention notebook or abandon and accept exp_012.

**My decision: TRY ONE MORE APPROACH before accepting exp_012.**

Reasoning:
1. **Mathematical analysis is compelling but not definitive**: The linear fit is based on only 8 data points from similar tabular approaches. A fundamentally different approach might break this pattern.

2. **Unexplored features exist**: We have `fragprints_lookup.csv` with 2133 fragment fingerprint features that we haven't tried. These capture different structural information than DRFP.

3. **Per-target models haven't been tried**: The competition explicitly allows different hyperparameters for different objectives. Product 2, Product 3, and SM might have different optimal architectures.

4. **Never give up principle**: The target IS attainable. We should exhaust all reasonable approaches before accepting defeat.

## Data Understanding

Reference notebooks:
- `exploration/evolver_loop19_analysis.ipynb`: Final assessment, CV-LB analysis, benchmark context
- `experiments/012_simple_ensemble/simple_ensemble.ipynb`: Best submission (LB 0.0913)

Available features NOT yet tried:
- **fragprints_lookup.csv**: 2133 fragment fingerprint features (vs 122 DRFP features we used)
- **acs_pca_descriptors_lookup.csv**: 5 PCA-reduced ACS descriptors

Key patterns from analysis:
1. **CV-LB correlation is strong (R²=0.95)** but with 10x gap
2. **[32,16] MLP is optimal** - simpler than [64,32] or [128,128,64]
3. **MLP + LightGBM ensemble (0.6/0.4)** provides best generalization
4. **Combined features (Spange + DRFP + Arrhenius)** outperform single feature sets

## Benchmark Context (arXiv paper 2512.19530)

| Method | MSE | Notes |
|--------|-----|-------|
| GBDT baseline | 0.099 | Paper's tabular baseline |
| **Our best (exp_012)** | **0.0913** | **7.8% better than GBDT** |
| Target | 0.0333 | 69% of way from GBDT to GNN |
| GNN (GAT + DRFP) | 0.0039 | Best possible (graph-based) |

## Recommended Approaches

**PRIORITY 1: Try Fragprints Features (HIGH POTENTIAL)**

The fragprints_lookup.csv contains 2133 fragment fingerprint features that we haven't tried. These capture different structural information than DRFP:
- DRFP: Differential Reaction Fingerprints (reaction-level)
- Fragprints: Fragment-based fingerprints (substructure-level)

Experiment:
1. Load fragprints features (2133 dim)
2. Apply variance-based feature selection (like we did with DRFP)
3. Combine with Spange + Arrhenius kinetics
4. Train MLP[32,16] + LightGBM ensemble
5. Compare CV to exp_012 (0.009004)

**PRIORITY 2: Per-Target Models (MEDIUM POTENTIAL)**

The competition explicitly allows different hyperparameters for different objectives. Try:
1. Train separate models for Product 2, Product 3, SM
2. Each target might have different optimal architecture
3. Combine predictions

**PRIORITY 3: Execute Attention Model (LOW POTENTIAL, CLOSES LOOSE END)**

The attention model (exp_017) is set up but not executed. Run it to close this loose end:
- If CV improves by >10% (CV < 0.0081), consider submitting
- Expected outcome: CV similar to or worse than exp_012

## What NOT to Try

1. **More ensemble variations** - Diminishing returns (3-model was worse than 2-model)
2. **Deeper architectures** - Already proven worse (exp_004 failed with deep residual)
3. **More hyperparameter tuning** - Weight optimization showed 0.07% difference (noise)
4. **PCA on features** - Already proven worse than variance-based selection

## Validation Notes

- CV scheme: Leave-one-solvent-out (24 folds) + Leave-one-ramp-out (13 folds)
- CV-LB relationship: LB = 4.05*CV + 0.0551 (R²=0.95)
- The 10x CV-LB gap is fundamental to leave-one-out generalization

## Submission Strategy

**Threshold for submission**: Only submit if CV improves by >10% (CV < 0.0081)

If no improvement after trying fragprints and per-target models:
- Accept exp_012 (LB 0.0913) as the final result
- This represents 7.8% improvement over paper's GBDT baseline

## Template Compliance

CRITICAL: All experiments must follow the competition template structure:
- Last 3 cells must match template exactly
- Only the model definition line can change
- Use the provided CV evaluation framework

## Key Achievement Summary

| Metric | Value | Context |
|--------|-------|---------|
| Our Best LB | 0.0913 | exp_012 |
| Paper GBDT | 0.099 | Baseline |
| Improvement | 7.8% | Over baseline |
| Paper GNN | 0.0039 | Best possible |
| Target | 0.0333 | Likely requires GNN |

## Final Note

The mathematical analysis suggests the target is unreachable with tabular ML. However, we should try the unexplored approaches (fragprints, per-target models) before accepting this conclusion. If these don't help, we have achieved the best possible tabular ML result (7.8% better than baseline), which is a significant achievement.
