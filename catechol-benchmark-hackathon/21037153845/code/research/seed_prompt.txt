## Current Status
- Best CV score: 0.007944 from exp_067 (Data-Type-Specific Features)
- Best LB score: 0.0877 from exp_030
- Target: 0.0347 | Gap to target: 0.0530 (60.5% reduction needed)

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.23 × CV + 0.0533 (R² = 0.98)
- Intercept interpretation: Even at CV=0, expected LB is 0.0533
- **CRITICAL**: Intercept (0.0533) > Target (0.0347)
- Required CV to hit target: NEGATIVE (mathematically impossible)
- **All 67 experiments fall on the same CV-LB line**
- **We MUST change the CV-LB relationship, not just improve CV**

## Response to Evaluator
- Technical verdict was TRUSTWORTHY. The implementation is correct.
- Evaluator's top priority: Implement the "Ens Model" kernel approach. **AGREED - this is the most promising path.**
- Key concerns raised:
  1. CV-LB intercept problem remains unsolved - **CRITICAL, must address**
  2. Only 5 submissions remaining - **Must be strategic**
  3. Multi-target normalization not implemented - **Will implement**
- Evaluator correctly identified that we need to try CatBoost + XGBoost ensemble with multi-target normalization.

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop63_analysis.ipynb` for CV-LB analysis
- Key patterns:
  1. Fragprints help single solvent (5.7% improvement) but hurt mixtures (2.4x worse)
  2. Data-type-specific features work (CV 0.007944 vs 0.008194)
  3. All model types (MLP, LGBM, XGB, GP) fall on the same CV-LB line
  4. The intercept (0.0533) represents EXTRAPOLATION ERROR that no model tuning can fix

## Recommended Approaches (PRIORITY ORDER)

### 1. IMPLEMENT ENS MODEL KERNEL APPROACH (HIGHEST PRIORITY)
The "Ens Model" kernel (matthewmaree) uses techniques we have NOT tried:

**a) CatBoost + XGBoost Ensemble** (instead of GP + MLP + LGBM)
```python
# CatBoost params for single solvent:
cat_params = dict(
    loss_function="MultiRMSE",
    depth=3, learning_rate=0.07, n_estimators=1050,
    l2_leaf_reg=3.5, bootstrap_type="Bayesian",
    bagging_temperature=0.225, rsm=0.75
)

# XGBoost params for single solvent:
xgb_params = dict(
    objective="reg:squarederror", tree_method="hist",
    subsample=0.5, reg_lambda=0.6, n_estimators=1000,
    max_depth=4, learning_rate=0.02, colsample_bytree=0.3
)
```

**b) Different Ensemble Weights for Single vs Full**
```python
if data == "single":
    cat_weight = 7.0 / 13.0  # 0.538
    xgb_weight = 6.0 / 13.0  # 0.462
else:
    cat_weight = 1.0 / 3.0   # 0.333
    xgb_weight = 2.0 / 3.0   # 0.667
```

**c) Feature Priority-Based Correlation Filtering**
```python
def feature_priority(name):
    if name.startswith("spange_"): return 5
    if name.startswith("acs_"): return 4
    if name.startswith("drfps_"): return 3
    if name.startswith("frag_"): return 2
    return 0

# When two features are correlated (>0.8), keep the higher-priority one
```

**d) Multi-Target Normalization**
```python
out = np.clip(out, a_min=0.0, a_max=None)
totals = out.sum(axis=1, keepdims=True)
divisor = np.maximum(totals, 1.0)
out = out / divisor
```

**Why this might work**: Different model types (CatBoost, XGBoost) may have different extrapolation behavior than GP + MLP + LGBM. The multi-target normalization ensures physical constraints are met, which may reduce extrapolation errors.

### 2. ADD MULTI-TARGET NORMALIZATION TO CURRENT BEST MODEL
If CatBoost + XGBoost doesn't work, add multi-target normalization to our best GP + MLP + LGBM ensemble:
```python
# After ensemble prediction:
out = np.clip(out, a_min=0.0, a_max=None)
totals = out.sum(axis=1, keepdims=True)
divisor = np.maximum(totals, 1.0)
out = out / divisor
```

### 3. SUBMIT NEW BEST CV (0.007944) FOR CALIBRATION
- Predicted LB: 0.0869 (vs best LB 0.0877)
- This will verify if the CV-LB relationship still holds
- If LB is significantly different from predicted, we may have found a way to change the relationship

## What NOT to Try
- More MLP/LGBM/GP variations - all fall on the same CV-LB line
- Hyperparameter tuning - doesn't change the intercept
- GNN approaches - exp_051 and exp_056 both failed (CV 0.014 and 0.030)
- GroupKFold CV - exp_042 showed worse LB (0.1147)

## Validation Notes
- Use Leave-One-Solvent-Out CV for single solvent (24 folds)
- Use Leave-One-Ramp-Out CV for full data (87 folds) - this is the correct methodology
- The CV-LB relationship is LB = 4.23*CV + 0.0533 (R² = 0.98)
- Any new approach should be evaluated for whether it changes this relationship

## CRITICAL REMINDER
- 5 submissions remaining
- Target (0.0347) is UNREACHABLE with current CV-LB relationship
- We MUST try something that changes the relationship
- The Ens Model kernel approach is the most promising path
- If CatBoost + XGBoost doesn't work, try multi-target normalization on current best
- Consider submitting new best CV (0.007944) to verify relationship

## Competition Constraints
- Must follow the notebook template structure
- The line `model = MLPModel()` can be replaced with a new model definition
- Same hyperparameters must be used across every fold
- Different hyperparameters for different tasks (single vs full) is allowed
