{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf07a847",
   "metadata": {},
   "source": [
    "# Loop 60 Analysis: CV-LB Relationship and Next Steps\n",
    "\n",
    "**Goal**: Analyze the CV-LB relationship and identify approaches that might CHANGE the relationship, not just improve CV.\n",
    "\n",
    "**Key Insight from exp_062 (Bias Correction)**:\n",
    "- Bias correction FAILED because the bias is NOT uniform across targets\n",
    "- Product 2: predictions are 0.009 LOWER than actuals (negative bias)\n",
    "- Product 3: predictions are 0.003 LOWER than actuals (negative bias)\n",
    "- SM: predictions are 0.021 HIGHER than actuals (positive bias)\n",
    "- Subtracting a constant hurts some targets while helping others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec66ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# CV-LB data from 13 submissions\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.011081, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.012297, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.010501, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.01043, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.009749, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.009262, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.009192, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.009004, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.008689, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.008465, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.008298, 'lb': 0.0877},\n",
    "    {'exp': 'exp_041', 'cv': 0.009002, 'lb': 0.0932},\n",
    "    {'exp': 'exp_042', 'cv': 0.014503, 'lb': 0.1147},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f'Total submissions: {len(df)}')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression: LB = slope * CV + intercept\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "\n",
    "print(f'\\n=== CV-LB Linear Regression ===')\n",
    "print(f'LB = {slope:.4f} * CV + {intercept:.4f}')\n",
    "print(f'R-squared: {r_value**2:.4f}')\n",
    "print(f'Intercept: {intercept:.4f}')\n",
    "print(f'\\nTarget LB: 0.0347')\n",
    "print(f'Intercept > Target: {intercept > 0.0347}')\n",
    "\n",
    "# Required CV to hit target\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f'\\nRequired CV to hit target: {required_cv:.6f}')\n",
    "print(f'This is IMPOSSIBLE (negative CV)' if required_cv < 0 else f'This requires CV = {required_cv:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a94b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV vs LB\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['cv'], df['lb'], s=100, c='blue', alpha=0.7, label='Submissions')\n",
    "\n",
    "# Regression line\n",
    "cv_range = np.linspace(0, 0.02, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.2f})')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Intercept line\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', linewidth=2, label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score (MSE)')\n",
    "plt.ylabel('LB Score (MSE)')\n",
    "plt.title('CV vs LB Relationship - All 13 Submissions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nKey Insight: The intercept ({intercept:.4f}) is ABOVE the target (0.0347).')\n",
    "print(f'This means even with perfect CV (CV=0), we would still get LB = {intercept:.4f}.')\n",
    "print(f'The target is MATHEMATICALLY UNREACHABLE with the current paradigm.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze residuals - are there any outliers?\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "\n",
    "print('=== Residual Analysis ===')\n",
    "print(df[['exp', 'cv', 'lb', 'predicted_lb', 'residual']].to_string())\n",
    "\n",
    "print(f'\\nMean residual: {df[\"residual\"].mean():.6f}')\n",
    "print(f'Std residual: {df[\"residual\"].std():.6f}')\n",
    "print(f'Max residual: {df[\"residual\"].max():.6f} ({df.loc[df[\"residual\"].idxmax(), \"exp\"]})')\n",
    "print(f'Min residual: {df[\"residual\"].min():.6f} ({df.loc[df[\"residual\"].idxmin(), \"exp\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc733367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would it take to reach the target?\n",
    "print('\\n=== What Would It Take to Reach Target? ===')\n",
    "print(f'Target LB: 0.0347')\n",
    "print(f'Current intercept: {intercept:.4f}')\n",
    "print(f'Gap: {intercept - 0.0347:.4f}')\n",
    "\n",
    "print(f'\\nOption 1: Reduce intercept by {intercept - 0.0347:.4f}')\n",
    "print(f'  - This requires changing the CV-LB RELATIONSHIP, not just improving CV')\n",
    "print(f'  - Approaches: Extrapolation detection, uncertainty weighting, domain constraints')\n",
    "\n",
    "print(f'\\nOption 2: Achieve CV = {required_cv:.6f}')\n",
    "print(f'  - This is IMPOSSIBLE (negative CV)')\n",
    "\n",
    "print(f'\\nOption 3: Find an approach that has a DIFFERENT CV-LB relationship')\n",
    "print(f'  - The \"mixall\" kernel uses GroupKFold (5 splits) - we tried this (exp_042) and it was WORSE')\n",
    "print(f'  - The \"Ens Model\" kernel uses CatBoost + XGBoost - we tried CatBoost (exp_045) and it was WORSE')\n",
    "print(f'  - Need to find something fundamentally different')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff084b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('\\n=== Approaches NOT Yet Tried ===')\n",
    "print('\\n1. TARGET-SPECIFIC BIAS CORRECTION')\n",
    "print('   - exp_062 showed bias is NOT uniform across targets:')\n",
    "print('     - Product 2: -0.009 (predictions too low)')\n",
    "print('     - Product 3: -0.003 (predictions too low)')\n",
    "print('     - SM: +0.021 (predictions too high)')\n",
    "print('   - Instead of subtracting a constant from ALL predictions,')\n",
    "print('     ADD to Product 2 and Product 3, SUBTRACT from SM')\n",
    "\n",
    "print('\\n2. ENSEMBLE VARIANCE AS UNCERTAINTY')\n",
    "print('   - exp_058 used GP uncertainty, which is uniformly HIGH')\n",
    "print('   - Instead, use variance across ensemble members')\n",
    "print('   - When variance is high, blend toward population mean')\n",
    "\n",
    "print('\\n3. SOLVENT CLUSTERING + CLASS-SPECIFIC MODELS')\n",
    "print('   - exp_052 tried per-solvent-type models and FAILED')\n",
    "print('   - But we could try CLUSTERING solvents by chemical similarity')\n",
    "print('   - Then use cluster-specific calibration')\n",
    "\n",
    "print('\\n4. PSEUDO-LABELING / SELF-TRAINING')\n",
    "print('   - Use confident predictions on test data to augment training')\n",
    "print('   - This could help with distribution shift')\n",
    "\n",
    "print('\\n5. DIFFERENT VALIDATION SCHEME')\n",
    "print('   - The server might use a different CV scheme than Leave-One-Solvent-Out')\n",
    "print('   - We tried GroupKFold (exp_042) and it was WORSE')\n",
    "print('   - But maybe the server uses something else entirely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f3ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the best experiments\n",
    "print('\\n=== Best Experiments Analysis ===')\n",
    "best_cv = df.loc[df['cv'].idxmin()]\n",
    "best_lb = df.loc[df['lb'].idxmin()]\n",
    "\n",
    "print(f'Best CV: {best_cv[\"exp\"]} with CV={best_cv[\"cv\"]:.6f}, LB={best_cv[\"lb\"]:.4f}')\n",
    "print(f'Best LB: {best_lb[\"exp\"]} with CV={best_lb[\"cv\"]:.6f}, LB={best_lb[\"lb\"]:.4f}')\n",
    "\n",
    "print(f'\\nBest CV (exp_030) predicted LB: {slope * 0.008298 + intercept:.4f}')\n",
    "print(f'Actual LB: 0.0877')\n",
    "print(f'Difference: {0.0877 - (slope * 0.008298 + intercept):.4f}')\n",
    "\n",
    "print(f'\\nexp_030 is BELOW the regression line (better than expected)')\n",
    "print(f'This suggests exp_030 has some property that reduces the intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was special about exp_030?\n",
    "print('\\n=== What Was Special About exp_030? ===')\n",
    "print('exp_030 was the GP + MLP + LGBM ensemble with weights (0.15, 0.55, 0.30)')\n",
    "print('It achieved the best LB (0.0877) with CV 0.008298')\n",
    "print('')\n",
    "print('Key features:')\n",
    "print('1. GP provides uncertainty estimates (but we found these are uniformly high)')\n",
    "print('2. MLP captures non-linear patterns')\n",
    "print('3. LGBM provides robustness')\n",
    "print('4. Ensemble averaging reduces variance')\n",
    "print('')\n",
    "print('The ensemble approach seems to be the best we have.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what improvement is needed\n",
    "print('\\n=== Required Improvement ===')\n",
    "current_best_lb = 0.0877\n",
    "target_lb = 0.0347\n",
    "gap = current_best_lb - target_lb\n",
    "pct_improvement = gap / current_best_lb * 100\n",
    "\n",
    "print(f'Current best LB: {current_best_lb}')\n",
    "print(f'Target LB: {target_lb}')\n",
    "print(f'Gap: {gap:.4f}')\n",
    "print(f'Required improvement: {pct_improvement:.1f}%')\n",
    "\n",
    "print(f'\\nThis is a MASSIVE gap. We need to reduce LB by 60%.')\n",
    "print(f'No amount of CV optimization can achieve this.')\n",
    "print(f'We need a fundamentally different approach.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print('\\n' + '='*60)\n",
    "print('SUMMARY: LOOP 60 ANALYSIS')\n",
    "print('='*60)\n",
    "print(f'\\n1. CV-LB Relationship: LB = {slope:.2f} * CV + {intercept:.4f} (R²={r_value**2:.2f})')\n",
    "print(f'2. Intercept ({intercept:.4f}) > Target (0.0347) - IMPOSSIBLE to reach target by improving CV')\n",
    "print(f'3. Best LB: 0.0877 (exp_030) - 152.7% above target')\n",
    "print(f'4. Best CV: 0.008194 (exp_032) - but this doesn\\'t translate to better LB')\n",
    "print(f'\\nKEY INSIGHT: The target IS reachable (someone achieved it).')\n",
    "print(f'But not with our current paradigm.')\n",
    "print(f'\\nWe need to find an approach that CHANGES the CV-LB relationship,')\n",
    "print(f'not just improves CV.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
