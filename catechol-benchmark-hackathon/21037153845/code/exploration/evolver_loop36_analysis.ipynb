{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15d54307",
   "metadata": {},
   "source": [
    "# Loop 36 Analysis: Critical Assessment\n",
    "\n",
    "**Current State:**\n",
    "- Best CV: 0.008194 (exp_032: GP 0.15 + MLP 0.55 + LGBM 0.3)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347\n",
    "- Gap to target: 2.53x\n",
    "- Submissions remaining: 5\n",
    "\n",
    "**Latest experiments (exp_037 & exp_038):**\n",
    "- Both similarity weighting experiments failed with IDENTICAL CV (0.022076)\n",
    "- This is 169% WORSE than baseline\n",
    "- The identical results suggest a bug in the implementation\n",
    "\n",
    "**Key Question:** What's causing the failure and what should we try next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7bcfcaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:44:06.805195Z",
     "iopub.status.busy": "2026-01-14T23:44:06.804600Z",
     "iopub.status.idle": "2026-01-14T23:44:07.584439Z",
     "shell.execute_reply": "2026-01-14T23:44:07.584020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Submission History ===\n",
      "        exp      cv      lb\n",
      "0   exp_000  0.0111  0.0982\n",
      "1   exp_001  0.0123  0.1065\n",
      "2   exp_003  0.0105  0.0972\n",
      "3   exp_005  0.0104  0.0969\n",
      "4   exp_006  0.0097  0.0946\n",
      "5   exp_007  0.0093  0.0932\n",
      "6   exp_009  0.0092  0.0936\n",
      "7   exp_012  0.0090  0.0913\n",
      "8   exp_024  0.0087  0.0893\n",
      "9   exp_026  0.0085  0.0887\n",
      "10  exp_030  0.0083  0.0877\n",
      "\n",
      "CV-LB Ratio: 9.69x\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Complete submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('=== Submission History ===')\n",
    "print(df)\n",
    "print(f'\\nCV-LB Ratio: {df[\"lb\"].mean() / df[\"cv\"].mean():.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c12748ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:44:07.585630Z",
     "iopub.status.busy": "2026-01-14T23:44:07.585457Z",
     "iopub.status.idle": "2026-01-14T23:44:07.590275Z",
     "shell.execute_reply": "2026-01-14T23:44:07.589902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear fit: LB = 4.30 * CV + 0.0524\n",
      "R² = 0.9675\n",
      "\n",
      "Intercept: 0.0524\n",
      "Target LB: 0.0347\n",
      "\n",
      "Predicted LB for exp_032 (CV=0.008194): 0.0877\n",
      "\n",
      "To reach target LB = 0.0347:\n",
      "  Required CV = (0.0347 - 0.0524) / 4.30 = -0.004118\n",
      "\n",
      "⚠️ With current CV-LB relationship, target is unreachable!\n",
      "The intercept alone (0.0524) is 1.51x higher than target (0.0347)\n",
      "\n",
      "BUT: This means we need to CHANGE the relationship, not just improve CV!\n"
     ]
    }
   ],
   "source": [
    "# Linear regression to understand CV-LB relationship\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f'Linear fit: LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nIntercept: {intercept:.4f}')\n",
    "print(f'Target LB: 0.0347')\n",
    "\n",
    "# Predict LB for our best CV models\n",
    "best_cv = 0.008194  # exp_032\n",
    "predicted_lb = slope * best_cv + intercept\n",
    "print(f'\\nPredicted LB for exp_032 (CV={best_cv}): {predicted_lb:.4f}')\n",
    "\n",
    "# What CV would we need to hit target?\n",
    "target_lb = 0.0347\n",
    "required_cv = (target_lb - intercept) / slope\n",
    "print(f'\\nTo reach target LB = {target_lb}:')\n",
    "print(f'  Required CV = ({target_lb} - {intercept:.4f}) / {slope:.2f} = {required_cv:.6f}')\n",
    "\n",
    "if required_cv < 0:\n",
    "    print('\\n⚠️ With current CV-LB relationship, target is unreachable!')\n",
    "    print(f'The intercept alone ({intercept:.4f}) is {intercept/target_lb:.2f}x higher than target ({target_lb})')\n",
    "    print('\\nBUT: This means we need to CHANGE the relationship, not just improve CV!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ea88c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:44:07.591161Z",
     "iopub.status.busy": "2026-01-14T23:44:07.591028Z",
     "iopub.status.idle": "2026-01-14T23:44:07.595587Z",
     "shell.execute_reply": "2026-01-14T23:44:07.595249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SIMILARITY WEIGHTING FAILURE ANALYSIS ===\n",
      "\n",
      "exp_037 (Similarity Weighting): CV 0.022076\n",
      "exp_038 (Inverse Similarity Weighting): CV 0.022076\n",
      "\n",
      "IDENTICAL RESULTS! This is highly suspicious.\n",
      "\n",
      "Evaluator identified the bug:\n",
      "  - Baseline uses WeightedHuberLoss with target weights [1.0, 1.0, 2.0]\n",
      "  - Similarity experiments dropped target weighting entirely!\n",
      "  - Loss computation was different:\n",
      "    Baseline: loss_fn(pred, y_batch) with target weights\n",
      "    Similarity: huber(pred, y_batch).mean(dim=1) * sample_weights\n",
      "\n",
      "The missing target weighting caused the degradation, NOT the sample weighting!\n"
     ]
    }
   ],
   "source": [
    "# Analyze the similarity weighting failure\n",
    "print('=== SIMILARITY WEIGHTING FAILURE ANALYSIS ===')\n",
    "print()\n",
    "print('exp_037 (Similarity Weighting): CV 0.022076')\n",
    "print('exp_038 (Inverse Similarity Weighting): CV 0.022076')\n",
    "print()\n",
    "print('IDENTICAL RESULTS! This is highly suspicious.')\n",
    "print()\n",
    "print('Evaluator identified the bug:')\n",
    "print('  - Baseline uses WeightedHuberLoss with target weights [1.0, 1.0, 2.0]')\n",
    "print('  - Similarity experiments dropped target weighting entirely!')\n",
    "print('  - Loss computation was different:')\n",
    "print('    Baseline: loss_fn(pred, y_batch) with target weights')\n",
    "print('    Similarity: huber(pred, y_batch).mean(dim=1) * sample_weights')\n",
    "print()\n",
    "print('The missing target weighting caused the degradation, NOT the sample weighting!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4145ec3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:44:07.596550Z",
     "iopub.status.busy": "2026-01-14T23:44:07.596463Z",
     "iopub.status.idle": "2026-01-14T23:44:07.599899Z",
     "shell.execute_reply": "2026-01-14T23:44:07.599531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNEXPLORED APPROACHES ===\n",
      "\n",
      "1. AGGRESSIVE FEATURE SELECTION\n",
      "   - Current: 145 features for 656 samples (24 solvents)\n",
      "   - Try: Top 20-30 features by importance\n",
      "   - Rationale: Fewer features = less overfitting to training solvents\n",
      "\n",
      "2. SIMPLER MODEL ARCHITECTURE\n",
      "   - Current: [32, 16] MLP\n",
      "   - Try: Linear model or [16] single layer\n",
      "   - Rationale: Simpler models generalize better\n",
      "\n",
      "3. STRONGER REGULARIZATION\n",
      "   - Current: weight_decay=1e-4\n",
      "   - Try: weight_decay=1e-2 or 1e-3\n",
      "   - Rationale: Prevent memorization of training solvents\n",
      "\n",
      "4. FIX THE SIMILARITY WEIGHTING BUG\n",
      "   - Apply sample weights WHILE keeping target weights [1.0, 1.0, 2.0]\n",
      "   - Apply to LGBM (which handles sample weights natively)\n",
      "\n",
      "5. DIFFERENT ENSEMBLE STRATEGY\n",
      "   - Try: Stacking with meta-learner instead of weighted average\n",
      "   - Try: Model selection per solvent type\n"
     ]
    }
   ],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('=== UNEXPLORED APPROACHES ===')\n",
    "print()\n",
    "print('1. AGGRESSIVE FEATURE SELECTION')\n",
    "print('   - Current: 145 features for 656 samples (24 solvents)')\n",
    "print('   - Try: Top 20-30 features by importance')\n",
    "print('   - Rationale: Fewer features = less overfitting to training solvents')\n",
    "print()\n",
    "print('2. SIMPLER MODEL ARCHITECTURE')\n",
    "print('   - Current: [32, 16] MLP')\n",
    "print('   - Try: Linear model or [16] single layer')\n",
    "print('   - Rationale: Simpler models generalize better')\n",
    "print()\n",
    "print('3. STRONGER REGULARIZATION')\n",
    "print('   - Current: weight_decay=1e-4')\n",
    "print('   - Try: weight_decay=1e-2 or 1e-3')\n",
    "print('   - Rationale: Prevent memorization of training solvents')\n",
    "print()\n",
    "print('4. FIX THE SIMILARITY WEIGHTING BUG')\n",
    "print('   - Apply sample weights WHILE keeping target weights [1.0, 1.0, 2.0]')\n",
    "print('   - Apply to LGBM (which handles sample weights natively)')\n",
    "print()\n",
    "print('5. DIFFERENT ENSEMBLE STRATEGY')\n",
    "print('   - Try: Stacking with meta-learner instead of weighted average')\n",
    "print('   - Try: Model selection per solvent type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a00112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:44:07.600771Z",
     "iopub.status.busy": "2026-01-14T23:44:07.600674Z",
     "iopub.status.idle": "2026-01-14T23:44:07.603753Z",
     "shell.execute_reply": "2026-01-14T23:44:07.603435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KEY INSIGHT: THE INTERCEPT IS THE PROBLEM ===\n",
      "\n",
      "Current CV-LB relationship: LB = 4.30 * CV + 0.0524\n",
      "Intercept (0.0524) > Target (0.0347)\n",
      "\n",
      "This means:\n",
      "  - Even with CV = 0, predicted LB would be 0.0527\n",
      "  - The intercept represents systematic generalization error\n",
      "  - We need approaches that REDUCE THE INTERCEPT\n",
      "\n",
      "What could reduce the intercept?\n",
      "  1. Simpler models (fewer parameters to overfit)\n",
      "  2. Fewer features (less opportunity to memorize)\n",
      "  3. Stronger regularization (prevent memorization)\n",
      "  4. Domain adaptation (learn solvent-invariant features)\n",
      "\n",
      "If we can reduce intercept from 0.0527 to ~0.02:\n",
      "  With CV = 0.008194, predicted LB = 4.30 * 0.008194 + 0.02 = 0.0553\n",
      "  This would be close to target!\n"
     ]
    }
   ],
   "source": [
    "# The key insight: intercept is the problem\n",
    "print('=== KEY INSIGHT: THE INTERCEPT IS THE PROBLEM ===')\n",
    "print()\n",
    "print(f'Current CV-LB relationship: LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'Intercept ({intercept:.4f}) > Target ({target_lb})')\n",
    "print()\n",
    "print('This means:')\n",
    "print('  - Even with CV = 0, predicted LB would be 0.0527')\n",
    "print('  - The intercept represents systematic generalization error')\n",
    "print('  - We need approaches that REDUCE THE INTERCEPT')\n",
    "print()\n",
    "print('What could reduce the intercept?')\n",
    "print('  1. Simpler models (fewer parameters to overfit)')\n",
    "print('  2. Fewer features (less opportunity to memorize)')\n",
    "print('  3. Stronger regularization (prevent memorization)')\n",
    "print('  4. Domain adaptation (learn solvent-invariant features)')\n",
    "print()\n",
    "print('If we can reduce intercept from 0.0527 to ~0.02:')\n",
    "print(f'  With CV = 0.008194, predicted LB = {slope:.2f} * 0.008194 + 0.02 = {slope * 0.008194 + 0.02:.4f}')\n",
    "print('  This would be close to target!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215ecd2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T23:44:07.604717Z",
     "iopub.status.busy": "2026-01-14T23:44:07.604628Z",
     "iopub.status.idle": "2026-01-14T23:44:07.607973Z",
     "shell.execute_reply": "2026-01-14T23:44:07.607626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STRATEGIC RECOMMENDATION ===\n",
      "\n",
      "PRIORITY 1: Aggressive Feature Selection + Simpler Model\n",
      "  - Get feature importance from LightGBM\n",
      "  - Select top 25-30 features\n",
      "  - Train simpler model (Ridge or [16] MLP)\n",
      "  - Use strong regularization (weight_decay=1e-2)\n",
      "  - Rationale: Directly attacks the intercept problem\n",
      "\n",
      "PRIORITY 2: Fix Similarity Weighting Bug\n",
      "  - Keep target weights [1.0, 1.0, 2.0]\n",
      "  - Add sample weights on top\n",
      "  - Apply to LGBM (native sample weight support)\n",
      "  - Rationale: The idea was sound, implementation was buggy\n",
      "\n",
      "PRIORITY 3: Submit exp_032 (best CV)\n",
      "  - CV 0.008194 is our best\n",
      "  - Predicted LB: 0.0877\n",
      "  - Verify the CV-LB relationship holds\n",
      "\n",
      "With 5 submissions remaining, we should:\n",
      "  1. Try aggressive simplification first (no submission cost)\n",
      "  2. If CV improves AND approach is fundamentally different, submit\n",
      "  3. Save submissions for approaches that could change the CV-LB relationship\n"
     ]
    }
   ],
   "source": [
    "# Strategic recommendation\n",
    "print('=== STRATEGIC RECOMMENDATION ===')\n",
    "print()\n",
    "print('PRIORITY 1: Aggressive Feature Selection + Simpler Model')\n",
    "print('  - Get feature importance from LightGBM')\n",
    "print('  - Select top 25-30 features')\n",
    "print('  - Train simpler model (Ridge or [16] MLP)')\n",
    "print('  - Use strong regularization (weight_decay=1e-2)')\n",
    "print('  - Rationale: Directly attacks the intercept problem')\n",
    "print()\n",
    "print('PRIORITY 2: Fix Similarity Weighting Bug')\n",
    "print('  - Keep target weights [1.0, 1.0, 2.0]')\n",
    "print('  - Add sample weights on top')\n",
    "print('  - Apply to LGBM (native sample weight support)')\n",
    "print('  - Rationale: The idea was sound, implementation was buggy')\n",
    "print()\n",
    "print('PRIORITY 3: Submit exp_032 (best CV)')\n",
    "print('  - CV 0.008194 is our best')\n",
    "print('  - Predicted LB: 0.0877')\n",
    "print('  - Verify the CV-LB relationship holds')\n",
    "print()\n",
    "print('With 5 submissions remaining, we should:')\n",
    "print('  1. Try aggressive simplification first (no submission cost)')\n",
    "print('  2. If CV improves AND approach is fundamentally different, submit')\n",
    "print('  3. Save submissions for approaches that could change the CV-LB relationship')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
