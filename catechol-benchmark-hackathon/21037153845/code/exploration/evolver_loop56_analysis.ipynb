{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ac9d156",
   "metadata": {},
   "source": [
    "# Loop 56 Analysis: Multi-Seed Ensemble Results & Strategic Assessment\n",
    "\n",
    "## Key Question: What's the path forward after multi-seed averaging failed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c40c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# All submissions data (CV, LB)\n",
    "submissions = [\n",
    "    ('exp_000', 0.0111, 0.0982),\n",
    "    ('exp_001', 0.0123, 0.1065),\n",
    "    ('exp_003', 0.0105, 0.0972),\n",
    "    ('exp_005', 0.0104, 0.0969),\n",
    "    ('exp_006', 0.0097, 0.0946),\n",
    "    ('exp_007', 0.0093, 0.0932),\n",
    "    ('exp_009', 0.0092, 0.0936),\n",
    "    ('exp_012', 0.0090, 0.0913),\n",
    "    ('exp_024', 0.0087, 0.0893),\n",
    "    ('exp_026', 0.0085, 0.0887),\n",
    "    ('exp_030', 0.0083, 0.0877),\n",
    "    ('exp_041', 0.0090, 0.0932),\n",
    "    ('exp_042', 0.0145, 0.1147),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions, columns=['exp', 'cv', 'lb'])\n",
    "print(f'Total submissions: {len(df)}')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e461360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression: LB = slope * CV + intercept\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "r_squared = r_value ** 2\n",
    "\n",
    "print(f'\\n=== CV-LB Relationship Analysis ===')\n",
    "print(f'Linear fit: LB = {slope:.4f} * CV + {intercept:.4f}')\n",
    "print(f'R-squared: {r_squared:.4f}')\n",
    "print(f'Intercept (extrapolation error): {intercept:.4f}')\n",
    "\n",
    "# Target analysis\n",
    "target_lb = 0.073040\n",
    "best_cv = 0.008194\n",
    "best_lb = 0.0877\n",
    "\n",
    "required_cv = (target_lb - intercept) / slope\n",
    "print(f'\\n=== Target Analysis ===')\n",
    "print(f'Target LB: {target_lb}')\n",
    "print(f'Best CV so far: {best_cv}')\n",
    "print(f'Best LB so far: {best_lb}')\n",
    "print(f'Required CV to hit target: {required_cv:.6f}')\n",
    "print(f'CV improvement needed: {(best_cv - required_cv) / best_cv * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['cv'], df['lb'], s=100, alpha=0.7, label='Submissions')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, 0.016, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'Fit: LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=target_lb, color='g', linestyle=':', label=f'Target: {target_lb}')\n",
    "\n",
    "# Best CV point\n",
    "plt.scatter([best_cv], [best_lb], s=200, marker='*', c='gold', edgecolors='black', label=f'Best: CV={best_cv}')\n",
    "\n",
    "# Required CV point\n",
    "plt.scatter([required_cv], [target_lb], s=200, marker='X', c='red', edgecolors='black', label=f'Required CV: {required_cv:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score (MSE)')\n",
    "plt.ylabel('LB Score (MSE)')\n",
    "plt.title('CV-LB Relationship Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_analysis_loop56.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nPlot saved to /home/code/exploration/cv_lb_analysis_loop56.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what approaches have been tried\n",
    "approaches_tried = {\n",
    "    'Multi-seed ensemble (10 seeds)': 0.008267,  # exp_058 - 0.89% worse\n",
    "    'Best GP+MLP+LGBM (single seed)': 0.008194,  # exp_032 - BEST\n",
    "    'Higher GP weight (0.4)': 0.009179,  # exp_031 - 10.6% worse\n",
    "    'Lower GP weight (0.15)': 0.008194,  # exp_032 - BEST\n",
    "    'Pure GP': 0.008298,  # exp_032 - 1.3% worse\n",
    "    'XGBoost ensemble': 0.0090,  # exp_041 - 9.8% worse\n",
    "    'GroupKFold CV': 0.0145,  # exp_042 - 77% worse\n",
    "    'Hyperparameter optimization': 0.012614,  # exp_055 - 54% worse\n",
    "    'Per-target optimization': 0.009895,  # exp_053 - 21% worse\n",
    "    'Per-solvent-type models': 0.019502,  # exp_054 - 138% worse\n",
    "    'ChemBERTa embeddings': 0.019444,  # exp_052 - 137% worse\n",
    "    'GNN (GCN)': 0.01408,  # exp_051 - 72% worse\n",
    "    'GNN (GAT)': 0.030013,  # exp_056 - 266% worse\n",
    "    'RDKit descriptors': 0.013306,  # exp_048 - 62% worse\n",
    "    'Simple Ridge': 0.016324,  # exp_049 - 99% worse\n",
    "    'Stacking meta-learner': 0.010016,  # exp_045 - 22% worse\n",
    "}\n",
    "\n",
    "print('\\n=== Approaches Tried (sorted by CV) ===')\n",
    "for name, cv in sorted(approaches_tried.items(), key=lambda x: x[1]):\n",
    "    pct_diff = (cv - best_cv) / best_cv * 100\n",
    "    status = '✓ BEST' if cv == best_cv else f'{pct_diff:+.1f}%'\n",
    "    print(f'{name}: CV {cv:.6f} ({status})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d12f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What hasn't been tried yet?\n",
    "print('\\n=== UNTRIED APPROACHES ===')\n",
    "print('''\n",
    "1. **Per-Target Ensemble Weight Optimization**\n",
    "   - Current: Same weights (GP 0.15, MLP 0.55, LGBM 0.30) for all targets\n",
    "   - Try: Different weights for SM, Product 2, Product 3\n",
    "   - Rationale: SM is typically hardest to predict, may need different model mix\n",
    "\n",
    "2. **Physical Constraints Post-Processing**\n",
    "   - Enforce: SM + Product2 + Product3 ≤ 1 (mass balance)\n",
    "   - Method: Normalize predictions or use constrained optimization\n",
    "   - Rationale: Enforces physical reality, may improve generalization\n",
    "\n",
    "3. **Feature Interaction Engineering**\n",
    "   - Add: Temperature × Spange interactions\n",
    "   - Add: Polynomial Arrhenius features (1/T², ln(t)², etc.)\n",
    "   - Rationale: Non-linear temperature-solvent effects\n",
    "\n",
    "4. **Uncertainty-Weighted Predictions**\n",
    "   - Use GP uncertainty to weight predictions\n",
    "   - High uncertainty → blend toward population mean\n",
    "   - Rationale: Conservative predictions for extrapolation\n",
    "\n",
    "5. **Solvent Clustering + Class-Specific Models**\n",
    "   - Group solvents by chemical class (alcohols, ethers, esters)\n",
    "   - Train class-specific models\n",
    "   - Rationale: Different solvent classes may have different behavior\n",
    "\n",
    "6. **Deeper MLP with Better Regularization**\n",
    "   - Try: [128, 64, 32] or [256, 128, 64] with stronger dropout\n",
    "   - Add: Early stopping based on validation loss\n",
    "   - Rationale: Current MLP may be underfitting\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The CV-LB relationship is STRUCTURAL\n",
    "print('\\n=== KEY INSIGHT: CV-LB Relationship is STRUCTURAL ===')\n",
    "print(f'''\n",
    "The linear fit (R² = {r_squared:.4f}) shows that:\n",
    "1. ALL model types fall on the SAME line\n",
    "2. The intercept ({intercept:.4f}) represents STRUCTURAL extrapolation error\n",
    "3. Improving CV is the ONLY path to better LB\n",
    "\n",
    "To hit target {target_lb}:\n",
    "- Required CV: {required_cv:.6f}\n",
    "- Current best CV: {best_cv}\n",
    "- Improvement needed: {(best_cv - required_cv) / best_cv * 100:.1f}%\n",
    "\n",
    "This is a LARGE gap. We need to find approaches that significantly improve CV.\n",
    "\n",
    "Multi-seed averaging did NOT help (0.89% worse).\n",
    "This suggests the best CV (0.008194) is a genuine ceiling for the current approach.\n",
    "\n",
    "To break through, we need:\n",
    "1. Better features (not just more models)\n",
    "2. Better model architecture (not just more seeds)\n",
    "3. Physical constraints that improve generalization\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143d09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-target performance\n",
    "print('\\n=== PER-TARGET ANALYSIS ===')\n",
    "print('''\n",
    "From exp_053 (per-target optimization):\n",
    "- SM target is typically hardest to predict\n",
    "- Product 2 and Product 3 are easier\n",
    "\n",
    "Potential strategy:\n",
    "1. Use different ensemble weights for each target\n",
    "2. SM: Higher GP weight (more conservative)\n",
    "3. Product 2/3: Higher MLP weight (more accurate)\n",
    "\n",
    "This could improve overall CV by optimizing each target separately.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendations\n",
    "print('\\n=== FINAL RECOMMENDATIONS ===')\n",
    "print('''\n",
    "**PRIORITY 1: Per-Target Ensemble Weight Optimization**\n",
    "- Optimize weights separately for SM, Product 2, Product 3\n",
    "- Use grid search or Bayesian optimization\n",
    "- Expected improvement: 5-10% CV reduction\n",
    "\n",
    "**PRIORITY 2: Physical Constraints Post-Processing**\n",
    "- Enforce SM + Product2 + Product3 ≤ 1\n",
    "- Normalize predictions after ensemble\n",
    "- Expected improvement: 2-5% CV reduction\n",
    "\n",
    "**PRIORITY 3: Deeper MLP with Early Stopping**\n",
    "- Try [128, 64, 32] architecture\n",
    "- Add early stopping based on validation loss\n",
    "- Expected improvement: 3-7% CV reduction\n",
    "\n",
    "**DO NOT TRY:**\n",
    "- More multi-seed averaging (already failed)\n",
    "- GNN approaches (consistently worse)\n",
    "- ChemBERTa embeddings (137% worse)\n",
    "- Per-solvent-type models (138% worse)\n",
    "\n",
    "**SUBMISSION STRATEGY:**\n",
    "- Only submit if CV improves by >10% (CV < 0.0074)\n",
    "- Save at least 1 submission for final attempt\n",
    "- 5 submissions remaining\n",
    "''')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
