{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5b4321",
   "metadata": {},
   "source": [
    "# Loop 62 Analysis: CV-LB Relationship and Strategy\n",
    "\n",
    "Analyzing the CV-LB relationship to understand the structural gap and develop strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'id': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'id': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'id': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'id': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'id': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'id': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'id': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'id': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'id': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'id': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'id': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},  # Best LB\n",
    "    {'id': 'exp_041', 'cv': 0.0090, 'lb': 0.0932},\n",
    "    {'id': 'exp_042', 'cv': 0.0145, 'lb': 0.1147},\n",
    "]\n",
    "\n",
    "cv_scores = np.array([s['cv'] for s in submissions])\n",
    "lb_scores = np.array([s['lb'] for s in submissions])\n",
    "\n",
    "print(f'Number of submissions: {len(submissions)}')\n",
    "print(f'Best CV: {cv_scores.min():.6f}')\n",
    "print(f'Best LB: {lb_scores.min():.6f}')\n",
    "print(f'Target: 0.0347')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9acba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression: LB = slope * CV + intercept\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_scores, lb_scores)\n",
    "\n",
    "print(f'Linear fit: LB = {slope:.4f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nInterpretation:')\n",
    "print(f'  - Intercept = {intercept:.4f} (LB when CV = 0)')\n",
    "print(f'  - Slope = {slope:.4f} (LB increase per unit CV increase)')\n",
    "print(f'\\nTo reach target LB = 0.0347:')\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f'  - Required CV = (0.0347 - {intercept:.4f}) / {slope:.4f} = {required_cv:.6f}')\n",
    "print(f'  - This is {required_cv/cv_scores.min()*100:.1f}% of our best CV ({cv_scores.min():.6f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7fa397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV vs LB\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cv_scores, lb_scores, c='blue', s=100, alpha=0.7, label='Submissions')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, cv_scores.max() * 1.1, 100)\n",
    "lb_fit = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_fit, 'r--', label=f'Fit: LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Best submission\n",
    "best_idx = np.argmin(lb_scores)\n",
    "plt.scatter([cv_scores[best_idx]], [lb_scores[best_idx]], c='red', s=200, marker='*', label=f'Best LB ({lb_scores[best_idx]:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score (MSE)')\n",
    "plt.ylabel('LB Score (MSE)')\n",
    "plt.title('CV vs LB Relationship')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nGap analysis:')\n",
    "print(f'  - Best LB: {lb_scores.min():.4f}')\n",
    "print(f'  - Target: 0.0347')\n",
    "print(f'  - Gap: {lb_scores.min() - 0.0347:.4f} ({(lb_scores.min() - 0.0347)/0.0347*100:.1f}% above target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddee079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the intercept problem\n",
    "print('='*60)\n",
    "print('CRITICAL ANALYSIS: The Intercept Problem')\n",
    "print('='*60)\n",
    "print(f'\\nThe linear fit shows:')\n",
    "print(f'  LB = {slope:.4f} * CV + {intercept:.4f}')\n",
    "print(f'\\nThis means:')\n",
    "print(f'  1. Even with CV = 0, expected LB = {intercept:.4f}')\n",
    "print(f'  2. The intercept ({intercept:.4f}) is HIGHER than target (0.0347)')\n",
    "print(f'  3. This is a STRUCTURAL problem - no amount of CV improvement can reach target')\n",
    "print(f'\\nTo reach target with current relationship:')\n",
    "print(f'  - Need CV = {required_cv:.6f}')\n",
    "if required_cv < 0:\n",
    "    print(f'  - This is NEGATIVE, meaning target is unreachable with current approach!')\n",
    "else:\n",
    "    print(f'  - This is {required_cv/cv_scores.min()*100:.1f}% of best CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9458ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would it take to reach the target?\n",
    "print('='*60)\n",
    "print('STRATEGIES TO REACH TARGET')\n",
    "print('='*60)\n",
    "print(f'\\nCurrent best: CV={cv_scores.min():.6f}, LB={lb_scores.min():.4f}')\n",
    "print(f'Target: LB=0.0347')\n",
    "print(f'\\nOption 1: Improve CV (keeping same relationship)')\n",
    "print(f'  - Required CV: {required_cv:.6f}')\n",
    "if required_cv < 0:\n",
    "    print(f'  - IMPOSSIBLE: Intercept > Target')\n",
    "else:\n",
    "    print(f'  - Improvement needed: {(cv_scores.min() - required_cv)/cv_scores.min()*100:.1f}%')\n",
    "\n",
    "print(f'\\nOption 2: Reduce intercept (change the relationship)')\n",
    "print(f'  - Current intercept: {intercept:.4f}')\n",
    "print(f'  - Need intercept < 0.0347 to have any chance')\n",
    "print(f'  - Reduction needed: {intercept - 0.0347:.4f}')\n",
    "\n",
    "print(f'\\nOption 3: Reduce slope (change the relationship)')\n",
    "print(f'  - Current slope: {slope:.4f}')\n",
    "print(f'  - With best CV ({cv_scores.min():.6f}), need slope < {(0.0347 - intercept)/cv_scores.min():.4f}')\n",
    "if (0.0347 - intercept)/cv_scores.min() < 0:\n",
    "    print(f'  - IMPOSSIBLE: Would need negative slope')\n",
    "\n",
    "print(f'\\nConclusion:')\n",
    "print(f'  - The intercept ({intercept:.4f}) > target (0.0347) means we MUST change the relationship')\n",
    "print(f'  - Simply improving CV will NOT reach the target')\n",
    "print(f'  - Need fundamentally different approaches that reduce the intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ab928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what the top kernels do differently\n",
    "print('='*60)\n",
    "print('INSIGHTS FROM TOP KERNELS')\n",
    "print('='*60)\n",
    "print(f'''\n",
    "1. \"Ens Model\" kernel (8 votes):\n",
    "   - Uses CatBoost + XGBoost ensemble\n",
    "   - Different weights for single vs full data:\n",
    "     * Single: CatBoost 7, XGBoost 6 (normalized)\n",
    "     * Full: CatBoost 1, XGBoost 2 (normalized)\n",
    "   - Feature priority-based correlation filtering\n",
    "   - Multi-target normalization: clip to [0,∞), divide by max(sum, 1.0)\n",
    "   - Combines ALL features: spange, acs_pca, drfps, fragprints, smiles\n",
    "\n",
    "2. \"mixall\" kernel (9 votes):\n",
    "   - Uses GroupKFold(5) instead of Leave-One-Out\n",
    "   - Ensemble of MLP + XGBoost + RandomForest + LightGBM\n",
    "   - Uses Optuna for hyperparameter optimization\n",
    "\n",
    "Key differences from our approach:\n",
    "   - We use GP + MLP + LGBM, they use CatBoost + XGBoost\n",
    "   - We don't use multi-target normalization\n",
    "   - We don't use different weights for single vs full data\n",
    "   - We haven't tried feature priority-based filtering\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05686b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we should try next\n",
    "print('='*60)\n",
    "print('RECOMMENDED NEXT STEPS')\n",
    "print('='*60)\n",
    "print(f'''\n",
    "PRIORITY 1: Implement \"Ens Model\" kernel approach\n",
    "   - CatBoost + XGBoost ensemble\n",
    "   - Different weights for single (7:6) vs full (1:2) data\n",
    "   - Feature priority-based correlation filtering\n",
    "   - Multi-target normalization\n",
    "   - This is a PROVEN approach with good LB score\n",
    "\n",
    "PRIORITY 2: Try different feature combinations\n",
    "   - The \"Ens Model\" uses ALL features (spange + acs + drfps + frag + smiles)\n",
    "   - We've been using Spange + DRFP + ACS PCA + Arrhenius\n",
    "   - Try adding SMILES-based features\n",
    "\n",
    "PRIORITY 3: Investigate the CV-LB gap\n",
    "   - Our CV is good (0.0083) but LB is much worse (0.0877)\n",
    "   - The gap is ~10x, suggesting distribution shift\n",
    "   - The \"Ens Model\" approach may handle this better\n",
    "\n",
    "PRIORITY 4: Consider the evaluation procedure\n",
    "   - The competition uses server-side CV evaluation\n",
    "   - Our local CV may not match the server's CV\n",
    "   - The \"Ens Model\" kernel may have better alignment\n",
    "''')\n",
    "\n",
    "print(f'\\nCurrent status:')\n",
    "print(f'  - Best CV: {cv_scores.min():.6f}')\n",
    "print(f'  - Best LB: {lb_scores.min():.4f}')\n",
    "print(f'  - Target: 0.0347')\n",
    "print(f'  - Gap to target: {lb_scores.min() - 0.0347:.4f} ({(lb_scores.min() - 0.0347)/0.0347*100:.1f}% above)')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
