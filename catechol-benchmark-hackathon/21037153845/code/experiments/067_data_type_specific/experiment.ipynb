{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7237a713",
   "metadata": {},
   "source": [
    "# Experiment 067: Data-Type-Specific Features\n",
    "\n",
    "Based on exp_066 findings:\n",
    "- Fragprints help single solvent (5.7% improvement)\n",
    "- Fragprints hurt mixture predictions (2.4x worse)\n",
    "\n",
    "Approach:\n",
    "- Single Solvent: Use Fragprints\n",
    "- Full Data: Don't use Fragprints\n",
    "- Use correct RAMP NUM-based CV for full data (87 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8036786f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T11:16:09.069492Z",
     "iopub.status.busy": "2026-01-16T11:16:09.068930Z",
     "iopub.status.idle": "2026-01-16T11:16:11.049647Z",
     "shell.execute_reply": "2026-01-16T11:16:11.049181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "DATA_PATH = '/home/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96eac18b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T11:16:11.050952Z",
     "iopub.status.busy": "2026-01-16T11:16:11.050772Z",
     "iopub.status.idle": "2026-01-16T11:16:11.106106Z",
     "shell.execute_reply": "2026-01-16T11:16:11.105711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13)\n",
      "DRFP filtered: (24, 122)\n",
      "ACS PCA: (24, 5)\n",
      "Fragprints filtered: (24, 144)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "FRAGPRINTS_DF = pd.read_csv(f'{DATA_PATH}/fragprints_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter to non-zero variance\n",
    "drfp_variance = DRFP_DF.var()\n",
    "DRFP_FILTERED = DRFP_DF[drfp_variance[drfp_variance > 0].index.tolist()]\n",
    "\n",
    "frag_variance = FRAGPRINTS_DF.var()\n",
    "FRAGPRINTS_FILTERED = FRAGPRINTS_DF[frag_variance[frag_variance > 0].index.tolist()]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}')\n",
    "print(f'DRFP filtered: {DRFP_FILTERED.shape}')\n",
    "print(f'ACS PCA: {ACS_PCA_DF.shape}')\n",
    "print(f'Fragprints filtered: {FRAGPRINTS_FILTERED.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b7c5509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T11:16:11.107179Z",
     "iopub.status.busy": "2026-01-16T11:16:11.107058Z",
     "iopub.status.idle": "2026-01-16T11:16:11.111637Z",
     "shell.execute_reply": "2026-01-16T11:16:11.111229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\", \"RAMP NUM\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    \"\"\"Leave-One-Ramp-Out CV using RAMP NUM (87 folds)\"\"\"\n",
    "    for ramp in sorted(X[\"RAMP NUM\"].unique()):\n",
    "        mask = X[\"RAMP NUM\"] != ramp\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f1d0687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T11:16:11.112799Z",
     "iopub.status.busy": "2026-01-16T11:16:11.112677Z",
     "iopub.status.idle": "2026-01-16T11:16:11.120675Z",
     "shell.execute_reply": "2026-01-16T11:16:11.120279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer defined\n"
     ]
    }
   ],
   "source": [
    "# Featurizer - different for single vs full\n",
    "class FullFeaturizer:\n",
    "    def __init__(self, mixed=False, include_fragprints=False):\n",
    "        self.mixed = mixed\n",
    "        self.include_fragprints = include_fragprints\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.frag_df = FRAGPRINTS_FILTERED\n",
    "        \n",
    "        base_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "        if include_fragprints:\n",
    "            self.feats_dim = base_dim + self.frag_df.shape[1]\n",
    "        else:\n",
    "            self.feats_dim = base_dim\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1) / 100.0\n",
    "            \n",
    "            if flip:\n",
    "                X_spange = B_spange * (1-pct) + A_spange * pct\n",
    "                X_drfp = B_drfp * (1-pct) + A_drfp * pct\n",
    "                X_acs = B_acs * (1-pct) + A_acs * pct\n",
    "            else:\n",
    "                X_spange = A_spange * (1-pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1-pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1-pct) + B_acs * pct\n",
    "            \n",
    "            if self.include_fragprints:\n",
    "                A_frag = self.frag_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                B_frag = self.frag_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                if flip:\n",
    "                    X_frag = B_frag * (1-pct) + A_frag * pct\n",
    "                else:\n",
    "                    X_frag = A_frag * (1-pct) + B_frag * pct\n",
    "                return np.hstack([X_kinetic, X_spange, X_drfp, X_acs, X_frag])\n",
    "            else:\n",
    "                return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            \n",
    "            if self.include_fragprints:\n",
    "                X_frag = self.frag_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "                return np.hstack([X_kinetic, X_spange, X_drfp, X_acs, X_frag])\n",
    "            else:\n",
    "                return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "    \n",
    "    def featurize_torch(self, X, flip=False):\n",
    "        return torch.tensor(self.featurize(X, flip), dtype=torch.double)\n",
    "\n",
    "print('Featurizer defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab82fa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T11:16:11.121847Z",
     "iopub.status.busy": "2026-01-16T11:16:11.121735Z",
     "iopub.status.idle": "2026-01-16T11:16:11.126278Z",
     "shell.execute_reply": "2026-01-16T11:16:11.125848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple featurizer defined\n"
     ]
    }
   ],
   "source": [
    "# Simple Featurizer for GP (Spange + Arrhenius only)\n",
    "class SimpleFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1) / 100.0\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1-pct) + A_spange * pct\n",
    "            else:\n",
    "                X_spange = A_spange * (1-pct) + B_spange * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange])\n",
    "\n",
    "print('Simple featurizer defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "608f2d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T11:16:11.127220Z",
     "iopub.status.busy": "2026-01-16T11:16:11.127106Z",
     "iopub.status.idle": "2026-01-16T11:16:11.132257Z",
     "shell.execute_reply": "2026-01-16T11:16:11.131828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP wrapper defined\n"
     ]
    }
   ],
   "source": [
    "# GP Wrapper\n",
    "class GPWrapper:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.featurizer = SimpleFeaturizer(mixed=(data=='full'))\n",
    "        self.models = []\n",
    "        self.scaler = None\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_std, X_flip])\n",
    "            y_all = np.vstack([y_vals, y_vals])\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X_all)\n",
    "        \n",
    "        self.models = []\n",
    "        kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "        \n",
    "        for i in range(3):\n",
    "            gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True, random_state=42)\n",
    "            gp.fit(X_scaled, y_all[:, i])\n",
    "            self.models.append(gp)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_feat = self.featurizer.featurize(X_test, flip=False)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        preds = np.column_stack([m.predict(X_scaled) for m in self.models])\n",
    "        return torch.tensor(preds, dtype=torch.double)\n",
    "\n",
    "print('GP wrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff4ca7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T11:16:11.133251Z",
     "iopub.status.busy": "2026-01-16T11:16:11.133132Z",
     "iopub.status.idle": "2026-01-16T11:16:11.141085Z",
     "shell.execute_reply": "2026-01-16T11:16:11.140684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP ensemble defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model\n",
    "class MLPModelInternal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[32, 16], output_dim=3, dropout=0.05):\n",
    "        super().__init__()\n",
    "        layers = [nn.BatchNorm1d(input_dim)]\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([nn.Linear(prev_dim, h_dim), nn.BatchNorm1d(h_dim), nn.ReLU(), nn.Dropout(dropout)])\n",
    "            prev_dim = h_dim\n",
    "        layers.extend([nn.Linear(prev_dim, output_dim), nn.Sigmoid()])\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class WeightedMLPEnsemble:\n",
    "    def __init__(self, hidden_dims=[32, 16], n_models=5, data='single', include_fragprints=False):\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.n_models = n_models\n",
    "        self.data_type = data\n",
    "        self.featurizer = FullFeaturizer(mixed=(data=='full'), include_fragprints=include_fragprints)\n",
    "        self.models = []\n",
    "\n",
    "    def train_model(self, X_train, y_train, epochs=200, batch_size=32, lr=5e-4):\n",
    "        X_std = self.featurizer.featurize_torch(X_train, flip=False)\n",
    "        y_vals = torch.tensor(y_train.values)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize_torch(X_train, flip=True)\n",
    "            X_all = torch.cat([X_std, X_flip], dim=0)\n",
    "            y_all = torch.cat([y_vals, y_vals], dim=0)\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "            \n",
    "        input_dim = X_all.shape[1]\n",
    "        self.models = []\n",
    "        \n",
    "        for i in range(self.n_models):\n",
    "            torch.manual_seed(42 + i)\n",
    "            model = MLPModelInternal(input_dim, self.hidden_dims).double().to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=20, factor=0.5)\n",
    "            criterion = nn.HuberLoss()\n",
    "            \n",
    "            dataset = TensorDataset(X_all.to(device), y_all.to(device))\n",
    "            loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            model.train()\n",
    "            for epoch in range(epochs):\n",
    "                epoch_loss = 0\n",
    "                for X_batch, y_batch in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(X_batch)\n",
    "                    loss = criterion(pred, y_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item()\n",
    "                scheduler.step(epoch_loss)\n",
    "            \n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_feat = self.featurizer.featurize_torch(X_test, flip=False).to(device)\n",
    "        preds = []\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                preds.append(model(X_feat).cpu())\n",
    "        return torch.mean(torch.stack(preds), dim=0)\n",
    "\n",
    "print('MLP ensemble defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "133d044d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T11:16:11.142022Z",
     "iopub.status.busy": "2026-01-16T11:16:11.141903Z",
     "iopub.status.idle": "2026-01-16T11:16:11.146921Z",
     "shell.execute_reply": "2026-01-16T11:16:11.146548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM wrapper defined\n"
     ]
    }
   ],
   "source": [
    "# LGBM Wrapper\n",
    "class LGBMWrapper:\n",
    "    def __init__(self, data='single', include_fragprints=False):\n",
    "        self.data_type = data\n",
    "        self.featurizer = FullFeaturizer(mixed=(data=='full'), include_fragprints=include_fragprints)\n",
    "        self.models = []\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_std, X_flip])\n",
    "            y_all = np.vstack([y_vals, y_vals])\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "        \n",
    "        self.models = []\n",
    "        params = {'objective': 'regression', 'metric': 'mse', 'boosting_type': 'gbdt',\n",
    "                  'num_leaves': 31, 'learning_rate': 0.05, 'feature_fraction': 0.9,\n",
    "                  'bagging_fraction': 0.8, 'bagging_freq': 5, 'verbose': -1, 'seed': 42}\n",
    "        \n",
    "        for i in range(3):\n",
    "            train_data = lgb.Dataset(X_all, label=y_all[:, i])\n",
    "            model = lgb.train(params, train_data, num_boost_round=100)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_feat = self.featurizer.featurize(X_test, flip=False)\n",
    "        preds = np.column_stack([m.predict(X_feat) for m in self.models])\n",
    "        return torch.tensor(preds, dtype=torch.double)\n",
    "\n",
    "print('LGBM wrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27769d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T11:16:11.147890Z",
     "iopub.status.busy": "2026-01-16T11:16:11.147779Z",
     "iopub.status.idle": "2026-01-16T11:16:11.152390Z",
     "shell.execute_reply": "2026-01-16T11:16:11.151956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble defined with data-type-specific features:\n",
      "  - Single Solvent: WITH Fragprints\n",
      "  - Full Data: WITHOUT Fragprints\n"
     ]
    }
   ],
   "source": [
    "# GP + MLP + LGBM Ensemble with data-type-specific features\n",
    "class GPMLPLGBMEnsemble:\n",
    "    def __init__(self, data='single', gp_weight=0.15, mlp_weight=0.55, lgbm_weight=0.30):\n",
    "        self.data_type = data\n",
    "        # Use Fragprints for single solvent, not for full data\n",
    "        include_fragprints = (data == 'single')\n",
    "        \n",
    "        self.gp = GPWrapper(data=data)\n",
    "        self.mlp = WeightedMLPEnsemble(hidden_dims=[32, 16], n_models=5, data=data, include_fragprints=include_fragprints)\n",
    "        self.lgbm = LGBMWrapper(data=data, include_fragprints=include_fragprints)\n",
    "        self.weights = {'gp': gp_weight, 'mlp': mlp_weight, 'lgbm': lgbm_weight}\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        self.gp.train_model(X_train, y_train)\n",
    "        self.mlp.train_model(X_train, y_train)\n",
    "        self.lgbm.train_model(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        gp_pred = self.gp.predict(X_test)\n",
    "        mlp_pred = self.mlp.predict(X_test)\n",
    "        lgbm_pred = self.lgbm.predict(X_test)\n",
    "        \n",
    "        combined = (self.weights['gp'] * gp_pred + \n",
    "                    self.weights['mlp'] * mlp_pred + \n",
    "                    self.weights['lgbm'] * lgbm_pred)\n",
    "        return torch.clamp(combined, 0, 1)\n",
    "\n",
    "print('Ensemble defined with data-type-specific features:')\n",
    "print('  - Single Solvent: WITH Fragprints')\n",
    "print('  - Full Data: WITHOUT Fragprints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a6bda6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T11:16:11.153434Z",
     "iopub.status.busy": "2026-01-16T11:16:11.153313Z",
     "iopub.status.idle": "2026-01-16T11:30:39.507409Z",
     "shell.execute_reply": "2026-01-16T11:30:39.507010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Single Solvent CV (with Fragprints)...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:37<14:15, 37.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [01:12<13:17, 36.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [01:46<12:14, 34.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [02:20<11:31, 34.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [02:56<11:06, 35.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [03:32<10:37, 35.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [04:08<10:04, 35.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [04:43<09:26, 35.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [05:22<09:09, 36.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [05:58<08:29, 36.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [06:34<07:51, 36.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [07:10<07:14, 36.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [07:45<06:34, 35.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [08:22<06:01, 36.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [08:58<05:25, 36.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [09:35<04:52, 36.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [10:13<04:17, 36.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [10:49<03:39, 36.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [11:24<03:00, 36.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [12:04<02:29, 37.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [12:40<01:51, 37.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [13:17<01:13, 36.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 23/24 [13:52<00:36, 36.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [14:28<00:00, 36.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [14:28<00:00, 36.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Solvent MSE: 0.008217 (n=656)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Single Solvent CV\n",
    "print('Running Single Solvent CV (with Fragprints)...')\n",
    "print('='*60)\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "\n",
    "all_preds_single = []\n",
    "all_actuals_single = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = GPMLPLGBMEnsemble(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    all_preds_single.append(predictions.numpy())\n",
    "    all_actuals_single.append(test_Y.values)\n",
    "\n",
    "all_preds_single = np.vstack(all_preds_single)\n",
    "all_actuals_single = np.vstack(all_actuals_single)\n",
    "mse_single = np.mean((all_preds_single - all_actuals_single) ** 2)\n",
    "print(f'\\nSingle Solvent MSE: {mse_single:.6f} (n={len(all_preds_single)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c5dd843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T11:30:52.470152Z",
     "iopub.status.busy": "2026-01-16T11:30:52.469631Z",
     "iopub.status.idle": "2026-01-16T16:22:47.205655Z",
     "shell.execute_reply": "2026-01-16T16:22:47.203079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Full Data CV (without Fragprints, 87 ramps)...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/87 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/87 [03:33<5:06:10, 213.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/87 [06:50<4:48:50, 203.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/87 [10:11<4:43:39, 202.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 4/87 [13:27<4:36:37, 199.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 5/87 [16:41<4:30:27, 197.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 6/87 [20:02<4:28:12, 198.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 7/87 [23:23<4:26:02, 199.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 8/87 [26:45<4:23:50, 200.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 9/87 [30:14<4:23:50, 202.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 10/87 [33:36<4:20:04, 202.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 11/87 [36:57<4:16:10, 202.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 12/87 [40:26<4:15:10, 204.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 13/87 [43:45<4:10:11, 202.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 14/87 [47:00<4:03:50, 200.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 15/87 [50:28<4:03:04, 202.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 16/87 [53:56<4:01:39, 204.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 17/87 [57:21<3:58:34, 204.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 18/87 [1:00:46<3:55:28, 204.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 19/87 [1:04:24<3:56:26, 208.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 20/87 [1:07:38<3:48:09, 204.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 21/87 [1:10:52<3:41:12, 201.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 22/87 [1:14:20<3:40:06, 203.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 23/87 [1:17:34<3:33:42, 200.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 24/87 [1:20:50<3:29:13, 199.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 25/87 [1:24:36<3:34:12, 207.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 26/87 [1:27:56<3:28:23, 204.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 27/87 [1:31:15<3:23:04, 203.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 28/87 [1:34:26<3:16:16, 199.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 29/87 [1:37:58<3:16:33, 203.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 30/87 [1:41:17<3:11:56, 202.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 31/87 [1:44:35<3:07:24, 200.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 32/87 [1:47:58<3:04:32, 201.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 33/87 [1:51:15<3:00:14, 200.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 34/87 [1:54:38<2:57:36, 201.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 35/87 [1:57:56<2:53:16, 199.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 36/87 [2:01:15<2:49:41, 199.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 37/87 [2:04:33<2:46:02, 199.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▎     | 38/87 [2:07:49<2:41:53, 198.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 39/87 [2:11:10<2:39:16, 199.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 40/87 [2:14:35<2:37:22, 200.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 41/87 [2:18:14<2:38:08, 206.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 42/87 [2:21:36<2:33:48, 205.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 43/87 [2:24:57<2:29:33, 203.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 44/87 [2:28:12<2:24:09, 201.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 45/87 [2:31:32<2:20:28, 200.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 46/87 [2:34:48<2:16:10, 199.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 47/87 [2:38:04<2:12:20, 198.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 48/87 [2:41:48<2:13:50, 205.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 49/87 [2:45:02<2:08:10, 202.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 50/87 [2:48:20<2:04:07, 201.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 51/87 [2:51:37<1:59:55, 199.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 52/87 [2:55:00<1:57:12, 200.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 53/87 [2:58:13<1:52:28, 198.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 54/87 [3:01:30<1:48:53, 197.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 55/87 [3:04:41<1:44:32, 196.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 56/87 [3:08:00<1:41:41, 196.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 57/87 [3:11:17<1:38:29, 196.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 58/87 [3:14:41<1:36:13, 199.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 59/87 [3:17:59<1:32:40, 198.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 60/87 [3:21:20<1:29:42, 199.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 61/87 [3:24:44<1:26:58, 200.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 62/87 [3:27:55<1:22:29, 197.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 63/87 [3:31:23<1:20:23, 200.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 64/87 [3:34:42<1:16:46, 200.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 65/87 [3:37:59<1:13:03, 199.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 66/87 [3:41:21<1:10:00, 200.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 67/87 [3:44:43<1:06:53, 200.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 68/87 [3:48:06<1:03:44, 201.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 69/87 [3:51:21<59:52, 199.56s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 70/87 [3:54:42<56:41, 200.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 71/87 [3:58:04<53:28, 200.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 72/87 [4:01:22<49:55, 199.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 73/87 [4:04:38<46:21, 198.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 74/87 [4:08:03<43:27, 200.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 75/87 [4:11:47<41:30, 207.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 76/87 [4:15:13<37:58, 207.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▊ | 77/87 [4:18:34<34:13, 205.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 78/87 [4:21:54<30:32, 203.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 79/87 [4:25:09<26:47, 200.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 80/87 [4:28:26<23:18, 199.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 81/87 [4:31:37<19:43, 197.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 82/87 [4:35:24<17:10, 206.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 83/87 [4:38:43<13:35, 203.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 84/87 [4:42:01<10:06, 202.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 85/87 [4:45:17<06:40, 200.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 86/87 [4:48:37<03:20, 200.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 87/87 [4:51:54<00:00, 199.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 87/87 [4:51:54<00:00, 201.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Data MSE: 0.007798 (n=1227)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Full Data CV (using RAMP NUM - 87 folds)\n",
    "print('\\nRunning Full Data CV (without Fragprints, 87 ramps)...')\n",
    "print('='*60)\n",
    "\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "split_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "\n",
    "all_preds_full = []\n",
    "all_actuals_full = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=87):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = GPMLPLGBMEnsemble(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    all_preds_full.append(predictions.numpy())\n",
    "    all_actuals_full.append(test_Y.values)\n",
    "\n",
    "all_preds_full = np.vstack(all_preds_full)\n",
    "all_actuals_full = np.vstack(all_actuals_full)\n",
    "mse_full = np.mean((all_preds_full - all_actuals_full) ** 2)\n",
    "print(f'\\nFull Data MSE: {mse_full:.6f} (n={len(all_preds_full)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b5c376d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T16:22:47.208689Z",
     "iopub.status.busy": "2026-01-16T16:22:47.208527Z",
     "iopub.status.idle": "2026-01-16T16:22:47.213292Z",
     "shell.execute_reply": "2026-01-16T16:22:47.212781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "============================================================\n",
      "Single Solvent MSE: 0.008217 (n=656)\n",
      "Full Data MSE: 0.007798 (n=1227)\n",
      "Weighted Combined MSE: 0.007944\n",
      "\n",
      "Best baseline CV: 0.008194\n",
      "Improvement: 3.05%\n"
     ]
    }
   ],
   "source": [
    "# Calculate combined CV score\n",
    "n_single = len(all_preds_single)\n",
    "n_full = len(all_preds_full)\n",
    "\n",
    "weighted_cv = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(f'\\n' + '='*60)\n",
    "print(f'FINAL RESULTS')\n",
    "print(f'='*60)\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Weighted Combined MSE: {weighted_cv:.6f}')\n",
    "print(f'\\nBest baseline CV: 0.008194')\n",
    "print(f'Improvement: {(0.008194 - weighted_cv) / 0.008194 * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
