{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45818d0f",
   "metadata": {},
   "source": [
    "# Loop 91 Analysis: Understanding the CV-LB Gap\n",
    "\n",
    "**Critical Problem**: The CV-LB relationship is LB = 4.29 × CV + 0.0528 (R² = 0.95)\n",
    "\n",
    "The intercept (0.0528) is ABOVE the target (0.0347), meaning no amount of CV improvement can reach the target.\n",
    "\n",
    "**Key Questions**:\n",
    "1. What makes test solvents different from training solvents?\n",
    "2. Can we identify which solvents are \"harder\" to predict?\n",
    "3. What approaches might change the CV-LB relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Load submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "    {'exp': 'exp_073', 'cv': 0.0084, 'lb': 0.1451},  # Outlier!\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f'Total submissions with LB: {len(df)}')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze CV-LB relationship (excluding outlier exp_073)\n",
    "df_clean = df[df['lb'] < 0.12]  # Exclude exp_073 outlier\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_clean['cv'], df_clean['lb'])\n",
    "\n",
    "print(f'\\n=== CV-LB Relationship Analysis ===')\n",
    "print(f'Linear fit: LB = {slope:.4f} × CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nIntercept: {intercept:.4f}')\n",
    "print(f'Target LB: 0.0347')\n",
    "print(f'\\nCRITICAL: Intercept ({intercept:.4f}) > Target (0.0347)')\n",
    "print(f'This means even with CV=0, expected LB would be {intercept:.4f}')\n",
    "\n",
    "# What CV would be needed to hit target?\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f'\\nRequired CV to hit target: {required_cv:.6f}')\n",
    "if required_cv < 0:\n",
    "    print('IMPOSSIBLE: Would require negative CV!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV vs LB\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot all points\n",
    "plt.scatter(df_clean['cv'], df_clean['lb'], s=100, alpha=0.7, label='Submissions')\n",
    "\n",
    "# Plot outlier\n",
    "outlier = df[df['lb'] >= 0.12]\n",
    "if len(outlier) > 0:\n",
    "    plt.scatter(outlier['cv'], outlier['lb'], s=100, c='red', marker='x', label='Outlier (exp_073)')\n",
    "\n",
    "# Plot regression line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'b--', label=f'LB = {slope:.2f}×CV + {intercept:.4f}')\n",
    "\n",
    "# Plot target\n",
    "plt.axhline(y=0.0347, color='g', linestyle=':', linewidth=2, label='Target LB = 0.0347')\n",
    "\n",
    "# Plot intercept\n",
    "plt.axhline(y=intercept, color='r', linestyle=':', linewidth=2, label=f'Intercept = {intercept:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship - The Intercept Problem')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_analysis_loop91.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print('\\nThe gap between intercept and target is the STRUCTURAL DISTRIBUTION SHIFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aacb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to understand solvent characteristics\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "df_single = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "df_full = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "\n",
    "print('=== Single Solvent Data ===')\n",
    "print(f'Samples: {len(df_single)}')\n",
    "print(f'Unique solvents: {df_single[\"SOLVENT NAME\"].nunique()}')\n",
    "print(f'\\nSolvents: {sorted(df_single[\"SOLVENT NAME\"].unique())}')\n",
    "\n",
    "print('\\n=== Full Data (Mixtures) ===')\n",
    "print(f'Samples: {len(df_full)}')\n",
    "print(f'Unique solvent A: {df_full[\"SOLVENT A NAME\"].nunique()}')\n",
    "print(f'Unique solvent B: {df_full[\"SOLVENT B NAME\"].nunique()}')\n",
    "print(f'\\nSolvent A: {sorted(df_full[\"SOLVENT A NAME\"].unique())}')\n",
    "print(f'Solvent B: {sorted(df_full[\"SOLVENT B NAME\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-solvent prediction difficulty\n",
    "# Load spange descriptors to understand solvent properties\n",
    "spange = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "print('=== Spange Descriptors ===')\n",
    "print(f'Shape: {spange.shape}')\n",
    "print(f'\\nSolvents in spange: {sorted(spange.index.tolist())}')\n",
    "\n",
    "# Check which solvents are in training vs might be in test\n",
    "single_solvents = set(df_single['SOLVENT NAME'].unique())\n",
    "full_solvents_a = set(df_full['SOLVENT A NAME'].unique())\n",
    "full_solvents_b = set(df_full['SOLVENT B NAME'].unique())\n",
    "all_solvents = single_solvents | full_solvents_a | full_solvents_b\n",
    "spange_solvents = set(spange.index.tolist())\n",
    "\n",
    "print(f'\\nSolvents in data: {len(all_solvents)}')\n",
    "print(f'Solvents in spange: {len(spange_solvents)}')\n",
    "print(f'Solvents in spange but not in data: {spange_solvents - all_solvents}')\n",
    "print(f'Solvents in data but not in spange: {all_solvents - spange_solvents}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfbefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze yield distribution per solvent\n",
    "print('=== Per-Solvent Yield Statistics ===')\n",
    "\n",
    "solvent_stats = df_single.groupby('SOLVENT NAME').agg({\n",
    "    'Product 2': ['mean', 'std'],\n",
    "    'Product 3': ['mean', 'std'],\n",
    "    'SM': ['mean', 'std']\n",
    "}).round(4)\n",
    "\n",
    "solvent_stats.columns = ['P2_mean', 'P2_std', 'P3_mean', 'P3_std', 'SM_mean', 'SM_std']\n",
    "\n",
    "# Calculate total yield variability\n",
    "solvent_stats['total_std'] = np.sqrt(solvent_stats['P2_std']**2 + solvent_stats['P3_std']**2 + solvent_stats['SM_std']**2)\n",
    "\n",
    "print(solvent_stats.sort_values('total_std', ascending=False))\n",
    "\n",
    "print('\\n=== Solvents with Highest Variability (Hardest to Predict) ===')\n",
    "print(solvent_stats.nlargest(5, 'total_std')[['P2_mean', 'P3_mean', 'SM_mean', 'total_std']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35135b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The benchmark paper achieved MSE 0.0039\n",
    "# Our best CV is 0.0081, best LB is 0.0877\n",
    "# The gap is HUGE\n",
    "\n",
    "print('=== Performance Gap Analysis ===')\n",
    "print(f'Benchmark paper MSE: 0.0039')\n",
    "print(f'Our best CV: 0.0081 (2.1x worse)')\n",
    "print(f'Our best LB: 0.0877 (22.5x worse than benchmark!)')\n",
    "print(f'Target LB: 0.0347 (8.9x worse than benchmark)')\n",
    "\n",
    "print('\\n=== What the benchmark paper likely did differently ===')\n",
    "print('1. Pre-training on large molecular datasets')\n",
    "print('2. Graph Neural Networks with attention mechanisms')\n",
    "print('3. Domain-specific constraints that generalize')\n",
    "print('4. Different validation strategy (not leave-one-out)')\n",
    "\n",
    "print('\\n=== What we MUST try ===')\n",
    "print('1. Pre-trained molecular embeddings (ChemBERTa, MolBERT)')\n",
    "print('2. GNN with proper message passing')\n",
    "print('3. Extrapolation detection + conservative predictions')\n",
    "print('4. Pseudo-labeling with confident predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2251ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the mixall kernel approach\n",
    "# It uses GroupKFold instead of Leave-One-Out\n",
    "# This might explain why it has good CV/LB correlation\n",
    "\n",
    "print('=== Key Insight from mixall Kernel ===')\n",
    "print('The mixall kernel uses GroupKFold (5-fold) instead of Leave-One-Out')\n",
    "print('This means each fold has ~20% of solvents held out')\n",
    "print('\\nThis is DIFFERENT from the official evaluation which uses Leave-One-Out')\n",
    "print('\\nHowever, the kernel claims \"good CV/LB\" correlation')\n",
    "print('\\nPossible explanation:')\n",
    "print('- GroupKFold with 5 folds is more robust than LOO')\n",
    "print('- LOO has high variance due to single-solvent test sets')\n",
    "print('- The official evaluation might use a different split')\n",
    "\n",
    "print('\\n=== Approaches to try ===')\n",
    "print('1. Ensemble of MLP + XGBoost + RF + LightGBM (from mixall)')\n",
    "print('2. Use GroupKFold for hyperparameter tuning, LOO for final CV')\n",
    "print('3. Focus on reducing variance, not just bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea47054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of findings\n",
    "print('='*70)\n",
    "print('LOOP 91 ANALYSIS SUMMARY')\n",
    "print('='*70)\n",
    "\n",
    "print('\\n1. CV-LB RELATIONSHIP:')\n",
    "print(f'   LB = {slope:.2f} × CV + {intercept:.4f} (R² = {r_value**2:.4f})')\n",
    "print(f'   Intercept ({intercept:.4f}) > Target (0.0347)')\n",
    "print(f'   IMPOSSIBLE to reach target by improving CV alone!')\n",
    "\n",
    "print('\\n2. DISTRIBUTION SHIFT:')\n",
    "print('   - Test solvents are systematically \"harder\" than training')\n",
    "print('   - The intercept represents structural extrapolation error')\n",
    "print('   - All tabular models fall on the SAME CV-LB line')\n",
    "\n",
    "print('\\n3. WHAT MUST CHANGE:')\n",
    "print('   - Need approaches that REDUCE THE INTERCEPT')\n",
    "print('   - Not just improve CV (which moves along the line)')\n",
    "print('   - Focus on extrapolation detection and conservative predictions')\n",
    "\n",
    "print('\\n4. PROMISING APPROACHES:')\n",
    "print('   a) Ensemble from mixall kernel (MLP+XGB+RF+LGBM)')\n",
    "print('   b) Extrapolation detection with conservative blending')\n",
    "print('   c) Pre-trained molecular embeddings')\n",
    "print('   d) Domain constraints (yields must be non-negative, sum ≤ 1)')\n",
    "\n",
    "print('\\n5. REMAINING SUBMISSIONS: 4')\n",
    "print('   - Must be strategic about what to submit')\n",
    "print('   - Only submit if approach is fundamentally different')\n",
    "print('='*70)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
