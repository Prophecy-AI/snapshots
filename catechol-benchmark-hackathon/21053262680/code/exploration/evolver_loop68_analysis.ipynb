{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb0a028",
   "metadata": {},
   "source": [
    "# Loop 68 Analysis: Critical Strategy Review\n",
    "\n",
    "## Key Questions:\n",
    "1. What is the CV-LB relationship and why is the intercept so high?\n",
    "2. What approaches from public kernels might help?\n",
    "3. What fundamentally different approaches should we try?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3e1fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history - 12 successful submissions\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982, 'model': 'MLP'},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065, 'model': 'LightGBM'},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972, 'model': 'MLP'},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969, 'model': 'MLP'},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946, 'model': 'MLP'},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932, 'model': 'MLP'},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936, 'model': 'Ridge'},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913, 'model': 'Ensemble'},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893, 'model': 'MLP+ACS'},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887, 'model': 'MLP'},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877, 'model': 'GP+MLP+LGBM'},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970, 'model': 'GP+MLP+LGBM'},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f'Successful submissions: {len(df)}')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049218f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression: LB = slope * CV + intercept\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "\n",
    "print(f'Linear fit: LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'Intercept = {intercept:.4f}')\n",
    "print(f'Target = 0.0347')\n",
    "print(f'')\n",
    "print(f'CRITICAL: Intercept ({intercept:.4f}) > Target (0.0347)')\n",
    "print(f'Even with CV = 0, predicted LB would be {intercept:.4f}')\n",
    "print(f'')\n",
    "print(f'Required CV to hit target: (0.0347 - {intercept:.4f}) / {slope:.2f} = {(0.0347 - intercept) / slope:.6f}')\n",
    "print(f'This is NEGATIVE - impossible to achieve with current approach!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff72ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['cv'], df['lb'], c='blue', s=100, label='Submissions')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'Fit: LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target LB = 0.0347')\n",
    "\n",
    "# Intercept line\n",
    "plt.axhline(y=intercept, color='orange', linestyle='-.', linewidth=2, label=f'Intercept = {intercept:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score (MSE)')\n",
    "plt.ylabel('LB Score (MSE)')\n",
    "plt.title('CV vs LB Relationship - THE INTERCEPT PROBLEM')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nThe gap between intercept ({intercept:.4f}) and target (0.0347) is {intercept - 0.0347:.4f}')\n",
    "print(f'This represents {(intercept - 0.0347) / 0.0347 * 100:.1f}% of the target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would it take to reach the target?\n",
    "print('='*70)\n",
    "print('ANALYSIS: WHY IS THE INTERCEPT SO HIGH?')\n",
    "print('='*70)\n",
    "print(f'')\n",
    "print('The intercept represents the STRUCTURAL error that exists even with perfect CV.')\n",
    "print('This is caused by DISTRIBUTION SHIFT between training and test data.')\n",
    "print(f'')\n",
    "print('In this competition:')\n",
    "print('- Training: Leave-one-solvent-out CV (24 solvents for single, 13 ramps for full)')\n",
    "print('- Test: Completely unseen solvents/ramps')\n",
    "print(f'')\n",
    "print('The test solvents are fundamentally DIFFERENT from training solvents.')\n",
    "print('Our models learn patterns that work for training solvents but NOT for test solvents.')\n",
    "print(f'')\n",
    "print('='*70)\n",
    "print('WHAT COULD REDUCE THE INTERCEPT?')\n",
    "print('='*70)\n",
    "print(f'')\n",
    "print('1. BETTER MOLECULAR REPRESENTATIONS:')\n",
    "print('   - GNN that captures molecular structure (not just descriptors)')\n",
    "print('   - ChemBERTa embeddings that generalize better')\n",
    "print('   - Learned embeddings that capture solvent similarity')\n",
    "print(f'')\n",
    "print('2. UNCERTAINTY-AWARE PREDICTIONS:')\n",
    "print('   - When model is uncertain (unseen solvent), predict conservatively')\n",
    "print('   - Blend toward population mean when extrapolating')\n",
    "print(f'')\n",
    "print('3. DOMAIN ADAPTATION:')\n",
    "print('   - Use test data structure (without labels) to adapt')\n",
    "print('   - Pseudo-labeling with confident predictions')\n",
    "print(f'')\n",
    "print('4. PHYSICS-INFORMED CONSTRAINTS:')\n",
    "print('   - Arrhenius kinetics (already implemented)')\n",
    "print('   - Solvent polarity relationships')\n",
    "print('   - Mixture behavior constraints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the pending submissions\n",
    "print('='*70)\n",
    "print('PENDING SUBMISSIONS ANALYSIS')\n",
    "print('='*70)\n",
    "print(f'')\n",
    "\n",
    "pending = [\n",
    "    {'exp': 'exp_049', 'cv': 0.0081, 'model': 'CatBoost+XGBoost'},\n",
    "    {'exp': 'exp_050', 'cv': 0.0081, 'model': 'CatBoost+XGBoost Fixed'},\n",
    "    {'exp': 'exp_052', 'cv': 0.0109, 'model': 'CatBoost+XGBoost Clipped'},\n",
    "    {'exp': 'exp_053', 'cv': 0.0081, 'model': 'Exact Template'},\n",
    "    {'exp': 'exp_054', 'cv': 0.0085, 'model': 'Mixall Approach'},\n",
    "    {'exp': 'exp_055', 'cv': 0.0085, 'model': 'Minimal Submission'},\n",
    "    {'exp': 'exp_057', 'cv': 0.0093, 'model': 'Ens Model All Features'},\n",
    "    {'exp': 'exp_063', 'cv': 0.0112, 'model': 'Correct Final Cell'},\n",
    "]\n",
    "\n",
    "print('All these submissions are marked as \"pending\" but actually FAILED.')\n",
    "print('They all got \"Evaluation metric raised an unexpected error\".')\n",
    "print(f'')\n",
    "print('Common factor: All use CatBoost/XGBoost or have structural issues.')\n",
    "print(f'')\n",
    "print('Successful submissions (exp_030, exp_035) used GP+MLP+LGBM ensemble.')\n",
    "print(f'')\n",
    "print('HYPOTHESIS: CatBoost/XGBoost may have compatibility issues with Kaggle evaluation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the public kernels tell us?\n",
    "print('='*70)\n",
    "print('INSIGHTS FROM PUBLIC KERNELS')\n",
    "print('='*70)\n",
    "print(f'')\n",
    "print('1. \"mixall\" kernel (9 votes):')\n",
    "print('   - Uses GroupKFold (5 splits) instead of Leave-One-Out')\n",
    "print('   - Ensemble: MLP + XGBoost + RF + LightGBM')\n",
    "print('   - Claims \"good CV/LB\" with only 2m 15s runtime')\n",
    "print('   - KEY INSIGHT: Different CV scheme may have different CV-LB relationship!')\n",
    "print(f'')\n",
    "print('2. \"System Malfunction V1\" (29 votes):')\n",
    "print('   - Basic MLP with Spange descriptors')\n",
    "print('   - Standard Leave-One-Out CV')\n",
    "print('   - Similar to our baseline')\n",
    "print(f'')\n",
    "print('3. \"Alchemy Baseline\" (12 votes):')\n",
    "print('   - Multi-GPU optimized MLP')\n",
    "print('   - 3-seed ensemble per fold')\n",
    "print('   - Numeric feature engineering (rt², temp², log, interaction)')\n",
    "print('   - Huber loss, cosine annealing, early stopping')\n",
    "print(f'')\n",
    "print('4. \"Arrhenius Kinetics + TTA\" (39 votes):')\n",
    "print('   - Similar to our approach')\n",
    "print('   - Score: 0.09831 (similar to our best 0.0877)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3960500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The benchmark achieved MSE 0.0039 - how?\n",
    "print('='*70)\n",
    "print('THE BENCHMARK MYSTERY')\n",
    "print('='*70)\n",
    "print(f'')\n",
    "print('The competition mentions the benchmark achieved MSE 0.0039.')\n",
    "print('This is 22x better than our best LB (0.0877)!')\n",
    "print(f'')\n",
    "print('From the competition description:')\n",
    "print('\"imputing any missing values using a multi-task GP\"')\n",
    "print(f'')\n",
    "print('This suggests the benchmark used a MULTI-TASK GP approach.')\n",
    "print('Multi-task GPs can share information across tasks (solvents).')\n",
    "print('This could help with generalization to unseen solvents.')\n",
    "print(f'')\n",
    "print('HOWEVER: The benchmark may have used different evaluation.')\n",
    "print('The 0.0039 might be on a different test set or with different CV.')\n",
    "print(f'')\n",
    "print('Our target is 0.0347, which is ~9x worse than benchmark.')\n",
    "print('This suggests the target is achievable but requires different approach.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2955cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print('='*70)\n",
    "print('SUMMARY AND RECOMMENDATIONS')\n",
    "print('='*70)\n",
    "print(f'')\n",
    "print('CURRENT STATUS:')\n",
    "print(f'  - Best CV: 0.0081 (exp_049, but submission failed)')\n",
    "print(f'  - Best LB: 0.0877 (exp_030, GP+MLP+LGBM)')\n",
    "print(f'  - Target: 0.0347')\n",
    "print(f'  - Gap: {0.0877 - 0.0347:.4f} ({(0.0877 - 0.0347) / 0.0347 * 100:.1f}%)')\n",
    "print(f'')\n",
    "print('THE PROBLEM:')\n",
    "print(f'  - CV-LB relationship: LB = 4.31*CV + 0.0525')\n",
    "print(f'  - Intercept (0.0525) > Target (0.0347)')\n",
    "print(f'  - This means NO amount of CV improvement can reach target!')\n",
    "print(f'')\n",
    "print('REQUIRED PIVOT:')\n",
    "print(f'  1. STOP optimizing tabular models (MLP, LGBM, XGB, CatBoost)')\n",
    "print(f'  2. Try approaches that CHANGE the CV-LB relationship')\n",
    "print(f'  3. Focus on REDUCING THE INTERCEPT, not improving CV')\n",
    "print(f'')\n",
    "print('RECOMMENDED APPROACHES:')\n",
    "print(f'  1. Multi-task GP (as mentioned in benchmark)')\n",
    "print(f'  2. GNN with molecular graphs')\n",
    "print(f'  3. Uncertainty-weighted predictions')\n",
    "print(f'  4. Domain adaptation techniques')\n",
    "print(f'')\n",
    "print('IMMEDIATE PRIORITY:')\n",
    "print(f'  - Submit exp_064 (GP+MLP+LGBM replication) to verify submissions work')\n",
    "print(f'  - If successful, pivot to intercept-reducing approaches')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
