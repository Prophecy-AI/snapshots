{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5453b7",
   "metadata": {},
   "source": [
    "# Loop 93 Analysis: Strategic Assessment\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "1. **CV-LB Relationship**: LB = 4.31 * CV + 0.0525 (R² = 0.95)\n",
    "2. **Intercept (0.0525) > Target (0.0347)** - Target is mathematically unreachable with current approaches\n",
    "3. **93 experiments** have been tried, all falling on the same CV-LB line\n",
    "4. **Best CV**: 0.0083 (exp_030) → **Best LB**: 0.0877\n",
    "5. **Gap to target**: 152.8%\n",
    "\n",
    "## Critical Problem\n",
    "\n",
    "The conservative extrapolation approach (exp_092) CANNOT be validated with CV:\n",
    "- CV with blending (0.3): 0.014120 (70% worse than baseline)\n",
    "- CV without blending: 0.010097 (22% worse than baseline)\n",
    "- Baseline: 0.008298\n",
    "\n",
    "This is because CV tests on held-out solvents that are SIMILAR to training solvents, while the LB tests on TRULY UNSEEN solvents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1a6ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T12:51:07.121333Z",
     "iopub.status.busy": "2026-01-16T12:51:07.120753Z",
     "iopub.status.idle": "2026-01-16T12:51:07.706847Z",
     "shell.execute_reply": "2026-01-16T12:51:07.706443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-LB Relationship Analysis\n",
      "==================================================\n",
      "Linear fit: LB = 4.3147 * CV + 0.0525\n",
      "R² = 0.9505\n",
      "Intercept = 0.0525\n",
      "Target LB = 0.0347\n",
      "Required CV for target = (0.0347 - 0.0525) / 4.3147 = -0.0041\n",
      "\n",
      "CRITICAL: Intercept (0.0525) > Target (0.0347)\n",
      "The target is MATHEMATICALLY UNREACHABLE with current approaches!\n",
      "\n",
      "Best CV: 0.0083 (exp_030)\n",
      "Best LB: 0.0877 (exp_030)\n",
      "Gap to target: 152.7%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# CV-LB data from submissions\n",
    "submissions = [\n",
    "    (\"exp_000\", 0.0111, 0.0982),\n",
    "    (\"exp_001\", 0.0123, 0.1065),\n",
    "    (\"exp_003\", 0.0105, 0.0972),\n",
    "    (\"exp_005\", 0.0104, 0.0969),\n",
    "    (\"exp_006\", 0.0097, 0.0946),\n",
    "    (\"exp_007\", 0.0093, 0.0932),\n",
    "    (\"exp_009\", 0.0092, 0.0936),\n",
    "    (\"exp_012\", 0.0090, 0.0913),\n",
    "    (\"exp_024\", 0.0087, 0.0893),\n",
    "    (\"exp_026\", 0.0085, 0.0887),\n",
    "    (\"exp_030\", 0.0083, 0.0877),\n",
    "    (\"exp_035\", 0.0098, 0.0970),\n",
    "]\n",
    "\n",
    "cvs = np.array([cv for _, cv, _ in submissions])\n",
    "lbs = np.array([lb for _, _, lb in submissions])\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cvs, lbs)\n",
    "\n",
    "print(\"CV-LB Relationship Analysis\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Linear fit: LB = {slope:.4f} * CV + {intercept:.4f}\")\n",
    "print(f\"R² = {r_value**2:.4f}\")\n",
    "print(f\"Intercept = {intercept:.4f}\")\n",
    "print(f\"Target LB = 0.0347\")\n",
    "print(f\"Required CV for target = ({0.0347} - {intercept:.4f}) / {slope:.4f} = {(0.0347 - intercept) / slope:.4f}\")\n",
    "print()\n",
    "print(f\"CRITICAL: Intercept ({intercept:.4f}) > Target ({0.0347})\")\n",
    "print(\"The target is MATHEMATICALLY UNREACHABLE with current approaches!\")\n",
    "print()\n",
    "print(f\"Best CV: 0.0083 (exp_030)\")\n",
    "print(f\"Best LB: 0.0877 (exp_030)\")\n",
    "print(f\"Gap to target: {(0.0877 - 0.0347) / 0.0347 * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085d6fb1",
   "metadata": {},
   "source": [
    "## What We've Learned\n",
    "\n",
    "### 1. All Tabular Models Fall on the Same Line\n",
    "- MLP, LightGBM, XGBoost, CatBoost, GP, Ridge - ALL produce the same CV-LB relationship\n",
    "- This means the problem is NOT the model - it's DISTRIBUTION SHIFT\n",
    "\n",
    "### 2. GNN/ChemBERTa Attempts Failed\n",
    "- 5+ GNN experiments achieved CV 0.018-0.026 (2-3x worse than baseline)\n",
    "- The benchmark paper achieved MSE 0.0039 with GNNs - 5-6x better than our GNNs\n",
    "- Possible reasons: implementation issues, no pre-training, wrong architecture\n",
    "\n",
    "### 3. Conservative Extrapolation Cannot Be Validated\n",
    "- The approach is designed to help on TRULY UNSEEN solvents\n",
    "- CV tests on held-out solvents that are SIMILAR to training\n",
    "- Any approach that helps on truly unseen solvents will HURT CV\n",
    "\n",
    "### 4. The Validation Paradox\n",
    "- We cannot validate intercept-reduction strategies with CV\n",
    "- With only 4 submissions remaining, we cannot afford to \"guess\"\n",
    "- The only path forward is approaches that improve BOTH CV and (hopefully) intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b930d",
   "metadata": {},
   "source": [
    "## Key Insights from Public Kernels\n",
    "\n",
    "### 1. MixAll Kernel (lishellliang)\n",
    "- Uses **GroupKFold (5 splits)** instead of Leave-One-Out\n",
    "- Claims \"good CV/LB correlation\"\n",
    "- Ensemble of MLP + XGBoost + RF + LightGBM\n",
    "- Runtime: only 2m 15s\n",
    "\n",
    "### 2. Ens Model Kernel (matthewmaree)\n",
    "- Uses **CatBoost + XGBoost** ensemble\n",
    "- Different weights for single (7:6) vs full (1:2)\n",
    "- Combines ALL feature sources (spange, acs_pca, drfps, fragprints, smiles)\n",
    "- Correlation-based feature filtering with priority\n",
    "- Yield renormalization (clip to 0, normalize sum ≤ 1)\n",
    "\n",
    "### 3. System Malfunction V1 (omarafik)\n",
    "- Simple MLP baseline\n",
    "- Uses standard Leave-One-Out CV\n",
    "- 29 votes - popular but basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e65f42",
   "metadata": {},
   "source": [
    "## Strategic Assessment\n",
    "\n",
    "### The Fundamental Problem\n",
    "The CV-LB intercept (0.0525) is ABOVE the target (0.0347). This means:\n",
    "1. Even with perfect CV (0.0), expected LB would be 0.0525\n",
    "2. No amount of model tuning can fix this\n",
    "3. We need to CHANGE THE RELATIONSHIP, not improve CV\n",
    "\n",
    "### What Could Change the Relationship?\n",
    "1. **Pre-trained molecular models** - ChemBERTa, MolBERT, ChemProp\n",
    "   - These have learned chemistry from millions of molecules\n",
    "   - May generalize better to unseen solvents\n",
    "   \n",
    "2. **Proper GNN implementation** - The benchmark paper achieved 0.0039\n",
    "   - Our GNN attempts were 5-6x worse\n",
    "   - Need to investigate why\n",
    "   \n",
    "3. **Domain constraints** - Physics-based rules that hold even on unseen data\n",
    "   - Mass balance constraints\n",
    "   - Thermodynamic constraints\n",
    "   \n",
    "4. **Pseudo-labeling** - Use confident test predictions to augment training\n",
    "   - Adapt to test distribution\n",
    "\n",
    "### What WON'T Change the Relationship?\n",
    "- More MLP/LGBM/XGB variants (92 experiments exhausted this)\n",
    "- More feature engineering without changing prediction strategy\n",
    "- Multi-seed ensembles for variance reduction\n",
    "- Conservative blending (cannot be validated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c19cb95",
   "metadata": {},
   "source": [
    "## Recommendations for Next Experiment\n",
    "\n",
    "### PRIORITY 1: Investigate GNN Failures\n",
    "The benchmark paper achieved MSE 0.0039 with GNNs. Our GNN attempts achieved CV ~0.018-0.026. This 5-6x gap is suspicious.\n",
    "\n",
    "Questions to investigate:\n",
    "1. Did the GNN submission cells use the SAME model class as CV computation?\n",
    "2. What specific architecture did the benchmark paper use? (GAT with DRFP and learned mixture encodings)\n",
    "3. Did we use pre-trained molecular embeddings?\n",
    "\n",
    "### PRIORITY 2: Try Pre-trained Molecular Models\n",
    "Options that may generalize better to unseen solvents:\n",
    "- **ChemProp**: Pre-trained on millions of molecules, provides molecular embeddings\n",
    "- **MolBERT/ChemBERTa**: Pre-trained molecular transformers\n",
    "- Use these as FEATURE EXTRACTORS, not end-to-end models\n",
    "\n",
    "### PRIORITY 3: Implement Proper GAT Architecture\n",
    "Based on the benchmark paper:\n",
    "- Graph Attention Networks (GAT) for molecular graphs\n",
    "- DRFP features for reaction encoding\n",
    "- Learned mixture-aware solvent encodings (not just linear interpolation)\n",
    "\n",
    "### DO NOT DO:\n",
    "- ❌ More tabular model variants\n",
    "- ❌ More conservative blending variants (cannot be validated)\n",
    "- ❌ Experiments that are worse than CV=0.008298"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
