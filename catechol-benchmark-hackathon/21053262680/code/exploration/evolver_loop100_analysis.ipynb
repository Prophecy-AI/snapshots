{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715b27bc",
   "metadata": {},
   "source": [
    "# Loop 100 Analysis: Critical Assessment\n",
    "\n",
    "## Key Findings from 100 Experiments:\n",
    "1. CV-LB relationship: LB = 4.31 × CV + 0.0525 (R² = 0.95)\n",
    "2. Intercept (0.0525) > Target (0.0347) - mathematically unreachable with current approaches\n",
    "3. Conservative blending HURTS CV - hypothesis invalidated\n",
    "4. All tabular models (MLP, LGBM, XGB, CatBoost, GP, Ridge) fall on the SAME line\n",
    "5. GNN attempts failed (CV 0.018-0.068)\n",
    "6. ChemBERTa attempts failed\n",
    "\n",
    "## What We Need to Investigate:\n",
    "1. Do the public kernels (mixall, ens-model) have a DIFFERENT CV-LB relationship?\n",
    "2. What specific techniques do they use that we haven't tried?\n",
    "3. Is there a fundamentally different approach we're missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "    {'exp': 'exp_073', 'cv': 0.0084, 'lb': 0.1451},  # Outlier - similarity weighting disaster\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f\"Total submissions with LB: {len(df)}\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b4947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the outlier (exp_073) for linear fit\n",
    "df_clean = df[df['exp'] != 'exp_073'].copy()\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_clean['cv'], df_clean['lb'])\n",
    "\n",
    "print(f\"\\n=== CV-LB LINEAR RELATIONSHIP ===\")\n",
    "print(f\"LB = {slope:.2f} × CV + {intercept:.4f}\")\n",
    "print(f\"R² = {r_value**2:.4f}\")\n",
    "print(f\"\\nIntercept: {intercept:.4f}\")\n",
    "print(f\"Target LB: 0.0347\")\n",
    "print(f\"Intercept > Target? {intercept > 0.0347}\")\n",
    "print(f\"\\nRequired CV for target: (0.0347 - {intercept:.4f}) / {slope:.2f} = {(0.0347 - intercept) / slope:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4654b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV vs LB\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_clean['cv'], df_clean['lb'], s=100, alpha=0.7, label='Submissions')\n",
    "plt.scatter(df[df['exp'] == 'exp_073']['cv'], df[df['exp'] == 'exp_073']['lb'], \n",
    "            s=100, c='red', marker='x', label='Outlier (exp_073)')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}×CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='g', linestyle=':', linewidth=2, label='Target LB = 0.0347')\n",
    "\n",
    "# Best CV point\n",
    "best_cv = df_clean['cv'].min()\n",
    "best_lb = df_clean[df_clean['cv'] == best_cv]['lb'].values[0]\n",
    "plt.scatter([best_cv], [best_lb], s=200, c='gold', edgecolors='black', marker='*', \n",
    "            label=f'Best: CV={best_cv:.4f}, LB={best_lb:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship (100 Experiments)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPlot saved to /home/code/exploration/cv_lb_relationship.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffe404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what the public kernels do differently\n",
    "print(\"=\" * 60)\n",
    "print(\"ANALYSIS: PUBLIC KERNEL DIFFERENCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. MIXALL KERNEL:\")\n",
    "print(\"   - Uses GroupKFold (5 splits) instead of Leave-One-Out\")\n",
    "print(\"   - Uses MLP + XGBoost + RandomForest + LightGBM ensemble\")\n",
    "print(\"   - Uses spange_descriptors features\")\n",
    "print(\"   - Uses TTA for mixtures\")\n",
    "print(\"   - KEY DIFFERENCE: Different validation scheme!\")\n",
    "\n",
    "print(\"\\n2. ENS-MODEL KERNEL:\")\n",
    "print(\"   - Uses CatBoost + XGBoost ensemble\")\n",
    "print(\"   - Uses ALL feature sources (spange, acs_pca, drfps, fragprints, smiles)\")\n",
    "print(\"   - Uses correlation-based filtering with priority\")\n",
    "print(\"   - Different weights for single vs full data (7:6 vs 1:2)\")\n",
    "print(\"   - Uses Leave-One-Out validation (same as us)\")\n",
    "print(\"   - KEY DIFFERENCE: Feature combination and filtering!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3158b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we've tried vs what we haven't\n",
    "print(\"=\" * 60)\n",
    "print(\"WHAT WE'VE TRIED (100 experiments)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tried = [\n",
    "    \"MLP with various architectures\",\n",
    "    \"LightGBM\",\n",
    "    \"XGBoost\",\n",
    "    \"CatBoost\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Ridge Regression\",\n",
    "    \"Random Forest\",\n",
    "    \"GNN (multiple attempts - all failed)\",\n",
    "    \"ChemBERTa (multiple attempts - all failed)\",\n",
    "    \"Spange descriptors\",\n",
    "    \"DRFP features\",\n",
    "    \"ACS PCA features\",\n",
    "    \"Fragprints\",\n",
    "    \"Various ensembles (MLP+LGBM+GP, CatBoost+XGBoost, etc.)\",\n",
    "    \"Conservative blending toward mean (FAILED - hurts CV)\",\n",
    "    \"Similarity weighting (FAILED - exp_073 disaster)\",\n",
    "    \"Yield normalization\",\n",
    "    \"Pseudo-labeling\",\n",
    "    \"GroupKFold validation\",\n",
    "]\n",
    "\n",
    "for i, t in enumerate(tried, 1):\n",
    "    print(f\"  {i}. {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we HAVEN'T tried or haven't tried CORRECTLY\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WHAT WE HAVEN'T TRIED OR HAVEN'T TRIED CORRECTLY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "not_tried = [\n",
    "    \"EXACT replication of ens-model kernel (with correlation filtering)\",\n",
    "    \"EXACT replication of mixall kernel (with GroupKFold)\",\n",
    "    \"Combining ALL feature sources with priority-based filtering\",\n",
    "    \"Different ensemble weights for single vs full data\",\n",
    "    \"Domain constraints (mass balance: P2 + P3 + SM ≈ 1)\",\n",
    "    \"Kinetic constraints (Arrhenius-like temperature dependence)\",\n",
    "    \"Physical bounds enforcement (yields in [0, 1])\",\n",
    "]\n",
    "\n",
    "for i, t in enumerate(not_tried, 1):\n",
    "    print(f\"  {i}. {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6713f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key insight: We need to replicate the public kernels EXACTLY\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHT: REPLICATE PUBLIC KERNELS EXACTLY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "The public kernels (mixall, ens-model) have achieved good LB scores.\n",
    "We need to check if they have a DIFFERENT CV-LB relationship.\n",
    "\n",
    "If they fall on the SAME line (LB = 4.31×CV + 0.0525), then:\n",
    "- The target is truly unreachable with current approaches\n",
    "- We need fundamentally different methods\n",
    "\n",
    "If they fall on a DIFFERENT line (lower intercept), then:\n",
    "- We need to understand WHAT makes them different\n",
    "- Replicate that approach exactly\n",
    "\n",
    "NEXT STEPS:\n",
    "1. Replicate ens-model kernel EXACTLY (CatBoost+XGBoost with all features)\n",
    "2. Compute local CV score\n",
    "3. Submit to get LB score\n",
    "4. Check if it falls on the same CV-LB line\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c039af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LOOP 100 SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\"\"\n",
    "After 100 experiments:\n",
    "- Best CV: 0.0081 (exp_049/050/053)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target LB: 0.0347\n",
    "- Gap: {(0.0877 - 0.0347) / 0.0347 * 100:.1f}%\n",
    "\n",
    "CV-LB Relationship:\n",
    "- LB = 4.31 × CV + 0.0525 (R² = 0.95)\n",
    "- Intercept (0.0525) > Target (0.0347)\n",
    "- Required CV for target: -0.0041 (IMPOSSIBLE)\n",
    "\n",
    "Key Findings:\n",
    "1. All tabular models fall on the SAME CV-LB line\n",
    "2. Conservative blending HURTS CV (hypothesis invalidated)\n",
    "3. GNN and ChemBERTa attempts failed\n",
    "4. The intercept problem is STRUCTURAL\n",
    "\n",
    "Recommendation:\n",
    "1. Replicate ens-model kernel EXACTLY\n",
    "2. Check if it has a different CV-LB relationship\n",
    "3. If yes, understand what makes it different\n",
    "4. If no, the target may require fundamentally different methods\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save findings\n",
    "findings = {\n",
    "    'cv_lb_slope': slope,\n",
    "    'cv_lb_intercept': intercept,\n",
    "    'cv_lb_r_squared': r_value**2,\n",
    "    'best_cv': 0.0081,\n",
    "    'best_lb': 0.0877,\n",
    "    'target_lb': 0.0347,\n",
    "    'gap_percent': (0.0877 - 0.0347) / 0.0347 * 100,\n",
    "    'required_cv_for_target': (0.0347 - intercept) / slope,\n",
    "    'intercept_gt_target': intercept > 0.0347,\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('/home/code/exploration/loop100_findings.json', 'w') as f:\n",
    "    json.dump(findings, f, indent=2)\n",
    "\n",
    "print(\"Findings saved to /home/code/exploration/loop100_findings.json\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
