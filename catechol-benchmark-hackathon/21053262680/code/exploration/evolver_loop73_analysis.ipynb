{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f1deae",
   "metadata": {},
   "source": [
    "# Loop 73 Analysis: CV-LB Relationship and Strategy Assessment\n",
    "\n",
    "## Key Questions:\n",
    "1. What is the current CV-LB relationship?\n",
    "2. Why did GNN and ChemBERTa fail so badly?\n",
    "3. What approaches haven't been tried that could break the CV-LB line?\n",
    "4. What are the top kernels doing that we're not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498033d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982, 'model': 'Baseline MLP'},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065, 'model': 'LightGBM'},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972, 'model': 'Combined Spange+DRFP'},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969, 'model': 'Large Ensemble'},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946, 'model': 'Simpler Model'},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932, 'model': 'Even Simpler'},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936, 'model': 'Single Layer'},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913, 'model': 'Compliant Ensemble'},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893, 'model': 'ACS PCA Fixed'},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887, 'model': 'Weighted Loss'},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877, 'model': 'GP+MLP+LGBM (BEST)'},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970, 'model': 'Minimal Features'},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submission History:')\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601f8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV-LB Relationship Analysis\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "\n",
    "print(f'\\nCV-LB Linear Regression:')\n",
    "print(f'  LB = {slope:.4f} * CV + {intercept:.4f}')\n",
    "print(f'  R² = {r_value**2:.4f}')\n",
    "print(f'  p-value = {p_value:.6f}')\n",
    "\n",
    "# Target analysis\n",
    "target_lb = 0.0347\n",
    "required_cv = (target_lb - intercept) / slope\n",
    "print(f'\\nTarget Analysis:')\n",
    "print(f'  Target LB: {target_lb}')\n",
    "print(f'  Intercept: {intercept:.4f}')\n",
    "print(f'  Required CV to hit target: {required_cv:.4f}')\n",
    "print(f'  Current best CV: {df[\"cv\"].min():.4f}')\n",
    "print(f'  Gap: {df[\"cv\"].min() - required_cv:.4f}')\n",
    "\n",
    "if required_cv < 0:\n",
    "    print('\\n⚠️ CRITICAL: Required CV is NEGATIVE - target is UNREACHABLE with current approach!')\n",
    "    print('   The intercept alone (0.0528) is HIGHER than the target (0.0347)!')\n",
    "    print('   We need approaches that REDUCE THE INTERCEPT, not just improve CV.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a78ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV vs LB\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cv, lb, c='blue', s=100, alpha=0.7, label='Submissions')\n",
    "\n",
    "# Regression line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.3f})')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=target_lb, color='green', linestyle=':', linewidth=2, label=f'Target LB = {target_lb}')\n",
    "\n",
    "# Best submission\n",
    "best_idx = df['lb'].idxmin()\n",
    "plt.scatter([df.loc[best_idx, 'cv']], [df.loc[best_idx, 'lb']], c='red', s=200, marker='*', label=f'Best: {df.loc[best_idx, \"model\"]}')\n",
    "\n",
    "plt.xlabel('CV Score (MSE)', fontsize=12)\n",
    "plt.ylabel('LB Score (MSE)', fontsize=12)\n",
    "plt.title('CV vs LB Relationship - All Submissions', fontsize=14)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship_loop73.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print('\\nPlot saved to /home/code/exploration/cv_lb_relationship_loop73.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76526e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recent experiments analysis\n",
    "recent_experiments = [\n",
    "    {'exp': 'exp_068', 'name': 'Multitask GP', 'cv': 0.010243, 'vs_baseline': '23% worse'},\n",
    "    {'exp': 'exp_069', 'name': 'GroupKFold validation', 'cv': 0.021210, 'vs_baseline': '156% worse'},\n",
    "    {'exp': 'exp_070', 'name': 'Ens model analysis', 'cv': 0.021210, 'vs_baseline': '156% worse'},\n",
    "    {'exp': 'exp_071', 'name': 'Label rescaling', 'cv': 0.008935, 'vs_baseline': '8% worse'},\n",
    "    {'exp': 'exp_072', 'name': 'GNN (GCNConv)', 'cv': 0.025649, 'vs_baseline': '209% worse'},\n",
    "    {'exp': 'chemberta', 'name': 'ChemBERTa', 'cv': 0.022464, 'vs_baseline': '171% worse'},\n",
    "]\n",
    "\n",
    "print('Recent Experiments (vs baseline CV 0.008298):')\n",
    "for exp in recent_experiments:\n",
    "    print(f\"  {exp['exp']}: {exp['name']} - CV {exp['cv']:.6f} ({exp['vs_baseline']})\")\n",
    "\n",
    "print('\\n⚠️ ALL recent experiments made things WORSE!')\n",
    "print('   GNN and ChemBERTa performed MUCH worse than Spange descriptors.')\n",
    "print('   This suggests the Spange descriptors ARE the right representation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1752f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('\\n=== APPROACHES NOT YET TRIED ===')\n",
    "print()\n",
    "print('1. HYBRID Spange + GNN/ChemBERTa (combine, not replace)')\n",
    "print('   - GNN/ChemBERTa alone failed, but might add complementary info')\n",
    "print('   - Concatenate Spange (13) + GNN embedding (16-32) + kinetics (5)')\n",
    "print()\n",
    "print('2. Similarity-based prediction weighting')\n",
    "print('   - Detect when test solvent is dissimilar to training')\n",
    "print('   - Weight predictions toward mean for dissimilar solvents')\n",
    "print('   - This could REDUCE THE INTERCEPT')\n",
    "print()\n",
    "print('3. Fix CatBoost/XGBoost submission issues')\n",
    "print('   - exp_049-063 all failed with evaluation errors')\n",
    "print('   - matthewmaree kernel uses CatBoost+XGBoost ensemble')\n",
    "print('   - Best CV achieved was 0.008092 (better than baseline!)')\n",
    "print()\n",
    "print('4. Pseudo-labeling / Self-training')\n",
    "print('   - Use confident predictions on test set to augment training')\n",
    "print('   - Could help with distribution shift')\n",
    "print()\n",
    "print('5. Domain-specific constraints')\n",
    "print('   - Yields must sum to <= 1')\n",
    "print('   - Enforce physical constraints in predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5760e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight from matthewmaree kernel\n",
    "print('\\n=== KEY INSIGHTS FROM TOP KERNELS ===')\n",
    "print()\n",
    "print('matthewmaree/ens-model kernel:')\n",
    "print('  - Uses CatBoost + XGBoost ensemble (NOT MLP)')\n",
    "print('  - Combines ALL features: Spange + ACS + DRFP + Fragprints + SMILES')\n",
    "print('  - Applies correlation-based feature filtering (threshold=0.90)')\n",
    "print('  - Uses feature priority: spange > acs > drfps > frag > smiles')\n",
    "print('  - Adds numeric features: T_x_RT, RT_log, T_inv, RT_scaled')\n",
    "print('  - Different weights for single vs full: single=(7:6), full=(1:2)')\n",
    "print()\n",
    "print('lishellliang/mixall kernel:')\n",
    "print('  - Uses GroupKFold (5 splits) instead of Leave-One-Out')\n",
    "print('  - Ensemble of MLP + XGBoost + RF + LightGBM')\n",
    "print('  - Optuna hyperparameter optimization')\n",
    "print()\n",
    "print('⚠️ We have NOT successfully submitted a CatBoost/XGBoost model!')\n",
    "print('   All attempts (exp_049-063) failed with evaluation errors.')\n",
    "print('   This is a MAJOR gap in our exploration.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0648d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print('\\n' + '='*60)\n",
    "print('LOOP 73 SUMMARY')\n",
    "print('='*60)\n",
    "print()\n",
    "print('CURRENT STATUS:')\n",
    "print(f'  Best CV: 0.0083 (exp_030 GP+MLP+LGBM)')\n",
    "print(f'  Best LB: 0.0877 (exp_030)')\n",
    "print(f'  Target: 0.0347')\n",
    "print(f'  Gap: 0.0530 (152.8%)')\n",
    "print()\n",
    "print('CV-LB RELATIONSHIP:')\n",
    "print(f'  LB = 4.29 * CV + 0.0528 (R² = 0.95)')\n",
    "print(f'  Intercept (0.0528) > Target (0.0347)')\n",
    "print(f'  Required CV: -0.0042 (IMPOSSIBLE)')\n",
    "print()\n",
    "print('WHAT FAILED:')\n",
    "print('  - GNN (GCNConv): CV 0.0256 (209% worse)')\n",
    "print('  - ChemBERTa: CV 0.0225 (171% worse)')\n",
    "print('  - Multitask GP: CV 0.0102 (23% worse)')\n",
    "print('  - Label rescaling: CV 0.0089 (8% worse)')\n",
    "print('  - GroupKFold: CV 0.0212 (156% worse)')\n",
    "print()\n",
    "print('WHAT HASN\\'T BEEN TRIED:')\n",
    "print('  1. Fix CatBoost/XGBoost submission (best CV 0.008092)')\n",
    "print('  2. Hybrid Spange + GNN/ChemBERTa features')\n",
    "print('  3. Similarity-based prediction weighting')\n",
    "print('  4. Pseudo-labeling for distribution adaptation')\n",
    "print()\n",
    "print('TOP PRIORITY:')\n",
    "print('  Submit a working CatBoost/XGBoost model to see if it has')\n",
    "print('  a DIFFERENT CV-LB relationship than MLP/GP/LGBM.')\n",
    "print('  The matthewmaree kernel uses this approach successfully.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
