{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f05fcae",
   "metadata": {},
   "source": [
    "# Loop 112 Analysis: CV-LB Relationship and Path Forward\n",
    "\n",
    "## Key Questions\n",
    "1. What is the current CV-LB relationship?\n",
    "2. What approaches have been tried?\n",
    "3. What approaches might CHANGE the relationship (not just improve CV)?\n",
    "4. What's the best path forward with 4 submissions remaining?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62986bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history with verified LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982, 'model': 'MLP'},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065, 'model': 'LightGBM'},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972, 'model': 'MLP+DRFP'},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969, 'model': 'MLP Ensemble'},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946, 'model': 'Simpler MLP'},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932, 'model': 'Even Simpler'},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936, 'model': 'Ridge'},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913, 'model': 'Simple Ensemble'},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893, 'model': 'ACS PCA'},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887, 'model': 'Weighted Loss'},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877, 'model': 'GP Ensemble'},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970, 'model': 'Lower GP Weight'},\n",
    "    {'exp': 'exp_073', 'cv': 0.0084, 'lb': 0.1451, 'model': 'RF Ensemble (OUTLIER)'},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f\"Total submissions with LB: {len(df)}\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0270ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outlier (exp_073 had submission format issue)\n",
    "df_clean = df[df['exp'] != 'exp_073'].copy()\n",
    "\n",
    "# Fit linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_clean['cv'], df_clean['lb'])\n",
    "\n",
    "print(f\"\\nCV-LB Relationship (excluding outlier):\")\n",
    "print(f\"LB = {slope:.3f} × CV + {intercept:.4f}\")\n",
    "print(f\"R² = {r_value**2:.4f}\")\n",
    "print(f\"\\nIntercept: {intercept:.4f}\")\n",
    "print(f\"Target LB: 0.0347\")\n",
    "print(f\"Gap: {intercept - 0.0347:.4f}\")\n",
    "print(f\"\\nRequired CV to hit target: ({0.0347} - {intercept:.4f}) / {slope:.3f} = {(0.0347 - intercept) / slope:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0750bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot all points\n",
    "plt.scatter(df_clean['cv'], df_clean['lb'], c='blue', s=100, label='Submissions')\n",
    "\n",
    "# Plot outlier\n",
    "outlier = df[df['exp'] == 'exp_073']\n",
    "if len(outlier) > 0:\n",
    "    plt.scatter(outlier['cv'], outlier['lb'], c='red', s=100, marker='x', label='Outlier (format issue)')\n",
    "\n",
    "# Plot regression line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'b--', alpha=0.5, label=f'LB = {slope:.2f}×CV + {intercept:.4f}')\n",
    "\n",
    "# Plot target\n",
    "plt.axhline(y=0.0347, color='green', linestyle='--', label='Target (0.0347)')\n",
    "\n",
    "# Plot intercept\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', alpha=0.7, label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship - All Submissions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n⚠️ CRITICAL: Intercept ({intercept:.4f}) > Target ({0.0347})\")\n",
    "print(f\"The target is UNREACHABLE with approaches that follow this line!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1260b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would it take to reach the target?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS: What would it take to reach the target?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Option 1: Improve CV along the same line\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f\"\\n1. If we stay on the same line:\")\n",
    "print(f\"   Required CV: {required_cv:.6f}\")\n",
    "print(f\"   Current best CV: 0.0081\")\n",
    "print(f\"   This is IMPOSSIBLE (negative CV)\")\n",
    "\n",
    "# Option 2: Change the intercept\n",
    "print(f\"\\n2. If we change the intercept:\")\n",
    "print(f\"   Current intercept: {intercept:.4f}\")\n",
    "print(f\"   Target LB: 0.0347\")\n",
    "print(f\"   Need to reduce intercept by: {intercept - 0.0347:.4f}\")\n",
    "print(f\"   That's a {(intercept - 0.0347) / intercept * 100:.1f}% reduction in intercept\")\n",
    "\n",
    "# Option 3: Change the slope\n",
    "print(f\"\\n3. If we change the slope (keeping intercept):\")\n",
    "print(f\"   Current slope: {slope:.3f}\")\n",
    "print(f\"   With best CV (0.0081), need slope: {(0.0347 - intercept) / 0.0081:.3f}\")\n",
    "print(f\"   This requires NEGATIVE slope (impossible)\")\n",
    "\n",
    "# Option 4: Change both\n",
    "print(f\"\\n4. If we change both slope and intercept:\")\n",
    "print(f\"   Example: If intercept = 0.03, slope = 0.5\")\n",
    "print(f\"   With CV = 0.0081, LB = 0.03 + 0.5 × 0.0081 = {0.03 + 0.5 * 0.0081:.4f}\")\n",
    "print(f\"   This would beat the target!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf9d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches might change the CV-LB relationship?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"APPROACHES THAT MIGHT CHANGE THE CV-LB RELATIONSHIP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "approaches = [\n",
    "    (\"1. Transductive Learning\", \"Use test data structure (without labels) to adapt predictions\"),\n",
    "    (\"2. Pseudo-labeling\", \"Use confident predictions to augment training\"),\n",
    "    (\"3. Conservative Blending\", \"Blend toward training mean for dissimilar samples\"),\n",
    "    (\"4. Uncertainty Weighting\", \"Weight predictions by confidence\"),\n",
    "    (\"5. Domain Constraints\", \"Apply chemistry-based constraints that generalize\"),\n",
    "    (\"6. GNN with Correct Format\", \"Previous GNN had model class mismatch\"),\n",
    "    (\"7. ChemBERTa Embeddings\", \"Use pretrained chemical language model\"),\n",
    "]\n",
    "\n",
    "for name, desc in approaches:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"   {desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's been tried\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENTS TRIED (last 20)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "exp_dirs = sorted([d for d in os.listdir('/home/code/experiments') if d.startswith(('0', '1'))])\n",
    "for exp_dir in exp_dirs[-20:]:\n",
    "    metrics_path = f'/home/code/experiments/{exp_dir}/metrics.json'\n",
    "    if os.path.exists(metrics_path):\n",
    "        with open(metrics_path) as f:\n",
    "            metrics = json.load(f)\n",
    "        cv = metrics.get('cv_score', metrics.get('combined_mse', 'N/A'))\n",
    "        notes = metrics.get('notes', '')[:60]\n",
    "        print(f\"{exp_dir}: CV={cv:.6f if isinstance(cv, float) else cv} | {notes}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b622b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The evaluator identified that exp_110 had a featurization mismatch\n",
    "# exp_108 used weighted average for mixtures (CV=0.0092)\n",
    "# exp_110 used concatenation for mixtures (CV=0.012912)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY INSIGHT: FEATURIZATION MISMATCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "exp_108 (CV=0.0092) - Mixture Featurization:\n",
    "  mixed = A * frac_A + B * frac_B  # WEIGHTED AVERAGE\n",
    "\n",
    "exp_110 (CV=0.012912) - Mixture Featurization:\n",
    "  X_out = concat([X_numeric, X_solvent_A, X_solvent_B, X_solvent_B_pct])  # CONCATENATION\n",
    "\n",
    "The weighted average is MORE PHYSICALLY MEANINGFUL:\n",
    "- Solvent properties blend linearly with composition\n",
    "- Concatenation doubles feature dimension and loses this insight\n",
    "\n",
    "FIX: Use weighted average featurization with correct submission format\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a6e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What should we do next?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDED NEXT STEPS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. IMMEDIATE: Fix the SimilarityAwareModel featurization\n",
    "   - Use weighted average for mixtures (like exp_108)\n",
    "   - Use correct submission format (like exp_110)\n",
    "   - Verify CV matches exp_108 (~0.0092)\n",
    "   - Submit to test if chemical similarity changes CV-LB relationship\n",
    "\n",
    "2. IF THAT DOESN'T WORK: Try more aggressive conservative blending\n",
    "   - Higher similarity_threshold (0.5, 0.6)\n",
    "   - Higher blend_weight (0.3, 0.4, 0.5)\n",
    "   - The goal is to REDUCE the intercept, not improve CV\n",
    "\n",
    "3. IF STILL STUCK: Try transductive learning\n",
    "   - Use test data structure to inform predictions\n",
    "   - Recent research shows 1.5-1.8x improvement on OOD prediction\n",
    "\n",
    "4. REMAINING SUBMISSIONS: 4\n",
    "   - Use them strategically to test hypotheses\n",
    "   - Each submission tells us about the CV-LB relationship\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00816082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save findings\n",
    "findings = {\n",
    "    'cv_lb_slope': slope,\n",
    "    'cv_lb_intercept': intercept,\n",
    "    'cv_lb_r_squared': r_value**2,\n",
    "    'target': 0.0347,\n",
    "    'best_cv': 0.0081,\n",
    "    'best_lb': 0.0877,\n",
    "    'intercept_vs_target': intercept - 0.0347,\n",
    "    'key_insight': 'Intercept (0.0528) > Target (0.0347). Target is unreachable with current approaches.',\n",
    "    'recommended_action': 'Fix SimilarityAwareModel featurization and submit to test hypothesis'\n",
    "}\n",
    "\n",
    "with open('/home/code/exploration/loop112_findings.json', 'w') as f:\n",
    "    json.dump(findings, f, indent=2)\n",
    "\n",
    "print(\"\\nFindings saved to /home/code/exploration/loop112_findings.json\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
