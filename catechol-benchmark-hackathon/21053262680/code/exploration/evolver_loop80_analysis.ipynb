{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1dbc8c",
   "metadata": {},
   "source": [
    "# Loop 80 Analysis: CV-LB Relationship and Strategy Assessment\n",
    "\n",
    "**Goal**: Analyze the CV-LB relationship across all submissions and identify strategies to break the pattern.\n",
    "\n",
    "**Key Questions**:\n",
    "1. What is the exact CV-LB relationship?\n",
    "2. Are there any outliers that deviate from the line?\n",
    "3. What approaches might change the intercept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbefac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submissions with both CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f\"Total submissions with LB: {len(df)}\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression: LB = slope * CV + intercept\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "\n",
    "print(f\"\\n=== CV-LB Relationship ===\")\n",
    "print(f\"Linear fit: LB = {slope:.4f} * CV + {intercept:.6f}\")\n",
    "print(f\"RÂ² = {r_value**2:.4f}\")\n",
    "print(f\"Standard error: {std_err:.4f}\")\n",
    "\n",
    "# Calculate residuals\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "print(f\"\\nResiduals (LB - predicted):\")\n",
    "print(df[['exp', 'cv', 'lb', 'predicted_lb', 'residual']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target analysis\n",
    "target = 0.0347\n",
    "\n",
    "print(f\"\\n=== Target Analysis ===\")\n",
    "print(f\"Target LB: {target}\")\n",
    "print(f\"Intercept: {intercept:.6f}\")\n",
    "print(f\"Intercept vs Target: {intercept:.6f} > {target} = {intercept > target}\")\n",
    "\n",
    "if intercept > target:\n",
    "    print(f\"\\n*** CRITICAL: Intercept ({intercept:.6f}) > Target ({target}) ***\")\n",
    "    print(f\"Even with CV=0, predicted LB would be {intercept:.6f}\")\n",
    "    print(f\"This means the target is UNREACHABLE with current approaches!\")\n",
    "else:\n",
    "    required_cv = (target - intercept) / slope\n",
    "    print(f\"Required CV to reach target: {required_cv:.6f}\")\n",
    "    print(f\"Best CV so far: {df['cv'].min():.6f}\")\n",
    "    print(f\"Gap: {(df['cv'].min() - required_cv) / required_cv * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze outliers - which submissions deviate most from the line?\n",
    "print(f\"\\n=== Outlier Analysis ===\")\n",
    "df_sorted = df.sort_values('residual')\n",
    "print(\"Submissions sorted by residual (negative = better than predicted):\")\n",
    "print(df_sorted[['exp', 'cv', 'lb', 'predicted_lb', 'residual']].to_string())\n",
    "\n",
    "print(f\"\\nBest outlier (most negative residual): {df_sorted.iloc[0]['exp']}\")\n",
    "print(f\"  CV: {df_sorted.iloc[0]['cv']:.6f}\")\n",
    "print(f\"  LB: {df_sorted.iloc[0]['lb']:.6f}\")\n",
    "print(f\"  Predicted LB: {df_sorted.iloc[0]['predicted_lb']:.6f}\")\n",
    "print(f\"  Residual: {df_sorted.iloc[0]['residual']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc0ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would it take to reach the target?\n",
    "print(f\"\\n=== Path to Target ===\")\n",
    "print(f\"Target: {target}\")\n",
    "print(f\"Best LB: {df['lb'].min():.6f} (exp_030)\")\n",
    "print(f\"Gap: {(df['lb'].min() - target) / target * 100:.1f}%\")\n",
    "\n",
    "# If we could reduce the intercept\n",
    "print(f\"\\nScenario 1: Reduce intercept to 0.02 (keep slope)\")\n",
    "new_intercept = 0.02\n",
    "required_cv_1 = (target - new_intercept) / slope\n",
    "print(f\"  Required CV: {required_cv_1:.6f}\")\n",
    "print(f\"  Achievable? Best CV is {df['cv'].min():.6f}\")\n",
    "\n",
    "print(f\"\\nScenario 2: Reduce slope to 2.0 (keep intercept)\")\n",
    "new_slope = 2.0\n",
    "required_cv_2 = (target - intercept) / new_slope\n",
    "print(f\"  Required CV: {required_cv_2:.6f}\")\n",
    "print(f\"  Achievable? {required_cv_2 > 0}\")\n",
    "\n",
    "print(f\"\\nScenario 3: Both intercept=0.02 and slope=2.0\")\n",
    "required_cv_3 = (target - 0.02) / 2.0\n",
    "print(f\"  Required CV: {required_cv_3:.6f}\")\n",
    "print(f\"  Achievable? Best CV is {df['cv'].min():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c42cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze pending submissions\n",
    "pending = [\n",
    "    {'exp': 'exp_049', 'cv': 0.0081},\n",
    "    {'exp': 'exp_050', 'cv': 0.0081},\n",
    "    {'exp': 'exp_052', 'cv': 0.0109},\n",
    "    {'exp': 'exp_053', 'cv': 0.0081},\n",
    "    {'exp': 'exp_054', 'cv': 0.0085},\n",
    "    {'exp': 'exp_055', 'cv': 0.0085},\n",
    "    {'exp': 'exp_057', 'cv': 0.0093},\n",
    "    {'exp': 'exp_063', 'cv': 0.0112},\n",
    "]\n",
    "\n",
    "print(f\"\\n=== Pending Submissions ===\")\n",
    "for p in pending:\n",
    "    predicted_lb = slope * p['cv'] + intercept\n",
    "    print(f\"{p['exp']}: CV={p['cv']:.4f} -> Predicted LB={predicted_lb:.4f}\")\n",
    "\n",
    "print(f\"\\nBest pending CV: 0.0081\")\n",
    "print(f\"Predicted LB for CV=0.0081: {slope * 0.0081 + intercept:.4f}\")\n",
    "print(f\"This would be slightly better than exp_030 (LB=0.0877) if on same line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f85505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have been tried?\n",
    "print(f\"\\n=== Approaches Tried (80 experiments) ===\")\n",
    "approaches = [\n",
    "    \"MLP with various architectures\",\n",
    "    \"LightGBM\",\n",
    "    \"XGBoost\",\n",
    "    \"CatBoost\",\n",
    "    \"Random Forest\",\n",
    "    \"Ridge Regression\",\n",
    "    \"Kernel Ridge\",\n",
    "    \"Gaussian Process\",\n",
    "    \"GNN (Graph Neural Network)\",\n",
    "    \"ChemBERTa embeddings\",\n",
    "    \"Ensembles (MLP+LGBM+GP, etc.)\",\n",
    "    \"Feature engineering (Spange, DRFP, ACS-PCA, Fragprints)\",\n",
    "    \"Arrhenius kinetics features\",\n",
    "    \"TTA (Test Time Augmentation)\",\n",
    "    \"Data augmentation for mixtures\",\n",
    "    \"Output normalization\",\n",
    "    \"Extrapolation detection\",\n",
    "    \"Similarity weighting\",\n",
    "    \"Per-target models\",\n",
    "    \"GroupKFold(5) validation\",\n",
    "]\n",
    "\n",
    "for i, approach in enumerate(approaches, 1):\n",
    "    print(f\"{i}. {approach}\")\n",
    "\n",
    "print(f\"\\nAll approaches fall on the SAME CV-LB line!\")\n",
    "print(f\"This indicates STRUCTURAL distribution shift, not model inadequacy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75729a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What hasn't been tried that might change the CV-LB relationship?\n",
    "print(f\"\\n=== Potential Approaches to Change CV-LB Relationship ===\")\n",
    "\n",
    "untried = [\n",
    "    \"1. DOMAIN CONSTRAINTS: Force predictions to sum to 1 (yield constraint)\",\n",
    "    \"2. PSEUDO-LABELING: Use confident test predictions to augment training\",\n",
    "    \"3. ADVERSARIAL VALIDATION: Identify and weight samples similar to test\",\n",
    "    \"4. SOLVENT SIMILARITY FEATURES: Add features measuring distance to training solvents\",\n",
    "    \"5. CONSERVATIVE PREDICTIONS: Blend toward mean when extrapolating\",\n",
    "    \"6. MULTI-TASK LEARNING: Share representations across targets\",\n",
    "    \"7. TEMPERATURE SCALING: Calibrate predictions post-hoc\",\n",
    "    \"8. MIXTURE-OF-EXPERTS: Different models for different solvent types\",\n",
    "]\n",
    "\n",
    "for approach in untried:\n",
    "    print(approach)\n",
    "\n",
    "print(f\"\\n*** KEY INSIGHT ***\")\n",
    "print(f\"The intercept (0.053) represents EXTRAPOLATION ERROR.\")\n",
    "print(f\"To reduce it, we need approaches that:\")\n",
    "print(f\"  1. Better generalize to unseen solvents\")\n",
    "print(f\"  2. Make conservative predictions when uncertain\")\n",
    "print(f\"  3. Exploit domain constraints (yields sum to 1)\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
