{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1dbc8c",
   "metadata": {},
   "source": [
    "# Loop 80 Analysis: CV-LB Relationship and Strategy Assessment\n",
    "\n",
    "**Goal**: Analyze the CV-LB relationship across all submissions and identify strategies to break the pattern.\n",
    "\n",
    "**Key Questions**:\n",
    "1. What is the exact CV-LB relationship?\n",
    "2. Are there any outliers that deviate from the line?\n",
    "3. What approaches might change the intercept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bbefac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:08:39.908881Z",
     "iopub.status.busy": "2026-01-16T09:08:39.908394Z",
     "iopub.status.idle": "2026-01-16T09:08:40.685566Z",
     "shell.execute_reply": "2026-01-16T09:08:40.685186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total submissions with LB: 12\n",
      "        exp      cv      lb\n",
      "0   exp_000  0.0111  0.0982\n",
      "1   exp_001  0.0123  0.1065\n",
      "2   exp_003  0.0105  0.0972\n",
      "3   exp_005  0.0104  0.0969\n",
      "4   exp_006  0.0097  0.0946\n",
      "5   exp_007  0.0093  0.0932\n",
      "6   exp_009  0.0092  0.0936\n",
      "7   exp_012  0.0090  0.0913\n",
      "8   exp_024  0.0087  0.0893\n",
      "9   exp_026  0.0085  0.0887\n",
      "10  exp_030  0.0083  0.0877\n",
      "11  exp_035  0.0098  0.0970\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submissions with both CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f\"Total submissions with LB: {len(df)}\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9c1970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:08:40.686668Z",
     "iopub.status.busy": "2026-01-16T09:08:40.686521Z",
     "iopub.status.idle": "2026-01-16T09:08:40.693387Z",
     "shell.execute_reply": "2026-01-16T09:08:40.693032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV-LB Relationship ===\n",
      "Linear fit: LB = 4.3147 * CV + 0.052520\n",
      "R² = 0.9505\n",
      "Standard error: 0.3113\n",
      "\n",
      "Residuals (LB - predicted):\n",
      "        exp      cv      lb  predicted_lb  residual\n",
      "0   exp_000  0.0111  0.0982      0.100413 -0.002213\n",
      "1   exp_001  0.0123  0.1065      0.105591  0.000909\n",
      "2   exp_003  0.0105  0.0972      0.097825 -0.000625\n",
      "3   exp_005  0.0104  0.0969      0.097393 -0.000493\n",
      "4   exp_006  0.0097  0.0946      0.094373  0.000227\n",
      "5   exp_007  0.0093  0.0932      0.092647  0.000553\n",
      "6   exp_009  0.0092  0.0936      0.092215  0.001385\n",
      "7   exp_012  0.0090  0.0913      0.091353 -0.000053\n",
      "8   exp_024  0.0087  0.0893      0.090058 -0.000758\n",
      "9   exp_026  0.0085  0.0887      0.089195 -0.000495\n",
      "10  exp_030  0.0083  0.0877      0.088332 -0.000632\n",
      "11  exp_035  0.0098  0.0970      0.094804  0.002196\n"
     ]
    }
   ],
   "source": [
    "# Fit linear regression: LB = slope * CV + intercept\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "\n",
    "print(f\"\\n=== CV-LB Relationship ===\")\n",
    "print(f\"Linear fit: LB = {slope:.4f} * CV + {intercept:.6f}\")\n",
    "print(f\"R² = {r_value**2:.4f}\")\n",
    "print(f\"Standard error: {std_err:.4f}\")\n",
    "\n",
    "# Calculate residuals\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "print(f\"\\nResiduals (LB - predicted):\")\n",
    "print(df[['exp', 'cv', 'lb', 'predicted_lb', 'residual']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ba0ab1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:08:40.694213Z",
     "iopub.status.busy": "2026-01-16T09:08:40.694114Z",
     "iopub.status.idle": "2026-01-16T09:08:40.697841Z",
     "shell.execute_reply": "2026-01-16T09:08:40.697450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Target Analysis ===\n",
      "Target LB: 0.0347\n",
      "Intercept: 0.052520\n",
      "Intercept vs Target: 0.052520 > 0.0347 = True\n",
      "\n",
      "*** CRITICAL: Intercept (0.052520) > Target (0.0347) ***\n",
      "Even with CV=0, predicted LB would be 0.052520\n",
      "This means the target is UNREACHABLE with current approaches!\n"
     ]
    }
   ],
   "source": [
    "# Target analysis\n",
    "target = 0.0347\n",
    "\n",
    "print(f\"\\n=== Target Analysis ===\")\n",
    "print(f\"Target LB: {target}\")\n",
    "print(f\"Intercept: {intercept:.6f}\")\n",
    "print(f\"Intercept vs Target: {intercept:.6f} > {target} = {intercept > target}\")\n",
    "\n",
    "if intercept > target:\n",
    "    print(f\"\\n*** CRITICAL: Intercept ({intercept:.6f}) > Target ({target}) ***\")\n",
    "    print(f\"Even with CV=0, predicted LB would be {intercept:.6f}\")\n",
    "    print(f\"This means the target is UNREACHABLE with current approaches!\")\n",
    "else:\n",
    "    required_cv = (target - intercept) / slope\n",
    "    print(f\"Required CV to reach target: {required_cv:.6f}\")\n",
    "    print(f\"Best CV so far: {df['cv'].min():.6f}\")\n",
    "    print(f\"Gap: {(df['cv'].min() - required_cv) / required_cv * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab26a338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:08:40.698762Z",
     "iopub.status.busy": "2026-01-16T09:08:40.698650Z",
     "iopub.status.idle": "2026-01-16T09:08:40.704146Z",
     "shell.execute_reply": "2026-01-16T09:08:40.703755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Outlier Analysis ===\n",
      "Submissions sorted by residual (negative = better than predicted):\n",
      "        exp      cv      lb  predicted_lb  residual\n",
      "0   exp_000  0.0111  0.0982      0.100413 -0.002213\n",
      "8   exp_024  0.0087  0.0893      0.090058 -0.000758\n",
      "10  exp_030  0.0083  0.0877      0.088332 -0.000632\n",
      "2   exp_003  0.0105  0.0972      0.097825 -0.000625\n",
      "9   exp_026  0.0085  0.0887      0.089195 -0.000495\n",
      "3   exp_005  0.0104  0.0969      0.097393 -0.000493\n",
      "7   exp_012  0.0090  0.0913      0.091353 -0.000053\n",
      "4   exp_006  0.0097  0.0946      0.094373  0.000227\n",
      "5   exp_007  0.0093  0.0932      0.092647  0.000553\n",
      "1   exp_001  0.0123  0.1065      0.105591  0.000909\n",
      "6   exp_009  0.0092  0.0936      0.092215  0.001385\n",
      "11  exp_035  0.0098  0.0970      0.094804  0.002196\n",
      "\n",
      "Best outlier (most negative residual): exp_000\n",
      "  CV: 0.011100\n",
      "  LB: 0.098200\n",
      "  Predicted LB: 0.100413\n",
      "  Residual: -0.002213\n"
     ]
    }
   ],
   "source": [
    "# Analyze outliers - which submissions deviate most from the line?\n",
    "print(f\"\\n=== Outlier Analysis ===\")\n",
    "df_sorted = df.sort_values('residual')\n",
    "print(\"Submissions sorted by residual (negative = better than predicted):\")\n",
    "print(df_sorted[['exp', 'cv', 'lb', 'predicted_lb', 'residual']].to_string())\n",
    "\n",
    "print(f\"\\nBest outlier (most negative residual): {df_sorted.iloc[0]['exp']}\")\n",
    "print(f\"  CV: {df_sorted.iloc[0]['cv']:.6f}\")\n",
    "print(f\"  LB: {df_sorted.iloc[0]['lb']:.6f}\")\n",
    "print(f\"  Predicted LB: {df_sorted.iloc[0]['predicted_lb']:.6f}\")\n",
    "print(f\"  Residual: {df_sorted.iloc[0]['residual']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc0ccf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:08:40.704936Z",
     "iopub.status.busy": "2026-01-16T09:08:40.704839Z",
     "iopub.status.idle": "2026-01-16T09:08:40.708561Z",
     "shell.execute_reply": "2026-01-16T09:08:40.708168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Path to Target ===\n",
      "Target: 0.0347\n",
      "Best LB: 0.087700 (exp_030)\n",
      "Gap: 152.7%\n",
      "\n",
      "Scenario 1: Reduce intercept to 0.02 (keep slope)\n",
      "  Required CV: 0.003407\n",
      "  Achievable? Best CV is 0.008300\n",
      "\n",
      "Scenario 2: Reduce slope to 2.0 (keep intercept)\n",
      "  Required CV: -0.008910\n",
      "  Achievable? False\n",
      "\n",
      "Scenario 3: Both intercept=0.02 and slope=2.0\n",
      "  Required CV: 0.007350\n",
      "  Achievable? Best CV is 0.008300\n"
     ]
    }
   ],
   "source": [
    "# What would it take to reach the target?\n",
    "print(f\"\\n=== Path to Target ===\")\n",
    "print(f\"Target: {target}\")\n",
    "print(f\"Best LB: {df['lb'].min():.6f} (exp_030)\")\n",
    "print(f\"Gap: {(df['lb'].min() - target) / target * 100:.1f}%\")\n",
    "\n",
    "# If we could reduce the intercept\n",
    "print(f\"\\nScenario 1: Reduce intercept to 0.02 (keep slope)\")\n",
    "new_intercept = 0.02\n",
    "required_cv_1 = (target - new_intercept) / slope\n",
    "print(f\"  Required CV: {required_cv_1:.6f}\")\n",
    "print(f\"  Achievable? Best CV is {df['cv'].min():.6f}\")\n",
    "\n",
    "print(f\"\\nScenario 2: Reduce slope to 2.0 (keep intercept)\")\n",
    "new_slope = 2.0\n",
    "required_cv_2 = (target - intercept) / new_slope\n",
    "print(f\"  Required CV: {required_cv_2:.6f}\")\n",
    "print(f\"  Achievable? {required_cv_2 > 0}\")\n",
    "\n",
    "print(f\"\\nScenario 3: Both intercept=0.02 and slope=2.0\")\n",
    "required_cv_3 = (target - 0.02) / 2.0\n",
    "print(f\"  Required CV: {required_cv_3:.6f}\")\n",
    "print(f\"  Achievable? Best CV is {df['cv'].min():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c42cad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:08:40.709403Z",
     "iopub.status.busy": "2026-01-16T09:08:40.709308Z",
     "iopub.status.idle": "2026-01-16T09:08:40.712501Z",
     "shell.execute_reply": "2026-01-16T09:08:40.712103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pending Submissions ===\n",
      "exp_049: CV=0.0081 -> Predicted LB=0.0875\n",
      "exp_050: CV=0.0081 -> Predicted LB=0.0875\n",
      "exp_052: CV=0.0109 -> Predicted LB=0.0996\n",
      "exp_053: CV=0.0081 -> Predicted LB=0.0875\n",
      "exp_054: CV=0.0085 -> Predicted LB=0.0892\n",
      "exp_055: CV=0.0085 -> Predicted LB=0.0892\n",
      "exp_057: CV=0.0093 -> Predicted LB=0.0926\n",
      "exp_063: CV=0.0112 -> Predicted LB=0.1008\n",
      "\n",
      "Best pending CV: 0.0081\n",
      "Predicted LB for CV=0.0081: 0.0875\n",
      "This would be slightly better than exp_030 (LB=0.0877) if on same line\n"
     ]
    }
   ],
   "source": [
    "# Analyze pending submissions\n",
    "pending = [\n",
    "    {'exp': 'exp_049', 'cv': 0.0081},\n",
    "    {'exp': 'exp_050', 'cv': 0.0081},\n",
    "    {'exp': 'exp_052', 'cv': 0.0109},\n",
    "    {'exp': 'exp_053', 'cv': 0.0081},\n",
    "    {'exp': 'exp_054', 'cv': 0.0085},\n",
    "    {'exp': 'exp_055', 'cv': 0.0085},\n",
    "    {'exp': 'exp_057', 'cv': 0.0093},\n",
    "    {'exp': 'exp_063', 'cv': 0.0112},\n",
    "]\n",
    "\n",
    "print(f\"\\n=== Pending Submissions ===\")\n",
    "for p in pending:\n",
    "    predicted_lb = slope * p['cv'] + intercept\n",
    "    print(f\"{p['exp']}: CV={p['cv']:.4f} -> Predicted LB={predicted_lb:.4f}\")\n",
    "\n",
    "print(f\"\\nBest pending CV: 0.0081\")\n",
    "print(f\"Predicted LB for CV=0.0081: {slope * 0.0081 + intercept:.4f}\")\n",
    "print(f\"This would be slightly better than exp_030 (LB=0.0877) if on same line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f85505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:08:40.713322Z",
     "iopub.status.busy": "2026-01-16T09:08:40.713218Z",
     "iopub.status.idle": "2026-01-16T09:08:40.716173Z",
     "shell.execute_reply": "2026-01-16T09:08:40.715789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Approaches Tried (80 experiments) ===\n",
      "1. MLP with various architectures\n",
      "2. LightGBM\n",
      "3. XGBoost\n",
      "4. CatBoost\n",
      "5. Random Forest\n",
      "6. Ridge Regression\n",
      "7. Kernel Ridge\n",
      "8. Gaussian Process\n",
      "9. GNN (Graph Neural Network)\n",
      "10. ChemBERTa embeddings\n",
      "11. Ensembles (MLP+LGBM+GP, etc.)\n",
      "12. Feature engineering (Spange, DRFP, ACS-PCA, Fragprints)\n",
      "13. Arrhenius kinetics features\n",
      "14. TTA (Test Time Augmentation)\n",
      "15. Data augmentation for mixtures\n",
      "16. Output normalization\n",
      "17. Extrapolation detection\n",
      "18. Similarity weighting\n",
      "19. Per-target models\n",
      "20. GroupKFold(5) validation\n",
      "\n",
      "All approaches fall on the SAME CV-LB line!\n",
      "This indicates STRUCTURAL distribution shift, not model inadequacy.\n"
     ]
    }
   ],
   "source": [
    "# What approaches have been tried?\n",
    "print(f\"\\n=== Approaches Tried (80 experiments) ===\")\n",
    "approaches = [\n",
    "    \"MLP with various architectures\",\n",
    "    \"LightGBM\",\n",
    "    \"XGBoost\",\n",
    "    \"CatBoost\",\n",
    "    \"Random Forest\",\n",
    "    \"Ridge Regression\",\n",
    "    \"Kernel Ridge\",\n",
    "    \"Gaussian Process\",\n",
    "    \"GNN (Graph Neural Network)\",\n",
    "    \"ChemBERTa embeddings\",\n",
    "    \"Ensembles (MLP+LGBM+GP, etc.)\",\n",
    "    \"Feature engineering (Spange, DRFP, ACS-PCA, Fragprints)\",\n",
    "    \"Arrhenius kinetics features\",\n",
    "    \"TTA (Test Time Augmentation)\",\n",
    "    \"Data augmentation for mixtures\",\n",
    "    \"Output normalization\",\n",
    "    \"Extrapolation detection\",\n",
    "    \"Similarity weighting\",\n",
    "    \"Per-target models\",\n",
    "    \"GroupKFold(5) validation\",\n",
    "]\n",
    "\n",
    "for i, approach in enumerate(approaches, 1):\n",
    "    print(f\"{i}. {approach}\")\n",
    "\n",
    "print(f\"\\nAll approaches fall on the SAME CV-LB line!\")\n",
    "print(f\"This indicates STRUCTURAL distribution shift, not model inadequacy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75729a6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:08:40.717075Z",
     "iopub.status.busy": "2026-01-16T09:08:40.716971Z",
     "iopub.status.idle": "2026-01-16T09:08:40.719926Z",
     "shell.execute_reply": "2026-01-16T09:08:40.719531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Potential Approaches to Change CV-LB Relationship ===\n",
      "1. DOMAIN CONSTRAINTS: Force predictions to sum to 1 (yield constraint)\n",
      "2. PSEUDO-LABELING: Use confident test predictions to augment training\n",
      "3. ADVERSARIAL VALIDATION: Identify and weight samples similar to test\n",
      "4. SOLVENT SIMILARITY FEATURES: Add features measuring distance to training solvents\n",
      "5. CONSERVATIVE PREDICTIONS: Blend toward mean when extrapolating\n",
      "6. MULTI-TASK LEARNING: Share representations across targets\n",
      "7. TEMPERATURE SCALING: Calibrate predictions post-hoc\n",
      "8. MIXTURE-OF-EXPERTS: Different models for different solvent types\n",
      "\n",
      "*** KEY INSIGHT ***\n",
      "The intercept (0.053) represents EXTRAPOLATION ERROR.\n",
      "To reduce it, we need approaches that:\n",
      "  1. Better generalize to unseen solvents\n",
      "  2. Make conservative predictions when uncertain\n",
      "  3. Exploit domain constraints (yields sum to 1)\n"
     ]
    }
   ],
   "source": [
    "# What hasn't been tried that might change the CV-LB relationship?\n",
    "print(f\"\\n=== Potential Approaches to Change CV-LB Relationship ===\")\n",
    "\n",
    "untried = [\n",
    "    \"1. DOMAIN CONSTRAINTS: Force predictions to sum to 1 (yield constraint)\",\n",
    "    \"2. PSEUDO-LABELING: Use confident test predictions to augment training\",\n",
    "    \"3. ADVERSARIAL VALIDATION: Identify and weight samples similar to test\",\n",
    "    \"4. SOLVENT SIMILARITY FEATURES: Add features measuring distance to training solvents\",\n",
    "    \"5. CONSERVATIVE PREDICTIONS: Blend toward mean when extrapolating\",\n",
    "    \"6. MULTI-TASK LEARNING: Share representations across targets\",\n",
    "    \"7. TEMPERATURE SCALING: Calibrate predictions post-hoc\",\n",
    "    \"8. MIXTURE-OF-EXPERTS: Different models for different solvent types\",\n",
    "]\n",
    "\n",
    "for approach in untried:\n",
    "    print(approach)\n",
    "\n",
    "print(f\"\\n*** KEY INSIGHT ***\")\n",
    "print(f\"The intercept (0.053) represents EXTRAPOLATION ERROR.\")\n",
    "print(f\"To reduce it, we need approaches that:\")\n",
    "print(f\"  1. Better generalize to unseen solvents\")\n",
    "print(f\"  2. Make conservative predictions when uncertain\")\n",
    "print(f\"  3. Exploit domain constraints (yields sum to 1)\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
