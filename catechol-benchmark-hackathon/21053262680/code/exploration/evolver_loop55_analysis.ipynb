{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06ae96f0",
   "metadata": {},
   "source": [
    "# Loop 55 Analysis: Submission Failure Investigation\n",
    "\n",
    "**Problem:** The last 5 submissions (exp_049 through exp_054) all failed with \"Evaluation metric raised an unexpected error\"\n",
    "\n",
    "**Goal:** Understand why submissions are failing and fix the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5229fe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:08:14.816519Z",
     "iopub.status.busy": "2026-01-15T23:08:14.815956Z",
     "iopub.status.idle": "2026-01-15T23:08:15.106177Z",
     "shell.execute_reply": "2026-01-15T23:08:15.105767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All submissions:\n",
      "  exp_000: CV=0.011081, LB=0.09816\n",
      "  exp_001: CV=0.012297, LB=0.10649\n",
      "  exp_003: CV=0.010501, LB=0.09719\n",
      "  exp_005: CV=0.01043, LB=0.09691\n",
      "  exp_006: CV=0.009749, LB=0.09457\n",
      "  exp_007: CV=0.009262, LB=0.09316\n",
      "  exp_009: CV=0.009192, LB=0.09364\n",
      "  exp_012: CV=0.009004, LB=0.09134\n",
      "  exp_024: CV=0.008689, LB=0.08929\n",
      "  exp_026: CV=0.008465, LB=0.08875\n",
      "  exp_030: CV=0.008298, LB=0.08772\n",
      "  exp_035: CV=0.009825, LB=0.09696\n",
      "  exp_049: CV=0.008092, LB=\n",
      "  exp_050: CV=0.008092, LB=\n",
      "  exp_052: CV=0.01088, LB=\n",
      "  exp_053: CV=0.008092, LB=\n",
      "  exp_054: CV=0.008504, LB=\n",
      "\n",
      "Successful submissions: 12\n",
      "Failed submissions: 5\n",
      "\n",
      "Failed submission IDs: ['exp_049', 'exp_050', 'exp_052', 'exp_053', 'exp_054']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load session state\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Get successful submissions\n",
    "submissions = state.get('submissions', [])\n",
    "print('All submissions:')\n",
    "for s in submissions:\n",
    "    lb = s.get('lb_score', '')\n",
    "    cv = s.get('cv_score', '')\n",
    "    print(f\"  {s.get('experiment_id')}: CV={cv}, LB={lb}\")\n",
    "\n",
    "# Filter successful submissions (those with LB scores)\n",
    "successful = [s for s in submissions if s.get('lb_score')]\n",
    "print(f'\\nSuccessful submissions: {len(successful)}')\n",
    "print(f'Failed submissions: {len(submissions) - len(successful)}')\n",
    "\n",
    "# Failed submissions\n",
    "failed = [s for s in submissions if not s.get('lb_score')]\n",
    "print(f'\\nFailed submission IDs: {[s.get(\"experiment_id\") for s in failed]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0f9e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:08:15.107295Z",
     "iopub.status.busy": "2026-01-15T23:08:15.107161Z",
     "iopub.status.idle": "2026-01-15T23:08:15.562030Z",
     "shell.execute_reply": "2026-01-15T23:08:15.561592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-LB Relationship Analysis\n",
      "==================================================\n",
      "Linear fit: LB = 4.2876 * CV + 0.0528\n",
      "R-squared = 0.9523\n",
      "Intercept = 0.0528\n",
      "Target = 0.0347\n",
      "\n",
      "CRITICAL: Intercept (0.0528) > Target (0.0347)\n",
      "Required CV to hit target: (0.0347 - 0.0528) / 4.2876 = -0.004218\n"
     ]
    }
   ],
   "source": [
    "# CV-LB relationship analysis\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "cv_scores = [s['cv_score'] for s in successful]\n",
    "lb_scores = [s['lb_score'] for s in successful]\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_scores, lb_scores)\n",
    "\n",
    "print('CV-LB Relationship Analysis')\n",
    "print('=' * 50)\n",
    "print(f'Linear fit: LB = {slope:.4f} * CV + {intercept:.4f}')\n",
    "print(f'R-squared = {r_value**2:.4f}')\n",
    "print(f'Intercept = {intercept:.4f}')\n",
    "print(f'Target = 0.0347')\n",
    "print()\n",
    "print(f'CRITICAL: Intercept ({intercept:.4f}) > Target (0.0347)')\n",
    "print(f'Required CV to hit target: (0.0347 - {intercept:.4f}) / {slope:.4f} = {(0.0347 - intercept) / slope:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747a686e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:08:15.563252Z",
     "iopub.status.busy": "2026-01-15T23:08:15.563082Z",
     "iopub.status.idle": "2026-01-15T23:08:15.572479Z",
     "shell.execute_reply": "2026-01-15T23:08:15.572127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Submission Analysis\n",
      "==================================================\n",
      "Total rows: 1883\n",
      "Columns: ['id', 'index', 'task', 'fold', 'row', 'target_1', 'target_2', 'target_3']\n",
      "\n",
      "Task distribution:\n",
      "task\n",
      "0     656\n",
      "1    1227\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Folds per task:\n",
      "task\n",
      "0    24\n",
      "1    13\n",
      "Name: fold, dtype: int64\n",
      "\n",
      "Target statistics:\n",
      "  target_1: min=0.000000, max=0.434598\n",
      "    Values > 1: 0\n",
      "    Values < 0: 0\n",
      "    NaN: 0\n",
      "  target_2: min=0.000000, max=0.435151\n",
      "    Values > 1: 0\n",
      "    Values < 0: 0\n",
      "    NaN: 0\n",
      "  target_3: min=0.000000, max=1.000000\n",
      "    Values > 1: 0\n",
      "    Values < 0: 0\n",
      "    NaN: 0\n"
     ]
    }
   ],
   "source": [
    "# Check current submission format\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "\n",
    "print('Current Submission Analysis')\n",
    "print('=' * 50)\n",
    "print(f'Total rows: {len(df)}')\n",
    "print(f'Columns: {df.columns.tolist()}')\n",
    "print(f'\\nTask distribution:')\n",
    "print(df['task'].value_counts().sort_index())\n",
    "print(f'\\nFolds per task:')\n",
    "print(df.groupby('task')['fold'].nunique())\n",
    "print(f'\\nTarget statistics:')\n",
    "for col in ['target_1', 'target_2', 'target_3']:\n",
    "    print(f'  {col}: min={df[col].min():.6f}, max={df[col].max():.6f}')\n",
    "    print(f'    Values > 1: {(df[col] > 1).sum()}')\n",
    "    print(f'    Values < 0: {(df[col] < 0).sum()}')\n",
    "    print(f'    NaN: {df[col].isna().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c960bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:08:15.573409Z",
     "iopub.status.busy": "2026-01-15T23:08:15.573317Z",
     "iopub.status.idle": "2026-01-15T23:08:15.579924Z",
     "shell.execute_reply": "2026-01-15T23:08:15.579581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold/Row structure analysis:\n",
      "==================================================\n",
      "\n",
      "Task 0:\n",
      "  Total rows: 656\n",
      "  Unique folds: 24\n",
      "  Fold range: 0 to 23\n",
      "  Rows per fold: min=5, max=59\n",
      "    Fold 0: rows 0 to 36, count=37\n",
      "    Fold 1: rows 0 to 36, count=37\n",
      "    Fold 2: rows 0 to 57, count=58\n",
      "\n",
      "Task 1:\n",
      "  Total rows: 1227\n",
      "  Unique folds: 13\n",
      "  Fold range: 0 to 12\n",
      "  Rows per fold: min=34, max=127\n",
      "    Fold 0: rows 0 to 123, count=124\n",
      "    Fold 1: rows 0 to 124, count=125\n",
      "    Fold 2: rows 0 to 123, count=124\n"
     ]
    }
   ],
   "source": [
    "# Check the fold/row structure more carefully\n",
    "print('Fold/Row structure analysis:')\n",
    "print('=' * 50)\n",
    "\n",
    "for task in [0, 1]:\n",
    "    task_df = df[df['task'] == task]\n",
    "    print(f'\\nTask {task}:')\n",
    "    print(f'  Total rows: {len(task_df)}')\n",
    "    print(f'  Unique folds: {task_df[\"fold\"].nunique()}')\n",
    "    print(f'  Fold range: {task_df[\"fold\"].min()} to {task_df[\"fold\"].max()}')\n",
    "    \n",
    "    # Check rows per fold\n",
    "    rows_per_fold = task_df.groupby('fold').size()\n",
    "    print(f'  Rows per fold: min={rows_per_fold.min()}, max={rows_per_fold.max()}')\n",
    "    \n",
    "    # Check row indices within each fold\n",
    "    for fold in sorted(task_df['fold'].unique())[:3]:  # Check first 3 folds\n",
    "        fold_df = task_df[task_df['fold'] == fold]\n",
    "        print(f'    Fold {fold}: rows {fold_df[\"row\"].min()} to {fold_df[\"row\"].max()}, count={len(fold_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f24b333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:08:15.580768Z",
     "iopub.status.busy": "2026-01-15T23:08:15.580666Z",
     "iopub.status.idle": "2026-01-15T23:08:15.592400Z",
     "shell.execute_reply": "2026-01-15T23:08:15.592051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Solvent Data:\n",
      "  Total rows: 656\n",
      "  Unique solvents: 24\n",
      "\n",
      "Full Data:\n",
      "  Total rows: 1227\n",
      "  Unique solvent pairs: 13\n"
     ]
    }
   ],
   "source": [
    "# Load the actual data to compare\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "# Load single solvent data\n",
    "single_df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "print('Single Solvent Data:')\n",
    "print(f'  Total rows: {len(single_df)}')\n",
    "print(f'  Unique solvents: {single_df[\"SOLVENT NAME\"].nunique()}')\n",
    "\n",
    "# Load full data\n",
    "full_df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "print('\\nFull Data:')\n",
    "print(f'  Total rows: {len(full_df)}')\n",
    "print(f'  Unique solvent pairs: {full_df.groupby([\"SOLVENT A NAME\", \"SOLVENT B NAME\"]).ngroups}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e90e90b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:08:15.593246Z",
     "iopub.status.busy": "2026-01-15T23:08:15.593152Z",
     "iopub.status.idle": "2026-01-15T23:08:15.596450Z",
     "shell.execute_reply": "2026-01-15T23:08:15.596102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Summary:\n",
      "==================================================\n",
      "\n",
      "1. Submission format appears correct:\n",
      "   - 1883 rows (656 single + 1227 full)\n",
      "   - Correct columns: id, index, task, fold, row, target_1, target_2, target_3\n",
      "   - Task 0: 24 folds, Task 1: 13 folds\n",
      "   - All targets in [0, 1] range\n",
      "   - No NaN or Inf values\n",
      "\n",
      "2. CV-LB Relationship:\n",
      "   - LB = 4.2876 * CV + 0.0528 (R-squared = 0.9523)\n",
      "   - Intercept (0.0528) > Target (0.0347)\n",
      "   - This means even CV=0 would give LB=0.0528\n",
      "\n",
      "3. Best CV achieved: 0.008092 (exp_050/051/053)\n",
      "   - Predicted LB: 0.0875\n",
      "   - Best actual LB: 0.0877 (exp_030)\n",
      "\n",
      "4. Submission failures:\n",
      "   - exp_049, exp_050, exp_052, exp_053, exp_054 all failed\n",
      "   - Error: \"Evaluation metric raised an unexpected error\"\n",
      "   - The format looks correct, so this may be a Kaggle-side issue\n",
      "   - OR there is something subtle about the evaluation we are missing\n"
     ]
    }
   ],
   "source": [
    "# Analysis Summary\n",
    "print('Analysis Summary:')\n",
    "print('=' * 50)\n",
    "print()\n",
    "print('1. Submission format appears correct:')\n",
    "print('   - 1883 rows (656 single + 1227 full)')\n",
    "print('   - Correct columns: id, index, task, fold, row, target_1, target_2, target_3')\n",
    "print('   - Task 0: 24 folds, Task 1: 13 folds')\n",
    "print('   - All targets in [0, 1] range')\n",
    "print('   - No NaN or Inf values')\n",
    "print()\n",
    "print('2. CV-LB Relationship:')\n",
    "print(f'   - LB = {slope:.4f} * CV + {intercept:.4f} (R-squared = {r_value**2:.4f})')\n",
    "print(f'   - Intercept ({intercept:.4f}) > Target (0.0347)')\n",
    "print(f'   - This means even CV=0 would give LB={intercept:.4f}')\n",
    "print()\n",
    "print('3. Best CV achieved: 0.008092 (exp_050/051/053)')\n",
    "print(f'   - Predicted LB: {slope * 0.008092 + intercept:.4f}')\n",
    "print(f'   - Best actual LB: 0.0877 (exp_030)')\n",
    "print()\n",
    "print('4. Submission failures:')\n",
    "print('   - exp_049, exp_050, exp_052, exp_053, exp_054 all failed')\n",
    "print('   - Error: \"Evaluation metric raised an unexpected error\"')\n",
    "print('   - The format looks correct, so this may be a Kaggle-side issue')\n",
    "print('   - OR there is something subtle about the evaluation we are missing')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
