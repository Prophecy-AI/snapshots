{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bfc83df",
   "metadata": {},
   "source": [
    "# Loop 101 Analysis: CV-LB Relationship and Strategy Assessment\n",
    "\n",
    "## Key Questions:\n",
    "1. What is the current CV-LB relationship?\n",
    "2. Is the mixall kernel's GroupKFold approach fundamentally different?\n",
    "3. What experiments have beaten the CV-LB line?\n",
    "4. What is the path forward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3752ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "    {'exp': 'exp_073', 'cv': 0.0084, 'lb': 0.1451},  # Outlier - likely failed submission\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f\"Total submissions with LB: {len(df)}\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13828c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers (exp_073 has LB 0.1451 which is clearly an error)\n",
    "df_clean = df[df['lb'] < 0.12].copy()\n",
    "print(f\"Clean submissions: {len(df_clean)}\")\n",
    "\n",
    "# Fit linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_clean['cv'], df_clean['lb'])\n",
    "\n",
    "print(f\"\\n=== CV-LB Linear Fit ===\")\n",
    "print(f\"LB = {slope:.4f} * CV + {intercept:.4f}\")\n",
    "print(f\"R² = {r_value**2:.4f}\")\n",
    "print(f\"Intercept = {intercept:.4f}\")\n",
    "print(f\"Target LB = 0.0347\")\n",
    "print(f\"\\nIntercept > Target? {intercept > 0.0347}\")\n",
    "print(f\"Required CV for target: (0.0347 - {intercept:.4f}) / {slope:.4f} = {(0.0347 - intercept) / slope:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ceec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot all points\n",
    "plt.scatter(df_clean['cv'], df_clean['lb'], s=100, alpha=0.7, label='Submissions')\n",
    "\n",
    "# Plot regression line\n",
    "cv_range = np.linspace(0.006, 0.014, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'Fit: LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.2f})')\n",
    "\n",
    "# Mark target\n",
    "plt.axhline(y=0.0347, color='g', linestyle=':', linewidth=2, label='Target LB = 0.0347')\n",
    "\n",
    "# Mark best LB\n",
    "best_lb = df_clean['lb'].min()\n",
    "best_cv = df_clean.loc[df_clean['lb'].idxmin(), 'cv']\n",
    "plt.scatter([best_cv], [best_lb], s=200, c='red', marker='*', label=f'Best: CV={best_cv:.4f}, LB={best_lb:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship (101 Experiments)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship_loop101.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest LB: {best_lb:.4f} (exp: {df_clean.loc[df_clean['lb'].idxmin(), 'exp']})\")\n",
    "print(f\"Best CV: {df_clean['cv'].min():.4f}\")\n",
    "print(f\"Gap to target: {best_lb - 0.0347:.4f} ({(best_lb - 0.0347) / 0.0347 * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e4fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze residuals - which experiments beat the line?\n",
    "df_clean['predicted_lb'] = slope * df_clean['cv'] + intercept\n",
    "df_clean['residual'] = df_clean['lb'] - df_clean['predicted_lb']\n",
    "df_clean['beat_line'] = df_clean['residual'] < 0\n",
    "\n",
    "print(\"=== Experiments that BEAT the CV-LB line ===\")\n",
    "beaters = df_clean[df_clean['beat_line']].sort_values('residual')\n",
    "print(beaters[['exp', 'cv', 'lb', 'predicted_lb', 'residual']])\n",
    "\n",
    "print(\"\\n=== Experiments that UNDERPERFORMED the line ===\")\n",
    "underperformers = df_clean[~df_clean['beat_line']].sort_values('residual', ascending=False)\n",
    "print(underperformers[['exp', 'cv', 'lb', 'predicted_lb', 'residual']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The mixall kernel uses GroupKFold (5 splits) instead of Leave-One-Out (24 folds)\n",
    "# This is a FUNDAMENTALLY DIFFERENT validation scheme\n",
    "\n",
    "print(\"=== CRITICAL INSIGHT: mixall Kernel Validation ===\")\n",
    "print()\n",
    "print(\"The mixall kernel OVERWRITES the validation functions:\")\n",
    "print(\"- generate_leave_one_out_splits: Uses GroupKFold(n_splits=5) instead of Leave-One-Out\")\n",
    "print(\"- generate_leave_one_ramp_out_splits: Uses GroupKFold(n_splits=5) instead of Leave-One-Ramp-Out\")\n",
    "print()\n",
    "print(\"This means:\")\n",
    "print(\"1. CV scores from mixall are NOT comparable to our experiments\")\n",
    "print(\"2. The CV-LB relationship may be COMPLETELY DIFFERENT\")\n",
    "print(\"3. This approach has NOT been properly replicated\")\n",
    "print()\n",
    "print(\"The mixall kernel uses an EnsembleModel with:\")\n",
    "print(\"- MLP (EnhancedMLP with BatchNorm, Dropout, Sigmoid output)\")\n",
    "print(\"- XGBoost\")\n",
    "print(\"- RandomForest\")\n",
    "print(\"- LightGBM\")\n",
    "print(\"- Weighted ensemble with learned weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the path forward?\n",
    "print(\"=== PATH FORWARD ===\")\n",
    "print()\n",
    "print(\"OPTION 1: Exactly replicate mixall kernel\")\n",
    "print(\"- Use GroupKFold (5 splits) for validation\")\n",
    "print(\"- Use the same EnsembleModel (MLP + XGBoost + RF + LightGBM)\")\n",
    "print(\"- Check if CV-LB relationship is different\")\n",
    "print()\n",
    "print(\"OPTION 2: Analyze what makes exp_030 (best LB) special\")\n",
    "print(f\"- exp_030: CV={0.0083}, LB={0.0877}\")\n",
    "print(f\"- Predicted LB: {slope * 0.0083 + intercept:.4f}\")\n",
    "print(f\"- Residual: {0.0877 - (slope * 0.0083 + intercept):.4f}\")\n",
    "print()\n",
    "print(\"OPTION 3: Submit pending experiments to get more LB data\")\n",
    "print(\"- exp_049: CV=0.0081 (pending)\")\n",
    "print(\"- exp_050: CV=0.0081 (pending)\")\n",
    "print(\"- exp_053: CV=0.0081 (pending)\")\n",
    "print(\"These have the best CV scores - if they beat the line, we learn something\")\n",
    "print()\n",
    "print(\"RECOMMENDATION: Try mixall replication first - it's a fundamentally different approach\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
