{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33a2f021",
   "metadata": {},
   "source": [
    "# Loop 96 Analysis: Strategic Assessment\n",
    "\n",
    "## Key Questions:\n",
    "1. Why have all 96 experiments fallen on the same CV-LB line?\n",
    "2. What fundamentally different approaches haven't been tried?\n",
    "3. What does the benchmark paper's success (MSE 0.0039) tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a600a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Load session state\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Extract submission data\n",
    "submissions = state.get('submissions', [])\n",
    "print(f'Total submissions: {len(submissions)}')\n",
    "\n",
    "# Get valid CV-LB pairs\n",
    "cv_lb_pairs = []\n",
    "for sub in submissions:\n",
    "    cv = sub.get('cv_score')\n",
    "    lb = sub.get('lb_score')\n",
    "    exp_id = sub.get('experiment_id', 'unknown')\n",
    "    if cv is not None and lb is not None:\n",
    "        try:\n",
    "            lb_float = float(lb)\n",
    "            if lb_float < 0.15 and exp_id != 'exp_073':  # Exclude outlier\n",
    "                cv_lb_pairs.append((float(cv), lb_float, exp_id))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(f'Valid CV-LB pairs: {len(cv_lb_pairs)}')\n",
    "for cv, lb, exp_id in sorted(cv_lb_pairs, key=lambda x: x[0]):\n",
    "    print(f'  {exp_id}: CV={cv:.6f}, LB={lb:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbf64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression\n",
    "cv_arr = np.array([x[0] for x in cv_lb_pairs])\n",
    "lb_arr = np.array([x[1] for x in cv_lb_pairs])\n",
    "\n",
    "slope, intercept = np.polyfit(cv_arr, lb_arr, 1)\n",
    "pred = slope * cv_arr + intercept\n",
    "ss_res = np.sum((lb_arr - pred) ** 2)\n",
    "ss_tot = np.sum((lb_arr - np.mean(lb_arr)) ** 2)\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "print('=== CV-LB RELATIONSHIP ===')\n",
    "print(f'Linear fit: LB = {slope:.4f} * CV + {intercept:.6f}')\n",
    "print(f'R-squared: {r_squared:.4f}')\n",
    "print(f'Intercept: {intercept:.6f}')\n",
    "print(f'Target LB: 0.0347')\n",
    "print(f'Required CV for target: {(0.0347 - intercept) / slope:.6f}')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cv_arr, lb_arr, c='blue', alpha=0.7, label='Submissions')\n",
    "plt.plot([0, max(cv_arr)*1.1], [intercept, slope*max(cv_arr)*1.1 + intercept], 'r--', label=f'Fit: LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', label='Target LB = 0.0347')\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', label=f'Intercept = {intercept:.4f}')\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship (96 experiments)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n=== CRITICAL INSIGHT ===')\n",
    "print(f'Intercept ({intercept:.4f}) > Target ({0.0347})')\n",
    "print(f'This means even with CV=0, expected LB would be {intercept:.4f}')\n",
    "print(f'The target is UNREACHABLE with current approaches!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a3ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze experiment types\n",
    "experiments = state.get('experiments', [])\n",
    "print(f'Total experiments logged: {len(experiments)}')\n",
    "\n",
    "# Categorize by model type\n",
    "model_types = {}\n",
    "for exp in experiments:\n",
    "    model_type = exp.get('model_type', 'unknown')\n",
    "    if model_type not in model_types:\n",
    "        model_types[model_type] = []\n",
    "    model_types[model_type].append(exp)\n",
    "\n",
    "print('\\n=== EXPERIMENTS BY MODEL TYPE ===')\n",
    "for mt, exps in sorted(model_types.items(), key=lambda x: -len(x[1])):\n",
    "    scores = [e.get('score', 0) for e in exps if e.get('score')]\n",
    "    if scores:\n",
    "        print(f'{mt}: {len(exps)} experiments, best CV: {min(scores):.6f}')\n",
    "    else:\n",
    "        print(f'{mt}: {len(exps)} experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what approaches have been tried\n",
    "print('=== APPROACHES TRIED ===')\n",
    "approaches = [\n",
    "    'MLP', 'LightGBM', 'XGBoost', 'CatBoost', 'RandomForest',\n",
    "    'Ridge', 'GP', 'GNN', 'ChemBERTa', 'Transformer',\n",
    "    'Ensemble', 'Stacking'\n",
    "]\n",
    "\n",
    "for approach in approaches:\n",
    "    count = sum(1 for exp in experiments if approach.lower() in str(exp).lower())\n",
    "    print(f'{approach}: {count} experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecceafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to understand the problem\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "df_single = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "df_full = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "\n",
    "print('=== DATA OVERVIEW ===')\n",
    "print(f'Single solvent: {df_single.shape}')\n",
    "print(f'Full data: {df_full.shape}')\n",
    "\n",
    "print(f'\\nUnique solvents in single: {df_single[\"SOLVENT NAME\"].nunique()}')\n",
    "print(f'Unique solvent pairs in full: {len(df_full[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates())}')\n",
    "\n",
    "print(f'\\nTarget statistics (single):')\n",
    "print(df_single[['Product 2', 'Product 3', 'SM']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key insight: Why does the intercept exist?\n",
    "# The intercept represents the STRUCTURAL GAP between CV and LB\n",
    "# This gap exists because:\n",
    "# 1. CV uses Leave-One-Solvent-Out, but test solvents are \"harder\"\n",
    "# 2. The model extrapolates poorly to unseen solvents\n",
    "# 3. Tabular features don't capture the full molecular structure\n",
    "\n",
    "print('=== ROOT CAUSE ANALYSIS ===')\n",
    "print()\n",
    "print('The CV-LB intercept (0.0528) represents DISTRIBUTION SHIFT:')\n",
    "print('1. CV uses Leave-One-Solvent-Out validation')\n",
    "print('2. Test solvents are structurally different from training')\n",
    "print('3. Tabular models extrapolate poorly to unseen chemical space')\n",
    "print()\n",
    "print('The benchmark paper achieved MSE 0.0039 by:')\n",
    "print('1. Using Graph Neural Networks (GATs) on molecular graphs')\n",
    "print('2. Operating on MOLECULAR STRUCTURE, not tabular features')\n",
    "print('3. Learning representations that generalize to unseen solvents')\n",
    "print()\n",
    "print('Our GNN attempts failed (CV 0.018-0.068) likely because:')\n",
    "print('1. Model class mismatch in submission cells')\n",
    "print('2. Missing DRFP integration with graph representation')\n",
    "print('3. Missing learned mixture-aware encodings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243280bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches could CHANGE the CV-LB relationship?\n",
    "print('=== APPROACHES TO CHANGE CV-LB RELATIONSHIP ===')\n",
    "print()\n",
    "print('1. PROPER GNN IMPLEMENTATION')\n",
    "print('   - Use PyTorch Geometric with GATConv')\n",
    "print('   - Convert SMILES to molecular graphs')\n",
    "print('   - Integrate DRFP features')\n",
    "print('   - VERIFY submission cells use same model class')\n",
    "print()\n",
    "print('2. PRE-TRAINED MOLECULAR EMBEDDINGS')\n",
    "print('   - ChemBERTa or MolBERT embeddings')\n",
    "print('   - These capture chemical knowledge from large corpora')\n",
    "print('   - May generalize better to unseen solvents')\n",
    "print()\n",
    "print('3. EXTRAPOLATION DETECTION + CONSERVATIVE PREDICTIONS')\n",
    "print('   - Detect when test sample is far from training')\n",
    "print('   - Blend toward population mean for extrapolation')\n",
    "print('   - This could reduce the intercept')\n",
    "print()\n",
    "print('4. DOMAIN CONSTRAINTS')\n",
    "print('   - Yields must sum to ~1 (mass balance)')\n",
    "print('   - Arrhenius kinetics constraints')\n",
    "print('   - These constraints hold even for unseen solvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1132eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the best experiment details\n",
    "best_exp = None\n",
    "best_cv = float('inf')\n",
    "for exp in experiments:\n",
    "    score = exp.get('score', float('inf'))\n",
    "    if score < best_cv:\n",
    "        best_cv = score\n",
    "        best_exp = exp\n",
    "\n",
    "if best_exp:\n",
    "    print('=== BEST EXPERIMENT ===')\n",
    "    print(f\"ID: {best_exp.get('id')}\")\n",
    "    print(f\"Name: {best_exp.get('name')}\")\n",
    "    print(f\"Model Type: {best_exp.get('model_type')}\")\n",
    "    print(f\"CV Score: {best_exp.get('score')}\")\n",
    "    print(f\"Notes: {best_exp.get('notes', '')[:500]}...\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
