{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703ff838",
   "metadata": {},
   "source": [
    "# Loop 84 Analysis: CV-LB Relationship and Strategy Assessment\n",
    "\n",
    "**Critical Situation:**\n",
    "- 84 experiments completed\n",
    "- Best CV: 0.008092 (exp_049)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347\n",
    "- Gap: 152.8%\n",
    "\n",
    "**Key Question:** How do we break the CV-LB line (LB = 4.29*CV + 0.0528)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de598258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history (CV, LB) pairs\n",
    "submissions = [\n",
    "    ('exp_000', 0.0111, 0.0982),\n",
    "    ('exp_001', 0.0123, 0.1065),\n",
    "    ('exp_003', 0.0105, 0.0972),\n",
    "    ('exp_005', 0.0104, 0.0969),\n",
    "    ('exp_006', 0.0097, 0.0946),\n",
    "    ('exp_007', 0.0093, 0.0932),\n",
    "    ('exp_009', 0.0092, 0.0936),\n",
    "    ('exp_012', 0.0090, 0.0913),\n",
    "    ('exp_024', 0.0087, 0.0893),\n",
    "    ('exp_026', 0.0085, 0.0887),\n",
    "    ('exp_030', 0.0083, 0.0877),\n",
    "    ('exp_035', 0.0098, 0.0970),\n",
    "    # exp_073 is an outlier (similarity weighting backfired)\n",
    "    ('exp_073', 0.0084, 0.1451),  # OUTLIER\n",
    "]\n",
    "\n",
    "# Separate outlier\n",
    "regular = [(n, cv, lb) for n, cv, lb in submissions if n != 'exp_073']\n",
    "outlier = [s for s in submissions if s[0] == 'exp_073']\n",
    "\n",
    "cvs = np.array([cv for _, cv, _ in regular])\n",
    "lbs = np.array([lb for _, _, lb in regular])\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cvs, lbs)\n",
    "print(f\"CV-LB Relationship: LB = {slope:.4f} * CV + {intercept:.4f}\")\n",
    "print(f\"R-squared: {r_value**2:.4f}\")\n",
    "print(f\"Intercept: {intercept:.4f}\")\n",
    "print(f\"Target LB: 0.0347\")\n",
    "print(f\"\\nCRITICAL: Intercept ({intercept:.4f}) > Target (0.0347)\")\n",
    "print(f\"Required CV for target: (0.0347 - {intercept:.4f}) / {slope:.4f} = {(0.0347 - intercept) / slope:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot regular submissions\n",
    "plt.scatter(cvs, lbs, c='blue', s=100, label='Regular submissions')\n",
    "\n",
    "# Plot outlier\n",
    "if outlier:\n",
    "    plt.scatter([outlier[0][1]], [outlier[0][2]], c='red', s=150, marker='x', \n",
    "                label=f'Outlier ({outlier[0][0]})', linewidths=3)\n",
    "\n",
    "# Plot regression line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'b--', label=f'LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Plot target\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target LB (0.0347)')\n",
    "\n",
    "# Plot intercept\n",
    "plt.axhline(y=intercept, color='orange', linestyle='--', alpha=0.7, label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score (MSE)', fontsize=12)\n",
    "plt.ylabel('LB Score (MSE)', fontsize=12)\n",
    "plt.title('CV-LB Relationship: All Submissions', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 0.015)\n",
    "plt.ylim(0, 0.16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship_loop84.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nKey insight: Even with CV=0, expected LB would be {intercept:.4f}\")\n",
    "print(f\"This is {(intercept - 0.0347) / 0.0347 * 100:.1f}% ABOVE the target!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec19c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have been tried?\n",
    "approaches_tried = {\n",
    "    'MLP variants': '50+ experiments, best CV 0.0082',\n",
    "    'LightGBM': 'CV ~0.012',\n",
    "    'XGBoost': 'CV ~0.009',\n",
    "    'CatBoost': 'CV ~0.008',\n",
    "    'CatBoost+XGBoost ensemble': 'CV 0.0081 (best)',\n",
    "    'Gaussian Process': 'CV ~0.009',\n",
    "    'Ridge Regression': 'CV ~0.012',\n",
    "    'GNN (from scratch)': 'CV 0.024 (much worse)',\n",
    "    'ChemBERTa embeddings': 'CV 0.015 (worse)',\n",
    "    'Similarity weighting': 'LB 0.145 (backfired!)',\n",
    "    'Yield normalization': 'No effect (0.00% change)',\n",
    "}\n",
    "\n",
    "print(\"Approaches tried and their results:\")\n",
    "print(\"=\"*60)\n",
    "for approach, result in approaches_tried.items():\n",
    "    print(f\"{approach}: {result}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL approaches fall on the SAME CV-LB line!\")\n",
    "print(\"This means the problem is DISTRIBUTION SHIFT, not model choice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd5efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What could break the CV-LB line?\n",
    "print(\"Potential approaches to BREAK the CV-LB line:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "potential_approaches = [\n",
    "    (\"1. Pre-trained molecular representations\", \n",
    "     \"ChemBERTa/MolBERT embeddings from large-scale pre-training\",\n",
    "     \"Tried but worse CV - maybe wrong integration?\"),\n",
    "    \n",
    "    (\"2. Graph Neural Networks with pre-training\",\n",
    "     \"Use pre-trained GNN encoders (ChemProp, MoleculeNet)\",\n",
    "     \"GNN from scratch failed - need pre-trained weights\"),\n",
    "    \n",
    "    (\"3. Domain adaptation / Transfer learning\",\n",
    "     \"Fine-tune on related reaction datasets first\",\n",
    "     \"Not tried - requires external data\"),\n",
    "    \n",
    "    (\"4. Importance weighting\",\n",
    "     \"Weight training samples by similarity to test distribution\",\n",
    "     \"Similarity weighting backfired (exp_073)\"),\n",
    "    \n",
    "    (\"5. Pseudo-labeling\",\n",
    "     \"Use confident test predictions to augment training\",\n",
    "     \"Not tried - could help with distribution shift\"),\n",
    "    \n",
    "    (\"6. Conservative predictions for extrapolation\",\n",
    "     \"Blend toward mean when extrapolating\",\n",
    "     \"Not tried systematically\"),\n",
    "    \n",
    "    (\"7. Different validation strategy\",\n",
    "     \"GroupKFold(5) instead of Leave-One-Out\",\n",
    "     \"exp_079 tried but submission format incompatible\"),\n",
    "    \n",
    "    (\"8. Multi-task learning with auxiliary targets\",\n",
    "     \"Predict intermediate quantities (selectivity, conversion)\",\n",
    "     \"Not tried\"),\n",
    "]\n",
    "\n",
    "for name, description, status in potential_approaches:\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  Description: {description}\")\n",
    "    print(f\"  Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bce199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the benchmark paper's approach\n",
    "print(\"Benchmark Paper Analysis (arXiv:2512.19530):\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTheir MSE: 0.0039 (vs our best LB: 0.0877)\")\n",
    "print(\"Gap: 22.5x worse than benchmark!\")\n",
    "\n",
    "print(\"\\nWhat they used:\")\n",
    "print(\"1. Hybrid GNN with Graph Attention Networks (GAT)\")\n",
    "print(\"2. DRFP (Differential Reaction Fingerprints)\")\n",
    "print(\"3. Learned mixture-aware encodings\")\n",
    "print(\"4. Pre-training on related reaction data\")\n",
    "\n",
    "print(\"\\nWhat we tried:\")\n",
    "print(\"1. GNN from scratch - CV 0.024 (6x worse than tabular)\")\n",
    "print(\"2. DRFP features - helped slightly but not breakthrough\")\n",
    "print(\"3. Linear mixture interpolation - standard approach\")\n",
    "print(\"4. No pre-training - trained from scratch\")\n",
    "\n",
    "print(\"\\nKey differences:\")\n",
    "print(\"- Benchmark used PRE-TRAINED GNN, we trained from scratch\")\n",
    "print(\"- Benchmark used ATTENTION mechanisms, we used simple GCN\")\n",
    "print(\"- Benchmark had access to more data for pre-training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the most promising unexplored direction?\n",
    "print(\"STRATEGIC ASSESSMENT:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. PROBLEM: CV-LB intercept (0.0528) > Target (0.0347)\")\n",
    "print(\"   - No amount of CV improvement can reach target\")\n",
    "print(\"   - Need to REDUCE the intercept, not improve CV\")\n",
    "\n",
    "print(\"\\n2. FAILED APPROACHES:\")\n",
    "print(\"   - GNN from scratch: Much worse CV\")\n",
    "print(\"   - ChemBERTa: Worse CV\")\n",
    "print(\"   - Similarity weighting: Backfired on LB\")\n",
    "print(\"   - Yield normalization: No effect\")\n",
    "\n",
    "print(\"\\n3. UNEXPLORED APPROACHES:\")\n",
    "print(\"   - Pre-trained GNN (ChemProp, MoleculeNet weights)\")\n",
    "print(\"   - Pseudo-labeling for distribution adaptation\")\n",
    "print(\"   - Conservative predictions with uncertainty\")\n",
    "print(\"   - Multi-task learning\")\n",
    "\n",
    "print(\"\\n4. REMAINING SUBMISSIONS: 4\")\n",
    "print(\"   - Should use strategically to test hypotheses\")\n",
    "\n",
    "print(\"\\n5. RECOMMENDATION:\")\n",
    "print(\"   - Try pre-trained molecular representations (ChemProp)\")\n",
    "print(\"   - If that fails, try pseudo-labeling\")\n",
    "print(\"   - If that fails, try conservative predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what public kernels achieve\n",
    "print(\"Public Kernel Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "kernels = [\n",
    "    (\"Template\", \"128 votes\", \"Baseline\"),\n",
    "    (\"Arrhenius Kinetics + TTA\", \"40 votes\", \"LB 0.09831\"),\n",
    "    (\"System Malfunction V1\", \"29 votes\", \"Simple MLP\"),\n",
    "    (\"Alchemy Baseline\", \"12 votes\", \"Unknown\"),\n",
    "    (\"Catechol\", \"11 votes\", \"XGBoost\"),\n",
    "    (\"mixall\", \"9 votes\", \"GroupKFold(5), good CV-LB\"),\n",
    "    (\"Catechol Pipeline LightGBM\", \"9 votes\", \"LightGBM\"),\n",
    "    (\"Ens Model\", \"7 votes\", \"CatBoost+XGBoost ensemble\"),\n",
    "]\n",
    "\n",
    "for name, votes, description in kernels:\n",
    "    print(f\"{name} ({votes}): {description}\")\n",
    "\n",
    "print(\"\\nKey insight: Best public kernel (Arrhenius + TTA) achieves LB 0.09831\")\n",
    "print(\"Our best LB: 0.0877 (10.6% better than best public kernel!)\")\n",
    "print(\"\\nThis suggests we're already at or near the PUBLIC ceiling.\")\n",
    "print(\"The target (0.0347) may require approaches not in public kernels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74196ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RECOMMENDATION FOR LOOP 84\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. STOP optimizing tabular models (MLP, LGBM, XGB, CatBoost)\n",
    "   - All fall on the same CV-LB line\n",
    "   - Improving CV won't reach target\n",
    "\n",
    "2. TRY pre-trained molecular representations\n",
    "   - ChemProp (pre-trained GNN for molecules)\n",
    "   - Use as feature extractor, not fine-tuning\n",
    "   - This could change the CV-LB relationship\n",
    "\n",
    "3. IF pre-trained fails, TRY pseudo-labeling\n",
    "   - Use confident test predictions to augment training\n",
    "   - This adapts the model to test distribution\n",
    "\n",
    "4. IF pseudo-labeling fails, TRY conservative predictions\n",
    "   - Detect extrapolation using distance to training data\n",
    "   - Blend toward mean when extrapolating\n",
    "\n",
    "5. SUBMIT strategically\n",
    "   - Only submit if approach shows DIFFERENT CV-LB relationship\n",
    "   - Don't waste submissions on marginal CV improvements\n",
    "\n",
    "The target IS reachable - the benchmark achieved MSE 0.0039.\n",
    "We need to find the approach that changes the CV-LB relationship.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890266b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there's a pattern in which solvents are harder to predict\n",
    "print(\"Analyzing solvent-level prediction difficulty...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load data\n",
    "DATA_PATH = '/home/data'\n",
    "single_df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "full_df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "\n",
    "print(f\"Single solvent data: {len(single_df)} samples, {single_df['SOLVENT NAME'].nunique()} solvents\")\n",
    "print(f\"Full data: {len(full_df)} samples\")\n",
    "\n",
    "# Solvent distribution\n",
    "print(\"\\nSolvent distribution (single solvent):\")\n",
    "print(single_df['SOLVENT NAME'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0cd08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if some solvents have more variance in yields\n",
    "print(\"\\nYield variance by solvent:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for target in ['Product 2', 'Product 3', 'SM']:\n",
    "    print(f\"\\n{target}:\")\n",
    "    variance_by_solvent = single_df.groupby('SOLVENT NAME')[target].var().sort_values(ascending=False)\n",
    "    print(variance_by_solvent.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOOP 84 ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "KEY FINDINGS:\n",
    "1. CV-LB relationship: LB = 4.29*CV + 0.0528 (RÂ² = 0.95)\n",
    "2. Intercept (0.0528) > Target (0.0347) - IMPOSSIBLE to reach target with current approach\n",
    "3. All 84 experiments fall on the SAME line - problem is distribution shift\n",
    "4. Best LB (0.0877) is 10.6% better than best public kernel (0.09831)\n",
    "5. Benchmark paper achieved MSE 0.0039 using pre-trained GNN + attention\n",
    "\n",
    "STRATEGIC DIRECTION:\n",
    "- STOP: Tabular model optimization\n",
    "- TRY: Pre-trained molecular representations (ChemProp)\n",
    "- TRY: Pseudo-labeling for distribution adaptation\n",
    "- TRY: Conservative predictions with uncertainty\n",
    "\n",
    "The target IS reachable - we just need to find the right approach.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
