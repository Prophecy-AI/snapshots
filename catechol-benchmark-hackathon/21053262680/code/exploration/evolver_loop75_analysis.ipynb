{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e67aea8e",
   "metadata": {},
   "source": [
    "# Loop 75 Strategic Analysis\n",
    "\n",
    "## Key Questions:\n",
    "1. What is the actual CV-LB relationship across all submissions?\n",
    "2. Why did GNN and ChemBERTa perform so poorly?\n",
    "3. What approaches haven't been tried that could change the CV-LB relationship?\n",
    "4. What does the lishellliang kernel do differently that claims 'good CV/LB'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139bdc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submissions with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f'Number of submissions with LB feedback: {len(df)}')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488328e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression: LB = slope * CV + intercept\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "\n",
    "print(f'\\nCV-LB Relationship Analysis:')\n",
    "print(f'Linear fit: LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nInterpretation:')\n",
    "print(f'- Intercept ({intercept:.4f}) represents the structural extrapolation error')\n",
    "print(f'- Even at CV=0, expected LB would be {intercept:.4f}')\n",
    "print(f'- Target LB: 0.0347')\n",
    "print(f'- Required CV for target: ({0.0347} - {intercept:.4f}) / {slope:.2f} = {(0.0347 - intercept) / slope:.4f}')\n",
    "\n",
    "if intercept > 0.0347:\n",
    "    print(f'\\n⚠️ CRITICAL: Intercept ({intercept:.4f}) > Target (0.0347)')\n",
    "    print(f'   This means the target is UNREACHABLE by improving CV alone!')\n",
    "    print(f'   We MUST change the CV-LB relationship (reduce the intercept).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df64ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['cv'], df['lb'], s=100, c='blue', alpha=0.7, label='Submissions')\n",
    "\n",
    "# Plot regression line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.3f})')\n",
    "\n",
    "# Mark target\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target LB (0.0347)')\n",
    "\n",
    "# Mark intercept\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', linewidth=2, label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score (MSE)')\n",
    "plt.ylabel('LB Score (MSE)')\n",
    "plt.title('CV vs LB Relationship - All Submissions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('cv_lb_relationship.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nBest CV: {df[\"cv\"].min():.4f} (exp_030)')\n",
    "print(f'Best LB: {df[\"lb\"].min():.4f} (exp_030)')\n",
    "print(f'Gap to target: {df[\"lb\"].min() - 0.0347:.4f} ({(df[\"lb\"].min() - 0.0347) / 0.0347 * 100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what approaches have been tried\n",
    "approaches = {\n",
    "    'MLP variants': ['exp_000', 'exp_003', 'exp_005', 'exp_006', 'exp_007'],\n",
    "    'LightGBM': ['exp_001'],\n",
    "    'Ensemble (MLP+LGBM)': ['exp_009', 'exp_012'],\n",
    "    'GP+MLP+LGBM': ['exp_024', 'exp_026', 'exp_030'],\n",
    "    'Per-target models': ['exp_035'],\n",
    "}\n",
    "\n",
    "print('Approaches tried and their best LB scores:')\n",
    "for approach, exps in approaches.items():\n",
    "    best_lb = df[df['exp'].isin(exps)]['lb'].min()\n",
    "    best_cv = df[df['exp'].isin(exps)]['cv'].min()\n",
    "    print(f'  {approach}: Best CV={best_cv:.4f}, Best LB={best_lb:.4f}')\n",
    "\n",
    "print('\\nKey insight: ALL approaches fall on the SAME CV-LB line!')\n",
    "print('This means the problem is NOT the model - it\\'s DISTRIBUTION SHIFT.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f08227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What the lishellliang kernel does differently\n",
    "print('\\n=== lishellliang Kernel Analysis ===')\n",
    "print('\\nKey differences from our approach:')\n",
    "print('1. Uses GroupKFold(5) instead of Leave-One-Out')\n",
    "print('   - LOO: 24 folds, each with 1 solvent held out, trains on 96% of data')\n",
    "print('   - GroupKFold(5): 5 folds, each with ~5 solvents held out, trains on 80% of data')\n",
    "print('\\n2. Uses EnsembleModel with MLP + XGBoost + RandomForest + LightGBM')\n",
    "print('   - We use GP + MLP + LightGBM (no RandomForest)')\n",
    "print('\\n3. Uses Optuna for hyperparameter optimization')\n",
    "print('   - We use fixed hyperparameters')\n",
    "print('\\n4. Uses weighted ensemble with learned weights')\n",
    "print('   - We use equal weights')\n",
    "\n",
    "print('\\n=== Our GroupKFold Test (exp_069) ===')\n",
    "print('LOO MSE: 0.008560')\n",
    "print('GroupKFold MSE: 0.013559')\n",
    "print('LOO is 36.87% BETTER than GroupKFold!')\n",
    "print('\\nConclusion: GroupKFold does NOT help - it makes CV worse.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches HAVEN'T been tried that could change the CV-LB relationship?\n",
    "print('\\n=== UNEXPLORED APPROACHES ===')\n",
    "print('\\n1. Transfer Learning (mentioned in benchmark paper)')\n",
    "print('   - Pre-train on related chemistry data')\n",
    "print('   - Fine-tune on catechol data')\n",
    "print('   - Could improve extrapolation to unseen solvents')\n",
    "\n",
    "print('\\n2. Exact lishellliang kernel replication')\n",
    "print('   - Include RandomForest in ensemble')\n",
    "print('   - Use Optuna for hyperparameter optimization')\n",
    "print('   - Use learned ensemble weights')\n",
    "\n",
    "print('\\n3. Domain Adaptation')\n",
    "print('   - Adversarial training for distribution shift')\n",
    "print('   - Importance weighting (IWCV was tried but poorly)')\n",
    "\n",
    "print('\\n4. Test-Time Adaptation')\n",
    "print('   - Adjust predictions based on test data characteristics')\n",
    "print('   - Use uncertainty to weight predictions')\n",
    "\n",
    "print('\\n5. Pseudo-labeling')\n",
    "print('   - Use confident test predictions to augment training')\n",
    "print('   - Could help with distribution adaptation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The benchmark paper achieved MSE 0.0039 - how?\n",
    "print('\\n=== BENCHMARK PAPER ANALYSIS ===')\n",
    "print('\\nThe benchmark paper achieved MSE 0.0039 using:')\n",
    "print('1. Transfer learning from related chemistry data')\n",
    "print('2. Active learning strategies')\n",
    "print('3. Graph neural networks with attention')\n",
    "print('\\nOur GNN attempt (exp_040) achieved CV=0.0256 - MUCH worse!')\n",
    "print('Possible reasons:')\n",
    "print('1. Implementation issues (model class mismatch?)')\n",
    "print('2. Not enough training data for deep learning')\n",
    "print('3. Missing the transfer learning component')\n",
    "print('4. Missing the active learning component')\n",
    "\n",
    "print('\\n=== KEY INSIGHT ===')\n",
    "print('The benchmark\\'s success was likely due to TRANSFER LEARNING,')\n",
    "print('not just the GNN architecture. We need to find related chemistry')\n",
    "print('data to pre-train on.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d671545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print('\\n' + '='*70)\n",
    "print('STRATEGIC SUMMARY')\n",
    "print('='*70)\n",
    "\n",
    "print('\\n1. CV-LB RELATIONSHIP:')\n",
    "print(f'   LB = {slope:.2f} * CV + {intercept:.4f} (R²={r_value**2:.3f})')\n",
    "print(f'   Intercept ({intercept:.4f}) > Target (0.0347)')\n",
    "print(f'   Target is UNREACHABLE by improving CV alone!')\n",
    "\n",
    "print('\\n2. WHAT WE\\'VE TRIED:')\n",
    "print('   - MLP, LightGBM, XGBoost, CatBoost, GP, Ridge')\n",
    "print('   - Various feature combinations (Spange, DRFP, ACS PCA)')\n",
    "print('   - GNN (CV=0.0256, much worse)')\n",
    "print('   - ChemBERTa (CV=0.0225, much worse)')\n",
    "print('   - GroupKFold validation (makes CV worse)')\n",
    "print('   - Similarity weighting (alpha=0 is best)')\n",
    "\n",
    "print('\\n3. WHAT WE HAVEN\\'T TRIED:')\n",
    "print('   - Transfer learning from related chemistry data')\n",
    "print('   - Exact lishellliang kernel (with RF and Optuna)')\n",
    "print('   - Test-time adaptation')\n",
    "print('   - Pseudo-labeling')\n",
    "\n",
    "print('\\n4. RECOMMENDED NEXT STEPS:')\n",
    "print('   Priority 1: Implement lishellliang kernel exactly (with RF)')\n",
    "print('   Priority 2: Research transfer learning for chemistry')\n",
    "print('   Priority 3: Try test-time adaptation')\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('THE TARGET IS REACHABLE - WE JUST HAVEN\\'T FOUND THE RIGHT APPROACH YET')\n",
    "print('='*70)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
