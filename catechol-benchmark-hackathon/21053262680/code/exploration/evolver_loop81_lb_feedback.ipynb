{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45db43e9",
   "metadata": {},
   "source": [
    "# Loop 81 LB Feedback Analysis\n",
    "\n",
    "**CRITICAL FINDING**: exp_073 (similarity_weighting) got LB 0.1451 - MUCH WORSE than expected!\n",
    "\n",
    "- CV: 0.0084\n",
    "- Expected LB (from line): 4.29 * 0.0084 + 0.053 = 0.089\n",
    "- Actual LB: 0.1451\n",
    "- Gap: 0.1451 - 0.089 = 0.056 (63% worse than expected!)\n",
    "\n",
    "This is a MASSIVE outlier from the CV-LB line. Let me analyze why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# All submissions with both CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "    {'exp': 'exp_073', 'cv': 0.0084, 'lb': 0.1451},  # NEW - similarity weighting\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f\"Total submissions with LB: {len(df)}\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression WITHOUT the outlier\n",
    "df_no_outlier = df[df['exp'] != 'exp_073']\n",
    "X = df_no_outlier['cv'].values.reshape(-1, 1)\n",
    "y = df_no_outlier['lb'].values\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X, y)\n",
    "\n",
    "print(f\"CV-LB relationship (without exp_073):\")\n",
    "print(f\"  LB = {reg.coef_[0]:.4f} * CV + {reg.intercept_:.4f}\")\n",
    "print(f\"  RÂ² = {reg.score(X, y):.4f}\")\n",
    "\n",
    "# Predict LB for exp_073\n",
    "exp073_cv = 0.0084\n",
    "exp073_expected_lb = reg.predict([[exp073_cv]])[0]\n",
    "exp073_actual_lb = 0.1451\n",
    "print(f\"\\nexp_073 analysis:\")\n",
    "print(f\"  CV: {exp073_cv}\")\n",
    "print(f\"  Expected LB (from line): {exp073_expected_lb:.4f}\")\n",
    "print(f\"  Actual LB: {exp073_actual_lb}\")\n",
    "print(f\"  Residual: {exp073_actual_lb - exp073_expected_lb:.4f}\")\n",
    "print(f\"  This is {(exp073_actual_lb - exp073_expected_lb) / exp073_expected_lb * 100:.1f}% worse than expected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a3dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV vs LB\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot all points except exp_073\n",
    "plt.scatter(df_no_outlier['cv'], df_no_outlier['lb'], c='blue', s=100, label='Standard submissions')\n",
    "\n",
    "# Plot exp_073 as outlier\n",
    "plt.scatter([0.0084], [0.1451], c='red', s=200, marker='X', label='exp_073 (similarity weighting)')\n",
    "\n",
    "# Plot regression line\n",
    "cv_range = np.linspace(0.007, 0.013, 100)\n",
    "lb_pred = reg.predict(cv_range.reshape(-1, 1))\n",
    "plt.plot(cv_range, lb_pred, 'b--', label=f'LB = {reg.coef_[0]:.2f}*CV + {reg.intercept_:.4f}')\n",
    "\n",
    "# Plot target\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target LB (0.0347)')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship - exp_073 is a MASSIVE OUTLIER')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('/home/code/exploration/cv_lb_with_outlier.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCRITICAL INSIGHT: exp_073 (similarity weighting) is a MASSIVE outlier!\")\n",
    "print(\"The similarity-based mean reversion HURT LB performance significantly.\")\n",
    "print(\"This suggests the test solvents are NOT 'outliers' that need conservative predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e776bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this tell us?\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS: Why did similarity weighting fail so badly?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. HYPOTHESIS WAS WRONG:\n",
    "   - We assumed test solvents were 'outliers' that needed conservative predictions\n",
    "   - But blending toward training mean HURT performance significantly\n",
    "   - This means test solvents are NOT outliers - they're just DIFFERENT\n",
    "\n",
    "2. THE REAL PROBLEM:\n",
    "   - The test solvents have different chemistry than training solvents\n",
    "   - But they're not 'extreme' - they're just in a different region of chemical space\n",
    "   - Blending toward training mean introduces BIAS, not reduces variance\n",
    "\n",
    "3. IMPLICATIONS:\n",
    "   - Distribution shift strategies that assume 'outlier detection' don't work\n",
    "   - We need approaches that LEARN the test distribution, not avoid it\n",
    "   - Pseudo-labeling or domain adaptation might help\n",
    "   - Or we need fundamentally different representations (GNN, Transformers)\n",
    "\n",
    "4. WHAT WORKS:\n",
    "   - Best LB: 0.0877 (exp_030) with GP+MLP+LGBM ensemble\n",
    "   - NO distribution shift handling - just good models\n",
    "   - The CV-LB line is REAL and we can't escape it with conservative predictions\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24883c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate required CV to hit target\n",
    "target_lb = 0.0347\n",
    "slope = reg.coef_[0]\n",
    "intercept = reg.intercept_\n",
    "\n",
    "required_cv = (target_lb - intercept) / slope\n",
    "print(f\"CV-LB relationship: LB = {slope:.4f} * CV + {intercept:.4f}\")\n",
    "print(f\"Target LB: {target_lb}\")\n",
    "print(f\"Required CV to hit target: {required_cv:.6f}\")\n",
    "\n",
    "if required_cv < 0:\n",
    "    print(\"\\nCRITICAL: Required CV is NEGATIVE!\")\n",
    "    print(\"This means the target is UNREACHABLE with current approach.\")\n",
    "    print(\"We MUST change the CV-LB relationship (reduce intercept or slope).\")\n",
    "else:\n",
    "    print(f\"\\nRequired CV improvement: {(0.0083 - required_cv) / 0.0083 * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all approaches tried\n",
    "print(\"=\"*60)\n",
    "print(\"SUMMARY: 81 Experiments, 13 LB Submissions\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "BEST RESULTS:\n",
    "- Best CV: 0.0081 (exp_049, exp_050, exp_053)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "\n",
    "APPROACHES TRIED:\n",
    "1. MLP variants (baseline, deep, residual) - all on same CV-LB line\n",
    "2. LightGBM, XGBoost, CatBoost - all on same CV-LB line\n",
    "3. Gaussian Process - all on same CV-LB line\n",
    "4. Ridge Regression - all on same CV-LB line\n",
    "5. Random Forest - all on same CV-LB line\n",
    "6. GNN attempts - worse CV than tabular (implementation issues?)\n",
    "7. ChemBERTa attempts - worse CV than tabular\n",
    "8. Similarity weighting - MASSIVE OUTLIER (LB 0.1451 vs expected 0.089)\n",
    "9. Various feature combinations - all on same CV-LB line\n",
    "10. Various ensemble strategies - all on same CV-LB line\n",
    "\n",
    "KEY INSIGHT:\n",
    "- ALL tabular approaches fall on the same CV-LB line: LB = 4.29*CV + 0.053\n",
    "- The intercept (0.053) > target (0.0347)\n",
    "- Even CV=0 would give LB=0.053, still 53% above target\n",
    "- Distribution shift handling (similarity weighting) made things WORSE\n",
    "\n",
    "WHAT'S LEFT TO TRY:\n",
    "1. Proper GNN implementation (benchmark achieved MSE 0.0039)\n",
    "2. Pseudo-labeling / domain adaptation\n",
    "3. Different validation scheme (GroupKFold(5) instead of LOO)\n",
    "4. Submit pending experiments to see if any break the line\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fbb9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pending submissions\n",
    "print(\"PENDING SUBMISSIONS (not yet graded):\")\n",
    "pending = [\n",
    "    {'exp': 'exp_049', 'cv': 0.0081, 'desc': 'CatBoost+XGBoost'},\n",
    "    {'exp': 'exp_050', 'cv': 0.0081, 'desc': 'CatBoost+XGBoost fixed'},\n",
    "    {'exp': 'exp_052', 'cv': 0.0109, 'desc': 'CatBoost+XGBoost clipped'},\n",
    "    {'exp': 'exp_053', 'cv': 0.0081, 'desc': 'Exact template'},\n",
    "    {'exp': 'exp_054', 'cv': 0.0085, 'desc': 'Mixall approach'},\n",
    "    {'exp': 'exp_055', 'cv': 0.0085, 'desc': 'Minimal submission'},\n",
    "    {'exp': 'exp_057', 'cv': 0.0093, 'desc': 'Ens-model all features'},\n",
    "    {'exp': 'exp_063', 'cv': 0.0112, 'desc': 'Correct final cell'},\n",
    "    {'exp': 'exp_079', 'cv': 0.0110, 'desc': 'GroupKFold(5)'},\n",
    "]\n",
    "\n",
    "for p in pending:\n",
    "    expected_lb = slope * p['cv'] + intercept\n",
    "    print(f\"  {p['exp']}: CV={p['cv']:.4f}, Expected LB={expected_lb:.4f} - {p['desc']}\")\n",
    "\n",
    "print(\"\\nNone of these are expected to beat target (0.0347) based on the CV-LB line.\")\n",
    "print(\"We need to BREAK the line, not optimize along it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b673d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print(\"=\"*60)\n",
    "print(\"RECOMMENDATION FOR NEXT STEPS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. STOP submitting tabular models - they all fall on the same line\n",
    "\n",
    "2. FOCUS on approaches that might CHANGE the CV-LB relationship:\n",
    "   a) Proper GNN with PyTorch Geometric (benchmark achieved MSE 0.0039)\n",
    "   b) Pseudo-labeling: Use confident test predictions to augment training\n",
    "   c) Domain adaptation: Learn to map test distribution to training\n",
    "\n",
    "3. DO NOT try more distribution shift handling:\n",
    "   - Similarity weighting FAILED (LB 0.1451 vs expected 0.089)\n",
    "   - Conservative predictions introduce BIAS, not reduce variance\n",
    "   - The test solvents are DIFFERENT, not OUTLIERS\n",
    "\n",
    "4. REMAINING SUBMISSIONS: 4\n",
    "   - Use them wisely to test fundamentally different approaches\n",
    "   - Don't waste on tabular variants\n",
    "\n",
    "5. THE TARGET IS REACHABLE:\n",
    "   - Benchmark achieved MSE 0.0039 with GNN\n",
    "   - Our best LB is 0.0877 (2.5x worse than target)\n",
    "   - The gap is large but NOT insurmountable\n",
    "   - We need the RIGHT approach, not more optimization\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nRecordFinding: exp_073 similarity weighting got LB 0.1451 (63% worse than expected 0.089). Distribution shift handling via conservative predictions HURTS performance. Test solvents are DIFFERENT, not OUTLIERS.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
