{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c86b05c",
   "metadata": {},
   "source": [
    "# Loop 89 Analysis: Strategic Assessment\n",
    "\n",
    "## Key Questions:\n",
    "1. What is the CV-LB relationship across all submissions?\n",
    "2. What approaches have been tried and what's their performance?\n",
    "3. What do top public kernels do differently?\n",
    "4. What's the path forward to beat target 0.0347?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history with verified LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "    {'exp': 'exp_073', 'cv': 0.0084, 'lb': 0.1451},  # Similarity weighting - FAILED\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submissions with verified LB scores:')\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f86b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude exp_073 (similarity weighting) as it's an outlier that HURT performance\n",
    "df_clean = df[df['exp'] != 'exp_073']\n",
    "\n",
    "# Fit linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_clean['cv'], df_clean['lb'])\n",
    "\n",
    "print(f'\\n=== CV-LB Relationship (excluding exp_073) ===')\n",
    "print(f'Linear fit: LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nInterpretation:')\n",
    "print(f'  - Intercept: {intercept:.4f} (structural error even at CV=0)')\n",
    "print(f'  - Slope: {slope:.2f} (each 0.001 CV improvement → {slope*0.001:.4f} LB improvement)')\n",
    "\n",
    "# What CV is needed to hit target?\n",
    "target_lb = 0.0347\n",
    "required_cv = (target_lb - intercept) / slope\n",
    "print(f'\\nTo hit target LB {target_lb}:')\n",
    "print(f'  Required CV = ({target_lb} - {intercept:.4f}) / {slope:.2f} = {required_cv:.6f}')\n",
    "if required_cv < 0:\n",
    "    print(f'  ⚠️ IMPOSSIBLE: Required CV is NEGATIVE!')\n",
    "    print(f'  The intercept ({intercept:.4f}) is HIGHER than the target ({target_lb})')\n",
    "    print(f'  This means NO amount of CV improvement can reach the target on this line!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fec215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot all submissions\n",
    "plt.scatter(df_clean['cv'], df_clean['lb'], s=100, c='blue', label='Standard approaches')\n",
    "plt.scatter([0.0084], [0.1451], s=100, c='red', marker='x', label='exp_073 (similarity weighting - FAILED)')\n",
    "\n",
    "# Plot the fitted line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'b--', label=f'Fit: LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Mark the target\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target LB = 0.0347')\n",
    "\n",
    "# Mark the intercept\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', linewidth=1, label=f'Intercept = {intercept:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship - All Submissions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship_loop89.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print('\\nKey insight: The intercept (0.0528) is HIGHER than the target (0.0347)!')\n",
    "print('This means we need to CHANGE THE RELATIONSHIP, not just improve CV.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what approaches have been tried\n",
    "approaches = {\n",
    "    'MLP variants': 50,  # exp_000 to exp_050 mostly\n",
    "    'LightGBM': 5,\n",
    "    'XGBoost': 3,\n",
    "    'CatBoost': 3,\n",
    "    'Gaussian Process': 5,\n",
    "    'Ridge Regression': 2,\n",
    "    'GNN (from scratch)': 5,  # exp_077, 079, 080, 082, 088\n",
    "    'ChemBERTa': 2,\n",
    "    'ChemProp features': 1,\n",
    "    'Similarity weighting': 1,  # exp_073 - FAILED badly\n",
    "    'Pseudo-labeling': 1,\n",
    "}\n",
    "\n",
    "print('=== Approaches Tried ===')\n",
    "for approach, count in approaches.items():\n",
    "    print(f'  {approach}: {count} experiments')\n",
    "\n",
    "print(f'\\nTotal experiments: {sum(approaches.values())}')\n",
    "print('\\nKey findings:')\n",
    "print('  1. ALL tabular approaches (MLP, LGBM, XGB, CatBoost, GP, Ridge) fall on the SAME CV-LB line')\n",
    "print('  2. GNN approaches (5 experiments) all performed 2-3x WORSE than tabular baselines')\n",
    "print('  3. Similarity weighting (exp_073) made LB 63% WORSE (0.0877 → 0.1451)')\n",
    "print('  4. ChemBERTa and ChemProp features did not help')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dadc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do top public kernels do?\n",
    "print('=== Top Public Kernels Analysis ===')\n",
    "print()\n",
    "print('1. \"ens-model\" by matthewmaree:')\n",
    "print('   - CatBoost + XGBoost ensemble')\n",
    "print('   - Combined features: spange + acs_pca + drfps + fragprints + smiles')\n",
    "print('   - Correlation-based feature filtering (threshold 0.90)')\n",
    "print('   - Different weights for single vs full data')\n",
    "print('   - Single: CatBoost 7, XGB 6')\n",
    "print('   - Full: CatBoost 1, XGB 2')\n",
    "print()\n",
    "print('2. \"mixall\" by lishellliang:')\n",
    "print('   - Uses GroupKFold (5 splits) instead of Leave-One-Out')\n",
    "print('   - Ensemble of MLP + XGBoost + RandomForest + LightGBM')\n",
    "print('   - Optuna hyperparameter optimization')\n",
    "print('   - Claims \"good CV/LB\" in title')\n",
    "print()\n",
    "print('3. \"System Malfunction V1\" by omarafik:')\n",
    "print('   - Simple MLP with Spange descriptors')\n",
    "print('   - Standard Leave-One-Out CV')\n",
    "print('   - No special tricks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feebc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical analysis: Why is the target 0.0347 so much lower than our best LB 0.0877?\n",
    "print('=== Gap Analysis ===')\n",
    "print(f'Best LB achieved: 0.0877')\n",
    "print(f'Target LB: 0.0347')\n",
    "print(f'Gap: {0.0877 - 0.0347:.4f} ({(0.0877 - 0.0347) / 0.0347 * 100:.1f}%)')\n",
    "print()\n",
    "print('Possible explanations:')\n",
    "print('  1. The benchmark paper (MSE 0.0039) used pre-training on large molecular datasets')\n",
    "print('  2. The benchmark paper may have used different data splits')\n",
    "print('  3. The benchmark paper may have had access to additional data')\n",
    "print('  4. Our validation scheme (Leave-One-Out by solvent) may be harder than theirs')\n",
    "print('  5. There may be a technique we haven\\'t discovered yet')\n",
    "print()\n",
    "print('What we KNOW doesn\\'t work:')\n",
    "print('  - GNN from scratch (5 experiments, all 2-3x worse)')\n",
    "print('  - ChemBERTa embeddings (failed)')\n",
    "print('  - ChemProp features (failed)')\n",
    "print('  - Similarity weighting (made LB 63% worse)')\n",
    "print('  - Distribution shift handling via conservative predictions (hurt performance)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f53d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What haven't we tried?\n",
    "print('=== Unexplored Approaches ===')\n",
    "print()\n",
    "print('1. EXACT replication of \"ens-model\" kernel:')\n",
    "print('   - We tried CatBoost + XGBoost but maybe not with the exact feature combination')\n",
    "print('   - The kernel uses ALL features: spange + acs_pca + drfps + fragprints + smiles')\n",
    "print('   - With correlation filtering at threshold 0.90')\n",
    "print()\n",
    "print('2. Pre-trained molecular models with FINE-TUNING:')\n",
    "print('   - We tried ChemBERTa as frozen embeddings')\n",
    "print('   - We haven\\'t tried fine-tuning ChemBERTa on our data')\n",
    "print()\n",
    "print('3. Multi-task learning with auxiliary targets:')\n",
    "print('   - We tried predicting P2, P3, SM separately')\n",
    "print('   - We haven\\'t tried predicting mass balance or selectivity as auxiliary targets')\n",
    "print()\n",
    "print('4. Data augmentation strategies:')\n",
    "print('   - We tried TTA for mixtures')\n",
    "print('   - We haven\\'t tried noise injection or SMOTE-like augmentation')\n",
    "print()\n",
    "print('5. Stacking with meta-learner:')\n",
    "print('   - We tried simple weighted averaging')\n",
    "print('   - We haven\\'t tried a proper stacking approach with a meta-learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3392f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendation\n",
    "print('=== STRATEGIC RECOMMENDATION ===')\n",
    "print()\n",
    "print('CRITICAL INSIGHT: The CV-LB intercept (0.0528) is HIGHER than the target (0.0347).')\n",
    "print('This means NO amount of CV improvement on the current line can reach the target.')\n",
    "print()\n",
    "print('OPTIONS:')\n",
    "print()\n",
    "print('Option A: Try to CHANGE the CV-LB relationship')\n",
    "print('  - This requires a fundamentally different approach')\n",
    "print('  - GNN from scratch failed (5 experiments)')\n",
    "print('  - ChemBERTa failed')\n",
    "print('  - Similarity weighting made things WORSE')\n",
    "print('  - We\\'ve exhausted most obvious approaches')\n",
    "print()\n",
    "print('Option B: Accept that the target may be unreachable with available techniques')\n",
    "print('  - The benchmark paper\\'s MSE 0.0039 may require pre-training or different data')\n",
    "print('  - Our best LB (0.0877) may be near the ceiling for this approach')\n",
    "print()\n",
    "print('Option C: Try the EXACT approach from top public kernels')\n",
    "print('  - The \"ens-model\" kernel combines ALL features with correlation filtering')\n",
    "print('  - We should replicate this EXACTLY and see if it improves')\n",
    "print()\n",
    "print('RECOMMENDATION: Option C - Replicate \"ens-model\" kernel exactly')\n",
    "print('  - It\\'s a low-risk approach that we haven\\'t tried exactly')\n",
    "print('  - If it doesn\\'t improve, we\\'ve exhausted reasonable options')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
