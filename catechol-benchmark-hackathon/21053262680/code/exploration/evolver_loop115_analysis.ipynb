{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d45a4b71",
   "metadata": {},
   "source": [
    "# Loop 115 Analysis: Critical Assessment\n",
    "\n",
    "## Key Facts\n",
    "- **115 experiments** conducted\n",
    "- **24 submissions** made (3 remaining)\n",
    "- **Best LB**: 0.0877 (exp_030, CV=0.0083)\n",
    "- **Target**: 0.0347\n",
    "- **Gap**: 152.8%\n",
    "\n",
    "## CV-LB Relationship (CRITICAL)\n",
    "- **LB = 4.07 × CV + 0.0548** (R² = 0.96)\n",
    "- **Intercept (0.0548) > Target (0.0347)**\n",
    "- **Required CV to hit target**: -0.0049 (IMPOSSIBLE)\n",
    "\n",
    "## Latest Experiment: Domain-Adversarial Training (FAILED)\n",
    "- CV = 0.168 (20x worse than best 0.0081)\n",
    "- The approach removes solvent information, which is essential for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CV-LB data from submissions\n",
    "submissions = [\n",
    "    ('exp_000', 0.011081, 0.09816),\n",
    "    ('exp_001', 0.012297, 0.10649),\n",
    "    ('exp_003', 0.010501, 0.09719),\n",
    "    ('exp_005', 0.01043, 0.09691),\n",
    "    ('exp_006', 0.009749, 0.09457),\n",
    "    ('exp_007', 0.009262, 0.09316),\n",
    "    ('exp_009', 0.009192, 0.09364),\n",
    "    ('exp_012', 0.009004, 0.09134),\n",
    "    ('exp_024', 0.008689, 0.08929),\n",
    "    ('exp_026', 0.008465, 0.08875),\n",
    "    ('exp_030', 0.008298, 0.08772),\n",
    "    ('exp_035', 0.009825, 0.09696),\n",
    "    ('exp_073', 0.00839, 0.14507),  # OUTLIER\n",
    "    ('exp_111', 0.012912, 0.10632),\n",
    "]\n",
    "\n",
    "# Filter valid (exclude outlier exp_073)\n",
    "valid = [(name, cv, lb) for name, cv, lb in submissions if lb < 0.12]\n",
    "print(f'Valid submissions: {len(valid)}')\n",
    "\n",
    "cvs = np.array([v[1] for v in valid])\n",
    "lbs = np.array([v[2] for v in valid])\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cvs, lbs)\n",
    "\n",
    "print(f'\\n=== CV-LB RELATIONSHIP ===')\n",
    "print(f'LB = {slope:.4f} × CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'Intercept = {intercept:.4f}')\n",
    "print(f'Target = 0.0347')\n",
    "print(f'Required CV = (0.0347 - {intercept:.4f}) / {slope:.4f} = {(0.0347 - intercept) / slope:.6f}')\n",
    "print(f'\\nBest LB: {min(lbs):.4f} (CV={cvs[np.argmin(lbs)]:.4f})')\n",
    "print(f'Gap to target: {min(lbs) - 0.0347:.4f} ({(min(lbs) - 0.0347)/0.0347*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cvs, lbs, s=100, alpha=0.7, label='Submissions')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}×CV + {intercept:.4f} (R²={r_value**2:.3f})')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='g', linestyle=':', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Intercept line\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', linewidth=2, label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score', fontsize=12)\n",
    "plt.ylabel('LB Score', fontsize=12)\n",
    "plt.title('CV-LB Relationship: The Intercept Problem', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship_loop115.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n⚠️ CRITICAL: Intercept ({intercept:.4f}) > Target ({0.0347})')\n",
    "print(f'This means even with CV=0, expected LB would be {intercept:.4f}')\n",
    "print(f'The target is MATHEMATICALLY UNREACHABLE with approaches on this line!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eabb23",
   "metadata": {},
   "source": [
    "## What Has Been Tried (115 experiments)\n",
    "\n",
    "### Model Families Tested:\n",
    "1. **MLP variants** (exp_000-010, many others) - All on same CV-LB line\n",
    "2. **LightGBM** (exp_001, 057, etc.) - Same line\n",
    "3. **XGBoost** (exp_049-053) - Same line\n",
    "4. **CatBoost** (exp_049-053) - Same line\n",
    "5. **Gaussian Process** (exp_030-035) - Same line\n",
    "6. **Ridge Regression** (exp_033) - Same line\n",
    "7. **Random Forest** (exp_073) - OUTLIER (worse)\n",
    "8. **GNN** (exp_040, 070, 079, 095-096) - 3-4x worse CV\n",
    "9. **ChemBERTa** (exp_041, 071, 076, 097-098) - 2-3x worse CV\n",
    "10. **Domain-Adversarial** (exp_113) - 20x worse CV\n",
    "\n",
    "### Distribution Shift Strategies Tested:\n",
    "1. **Extrapolation detection** (exp_058-059, 105) - Made CV worse\n",
    "2. **Uncertainty weighting** (exp_107) - No improvement\n",
    "3. **Chemical similarity blending** (exp_108, 110-111) - No improvement\n",
    "4. **Pseudo-labeling** (exp_112) - Marginal improvement\n",
    "5. **Bias correction** (exp_104, 106) - No improvement\n",
    "\n",
    "### Feature Engineering Tested:\n",
    "1. **Spange descriptors** - Best single source\n",
    "2. **DRFP fingerprints** - Worse alone, marginal help combined\n",
    "3. **ACS PCA descriptors** - Marginal help\n",
    "4. **Fragprints** - Marginal help\n",
    "5. **ChemBERTa embeddings** - Made things worse\n",
    "6. **Arrhenius kinetics** - Helpful\n",
    "7. **Combined features** - Best approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c164aa",
   "metadata": {},
   "source": [
    "## The Core Problem\n",
    "\n",
    "**ALL approaches fall on the SAME CV-LB line with R² = 0.96**\n",
    "\n",
    "This means:\n",
    "1. The problem is NOT the model architecture\n",
    "2. The problem is NOT the feature engineering\n",
    "3. The problem IS the fundamental mismatch between training and test distributions\n",
    "\n",
    "**The intercept (0.0548) represents STRUCTURAL extrapolation error that:**\n",
    "- Cannot be reduced by improving CV\n",
    "- Cannot be reduced by changing model family\n",
    "- Cannot be reduced by changing features\n",
    "- CAN ONLY be reduced by changing the CV-LB relationship itself\n",
    "\n",
    "## What Would Change the Relationship?\n",
    "\n",
    "1. **Different validation scheme** - But we must use Leave-One-Out per competition rules\n",
    "2. **Post-hoc calibration** - Shift predictions based on known CV-LB relationship\n",
    "3. **Physics constraints** - Mass balance, Arrhenius constraints that generalize\n",
    "4. **Test-time adaptation** - Use test data structure to adapt predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a403a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what the best public kernels achieve\n",
    "print('=== PUBLIC KERNEL ANALYSIS ===')\n",
    "print()\n",
    "print('1. \"mixall\" kernel (lishellliang):')\n",
    "print('   - Uses GroupKFold (5 splits) instead of Leave-One-Out')\n",
    "print('   - Ensemble: MLP + XGBoost + RandomForest + LightGBM')\n",
    "print('   - Claims \"good CV/LB\" but uses different validation')\n",
    "print()\n",
    "print('2. \"ens-model\" kernel (matthewmaree):')\n",
    "print('   - CatBoost + XGBoost ensemble')\n",
    "print('   - Weights: single (7:6), full (1:2)')\n",
    "print('   - Combined features: spange + acs + drfps + fragprints + smiles')\n",
    "print('   - Correlation-based feature filtering')\n",
    "print('   - Arrhenius kinetics features')\n",
    "print()\n",
    "print('Key insight: Both kernels use similar approaches to what we\\'ve tried.')\n",
    "print('The best public LB is ~0.09, which is on the SAME CV-LB line.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a145d",
   "metadata": {},
   "source": [
    "## Strategic Options with 3 Submissions Remaining\n",
    "\n",
    "### Option A: Post-hoc Calibration (RISKY)\n",
    "- If LB = 4.07 × CV + 0.0548, and we want LB = 0.0347\n",
    "- We need to shift predictions by (0.0548 - 0.0347) = 0.0201\n",
    "- This is a heuristic that might help or hurt\n",
    "\n",
    "### Option B: Physics-Constrained Predictions (MODERATE RISK)\n",
    "- Enforce mass balance: yields sum to ~1\n",
    "- Enforce Arrhenius: temperature dependence follows exponential form\n",
    "- These constraints generalize to unseen solvents\n",
    "\n",
    "### Option C: Conservative Blending for Outliers (MODERATE RISK)\n",
    "- Detect samples that are \"far\" from training distribution\n",
    "- Blend toward training mean for these samples\n",
    "- Already tried (exp_105, 107, 108, 111) - didn't help\n",
    "\n",
    "### Option D: Submit Best CV Model (SAFE)\n",
    "- exp_030 (CV=0.0083, LB=0.0877) is our best\n",
    "- No new experiments, just verify submission\n",
    "\n",
    "### Option E: Try Completely Different Representation (HIGH RISK)\n",
    "- GNN/ChemBERTa failed badly\n",
    "- Domain-adversarial failed badly\n",
    "- What else is there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what calibration would need to achieve\n",
    "print('=== CALIBRATION ANALYSIS ===')\n",
    "print()\n",
    "print('Current best: CV=0.0083, LB=0.0877')\n",
    "print('Target: LB=0.0347')\n",
    "print('Gap: 0.0530 (152.8%)')\n",
    "print()\n",
    "print('If we apply a linear calibration:')\n",
    "print('  calibrated_LB = a × raw_LB + b')\n",
    "print()\n",
    "print('To map 0.0877 → 0.0347:')\n",
    "print('  If a=1: b = 0.0347 - 0.0877 = -0.0530')\n",
    "print('  This means subtracting 0.0530 from all predictions')\n",
    "print()\n",
    "print('But this is WRONG because:')\n",
    "print('  1. We don\\'t know the true LB until submission')\n",
    "print('  2. The calibration would need to be applied to predictions, not LB')\n",
    "print('  3. The relationship is between CV and LB, not raw predictions and LB')\n",
    "print()\n",
    "print('The ONLY way to reduce LB is to:')\n",
    "print('  1. Reduce CV (but we\\'re already at 0.0083, and target requires -0.0049)')\n",
    "print('  2. Change the CV-LB relationship (intercept or slope)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93252b7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**The target (0.0347) appears to be unreachable with current approaches.**\n",
    "\n",
    "However, per the PRIME DIRECTIVE, we MUST NOT GIVE UP.\n",
    "\n",
    "**Remaining options:**\n",
    "1. Try a fundamentally different approach that hasn't been tested\n",
    "2. Look for bugs in our best models that might be hurting LB\n",
    "3. Try post-hoc calibration as a last resort\n",
    "4. Submit our best model and hope for the best\n",
    "\n",
    "**With 3 submissions remaining, we should:**\n",
    "1. NOT waste submissions on approaches that fall on the same line\n",
    "2. ONLY submit if we have evidence the approach changes the relationship\n",
    "3. Consider submitting exp_049/050/053 (CV=0.0081) which have pending LB scores"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
