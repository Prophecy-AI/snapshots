{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be7a852",
   "metadata": {},
   "source": [
    "# Experiment 107: Uncertainty-Weighted Conservative Predictions\n",
    "\n",
    "## Goal\n",
    "When the model is uncertain (high ensemble disagreement), blend toward a conservative prediction. This might reduce the CV-LB intercept by making more conservative predictions for hard-to-predict samples.\n",
    "\n",
    "## Key Insight\n",
    "The CV-LB relationship is LB = 4.31 Ã— CV + 0.0525. The intercept (0.0525) > target (0.0347). We need to CHANGE this relationship, not just improve CV.\n",
    "\n",
    "## Approach\n",
    "1. Train multiple models with different random seeds\n",
    "2. Compute prediction uncertainty (std across models)\n",
    "3. Blend toward training mean when uncertainty is high\n",
    "4. Test different blend thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd806a51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:14:22.173400Z",
     "iopub.status.busy": "2026-01-16T18:14:22.172853Z",
     "iopub.status.idle": "2026-01-16T18:14:23.123916Z",
     "shell.execute_reply": "2026-01-16T18:14:23.123524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add data path\n",
    "sys.path.append('/home/data/')\n",
    "\n",
    "# Override the load functions to use local paths\n",
    "DATA_PATH = '/home/data/'\n",
    "\n",
    "TARGET_LABELS = ['Product 2', 'Product 3', 'SM']\n",
    "\n",
    "def load_data_local(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}catechol_full_data_yields.csv')\n",
    "        INPUT_LABELS = ['SOLVENT A NAME', 'SOLVENT B NAME', 'SolventB%', 'Temperature', 'Residence Time']\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}catechol_single_solvent_yields.csv')\n",
    "        INPUT_LABELS = ['SOLVENT NAME', 'Temperature', 'Residence Time']\n",
    "    \n",
    "    X = df[INPUT_LABELS]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features_local(name=\"spange_descriptors\"):\n",
    "    assert name in [\"spange_descriptors\", \"acs_pca_descriptors\", \"drfps_catechol\", \"fragprints\", \"smiles\"]\n",
    "    features = pd.read_csv(f'{DATA_PATH}{name}_lookup.csv', index_col=0)\n",
    "    return features\n",
    "\n",
    "# Import the split generators from utils\n",
    "from utils import generate_leave_one_out_splits, generate_leave_one_ramp_out_splits\n",
    "\n",
    "# Override load functions\n",
    "load_data = load_data_local\n",
    "load_features = load_features_local\n",
    "\n",
    "# Get input labels from utils\n",
    "from utils import INPUT_LABELS_FULL_SOLVENT, INPUT_LABELS_SINGLE_SOLVENT, INPUT_LABELS_NUMERIC\n",
    "\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f6dc46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:14:23.125067Z",
     "iopub.status.busy": "2026-01-16T18:14:23.124919Z",
     "iopub.status.idle": "2026-01-16T18:14:23.135558Z",
     "shell.execute_reply": "2026-01-16T18:14:23.135213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering functions defined\n"
     ]
    }
   ],
   "source": [
    "# Base classes and feature engineering (from ens-model kernel)\n",
    "from abc import ABC, abstractmethod\n",
    "from functools import reduce\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "    def featurize(X, Y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "    def predict(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "_SOLVENT_TABLE_CACHE = None\n",
    "\n",
    "def feature_priority(name: str) -> int:\n",
    "    if name.startswith(\"spange_\"): return 5\n",
    "    if name.startswith(\"acs_\"): return 4\n",
    "    if name.startswith(\"drfps_\"): return 3\n",
    "    if name.startswith(\"frag_\"): return 2\n",
    "    if name.startswith(\"smiles_\"): return 1\n",
    "    return 0\n",
    "\n",
    "def filter_correlated_features(df, threshold=0.8):\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    if numeric_df.shape[1] == 0:\n",
    "        return df, []\n",
    "    std = numeric_df.std(axis=0)\n",
    "    constant_cols = std[std == 0].index.tolist()\n",
    "    if constant_cols:\n",
    "        numeric_df = numeric_df.drop(columns=constant_cols)\n",
    "    corr = numeric_df.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool)).fillna(0.0)\n",
    "    cols = upper.columns.tolist()\n",
    "    to_drop = set()\n",
    "    high_corr_pairs = []\n",
    "    for i, col_i in enumerate(cols):\n",
    "        for j in range(i + 1, len(cols)):\n",
    "            col_j = cols[j]\n",
    "            cval = upper.iloc[i, j]\n",
    "            if cval > threshold:\n",
    "                high_corr_pairs.append((col_i, col_j, cval))\n",
    "    for col_i, col_j, cval in high_corr_pairs:\n",
    "        if col_i in to_drop or col_j in to_drop:\n",
    "            continue\n",
    "        p_i = feature_priority(col_i)\n",
    "        p_j = feature_priority(col_j)\n",
    "        if p_i > p_j:\n",
    "            drop = col_j\n",
    "        elif p_j > p_i:\n",
    "            drop = col_i\n",
    "        else:\n",
    "            idx_i = df.columns.get_loc(col_i)\n",
    "            idx_j = df.columns.get_loc(col_j)\n",
    "            drop = col_i if idx_i > idx_j else col_j\n",
    "        to_drop.add(drop)\n",
    "    all_to_drop = list(set(constant_cols).union(to_drop))\n",
    "    df_filtered = df.drop(columns=all_to_drop, errors=\"ignore\")\n",
    "    return df_filtered, all_to_drop\n",
    "\n",
    "def add_numeric_features(X_numeric):\n",
    "    X_num = X_numeric.copy()\n",
    "    cols = set(X_num.columns)\n",
    "    if {\"Temperature\", \"Residence Time\"} <= cols:\n",
    "        X_num[\"Temperature\"] = X_num[\"Temperature\"] + 273.15\n",
    "        T = X_num[\"Temperature\"]\n",
    "        rt = X_num[\"Residence Time\"]\n",
    "        X_num[\"T_x_RT\"] = T * rt\n",
    "        X_num[\"RT_log\"] = np.log(rt + 1e-6)\n",
    "        X_num[\"T_inv\"] = 1 / T\n",
    "        X_num[\"RT_scaled\"] = rt / rt.mean()\n",
    "    return X_num\n",
    "\n",
    "def build_solvent_feature_table(threshold=0.90):\n",
    "    global _SOLVENT_TABLE_CACHE\n",
    "    if _SOLVENT_TABLE_CACHE is not None:\n",
    "        return _SOLVENT_TABLE_CACHE\n",
    "    print(\">>> Building solvent feature table...\")\n",
    "    sources = [\"spange_descriptors\", \"acs_pca_descriptors\", \"drfps_catechol\", \"fragprints\", \"smiles\"]\n",
    "    dfs = []\n",
    "    for src in sources:\n",
    "        df_src = load_features(src).copy()\n",
    "        if \"SOLVENT NAME\" not in df_src.columns:\n",
    "            df_src = df_src.reset_index().rename(columns={\"index\": \"SOLVENT NAME\"})\n",
    "        if src in [\"drfps_catechol\", \"fragprints\"]:\n",
    "            prefix = \"drfps\" if src == \"drfps_catechol\" else \"frag\"\n",
    "            df_src = df_src.loc[:, (df_src != 0).any(axis=0)]\n",
    "            df_src = df_src.loc[:, (df_src != 1).any(axis=0)]\n",
    "            values = df_src.drop(columns={\"SOLVENT NAME\"})\n",
    "            count = values.sum(axis=0).T\n",
    "            drop_cols = count[count == 1].index\n",
    "            df_src = df_src.drop(columns=drop_cols)\n",
    "            cols_to_rename = [c for c in df_src.columns if c != \"SOLVENT NAME\"]\n",
    "            df_src = df_src.rename(columns={c: f\"{prefix}_{c}\" for c in cols_to_rename})\n",
    "        else:\n",
    "            if src == \"spange_descriptors\": prefix = \"spange\"\n",
    "            elif src == \"acs_pca_descriptors\": prefix = \"acs\"\n",
    "            elif src == \"smiles\": prefix = \"smiles\"\n",
    "            else: prefix = src\n",
    "            cols_to_rename = [c for c in df_src.columns if c != \"SOLVENT NAME\"]\n",
    "            df_src = df_src.rename(columns={c: f\"{prefix}_{c}\" for c in cols_to_rename})\n",
    "        smiles_like = [c for c in df_src.columns if \"SMILES\" in c.upper()]\n",
    "        df_src = df_src.drop(columns=smiles_like, errors=\"ignore\")\n",
    "        df_src = df_src.set_index(\"SOLVENT NAME\")\n",
    "        dfs.append(df_src)\n",
    "    featurizer = reduce(lambda l, r: l.join(r, how=\"inner\"), dfs)\n",
    "    print(f\"Combined feature table shape (before corr filter): {featurizer.shape}\")\n",
    "    featurizer_filtered, dropped_cols = filter_correlated_features(featurizer, threshold=threshold)\n",
    "    print(f\"Final solvent feature table shape: {featurizer_filtered.shape}\")\n",
    "    _SOLVENT_TABLE_CACHE = featurizer_filtered\n",
    "    return featurizer_filtered\n",
    "\n",
    "print(\"Feature engineering functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9f7d96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:14:23.136584Z",
     "iopub.status.busy": "2026-01-16T18:14:23.136481Z",
     "iopub.status.idle": "2026-01-16T18:14:23.140971Z",
     "shell.execute_reply": "2026-01-16T18:14:23.140633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizers defined\n"
     ]
    }
   ],
   "source": [
    "# Featurizers\n",
    "class PrecomputedFeaturizer(SmilesFeaturizer):\n",
    "    def __init__(self):\n",
    "        self.featurizer = build_solvent_feature_table()\n",
    "        dummy_num = pd.DataFrame([[0] * len(INPUT_LABELS_NUMERIC)], columns=INPUT_LABELS_NUMERIC)\n",
    "        numeric_dim = add_numeric_features(dummy_num).shape[1]\n",
    "        self.feats_dim = numeric_dim + self.featurizer.shape[1]\n",
    "\n",
    "    def featurize(self, X):\n",
    "        X_numeric = add_numeric_features(X[INPUT_LABELS_NUMERIC].copy())\n",
    "        X_solvent = self.featurizer.loc[X[\"SOLVENT NAME\"]]\n",
    "        X_out = np.concatenate([X_numeric.values, X_solvent.values], axis=1)\n",
    "        return torch.tensor(X_out, dtype=torch.double)\n",
    "\n",
    "class PrecomputedFeaturizerMixed(SmilesFeaturizer):\n",
    "    def __init__(self):\n",
    "        self.featurizer = build_solvent_feature_table()\n",
    "        dummy_num = pd.DataFrame([[0] * len(INPUT_LABELS_NUMERIC)], columns=INPUT_LABELS_NUMERIC)\n",
    "        numeric_dim = add_numeric_features(dummy_num).shape[1]\n",
    "        self.feats_dim = numeric_dim + self.featurizer.shape[1]\n",
    "\n",
    "    def featurize(self, X):\n",
    "        X_numeric = add_numeric_features(X[INPUT_LABELS_NUMERIC].copy())\n",
    "        A = self.featurizer.loc[X[\"SOLVENT A NAME\"]].values\n",
    "        B = self.featurizer.loc[X[\"SOLVENT B NAME\"]].values\n",
    "        frac_B = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "        frac_A = 1 - frac_B\n",
    "        mixed = A * frac_A + B * frac_B\n",
    "        X_out = np.concatenate([X_numeric.values, mixed], axis=1)\n",
    "        return torch.tensor(X_out, dtype=torch.double)\n",
    "\n",
    "print(\"Featurizers defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02359132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:14:23.141861Z",
     "iopub.status.busy": "2026-01-16T18:14:23.141766Z",
     "iopub.status.idle": "2026-01-16T18:14:23.527952Z",
     "shell.execute_reply": "2026-01-16T18:14:23.527591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostModel defined\n"
     ]
    }
   ],
   "source": [
    "# CatBoost Model with random seed support\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "class CatBoostModel(BaseModel):\n",
    "    def __init__(self, data=\"single\", verbose=False, random_state=42):\n",
    "        self.data_mode = data\n",
    "        self.verbose = verbose\n",
    "        self.random_state = random_state\n",
    "        if data == \"single\":\n",
    "            self.smiles_featurizer = PrecomputedFeaturizer()\n",
    "            self.cat_params = dict(\n",
    "                random_seed=random_state, loss_function=\"MultiRMSE\",\n",
    "                depth=3, learning_rate=0.07, n_estimators=1050,\n",
    "                l2_leaf_reg=3.5, bootstrap_type=\"Bayesian\",\n",
    "                bagging_temperature=0.225, grow_policy=\"SymmetricTree\",\n",
    "                rsm=0.75, verbose=verbose,\n",
    "            )\n",
    "        else:\n",
    "            self.smiles_featurizer = PrecomputedFeaturizerMixed()\n",
    "            self.cat_params = dict(\n",
    "                random_seed=random_state, loss_function=\"MultiRMSE\",\n",
    "                depth=3, learning_rate=0.06, n_estimators=1100,\n",
    "                l2_leaf_reg=2.5, bootstrap_type=\"Bayesian\",\n",
    "                bagging_temperature=0.25, grow_policy=\"SymmetricTree\",\n",
    "                rsm=0.75, verbose=verbose,\n",
    "            )\n",
    "        self.model = None\n",
    "        self.n_targets = None\n",
    "\n",
    "    def train_model(self, train_X, train_Y, device=None, verbose=False):\n",
    "        X_tensor = self.smiles_featurizer.featurize(train_X)\n",
    "        X_np = X_tensor.detach().cpu().numpy()\n",
    "        Y_np = train_Y.values\n",
    "        self.n_targets = Y_np.shape[1]\n",
    "        self.model = CatBoostRegressor(**self.cat_params)\n",
    "        self.model.fit(X_np, Y_np)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_tensor = self.smiles_featurizer.featurize(X)\n",
    "        X_np = X_tensor.detach().cpu().numpy()\n",
    "        out = self.model.predict(X_np)\n",
    "        out = np.asarray(out)\n",
    "        if out.ndim == 1:\n",
    "            out = out.reshape(-1, 1)\n",
    "        out = np.clip(out, a_min=0.0, a_max=None)\n",
    "        if out.shape[1] > 1:\n",
    "            totals = out.sum(axis=1, keepdims=True)\n",
    "            divisor = np.maximum(totals, 1.0)\n",
    "            out = out / divisor\n",
    "        return torch.tensor(out, dtype=torch.double)\n",
    "\n",
    "print(\"CatBoostModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54540327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:14:23.529133Z",
     "iopub.status.busy": "2026-01-16T18:14:23.528991Z",
     "iopub.status.idle": "2026-01-16T18:14:23.534592Z",
     "shell.execute_reply": "2026-01-16T18:14:23.534221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBModel defined\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Model with random seed support\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "class XGBModel(BaseModel):\n",
    "    def __init__(self, data=\"single\", random_state=42, verbose=False):\n",
    "        self.data_mode = data\n",
    "        self.verbose = verbose\n",
    "        self.random_state = random_state\n",
    "        if data == \"single\":\n",
    "            self.smiles_featurizer = PrecomputedFeaturizer()\n",
    "            self.xgb_params = dict(\n",
    "                random_state=random_state, objective=\"reg:squarederror\",\n",
    "                tree_method=\"hist\", subsample=0.5, reg_lambda=0.6,\n",
    "                reg_alpha=0.0, n_estimators=1000, min_child_weight=1,\n",
    "                max_depth=4, max_delta_step=1, learning_rate=0.02,\n",
    "                grow_policy=\"depthwise\", gamma=0.0, colsample_bytree=0.3,\n",
    "                colsample_bylevel=0.6,\n",
    "            )\n",
    "        else:\n",
    "            self.smiles_featurizer = PrecomputedFeaturizerMixed()\n",
    "            self.xgb_params = dict(\n",
    "                random_state=random_state, objective=\"reg:squarederror\",\n",
    "                tree_method=\"approx\", subsample=0.5, reg_lambda=0.6,\n",
    "                reg_alpha=0.0, n_estimators=1000, min_child_weight=1,\n",
    "                max_depth=4, max_delta_step=1, learning_rate=0.02,\n",
    "                grow_policy=\"lossguide\", gamma=0.0, colsample_bytree=0.3,\n",
    "                colsample_bylevel=0.6,\n",
    "            )\n",
    "        self.models = None\n",
    "        self.n_targets = None\n",
    "\n",
    "    def train_model(self, train_X, train_Y, device=None, verbose=False):\n",
    "        X_tensor = self.smiles_featurizer.featurize(train_X)\n",
    "        X_np = X_tensor.detach().cpu().numpy()\n",
    "        Y_np = train_Y.values\n",
    "        self.n_targets = Y_np.shape[1]\n",
    "        self.models = []\n",
    "        for t in range(self.n_targets):\n",
    "            model_t = XGBRegressor(**self.xgb_params)\n",
    "            model_t.fit(X_np, Y_np[:, t])\n",
    "            self.models.append(model_t)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_tensor = self.smiles_featurizer.featurize(X)\n",
    "        X_np = X_tensor.detach().cpu().numpy()\n",
    "        preds_list = [m.predict(X_np) for m in self.models]\n",
    "        out = np.column_stack(preds_list)\n",
    "        out = np.clip(out, a_min=0.0, a_max=None)\n",
    "        if out.shape[1] > 1:\n",
    "            totals = out.sum(axis=1, keepdims=True)\n",
    "            divisor = np.maximum(totals, 1.0)\n",
    "            out = out / divisor\n",
    "        return torch.tensor(out, dtype=torch.double)\n",
    "\n",
    "print(\"XGBModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c1002f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:14:23.535377Z",
     "iopub.status.busy": "2026-01-16T18:14:23.535282Z",
     "iopub.status.idle": "2026-01-16T18:14:23.539484Z",
     "shell.execute_reply": "2026-01-16T18:14:23.539145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnsembleModel defined\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Model with random seed support\n",
    "class EnsembleModel(BaseModel):\n",
    "    def __init__(self, data=\"single\", verbose=False, random_state=42):\n",
    "        self.data_mode = data\n",
    "        self.verbose = verbose\n",
    "        self.random_state = random_state\n",
    "        if data == \"single\":\n",
    "            self.weights = {\"catboost\": 0.65, \"xgb\": 0.35}\n",
    "        else:\n",
    "            self.weights = {\"catboost\": 0.60, \"xgb\": 0.40}\n",
    "        self.catboost_model = CatBoostModel(data=data, verbose=verbose, random_state=random_state)\n",
    "        self.xgb_model = XGBModel(data=data, verbose=verbose, random_state=random_state)\n",
    "\n",
    "    def train_model(self, train_X, train_Y, device=None, verbose=False):\n",
    "        self.catboost_model.train_model(train_X, train_Y, device, verbose)\n",
    "        self.xgb_model.train_model(train_X, train_Y, device, verbose)\n",
    "\n",
    "    def predict(self, X):\n",
    "        cat_pred = self.catboost_model.predict(X).numpy()\n",
    "        xgb_pred = self.xgb_model.predict(X).numpy()\n",
    "        w_cat = self.weights[\"catboost\"]\n",
    "        w_xgb = self.weights[\"xgb\"]\n",
    "        out = w_cat * cat_pred + w_xgb * xgb_pred\n",
    "        out = np.clip(out, a_min=0.0, a_max=None)\n",
    "        if out.shape[1] > 1:\n",
    "            totals = out.sum(axis=1, keepdims=True)\n",
    "            divisor = np.maximum(totals, 1.0)\n",
    "            out = out / divisor\n",
    "        return torch.tensor(out, dtype=torch.double)\n",
    "\n",
    "print(\"EnsembleModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "050226e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:14:23.540403Z",
     "iopub.status.busy": "2026-01-16T18:14:23.540315Z",
     "iopub.status.idle": "2026-01-16T18:14:23.545179Z",
     "shell.execute_reply": "2026-01-16T18:14:23.544824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UncertaintyAwareModel defined\n"
     ]
    }
   ],
   "source": [
    "# UncertaintyAwareModel - THE KEY INNOVATION\n",
    "class UncertaintyAwareModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Trains multiple models with different random seeds and uses prediction\n",
    "    uncertainty (std across models) to blend toward a conservative prediction.\n",
    "    \n",
    "    Key insight:\n",
    "    - When models disagree (high std), we're uncertain about the prediction\n",
    "    - In these cases, blend toward the median prediction (more robust)\n",
    "    - This might reduce the CV-LB intercept by being more conservative on hard samples\n",
    "    \"\"\"\n",
    "    def __init__(self, data=\"single\", n_seeds=5, blend_threshold=0.1, verbose=False):\n",
    "        self.data_mode = data\n",
    "        self.n_seeds = n_seeds\n",
    "        self.blend_threshold = blend_threshold\n",
    "        self.verbose = verbose\n",
    "        self.models = []\n",
    "        self.train_mean = None\n",
    "        \n",
    "    def train_model(self, train_X, train_Y, device=None, verbose=False):\n",
    "        # Store training mean for fallback\n",
    "        self.train_mean = train_Y.values.mean(axis=0)\n",
    "        \n",
    "        # Train multiple models with different seeds\n",
    "        self.models = []\n",
    "        for i in range(self.n_seeds):\n",
    "            seed = 42 + i * 17  # Different seeds\n",
    "            model = EnsembleModel(data=self.data_mode, verbose=self.verbose, random_state=seed)\n",
    "            model.train_model(train_X, train_Y, device, verbose)\n",
    "            self.models.append(model)\n",
    "        \n",
    "        if self.verbose or verbose:\n",
    "            print(f\"[UncertaintyAwareModel] Trained {self.n_seeds} models\")\n",
    "            print(f\"[UncertaintyAwareModel] Train mean: {self.train_mean}\")\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Get predictions from all models\n",
    "        preds = np.array([m.predict(X).numpy() for m in self.models])\n",
    "        \n",
    "        # Compute mean and std\n",
    "        mean_pred = preds.mean(axis=0)\n",
    "        std_pred = preds.std(axis=0)\n",
    "        \n",
    "        # Compute median (more robust)\n",
    "        median_pred = np.median(preds, axis=0)\n",
    "        \n",
    "        # Blend toward median when uncertainty is high\n",
    "        # weight = 0 when std is low, weight increases with std\n",
    "        weight = np.clip(std_pred / self.blend_threshold, 0, 0.5)\n",
    "        \n",
    "        # Blend: (1 - weight) * mean + weight * median\n",
    "        final_pred = (1 - weight) * mean_pred + weight * median_pred\n",
    "        \n",
    "        # Clip and renormalize\n",
    "        final_pred = np.clip(final_pred, 0, 1)\n",
    "        if final_pred.shape[1] > 1:\n",
    "            totals = final_pred.sum(axis=1, keepdims=True)\n",
    "            divisor = np.maximum(totals, 1.0)\n",
    "            final_pred = final_pred / divisor\n",
    "        \n",
    "        return torch.tensor(final_pred, dtype=torch.double)\n",
    "\n",
    "print(\"UncertaintyAwareModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa4ebae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:14:23.546163Z",
     "iopub.status.busy": "2026-01-16T18:14:23.545939Z",
     "iopub.status.idle": "2026-01-16T18:14:23.549683Z",
     "shell.execute_reply": "2026-01-16T18:14:23.549346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function defined\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "import tqdm\n",
    "\n",
    "def evaluate_model(model_class, data_mode, **kwargs):\n",
    "    \"\"\"Evaluate a model using leave-one-out CV\"\"\"\n",
    "    if data_mode == \"single\":\n",
    "        X, Y = load_data(\"single_solvent\")\n",
    "        split_generator = generate_leave_one_out_splits(X, Y)\n",
    "    else:\n",
    "        X, Y = load_data(\"full\")\n",
    "        split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    for fold_idx, split in tqdm.tqdm(enumerate(split_generator), desc=f\"{data_mode}\"):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = model_class(data=data_mode, **kwargs)\n",
    "        model.train_model(train_X, train_Y)\n",
    "        predictions = model.predict(test_X)\n",
    "        \n",
    "        predictions_df = pd.DataFrame(\n",
    "            predictions.numpy(),\n",
    "            columns=test_Y.columns,\n",
    "            index=test_Y.index\n",
    "        )\n",
    "        all_predictions.append(predictions_df)\n",
    "    \n",
    "    all_predictions = pd.concat(all_predictions)\n",
    "    Y_true = Y.loc[all_predictions.index]\n",
    "    mse = ((all_predictions - Y_true) ** 2).mean().mean()\n",
    "    return mse, all_predictions\n",
    "\n",
    "print(\"Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1f34004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:15:23.937888Z",
     "iopub.status.busy": "2026-01-16T18:15:23.937360Z",
     "iopub.status.idle": "2026-01-16T18:16:14.504253Z",
     "shell.execute_reply": "2026-01-16T18:16:14.503869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Evaluating baseline EnsembleModel (single seed)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Building solvent feature table...\n",
      "Combined feature table shape (before corr filter): (24, 113)\n",
      "Final solvent feature table shape: (24, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 1it [00:01,  1.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 2it [00:02,  1.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 3it [00:03,  1.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 4it [00:04,  1.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 5it [00:04,  1.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 6it [00:05,  1.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 7it [00:06,  1.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 8it [00:07,  1.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 9it [00:08,  1.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 10it [00:09,  1.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 11it [00:10,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 12it [00:11,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 13it [00:12,  1.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 14it [00:13,  1.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 15it [00:14,  1.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 16it [00:15,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 17it [00:16,  1.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 18it [00:17,  1.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 19it [00:18,  1.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 20it [00:19,  1.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 21it [00:19,  1.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 22it [00:20,  1.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 23it [00:21,  1.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [00:22,  1.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [00:22,  1.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Single Solvent MSE: 0.008175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 1it [00:02,  2.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 2it [00:04,  2.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 3it [00:06,  2.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 4it [00:08,  2.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 5it [00:10,  2.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 6it [00:12,  2.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 7it [00:15,  2.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 8it [00:17,  2.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 9it [00:19,  2.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 10it [00:21,  2.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 11it [00:23,  2.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 12it [00:25,  2.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [00:27,  2.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [00:27,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Full Data MSE: 0.009784\n",
      "\n",
      "Baseline Combined MSE: 0.009223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# First, evaluate baseline EnsembleModel (single seed)\n",
    "print(\"=\" * 60)\n",
    "print(\"Evaluating baseline EnsembleModel (single seed)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "baseline_single_mse, _ = evaluate_model(EnsembleModel, \"single\")\n",
    "print(f\"\\nBaseline Single Solvent MSE: {baseline_single_mse:.6f}\")\n",
    "\n",
    "baseline_full_mse, _ = evaluate_model(EnsembleModel, \"full\")\n",
    "print(f\"Baseline Full Data MSE: {baseline_full_mse:.6f}\")\n",
    "\n",
    "baseline_combined = (baseline_single_mse * 656 + baseline_full_mse * 1227) / (656 + 1227)\n",
    "print(f\"\\nBaseline Combined MSE: {baseline_combined:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31fb3b21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:17:02.108225Z",
     "iopub.status.busy": "2026-01-16T18:17:02.107846Z",
     "iopub.status.idle": "2026-01-16T18:24:31.587048Z",
     "shell.execute_reply": "2026-01-16T18:24:31.586669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing UncertaintyAwareModel with different blend thresholds\n",
      "============================================================\n",
      "\n",
      "--- Blend threshold: 0.05 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 1it [00:02,  2.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 2it [00:05,  2.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 3it [00:08,  2.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 4it [00:11,  2.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 5it [00:13,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 6it [00:16,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 7it [00:19,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 8it [00:22,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 9it [00:24,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 10it [00:27,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 11it [00:30,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 12it [00:33,  2.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 13it [00:35,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 14it [00:38,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 15it [00:41,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 16it [00:44,  2.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 17it [00:46,  2.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 18it [00:49,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 19it [00:52,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 20it [00:55,  2.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 21it [00:57,  2.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 22it [01:00,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 23it [01:03,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [01:06,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [01:06,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Solvent MSE: 0.008656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 1it [00:06,  6.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 2it [00:12,  6.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 3it [00:18,  6.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 4it [00:25,  6.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 5it [00:31,  6.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 6it [00:37,  6.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 7it [00:43,  6.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 8it [00:50,  6.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 9it [00:56,  6.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 10it [01:02,  6.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 11it [01:09,  6.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 12it [01:15,  6.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [01:21,  6.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [01:21,  6.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data MSE: 0.009794\n",
      "Combined MSE: 0.009398\n",
      "\n",
      "--- Blend threshold: 0.1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 1it [00:02,  2.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 2it [00:05,  2.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 3it [00:08,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 4it [00:10,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 5it [00:13,  2.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 6it [00:16,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 7it [00:19,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 8it [00:21,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 9it [00:24,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 10it [00:27,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 11it [00:30,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 12it [00:33,  2.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 13it [00:35,  2.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 14it [00:38,  2.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 15it [00:41,  2.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 16it [00:44,  2.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 17it [00:47,  2.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 18it [00:49,  2.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 19it [00:52,  2.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 20it [00:55,  2.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 21it [00:58,  2.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 22it [01:01,  2.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 23it [01:03,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [01:06,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [01:06,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Solvent MSE: 0.008646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 1it [00:06,  6.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 2it [00:12,  6.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 3it [00:19,  6.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 4it [00:26,  6.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 5it [00:32,  6.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 6it [00:38,  6.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 7it [00:45,  6.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 8it [00:51,  6.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 9it [00:57,  6.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 10it [01:04,  6.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 11it [01:10,  6.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 12it [01:17,  6.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [01:24,  6.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [01:24,  6.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data MSE: 0.009799\n",
      "Combined MSE: 0.009397\n",
      "\n",
      "--- Blend threshold: 0.2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 1it [00:02,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 2it [00:05,  2.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 3it [00:08,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 4it [00:11,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 5it [00:13,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 6it [00:16,  2.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 7it [00:19,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 8it [00:21,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 9it [00:24,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 10it [00:27,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 11it [00:30,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 12it [00:33,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 13it [00:35,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 14it [00:38,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 15it [00:41,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 16it [00:44,  2.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 17it [00:46,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 18it [00:49,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 19it [00:52,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 20it [00:55,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 21it [00:57,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 22it [01:00,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 23it [01:03,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [01:06,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [01:06,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Solvent MSE: 0.008640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 1it [00:06,  6.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 2it [00:12,  6.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 3it [00:18,  6.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 4it [00:25,  6.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 5it [00:31,  6.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 6it [00:37,  6.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 7it [00:44,  6.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 8it [00:51,  6.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 9it [00:57,  6.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 10it [01:04,  6.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 11it [01:11,  6.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 12it [01:17,  6.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [01:24,  6.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [01:24,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data MSE: 0.009802\n",
      "Combined MSE: 0.009397\n",
      "\n",
      "============================================================\n",
      "Summary of Results\n",
      "============================================================\n",
      " blend_threshold  single_mse  full_mse  combined_mse\n",
      "            0.05    0.008656  0.009794      0.009398\n",
      "            0.10    0.008646  0.009799      0.009397\n",
      "            0.20    0.008640  0.009802      0.009397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test UncertaintyAwareModel with different blend thresholds\n",
    "blend_thresholds = [0.05, 0.1, 0.2]\n",
    "results = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Testing UncertaintyAwareModel with different blend thresholds\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for bt in blend_thresholds:\n",
    "    print(f\"\\n--- Blend threshold: {bt} ---\")\n",
    "    \n",
    "    single_mse, _ = evaluate_model(UncertaintyAwareModel, \"single\", n_seeds=3, blend_threshold=bt)\n",
    "    print(f\"Single Solvent MSE: {single_mse:.6f}\")\n",
    "    \n",
    "    full_mse, _ = evaluate_model(UncertaintyAwareModel, \"full\", n_seeds=3, blend_threshold=bt)\n",
    "    print(f\"Full Data MSE: {full_mse:.6f}\")\n",
    "    \n",
    "    combined = (single_mse * 656 + full_mse * 1227) / (656 + 1227)\n",
    "    print(f\"Combined MSE: {combined:.6f}\")\n",
    "    \n",
    "    results.append({\n",
    "        'blend_threshold': bt,\n",
    "        'single_mse': single_mse,\n",
    "        'full_mse': full_mse,\n",
    "        'combined_mse': combined\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary of Results\")\n",
    "print(\"=\" * 60)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef76e314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:24:47.051685Z",
     "iopub.status.busy": "2026-01-16T18:24:47.051444Z",
     "iopub.status.idle": "2026-01-16T18:24:47.055034Z",
     "shell.execute_reply": "2026-01-16T18:24:47.054688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best blend threshold: 0.1\n",
      "Best combined MSE: 0.009397\n",
      "Baseline combined MSE: 0.009223\n",
      "Improvement: -1.88%\n"
     ]
    }
   ],
   "source": [
    "# Find best blend threshold\n",
    "best_idx = results_df['combined_mse'].idxmin()\n",
    "best_bt = results_df.loc[best_idx, 'blend_threshold']\n",
    "best_mse = results_df.loc[best_idx, 'combined_mse']\n",
    "\n",
    "print(f\"\\nBest blend threshold: {best_bt}\")\n",
    "print(f\"Best combined MSE: {best_mse:.6f}\")\n",
    "print(f\"Baseline combined MSE: {baseline_combined:.6f}\")\n",
    "print(f\"Improvement: {(baseline_combined - best_mse) / baseline_combined * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1752555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:24:47.056074Z",
     "iopub.status.busy": "2026-01-16T18:24:47.055981Z",
     "iopub.status.idle": "2026-01-16T18:24:47.059314Z",
     "shell.execute_reply": "2026-01-16T18:24:47.058987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved\n"
     ]
    }
   ],
   "source": [
    "# Save metrics\n",
    "import json\n",
    "\n",
    "metrics = {\n",
    "    'baseline_single_mse': float(baseline_single_mse),\n",
    "    'baseline_full_mse': float(baseline_full_mse),\n",
    "    'baseline_combined_mse': float(baseline_combined),\n",
    "    'best_blend_threshold': float(best_bt),\n",
    "    'best_combined_mse': float(best_mse),\n",
    "    'all_results': results,\n",
    "    'cv_score': float(best_mse),\n",
    "    'notes': 'Uncertainty-weighted conservative predictions. Trains multiple models with different seeds and blends toward median when uncertainty is high.'\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/107_uncertainty_weighted/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Metrics saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb947ba8",
   "metadata": {},
   "source": [
    "## Submission Cells\n",
    "\n",
    "Using the best blend threshold found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = UncertaintyAwareModel(data='single', n_seeds=3, blend_threshold=best_bt) # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "\n",
    "    predictions_df = pd.DataFrame(\n",
    "        predictions.numpy(),\n",
    "        columns=test_Y.columns,\n",
    "        index=test_Y.index\n",
    "    )\n",
    "    all_predictions.append(predictions_df)\n",
    "\n",
    "submission_single_solvent = pd.concat(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = UncertaintyAwareModel(data='full', n_seeds=3, blend_threshold=best_bt) # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "\n",
    "    predictions_df = pd.DataFrame(\n",
    "        predictions.numpy(),\n",
    "        columns=test_Y.columns,\n",
    "        index=test_Y.index\n",
    "    )\n",
    "    all_predictions.append(predictions_df)\n",
    "\n",
    "submission_full_data = pd.concat(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c2ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/code/experiments/107_uncertainty_weighted/submission.csv\", index=True)\n",
    "\n",
    "# Also copy to main submission folder\n",
    "import shutil\n",
    "shutil.copy(\"/home/code/experiments/107_uncertainty_weighted/submission.csv\", \"/home/submission/submission.csv\")\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"Submission saved to /home/submission/submission.csv\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
