{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f39b76e",
   "metadata": {},
   "source": [
    "# Experiment 066: MLP+LGBM with Yield Normalization\n",
    "\n",
    "**Goal:** Test yield normalization constraint with a faster model (no GP).\n",
    "\n",
    "**Hypothesis:** Product 2 + Product 3 + SM should sum to ~1 (mass balance). Enforcing this constraint may improve generalization.\n",
    "\n",
    "**Implementation:**\n",
    "- MLP + LGBM ensemble (faster than GP+MLP+LGBM)\n",
    "- Add yield normalization: if sum > 1, divide by sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc54b7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:21:28.622713Z",
     "iopub.status.busy": "2026-01-16T04:21:28.622179Z",
     "iopub.status.idle": "2026-01-16T04:21:30.317905Z",
     "shell.execute_reply": "2026-01-16T04:21:30.317488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bdd4dd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:21:30.319217Z",
     "iopub.status.busy": "2026-01-16T04:21:30.319060Z",
     "iopub.status.idle": "2026-01-16T04:21:30.323355Z",
     "shell.execute_reply": "2026-01-16T04:21:30.322999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0075a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:21:30.324180Z",
     "iopub.status.busy": "2026-01-16T04:21:30.324083Z",
     "iopub.status.idle": "2026-01-16T04:21:30.351290Z",
     "shell.execute_reply": "2026-01-16T04:21:30.350954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP filtered: (24, 122), ACS PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd355133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:21:30.352176Z",
     "iopub.status.busy": "2026-01-16T04:21:30.352081Z",
     "iopub.status.idle": "2026-01-16T04:21:30.357285Z",
     "shell.execute_reply": "2026-01-16T04:21:30.356940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullFeaturizer defined with 145 features\n"
     ]
    }
   ],
   "source": [
    "# Featurizer\n",
    "class FullFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "                X_drfp = B_drfp * (1 - (1-pct)) + A_drfp * (1-pct)\n",
    "                X_acs = B_acs * (1 - (1-pct)) + A_acs * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "    \n",
    "    def featurize_torch(self, X, flip=False):\n",
    "        return torch.tensor(self.featurize(X, flip), dtype=torch.double)\n",
    "\n",
    "print(f'FullFeaturizer defined with {FullFeaturizer().feats_dim} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d706a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:21:30.358232Z",
     "iopub.status.busy": "2026-01-16T04:21:30.358126Z",
     "iopub.status.idle": "2026-01-16T04:21:30.365150Z",
     "shell.execute_reply": "2026-01-16T04:21:30.364783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model\n",
    "class MLPModelInternal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[64, 32], output_dim=3, dropout=0.1):\n",
    "        super(MLPModelInternal, self).__init__()\n",
    "        layers = [nn.BatchNorm1d(input_dim)]\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([nn.Linear(prev_dim, h_dim), nn.BatchNorm1d(h_dim), nn.ReLU(), nn.Dropout(dropout)])\n",
    "            prev_dim = h_dim\n",
    "        layers.extend([nn.Linear(prev_dim, output_dim), nn.Sigmoid()])\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class MLPWrapper:\n",
    "    def __init__(self, data='single', n_models=3):\n",
    "        self.data_type = data\n",
    "        self.n_models = n_models\n",
    "        self.featurizer = FullFeaturizer(mixed=(data=='full'))\n",
    "        self.models = []\n",
    "        self.scaler = None\n",
    "\n",
    "    def train_model(self, X_train, y_train, epochs=150, batch_size=32, lr=5e-4):\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_std, X_flip])\n",
    "            y_all = np.vstack([y_vals, y_vals])\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X_all)\n",
    "        \n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.double)\n",
    "        y_tensor = torch.tensor(y_all, dtype=torch.double)\n",
    "        \n",
    "        input_dim = X_tensor.shape[1]\n",
    "        self.models = []\n",
    "        \n",
    "        for i in range(self.n_models):\n",
    "            model = MLPModelInternal(input_dim, [64, 32], 3, dropout=0.1).double()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "            criterion = nn.MSELoss()\n",
    "            \n",
    "            dataset = TensorDataset(X_tensor, y_tensor)\n",
    "            loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                for X_batch, y_batch in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(X_batch)\n",
    "                    loss = criterion(pred, y_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_std = self.featurizer.featurize(X_test, flip=False)\n",
    "        X_scaled = self.scaler.transform(X_std)\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.double)\n",
    "        \n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for model in self.models:\n",
    "                preds.append(model(X_tensor))\n",
    "        \n",
    "        return torch.stack(preds).mean(dim=0)\n",
    "\n",
    "print('MLPWrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a0014a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:21:30.365991Z",
     "iopub.status.busy": "2026-01-16T04:21:30.365896Z",
     "iopub.status.idle": "2026-01-16T04:21:30.370192Z",
     "shell.execute_reply": "2026-01-16T04:21:30.369850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Wrapper\n",
    "class LGBMWrapper:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.featurizer = FullFeaturizer(mixed=(data=='full'))\n",
    "        self.models = []\n",
    "        self.scaler = None\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_std, X_flip])\n",
    "            y_all = np.vstack([y_vals, y_vals])\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X_all)\n",
    "        \n",
    "        self.models = []\n",
    "        params = {'objective': 'regression', 'metric': 'mse', 'boosting_type': 'gbdt',\n",
    "                  'num_leaves': 31, 'learning_rate': 0.05, 'feature_fraction': 0.9,\n",
    "                  'bagging_fraction': 0.8, 'bagging_freq': 5, 'verbose': -1, 'seed': 42}\n",
    "        \n",
    "        for i in range(3):\n",
    "            train_data = lgb.Dataset(X_scaled, label=y_all[:, i])\n",
    "            model = lgb.train(params, train_data, num_boost_round=100)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_std = self.featurizer.featurize(X_test, flip=False)\n",
    "        X_scaled = self.scaler.transform(X_std)\n",
    "        \n",
    "        preds = []\n",
    "        for model in self.models:\n",
    "            preds.append(model.predict(X_scaled))\n",
    "        \n",
    "        return torch.tensor(np.column_stack(preds), dtype=torch.double)\n",
    "\n",
    "print('LGBMWrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fdf24a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:21:30.371224Z",
     "iopub.status.busy": "2026-01-16T04:21:30.370957Z",
     "iopub.status.idle": "2026-01-16T04:21:30.374485Z",
     "shell.execute_reply": "2026-01-16T04:21:30.374108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPLGBMNormalizedEnsemble defined with YIELD NORMALIZATION\n"
     ]
    }
   ],
   "source": [
    "# MLP + LGBM Ensemble with Yield Normalization\n",
    "class MLPLGBMNormalizedEnsemble:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mlp = MLPWrapper(data=data, n_models=3)\n",
    "        self.lgbm = LGBMWrapper(data=data)\n",
    "        # Weights: MLP 0.5, LGBM 0.5\n",
    "        self.weights = {'mlp': 0.5, 'lgbm': 0.5}\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        self.mlp.train_model(X_train, y_train)\n",
    "        self.lgbm.train_model(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        mlp_pred = self.mlp.predict(X_test)\n",
    "        lgbm_pred = self.lgbm.predict(X_test)\n",
    "        \n",
    "        combined = (self.weights['mlp'] * mlp_pred + \n",
    "                    self.weights['lgbm'] * lgbm_pred)\n",
    "        \n",
    "        # Clip to [0, 1]\n",
    "        combined = torch.clamp(combined, 0, 1)\n",
    "        \n",
    "        # YIELD NORMALIZATION: Ensure predictions sum to 1 (mass balance)\n",
    "        # Product 2 + Product 3 + SM should sum to ~1\n",
    "        totals = combined.sum(dim=1, keepdim=True)\n",
    "        # Only normalize if sum > 1 (don't inflate small predictions)\n",
    "        divisor = torch.maximum(totals, torch.ones_like(totals))\n",
    "        combined = combined / divisor\n",
    "        \n",
    "        return combined\n",
    "\n",
    "print('MLPLGBMNormalizedEnsemble defined with YIELD NORMALIZATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07d80da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:21:42.333272Z",
     "iopub.status.busy": "2026-01-16T04:21:42.333074Z",
     "iopub.status.idle": "2026-01-16T04:26:24.884748Z",
     "shell.execute_reply": "2026-01-16T04:26:24.884347Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:12, 12.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:24, 11.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:35, 11.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:48, 12.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:59, 11.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [01:11, 11.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [01:22, 11.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [01:34, 11.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [01:46, 11.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [01:58, 11.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [02:10, 11.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [02:21, 11.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [02:33, 11.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [02:45, 11.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [02:56, 11.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [03:08, 11.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [03:20, 11.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [03:32, 11.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [03:44, 11.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [03:55, 11.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [04:07, 11.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [04:19, 11.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [04:30, 11.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [04:42, 11.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [04:42, 11.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MLPLGBMNormalizedEnsemble(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f247b46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:26:37.288211Z",
     "iopub.status.busy": "2026-01-16T04:26:37.287665Z",
     "iopub.status.idle": "2026-01-16T04:35:43.023670Z",
     "shell.execute_reply": "2026-01-16T04:35:43.023265Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:39, 39.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [01:20, 40.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [02:02, 41.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [02:44, 41.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [03:25, 41.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [04:06, 41.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [04:47, 41.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [05:28, 41.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [06:09, 41.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [06:53, 42.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [07:38, 42.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [08:21, 42.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [09:05, 43.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [09:05, 41.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MLPLGBMNormalizedEnsemble(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e6cc577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:35:55.246164Z",
     "iopub.status.busy": "2026-01-16T04:35:55.245652Z",
     "iopub.status.idle": "2026-01-16T04:35:55.255850Z",
     "shell.execute_reply": "2026-01-16T04:35:55.255466Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16cf0e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:35:55.256850Z",
     "iopub.status.busy": "2026-01-16T04:35:55.256753Z",
     "iopub.status.idle": "2026-01-16T04:35:55.301952Z",
     "shell.execute_reply": "2026-01-16T04:35:55.301616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Solvent CV MSE: 0.021210\n",
      "Full Data CV MSE: 0.022834\n",
      "Submission saved with 1883 rows\n"
     ]
    }
   ],
   "source": [
    "# CV CALCULATION - This cell is AFTER the final submission cell\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "submission.to_csv('/home/submission/submission.csv', index=True)\n",
    "\n",
    "# Single solvent CV\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "split_gen = list(generate_leave_one_out_splits(X_single, Y_single))\n",
    "all_y_true, all_y_pred = [], []\n",
    "for fold_idx, split in enumerate(split_gen):\n",
    "    (_, _), (_, test_Y) = split\n",
    "    fold_preds = submission_single_solvent[submission_single_solvent['fold'] == fold_idx]\n",
    "    all_y_true.append(test_Y.values)\n",
    "    all_y_pred.append(fold_preds[['target_1', 'target_2', 'target_3']].values)\n",
    "mse_single = mean_squared_error(np.vstack(all_y_true), np.vstack(all_y_pred))\n",
    "\n",
    "# Full data CV\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "split_gen = list(generate_leave_one_ramp_out_splits(X_full, Y_full))\n",
    "all_y_true, all_y_pred = [], []\n",
    "for fold_idx, split in enumerate(split_gen):\n",
    "    (_, _), (_, test_Y) = split\n",
    "    fold_preds = submission_full_data[submission_full_data['fold'] == fold_idx]\n",
    "    all_y_true.append(test_Y.values)\n",
    "    all_y_pred.append(fold_preds[['target_1', 'target_2', 'target_3']].values)\n",
    "mse_full = mean_squared_error(np.vstack(all_y_true), np.vstack(all_y_pred))\n",
    "\n",
    "print(f'Single Solvent CV MSE: {mse_single:.6f}')\n",
    "print(f'Full Data CV MSE: {mse_full:.6f}')\n",
    "print(f'Submission saved with {len(submission)} rows')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
