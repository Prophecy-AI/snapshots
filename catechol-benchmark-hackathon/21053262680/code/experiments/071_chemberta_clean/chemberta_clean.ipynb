{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc16ad59",
   "metadata": {},
   "source": [
    "# ChemBERTa Embeddings for Solvent Representation\n",
    "\n",
    "**Problem**: CV-LB gap has intercept (0.0525) > target (0.0347). Current approach CANNOT reach target.\n",
    "\n",
    "**Solution**: Use pre-trained ChemBERTa embeddings from SMILES. ChemBERTa is trained on millions of molecules and captures chemical knowledge.\n",
    "\n",
    "**Key**: This notebook has EXACTLY 3 submission cells at the end (no extra cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f36752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75350f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SMILES lookup\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "print(f'SMILES lookup: {len(SMILES_DF)} solvents')\n",
    "print(SMILES_DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ChemBERTa model and tokenizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "print('Loading ChemBERTa model...')\n",
    "model_name = 'seyonec/ChemBERTa-zinc-base-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "chemberta = AutoModel.from_pretrained(model_name).to(device)\n",
    "chemberta.eval()\n",
    "print(f'ChemBERTa loaded: {model_name}')\n",
    "print(f'Hidden size: {chemberta.config.hidden_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294b61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute ChemBERTa embeddings for all solvents\n",
    "def get_chemberta_embedding(smiles):\n",
    "    \"\"\"Get ChemBERTa embedding for a SMILES string.\"\"\"\n",
    "    # Handle mixture SMILES by taking the first component\n",
    "    if '.' in smiles:\n",
    "        smiles = smiles.split('.')[0]\n",
    "    \n",
    "    inputs = tokenizer(smiles, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = chemberta(**inputs)\n",
    "        # Use [CLS] token embedding\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy().flatten()\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "# Pre-compute embeddings for all solvents\n",
    "SOLVENT_EMBEDDINGS = {}\n",
    "for solvent_name in SMILES_DF.index:\n",
    "    smiles = SMILES_DF.loc[solvent_name, 'solvent smiles']\n",
    "    SOLVENT_EMBEDDINGS[solvent_name] = get_chemberta_embedding(smiles)\n",
    "\n",
    "print(f'Pre-computed {len(SOLVENT_EMBEDDINGS)} solvent embeddings')\n",
    "print(f'Embedding dimension: {len(list(SOLVENT_EMBEDDINGS.values())[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChemBERTa + MLP Model\n",
    "class ChemBERTaModel:\n",
    "    def __init__(self, data='single', hidden_dims=[128, 64]):\n",
    "        self.data_type = data\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "        \n",
    "    def _get_features(self, X):\n",
    "        \"\"\"Get combined features: kinetics + ChemBERTa embeddings.\"\"\"\n",
    "        # Kinetics features\n",
    "        time_m = X[\"Residence Time\"].values.reshape(-1, 1)\n",
    "        temp_c = X[\"Temperature\"].values.reshape(-1, 1)\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        kinetics = np.hstack([time_m, temp_c, inv_temp, log_time, interaction])\n",
    "        \n",
    "        # ChemBERTa embeddings\n",
    "        if self.data_type == 'single':\n",
    "            embeddings = np.array([SOLVENT_EMBEDDINGS[name] for name in X[\"SOLVENT NAME\"]])\n",
    "        else:\n",
    "            emb_a = np.array([SOLVENT_EMBEDDINGS[name] for name in X[\"SOLVENT A NAME\"]])\n",
    "            emb_b = np.array([SOLVENT_EMBEDDINGS[name] for name in X[\"SOLVENT B NAME\"]])\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            # Weighted combination\n",
    "            embeddings = (1 - pct) * emb_a + pct * emb_b\n",
    "        \n",
    "        return np.hstack([kinetics, embeddings])\n",
    "    \n",
    "    def train_model(self, X_train, Y_train, epochs=200):\n",
    "        Y_np = Y_train.values if hasattr(Y_train, 'values') else Y_train\n",
    "        \n",
    "        # Get features\n",
    "        X_features = self._get_features(X_train)\n",
    "        X_scaled = self.scaler.fit_transform(X_features)\n",
    "        \n",
    "        # Build MLP\n",
    "        input_dim = X_scaled.shape[1]\n",
    "        layers = [nn.BatchNorm1d(input_dim)]\n",
    "        prev_dim = input_dim\n",
    "        for h in self.hidden_dims:\n",
    "            layers.extend([nn.Linear(prev_dim, h), nn.ReLU(), nn.Dropout(0.2)])\n",
    "            prev_dim = h\n",
    "        layers.append(nn.Linear(prev_dim, 3))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        \n",
    "        self.model = nn.Sequential(*layers).to(device)\n",
    "        \n",
    "        # Training\n",
    "        X_torch = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "        Y_torch = torch.tensor(Y_np, dtype=torch.float32).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "        criterion = nn.HuberLoss()\n",
    "        \n",
    "        dataset = TensorDataset(X_torch, Y_torch)\n",
    "        loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for xb, yb in loader:\n",
    "                optimizer.zero_grad()\n",
    "                pred = self.model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X_features = self._get_features(X_test)\n",
    "        X_scaled = self.scaler.transform(X_features)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_torch = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "            preds = self.model(X_torch).cpu()\n",
    "        \n",
    "        return torch.clamp(preds, 0, 1).double()\n",
    "\n",
    "print('ChemBERTaModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f039c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test on single fold\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "test_solvent = sorted(X_single[\"SOLVENT NAME\"].unique())[0]\n",
    "mask = X_single[\"SOLVENT NAME\"] != test_solvent\n",
    "\n",
    "print(f\"Test solvent: {test_solvent}\")\n",
    "print(f\"Training samples: {mask.sum()}, Test samples: {(~mask).sum()}\")\n",
    "\n",
    "model = ChemBERTaModel(data='single')\n",
    "model.train_model(X_single[mask], Y_single[mask], epochs=100)\n",
    "preds = model.predict(X_single[~mask])\n",
    "\n",
    "actuals = Y_single[~mask].values\n",
    "mse = np.mean((actuals - preds.numpy()) ** 2)\n",
    "print(f'Test fold MSE: {mse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1195f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ChemBERTaModel(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y, epochs=200)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "# Calculate single solvent MSE\n",
    "actuals_single = []\n",
    "for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "    mask = X[\"SOLVENT NAME\"] == solvent\n",
    "    actuals_single.append(Y[mask].values)\n",
    "actuals_single = np.vstack(actuals_single)\n",
    "preds_single = submission_single_solvent[['target_1', 'target_2', 'target_3']].values\n",
    "mse_single = np.mean((actuals_single - preds_single) ** 2)\n",
    "print(f'\\nSingle Solvent MSE: {mse_single:.6f}')\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4557d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ChemBERTaModel(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y, epochs=200)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "# Calculate full data MSE\n",
    "actuals_full = []\n",
    "ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "for _, row in ramps.iterrows():\n",
    "    mask = (X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"])\n",
    "    actuals_full.append(Y[mask].values)\n",
    "actuals_full = np.vstack(actuals_full)\n",
    "preds_full = submission_full_data[['target_1', 'target_2', 'target_3']].values\n",
    "mse_full = np.mean((actuals_full - preds_full) ** 2)\n",
    "print(f'\\nFull Data MSE: {mse_full:.6f}')\n",
    "\n",
    "# Calculate overall MSE\n",
    "n_single = len(actuals_single)\n",
    "n_full = len(actuals_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "print(f'\\nOverall MSE: {overall_mse:.6f}')\n",
    "print(f'Baseline (exp_030): CV 0.008298')\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbbebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
