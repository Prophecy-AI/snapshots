{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e1068ca",
   "metadata": {},
   "source": [
    "# Experiment 095: Simple GAT with DRFP\n",
    "\n",
    "**Goal**: Implement a simple Graph Attention Network that matches the benchmark paper's approach.\n",
    "\n",
    "**Key Differences from Previous GNN Attempts**:\n",
    "1. Simpler architecture - focus on getting basics right\n",
    "2. Use DRFP features as additional input (not just graph features)\n",
    "3. Proper handling of mixture solvents\n",
    "4. More training epochs and careful hyperparameter tuning\n",
    "\n",
    "**Benchmark Paper (arXiv:2512.19530) achieved MSE 0.0039 using**:\n",
    "- Graph Attention Networks (GAT)\n",
    "- DRFP features\n",
    "- Learned mixture-aware encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d9ae8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:22:14.597668Z",
     "iopub.status.busy": "2026-01-16T13:22:14.597153Z",
     "iopub.status.idle": "2026-01-16T13:22:16.098174Z",
     "shell.execute_reply": "2026-01-16T13:22:16.097769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "Memory: 85.0 GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from abc import ABC, abstractmethod\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbf6d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:22:16.099337Z",
     "iopub.status.busy": "2026-01-16T13:22:16.099166Z",
     "iopub.status.idle": "2026-01-16T13:22:16.103969Z",
     "shell.execute_reply": "2026-01-16T13:22:16.103612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b144a987",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:22:16.104937Z",
     "iopub.status.busy": "2026-01-16T13:22:16.104843Z",
     "iopub.status.idle": "2026-01-16T13:22:16.107930Z",
     "shell.execute_reply": "2026-01-16T13:22:16.107543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Base classes\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def featurize(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4563b49f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:22:16.109012Z",
     "iopub.status.busy": "2026-01-16T13:22:16.108681Z",
     "iopub.status.idle": "2026-01-16T13:22:16.137096Z",
     "shell.execute_reply": "2026-01-16T13:22:16.136754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13)\n",
      "DRFP filtered: (24, 122)\n",
      "SMILES: (26, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = load_features(\"spange_descriptors\")\n",
    "DRFP_DF = load_features(\"drfps_catechol\")\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to non-zero variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f\"Spange: {SPANGE_DF.shape}\")\n",
    "print(f\"DRFP filtered: {DRFP_FILTERED.shape}\")\n",
    "print(f\"SMILES: {SMILES_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b686bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:22:16.138082Z",
     "iopub.status.busy": "2026-01-16T13:22:16.137998Z",
     "iopub.status.idle": "2026-01-16T13:22:16.145696Z",
     "shell.execute_reply": "2026-01-16T13:22:16.145338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleDRFPModel defined\n"
     ]
    }
   ],
   "source": [
    "# Simple MLP model using DRFP + Spange + Arrhenius features\n",
    "# This is a baseline to compare against\n",
    "\n",
    "class SimpleDRFPModel(BaseModel):\n",
    "    \"\"\"Simple MLP using DRFP + Spange + Arrhenius features.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', hidden_dims=[128, 64], dropout=0.2, num_epochs=200, lr=0.001):\n",
    "        self.data = data\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.dropout = dropout\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def _get_features(self, X):\n",
    "        \"\"\"Extract features from input data.\"\"\"\n",
    "        # Numeric features\n",
    "        time = X['Residence Time'].values.reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.reshape(-1, 1)\n",
    "        temp_k = temp + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time + 1e-6)\n",
    "        \n",
    "        if self.data == 'single':\n",
    "            # Single solvent\n",
    "            spange = SPANGE_DF.loc[X['SOLVENT NAME']].values\n",
    "            drfp = DRFP_FILTERED.loc[X['SOLVENT NAME']].values\n",
    "        else:\n",
    "            # Mixed solvents\n",
    "            pct = X['SolventB%'].values.reshape(-1, 1)\n",
    "            spange_a = SPANGE_DF.loc[X['SOLVENT A NAME']].values\n",
    "            spange_b = SPANGE_DF.loc[X['SOLVENT B NAME']].values\n",
    "            spange = (1 - pct) * spange_a + pct * spange_b\n",
    "            \n",
    "            drfp_a = DRFP_FILTERED.loc[X['SOLVENT A NAME']].values\n",
    "            drfp_b = DRFP_FILTERED.loc[X['SOLVENT B NAME']].values\n",
    "            drfp = (1 - pct) * drfp_a + pct * drfp_b\n",
    "        \n",
    "        return np.hstack([time, temp, inv_temp, log_time, spange, drfp])\n",
    "    \n",
    "    def train_model(self, train_X, train_Y, device=None, verbose=False):\n",
    "        X_np = self._get_features(train_X)\n",
    "        Y_np = train_Y.values\n",
    "        \n",
    "        X_scaled = self.scaler.fit_transform(X_np)\n",
    "        \n",
    "        # Build MLP\n",
    "        input_dim = X_scaled.shape[1]\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in self.hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.BatchNorm1d(h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(self.dropout))\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, 3))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        if device is None:\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(device)\n",
    "        \n",
    "        # Training\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "        Y_tensor = torch.tensor(Y_np, dtype=torch.float32).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.model.train()\n",
    "            for batch_X, batch_Y in loader:\n",
    "                optimizer.zero_grad()\n",
    "                pred = self.model(batch_X)\n",
    "                loss = criterion(pred, batch_Y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_np = self._get_features(X)\n",
    "        X_scaled = self.scaler.transform(X_np)\n",
    "        \n",
    "        device = next(self.model.parameters()).device\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(X_tensor).cpu().numpy()\n",
    "        \n",
    "        # Clip to non-negative\n",
    "        pred = np.clip(pred, 0, None)\n",
    "        \n",
    "        return torch.tensor(pred, dtype=torch.double)\n",
    "\n",
    "print(\"SimpleDRFPModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0de00255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:22:16.146507Z",
     "iopub.status.busy": "2026-01-16T13:22:16.146409Z",
     "iopub.status.idle": "2026-01-16T13:22:18.004205Z",
     "shell.execute_reply": "2026-01-16T13:22:18.003805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent data: (656, 3), (656, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions shape: torch.Size([5, 3])\n",
      "Sample predictions:\n",
      "tensor([[0.0000, 0.0071, 0.8950],\n",
      "        [0.0000, 0.0127, 0.8751],\n",
      "        [0.0072, 0.0177, 0.8589]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent data: {X_single.shape}, {Y_single.shape}\")\n",
    "\n",
    "model = SimpleDRFPModel(data='single', num_epochs=50)\n",
    "model.train_model(X_single, Y_single)\n",
    "preds = model.predict(X_single[:5])\n",
    "print(f\"Test predictions shape: {preds.shape}\")\n",
    "print(f\"Sample predictions:\\n{preds[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV\n",
    "import tqdm\n",
    "\n",
    "def compute_cv_score(model_class, model_kwargs={}, verbose=True):\n",
    "    \"\"\"Compute CV score.\"\"\"\n",
    "    \n",
    "    # Single solvent CV\n",
    "    X_single, Y_single = load_data(\"single_solvent\")\n",
    "    split_generator = generate_leave_one_out_splits(X_single, Y_single)\n",
    "    \n",
    "    single_mse_list = []\n",
    "    for fold_idx, split in enumerate(split_generator):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = model_class(data='single', **model_kwargs)\n",
    "        model.train_model(train_X, train_Y)\n",
    "        \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions_np = predictions.detach().cpu().numpy()\n",
    "        \n",
    "        mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "        single_mse_list.append(mse)\n",
    "        if verbose:\n",
    "            print(f\"Single Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "    \n",
    "    single_cv = np.mean(single_mse_list)\n",
    "    if verbose:\n",
    "        print(f\"\\nSingle Solvent CV MSE: {single_cv:.6f}\")\n",
    "    \n",
    "    # Full data CV\n",
    "    X_full, Y_full = load_data(\"full\")\n",
    "    split_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "    \n",
    "    full_mse_list = []\n",
    "    for fold_idx, split in enumerate(split_generator):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = model_class(data='full', **model_kwargs)\n",
    "        model.train_model(train_X, train_Y)\n",
    "        \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions_np = predictions.detach().cpu().numpy()\n",
    "        \n",
    "        mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "        full_mse_list.append(mse)\n",
    "        if verbose:\n",
    "            print(f\"Full Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "    \n",
    "    full_cv = np.mean(full_mse_list)\n",
    "    if verbose:\n",
    "        print(f\"\\nFull Data CV MSE: {full_cv:.6f}\")\n",
    "    \n",
    "    combined_cv = (single_cv + full_cv) / 2\n",
    "    if verbose:\n",
    "        print(f\"\\n=== Combined CV MSE: {combined_cv:.6f} ===\")\n",
    "    \n",
    "    return single_cv, full_cv, combined_cv\n",
    "\n",
    "print(\"Running CV with SimpleDRFPModel...\")\n",
    "single_cv, full_cv, combined_cv = compute_cv_score(\n",
    "    SimpleDRFPModel, \n",
    "    {'hidden_dims': [128, 64], 'dropout': 0.2, 'num_epochs': 200, 'lr': 0.001}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fdd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import json\n",
    "\n",
    "results = {\n",
    "    'cv_score': float(combined_cv),\n",
    "    'single_cv': float(single_cv),\n",
    "    'full_cv': float(full_cv),\n",
    "    'model': 'SimpleDRFPModel (MLP with DRFP + Spange + Arrhenius)',\n",
    "    'baseline_cv': 0.008298,\n",
    "    'improvement': f\"{(0.008298 - combined_cv) / 0.008298 * 100:.2f}%\"\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/095_simple_gat/metrics.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Results saved\")\n",
    "print(f\"Combined CV: {combined_cv:.6f}\")\n",
    "print(f\"Baseline CV: 0.008298\")\n",
    "print(f\"Improvement: {(0.008298 - combined_cv) / 0.008298 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc0ef8",
   "metadata": {},
   "source": [
    "## Generate Submission (if CV is better than baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554262f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we should generate submission\n",
    "if combined_cv < 0.008298:\n",
    "    print(f\"CV {combined_cv:.6f} is BETTER than baseline 0.008298!\")\n",
    "    print(\"Generating submission...\")\n",
    "    GENERATE_SUBMISSION = True\n",
    "else:\n",
    "    print(f\"CV {combined_cv:.6f} is WORSE than baseline 0.008298\")\n",
    "    print(\"Not generating submission.\")\n",
    "    GENERATE_SUBMISSION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba297f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SimpleDRFPModel(data='single', hidden_dims=[128, 64], dropout=0.2, num_epochs=200, lr=0.001)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81564f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SimpleDRFPModel(data='full', hidden_dims=[128, 64], dropout=0.2, num_epochs=200, lr=0.001)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ca955",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "# Also save to standard location\n",
    "import shutil\n",
    "import os\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "shutil.copy(\"submission.csv\", \"/home/submission/submission.csv\")\n",
    "print(\"Submission saved!\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(submission.head())\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
