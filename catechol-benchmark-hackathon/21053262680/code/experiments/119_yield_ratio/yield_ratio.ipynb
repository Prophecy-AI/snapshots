{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbd4345c",
   "metadata": {},
   "source": [
    "# Experiment 119: Yield Ratio Prediction\n",
    "\n",
    "**Goal**: Predict yield RATIOS instead of absolute yields, then multiply by predicted total.\n",
    "\n",
    "**Key Insight**: The distribution shift might be in the absolute scale, not the relative proportions. By predicting ratios and total separately, we may achieve better generalization.\n",
    "\n",
    "**Approach**:\n",
    "1. Compute ratios: P2_ratio = P2/total, P3_ratio = P3/total, SM_ratio = SM/total\n",
    "2. Train separate models for P2_ratio, P3_ratio, and total\n",
    "3. At prediction: pred = ratio * total\n",
    "\n",
    "**Hypothesis**: Ratios might be more stable across solvents than absolute yields, potentially changing the CV-LB relationship.\n",
    "\n",
    "**CRITICAL**: The model class `YieldRatioModel` will be used in BOTH CV computation AND submission cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c36049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801bf79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurizer\n",
    "class Featurizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "                X_drfp = B_drfp * (1 - (1-pct)) + A_drfp * (1-pct)\n",
    "                X_acs = B_acs * (1 - (1-pct)) + A_acs * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "\n",
    "print(f'Feature dimension: {Featurizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6472e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yield Ratio Model - predicts ratios and total separately\n",
    "class YieldRatioModel:\n",
    "    \"\"\"Predict yield ratios instead of absolute yields.\n",
    "    \n",
    "    Key insight: The distribution shift might be in the absolute scale,\n",
    "    not the relative proportions. By predicting ratios and total separately,\n",
    "    we may achieve better generalization.\n",
    "    \n",
    "    This is the SAME class used in both CV and submission cells.\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.featurizer = Featurizer(mixed=(data=='full'))\n",
    "        self.scaler = StandardScaler()\n",
    "        self.ratio_models = []  # Predict P2/total, P3/total\n",
    "        self.total_model = None  # Predict total = P2 + P3 + SM\n",
    "        \n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Featurize\n",
    "        X_feat = self.featurizer.featurize(X_train)\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        \n",
    "        y_vals = y_train.values\n",
    "        total = y_vals.sum(axis=1)\n",
    "        \n",
    "        # Compute ratios (handle division by zero)\n",
    "        ratios = y_vals / np.maximum(total.reshape(-1, 1), 1e-6)\n",
    "        \n",
    "        # Train ratio models for P2 and P3 (SM ratio = 1 - P2_ratio - P3_ratio)\n",
    "        for i in range(2):  # Only P2 and P3 ratios\n",
    "            model = cb.CatBoostRegressor(\n",
    "                iterations=500,\n",
    "                learning_rate=0.05,\n",
    "                depth=6,\n",
    "                l2_leaf_reg=3,\n",
    "                random_seed=42,\n",
    "                verbose=False\n",
    "            )\n",
    "            model.fit(X_scaled, ratios[:, i])\n",
    "            self.ratio_models.append(model)\n",
    "        \n",
    "        # Train total model\n",
    "        self.total_model = cb.CatBoostRegressor(\n",
    "            iterations=500,\n",
    "            learning_rate=0.05,\n",
    "            depth=6,\n",
    "            l2_leaf_reg=3,\n",
    "            random_seed=42,\n",
    "            verbose=False\n",
    "        )\n",
    "        self.total_model.fit(X_scaled, total)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_feat = self.featurizer.featurize(X)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        # Predict ratios\n",
    "        p2_ratio = self.ratio_models[0].predict(X_scaled)\n",
    "        p3_ratio = self.ratio_models[1].predict(X_scaled)\n",
    "        sm_ratio = 1 - p2_ratio - p3_ratio\n",
    "        \n",
    "        # Clip ratios to [0, 1]\n",
    "        p2_ratio = np.clip(p2_ratio, 0, 1)\n",
    "        p3_ratio = np.clip(p3_ratio, 0, 1)\n",
    "        sm_ratio = np.clip(sm_ratio, 0, 1)\n",
    "        \n",
    "        # Renormalize ratios to sum to 1\n",
    "        total_ratio = p2_ratio + p3_ratio + sm_ratio\n",
    "        p2_ratio = p2_ratio / np.maximum(total_ratio, 1e-6)\n",
    "        p3_ratio = p3_ratio / np.maximum(total_ratio, 1e-6)\n",
    "        sm_ratio = sm_ratio / np.maximum(total_ratio, 1e-6)\n",
    "        \n",
    "        # Predict total\n",
    "        total = self.total_model.predict(X_scaled)\n",
    "        total = np.clip(total, 0, 1.5)  # Reasonable range\n",
    "        \n",
    "        # Compute final predictions\n",
    "        pred = np.column_stack([\n",
    "            p2_ratio * total,\n",
    "            p3_ratio * total,\n",
    "            sm_ratio * total\n",
    "        ])\n",
    "        \n",
    "        return torch.tensor(pred)\n",
    "\n",
    "print('YieldRatioModel defined - will be used in both CV and submission cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dc794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's analyze the ratio distributions in training data\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "# Compute ratios\n",
    "y_single = Y_single.values\n",
    "total_single = y_single.sum(axis=1)\n",
    "ratios_single = y_single / np.maximum(total_single.reshape(-1, 1), 1e-6)\n",
    "\n",
    "y_full = Y_full.values\n",
    "total_full = y_full.sum(axis=1)\n",
    "ratios_full = y_full / np.maximum(total_full.reshape(-1, 1), 1e-6)\n",
    "\n",
    "print(\"Ratio analysis (P2, P3, SM):\")\n",
    "print(f\"Single solvent ratios - mean: {ratios_single.mean(axis=0)}\")\n",
    "print(f\"Single solvent ratios - std: {ratios_single.std(axis=0)}\")\n",
    "print(f\"\\nFull data ratios - mean: {ratios_full.mean(axis=0)}\")\n",
    "print(f\"Full data ratios - std: {ratios_full.std(axis=0)}\")\n",
    "\n",
    "print(f\"\\nTotal yield analysis:\")\n",
    "print(f\"Single solvent total - mean: {total_single.mean():.4f}, std: {total_single.std():.4f}\")\n",
    "print(f\"Full data total - mean: {total_full.mean():.4f}, std: {total_full.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation to compute CV score\n",
    "print(\"Computing CV score...\")\n",
    "\n",
    "# Single solvent CV\n",
    "single_mses = []\n",
    "\n",
    "for fold_idx, split in enumerate(generate_leave_one_out_splits(X_single, Y_single)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = YieldRatioModel(data='single')  # SAME CLASS AS SUBMISSION\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    targets = test_Y.values\n",
    "    \n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    single_mses.append(mse)\n",
    "    \n",
    "    if fold_idx % 6 == 0:\n",
    "        print(f\"  Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "\n",
    "single_mse = np.mean(single_mses)\n",
    "print(f\"\\nSingle solvent MSE: {single_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffec390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full data CV\n",
    "full_mses = []\n",
    "\n",
    "for fold_idx, split in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = YieldRatioModel(data='full')  # SAME CLASS AS SUBMISSION\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    targets = test_Y.values\n",
    "    \n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    full_mses.append(mse)\n",
    "    \n",
    "    if fold_idx % 3 == 0:\n",
    "        print(f\"  Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "\n",
    "full_mse = np.mean(full_mses)\n",
    "print(f\"\\nFull data MSE: {full_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4159a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined CV score\n",
    "cv_score = (single_mse + full_mse) / 2\n",
    "print(f\"\\n=== CV Results ===\")\n",
    "print(f\"Single solvent MSE: {single_mse:.6f}\")\n",
    "print(f\"Full data MSE: {full_mse:.6f}\")\n",
    "print(f\"Combined CV score: {cv_score:.6f}\")\n",
    "\n",
    "# Save metrics\n",
    "import json\n",
    "metrics = {\n",
    "    'cv_score': cv_score,\n",
    "    'single_mse': single_mse,\n",
    "    'full_mse': full_mse\n",
    "}\n",
    "with open('/home/code/experiments/119_yield_ratio/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "\n",
    "print(f\"\\nComparison with best CV: 0.0081\")\n",
    "print(f\"This experiment: {cv_score:.6f}\")\n",
    "if cv_score < 0.0081:\n",
    "    print(\"IMPROVEMENT! This is better than best CV.\")\n",
    "else:\n",
    "    print(f\"No improvement. Difference: {cv_score - 0.0081:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ce82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = YieldRatioModel(data='single')  # SAME CLASS AS CV\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = YieldRatioModel(data='full')  # SAME CLASS AS CV\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "print(f\"Submission saved with {len(submission)} rows\")\n",
    "print(submission.head())\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
