{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd23edb",
   "metadata": {},
   "source": [
    "# Similarity-Based Prediction Weighting\n",
    "\n",
    "**Problem**: CV-LB intercept (0.0525) > Target (0.0347). Even CV=0 would give LB=0.0525.\n",
    "\n",
    "**Solution**: Detect when we're extrapolating to dissimilar solvents and make conservative predictions.\n",
    "\n",
    "**Approach**:\n",
    "1. Use GP+MLP+LGBM ensemble (best model from exp_030)\n",
    "2. Compute similarity to training solvents using Spange features\n",
    "3. When test solvent is dissimilar, blend prediction toward training mean\n",
    "4. This should reduce the intercept by dampening extreme predictions on unseen solvents\n",
    "\n",
    "**Key**: This notebook has EXACTLY 3 submission cells at the end (no extra cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c0c189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:35:59.414016Z",
     "iopub.status.busy": "2026-01-16T06:35:59.413579Z",
     "iopub.status.idle": "2026-01-16T06:36:01.127733Z",
     "shell.execute_reply": "2026-01-16T06:36:01.127278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20ddd09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:36:01.128943Z",
     "iopub.status.busy": "2026-01-16T06:36:01.128771Z",
     "iopub.status.idle": "2026-01-16T06:36:01.133110Z",
     "shell.execute_reply": "2026-01-16T06:36:01.132763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24e5ef68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:36:01.134021Z",
     "iopub.status.busy": "2026-01-16T06:36:01.133907Z",
     "iopub.status.idle": "2026-01-16T06:36:01.162385Z",
     "shell.execute_reply": "2026-01-16T06:36:01.162019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP filtered: (24, 122), ACS PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49ae61b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:36:01.163470Z",
     "iopub.status.busy": "2026-01-16T06:36:01.163364Z",
     "iopub.status.idle": "2026-01-16T06:36:01.169293Z",
     "shell.execute_reply": "2026-01-16T06:36:01.168878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full feature dimension: 145\n"
     ]
    }
   ],
   "source": [
    "# Full Featurizer (for MLP and LGBM) - 145 features\n",
    "class FullFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "                X_drfp = B_drfp * (1 - (1-pct)) + A_drfp * (1-pct)\n",
    "                X_acs = B_acs * (1 - (1-pct)) + A_acs * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "    \n",
    "    def featurize_torch(self, X, flip=False):\n",
    "        return torch.tensor(self.featurize(X, flip))\n",
    "\n",
    "print(f'Full feature dimension: {FullFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8ff08e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:36:01.170252Z",
     "iopub.status.busy": "2026-01-16T06:36:01.170117Z",
     "iopub.status.idle": "2026-01-16T06:36:01.174858Z",
     "shell.execute_reply": "2026-01-16T06:36:01.174487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple feature dimension (for GP): 18\n"
     ]
    }
   ],
   "source": [
    "# Simple Featurizer (for GP) - 18 features (Spange + Arrhenius kinetics)\n",
    "class SimpleFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1]  # 18 features\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange])\n",
    "\n",
    "print(f'Simple feature dimension (for GP): {SimpleFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07273c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:36:01.175790Z",
     "iopub.status.busy": "2026-01-16T06:36:01.175678Z",
     "iopub.status.idle": "2026-01-16T06:36:01.179432Z",
     "shell.execute_reply": "2026-01-16T06:36:01.179063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[64, 32], output_dim=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = [nn.BatchNorm1d(input_dim)]\n",
    "        prev_dim = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.extend([nn.Linear(prev_dim, h), nn.ReLU(), nn.Dropout(dropout)])\n",
    "            prev_dim = h\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print('MLP model defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae9e6f66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:36:01.180352Z",
     "iopub.status.busy": "2026-01-16T06:36:01.180229Z",
     "iopub.status.idle": "2026-01-16T06:36:01.189962Z",
     "shell.execute_reply": "2026-01-16T06:36:01.189596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimilarityWeightedModel defined\n"
     ]
    }
   ],
   "source": [
    "# Similarity-Weighted GP+MLP+LGBM Ensemble Model\n",
    "class SimilarityWeightedModel:\n",
    "    \"\"\"GP+MLP+LGBM ensemble with similarity-based prediction weighting.\n",
    "    \n",
    "    When test solvent is dissimilar to training solvents, blend prediction toward training mean.\n",
    "    This should reduce the intercept in the CV-LB relationship.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', gp_weight=0.3, mlp_weight=0.4, lgbm_weight=0.3,\n",
    "                 similarity_alpha=0.3, n_neighbors=5):\n",
    "        self.data = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.gp_weight = gp_weight\n",
    "        self.mlp_weight = mlp_weight\n",
    "        self.lgbm_weight = lgbm_weight\n",
    "        self.similarity_alpha = similarity_alpha  # How much to blend toward mean for dissimilar solvents\n",
    "        self.n_neighbors = n_neighbors\n",
    "        \n",
    "        self.full_featurizer = FullFeaturizer(mixed=self.mixed)\n",
    "        self.simple_featurizer = SimpleFeaturizer(mixed=self.mixed)\n",
    "        \n",
    "        self.scaler_full = StandardScaler()\n",
    "        self.scaler_simple = StandardScaler()\n",
    "        \n",
    "        # Store training statistics\n",
    "        self.train_mean = None\n",
    "        self.train_spange_features = None\n",
    "        self.nn_model = None\n",
    "        self.train_distances_threshold = None\n",
    "        \n",
    "    def _get_spange_features(self, X):\n",
    "        \"\"\"Get Spange features for similarity computation.\"\"\"\n",
    "        if self.mixed:\n",
    "            A_spange = SPANGE_DF.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = SPANGE_DF.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            return (1 - pct) * A_spange + pct * B_spange\n",
    "        else:\n",
    "            return SPANGE_DF.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "    def train_model(self, X, Y):\n",
    "        Y_np = Y.values if hasattr(Y, 'values') else Y\n",
    "        \n",
    "        # Store training target statistics\n",
    "        self.train_mean = Y_np.mean(axis=0)\n",
    "        \n",
    "        # Store training Spange features for similarity computation\n",
    "        self.train_spange_features = self._get_spange_features(X)\n",
    "        \n",
    "        # Fit nearest neighbors for similarity computation\n",
    "        self.nn_model = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn_model.fit(self.train_spange_features)\n",
    "        \n",
    "        # Compute threshold from training data (mean + 2*std of distances)\n",
    "        train_distances, _ = self.nn_model.kneighbors(self.train_spange_features)\n",
    "        self.train_distances_threshold = train_distances.mean() + 2 * train_distances.std()\n",
    "        \n",
    "        # Featurize\n",
    "        X_full = self.full_featurizer.featurize(X)\n",
    "        X_simple = self.simple_featurizer.featurize(X)\n",
    "        \n",
    "        # Scale\n",
    "        X_full_scaled = self.scaler_full.fit_transform(X_full)\n",
    "        X_simple_scaled = self.scaler_simple.fit_transform(X_simple)\n",
    "        \n",
    "        # Train GP (on simple features)\n",
    "        kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "        self.gp_models = []\n",
    "        for i in range(3):\n",
    "            gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=2, random_state=42)\n",
    "            gp.fit(X_simple_scaled, Y_np[:, i])\n",
    "            self.gp_models.append(gp)\n",
    "        \n",
    "        # Train MLP\n",
    "        X_torch = torch.tensor(X_full_scaled, dtype=torch.double)\n",
    "        Y_torch = torch.tensor(Y_np, dtype=torch.double)\n",
    "        \n",
    "        self.mlp = MLP(input_dim=X_full_scaled.shape[1]).double().to(device)\n",
    "        optimizer = torch.optim.Adam(self.mlp.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "        criterion = nn.HuberLoss()\n",
    "        \n",
    "        dataset = TensorDataset(X_torch, Y_torch)\n",
    "        loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        self.mlp.train()\n",
    "        for epoch in range(200):\n",
    "            for xb, yb in loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                pred = self.mlp(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Train LGBM\n",
    "        self.lgbm_models = []\n",
    "        for i in range(3):\n",
    "            model = lgb.LGBMRegressor(\n",
    "                n_estimators=500, learning_rate=0.03, max_depth=6,\n",
    "                num_leaves=31, reg_alpha=0.1, reg_lambda=0.1,\n",
    "                random_state=42, verbose=-1\n",
    "            )\n",
    "            model.fit(X_full_scaled, Y_np[:, i])\n",
    "            self.lgbm_models.append(model)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Featurize\n",
    "        X_full = self.full_featurizer.featurize(X)\n",
    "        X_simple = self.simple_featurizer.featurize(X)\n",
    "        \n",
    "        # Scale\n",
    "        X_full_scaled = self.scaler_full.transform(X_full)\n",
    "        X_simple_scaled = self.scaler_simple.transform(X_simple)\n",
    "        \n",
    "        # GP predictions\n",
    "        gp_preds = np.column_stack([gp.predict(X_simple_scaled) for gp in self.gp_models])\n",
    "        \n",
    "        # MLP predictions\n",
    "        self.mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            X_torch = torch.tensor(X_full_scaled, dtype=torch.double).to(device)\n",
    "            mlp_preds = self.mlp(X_torch).cpu().numpy()\n",
    "        \n",
    "        # LGBM predictions\n",
    "        lgbm_preds = np.column_stack([m.predict(X_full_scaled) for m in self.lgbm_models])\n",
    "        \n",
    "        # Ensemble\n",
    "        raw_preds = (self.gp_weight * gp_preds + \n",
    "                     self.mlp_weight * mlp_preds + \n",
    "                     self.lgbm_weight * lgbm_preds)\n",
    "        \n",
    "        # Compute similarity to training solvents\n",
    "        test_spange = self._get_spange_features(X)\n",
    "        distances, _ = self.nn_model.kneighbors(test_spange)\n",
    "        extrapolation_score = distances.mean(axis=1)\n",
    "        \n",
    "        # Compute blending weight based on extrapolation score\n",
    "        # Higher extrapolation_score = more dissimilar = blend more toward mean\n",
    "        blend_weight = np.clip(extrapolation_score / self.train_distances_threshold, 0, 1)\n",
    "        blend_weight = blend_weight.reshape(-1, 1) * self.similarity_alpha\n",
    "        \n",
    "        # Blend predictions toward training mean for dissimilar solvents\n",
    "        final_preds = (1 - blend_weight) * raw_preds + blend_weight * self.train_mean\n",
    "        \n",
    "        # Clip to valid range [0, 1]\n",
    "        final_preds = np.clip(final_preds, 0, 1)\n",
    "        \n",
    "        return torch.tensor(final_preds, dtype=torch.double)\n",
    "\n",
    "print('SimilarityWeightedModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a26e7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:36:01.190824Z",
     "iopub.status.busy": "2026-01-16T06:36:01.190718Z",
     "iopub.status.idle": "2026-01-16T06:36:22.429284Z",
     "shell.execute_reply": "2026-01-16T06:36:22.428920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test solvent: 1,1,1,3,3,3-Hexafluoropropan-2-ol\n",
      "Training samples: 619, Test samples: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fold MSE: 0.043239\n",
      "Baseline (exp_030) test fold MSE: ~0.068 (for this solvent)\n"
     ]
    }
   ],
   "source": [
    "# Quick test on single fold\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "test_solvent = sorted(X_single[\"SOLVENT NAME\"].unique())[0]\n",
    "mask = X_single[\"SOLVENT NAME\"] != test_solvent\n",
    "\n",
    "print(f\"Test solvent: {test_solvent}\")\n",
    "print(f\"Training samples: {mask.sum()}, Test samples: {(~mask).sum()}\")\n",
    "\n",
    "model = SimilarityWeightedModel(data='single', similarity_alpha=0.3)\n",
    "model.train_model(X_single[mask], Y_single[mask])\n",
    "preds = model.predict(X_single[~mask])\n",
    "\n",
    "actuals = Y_single[~mask].values\n",
    "mse = np.mean((actuals - preds.numpy()) ** 2)\n",
    "print(f'Test fold MSE: {mse:.6f}')\n",
    "print(f'Baseline (exp_030) test fold MSE: ~0.068 (for this solvent)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae96dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SimilarityWeightedModel(data='single', similarity_alpha=0.3)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dffba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SimilarityWeightedModel(data='full', similarity_alpha=0.3)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
