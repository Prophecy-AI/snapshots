{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a965601f",
   "metadata": {},
   "source": [
    "# Experiment 120: Median Ensemble\n",
    "\n",
    "**Goal**: Use median aggregation instead of mean for robustness to outliers.\n",
    "\n",
    "**Key Insight**: Mean aggregation can be dominated by extreme predictions. Median is more robust and may reduce errors on unseen solvents.\n",
    "\n",
    "**Approach**:\n",
    "1. Train multiple CatBoost + XGBoost models with different seeds\n",
    "2. At prediction time, use MEDIAN instead of mean to aggregate\n",
    "3. This should be more robust to outlier predictions\n",
    "\n",
    "**Hypothesis**: Median aggregation might reduce the CV-LB intercept by avoiding extreme predictions on unseen solvents.\n",
    "\n",
    "**CRITICAL**: The model class `MedianEnsembleModel` will be used in BOTH CV computation AND submission cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8aa5e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:22:46.906673Z",
     "iopub.status.busy": "2026-01-16T22:22:46.906040Z",
     "iopub.status.idle": "2026-01-16T22:22:48.485406Z",
     "shell.execute_reply": "2026-01-16T22:22:48.484975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a819a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:22:48.486757Z",
     "iopub.status.busy": "2026-01-16T22:22:48.486589Z",
     "iopub.status.idle": "2026-01-16T22:22:48.491007Z",
     "shell.execute_reply": "2026-01-16T22:22:48.490648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb695e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:22:48.492056Z",
     "iopub.status.busy": "2026-01-16T22:22:48.491956Z",
     "iopub.status.idle": "2026-01-16T22:22:48.522891Z",
     "shell.execute_reply": "2026-01-16T22:22:48.522521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP filtered: (24, 122), ACS PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a447b330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:22:48.523814Z",
     "iopub.status.busy": "2026-01-16T22:22:48.523708Z",
     "iopub.status.idle": "2026-01-16T22:22:48.529470Z",
     "shell.execute_reply": "2026-01-16T22:22:48.529053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension: 145\n"
     ]
    }
   ],
   "source": [
    "# Featurizer\n",
    "class Featurizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "                X_drfp = B_drfp * (1 - (1-pct)) + A_drfp * (1-pct)\n",
    "                X_acs = B_acs * (1 - (1-pct)) + A_acs * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "\n",
    "print(f'Feature dimension: {Featurizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f18fd18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:22:48.530399Z",
     "iopub.status.busy": "2026-01-16T22:22:48.530284Z",
     "iopub.status.idle": "2026-01-16T22:22:48.536413Z",
     "shell.execute_reply": "2026-01-16T22:22:48.535983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedianEnsembleModel defined - will be used in both CV and submission cells\n"
     ]
    }
   ],
   "source": [
    "# Median Ensemble Model - uses median aggregation for robustness\n",
    "class MedianEnsembleModel:\n",
    "    \"\"\"Ensemble with median aggregation for robustness to outliers.\n",
    "    \n",
    "    Key insight: Mean aggregation can be dominated by extreme predictions.\n",
    "    Median is more robust and may reduce errors on unseen solvents.\n",
    "    \n",
    "    This is the SAME class used in both CV and submission cells.\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single', n_seeds=5):\n",
    "        self.data_type = data\n",
    "        self.n_seeds = n_seeds\n",
    "        self.featurizer = Featurizer(mixed=(data=='full'))\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = []  # List of model lists for each seed\n",
    "        \n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Featurize\n",
    "        X_feat = self.featurizer.featurize(X_train)\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        # Train models with different seeds\n",
    "        for seed in range(self.n_seeds):\n",
    "            seed_models = []\n",
    "            for i in range(3):  # 3 targets\n",
    "                # CatBoost\n",
    "                cb_model = cb.CatBoostRegressor(\n",
    "                    iterations=500,\n",
    "                    learning_rate=0.05,\n",
    "                    depth=6,\n",
    "                    l2_leaf_reg=3,\n",
    "                    random_seed=42 + seed * 100,\n",
    "                    verbose=False\n",
    "                )\n",
    "                cb_model.fit(X_scaled, y_vals[:, i])\n",
    "                \n",
    "                # XGBoost\n",
    "                xgb_model = xgb.XGBRegressor(\n",
    "                    n_estimators=500,\n",
    "                    learning_rate=0.05,\n",
    "                    max_depth=6,\n",
    "                    reg_lambda=1,\n",
    "                    random_state=42 + seed * 100,\n",
    "                    verbosity=0\n",
    "                )\n",
    "                xgb_model.fit(X_scaled, y_vals[:, i])\n",
    "                \n",
    "                seed_models.append((cb_model, xgb_model))\n",
    "            self.models.append(seed_models)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_feat = self.featurizer.featurize(X)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        all_preds = []\n",
    "        for seed_models in self.models:\n",
    "            seed_pred = []\n",
    "            for i, (cb_model, xgb_model) in enumerate(seed_models):\n",
    "                cb_pred = cb_model.predict(X_scaled)\n",
    "                xgb_pred = xgb_model.predict(X_scaled)\n",
    "                # Average CatBoost and XGBoost for this seed\n",
    "                seed_pred.append((cb_pred + xgb_pred) / 2)\n",
    "            all_preds.append(np.column_stack(seed_pred))\n",
    "        \n",
    "        # Use MEDIAN instead of mean across seeds\n",
    "        pred = np.median(all_preds, axis=0)\n",
    "        pred = np.clip(pred, 0, 1)\n",
    "        \n",
    "        return torch.tensor(pred)\n",
    "\n",
    "print('MedianEnsembleModel defined - will be used in both CV and submission cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9c52bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:22:48.537335Z",
     "iopub.status.busy": "2026-01-16T22:22:48.537211Z",
     "iopub.status.idle": "2026-01-16T22:22:48.550926Z",
     "shell.execute_reply": "2026-01-16T22:22:48.550523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent: 656 samples\n",
      "Full data: 1227 samples\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "print(f\"Single solvent: {len(X_single)} samples\")\n",
    "print(f\"Full data: {len(X_full)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "681c0826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:23:01.429712Z",
     "iopub.status.busy": "2026-01-16T22:23:01.429292Z",
     "iopub.status.idle": "2026-01-16T22:25:53.331814Z",
     "shell.execute_reply": "2026-01-16T22:25:53.331050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing CV score...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 0: MSE = 0.037096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6: MSE = 0.007061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 12: MSE = 0.002549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 18: MSE = 0.009140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single solvent MSE: 0.010299\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation to compute CV score\n",
    "print(\"Computing CV score...\")\n",
    "\n",
    "# Single solvent CV\n",
    "single_mses = []\n",
    "\n",
    "for fold_idx, split in enumerate(generate_leave_one_out_splits(X_single, Y_single)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = MedianEnsembleModel(data='single', n_seeds=5)  # SAME CLASS AS SUBMISSION\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    targets = test_Y.values\n",
    "    \n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    single_mses.append(mse)\n",
    "    \n",
    "    if fold_idx % 6 == 0:\n",
    "        print(f\"  Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "\n",
    "single_mse = np.mean(single_mses)\n",
    "print(f\"\\nSingle solvent MSE: {single_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3125ed10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:26:08.024660Z",
     "iopub.status.busy": "2026-01-16T22:26:08.024148Z",
     "iopub.status.idle": "2026-01-16T22:29:04.782546Z",
     "shell.execute_reply": "2026-01-16T22:29:04.782110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 0: MSE = 0.006294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3: MSE = 0.009415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6: MSE = 0.018295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 9: MSE = 0.004881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 12: MSE = 0.002259\n",
      "\n",
      "Full data MSE: 0.008190\n"
     ]
    }
   ],
   "source": [
    "# Full data CV\n",
    "full_mses = []\n",
    "\n",
    "for fold_idx, split in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = MedianEnsembleModel(data='full', n_seeds=5)  # SAME CLASS AS SUBMISSION\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    targets = test_Y.values\n",
    "    \n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    full_mses.append(mse)\n",
    "    \n",
    "    if fold_idx % 3 == 0:\n",
    "        print(f\"  Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "\n",
    "full_mse = np.mean(full_mses)\n",
    "print(f\"\\nFull data MSE: {full_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0af34fb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:29:04.783723Z",
     "iopub.status.busy": "2026-01-16T22:29:04.783618Z",
     "iopub.status.idle": "2026-01-16T22:29:04.787135Z",
     "shell.execute_reply": "2026-01-16T22:29:04.786781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV Results ===\n",
      "Single solvent MSE: 0.010299\n",
      "Full data MSE: 0.008190\n",
      "Combined CV score: 0.009244\n",
      "\n",
      "Comparison with best CV: 0.0081\n",
      "This experiment: 0.009244\n",
      "No improvement. Difference: 0.001144\n"
     ]
    }
   ],
   "source": [
    "# Combined CV score\n",
    "cv_score = (single_mse + full_mse) / 2\n",
    "print(f\"\\n=== CV Results ===\")\n",
    "print(f\"Single solvent MSE: {single_mse:.6f}\")\n",
    "print(f\"Full data MSE: {full_mse:.6f}\")\n",
    "print(f\"Combined CV score: {cv_score:.6f}\")\n",
    "\n",
    "# Save metrics\n",
    "import json\n",
    "metrics = {\n",
    "    'cv_score': cv_score,\n",
    "    'single_mse': single_mse,\n",
    "    'full_mse': full_mse\n",
    "}\n",
    "with open('/home/code/experiments/120_median_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "\n",
    "print(f\"\\nComparison with best CV: 0.0081\")\n",
    "print(f\"This experiment: {cv_score:.6f}\")\n",
    "if cv_score < 0.0081:\n",
    "    print(\"IMPROVEMENT! This is better than best CV.\")\n",
    "else:\n",
    "    print(f\"No improvement. Difference: {cv_score - 0.0081:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MedianEnsembleModel(data='single', n_seeds=5)  # SAME CLASS AS CV\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MedianEnsembleModel(data='full', n_seeds=5)  # SAME CLASS AS CV\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20328b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "print(f\"Submission saved with {len(submission)} rows\")\n",
    "print(submission.head())\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
