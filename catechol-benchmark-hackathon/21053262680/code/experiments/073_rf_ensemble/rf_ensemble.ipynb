{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756722b0",
   "metadata": {},
   "source": [
    "# MLP + XGBoost + RandomForest + LightGBM Ensemble\n",
    "\n",
    "**Problem**: CV-LB intercept (0.0525) > Target (0.0347). Need to change the CV-LB relationship.\n",
    "\n",
    "**Approach**: Implement the lishellliang kernel's ensemble with RandomForest.\n",
    "- MLP + XGBoost + RandomForest + LightGBM\n",
    "- Use Leave-One-Out validation (NOT GroupKFold)\n",
    "- Test if RF adds diversity that changes CV-LB relationship\n",
    "\n",
    "**Key**: This notebook has EXACTLY 3 submission cells at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61afb0f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:29:55.545353Z",
     "iopub.status.busy": "2026-01-16T07:29:55.544813Z",
     "iopub.status.idle": "2026-01-16T07:29:57.259544Z",
     "shell.execute_reply": "2026-01-16T07:29:57.259136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4fc8c72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:29:57.260862Z",
     "iopub.status.busy": "2026-01-16T07:29:57.260705Z",
     "iopub.status.idle": "2026-01-16T07:29:57.265044Z",
     "shell.execute_reply": "2026-01-16T07:29:57.264677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42719e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:29:57.266073Z",
     "iopub.status.busy": "2026-01-16T07:29:57.265960Z",
     "iopub.status.idle": "2026-01-16T07:29:57.293727Z",
     "shell.execute_reply": "2026-01-16T07:29:57.293409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP filtered: (24, 122), ACS PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8880367d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:29:57.294634Z",
     "iopub.status.busy": "2026-01-16T07:29:57.294541Z",
     "iopub.status.idle": "2026-01-16T07:29:57.299403Z",
     "shell.execute_reply": "2026-01-16T07:29:57.299018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension: 145\n"
     ]
    }
   ],
   "source": [
    "# Featurizer class\n",
    "class Featurizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float32)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "            X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "            X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs]).astype(np.float32)\n",
    "\n",
    "print(f'Feature dimension: {Featurizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf126243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:29:57.300306Z",
     "iopub.status.busy": "2026-01-16T07:29:57.300203Z",
     "iopub.status.idle": "2026-01-16T07:29:57.303557Z",
     "shell.execute_reply": "2026-01-16T07:29:57.303217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnhancedMLP defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model\n",
    "class EnhancedMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 64, 32], output_dim=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = [nn.BatchNorm1d(input_dim)]\n",
    "        prev_dim = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.extend([nn.Linear(prev_dim, h), nn.ReLU(), nn.Dropout(dropout)])\n",
    "            prev_dim = h\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print('EnhancedMLP defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "412e0c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:29:57.304624Z",
     "iopub.status.busy": "2026-01-16T07:29:57.304387Z",
     "iopub.status.idle": "2026-01-16T07:29:57.311477Z",
     "shell.execute_reply": "2026-01-16T07:29:57.311132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFEnsembleModel defined\n"
     ]
    }
   ],
   "source": [
    "# MLP + XGBoost + RandomForest + LightGBM Ensemble\n",
    "class RFEnsembleModel:\n",
    "    \"\"\"Ensemble with MLP + XGBoost + RandomForest + LightGBM.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "        self.data = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.weights = weights  # [mlp, xgb, rf, lgbm]\n",
    "        \n",
    "        self.featurizer = Featurizer(mixed=self.mixed)\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def train_model(self, X, Y, epochs=150):\n",
    "        Y_np = Y.values if hasattr(Y, 'values') else Y\n",
    "        \n",
    "        # Featurize and scale\n",
    "        X_features = self.featurizer.featurize(X)\n",
    "        X_scaled = self.scaler.fit_transform(X_features)\n",
    "        \n",
    "        # Train MLP\n",
    "        X_torch = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "        Y_torch = torch.tensor(Y_np, dtype=torch.float32).to(device)\n",
    "        \n",
    "        self.mlp = EnhancedMLP(input_dim=X_scaled.shape[1]).to(device)\n",
    "        optimizer = torch.optim.Adam(self.mlp.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "        criterion = nn.HuberLoss()\n",
    "        \n",
    "        dataset = TensorDataset(X_torch, Y_torch)\n",
    "        loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        self.mlp.train()\n",
    "        for epoch in range(epochs):\n",
    "            for xb, yb in loader:\n",
    "                optimizer.zero_grad()\n",
    "                pred = self.mlp(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Train XGBoost (per-target)\n",
    "        self.xgb_models = []\n",
    "        for i in range(3):\n",
    "            model = xgb.XGBRegressor(\n",
    "                n_estimators=200, max_depth=6, learning_rate=0.05,\n",
    "                subsample=0.8, colsample_bytree=0.8,\n",
    "                random_state=42, verbosity=0\n",
    "            )\n",
    "            model.fit(X_scaled, Y_np[:, i])\n",
    "            self.xgb_models.append(model)\n",
    "        \n",
    "        # Train RandomForest (per-target)\n",
    "        self.rf_models = []\n",
    "        for i in range(3):\n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=100, max_depth=10, min_samples_split=5,\n",
    "                random_state=42, n_jobs=-1\n",
    "            )\n",
    "            model.fit(X_scaled, Y_np[:, i])\n",
    "            self.rf_models.append(model)\n",
    "        \n",
    "        # Train LightGBM (per-target)\n",
    "        self.lgbm_models = []\n",
    "        for i in range(3):\n",
    "            model = lgb.LGBMRegressor(\n",
    "                n_estimators=200, learning_rate=0.05, max_depth=6,\n",
    "                num_leaves=31, reg_alpha=0.1, reg_lambda=0.1,\n",
    "                random_state=42, verbose=-1\n",
    "            )\n",
    "            model.fit(X_scaled, Y_np[:, i])\n",
    "            self.lgbm_models.append(model)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_features = self.featurizer.featurize(X)\n",
    "        X_scaled = self.scaler.transform(X_features)\n",
    "        \n",
    "        # MLP predictions\n",
    "        self.mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            X_torch = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "            mlp_preds = self.mlp(X_torch).cpu().numpy()\n",
    "        \n",
    "        # XGBoost predictions\n",
    "        xgb_preds = np.column_stack([m.predict(X_scaled) for m in self.xgb_models])\n",
    "        \n",
    "        # RandomForest predictions\n",
    "        rf_preds = np.column_stack([m.predict(X_scaled) for m in self.rf_models])\n",
    "        \n",
    "        # LightGBM predictions\n",
    "        lgbm_preds = np.column_stack([m.predict(X_scaled) for m in self.lgbm_models])\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        final_preds = (self.weights[0] * mlp_preds + \n",
    "                       self.weights[1] * xgb_preds + \n",
    "                       self.weights[2] * rf_preds + \n",
    "                       self.weights[3] * lgbm_preds)\n",
    "        \n",
    "        # Clip to valid range [0, 1]\n",
    "        final_preds = np.clip(final_preds, 0, 1)\n",
    "        \n",
    "        return torch.tensor(final_preds, dtype=torch.float32)\n",
    "\n",
    "print('RFEnsembleModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b26fa53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:29:57.312525Z",
     "iopub.status.busy": "2026-01-16T07:29:57.312309Z",
     "iopub.status.idle": "2026-01-16T07:30:01.254600Z",
     "shell.execute_reply": "2026-01-16T07:30:01.254195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test solvent: 1,1,1,3,3,3-Hexafluoropropan-2-ol\n",
      "Training samples: 619, Test samples: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fold MSE: 0.045170\n"
     ]
    }
   ],
   "source": [
    "# Quick test on single fold\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "test_solvent = sorted(X_single[\"SOLVENT NAME\"].unique())[0]\n",
    "mask = X_single[\"SOLVENT NAME\"] != test_solvent\n",
    "\n",
    "print(f\"Test solvent: {test_solvent}\")\n",
    "print(f\"Training samples: {mask.sum()}, Test samples: {(~mask).sum()}\")\n",
    "\n",
    "model = RFEnsembleModel(data='single')\n",
    "model.train_model(X_single[mask], Y_single[mask], epochs=100)\n",
    "preds = model.predict(X_single[~mask])\n",
    "\n",
    "actuals = Y_single[~mask].values\n",
    "mse = np.mean((actuals - preds.numpy()) ** 2)\n",
    "print(f'Test fold MSE: {mse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b10f92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:30:17.942578Z",
     "iopub.status.busy": "2026-01-16T07:30:17.941904Z",
     "iopub.status.idle": "2026-01-16T07:32:05.184174Z",
     "shell.execute_reply": "2026-01-16T07:32:05.183782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CV for single solvent data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:04,  4.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:08,  4.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:13,  4.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:17,  4.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:22,  4.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:26,  4.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:30,  4.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:35,  4.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:39,  4.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:44,  4.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:48,  4.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:53,  4.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:57,  4.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [01:02,  4.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [01:06,  4.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [01:11,  4.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [01:15,  4.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [01:20,  4.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [01:24,  4.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [01:29,  4.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [01:33,  4.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [01:38,  4.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [01:42,  4.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [01:47,  4.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [01:47,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Solvent MSE: 0.010213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run full CV for single solvent\n",
    "print('Running CV for single solvent data...')\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_preds = []\n",
    "all_actuals = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = RFEnsembleModel(data='single')\n",
    "    model.train_model(train_X, train_Y, epochs=150)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    all_preds.append(predictions_np)\n",
    "    all_actuals.append(test_Y.values)\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_actuals = np.vstack(all_actuals)\n",
    "mse_single = np.mean((all_preds - all_actuals) ** 2)\n",
    "print(f'\\nSingle Solvent MSE: {mse_single:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "704e721e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:32:20.569176Z",
     "iopub.status.busy": "2026-01-16T07:32:20.568661Z",
     "iopub.status.idle": "2026-01-16T07:34:03.861595Z",
     "shell.execute_reply": "2026-01-16T07:34:03.861152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CV for full data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:07,  7.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:15,  7.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:23,  7.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:31,  7.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:38,  7.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:46,  7.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:54,  7.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [01:01,  7.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [01:09,  7.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [01:18,  7.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [01:26,  8.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [01:34,  8.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [01:43,  8.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [01:43,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Data MSE: 0.009643\n",
      "\n",
      "Overall MSE: 0.009842\n",
      "Baseline (exp_030 GP+MLP+LGBM): CV 0.008298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run full CV for full data\n",
    "print('Running CV for full data...')\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_preds_full = []\n",
    "all_actuals_full = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = RFEnsembleModel(data='full')\n",
    "    model.train_model(train_X, train_Y, epochs=150)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    all_preds_full.append(predictions_np)\n",
    "    all_actuals_full.append(test_Y.values)\n",
    "\n",
    "all_preds_full = np.vstack(all_preds_full)\n",
    "all_actuals_full = np.vstack(all_actuals_full)\n",
    "mse_full = np.mean((all_preds_full - all_actuals_full) ** 2)\n",
    "print(f'\\nFull Data MSE: {mse_full:.6f}')\n",
    "\n",
    "# Overall MSE\n",
    "n_single = len(all_actuals)\n",
    "n_full = len(all_actuals_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "print(f'\\nOverall MSE: {overall_mse:.6f}')\n",
    "print(f'Baseline (exp_030 GP+MLP+LGBM): CV 0.008298')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = RFEnsembleModel(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97331e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = RFEnsembleModel(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599590f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
