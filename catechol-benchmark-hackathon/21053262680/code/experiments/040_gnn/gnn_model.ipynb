{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c825bc",
   "metadata": {},
   "source": [
    "# GNN Model with AttentiveFP\n",
    "\n",
    "**Problem**: CV-LB gap has intercept (0.0525) > target (0.0347). Current approach CANNOT reach target.\n",
    "\n",
    "**Solution**: GNN learns from molecular STRUCTURE, not IDENTITY. Can generalize to unseen solvents.\n",
    "\n",
    "**GNN Benchmark**: MSE 0.0039 on this exact dataset (22x better than our best LB!)\n",
    "\n",
    "**Baseline**: exp_035 CV 0.008194, LB 0.0877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea484e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:02:33.936917Z",
     "iopub.status.busy": "2026-01-15T05:02:33.936628Z",
     "iopub.status.idle": "2026-01-15T05:02:37.886539Z",
     "shell.execute_reply": "2026-01-15T05:02:37.885808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch Geometric imports\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import AttentiveFP, global_mean_pool\n",
    "\n",
    "# RDKit imports\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.float32)  # GNN works better with float32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64f7c7a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:02:37.889266Z",
     "iopub.status.busy": "2026-01-15T05:02:37.888533Z",
     "iopub.status.idle": "2026-01-15T05:02:37.896094Z",
     "shell.execute_reply": "2026-01-15T05:02:37.895413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28161fbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:02:37.897936Z",
     "iopub.status.busy": "2026-01-15T05:02:37.897570Z",
     "iopub.status.idle": "2026-01-15T05:02:37.908092Z",
     "shell.execute_reply": "2026-01-15T05:02:37.907532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES lookup: 26 solvents\n",
      "                                           solvent smiles\n",
      "SOLVENT NAME                                             \n",
      "Cyclohexane                                      C1CCCCC1\n",
      "Ethyl Acetate                                   O=C(OCC)C\n",
      "Acetic Acid                                       CC(=O)O\n",
      "2-Methyltetrahydrofuran [2-MeTHF]              O1C(C)CCC1\n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol  C(C(F)(F)F)(C(F)(F)F)O\n"
     ]
    }
   ],
   "source": [
    "# Load SMILES lookup\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "print(f'SMILES lookup: {len(SMILES_DF)} solvents')\n",
    "print(SMILES_DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5efa76d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:02:37.910034Z",
     "iopub.status.busy": "2026-01-15T05:02:37.909615Z",
     "iopub.status.idle": "2026-01-15T05:02:37.925075Z",
     "shell.execute_reply": "2026-01-15T05:02:37.924590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test SMILES: CCO\n",
      "Graph: 3 nodes, 4 edges\n",
      "Node features shape: torch.Size([3, 6])\n",
      "Edge features shape: torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# SMILES to molecular graph conversion\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"Convert SMILES to PyTorch Geometric Data object.\n",
    "    \n",
    "    For mixture SMILES (e.g., 'O.CC#N'), we process the first component.\n",
    "    \"\"\"\n",
    "    # Handle mixture SMILES by taking the first component\n",
    "    if '.' in smiles:\n",
    "        smiles = smiles.split('.')[0]\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        raise ValueError(f\"Could not parse SMILES: {smiles}\")\n",
    "    \n",
    "    # Atom features (6 features)\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        features = [\n",
    "            atom.GetAtomicNum(),\n",
    "            atom.GetDegree(),\n",
    "            atom.GetFormalCharge(),\n",
    "            int(atom.GetHybridization()),\n",
    "            int(atom.GetIsAromatic()),\n",
    "            atom.GetTotalNumHs(),\n",
    "        ]\n",
    "        atom_features.append(features)\n",
    "    \n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    \n",
    "    # Edge features (3 features)\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_index.extend([[i, j], [j, i]])\n",
    "        \n",
    "        bond_features = [\n",
    "            float(bond.GetBondTypeAsDouble()),\n",
    "            int(bond.GetIsAromatic()),\n",
    "            int(bond.IsInRing()),\n",
    "        ]\n",
    "        edge_attr.extend([bond_features, bond_features])\n",
    "    \n",
    "    if len(edge_index) == 0:\n",
    "        # Single atom molecule (e.g., Water 'O')\n",
    "        edge_index = [[0, 0]]\n",
    "        edge_attr = [[0.0, 0, 0]]\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "# Test the function\n",
    "test_smiles = SMILES_DF.loc['Ethanol', 'solvent smiles']\n",
    "print(f\"Test SMILES: {test_smiles}\")\n",
    "graph = smiles_to_graph(test_smiles)\n",
    "print(f\"Graph: {graph.num_nodes} nodes, {graph.num_edges} edges\")\n",
    "print(f\"Node features shape: {graph.x.shape}\")\n",
    "print(f\"Edge features shape: {graph.edge_attr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752b5df5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:02:37.926537Z",
     "iopub.status.busy": "2026-01-15T05:02:37.926370Z",
     "iopub.status.idle": "2026-01-15T05:02:37.940690Z",
     "shell.execute_reply": "2026-01-15T05:02:37.940197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cyclohexane: 6 nodes, 12 edges\n",
      "Ethyl Acetate: 6 nodes, 10 edges\n",
      "Acetic Acid: 4 nodes, 6 edges\n",
      "2-Methyltetrahydrofuran [2-MeTHF]: 6 nodes, 12 edges\n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol: 10 nodes, 18 edges\n",
      "IPA [Propan-2-ol]: 4 nodes, 6 edges\n",
      "Ethanol: 3 nodes, 4 edges\n",
      "Methanol: 2 nodes, 2 edges\n",
      "Ethylene Glycol [1,2-Ethanediol]: 4 nodes, 6 edges\n",
      "Acetonitrile: 3 nodes, 4 edges\n",
      "Water: 1 nodes, 1 edges\n",
      "Diethyl Ether [Ether]: 5 nodes, 8 edges\n",
      "MTBE [tert-Butylmethylether]: 6 nodes, 10 edges\n",
      "Dimethyl Carbonate: 6 nodes, 10 edges\n",
      "tert-Butanol [2-Methylpropan-2-ol]: 5 nodes, 8 edges\n",
      "DMA [N,N-Dimethylacetamide]: 6 nodes, 10 edges\n",
      "2,2,2-Trifluoroethanol: 6 nodes, 10 edges\n",
      "Dihydrolevoglucosenone (Cyrene): 9 nodes, 20 edges\n",
      "Decanol: 11 nodes, 20 edges\n",
      "Butanone [MEK]: 5 nodes, 8 edges\n",
      "Ethyl Lactate: 8 nodes, 14 edges\n",
      "Methyl Propionate: 6 nodes, 10 edges\n",
      "THF [Tetrahydrofuran]: 5 nodes, 10 edges\n",
      "Water.Acetonitrile: 1 nodes, 1 edges\n",
      "Acetonitrile.Acetic Acid: 3 nodes, 4 edges\n",
      "Water.2,2,2-Trifluoroethanol: 1 nodes, 1 edges\n",
      "\n",
      "Total graphs: 26\n"
     ]
    }
   ],
   "source": [
    "# Pre-compute molecular graphs for all solvents\n",
    "SOLVENT_GRAPHS = {}\n",
    "for solvent_name in SMILES_DF.index:\n",
    "    smiles = SMILES_DF.loc[solvent_name, 'solvent smiles']\n",
    "    try:\n",
    "        graph = smiles_to_graph(smiles)\n",
    "        SOLVENT_GRAPHS[solvent_name] = graph\n",
    "        print(f\"{solvent_name}: {graph.num_nodes} nodes, {graph.num_edges} edges\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR {solvent_name}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal graphs: {len(SOLVENT_GRAPHS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ea6c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:02:37.942581Z",
     "iopub.status.busy": "2026-01-15T05:02:37.942119Z",
     "iopub.status.idle": "2026-01-15T05:02:37.948849Z",
     "shell.execute_reply": "2026-01-15T05:02:37.948362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNModel defined\n"
     ]
    }
   ],
   "source": [
    "# GNN Model using AttentiveFP\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, data='single'):\n",
    "        super().__init__()\n",
    "        self.data_type = data\n",
    "        \n",
    "        # AttentiveFP for molecular property prediction\n",
    "        self.gnn = AttentiveFP(\n",
    "            in_channels=6,      # atom features\n",
    "            hidden_channels=64,\n",
    "            out_channels=32,    # embedding dim\n",
    "            edge_dim=3,         # edge features\n",
    "            num_layers=2,\n",
    "            num_timesteps=2,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        \n",
    "        # Kinetics features: T, t, 1/T, ln(t), interaction\n",
    "        kinetics_dim = 5\n",
    "        \n",
    "        if data == 'single':\n",
    "            input_dim = 32 + kinetics_dim  # GNN embedding + kinetics\n",
    "        else:\n",
    "            input_dim = 64 + kinetics_dim + 1  # 2 GNN embeddings + kinetics + pct\n",
    "        \n",
    "        # Prediction head\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, graph_batch, kinetics, pct=None, graph_batch_b=None):\n",
    "        # Get GNN embeddings\n",
    "        emb_a = self.gnn(graph_batch.x, graph_batch.edge_index, \n",
    "                        graph_batch.edge_attr, graph_batch.batch)\n",
    "        \n",
    "        if self.data_type == 'single':\n",
    "            x = torch.cat([emb_a, kinetics], dim=1)\n",
    "        else:\n",
    "            emb_b = self.gnn(graph_batch_b.x, graph_batch_b.edge_index,\n",
    "                           graph_batch_b.edge_attr, graph_batch_b.batch)\n",
    "            x = torch.cat([emb_a, emb_b, pct.unsqueeze(1), kinetics], dim=1)\n",
    "        \n",
    "        return self.predictor(x)\n",
    "\n",
    "print('GNNModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1585fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:02:37.950595Z",
     "iopub.status.busy": "2026-01-15T05:02:37.950405Z",
     "iopub.status.idle": "2026-01-15T05:02:37.965119Z",
     "shell.execute_reply": "2026-01-15T05:02:37.964618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# GNN Wrapper for training and prediction\n",
    "class GNNWrapper:\n",
    "    def __init__(self, data='single', n_models=3):\n",
    "        self.data_type = data\n",
    "        self.n_models = n_models\n",
    "        self.models = []\n",
    "        self.solvent_graphs = SOLVENT_GRAPHS\n",
    "    \n",
    "    def _get_kinetics(self, X):\n",
    "        \"\"\"Extract kinetics features: time, temp, 1/T, ln(t), interaction\"\"\"\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float32)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        return np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "    \n",
    "    def _get_graphs(self, solvent_names):\n",
    "        \"\"\"Get list of graphs for solvent names\"\"\"\n",
    "        graphs = []\n",
    "        for name in solvent_names:\n",
    "            if name in self.solvent_graphs:\n",
    "                graphs.append(self.solvent_graphs[name])\n",
    "            else:\n",
    "                # Fallback: create a simple graph\n",
    "                print(f\"Warning: No graph for {name}\")\n",
    "                graphs.append(self.solvent_graphs['Water'])\n",
    "        return graphs\n",
    "    \n",
    "    def train_model(self, X_train, y_train, epochs=200, batch_size=32, lr=1e-3):\n",
    "        kinetics = torch.tensor(self._get_kinetics(X_train), dtype=torch.float32)\n",
    "        y_vals = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "        \n",
    "        if self.data_type == 'single':\n",
    "            graphs = self._get_graphs(X_train[\"SOLVENT NAME\"].values)\n",
    "        else:\n",
    "            graphs_a = self._get_graphs(X_train[\"SOLVENT A NAME\"].values)\n",
    "            graphs_b = self._get_graphs(X_train[\"SOLVENT B NAME\"].values)\n",
    "            pct = torch.tensor(X_train[\"SolventB%\"].values, dtype=torch.float32)\n",
    "        \n",
    "        self.models = []\n",
    "        for i in range(self.n_models):\n",
    "            torch.manual_seed(42 + i)\n",
    "            model = GNNModel(data=self.data_type).to(device)\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "            criterion = nn.HuberLoss()\n",
    "            \n",
    "            model.train()\n",
    "            n_samples = len(kinetics)\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                # Shuffle indices\n",
    "                indices = torch.randperm(n_samples)\n",
    "                \n",
    "                for start in range(0, n_samples, batch_size):\n",
    "                    end = min(start + batch_size, n_samples)\n",
    "                    batch_idx = indices[start:end]\n",
    "                    \n",
    "                    # Get batch data\n",
    "                    batch_kinetics = kinetics[batch_idx].to(device)\n",
    "                    batch_y = y_vals[batch_idx].to(device)\n",
    "                    \n",
    "                    if self.data_type == 'single':\n",
    "                        batch_graphs = [graphs[j] for j in batch_idx]\n",
    "                        batch_graph = Batch.from_data_list(batch_graphs).to(device)\n",
    "                        pred = model(batch_graph, batch_kinetics)\n",
    "                    else:\n",
    "                        batch_graphs_a = [graphs_a[j] for j in batch_idx]\n",
    "                        batch_graphs_b = [graphs_b[j] for j in batch_idx]\n",
    "                        batch_graph_a = Batch.from_data_list(batch_graphs_a).to(device)\n",
    "                        batch_graph_b = Batch.from_data_list(batch_graphs_b).to(device)\n",
    "                        batch_pct = pct[batch_idx].to(device)\n",
    "                        pred = model(batch_graph_a, batch_kinetics, batch_pct, batch_graph_b)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    loss = criterion(pred, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            self.models.append(model)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        kinetics = torch.tensor(self._get_kinetics(X_test), dtype=torch.float32).to(device)\n",
    "        \n",
    "        if self.data_type == 'single':\n",
    "            graphs = self._get_graphs(X_test[\"SOLVENT NAME\"].values)\n",
    "            graph_batch = Batch.from_data_list(graphs).to(device)\n",
    "        else:\n",
    "            graphs_a = self._get_graphs(X_test[\"SOLVENT A NAME\"].values)\n",
    "            graphs_b = self._get_graphs(X_test[\"SOLVENT B NAME\"].values)\n",
    "            graph_batch_a = Batch.from_data_list(graphs_a).to(device)\n",
    "            graph_batch_b = Batch.from_data_list(graphs_b).to(device)\n",
    "            pct = torch.tensor(X_test[\"SolventB%\"].values, dtype=torch.float32).to(device)\n",
    "        \n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for model in self.models:\n",
    "                if self.data_type == 'single':\n",
    "                    pred = model(graph_batch, kinetics)\n",
    "                else:\n",
    "                    pred = model(graph_batch_a, kinetics, pct, graph_batch_b)\n",
    "                preds.append(pred.cpu())\n",
    "        \n",
    "        return torch.clamp(torch.stack(preds).mean(dim=0), 0, 1).double()\n",
    "\n",
    "print('GNNWrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e5984fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:02:37.967002Z",
     "iopub.status.busy": "2026-01-15T05:02:37.966521Z",
     "iopub.status.idle": "2026-01-15T05:02:50.350405Z",
     "shell.execute_reply": "2026-01-15T05:02:50.349823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test solvent: 1,1,1,3,3,3-Hexafluoropropan-2-ol\n",
      "Training samples: 619, Test samples: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fold MSE: 0.068767\n",
      "Predictions shape: torch.Size([37, 3])\n"
     ]
    }
   ],
   "source": [
    "# Quick test on single fold\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "test_solvent = sorted(X_single[\"SOLVENT NAME\"].unique())[0]\n",
    "mask = X_single[\"SOLVENT NAME\"] != test_solvent\n",
    "\n",
    "print(f\"Test solvent: {test_solvent}\")\n",
    "print(f\"Training samples: {mask.sum()}, Test samples: {(~mask).sum()}\")\n",
    "\n",
    "model = GNNWrapper(data='single', n_models=1)\n",
    "model.train_model(X_single[mask], Y_single[mask], epochs=50)\n",
    "preds = model.predict(X_single[~mask])\n",
    "\n",
    "actuals = Y_single[~mask].values\n",
    "mse = np.mean((actuals - preds.numpy()) ** 2)\n",
    "print(f'Test fold MSE: {mse:.6f}')\n",
    "print(f'Predictions shape: {preds.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNWrapper(data='single', n_models=3)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y, epochs=100)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNWrapper(data='full', n_models=3)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y, epochs=100)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8674cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CV score (for verification only - NOT part of submission)\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "# Get actuals in same order as predictions\n",
    "actuals_single = []\n",
    "for solvent in sorted(X_single[\"SOLVENT NAME\"].unique()):\n",
    "    mask = X_single[\"SOLVENT NAME\"] == solvent\n",
    "    actuals_single.append(Y_single[mask].values)\n",
    "actuals_single = np.vstack(actuals_single)\n",
    "\n",
    "actuals_full = []\n",
    "ramps = X_full[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "for _, row in ramps.iterrows():\n",
    "    mask = (X_full[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X_full[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"])\n",
    "    actuals_full.append(Y_full[mask].values)\n",
    "actuals_full = np.vstack(actuals_full)\n",
    "\n",
    "# Get predictions\n",
    "preds_single = submission_single_solvent[['target_1', 'target_2', 'target_3']].values\n",
    "preds_full = submission_full_data[['target_1', 'target_2', 'target_3']].values\n",
    "\n",
    "# Calculate MSE\n",
    "mse_single = np.mean((actuals_single - preds_single) ** 2)\n",
    "mse_full = np.mean((actuals_full - preds_full) ** 2)\n",
    "n_single = len(actuals_single)\n",
    "n_full = len(actuals_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(f'\\n=== CV SCORE VERIFICATION ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nexp_035 baseline (GP+MLP+LGBM): CV 0.008194')\n",
    "print(f'This (GNN): CV {overall_mse:.6f}')\n",
    "\n",
    "if overall_mse < 0.008194:\n",
    "    improvement = (0.008194 - overall_mse) / 0.008194 * 100\n",
    "    print(f'\\n✓ IMPROVEMENT: {improvement:.2f}% better than exp_035!')\n",
    "else:\n",
    "    degradation = (overall_mse - 0.008194) / 0.008194 * 100\n",
    "    print(f'\\n✗ WORSE: {degradation:.2f}% worse than exp_035')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
