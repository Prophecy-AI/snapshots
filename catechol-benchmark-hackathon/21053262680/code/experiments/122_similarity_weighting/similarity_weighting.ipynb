{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8e722c",
   "metadata": {},
   "source": [
    "# Experiment 122: Solvent Similarity-Based Prediction Weighting\n",
    "\n",
    "**Goal**: Address the extrapolation problem by weighting predictions based on similarity to training solvents.\n",
    "\n",
    "**Key Insight**: The CV-LB intercept (0.0546) > target (0.0347) means we're making large errors on unseen solvents. By detecting when we're extrapolating (low similarity to training) and blending toward the population mean, we might reduce these errors.\n",
    "\n",
    "**Approach**:\n",
    "1. Compute Tanimoto similarity between test solvent and all training solvents\n",
    "2. If max similarity is low (extrapolating), blend prediction toward training mean\n",
    "3. If max similarity is high (interpolating), trust model prediction\n",
    "\n",
    "**CRITICAL**: The model class `SimilarityWeightedModel` will be used in BOTH CV computation AND submission cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318d87b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:02:39.619636Z",
     "iopub.status.busy": "2026-01-16T23:02:39.619121Z",
     "iopub.status.idle": "2026-01-16T23:02:41.197184Z",
     "shell.execute_reply": "2026-01-16T23:02:41.196786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d2fc15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:02:41.198497Z",
     "iopub.status.busy": "2026-01-16T23:02:41.198331Z",
     "iopub.status.idle": "2026-01-16T23:02:41.336514Z",
     "shell.execute_reply": "2026-01-16T23:02:41.336143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit imported successfully\n"
     ]
    }
   ],
   "source": [
    "# RDKit imports for similarity computation\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "print('RDKit imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22fa7989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:02:41.337579Z",
     "iopub.status.busy": "2026-01-16T23:02:41.337481Z",
     "iopub.status.idle": "2026-01-16T23:02:41.341675Z",
     "shell.execute_reply": "2026-01-16T23:02:41.341347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a46897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:02:41.342548Z",
     "iopub.status.busy": "2026-01-16T23:02:41.342455Z",
     "iopub.status.idle": "2026-01-16T23:02:41.370916Z",
     "shell.execute_reply": "2026-01-16T23:02:41.370586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP filtered: (24, 122), ACS PCA: (24, 5)\n",
      "SMILES: (26, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')\n",
    "print(f'SMILES: {SMILES_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be941486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:02:41.371871Z",
     "iopub.status.busy": "2026-01-16T23:02:41.371784Z",
     "iopub.status.idle": "2026-01-16T23:02:41.380299Z",
     "shell.execute_reply": "2026-01-16T23:02:41.379957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed Morgan fingerprints for 23 solvents\n",
      "Solvents with fingerprints: ['Cyclohexane', 'Ethyl Acetate', 'Acetic Acid', '2-Methyltetrahydrofuran [2-MeTHF]', '1,1,1,3,3,3-Hexafluoropropan-2-ol']...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:02:41] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    }
   ],
   "source": [
    "# Pre-compute Morgan fingerprints for all solvents\n",
    "MORGAN_FP = {}\n",
    "for solvent in SMILES_DF.index:\n",
    "    smiles = SMILES_DF.loc[solvent, 'solvent smiles']\n",
    "    if isinstance(smiles, str) and '.' not in smiles:  # Skip mixtures\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "            MORGAN_FP[solvent] = fp\n",
    "\n",
    "print(f'Pre-computed Morgan fingerprints for {len(MORGAN_FP)} solvents')\n",
    "print(f'Solvents with fingerprints: {list(MORGAN_FP.keys())[:5]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "489efbe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:02:41.381052Z",
     "iopub.status.busy": "2026-01-16T23:02:41.380964Z",
     "iopub.status.idle": "2026-01-16T23:02:41.385835Z",
     "shell.execute_reply": "2026-01-16T23:02:41.385491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension: 145\n"
     ]
    }
   ],
   "source": [
    "# Featurizer\n",
    "class Featurizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "                X_drfp = B_drfp * (1 - (1-pct)) + A_drfp * (1-pct)\n",
    "                X_acs = B_acs * (1 - (1-pct)) + A_acs * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "\n",
    "print(f'Feature dimension: {Featurizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3ace2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:02:41.386633Z",
     "iopub.status.busy": "2026-01-16T23:02:41.386544Z",
     "iopub.status.idle": "2026-01-16T23:02:41.393166Z",
     "shell.execute_reply": "2026-01-16T23:02:41.392831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimilarityWeightedModel defined - will be used in both CV and submission cells\n"
     ]
    }
   ],
   "source": [
    "# Similarity-Weighted Model\n",
    "class SimilarityWeightedModel:\n",
    "    \"\"\"Model that weights predictions based on similarity to training solvents.\n",
    "    \n",
    "    Key insight: For test solvents very different from training, blend toward\n",
    "    the population mean to reduce extrapolation error.\n",
    "    \n",
    "    This is the SAME class used in both CV and submission cells.\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single', blend_threshold=0.5, blend_weight=0.3):\n",
    "        self.data_type = data\n",
    "        self.blend_threshold = blend_threshold  # Below this similarity, blend toward mean\n",
    "        self.blend_weight = blend_weight  # How much to blend toward mean\n",
    "        self.featurizer = Featurizer(mixed=(data=='full'))\n",
    "        self.scaler = StandardScaler()\n",
    "        self.catboost_models = []\n",
    "        self.xgboost_models = []\n",
    "        self.train_mean = None\n",
    "        self.train_solvents = None\n",
    "        \n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Featurize\n",
    "        X_feat = self.featurizer.featurize(X_train)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        # Store training mean and solvents\n",
    "        self.train_mean = y_vals.mean(axis=0)\n",
    "        if self.data_type == 'full':\n",
    "            self.train_solvents = set(X_train[\"SOLVENT A NAME\"].unique()) | set(X_train[\"SOLVENT B NAME\"].unique())\n",
    "        else:\n",
    "            self.train_solvents = set(X_train[\"SOLVENT NAME\"].unique())\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        \n",
    "        # Train separate models for each target\n",
    "        for i in range(3):\n",
    "            # CatBoost\n",
    "            cb_model = cb.CatBoostRegressor(\n",
    "                iterations=500,\n",
    "                learning_rate=0.05,\n",
    "                depth=6,\n",
    "                l2_leaf_reg=3,\n",
    "                random_seed=42,\n",
    "                verbose=False\n",
    "            )\n",
    "            cb_model.fit(X_scaled, y_vals[:, i])\n",
    "            self.catboost_models.append(cb_model)\n",
    "            \n",
    "            # XGBoost\n",
    "            xgb_model = xgb.XGBRegressor(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                reg_lambda=1,\n",
    "                random_state=42,\n",
    "                verbosity=0\n",
    "            )\n",
    "            xgb_model.fit(X_scaled, y_vals[:, i])\n",
    "            self.xgboost_models.append(xgb_model)\n",
    "    \n",
    "    def _get_max_similarity(self, test_solvent):\n",
    "        \"\"\"Get maximum Tanimoto similarity between test solvent and training solvents.\"\"\"\n",
    "        if test_solvent not in MORGAN_FP:\n",
    "            return 0.0  # Unknown solvent, treat as low similarity\n",
    "        \n",
    "        test_fp = MORGAN_FP[test_solvent]\n",
    "        max_sim = 0.0\n",
    "        \n",
    "        for train_solvent in self.train_solvents:\n",
    "            if train_solvent in MORGAN_FP:\n",
    "                train_fp = MORGAN_FP[train_solvent]\n",
    "                sim = DataStructs.TanimotoSimilarity(test_fp, train_fp)\n",
    "                max_sim = max(max_sim, sim)\n",
    "        \n",
    "        return max_sim\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_feat = self.featurizer.featurize(X)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        # Get predictions from both models\n",
    "        preds = []\n",
    "        for i in range(3):\n",
    "            cb_pred = self.catboost_models[i].predict(X_scaled)\n",
    "            xgb_pred = self.xgboost_models[i].predict(X_scaled)\n",
    "            # Average ensemble\n",
    "            pred = (cb_pred + xgb_pred) / 2\n",
    "            preds.append(pred)\n",
    "        \n",
    "        pred = np.column_stack(preds)\n",
    "        \n",
    "        # Apply similarity-based blending\n",
    "        if self.data_type == 'full':\n",
    "            test_solvents = X[\"SOLVENT A NAME\"].values  # Use primary solvent\n",
    "        else:\n",
    "            test_solvents = X[\"SOLVENT NAME\"].values\n",
    "        \n",
    "        for idx, test_solvent in enumerate(test_solvents):\n",
    "            max_sim = self._get_max_similarity(test_solvent)\n",
    "            \n",
    "            if max_sim < self.blend_threshold:\n",
    "                # Low similarity - blend toward mean\n",
    "                # The lower the similarity, the more we blend\n",
    "                blend_factor = self.blend_weight * (1 - max_sim / self.blend_threshold)\n",
    "                pred[idx] = (1 - blend_factor) * pred[idx] + blend_factor * self.train_mean\n",
    "        \n",
    "        pred = np.clip(pred, 0, 1)\n",
    "        \n",
    "        return torch.tensor(pred)\n",
    "\n",
    "print('SimilarityWeightedModel defined - will be used in both CV and submission cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508f5763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T23:02:41.394082Z",
     "iopub.status.busy": "2026-01-16T23:02:41.393979Z",
     "iopub.status.idle": "2026-01-16T23:02:41.405206Z",
     "shell.execute_reply": "2026-01-16T23:02:41.404886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent: 656 samples\n",
      "Full data: 1227 samples\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "print(f\"Single solvent: {len(X_single)} samples\")\n",
    "print(f\"Full data: {len(X_full)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf8ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation to compute CV score\n",
    "print(\"Computing CV score...\")\n",
    "\n",
    "# Single solvent CV\n",
    "single_mses = []\n",
    "\n",
    "for fold_idx, split in enumerate(generate_leave_one_out_splits(X_single, Y_single)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = SimilarityWeightedModel(data='single', blend_threshold=0.5, blend_weight=0.3)  # SAME CLASS AS SUBMISSION\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    targets = test_Y.values\n",
    "    \n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    single_mses.append(mse)\n",
    "    \n",
    "    if fold_idx % 6 == 0:\n",
    "        print(f\"  Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "\n",
    "single_mse = np.mean(single_mses)\n",
    "print(f\"\\nSingle solvent MSE: {single_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full data CV\n",
    "full_mses = []\n",
    "\n",
    "for fold_idx, split in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = SimilarityWeightedModel(data='full', blend_threshold=0.5, blend_weight=0.3)  # SAME CLASS AS SUBMISSION\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    targets = test_Y.values\n",
    "    \n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    full_mses.append(mse)\n",
    "    \n",
    "    if fold_idx % 3 == 0:\n",
    "        print(f\"  Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "\n",
    "full_mse = np.mean(full_mses)\n",
    "print(f\"\\nFull data MSE: {full_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined CV score\n",
    "cv_score = (single_mse + full_mse) / 2\n",
    "print(f\"\\n=== CV Results ===\")\n",
    "print(f\"Single solvent MSE: {single_mse:.6f}\")\n",
    "print(f\"Full data MSE: {full_mse:.6f}\")\n",
    "print(f\"Combined CV score: {cv_score:.6f}\")\n",
    "\n",
    "# Save metrics\n",
    "import json\n",
    "metrics = {\n",
    "    'cv_score': cv_score,\n",
    "    'single_mse': single_mse,\n",
    "    'full_mse': full_mse,\n",
    "    'blend_threshold': 0.5,\n",
    "    'blend_weight': 0.3\n",
    "}\n",
    "with open('/home/code/experiments/122_similarity_weighting/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "\n",
    "print(f\"\\nComparison with best CV: 0.0081\")\n",
    "print(f\"This experiment: {cv_score:.6f}\")\n",
    "if cv_score < 0.0081:\n",
    "    print(\"IMPROVEMENT! This is better than best CV.\")\n",
    "else:\n",
    "    print(f\"No improvement. Difference: {cv_score - 0.0081:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7616f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SimilarityWeightedModel(data='single', blend_threshold=0.5, blend_weight=0.3)  # SAME CLASS AS CV\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SimilarityWeightedModel(data='full', blend_threshold=0.5, blend_weight=0.3)  # SAME CLASS AS CV\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be0ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "print(f\"Submission saved with {len(submission)} rows\")\n",
    "print(submission.head())\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
