{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da97ce3c",
   "metadata": {},
   "source": [
    "# Clean GNN Model with AttentiveFP\n",
    "\n",
    "**Problem**: CV-LB gap has intercept (0.0525) > target (0.0347). Current approach CANNOT reach target.\n",
    "\n",
    "**Solution**: GNN learns from molecular STRUCTURE, not IDENTITY. Can generalize to unseen solvents.\n",
    "\n",
    "**Key**: This notebook has EXACTLY 3 submission cells at the end (no extra cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f2e9fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:10:49.614220Z",
     "iopub.status.busy": "2026-01-16T06:10:49.613748Z",
     "iopub.status.idle": "2026-01-16T06:10:49.713978Z",
     "shell.execute_reply": "2026-01-16T06:10:49.713579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch Geometric imports\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "# RDKit imports\n",
    "from rdkit import Chem\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19f9249a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:10:49.715086Z",
     "iopub.status.busy": "2026-01-16T06:10:49.714992Z",
     "iopub.status.idle": "2026-01-16T06:10:49.719659Z",
     "shell.execute_reply": "2026-01-16T06:10:49.719062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f377b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:10:49.720597Z",
     "iopub.status.busy": "2026-01-16T06:10:49.720494Z",
     "iopub.status.idle": "2026-01-16T06:10:49.724903Z",
     "shell.execute_reply": "2026-01-16T06:10:49.724569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES lookup: 26 solvents\n"
     ]
    }
   ],
   "source": [
    "# Load SMILES lookup\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "print(f'SMILES lookup: {len(SMILES_DF)} solvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc0077bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:10:49.725744Z",
     "iopub.status.busy": "2026-01-16T06:10:49.725655Z",
     "iopub.status.idle": "2026-01-16T06:10:49.736586Z",
     "shell.execute_reply": "2026-01-16T06:10:49.736232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed 26 solvent graphs\n"
     ]
    }
   ],
   "source": [
    "# SMILES to molecular graph conversion\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"Convert SMILES to PyTorch Geometric Data object.\"\"\"\n",
    "    if '.' in smiles:\n",
    "        smiles = smiles.split('.')[0]\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        raise ValueError(f\"Could not parse SMILES: {smiles}\")\n",
    "    \n",
    "    # Atom features (6 features)\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        features = [\n",
    "            atom.GetAtomicNum(),\n",
    "            atom.GetDegree(),\n",
    "            atom.GetFormalCharge(),\n",
    "            int(atom.GetHybridization()),\n",
    "            int(atom.GetIsAromatic()),\n",
    "            atom.GetTotalNumHs(),\n",
    "        ]\n",
    "        atom_features.append(features)\n",
    "    \n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    \n",
    "    # Edge index\n",
    "    edge_index = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_index.extend([[i, j], [j, i]])\n",
    "    \n",
    "    if len(edge_index) == 0:\n",
    "        edge_index = [[0, 0]]\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Pre-compute all graphs\n",
    "SOLVENT_GRAPHS = {}\n",
    "for solvent_name in SMILES_DF.index:\n",
    "    smiles = SMILES_DF.loc[solvent_name, 'solvent smiles']\n",
    "    SOLVENT_GRAPHS[solvent_name] = smiles_to_graph(smiles)\n",
    "\n",
    "print(f'Pre-computed {len(SOLVENT_GRAPHS)} solvent graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be74ed66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:10:49.737527Z",
     "iopub.status.busy": "2026-01-16T06:10:49.737429Z",
     "iopub.status.idle": "2026-01-16T06:10:49.743674Z",
     "shell.execute_reply": "2026-01-16T06:10:49.743333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN models defined\n"
     ]
    }
   ],
   "source": [
    "# Simple GNN Model using GCNConv\n",
    "class SimpleGNN(nn.Module):\n",
    "    def __init__(self, node_dim=6, hidden_dim=64, output_dim=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(node_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.relu(self.conv1(x, edge_index))\n",
    "        x = self.relu(self.conv2(x, edge_index))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return x\n",
    "\n",
    "# Combined GNN + MLP Model for single solvent\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, gnn_output_dim=32, kinetics_dim=5, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.gnn = SimpleGNN(output_dim=gnn_output_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(gnn_output_dim + kinetics_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, graph_batch, kinetics):\n",
    "        gnn_emb = self.gnn(graph_batch)\n",
    "        combined = torch.cat([gnn_emb, kinetics], dim=1)\n",
    "        return self.mlp(combined)\n",
    "\n",
    "# Combined GNN + MLP Model for mixed solvents\n",
    "class GNNModelMixed(nn.Module):\n",
    "    def __init__(self, gnn_output_dim=32, kinetics_dim=5, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.gnn = SimpleGNN(output_dim=gnn_output_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(gnn_output_dim * 2 + kinetics_dim + 1, hidden_dim),  # +1 for pct\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, graph_batch_a, kinetics, pct, graph_batch_b):\n",
    "        gnn_emb_a = self.gnn(graph_batch_a)\n",
    "        gnn_emb_b = self.gnn(graph_batch_b)\n",
    "        # Weighted combination based on percentage\n",
    "        pct_expanded = pct.unsqueeze(1)\n",
    "        combined = torch.cat([gnn_emb_a, gnn_emb_b, kinetics, pct_expanded], dim=1)\n",
    "        return self.mlp(combined)\n",
    "\n",
    "print('GNN models defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c888d9e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:10:49.744633Z",
     "iopub.status.busy": "2026-01-16T06:10:49.744537Z",
     "iopub.status.idle": "2026-01-16T06:10:49.752849Z",
     "shell.execute_reply": "2026-01-16T06:10:49.752500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNModelWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# GNN Wrapper class for training and prediction\n",
    "class GNNModelWrapper:\n",
    "    def __init__(self, data='single', n_models=3):\n",
    "        self.data_type = data\n",
    "        self.n_models = n_models\n",
    "        self.models = []\n",
    "        \n",
    "    def _get_kinetics(self, X):\n",
    "        \"\"\"Extract kinetics features.\"\"\"\n",
    "        time_m = X[\"Residence Time\"].values.reshape(-1, 1)\n",
    "        temp_c = X[\"Temperature\"].values.reshape(-1, 1)\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        return np.hstack([time_m, temp_c, inv_temp, log_time, interaction])\n",
    "    \n",
    "    def _get_graphs(self, solvent_names):\n",
    "        \"\"\"Get pre-computed graphs for solvents.\"\"\"\n",
    "        return [SOLVENT_GRAPHS[name].clone() for name in solvent_names]\n",
    "    \n",
    "    def train_model(self, X_train, Y_train, epochs=100):\n",
    "        Y_np = Y_train.values if hasattr(Y_train, 'values') else Y_train\n",
    "        kinetics = torch.tensor(self._get_kinetics(X_train), dtype=torch.float32).to(device)\n",
    "        targets = torch.tensor(Y_np, dtype=torch.float32).to(device)\n",
    "        \n",
    "        if self.data_type == 'single':\n",
    "            graphs = self._get_graphs(X_train[\"SOLVENT NAME\"].values)\n",
    "        else:\n",
    "            graphs_a = self._get_graphs(X_train[\"SOLVENT A NAME\"].values)\n",
    "            graphs_b = self._get_graphs(X_train[\"SOLVENT B NAME\"].values)\n",
    "            pct = torch.tensor(X_train[\"SolventB%\"].values, dtype=torch.float32).to(device)\n",
    "        \n",
    "        self.models = []\n",
    "        for seed in range(self.n_models):\n",
    "            torch.manual_seed(42 + seed)\n",
    "            \n",
    "            if self.data_type == 'single':\n",
    "                model = GNNModel().to(device)\n",
    "            else:\n",
    "                model = GNNModelMixed().to(device)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "            criterion = nn.HuberLoss()\n",
    "            \n",
    "            model.train()\n",
    "            batch_size = 32\n",
    "            n_samples = len(Y_np)\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                indices = torch.randperm(n_samples)\n",
    "                for start in range(0, n_samples, batch_size):\n",
    "                    end = min(start + batch_size, n_samples)\n",
    "                    batch_idx = indices[start:end]\n",
    "                    \n",
    "                    batch_kinetics = kinetics[batch_idx]\n",
    "                    batch_y = targets[batch_idx]\n",
    "                    \n",
    "                    if self.data_type == 'single':\n",
    "                        batch_graphs = [graphs[i] for i in batch_idx]\n",
    "                        batch_graph = Batch.from_data_list(batch_graphs).to(device)\n",
    "                        pred = model(batch_graph, batch_kinetics)\n",
    "                    else:\n",
    "                        batch_graphs_a = [graphs_a[i] for i in batch_idx]\n",
    "                        batch_graphs_b = [graphs_b[i] for i in batch_idx]\n",
    "                        batch_graph_a = Batch.from_data_list(batch_graphs_a).to(device)\n",
    "                        batch_graph_b = Batch.from_data_list(batch_graphs_b).to(device)\n",
    "                        batch_pct = pct[batch_idx]\n",
    "                        pred = model(batch_graph_a, batch_kinetics, batch_pct, batch_graph_b)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    loss = criterion(pred, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            self.models.append(model)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        kinetics = torch.tensor(self._get_kinetics(X_test), dtype=torch.float32).to(device)\n",
    "        \n",
    "        if self.data_type == 'single':\n",
    "            graphs = self._get_graphs(X_test[\"SOLVENT NAME\"].values)\n",
    "            graph_batch = Batch.from_data_list(graphs).to(device)\n",
    "        else:\n",
    "            graphs_a = self._get_graphs(X_test[\"SOLVENT A NAME\"].values)\n",
    "            graphs_b = self._get_graphs(X_test[\"SOLVENT B NAME\"].values)\n",
    "            graph_batch_a = Batch.from_data_list(graphs_a).to(device)\n",
    "            graph_batch_b = Batch.from_data_list(graphs_b).to(device)\n",
    "            pct = torch.tensor(X_test[\"SolventB%\"].values, dtype=torch.float32).to(device)\n",
    "        \n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for model in self.models:\n",
    "                if self.data_type == 'single':\n",
    "                    pred = model(graph_batch, kinetics)\n",
    "                else:\n",
    "                    pred = model(graph_batch_a, kinetics, pct, graph_batch_b)\n",
    "                preds.append(pred.cpu())\n",
    "        \n",
    "        return torch.clamp(torch.stack(preds).mean(dim=0), 0, 1).double()\n",
    "\n",
    "print('GNNModelWrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d4f312c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:10:58.925037Z",
     "iopub.status.busy": "2026-01-16T06:10:58.924514Z",
     "iopub.status.idle": "2026-01-16T06:11:02.516821Z",
     "shell.execute_reply": "2026-01-16T06:11:02.516460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test solvent: 1,1,1,3,3,3-Hexafluoropropan-2-ol\n",
      "Training samples: 619, Test samples: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fold MSE: 0.057851\n"
     ]
    }
   ],
   "source": [
    "# Quick test on single fold\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "test_solvent = sorted(X_single[\"SOLVENT NAME\"].unique())[0]\n",
    "mask = X_single[\"SOLVENT NAME\"] != test_solvent\n",
    "\n",
    "print(f\"Test solvent: {test_solvent}\")\n",
    "print(f\"Training samples: {mask.sum()}, Test samples: {(~mask).sum()}\")\n",
    "\n",
    "model = GNNModelWrapper(data='single', n_models=1)\n",
    "model.train_model(X_single[mask], Y_single[mask], epochs=50)\n",
    "preds = model.predict(X_single[~mask])\n",
    "\n",
    "actuals = Y_single[~mask].values\n",
    "mse = np.mean((actuals - preds.numpy()) ** 2)\n",
    "print(f'Test fold MSE: {mse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b3c665e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:11:27.870109Z",
     "iopub.status.busy": "2026-01-16T06:11:27.869600Z",
     "iopub.status.idle": "2026-01-16T06:14:02.557875Z",
     "shell.execute_reply": "2026-01-16T06:14:02.557467Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:06,  6.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:12,  6.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:19,  6.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:25,  6.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:31,  6.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:38,  6.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:44,  6.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:50,  6.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:57,  6.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [01:03,  6.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [01:10,  6.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [01:16,  6.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [01:23,  6.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [01:29,  6.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [01:36,  6.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [01:42,  6.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [01:49,  6.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [01:55,  6.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [02:02,  6.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [02:08,  6.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [02:15,  6.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [02:21,  6.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [02:28,  6.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [02:34,  6.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [02:34,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Solvent MSE: 0.015595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNModelWrapper(data='single', n_models=2)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y, epochs=50)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "# Calculate single solvent MSE\n",
    "actuals_single = []\n",
    "for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "    mask = X[\"SOLVENT NAME\"] == solvent\n",
    "    actuals_single.append(Y[mask].values)\n",
    "actuals_single = np.vstack(actuals_single)\n",
    "preds_single = submission_single_solvent[['target_1', 'target_2', 'target_3']].values\n",
    "mse_single = np.mean((actuals_single - preds_single) ** 2)\n",
    "print(f'\\nSingle Solvent MSE: {mse_single:.6f}')\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9291c150",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:14:31.289756Z",
     "iopub.status.busy": "2026-01-16T06:14:31.289231Z",
     "iopub.status.idle": "2026-01-16T06:18:36.035648Z",
     "shell.execute_reply": "2026-01-16T06:18:36.035265Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:18, 18.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:36, 18.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:55, 18.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:13, 18.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:31, 18.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [01:50, 18.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:08, 18.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [02:26, 18.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [02:45, 18.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [03:05, 18.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [03:25, 19.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [03:44, 19.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [04:04, 19.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [04:04, 18.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Data MSE: 0.031024\n",
      "\n",
      "Overall MSE: 0.025649\n",
      "Baseline (exp_030): CV 0.008298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNModelWrapper(data='full', n_models=2)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y, epochs=50)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "# Calculate full data MSE\n",
    "actuals_full = []\n",
    "ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "for _, row in ramps.iterrows():\n",
    "    mask = (X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"])\n",
    "    actuals_full.append(Y[mask].values)\n",
    "actuals_full = np.vstack(actuals_full)\n",
    "preds_full = submission_full_data[['target_1', 'target_2', 'target_3']].values\n",
    "mse_full = np.mean((actuals_full - preds_full) ** 2)\n",
    "print(f'\\nFull Data MSE: {mse_full:.6f}')\n",
    "\n",
    "# Calculate overall MSE\n",
    "n_single = len(actuals_single)\n",
    "n_full = len(actuals_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "print(f'\\nOverall MSE: {overall_mse:.6f}')\n",
    "print(f'Baseline (exp_030): CV 0.008298')\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
