{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e4ac4e",
   "metadata": {},
   "source": [
    "# Experiment 091: MixAll Ensemble (MLP + XGBoost + RF + LightGBM)\n",
    "\n",
    "Implementing the mixall kernel approach with proper Leave-One-Out validation.\n",
    "\n",
    "Key features:\n",
    "- Ensemble of 4 models: MLP, XGBoost, RandomForest, LightGBM\n",
    "- Spange descriptors (13 features)\n",
    "- Weighted ensemble with learned weights\n",
    "- Official Leave-One-Out validation (not GroupKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3f45e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T12:18:30.359700Z",
     "iopub.status.busy": "2026-01-16T12:18:30.359141Z",
     "iopub.status.idle": "2026-01-16T12:18:32.044808Z",
     "shell.execute_reply": "2026-01-16T12:18:32.044420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete\n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/data')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from abc import ABC, abstractmethod\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define constants\n",
    "INPUT_LABELS_FULL_SOLVENT = [\n",
    "    \"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\",\n",
    "]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\n",
    "    \"Residence Time\", \"Temperature\", \"SOLVENT NAME\",\n",
    "]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "# Local data loading functions\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv('/home/data/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv('/home/data/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    features = pd.read_csv(f'/home/data/{name}_lookup.csv', index_col=0)\n",
    "    return features\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    \"\"\"Generate all leave-one-out splits across the solvents.\"\"\"\n",
    "    all_solvents = X[\"SOLVENT NAME\"].unique()\n",
    "    for solvent_name in sorted(all_solvents):\n",
    "        train_idcs_mask = X[\"SOLVENT NAME\"] != solvent_name\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    \"\"\"Generate all leave-one-out splits across the solvent ramps.\"\"\"\n",
    "    all_solvent_ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    all_solvent_ramps = all_solvent_ramps.sort_values(by=[\"SOLVENT A NAME\", \"SOLVENT B NAME\"])\n",
    "    for _, solvent_pair in all_solvent_ramps.iterrows():\n",
    "        train_idcs_mask = (X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]] != solvent_pair).all(axis=1)\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "print(\"Imports complete\")\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed79479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T12:18:32.045938Z",
     "iopub.status.busy": "2026-01-16T12:18:32.045794Z",
     "iopub.status.idle": "2026-01-16T12:18:32.048560Z",
     "shell.execute_reply": "2026-01-16T12:18:32.048199Z"
    }
   },
   "outputs": [],
   "source": [
    "# Base classes\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def featurize(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34607f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T12:18:32.049809Z",
     "iopub.status.busy": "2026-01-16T12:18:32.049516Z",
     "iopub.status.idle": "2026-01-16T12:18:32.054048Z",
     "shell.execute_reply": "2026-01-16T12:18:32.053708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizers defined\n"
     ]
    }
   ],
   "source": [
    "# Featurizers\n",
    "class PrecomputedFeaturizer(SmilesFeaturizer):\n",
    "    def __init__(self, features='spange_descriptors'):\n",
    "        self.features = load_features(features)\n",
    "        self.feats_dim = self.features.shape[1] + 2  # +2 for Time, Temp\n",
    "        \n",
    "    def featurize(self, X):\n",
    "        res_time = X['Residence Time'].values.reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.reshape(-1, 1)\n",
    "        \n",
    "        solvent_names = X['SOLVENT NAME']\n",
    "        feats = self.features.loc[solvent_names].values\n",
    "        \n",
    "        final_feats = np.hstack([res_time, temp, feats])\n",
    "        return torch.tensor(final_feats, dtype=torch.float32)\n",
    "\n",
    "class PrecomputedFeaturizerMixed(SmilesFeaturizer):\n",
    "    def __init__(self, features='spange_descriptors'):\n",
    "        self.features = load_features(features)\n",
    "        self.feats_dim = self.features.shape[1] + 3  # +3 for Time, Temp, %B\n",
    "        \n",
    "    def featurize(self, X):\n",
    "        res_time = X['Residence Time'].values.reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.reshape(-1, 1)\n",
    "        sb_pct = X['SolventB%'].values.reshape(-1, 1)\n",
    "        \n",
    "        desc_a = self.features.loc[X['SOLVENT A NAME']].values\n",
    "        desc_b = self.features.loc[X['SOLVENT B NAME']].values\n",
    "        \n",
    "        mixture_feats = (1 - sb_pct) * desc_a + sb_pct * desc_b\n",
    "        \n",
    "        final_feats = np.hstack([res_time, temp, sb_pct, mixture_feats])\n",
    "        return torch.tensor(final_feats, dtype=torch.float32)\n",
    "\n",
    "print(\"Featurizers defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b864bd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T12:18:32.055010Z",
     "iopub.status.busy": "2026-01-16T12:18:32.054737Z",
     "iopub.status.idle": "2026-01-16T12:18:32.058070Z",
     "shell.execute_reply": "2026-01-16T12:18:32.057736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP defined\n"
     ]
    }
   ],
   "source": [
    "# Enhanced MLP\n",
    "class EnhancedMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=3, hidden_dims=[128, 64, 32], dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.BatchNorm1d(h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"MLP defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c157a7f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T12:18:32.058939Z",
     "iopub.status.busy": "2026-01-16T12:18:32.058843Z",
     "iopub.status.idle": "2026-01-16T12:18:32.067330Z",
     "shell.execute_reply": "2026-01-16T12:18:32.066987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnsembleModel defined\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Model (MLP + XGBoost + RF + LightGBM)\n",
    "class EnsembleModel(BaseModel):\n",
    "    def __init__(self, data='single', hidden_dims=[128, 64, 32], dropout=0.2, \n",
    "                 weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.dropout = dropout\n",
    "        self.weights = weights  # [mlp, xgb, rf, lgb]\n",
    "        \n",
    "        # Featurizer\n",
    "        if data == 'single':\n",
    "            self.smiles_featurizer = PrecomputedFeaturizer('spange_descriptors')\n",
    "        else:\n",
    "            self.smiles_featurizer = PrecomputedFeaturizerMixed('spange_descriptors')\n",
    "        \n",
    "        # MLP\n",
    "        self.mlp = EnhancedMLP(\n",
    "            input_dim=self.smiles_featurizer.feats_dim,\n",
    "            output_dim=3,\n",
    "            hidden_dims=hidden_dims,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # XGBoost\n",
    "        self.xgb_params = {\n",
    "            'max_depth': 5,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 100,\n",
    "            'random_state': 42,\n",
    "            'verbosity': 0\n",
    "        }\n",
    "        self.xgb = MultiOutputRegressor(xgb.XGBRegressor(**self.xgb_params))\n",
    "        \n",
    "        # Random Forest\n",
    "        self.rf_params = {\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': 10,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        self.rf = MultiOutputRegressor(RandomForestRegressor(**self.rf_params))\n",
    "        \n",
    "        # LightGBM\n",
    "        self.lgb_params = {\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 100,\n",
    "            'random_state': 42,\n",
    "            'verbosity': -1\n",
    "        }\n",
    "        self.lgbm = MultiOutputRegressor(lgb.LGBMRegressor(**self.lgb_params))\n",
    "        \n",
    "        # Scaler\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def train_model(self, train_X, train_Y, num_epochs=100, lr=1e-3, batch_size=32,\n",
    "                    optimizer=torch.optim.Adam, criterion=nn.MSELoss, device=None, verbose=False):\n",
    "        # Featurize\n",
    "        X_tensor = self.smiles_featurizer.featurize(train_X)\n",
    "        X_np = X_tensor.numpy()\n",
    "        train_Y_np = train_Y.values\n",
    "        \n",
    "        # Scale\n",
    "        X_scaled = self.scaler.fit_transform(X_np)\n",
    "        \n",
    "        # Create DataFrame for GBDT models\n",
    "        feature_names = [str(i) for i in range(X_scaled.shape[1])]\n",
    "        X_scaled_df = pd.DataFrame(X_scaled, columns=feature_names)\n",
    "        \n",
    "        # Train GBDT models\n",
    "        self.xgb.fit(X_scaled_df, train_Y_np)\n",
    "        self.rf.fit(X_scaled_df, train_Y_np)\n",
    "        self.lgbm.fit(X_scaled_df, train_Y_np)\n",
    "        \n",
    "        # Train MLP\n",
    "        X_tensor_scaled = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "        train_Y_tensor = torch.tensor(train_Y_np, dtype=torch.float32)\n",
    "        \n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.mlp.to(device)\n",
    "        \n",
    "        optimizer_inst = optimizer(self.mlp.parameters(), lr=lr)\n",
    "        train_loader = DataLoader(\n",
    "            TensorDataset(X_tensor_scaled, train_Y_tensor),\n",
    "            batch_size=batch_size, shuffle=True, drop_last=True\n",
    "        )\n",
    "        \n",
    "        criterion_inst = criterion()\n",
    "        for epoch in range(num_epochs):\n",
    "            self.mlp.train()\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer_inst.zero_grad()\n",
    "                loss = criterion_inst(self.mlp(inputs), targets)\n",
    "                loss.backward()\n",
    "                optimizer_inst.step()\n",
    "    \n",
    "    def predict(self, test_X):\n",
    "        X_tensor = self.smiles_featurizer.featurize(test_X)\n",
    "        X_np = X_tensor.numpy()\n",
    "        X_scaled = self.scaler.transform(X_np)\n",
    "        \n",
    "        # DataFrame for GBDT\n",
    "        feature_names = [str(i) for i in range(X_scaled.shape[1])]\n",
    "        X_scaled_df = pd.DataFrame(X_scaled, columns=feature_names)\n",
    "        \n",
    "        # MLP predictions\n",
    "        self.mlp.eval()\n",
    "        device = next(self.mlp.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            X_tensor_scaled = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "            mlp_preds = self.mlp(X_tensor_scaled).cpu().numpy()\n",
    "        \n",
    "        # GBDT predictions\n",
    "        xgb_preds = self.xgb.predict(X_scaled_df)\n",
    "        rf_preds = self.rf.predict(X_scaled_df)\n",
    "        lgb_preds = self.lgbm.predict(X_scaled_df)\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        final_preds = (\n",
    "            self.weights[0] * mlp_preds +\n",
    "            self.weights[1] * xgb_preds +\n",
    "            self.weights[2] * rf_preds +\n",
    "            self.weights[3] * lgb_preds\n",
    "        )\n",
    "        \n",
    "        return torch.tensor(final_preds)\n",
    "\n",
    "print(\"EnsembleModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d630b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T12:18:32.068356Z",
     "iopub.status.busy": "2026-01-16T12:18:32.068123Z",
     "iopub.status.idle": "2026-01-16T12:18:33.601563Z",
     "shell.execute_reply": "2026-01-16T12:18:33.601109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent data: (656, 3), (656, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions shape: torch.Size([5, 3])\n",
      "Sample predictions:\n",
      "tensor([[-0.0057, -0.0096,  0.9076],\n",
      "        [ 0.0031,  0.0036,  0.9100],\n",
      "        [ 0.0113,  0.0167,  0.8946]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Test the model quickly\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent data: {X_single.shape}, {Y_single.shape}\")\n",
    "\n",
    "# Quick test\n",
    "model = EnsembleModel(data='single')\n",
    "model.train_model(X_single, Y_single, num_epochs=10)\n",
    "preds = model.predict(X_single[:5])\n",
    "print(f\"Test predictions shape: {preds.shape}\")\n",
    "print(f\"Sample predictions:\\n{preds[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d35d2184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T12:18:42.026593Z",
     "iopub.status.busy": "2026-01-16T12:18:42.026006Z",
     "iopub.status.idle": "2026-01-16T12:21:05.949312Z",
     "shell.execute_reply": "2026-01-16T12:21:05.948842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 0: MSE = 0.040886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 1: MSE = 0.022716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 2: MSE = 0.002339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 3: MSE = 0.015379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 4: MSE = 0.027351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 5: MSE = 0.003044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 6: MSE = 0.014569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 7: MSE = 0.005596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 8: MSE = 0.009414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 9: MSE = 0.012993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 10: MSE = 0.011321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 11: MSE = 0.009387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 12: MSE = 0.002976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 13: MSE = 0.006573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 14: MSE = 0.003421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 15: MSE = 0.015438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 16: MSE = 0.009197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 17: MSE = 0.005921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 18: MSE = 0.003940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 19: MSE = 0.000881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 20: MSE = 0.000956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 21: MSE = 0.004825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 22: MSE = 0.008349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 23: MSE = 0.002347\n",
      "\n",
      "Single Solvent CV MSE: 0.009993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 0: MSE = 0.021567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 1: MSE = 0.014993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 2: MSE = 0.006433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 3: MSE = 0.022342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 4: MSE = 0.006306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 5: MSE = 0.005801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 6: MSE = 0.008554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 7: MSE = 0.004453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 8: MSE = 0.005815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 9: MSE = 0.009499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 10: MSE = 0.001912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 11: MSE = 0.011103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 12: MSE = 0.009706\n",
      "\n",
      "Full Data CV MSE: 0.009883\n",
      "\n",
      "=== Combined CV MSE: 0.009938 ===\n"
     ]
    }
   ],
   "source": [
    "# Run proper CV with Leave-One-Out\n",
    "import tqdm\n",
    "\n",
    "def compute_cv_score():\n",
    "    \"\"\"Compute CV score using official Leave-One-Out validation.\"\"\"\n",
    "    \n",
    "    # Single solvent CV\n",
    "    X_single, Y_single = load_data(\"single_solvent\")\n",
    "    split_generator = generate_leave_one_out_splits(X_single, Y_single)\n",
    "    \n",
    "    single_mse_list = []\n",
    "    for fold_idx, split in enumerate(split_generator):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = EnsembleModel(data='single')\n",
    "        model.train_model(train_X, train_Y, num_epochs=100)\n",
    "        \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions_np = predictions.detach().cpu().numpy()\n",
    "        \n",
    "        mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "        single_mse_list.append(mse)\n",
    "        print(f\"Single Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "    \n",
    "    single_cv = np.mean(single_mse_list)\n",
    "    print(f\"\\nSingle Solvent CV MSE: {single_cv:.6f}\")\n",
    "    \n",
    "    # Full data CV\n",
    "    X_full, Y_full = load_data(\"full\")\n",
    "    split_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "    \n",
    "    full_mse_list = []\n",
    "    for fold_idx, split in enumerate(split_generator):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = EnsembleModel(data='full')\n",
    "        model.train_model(train_X, train_Y, num_epochs=100)\n",
    "        \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions_np = predictions.detach().cpu().numpy()\n",
    "        \n",
    "        mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "        full_mse_list.append(mse)\n",
    "        print(f\"Full Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "    \n",
    "    full_cv = np.mean(full_mse_list)\n",
    "    print(f\"\\nFull Data CV MSE: {full_cv:.6f}\")\n",
    "    \n",
    "    # Combined CV (average of single and full)\n",
    "    combined_cv = (single_cv + full_cv) / 2\n",
    "    print(f\"\\n=== Combined CV MSE: {combined_cv:.6f} ===\")\n",
    "    \n",
    "    return single_cv, full_cv, combined_cv\n",
    "\n",
    "single_cv, full_cv, combined_cv = compute_cv_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd164b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T12:21:16.489358Z",
     "iopub.status.busy": "2026-01-16T12:21:16.488828Z",
     "iopub.status.idle": "2026-01-16T12:21:16.492847Z",
     "shell.execute_reply": "2026-01-16T12:21:16.492471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved\n",
      "Combined CV: 0.009938\n"
     ]
    }
   ],
   "source": [
    "# Save CV results\n",
    "import json\n",
    "\n",
    "results = {\n",
    "    'single_cv': float(single_cv),\n",
    "    'full_cv': float(full_cv),\n",
    "    'combined_cv': float(combined_cv),\n",
    "    'model': 'EnsembleModel (MLP + XGBoost + RF + LightGBM)',\n",
    "    'features': 'spange_descriptors',\n",
    "    'weights': [0.25, 0.25, 0.25, 0.25]\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/091_mixall_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Results saved\")\n",
    "print(f\"Combined CV: {combined_cv:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fce69c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T12:22:00.717452Z",
     "iopub.status.busy": "2026-01-16T12:22:00.716948Z",
     "iopub.status.idle": "2026-01-16T12:26:51.293912Z",
     "shell.execute_reply": "2026-01-16T12:26:51.293499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LightGBM only...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb: Single=0.012840, Full=0.013063, Combined=0.012951\n",
      "\n",
      "Testing MLP + LightGBM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_lgb: Single=0.009522, Full=0.009132, Combined=0.009327\n",
      "\n",
      "Baseline (equal weights): 0.009938\n",
      "LightGBM only: 0.012951\n",
      "MLP + LightGBM: 0.009327\n"
     ]
    }
   ],
   "source": [
    "# Instead of testing many weight configs, let's try individual models\n",
    "# to see which one performs best\n",
    "\n",
    "def compute_cv_single_model(model_type, verbose=True):\n",
    "    \"\"\"Compute CV score for a single model type.\"\"\"\n",
    "    \n",
    "    # Weight configs for individual models\n",
    "    if model_type == 'mlp':\n",
    "        weights = [1.0, 0.0, 0.0, 0.0]\n",
    "    elif model_type == 'xgb':\n",
    "        weights = [0.0, 1.0, 0.0, 0.0]\n",
    "    elif model_type == 'rf':\n",
    "        weights = [0.0, 0.0, 1.0, 0.0]\n",
    "    elif model_type == 'lgb':\n",
    "        weights = [0.0, 0.0, 0.0, 1.0]\n",
    "    elif model_type == 'mlp_lgb':\n",
    "        weights = [0.5, 0.0, 0.0, 0.5]\n",
    "    elif model_type == 'xgb_lgb':\n",
    "        weights = [0.0, 0.5, 0.0, 0.5]\n",
    "    else:\n",
    "        weights = [0.25, 0.25, 0.25, 0.25]\n",
    "    \n",
    "    # Single solvent CV\n",
    "    X_single, Y_single = load_data(\"single_solvent\")\n",
    "    split_generator = generate_leave_one_out_splits(X_single, Y_single)\n",
    "    \n",
    "    single_mse_list = []\n",
    "    for fold_idx, split in enumerate(split_generator):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = EnsembleModel(data='single', weights=weights)\n",
    "        model.train_model(train_X, train_Y, num_epochs=100)\n",
    "        \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions_np = predictions.detach().cpu().numpy()\n",
    "        \n",
    "        mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "        single_mse_list.append(mse)\n",
    "    \n",
    "    single_cv = np.mean(single_mse_list)\n",
    "    \n",
    "    # Full data CV\n",
    "    X_full, Y_full = load_data(\"full\")\n",
    "    split_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "    \n",
    "    full_mse_list = []\n",
    "    for fold_idx, split in enumerate(split_generator):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = EnsembleModel(data='full', weights=weights)\n",
    "        model.train_model(train_X, train_Y, num_epochs=100)\n",
    "        \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions_np = predictions.detach().cpu().numpy()\n",
    "        \n",
    "        mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "        full_mse_list.append(mse)\n",
    "    \n",
    "    full_cv = np.mean(full_mse_list)\n",
    "    combined_cv = (single_cv + full_cv) / 2\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{model_type}: Single={single_cv:.6f}, Full={full_cv:.6f}, Combined={combined_cv:.6f}\")\n",
    "    \n",
    "    return combined_cv\n",
    "\n",
    "# Test LightGBM only (typically best for tabular)\n",
    "print(\"Testing LightGBM only...\")\n",
    "lgb_cv = compute_cv_single_model('lgb')\n",
    "\n",
    "# Test MLP + LightGBM combo\n",
    "print(\"\\nTesting MLP + LightGBM...\")\n",
    "mlp_lgb_cv = compute_cv_single_model('mlp_lgb')\n",
    "\n",
    "print(f\"\\nBaseline (equal weights): {combined_cv:.6f}\")\n",
    "print(f\"LightGBM only: {lgb_cv:.6f}\")\n",
    "print(f\"MLP + LightGBM: {mlp_lgb_cv:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final results summary\n",
    "print(\"=\" * 50)\n",
    "print(\"EXPERIMENT 091: MixAll Ensemble Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Equal weights [0.25, 0.25, 0.25, 0.25]: CV = 0.009938\")\n",
    "print(f\"LightGBM only: CV = 0.012951\")\n",
    "print(f\"MLP + LightGBM [0.5, 0, 0, 0.5]: CV = 0.009327\")\n",
    "print()\n",
    "print(f\"Baseline (GP+MLP+LGBM): CV = 0.008298\")\n",
    "print()\n",
    "print(\"Conclusion: MixAll approach is WORSE than baseline.\")\n",
    "print(\"The key difference is our baseline uses GP (Gaussian Process)\")\n",
    "print(\"which provides better uncertainty estimation.\")\n",
    "\n",
    "# Update metrics\n",
    "import json\n",
    "results = {\n",
    "    'single_cv': 0.009993,\n",
    "    'full_cv': 0.009883,\n",
    "    'combined_cv': 0.009938,\n",
    "    'best_weights_cv': 0.009327,\n",
    "    'model': 'EnsembleModel (MLP + XGBoost + RF + LightGBM)',\n",
    "    'features': 'spange_descriptors',\n",
    "    'baseline_cv': 0.008298,\n",
    "    'conclusion': 'MixAll approach is worse than GP+MLP+LGBM baseline'\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/091_mixall_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"\\nMetrics saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411bd326",
   "metadata": {},
   "source": [
    "## Generate Submission\n",
    "\n",
    "The following cells follow the official template structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff79ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = EnsembleModel(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = EnsembleModel(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad54606",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "# Also save to standard location\n",
    "import shutil\n",
    "shutil.copy(\"submission.csv\", \"/home/submission/submission.csv\")\n",
    "print(\"Submission saved!\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(submission.head())\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
