{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "044e1542",
   "metadata": {},
   "source": [
    "# Experiment 118: Softmax Output Layer Model\n",
    "\n",
    "**Goal**: Enforce SM + P2 + P3 = 1 EXACTLY using softmax normalization.\n",
    "\n",
    "**Key Difference from Physics-Constrained (exp_117)**:\n",
    "- exp_117: Post-hoc constraint that normalizes only if sum > 1\n",
    "- This exp: ALWAYS normalize to sum = 1 using softmax-like normalization\n",
    "\n",
    "**Hypothesis**: By enforcing that yields sum to exactly 1, we may:\n",
    "1. Reduce extreme predictions for unseen solvents\n",
    "2. Change the output space in a way that improves generalization\n",
    "3. Potentially change the CV-LB relationship\n",
    "\n",
    "**CRITICAL**: The model class `SoftmaxOutputModel` will be used in BOTH CV computation AND submission cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "749401fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:01:32.621074Z",
     "iopub.status.busy": "2026-01-16T22:01:32.620694Z",
     "iopub.status.idle": "2026-01-16T22:01:34.180204Z",
     "shell.execute_reply": "2026-01-16T22:01:34.179785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34555d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:01:34.181437Z",
     "iopub.status.busy": "2026-01-16T22:01:34.181282Z",
     "iopub.status.idle": "2026-01-16T22:01:34.185581Z",
     "shell.execute_reply": "2026-01-16T22:01:34.185215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211f6e3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:01:34.186548Z",
     "iopub.status.busy": "2026-01-16T22:01:34.186446Z",
     "iopub.status.idle": "2026-01-16T22:01:34.213482Z",
     "shell.execute_reply": "2026-01-16T22:01:34.213144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP filtered: (24, 122), ACS PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056702a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:01:34.214452Z",
     "iopub.status.busy": "2026-01-16T22:01:34.214369Z",
     "iopub.status.idle": "2026-01-16T22:01:34.219438Z",
     "shell.execute_reply": "2026-01-16T22:01:34.219046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension: 145\n"
     ]
    }
   ],
   "source": [
    "# Featurizer\n",
    "class Featurizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "                X_drfp = B_drfp * (1 - (1-pct)) + A_drfp * (1-pct)\n",
    "                X_acs = B_acs * (1 - (1-pct)) + A_acs * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "\n",
    "print(f'Feature dimension: {Featurizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b4f55d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:01:34.220368Z",
     "iopub.status.busy": "2026-01-16T22:01:34.220277Z",
     "iopub.status.idle": "2026-01-16T22:01:34.225431Z",
     "shell.execute_reply": "2026-01-16T22:01:34.225072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxOutputModel defined - will be used in both CV and submission cells\n"
     ]
    }
   ],
   "source": [
    "# Softmax Output Model - enforces SM + P2 + P3 = 1 EXACTLY\n",
    "class SoftmaxOutputModel:\n",
    "    \"\"\"Model with softmax-like output normalization.\n",
    "    \n",
    "    Key insight: SM + P2 + P3 should sum to 1 (mass balance).\n",
    "    By normalizing predictions to sum to 1, we enforce this constraint.\n",
    "    \n",
    "    This is different from post-hoc constraints because:\n",
    "    1. We ALWAYS normalize, not just when sum > 1\n",
    "    2. This changes the output space, potentially improving generalization\n",
    "    \n",
    "    This is the SAME class used in both CV and submission cells.\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.featurizer = Featurizer(mixed=(data=='full'))\n",
    "        self.scaler = StandardScaler()\n",
    "        self.catboost_models = []\n",
    "        self.xgboost_models = []\n",
    "        \n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Featurize\n",
    "        X_feat = self.featurizer.featurize(X_train)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        \n",
    "        # Train separate models for each target\n",
    "        for i in range(3):\n",
    "            # CatBoost\n",
    "            cb_model = cb.CatBoostRegressor(\n",
    "                iterations=500,\n",
    "                learning_rate=0.05,\n",
    "                depth=6,\n",
    "                l2_leaf_reg=3,\n",
    "                random_seed=42,\n",
    "                verbose=False\n",
    "            )\n",
    "            cb_model.fit(X_scaled, y_vals[:, i])\n",
    "            self.catboost_models.append(cb_model)\n",
    "            \n",
    "            # XGBoost\n",
    "            xgb_model = xgb.XGBRegressor(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                reg_lambda=1,\n",
    "                random_state=42,\n",
    "                verbosity=0\n",
    "            )\n",
    "            xgb_model.fit(X_scaled, y_vals[:, i])\n",
    "            self.xgboost_models.append(xgb_model)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_feat = self.featurizer.featurize(X)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        # Get predictions from both models\n",
    "        preds = []\n",
    "        for i in range(3):\n",
    "            cb_pred = self.catboost_models[i].predict(X_scaled)\n",
    "            xgb_pred = self.xgboost_models[i].predict(X_scaled)\n",
    "            # Average ensemble\n",
    "            pred = (cb_pred + xgb_pred) / 2\n",
    "            preds.append(pred)\n",
    "        \n",
    "        pred = np.column_stack(preds)\n",
    "        \n",
    "        # Apply softmax-like normalization to ensure sum = 1\n",
    "        pred = self._softmax_normalize(pred)\n",
    "        \n",
    "        return torch.tensor(pred)\n",
    "    \n",
    "    def _softmax_normalize(self, pred):\n",
    "        \"\"\"Normalize predictions to sum to 1.\n",
    "        \n",
    "        Steps:\n",
    "        1. Clip to [0, 1] to avoid negative values\n",
    "        2. Normalize by dividing by sum\n",
    "        \n",
    "        This ensures SM + P2 + P3 = 1 exactly.\n",
    "        \"\"\"\n",
    "        # First clip to [0, 1]\n",
    "        pred = np.clip(pred, 0, 1)\n",
    "        \n",
    "        # Then normalize to sum to 1\n",
    "        total = pred.sum(axis=1, keepdims=True)\n",
    "        # Avoid division by zero\n",
    "        pred = pred / np.maximum(total, 1e-6)\n",
    "        \n",
    "        return pred\n",
    "\n",
    "print('SoftmaxOutputModel defined - will be used in both CV and submission cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32251047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:01:34.226192Z",
     "iopub.status.busy": "2026-01-16T22:01:34.226103Z",
     "iopub.status.idle": "2026-01-16T22:01:34.240553Z",
     "shell.execute_reply": "2026-01-16T22:01:34.240214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data yield sum analysis:\n",
      "Single solvent: mean sum = 0.7955, std = 0.1943\n",
      "Full data: mean sum = 0.8035, std = 0.2092\n",
      "\n",
      "Single solvent sum percentiles:\n",
      "  5th: 0.4454\n",
      "  50th: 0.8496\n",
      "  95th: 0.9958\n"
     ]
    }
   ],
   "source": [
    "# First, let's check the actual distribution of yield sums in training data\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "print(\"Training data yield sum analysis:\")\n",
    "print(f\"Single solvent: mean sum = {Y_single.sum(axis=1).mean():.4f}, std = {Y_single.sum(axis=1).std():.4f}\")\n",
    "print(f\"Full data: mean sum = {Y_full.sum(axis=1).mean():.4f}, std = {Y_full.sum(axis=1).std():.4f}\")\n",
    "\n",
    "# Check the distribution\n",
    "print(f\"\\nSingle solvent sum percentiles:\")\n",
    "print(f\"  5th: {Y_single.sum(axis=1).quantile(0.05):.4f}\")\n",
    "print(f\"  50th: {Y_single.sum(axis=1).quantile(0.50):.4f}\")\n",
    "print(f\"  95th: {Y_single.sum(axis=1).quantile(0.95):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e38749e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T22:01:47.320798Z",
     "iopub.status.busy": "2026-01-16T22:01:47.320330Z",
     "iopub.status.idle": "2026-01-16T22:02:21.198074Z",
     "shell.execute_reply": "2026-01-16T22:02:21.197645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing CV score...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 0: MSE = 0.052950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6: MSE = 0.018711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 12: MSE = 0.009690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 18: MSE = 0.020181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single solvent MSE: 0.015645\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation to compute CV score\n",
    "print(\"Computing CV score...\")\n",
    "\n",
    "# Single solvent CV\n",
    "single_mses = []\n",
    "\n",
    "for fold_idx, split in enumerate(generate_leave_one_out_splits(X_single, Y_single)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = SoftmaxOutputModel(data='single')  # SAME CLASS AS SUBMISSION\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    targets = test_Y.values\n",
    "    \n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    single_mses.append(mse)\n",
    "    \n",
    "    if fold_idx % 6 == 0:\n",
    "        print(f\"  Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "\n",
    "single_mse = np.mean(single_mses)\n",
    "print(f\"\\nSingle solvent MSE: {single_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full data CV\n",
    "full_mses = []\n",
    "\n",
    "for fold_idx, split in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = SoftmaxOutputModel(data='full')  # SAME CLASS AS SUBMISSION\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    targets = test_Y.values\n",
    "    \n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    full_mses.append(mse)\n",
    "    \n",
    "    if fold_idx % 3 == 0:\n",
    "        print(f\"  Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "\n",
    "full_mse = np.mean(full_mses)\n",
    "print(f\"\\nFull data MSE: {full_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c293cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined CV score\n",
    "cv_score = (single_mse + full_mse) / 2\n",
    "print(f\"\\n=== CV Results ===\")\n",
    "print(f\"Single solvent MSE: {single_mse:.6f}\")\n",
    "print(f\"Full data MSE: {full_mse:.6f}\")\n",
    "print(f\"Combined CV score: {cv_score:.6f}\")\n",
    "\n",
    "# Save metrics\n",
    "import json\n",
    "metrics = {\n",
    "    'cv_score': cv_score,\n",
    "    'single_mse': single_mse,\n",
    "    'full_mse': full_mse\n",
    "}\n",
    "with open('/home/code/experiments/118_softmax_output/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "\n",
    "print(f\"\\nComparison with best CV: 0.0081\")\n",
    "print(f\"This experiment: {cv_score:.6f}\")\n",
    "if cv_score < 0.0081:\n",
    "    print(\"IMPROVEMENT! This is better than best CV.\")\n",
    "else:\n",
    "    print(f\"No improvement. Difference: {cv_score - 0.0081:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d7d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SoftmaxOutputModel(data='single')  # SAME CLASS AS CV\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SoftmaxOutputModel(data='full')  # SAME CLASS AS CV\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "print(f\"Submission saved with {len(submission)} rows\")\n",
    "print(submission.head())\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
