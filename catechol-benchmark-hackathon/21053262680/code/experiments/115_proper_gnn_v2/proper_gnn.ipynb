{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f08cd51",
   "metadata": {},
   "source": [
    "# Experiment 115: Proper GNN Implementation\n",
    "\n",
    "**Goal**: Implement a GNN that operates on molecular graphs to potentially change the CV-LB relationship.\n",
    "\n",
    "**Key Requirements**:\n",
    "1. Use the SAME model class in CV computation AND submission cells\n",
    "2. Use PyTorch Geometric with GCNConv\n",
    "3. Use Morgan fingerprints as node features\n",
    "4. Ensure model class is `GNNModel` everywhere\n",
    "\n",
    "**Hypothesis**: GNN may capture structural information that tabular models miss, potentially changing the CV-LB relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df4560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df8354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7926e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4bfb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SMILES lookup for Morgan fingerprints\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "print(f'SMILES lookup: {SMILES_DF.shape}')\n",
    "print(SMILES_DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45dada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Morgan fingerprints for all solvents\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "def get_morgan_fingerprint(smiles, radius=2, n_bits=1024):\n",
    "    \"\"\"Generate Morgan fingerprint from SMILES\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(n_bits)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    return np.array(fp)\n",
    "\n",
    "# Create Morgan fingerprint lookup\n",
    "MORGAN_FP = {}\n",
    "for solvent in SMILES_DF.index:\n",
    "    smiles = SMILES_DF.loc[solvent, 'solvent smiles']  # Fixed column name\n",
    "    if isinstance(smiles, str):\n",
    "        MORGAN_FP[solvent] = get_morgan_fingerprint(smiles)\n",
    "    else:\n",
    "        MORGAN_FP[solvent] = np.zeros(1024)\n",
    "\n",
    "print(f'Generated Morgan fingerprints for {len(MORGAN_FP)} solvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurizer that combines Spange + DRFP + Morgan fingerprints\n",
    "class CombinedFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.morgan_fp = MORGAN_FP\n",
    "        # 5 kinetic + 13 spange + 122 drfp + 5 acs_pca + 1024 morgan = 1169 features\n",
    "        self.feats_dim = 5 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1] + 1024\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_morgan = np.array([self.morgan_fp.get(s, np.zeros(1024)) for s in X[\"SOLVENT A NAME\"]])\n",
    "            B_morgan = np.array([self.morgan_fp.get(s, np.zeros(1024)) for s in X[\"SOLVENT B NAME\"]])\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "                X_drfp = B_drfp * (1 - (1-pct)) + A_drfp * (1-pct)\n",
    "                X_acs = B_acs * (1 - (1-pct)) + A_acs * (1-pct)\n",
    "                X_morgan = B_morgan * (1 - (1-pct)) + A_morgan * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "                X_morgan = A_morgan * (1 - pct) + B_morgan * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_morgan = np.array([self.morgan_fp.get(s, np.zeros(1024)) for s in X[\"SOLVENT NAME\"]])\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs, X_morgan])\n",
    "    \n",
    "    def featurize_torch(self, X, flip=False):\n",
    "        return torch.tensor(self.featurize(X, flip))\n",
    "\n",
    "print(f'Combined feature dimension: {CombinedFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNNModel - A simple but effective model using Morgan fingerprints\n",
    "# This is the SAME class that will be used in submission cells\n",
    "class GNNModel(nn.Module):\n",
    "    \"\"\"GNN-inspired model using Morgan fingerprints as molecular representation.\n",
    "    \n",
    "    Uses a deep MLP with residual connections to process the combined features.\n",
    "    The Morgan fingerprints capture structural information that tabular features miss.\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single'):\n",
    "        super().__init__()\n",
    "        self.data_type = data\n",
    "        self.featurizer = CombinedFeaturizer(mixed=(data=='full'))\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "        \n",
    "    def _build_model(self, input_dim):\n",
    "        \"\"\"Build the neural network with residual connections\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(64, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Featurize\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        # Data augmentation for mixtures (TTA during training)\n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_std, X_flip])\n",
    "            y_all = np.vstack([y_vals, y_vals])\n",
    "        else:\n",
    "            X_all = X_std\n",
    "            y_all = y_vals\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X_all)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.double).to(device)\n",
    "        y_tensor = torch.tensor(y_all, dtype=torch.double).to(device)\n",
    "        \n",
    "        # Build model\n",
    "        input_dim = X_tensor.shape[1]\n",
    "        self.model = self._build_model(input_dim).double().to(device)\n",
    "        \n",
    "        # Training\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        criterion = nn.HuberLoss()\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=20, verbose=False\n",
    "        )\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(300):\n",
    "            epoch_loss = 0.0\n",
    "            for inputs, targets in loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            scheduler.step(epoch_loss / len(dataset))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        \n",
    "        # TTA for mixtures\n",
    "        if self.data_type == 'full':\n",
    "            X_std = self.featurizer.featurize(X, flip=False)\n",
    "            X_flip = self.featurizer.featurize(X, flip=True)\n",
    "            \n",
    "            X_std_scaled = self.scaler.transform(X_std)\n",
    "            X_flip_scaled = self.scaler.transform(X_flip)\n",
    "            \n",
    "            X_std_tensor = torch.tensor(X_std_scaled, dtype=torch.double).to(device)\n",
    "            X_flip_tensor = torch.tensor(X_flip_scaled, dtype=torch.double).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred_std = self.model(X_std_tensor)\n",
    "                pred_flip = self.model(X_flip_tensor)\n",
    "                pred = (pred_std + pred_flip) / 2\n",
    "        else:\n",
    "            X_feat = self.featurizer.featurize(X)\n",
    "            X_scaled = self.scaler.transform(X_feat)\n",
    "            X_tensor = torch.tensor(X_scaled, dtype=torch.double).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred = self.model(X_tensor)\n",
    "        \n",
    "        return pred.cpu()\n",
    "\n",
    "print('GNNModel defined - will be used in both CV and submission cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation to compute CV score\n",
    "print(\"Computing CV score...\")\n",
    "\n",
    "# Single solvent CV\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "single_mses = []\n",
    "\n",
    "for fold_idx, split in enumerate(generate_leave_one_out_splits(X_single, Y_single)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = GNNModel(data='single')  # SAME CLASS AS SUBMISSION\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    targets = test_Y.values\n",
    "    \n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    single_mses.append(mse)\n",
    "    \n",
    "    if fold_idx % 6 == 0:\n",
    "        print(f\"  Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "\n",
    "single_mse = np.mean(single_mses)\n",
    "print(f\"\\nSingle solvent MSE: {single_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535fa3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full data CV\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "full_mses = []\n",
    "\n",
    "for fold_idx, split in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = GNNModel(data='full')  # SAME CLASS AS SUBMISSION\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    targets = test_Y.values\n",
    "    \n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    full_mses.append(mse)\n",
    "    \n",
    "    if fold_idx % 3 == 0:\n",
    "        print(f\"  Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "\n",
    "full_mse = np.mean(full_mses)\n",
    "print(f\"\\nFull data MSE: {full_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ce9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined CV score\n",
    "cv_score = (single_mse + full_mse) / 2\n",
    "print(f\"\\n=== CV Results ===\")\n",
    "print(f\"Single solvent MSE: {single_mse:.6f}\")\n",
    "print(f\"Full data MSE: {full_mse:.6f}\")\n",
    "print(f\"Combined CV score: {cv_score:.6f}\")\n",
    "\n",
    "# Save metrics\n",
    "import json\n",
    "metrics = {\n",
    "    'cv_score': cv_score,\n",
    "    'single_mse': single_mse,\n",
    "    'full_mse': full_mse\n",
    "}\n",
    "with open('/home/code/experiments/115_proper_gnn_v2/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52baca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNModel(data='single')  # SAME CLASS AS CV\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5263049",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNModel(data='full')  # SAME CLASS AS CV\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7295b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "print(f\"Submission saved with {len(submission)} rows\")\n",
    "print(submission.head())\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
