{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a0ae95",
   "metadata": {},
   "source": [
    "# Experiment 098: PCA-Reduced ChemBERTa Embeddings + Domain Constraints\n",
    "\n",
    "**Goal**: Fix the dimensionality problem from exp_097 by applying PCA to reduce ChemBERTa embeddings from 768 to 20 dimensions.\n",
    "\n",
    "**Rationale**:\n",
    "- exp_097 used 786 features (768 ChemBERTa + 13 Spange + 5 Arrhenius) for ~600 samples\n",
    "- Feature-to-sample ratio of 1.31 is WAY too high (should be < 0.1)\n",
    "- Best model (exp_030) uses only 18 features\n",
    "- PCA reduction to 20 components should help generalization\n",
    "\n",
    "**Approach**:\n",
    "1. Extract ChemBERTa embeddings (768-dim)\n",
    "2. Apply PCA to reduce to 20 dimensions\n",
    "3. Combine with Spange (13) + Arrhenius (5) = 38 total features\n",
    "4. Train GP+MLP+LGBM ensemble\n",
    "5. Apply domain constraints (mass balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0d08ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:56.961632Z",
     "iopub.status.busy": "2026-01-16T13:59:56.961109Z",
     "iopub.status.idle": "2026-01-16T13:59:58.616416Z",
     "shell.execute_reply": "2026-01-16T13:59:58.616006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "import lightgbm as lgb\n",
    "from abc import ABC, abstractmethod\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07a4534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:58.617574Z",
     "iopub.status.busy": "2026-01-16T13:59:58.617417Z",
     "iopub.status.idle": "2026-01-16T13:59:58.622029Z",
     "shell.execute_reply": "2026-01-16T13:59:58.621692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c4a5a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:58.623031Z",
     "iopub.status.busy": "2026-01-16T13:59:58.622939Z",
     "iopub.status.idle": "2026-01-16T13:59:58.625832Z",
     "shell.execute_reply": "2026-01-16T13:59:58.625516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Base classes\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def featurize(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea19083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:58.626675Z",
     "iopub.status.busy": "2026-01-16T13:59:58.626585Z",
     "iopub.status.idle": "2026-01-16T13:59:58.633132Z",
     "shell.execute_reply": "2026-01-16T13:59:58.632798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES lookup: (26, 1)\n",
      "Spange: (26, 13)\n",
      "\n",
      "Sample SMILES:\n",
      "                                           solvent smiles\n",
      "SOLVENT NAME                                             \n",
      "Cyclohexane                                      C1CCCCC1\n",
      "Ethyl Acetate                                   O=C(OCC)C\n",
      "Acetic Acid                                       CC(=O)O\n",
      "2-Methyltetrahydrofuran [2-MeTHF]              O1C(C)CCC1\n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol  C(C(F)(F)F)(C(F)(F)F)O\n"
     ]
    }
   ],
   "source": [
    "# Load SMILES and Spange descriptors\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "SPANGE_DF = load_features(\"spange_descriptors\")\n",
    "\n",
    "print(f\"SMILES lookup: {SMILES_DF.shape}\")\n",
    "print(f\"Spange: {SPANGE_DF.shape}\")\n",
    "print(f\"\\nSample SMILES:\")\n",
    "print(SMILES_DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6017d89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:58.634089Z",
     "iopub.status.busy": "2026-01-16T13:59:58.633997Z",
     "iopub.status.idle": "2026-01-16T14:00:02.151261Z",
     "shell.execute_reply": "2026-01-16T14:00:02.150904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ChemBERTa model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. Hidden size: 768\n"
     ]
    }
   ],
   "source": [
    "# Load ChemBERTa model and extract embeddings\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "print(\"Loading ChemBERTa model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "chemberta_model = AutoModel.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "chemberta_model.eval()\n",
    "\n",
    "print(f\"Model loaded. Hidden size: {chemberta_model.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6db6ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T14:00:02.152411Z",
     "iopub.status.busy": "2026-01-16T14:00:02.152316Z",
     "iopub.status.idle": "2026-01-16T14:00:02.664601Z",
     "shell.execute_reply": "2026-01-16T14:00:02.664138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ChemBERTa embeddings for all solvents...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cyclohexane: (768,)\n",
      "  Ethyl Acetate: (768,)\n",
      "  Acetic Acid: (768,)\n",
      "  2-Methyltetrahydrofuran [2-MeTHF]: (768,)\n",
      "  1,1,1,3,3,3-Hexafluoropropan-2-ol: (768,)\n",
      "  IPA [Propan-2-ol]: (768,)\n",
      "  Ethanol: (768,)\n",
      "  Methanol: (768,)\n",
      "  Ethylene Glycol [1,2-Ethanediol]: (768,)\n",
      "  Acetonitrile: (768,)\n",
      "  Water: (768,)\n",
      "  Diethyl Ether [Ether]: (768,)\n",
      "  MTBE [tert-Butylmethylether]: (768,)\n",
      "  Dimethyl Carbonate: (768,)\n",
      "  tert-Butanol [2-Methylpropan-2-ol]: (768,)\n",
      "  DMA [N,N-Dimethylacetamide]: (768,)\n",
      "  2,2,2-Trifluoroethanol: (768,)\n",
      "  Dihydrolevoglucosenone (Cyrene): (768,)\n",
      "  Decanol: (768,)\n",
      "  Butanone [MEK]: (768,)\n",
      "  Ethyl Lactate: (768,)\n",
      "  Methyl Propionate: (768,)\n",
      "  THF [Tetrahydrofuran]: (768,)\n",
      "  Water.Acetonitrile: (768,)\n",
      "  Acetonitrile.Acetic Acid: (768,)\n",
      "  Water.2,2,2-Trifluoroethanol: (768,)\n",
      "\n",
      "ChemBERTa embeddings shape: (26, 768)\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings for all solvents\n",
    "def extract_chemberta_embedding(smiles, tokenizer, model):\n",
    "    \"\"\"Extract ChemBERTa embedding for a single SMILES string.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(smiles, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        # Mean pool over token dimension (excluding padding)\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        # Mask out padding tokens\n",
    "        mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "        sum_hidden = torch.sum(hidden_states * mask_expanded, dim=1)\n",
    "        sum_mask = torch.clamp(mask_expanded.sum(dim=1), min=1e-9)\n",
    "        embedding = sum_hidden / sum_mask\n",
    "        return embedding.squeeze().numpy()\n",
    "\n",
    "print(\"Extracting ChemBERTa embeddings for all solvents...\")\n",
    "chemberta_embeddings = {}\n",
    "for solvent_name in SMILES_DF.index:\n",
    "    smiles = SMILES_DF.loc[solvent_name, 'solvent smiles']\n",
    "    embedding = extract_chemberta_embedding(smiles, tokenizer, chemberta_model)\n",
    "    chemberta_embeddings[solvent_name] = embedding\n",
    "    print(f\"  {solvent_name}: {embedding.shape}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "CHEMBERTA_DF = pd.DataFrame(chemberta_embeddings).T\n",
    "CHEMBERTA_DF.columns = [f'chemberta_{i}' for i in range(768)]\n",
    "print(f\"\\nChemBERTa embeddings shape: {CHEMBERTA_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a03f8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T14:00:11.445343Z",
     "iopub.status.busy": "2026-01-16T14:00:11.444730Z",
     "iopub.status.idle": "2026-01-16T14:00:11.451336Z",
     "shell.execute_reply": "2026-01-16T14:00:11.450931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PCA to reduce ChemBERTa embeddings...\n",
      "Original shape: (26, 768)\n",
      "Reduced shape: (26, 20)\n",
      "Explained variance ratio: 0.9959\n",
      "\n",
      "PCA-reduced ChemBERTa embeddings shape: (26, 20)\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA to reduce ChemBERTa embeddings from 768 to 20 dimensions\n",
    "print(\"Applying PCA to reduce ChemBERTa embeddings...\")\n",
    "\n",
    "# Fit PCA on all solvents\n",
    "pca = PCA(n_components=20)\n",
    "chemberta_reduced = pca.fit_transform(CHEMBERTA_DF.values)\n",
    "\n",
    "print(f\"Original shape: {CHEMBERTA_DF.shape}\")\n",
    "print(f\"Reduced shape: {chemberta_reduced.shape}\")\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "\n",
    "# Create reduced DataFrame\n",
    "CHEMBERTA_PCA_DF = pd.DataFrame(\n",
    "    chemberta_reduced,\n",
    "    index=CHEMBERTA_DF.index,\n",
    "    columns=[f'chemberta_pca_{i}' for i in range(20)]\n",
    ")\n",
    "print(f\"\\nPCA-reduced ChemBERTa embeddings shape: {CHEMBERTA_PCA_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34529599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T14:15:59.989544Z",
     "iopub.status.busy": "2026-01-16T14:15:59.989057Z",
     "iopub.status.idle": "2026-01-16T14:15:59.999809Z",
     "shell.execute_reply": "2026-01-16T14:15:59.999422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemBERTaPCAEnsembleModel defined\n",
      "Features: 5 (Arrhenius) + 13 (Spange) + 20 (ChemBERTa PCA) = 38 total\n"
     ]
    }
   ],
   "source": [
    "# Define the PCA ChemBERTa Ensemble Model\n",
    "class ChemBERTaPCAEnsembleModel(BaseModel):\n",
    "    \"\"\"GP + MLP + LGBM ensemble using PCA-reduced ChemBERTa embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', num_epochs=100):\n",
    "        self.data = data\n",
    "        self.num_epochs = num_epochs\n",
    "        self.scaler = StandardScaler()\n",
    "        self.gp_model = None\n",
    "        self.mlp_model = None\n",
    "        self.lgbm_model = None\n",
    "        self.train_mean = None  # For conservative blending\n",
    "        \n",
    "    def _get_features(self, X):\n",
    "        \"\"\"Extract features from input data.\"\"\"\n",
    "        features_list = []\n",
    "        \n",
    "        if self.data == 'single':\n",
    "            # Arrhenius features\n",
    "            res_time = X['Residence Time'].values.reshape(-1, 1)\n",
    "            temp = X['Temperature'].values.reshape(-1, 1)\n",
    "            temp_kelvin = temp + 273.15\n",
    "            inv_temp = 1.0 / temp_kelvin\n",
    "            log_res_time = np.log(res_time + 1e-6)\n",
    "            arrhenius = res_time * np.exp(-1000 / temp_kelvin)  # Simplified Arrhenius\n",
    "            \n",
    "            features_list.extend([res_time, temp, inv_temp, log_res_time, arrhenius])\n",
    "            \n",
    "            # Spange descriptors (13 features)\n",
    "            spange_features = np.array([SPANGE_DF.loc[s].values for s in X['SOLVENT NAME']])\n",
    "            features_list.append(spange_features)\n",
    "            \n",
    "            # PCA-reduced ChemBERTa embeddings (20 features)\n",
    "            chemberta_features = np.array([CHEMBERTA_PCA_DF.loc[s].values for s in X['SOLVENT NAME']])\n",
    "            features_list.append(chemberta_features)\n",
    "            \n",
    "        else:  # full data\n",
    "            # Arrhenius features\n",
    "            res_time = X['Residence Time'].values.reshape(-1, 1)\n",
    "            temp = X['Temperature'].values.reshape(-1, 1)\n",
    "            temp_kelvin = temp + 273.15\n",
    "            inv_temp = 1.0 / temp_kelvin\n",
    "            log_res_time = np.log(res_time + 1e-6)\n",
    "            arrhenius = res_time * np.exp(-1000 / temp_kelvin)\n",
    "            solvent_b_pct = X['SolventB%'].values.reshape(-1, 1)\n",
    "            \n",
    "            features_list.extend([res_time, temp, inv_temp, log_res_time, arrhenius, solvent_b_pct])\n",
    "            \n",
    "            # Spange descriptors - weighted average for mixtures\n",
    "            spange_a = np.array([SPANGE_DF.loc[s].values for s in X['SOLVENT A NAME']])\n",
    "            spange_b = np.array([SPANGE_DF.loc[s].values for s in X['SOLVENT B NAME']])\n",
    "            weight_b = solvent_b_pct / 100.0\n",
    "            spange_mixed = (1 - weight_b) * spange_a + weight_b * spange_b\n",
    "            features_list.append(spange_mixed)\n",
    "            \n",
    "            # PCA-reduced ChemBERTa embeddings - weighted average for mixtures\n",
    "            chemberta_a = np.array([CHEMBERTA_PCA_DF.loc[s].values for s in X['SOLVENT A NAME']])\n",
    "            chemberta_b = np.array([CHEMBERTA_PCA_DF.loc[s].values for s in X['SOLVENT B NAME']])\n",
    "            chemberta_mixed = (1 - weight_b) * chemberta_a + weight_b * chemberta_b\n",
    "            features_list.append(chemberta_mixed)\n",
    "        \n",
    "        return np.hstack(features_list)\n",
    "    \n",
    "    def train_model(self, X, Y):\n",
    "        \"\"\"Train GP + MLP + LGBM ensemble.\"\"\"\n",
    "        features = self._get_features(X)\n",
    "        features_scaled = self.scaler.fit_transform(features)\n",
    "        y_values = Y.values\n",
    "        \n",
    "        # Store training mean for conservative blending\n",
    "        self.train_mean = y_values.mean(axis=0)\n",
    "        \n",
    "        # 1. Train GP (on subset of features for efficiency)\n",
    "        kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "        self.gp_model = MultiOutputRegressor(\n",
    "            GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=2, random_state=42)\n",
    "        )\n",
    "        self.gp_model.fit(features_scaled, y_values)\n",
    "        \n",
    "        # 2. Train MLP\n",
    "        self.mlp_model = self._train_mlp(features_scaled, y_values)\n",
    "        \n",
    "        # 3. Train LGBM\n",
    "        self.lgbm_model = MultiOutputRegressor(\n",
    "            lgb.LGBMRegressor(n_estimators=100, learning_rate=0.05, max_depth=5, \n",
    "                             num_leaves=31, random_state=42, verbose=-1)\n",
    "        )\n",
    "        self.lgbm_model.fit(features_scaled, y_values)\n",
    "        \n",
    "    def _train_mlp(self, X, Y):\n",
    "        \"\"\"Train a simple MLP.\"\"\"\n",
    "        input_dim = X.shape[1]\n",
    "        output_dim = Y.shape[1]\n",
    "        \n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, output_dim)\n",
    "        )\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        X_tensor = torch.FloatTensor(X)\n",
    "        Y_tensor = torch.FloatTensor(Y)\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in range(self.num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_tensor)\n",
    "            loss = criterion(outputs, Y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        return model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using ensemble with domain constraints.\"\"\"\n",
    "        features = self._get_features(X)\n",
    "        features_scaled = self.scaler.transform(features)\n",
    "        \n",
    "        # Get predictions from each model\n",
    "        gp_pred = self.gp_model.predict(features_scaled)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            mlp_pred = self.mlp_model(torch.FloatTensor(features_scaled)).numpy()\n",
    "        \n",
    "        lgbm_pred = self.lgbm_model.predict(features_scaled)\n",
    "        \n",
    "        # Ensemble: weighted average (GP gets higher weight for uncertainty)\n",
    "        ensemble_pred = 0.4 * gp_pred + 0.3 * mlp_pred + 0.3 * lgbm_pred\n",
    "        \n",
    "        # Apply domain constraints (mass balance)\n",
    "        ensemble_pred = self._enforce_mass_balance(ensemble_pred)\n",
    "        \n",
    "        return torch.FloatTensor(ensemble_pred)\n",
    "    \n",
    "    def _enforce_mass_balance(self, predictions):\n",
    "        \"\"\"Post-process predictions to satisfy mass balance.\"\"\"\n",
    "        # Clip to [0, 1]\n",
    "        predictions = np.clip(predictions, 0, 1)\n",
    "        \n",
    "        # Ensure sum doesn't exceed 1 (yields can't exceed 100% total)\n",
    "        row_sums = predictions.sum(axis=1, keepdims=True)\n",
    "        for i in range(len(predictions)):\n",
    "            if row_sums[i, 0] > 1:\n",
    "                predictions[i] = predictions[i] / row_sums[i, 0]\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "print(\"ChemBERTaPCAEnsembleModel defined\")\n",
    "print(\"Features: 5 (Arrhenius) + 13 (Spange) + 20 (ChemBERTa PCA) = 38 total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87a48ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T14:16:00.000808Z",
     "iopub.status.busy": "2026-01-16T14:16:00.000717Z",
     "iopub.status.idle": "2026-01-16T14:33:06.330510Z",
     "shell.execute_reply": "2026-01-16T14:33:06.329000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CV with PCA-reduced ChemBERTa embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 0: MSE = 0.041562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 1: MSE = 0.017304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 2: MSE = 0.006700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 3: MSE = 0.007438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 4: MSE = 0.023706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 5: MSE = 0.003313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 6: MSE = 0.006805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 7: MSE = 0.015436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 8: MSE = 0.035206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 9: MSE = 0.017351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 10: MSE = 0.007266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 11: MSE = 0.012168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 12: MSE = 0.003641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 13: MSE = 0.004840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 14: MSE = 0.004309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 15: MSE = 0.023920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 16: MSE = 0.024051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 17: MSE = 0.006335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 18: MSE = 0.003236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 19: MSE = 0.008072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 20: MSE = 0.003486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 21: MSE = 0.009069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 22: MSE = 0.031475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Fold 23: MSE = 0.001435\n",
      "\n",
      "Single Solvent CV MSE: 0.013255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 0: MSE = 0.012540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 1: MSE = 0.027881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 2: MSE = 0.025746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 3: MSE = 0.032094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 4: MSE = 0.017479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 5: MSE = 0.008385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 6: MSE = 0.025360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 7: MSE = 0.028409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 8: MSE = 0.006475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 9: MSE = 0.006530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 10: MSE = 0.006947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 11: MSE = 0.008297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fold 12: MSE = 0.005972\n",
      "\n",
      "Full Data CV MSE: 0.016317\n",
      "\n",
      "=== Combined CV MSE: 0.014786 ===\n"
     ]
    }
   ],
   "source": [
    "# Run CV\n",
    "import tqdm\n",
    "\n",
    "def compute_cv_score(verbose=True):\n",
    "    \"\"\"Compute CV score with PCA-reduced ChemBERTa embeddings.\"\"\"\n",
    "    \n",
    "    # Single solvent CV\n",
    "    X_single, Y_single = load_data(\"single_solvent\")\n",
    "    split_generator = generate_leave_one_out_splits(X_single, Y_single)\n",
    "    \n",
    "    single_mse_list = []\n",
    "    for fold_idx, split in enumerate(split_generator):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = ChemBERTaPCAEnsembleModel(data='single', num_epochs=100)\n",
    "        model.train_model(train_X, train_Y)\n",
    "        \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions_np = predictions.detach().cpu().numpy()\n",
    "        \n",
    "        mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "        single_mse_list.append(mse)\n",
    "        if verbose:\n",
    "            print(f\"Single Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "    \n",
    "    single_cv = np.mean(single_mse_list)\n",
    "    if verbose:\n",
    "        print(f\"\\nSingle Solvent CV MSE: {single_cv:.6f}\")\n",
    "    \n",
    "    # Full data CV\n",
    "    X_full, Y_full = load_data(\"full\")\n",
    "    split_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "    \n",
    "    full_mse_list = []\n",
    "    for fold_idx, split in enumerate(split_generator):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = ChemBERTaPCAEnsembleModel(data='full', num_epochs=100)\n",
    "        model.train_model(train_X, train_Y)\n",
    "        \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions_np = predictions.detach().cpu().numpy()\n",
    "        \n",
    "        mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "        full_mse_list.append(mse)\n",
    "        if verbose:\n",
    "            print(f\"Full Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "    \n",
    "    full_cv = np.mean(full_mse_list)\n",
    "    if verbose:\n",
    "        print(f\"\\nFull Data CV MSE: {full_cv:.6f}\")\n",
    "    \n",
    "    combined_cv = (single_cv + full_cv) / 2\n",
    "    if verbose:\n",
    "        print(f\"\\n=== Combined CV MSE: {combined_cv:.6f} ===\")\n",
    "    \n",
    "    return single_cv, full_cv, combined_cv\n",
    "\n",
    "print(\"Running CV with PCA-reduced ChemBERTa embeddings...\")\n",
    "single_cv, full_cv, combined_cv = compute_cv_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb89742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import json\n",
    "\n",
    "results = {\n",
    "    'cv_score': float(combined_cv),\n",
    "    'single_cv': float(single_cv),\n",
    "    'full_cv': float(full_cv),\n",
    "    'model': 'ChemBERTaPCAEnsembleModel (GP+MLP+LGBM with PCA-reduced ChemBERTa)',\n",
    "    'baseline_cv': 0.0081,\n",
    "    'improvement': f\"{(0.0081 - combined_cv) / 0.0081 * 100:.2f}%\",\n",
    "    'features': '5 (Arrhenius) + 13 (Spange) + 20 (ChemBERTa PCA) = 38 total',\n",
    "    'pca_explained_variance': float(pca.explained_variance_ratio_.sum())\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/098_chemberta_pca/metrics.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Results saved\")\n",
    "print(f\"Combined CV: {combined_cv:.6f}\")\n",
    "print(f\"Baseline CV: 0.0081\")\n",
    "print(f\"Improvement: {(0.0081 - combined_cv) / 0.0081 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd83ab8",
   "metadata": {},
   "source": [
    "## Generate Submission (if CV is better than baseline)\n",
    "\n",
    "The following cells follow the official template structure.\n",
    "\n",
    "**CRITICAL**: The model class in submission cells MUST match the CV computation class (`ChemBERTaPCAEnsembleModel`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b53252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we should generate submission\n",
    "if combined_cv < 0.0081:\n",
    "    print(f\"CV {combined_cv:.6f} is BETTER than baseline 0.0081!\")\n",
    "    print(\"Generating submission...\")\n",
    "    GENERATE_SUBMISSION = True\n",
    "else:\n",
    "    print(f\"CV {combined_cv:.6f} is WORSE than baseline 0.0081\")\n",
    "    print(\"Not generating submission.\")\n",
    "    GENERATE_SUBMISSION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36528b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ChemBERTaPCAEnsembleModel(data='single', num_epochs=100)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eedd20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ChemBERTaPCAEnsembleModel(data='full', num_epochs=100)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af3af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "# Also save to standard location\n",
    "import shutil\n",
    "import os\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "shutil.copy(\"submission.csv\", \"/home/submission/submission.csv\")\n",
    "print(\"Submission saved!\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(submission.head())\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
