{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b6925b2",
   "metadata": {},
   "source": [
    "# Experiment 055: Minimal Submission (Mean Predictor)\n",
    "\n",
    "**Goal:** Create a MINIMAL submission to debug the evaluation error.\n",
    "\n",
    "**Approach:** Use the EXACT official template code, only changing the model to predict the mean.\n",
    "\n",
    "**Purpose:** If this works, we know the submission format is correct. If it fails, there's something else wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8bbc8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:33:28.279398Z",
     "iopub.status.busy": "2026-01-15T23:33:28.278943Z",
     "iopub.status.idle": "2026-01-15T23:33:29.289812Z",
     "shell.execute_reply": "2026-01-15T23:33:29.289320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "# EXACT imports from official template\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from abc import ABC, abstractmethod\n",
    "import tqdm\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "# Data path for local execution\n",
    "DATA_PATH = \"/home/data\"\n",
    "\n",
    "print(\"Imports complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc644049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:33:29.291088Z",
     "iopub.status.busy": "2026-01-15T23:33:29.290900Z",
     "iopub.status.idle": "2026-01-15T23:33:29.294013Z",
     "shell.execute_reply": "2026-01-15T23:33:29.293671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constants defined.\n"
     ]
    }
   ],
   "source": [
    "# EXACT constants from official template\n",
    "INPUT_LABELS_FULL_SOLVENT = [\n",
    "    \"Residence Time\",\n",
    "    \"Temperature\",\n",
    "    \"SOLVENT A NAME\",\n",
    "    \"SOLVENT B NAME\",\n",
    "    \"SolventB%\",\n",
    "]\n",
    "\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\n",
    "    \"Residence Time\",\n",
    "    \"Temperature\",\n",
    "    \"SOLVENT NAME\",\n",
    "]\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\n",
    "    \"Residence Time\",\n",
    "    \"Temperature\",\n",
    "]\n",
    "\n",
    "INPUT_LABELS_SINGLE_FEATURES = [\n",
    "    \"SOLVENT NAME\",\n",
    "]\n",
    "\n",
    "INPUT_LABELS_FULL_FEATURES = [\n",
    "    \"SOLVENT A NAME\",\n",
    "    \"SOLVENT B NAME\",\n",
    "    \"SolventB%\"\n",
    "]\n",
    "\n",
    "TARGET_LABELS = [\n",
    "    \"Product 2\",\n",
    "    \"Product 3\",\n",
    "    \"SM\",\n",
    "]\n",
    "\n",
    "print(\"Constants defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8bdd73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:33:29.294854Z",
     "iopub.status.busy": "2026-01-15T23:33:29.294760Z",
     "iopub.status.idle": "2026-01-15T23:33:29.299485Z",
     "shell.execute_reply": "2026-01-15T23:33:29.299148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading and CV functions defined.\n"
     ]
    }
   ],
   "source": [
    "# EXACT data loading functions from official template (adapted for local paths)\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    assert name in [\"spange_descriptors\", \"acs_pca_descriptors\", \"drfps_catechol\", \"fragprints\", \"smiles\"]\n",
    "    features = pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "    return features\n",
    "\n",
    "# EXACT CV functions from official template\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    \"\"\"Generate all leave-one-out splits across the solvents.\"\"\"\n",
    "    all_solvents = X[\"SOLVENT NAME\"].unique()\n",
    "    for solvent_name in sorted(all_solvents):\n",
    "        train_idcs_mask = X[\"SOLVENT NAME\"] != solvent_name\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    \"\"\"Generate all leave-one-out splits across the solvent ramps.\"\"\"\n",
    "    all_solvent_ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    all_solvent_ramps = all_solvent_ramps.sort_values(by=[\"SOLVENT A NAME\", \"SOLVENT B NAME\"])\n",
    "    for _, solvent_pair in all_solvent_ramps.iterrows():\n",
    "        train_idcs_mask = (X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]] != solvent_pair).any(axis=1)\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "print(\"Data loading and CV functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b208ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:33:29.300419Z",
     "iopub.status.busy": "2026-01-15T23:33:29.300327Z",
     "iopub.status.idle": "2026-01-15T23:33:29.303289Z",
     "shell.execute_reply": "2026-01-15T23:33:29.302973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base classes defined.\n"
     ]
    }
   ],
   "source": [
    "# EXACT base classes from official template\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def featurize(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "print(\"Base classes defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c70209c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:33:29.304186Z",
     "iopub.status.busy": "2026-01-15T23:33:29.304089Z",
     "iopub.status.idle": "2026-01-15T23:33:29.307395Z",
     "shell.execute_reply": "2026-01-15T23:33:29.307064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanPredictor model defined.\n"
     ]
    }
   ],
   "source": [
    "# MINIMAL MODEL: Just predict the mean\n",
    "class MeanPredictor(BaseModel):\n",
    "    \"\"\"Simplest possible model - just predicts the training mean.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single'):\n",
    "        self.data = data\n",
    "        self.mean = None\n",
    "    \n",
    "    def train_model(self, train_X, train_Y, device=None, verbose=False):\n",
    "        # Just store the mean of the training targets\n",
    "        self.mean = train_Y.mean().values\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Return the mean for all samples\n",
    "        n_samples = len(X)\n",
    "        predictions = np.tile(self.mean, (n_samples, 1))\n",
    "        # Clip to [0, 1]\n",
    "        predictions = np.clip(predictions, 0, 1)\n",
    "        return torch.tensor(predictions, dtype=torch.double)\n",
    "\n",
    "print(\"MeanPredictor model defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0737de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:33:29.308240Z",
     "iopub.status.busy": "2026-01-15T23:33:29.308147Z",
     "iopub.status.idle": "2026-01-15T23:33:29.318630Z",
     "shell.execute_reply": "2026-01-15T23:33:29.318281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MeanPredictor...\n",
      "Single solvent data: X=(656, 3), Y=(656, 3)\n",
      "Predictions shape: torch.Size([37, 3])\n",
      "Predictions: tensor([0.1398, 0.1137, 0.5432])\n",
      "Training mean: [0.13978304 0.11369471 0.54321009]\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "print(\"Testing MeanPredictor...\")\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent data: X={X.shape}, Y={Y.shape}\")\n",
    "\n",
    "# Test one fold\n",
    "split_gen = generate_leave_one_out_splits(X, Y)\n",
    "(train_X, train_Y), (test_X, test_Y) = next(split_gen)\n",
    "\n",
    "model = MeanPredictor()\n",
    "model.train_model(train_X, train_Y)\n",
    "preds = model.predict(test_X)\n",
    "\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"Predictions: {preds[0]}\")\n",
    "print(f\"Training mean: {model.mean}\")\n",
    "print(\"Test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f1baccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:33:29.319510Z",
     "iopub.status.busy": "2026-01-15T23:33:29.319409Z",
     "iopub.status.idle": "2026-01-15T23:33:29.344430Z",
     "shell.execute_reply": "2026-01-15T23:33:29.344092Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:00, 1571.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent predictions: 656\n",
      "Unique folds: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MeanPredictor() # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "print(f\"Single solvent predictions: {len(submission_single_solvent)}\")\n",
    "print(f\"Unique folds: {submission_single_solvent['fold'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11e6b8ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:33:29.345286Z",
     "iopub.status.busy": "2026-01-15T23:33:29.345198Z",
     "iopub.status.idle": "2026-01-15T23:33:29.376288Z",
     "shell.execute_reply": "2026-01-15T23:33:29.375887Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:00, 674.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data predictions: 1227\n",
      "Unique folds: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MeanPredictor(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "print(f\"Full data predictions: {len(submission_full_data)}\")\n",
    "print(f\"Unique folds: {submission_full_data['fold'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51e6202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:33:29.377318Z",
     "iopub.status.busy": "2026-01-15T23:33:29.377204Z",
     "iopub.status.idle": "2026-01-15T23:33:29.387339Z",
     "shell.execute_reply": "2026-01-15T23:33:29.387011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to /home/submission/submission.csv\n",
      "Total rows: 1883\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "print(f\"Submission saved to /home/submission/submission.csv\")\n",
    "print(f\"Total rows: {len(submission)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ae17fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:33:29.388240Z",
     "iopub.status.busy": "2026-01-15T23:33:29.388152Z",
     "iopub.status.idle": "2026-01-15T23:33:29.399298Z",
     "shell.execute_reply": "2026-01-15T23:33:29.398969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUBMISSION VERIFICATION\n",
      "============================================================\n",
      "\n",
      "Columns: ['id', 'index', 'task', 'fold', 'row', 'target_1', 'target_2', 'target_3']\n",
      "Total rows: 1883\n",
      "\n",
      "Task 0 (single solvent):\n",
      "  Rows: 656\n",
      "  Folds: 24\n",
      "  Fold range: 0 to 23\n",
      "  Fold values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "\n",
      "Task 1 (full data):\n",
      "  Rows: 1227\n",
      "  Folds: 13\n",
      "  Fold range: 0 to 12\n",
      "  Fold values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "\n",
      "Target statistics:\n",
      "  target_1: min=0.139783, max=0.175118, mean=0.158796\n",
      "    Values > 1: 0\n",
      "    Values < 0: 0\n",
      "    NaN values: 0\n",
      "  target_2: min=0.113695, max=0.154595, mean=0.136127\n",
      "    Values > 1: 0\n",
      "    Values < 0: 0\n",
      "    NaN values: 0\n",
      "  target_3: min=0.478333, max=0.543210, mean=0.506416\n",
      "    Values > 1: 0\n",
      "    Values < 0: 0\n",
      "    NaN values: 0\n",
      "\n",
      "Data types:\n",
      "id            int64\n",
      "index         int64\n",
      "task          int64\n",
      "fold          int64\n",
      "row           int64\n",
      "target_1    float64\n",
      "target_2    float64\n",
      "target_3    float64\n",
      "dtype: object\n",
      "\n",
      "First 5 rows:\n",
      "   id  index  task  fold  row  target_1  target_2  target_3\n",
      "0   0      0     0     0    0  0.139783  0.113695   0.54321\n",
      "1   1      1     0     0    1  0.139783  0.113695   0.54321\n",
      "2   2      2     0     0    2  0.139783  0.113695   0.54321\n",
      "3   3      3     0     0    3  0.139783  0.113695   0.54321\n",
      "4   4      4     0     0    4  0.139783  0.113695   0.54321\n",
      "\n",
      "Last 5 rows:\n",
      "        id  index  task  fold  row  target_1  target_2  target_3\n",
      "1878  1878   1222     1    12   31  0.167632  0.146549  0.486409\n",
      "1879  1879   1223     1    12   32  0.167632  0.146549  0.486409\n",
      "1880  1880   1224     1    12   33  0.167632  0.146549  0.486409\n",
      "1881  1881   1225     1    12   34  0.167632  0.146549  0.486409\n",
      "1882  1882   1226     1    12   35  0.167632  0.146549  0.486409\n"
     ]
    }
   ],
   "source": [
    "# THOROUGH VERIFICATION\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUBMISSION VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "\n",
    "print(f\"\\nTask 0 (single solvent):\")\n",
    "task0 = df[df['task'] == 0]\n",
    "print(f\"  Rows: {len(task0)}\")\n",
    "print(f\"  Folds: {task0['fold'].nunique()}\")\n",
    "print(f\"  Fold range: {task0['fold'].min()} to {task0['fold'].max()}\")\n",
    "print(f\"  Fold values: {sorted(task0['fold'].unique())}\")\n",
    "\n",
    "print(f\"\\nTask 1 (full data):\")\n",
    "task1 = df[df['task'] == 1]\n",
    "print(f\"  Rows: {len(task1)}\")\n",
    "print(f\"  Folds: {task1['fold'].nunique()}\")\n",
    "print(f\"  Fold range: {task1['fold'].min()} to {task1['fold'].max()}\")\n",
    "print(f\"  Fold values: {sorted(task1['fold'].unique())}\")\n",
    "\n",
    "print(f\"\\nTarget statistics:\")\n",
    "for col in ['target_1', 'target_2', 'target_3']:\n",
    "    print(f\"  {col}: min={df[col].min():.6f}, max={df[col].max():.6f}, mean={df[col].mean():.6f}\")\n",
    "    print(f\"    Values > 1: {(df[col] > 1).sum()}\")\n",
    "    print(f\"    Values < 0: {(df[col] < 0).sum()}\")\n",
    "    print(f\"    NaN values: {df[col].isna().sum()}\")\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nLast 5 rows:\")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e71d12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:33:29.400092Z",
     "iopub.status.busy": "2026-01-15T23:33:29.400004Z",
     "iopub.status.idle": "2026-01-15T23:33:29.441836Z",
     "shell.execute_reply": "2026-01-15T23:33:29.441480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CV CALCULATION\n",
      "============================================================\n",
      "Single solvent CV MSE: 0.054253\n",
      "Full data CV MSE: 0.056957\n",
      "\n",
      "FINAL CV FOR LOGGING: 0.054253\n"
     ]
    }
   ],
   "source": [
    "# Calculate CV for logging\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CV CALCULATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Single solvent CV\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "fold_mses = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X, Y)):\n",
    "    model = MeanPredictor()\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mse = np.mean((preds - test_Y.values) ** 2)\n",
    "    fold_mses.append(mse)\n",
    "\n",
    "single_cv = np.mean(fold_mses)\n",
    "print(f\"Single solvent CV MSE: {single_cv:.6f}\")\n",
    "\n",
    "# Full data CV\n",
    "X, Y = load_data(\"full\")\n",
    "full_fold_mses = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_ramp_out_splits(X, Y)):\n",
    "    model = MeanPredictor(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mse = np.mean((preds - test_Y.values) ** 2)\n",
    "    full_fold_mses.append(mse)\n",
    "\n",
    "full_cv = np.mean(full_fold_mses)\n",
    "print(f\"Full data CV MSE: {full_cv:.6f}\")\n",
    "\n",
    "print(f\"\\nFINAL CV FOR LOGGING: {single_cv:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec33171b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:33:29.443016Z",
     "iopub.status.busy": "2026-01-15T23:33:29.442630Z",
     "iopub.status.idle": "2026-01-15T23:33:29.446165Z",
     "shell.execute_reply": "2026-01-15T23:33:29.445842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPERIMENT 055: MINIMAL SUBMISSION SUMMARY\n",
      "============================================================\n",
      "\n",
      "GOAL: Debug submission format by using simplest possible model\n",
      "\n",
      "MODEL: MeanPredictor - just predicts the training mean\n",
      "\n",
      "SUBMISSION FORMAT:\n",
      "  Total rows: 1883\n",
      "  Task 0: 656 rows, 24 folds (0-23)\n",
      "  Task 1: 1227 rows, 13 folds (0-12)\n",
      "  All targets in [0, 1]: YES\n",
      "  No NaN values: YES\n",
      "\n",
      "CV SCORES:\n",
      "  Single solvent: 0.054253\n",
      "  Full data: 0.056957\n",
      "\n",
      "PURPOSE:\n",
      "  If this submission works, the format is correct.\n",
      "  If it fails, there's something else wrong with the evaluation.\n",
      "  This is the SIMPLEST possible submission to debug the issue.\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 055: MINIMAL SUBMISSION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nGOAL: Debug submission format by using simplest possible model\")\n",
    "print(\"\\nMODEL: MeanPredictor - just predicts the training mean\")\n",
    "\n",
    "print(f\"\\nSUBMISSION FORMAT:\")\n",
    "print(f\"  Total rows: {len(df)}\")\n",
    "print(f\"  Task 0: {len(task0)} rows, {task0['fold'].nunique()} folds (0-{task0['fold'].max()})\")\n",
    "print(f\"  Task 1: {len(task1)} rows, {task1['fold'].nunique()} folds (0-{task1['fold'].max()})\")\n",
    "print(f\"  All targets in [0, 1]: YES\")\n",
    "print(f\"  No NaN values: YES\")\n",
    "\n",
    "print(f\"\\nCV SCORES:\")\n",
    "print(f\"  Single solvent: {single_cv:.6f}\")\n",
    "print(f\"  Full data: {full_cv:.6f}\")\n",
    "\n",
    "print(\"\\nPURPOSE:\")\n",
    "print(\"  If this submission works, the format is correct.\")\n",
    "print(\"  If it fails, there's something else wrong with the evaluation.\")\n",
    "print(\"  This is the SIMPLEST possible submission to debug the issue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8215f01f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:34:31.772450Z",
     "iopub.status.busy": "2026-01-15T23:34:31.771921Z",
     "iopub.status.idle": "2026-01-15T23:34:31.775100Z",
     "shell.execute_reply": "2026-01-15T23:34:31.774752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def generate_leave_one_ramp_out_splits(X, Y):\n",
      "    \"\"\"Generate all leave-one-out splits across the solvent ramps.\"\"\"\n",
      "    all_solvent_ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
      "    all_solvent_ramps = all_solvent_ramps.sort_values(by=[\"SOLVENT A NAME\", \"SOLVENT B NAME\"])\n",
      "    for _, solvent_pair in all_solvent_ramps.iterrows():\n",
      "        train_idcs_mask = (X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]] != solvent_pair).any(axis=1)\n",
      "        yield (\n",
      "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
      "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the actual implementation of generate_leave_one_ramp_out_splits\n",
    "import inspect\n",
    "print(inspect.getsource(generate_leave_one_ramp_out_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0413ac0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:35:07.555071Z",
     "iopub.status.busy": "2026-01-15T23:35:07.554494Z",
     "iopub.status.idle": "2026-01-15T23:35:07.593869Z",
     "shell.execute_reply": "2026-01-15T23:35:07.593461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My implementation (.any()):\n",
      "  Number of folds: 13\n",
      "  Fold 0: train=1103, test=124\n",
      "  Fold 1: train=1102, test=125\n",
      "  Fold 2: train=1103, test=124\n",
      "  Fold 3: train=1102, test=125\n",
      "  Fold 4: train=1123, test=104\n",
      "  Fold 5: train=1117, test=110\n",
      "  Fold 6: train=1191, test=36\n",
      "  Fold 7: train=1100, test=127\n",
      "  Fold 8: train=1193, test=34\n",
      "  Fold 9: train=1105, test=122\n",
      "  Fold 10: train=1192, test=35\n",
      "  Fold 11: train=1102, test=125\n",
      "  Fold 12: train=1191, test=36\n",
      "\n",
      "Official implementation (.all()):\n",
      "  Number of folds: 13\n",
      "  Fold 0: train=1103, test=124\n",
      "  Fold 1: train=1102, test=125\n",
      "  Fold 2: train=1103, test=124\n",
      "  Fold 3: train=1102, test=125\n",
      "  Fold 4: train=1123, test=104\n",
      "  Fold 5: train=1117, test=110\n",
      "  Fold 6: train=1191, test=36\n",
      "  Fold 7: train=1100, test=127\n",
      "  Fold 8: train=1193, test=34\n",
      "  Fold 9: train=1105, test=122\n",
      "  Fold 10: train=1192, test=35\n",
      "  Fold 11: train=1102, test=125\n",
      "  Fold 12: train=1191, test=36\n"
     ]
    }
   ],
   "source": [
    "# Compare my implementation with the official one\n",
    "def generate_leave_one_ramp_out_splits_official(X, Y):\n",
    "    \"\"\"Official implementation from utils.py\"\"\"\n",
    "    all_solvent_ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    all_solvent_ramps = all_solvent_ramps.sort_values(by=[\"SOLVENT A NAME\", \"SOLVENT B NAME\"])\n",
    "    for _, solvent_pair in all_solvent_ramps.iterrows():\n",
    "        train_idcs_mask = (X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]] != solvent_pair).all(axis=1)\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "# Test both implementations\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "print(\"My implementation (.any()):\")\n",
    "my_folds = list(generate_leave_one_ramp_out_splits(X, Y))\n",
    "print(f\"  Number of folds: {len(my_folds)}\")\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(my_folds):\n",
    "    print(f\"  Fold {i}: train={len(train_X)}, test={len(test_X)}\")\n",
    "\n",
    "print(\"\\nOfficial implementation (.all()):\")\n",
    "official_folds = list(generate_leave_one_ramp_out_splits_official(X, Y))\n",
    "print(f\"  Number of folds: {len(official_folds)}\")\n",
    "for i, ((train_X, train_Y), (test_X, test_Y)) in enumerate(official_folds):\n",
    "    print(f\"  Fold {i}: train={len(train_X)}, test={len(test_X)}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
