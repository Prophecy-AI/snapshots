{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23fc818c",
   "metadata": {},
   "source": [
    "# Experiment 093: ChemProp Pre-trained Embeddings\n",
    "\n",
    "**Goal**: Use ChemProp's pre-trained molecular embeddings as features for our best model.\n",
    "\n",
    "**Rationale**: \n",
    "- The benchmark paper achieved MSE 0.0039 using GNNs\n",
    "- Our GNN attempts achieved CV ~0.018-0.026 (5-6x worse)\n",
    "- Pre-trained models have learned chemistry from millions of molecules\n",
    "- Using pre-trained embeddings as features may capture chemistry better than hand-crafted features\n",
    "\n",
    "**Approach**:\n",
    "1. Extract ChemProp embeddings for all solvents\n",
    "2. Use embeddings + Arrhenius features as input to GP+MLP+LGBM ensemble\n",
    "3. Compare CV to baseline (0.008298)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "import lightgbm as lgb\n",
    "from abc import ABC, abstractmethod\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Imports complete\")\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb4ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ChemProp version and capabilities\n",
    "import chemprop\n",
    "print(f\"ChemProp version: {chemprop.__version__}\")\n",
    "\n",
    "# Check what's available in chemprop\n",
    "print(\"\\nChemProp modules:\")\n",
    "for attr in dir(chemprop):\n",
    "    if not attr.startswith('_'):\n",
    "        print(f\"  {attr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d630cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SMILES lookup\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "print(f\"SMILES lookup shape: {SMILES_DF.shape}\")\n",
    "print(f\"Columns: {SMILES_DF.columns.tolist()}\")\n",
    "print(f\"\\nSample SMILES:\")\n",
    "print(SMILES_DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb2cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get ChemProp embeddings\n",
    "# ChemProp 2.x has a different API than 1.x\n",
    "\n",
    "try:\n",
    "    from chemprop.featurizers import MoleculeFeaturizer\n",
    "    from chemprop.data import MoleculeDatapoint, MoleculeDataset\n",
    "    print(\"ChemProp 2.x API available\")\n",
    "    \n",
    "    # Get unique solvents\n",
    "    smiles_list = SMILES_DF['smiles'].tolist()\n",
    "    solvent_names = SMILES_DF.index.tolist()\n",
    "    \n",
    "    print(f\"\\nNumber of solvents: {len(smiles_list)}\")\n",
    "    print(f\"Sample SMILES: {smiles_list[:3]}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Trying alternative approach...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78282df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RDKit to compute Morgan fingerprints as molecular features\n",
    "# This is a simpler but effective approach\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors, rdMolDescriptors\n",
    "import numpy as np\n",
    "\n",
    "def compute_morgan_fingerprint(smiles, radius=2, n_bits=2048):\n",
    "    \"\"\"Compute Morgan fingerprint for a molecule.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(n_bits)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    return np.array(fp)\n",
    "\n",
    "def compute_rdkit_descriptors(smiles):\n",
    "    \"\"\"Compute RDKit 2D descriptors for a molecule.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(15)  # Return zeros if invalid\n",
    "    \n",
    "    descriptors = []\n",
    "    # Molecular weight\n",
    "    descriptors.append(Descriptors.MolWt(mol))\n",
    "    # LogP\n",
    "    descriptors.append(Descriptors.MolLogP(mol))\n",
    "    # TPSA\n",
    "    descriptors.append(Descriptors.TPSA(mol))\n",
    "    # Number of rotatable bonds\n",
    "    descriptors.append(Descriptors.NumRotatableBonds(mol))\n",
    "    # Number of H-bond donors\n",
    "    descriptors.append(Descriptors.NumHDonors(mol))\n",
    "    # Number of H-bond acceptors\n",
    "    descriptors.append(Descriptors.NumHAcceptors(mol))\n",
    "    # Number of heavy atoms\n",
    "    descriptors.append(Descriptors.HeavyAtomCount(mol))\n",
    "    # Number of rings\n",
    "    descriptors.append(Descriptors.RingCount(mol))\n",
    "    # Fraction of sp3 carbons\n",
    "    descriptors.append(Descriptors.FractionCSP3(mol))\n",
    "    # Number of aromatic rings\n",
    "    descriptors.append(Descriptors.NumAromaticRings(mol))\n",
    "    # Molar refractivity\n",
    "    descriptors.append(Descriptors.MolMR(mol))\n",
    "    # Balaban J\n",
    "    try:\n",
    "        descriptors.append(Descriptors.BalabanJ(mol))\n",
    "    except:\n",
    "        descriptors.append(0)\n",
    "    # BertzCT\n",
    "    descriptors.append(Descriptors.BertzCT(mol))\n",
    "    # Chi0\n",
    "    descriptors.append(Descriptors.Chi0(mol))\n",
    "    # Chi1\n",
    "    descriptors.append(Descriptors.Chi1(mol))\n",
    "    \n",
    "    return np.array(descriptors)\n",
    "\n",
    "# Compute features for all solvents\n",
    "print(\"Computing molecular features...\")\n",
    "smiles_list = SMILES_DF['solvent smiles'].tolist()\n",
    "solvent_names = SMILES_DF.index.tolist()\n",
    "\n",
    "# Morgan fingerprints (2048 bits)\n",
    "morgan_fps = np.array([compute_morgan_fingerprint(s) for s in smiles_list])\n",
    "print(f\"Morgan fingerprints shape: {morgan_fps.shape}\")\n",
    "\n",
    "# RDKit descriptors\n",
    "rdkit_descs = np.array([compute_rdkit_descriptors(s) for s in smiles_list])\n",
    "print(f\"RDKit descriptors shape: {rdkit_descs.shape}\")\n",
    "\n",
    "# Create DataFrames\n",
    "MORGAN_DF = pd.DataFrame(morgan_fps, index=solvent_names)\n",
    "RDKIT_DF = pd.DataFrame(rdkit_descs, index=solvent_names)\n",
    "\n",
    "print(f\"\\nMorgan DF shape: {MORGAN_DF.shape}\")\n",
    "print(f\"RDKit DF shape: {RDKIT_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dacd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing feature lookups for comparison\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}')\n",
    "print(f'DRFP filtered: {DRFP_FILTERED.shape}')\n",
    "print(f'ACS PCA: {ACS_PCA_DF.shape}')\n",
    "print(f'Morgan: {MORGAN_DF.shape}')\n",
    "print(f'RDKit: {RDKIT_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628331eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce Morgan fingerprint dimensionality using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA on Morgan fingerprints\n",
    "pca_morgan = PCA(n_components=50, random_state=42)\n",
    "morgan_pca = pca_morgan.fit_transform(MORGAN_DF.values)\n",
    "MORGAN_PCA_DF = pd.DataFrame(morgan_pca, index=solvent_names)\n",
    "print(f\"Morgan PCA shape: {MORGAN_PCA_DF.shape}\")\n",
    "print(f\"Explained variance ratio: {pca_morgan.explained_variance_ratio_.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base classes\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def featurize(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9df89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=3, hidden_dims=[128, 64], dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.BatchNorm1d(h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"MLP defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd27066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with Morgan fingerprint features\n",
    "class MorganFeatureModel(BaseModel):\n",
    "    \"\"\"Model using Morgan fingerprints + RDKit descriptors + Arrhenius features.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', use_morgan_pca=True):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.use_morgan_pca = use_morgan_pca\n",
    "        \n",
    "        # Feature sources\n",
    "        self.morgan_df = MORGAN_PCA_DF if use_morgan_pca else MORGAN_DF\n",
    "        self.rdkit_df = RDKIT_DF\n",
    "        self.spange_df = SPANGE_DF\n",
    "        \n",
    "        # Calculate feature dimension\n",
    "        # Arrhenius: time, temp, 1/T, log(t), t/T = 5 features\n",
    "        # Morgan PCA: 50 features\n",
    "        # RDKit: 15 features\n",
    "        # Spange: 13 features\n",
    "        self.feats_dim = 5 + self.morgan_df.shape[1] + self.rdkit_df.shape[1] + self.spange_df.shape[1]\n",
    "        \n",
    "        # MLP\n",
    "        self.mlp = SimpleMLP(\n",
    "            input_dim=self.feats_dim,\n",
    "            output_dim=3,\n",
    "            hidden_dims=[128, 64],\n",
    "            dropout=0.1\n",
    "        )\n",
    "        \n",
    "        # LightGBM\n",
    "        self.lgbm = MultiOutputRegressor(lgb.LGBMRegressor(\n",
    "            num_leaves=31,\n",
    "            learning_rate=0.1,\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            verbosity=-1\n",
    "        ))\n",
    "        \n",
    "        # GP\n",
    "        kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "        self.gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=2, random_state=42)\n",
    "        \n",
    "        # Scaler\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Ensemble weights\n",
    "        self.weights = [0.3, 0.4, 0.3]  # GP, MLP, LGBM\n",
    "        \n",
    "    def _get_features(self, X):\n",
    "        \"\"\"Extract features from input data.\"\"\"\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.data == 'single':\n",
    "            X_morgan = self.morgan_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_rdkit = self.rdkit_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        else:\n",
    "            # Mixed solvents - weighted average\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            A_morgan = self.morgan_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_morgan = self.morgan_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            X_morgan = A_morgan * (1 - pct) + B_morgan * pct\n",
    "            \n",
    "            A_rdkit = self.rdkit_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_rdkit = self.rdkit_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            X_rdkit = A_rdkit * (1 - pct) + B_rdkit * pct\n",
    "            \n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_morgan, X_rdkit, X_spange])\n",
    "        \n",
    "    def train_model(self, train_X, train_Y, num_epochs=100, lr=1e-3, batch_size=32,\n",
    "                    optimizer=torch.optim.Adam, criterion=nn.MSELoss, device=None, verbose=False):\n",
    "        # Get features\n",
    "        X_np = self._get_features(train_X)\n",
    "        train_Y_np = train_Y.values\n",
    "        \n",
    "        # Scale\n",
    "        X_scaled = self.scaler.fit_transform(X_np)\n",
    "        \n",
    "        # DataFrame for GBDT\n",
    "        feature_names = [str(i) for i in range(X_scaled.shape[1])]\n",
    "        X_scaled_df = pd.DataFrame(X_scaled, columns=feature_names)\n",
    "        \n",
    "        # Train LightGBM\n",
    "        self.lgbm.fit(X_scaled_df, train_Y_np)\n",
    "        \n",
    "        # Train GP (on subset for speed)\n",
    "        n_gp = min(200, len(X_scaled))\n",
    "        indices = np.random.choice(len(X_scaled), n_gp, replace=False)\n",
    "        self.gp.fit(X_scaled[indices], train_Y_np[indices, 0])  # GP for first target\n",
    "        \n",
    "        # Train MLP\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "        train_Y_tensor = torch.tensor(train_Y_np, dtype=torch.float32)\n",
    "        \n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.mlp.to(device)\n",
    "        \n",
    "        optimizer_inst = optimizer(self.mlp.parameters(), lr=lr)\n",
    "        train_loader = DataLoader(\n",
    "            TensorDataset(X_tensor, train_Y_tensor),\n",
    "            batch_size=batch_size, shuffle=True, drop_last=True\n",
    "        )\n",
    "        \n",
    "        criterion_inst = criterion()\n",
    "        for epoch in range(num_epochs):\n",
    "            self.mlp.train()\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer_inst.zero_grad()\n",
    "                loss = criterion_inst(self.mlp(inputs), targets)\n",
    "                loss.backward()\n",
    "                optimizer_inst.step()\n",
    "    \n",
    "    def predict(self, test_X):\n",
    "        X_np = self._get_features(test_X)\n",
    "        X_scaled = self.scaler.transform(X_np)\n",
    "        \n",
    "        # DataFrame for GBDT\n",
    "        feature_names = [str(i) for i in range(X_scaled.shape[1])]\n",
    "        X_scaled_df = pd.DataFrame(X_scaled, columns=feature_names)\n",
    "        \n",
    "        # MLP predictions\n",
    "        self.mlp.eval()\n",
    "        device = next(self.mlp.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "            mlp_preds = self.mlp(X_tensor).cpu().numpy()\n",
    "        \n",
    "        # LGBM predictions\n",
    "        lgb_preds = self.lgbm.predict(X_scaled_df)\n",
    "        \n",
    "        # GP predictions\n",
    "        gp_mean = self.gp.predict(X_scaled)\n",
    "        gp_preds = np.column_stack([gp_mean, gp_mean, gp_mean])\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        final_preds = (\n",
    "            self.weights[0] * gp_preds +\n",
    "            self.weights[1] * mlp_preds +\n",
    "            self.weights[2] * lgb_preds\n",
    "        )\n",
    "        \n",
    "        return torch.tensor(final_preds)\n",
    "\n",
    "print(\"MorganFeatureModel defined\")\n",
    "print(f\"Feature dimension: {5 + MORGAN_PCA_DF.shape[1] + RDKIT_DF.shape[1] + SPANGE_DF.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7474953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent data: {X_single.shape}, {Y_single.shape}\")\n",
    "\n",
    "model = MorganFeatureModel(data='single')\n",
    "model.train_model(X_single, Y_single, num_epochs=10)\n",
    "preds = model.predict(X_single[:5])\n",
    "print(f\"Test predictions shape: {preds.shape}\")\n",
    "print(f\"Sample predictions:\\n{preds[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a63651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV\n",
    "import tqdm\n",
    "\n",
    "def compute_cv_score(verbose=True):\n",
    "    \"\"\"Compute CV score with Morgan fingerprint features.\"\"\"\n",
    "    \n",
    "    # Single solvent CV\n",
    "    X_single, Y_single = load_data(\"single_solvent\")\n",
    "    split_generator = generate_leave_one_out_splits(X_single, Y_single)\n",
    "    \n",
    "    single_mse_list = []\n",
    "    for fold_idx, split in enumerate(split_generator):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = MorganFeatureModel(data='single')\n",
    "        model.train_model(train_X, train_Y, num_epochs=100)\n",
    "        \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions_np = predictions.detach().cpu().numpy()\n",
    "        \n",
    "        mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "        single_mse_list.append(mse)\n",
    "        if verbose:\n",
    "            print(f\"Single Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "    \n",
    "    single_cv = np.mean(single_mse_list)\n",
    "    if verbose:\n",
    "        print(f\"\\nSingle Solvent CV MSE: {single_cv:.6f}\")\n",
    "    \n",
    "    # Full data CV\n",
    "    X_full, Y_full = load_data(\"full\")\n",
    "    split_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "    \n",
    "    full_mse_list = []\n",
    "    for fold_idx, split in enumerate(split_generator):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = MorganFeatureModel(data='full')\n",
    "        model.train_model(train_X, train_Y, num_epochs=100)\n",
    "        \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions_np = predictions.detach().cpu().numpy()\n",
    "        \n",
    "        mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "        full_mse_list.append(mse)\n",
    "        if verbose:\n",
    "            print(f\"Full Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "    \n",
    "    full_cv = np.mean(full_mse_list)\n",
    "    if verbose:\n",
    "        print(f\"\\nFull Data CV MSE: {full_cv:.6f}\")\n",
    "    \n",
    "    combined_cv = (single_cv + full_cv) / 2\n",
    "    if verbose:\n",
    "        print(f\"\\n=== Combined CV MSE: {combined_cv:.6f} ===\")\n",
    "    \n",
    "    return single_cv, full_cv, combined_cv\n",
    "\n",
    "print(\"Running CV with Morgan fingerprint features...\")\n",
    "single_cv, full_cv, combined_cv = compute_cv_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import json\n",
    "\n",
    "results = {\n",
    "    'cv_score': float(combined_cv),\n",
    "    'single_cv': float(single_cv),\n",
    "    'full_cv': float(full_cv),\n",
    "    'model': 'MorganFeatureModel (GP+MLP+LGBM with Morgan FP + RDKit + Spange)',\n",
    "    'baseline_cv': 0.008298,\n",
    "    'improvement': f\"{(0.008298 - combined_cv) / 0.008298 * 100:.2f}%\"\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/093_chemprop_pretrained/metrics.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Results saved\")\n",
    "print(f\"Combined CV: {combined_cv:.6f}\")\n",
    "print(f\"Baseline CV: 0.008298\")\n",
    "print(f\"Improvement: {(0.008298 - combined_cv) / 0.008298 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56d4d7d",
   "metadata": {},
   "source": [
    "## Generate Submission (if CV is better than baseline)\n",
    "\n",
    "The following cells follow the official template structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ec5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we should generate submission\n",
    "if combined_cv < 0.008298:\n",
    "    print(f\"CV {combined_cv:.6f} is BETTER than baseline 0.008298!\")\n",
    "    print(\"Generating submission...\")\n",
    "    GENERATE_SUBMISSION = True\n",
    "else:\n",
    "    print(f\"CV {combined_cv:.6f} is WORSE than baseline 0.008298\")\n",
    "    print(\"Not generating submission.\")\n",
    "    GENERATE_SUBMISSION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c551c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MorganFeatureModel(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MorganFeatureModel(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a62a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "# Also save to standard location\n",
    "import shutil\n",
    "import os\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "shutil.copy(\"submission.csv\", \"/home/submission/submission.csv\")\n",
    "print(\"Submission saved!\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(submission.head())\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
