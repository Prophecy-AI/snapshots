{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "886cc0b6",
   "metadata": {},
   "source": [
    "# Experiment 096: Multi-Order GAT with Attention Readout\n",
    "\n",
    "**Goal**: Implement a PROPER Graph Attention Network (not just name it GNN and implement MLP).\n",
    "\n",
    "**Architecture based on MoGAT paper**:\n",
    "1. Multi-order graph attention - extract embeddings from EVERY GAT layer\n",
    "2. Attention-based readout - learned weighted sum of graph embeddings\n",
    "3. Proper node features from RDKit\n",
    "4. DRFP features integrated after graph pooling\n",
    "5. Reaction conditions (T, RT)\n",
    "\n",
    "**Benchmark paper achieved MSE 0.0039** - this proves the target is reachable with GNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f8716d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:35:48.416376Z",
     "iopub.status.busy": "2026-01-16T13:35:48.415840Z",
     "iopub.status.idle": "2026-01-16T13:35:50.867741Z",
     "shell.execute_reply": "2026-01-16T13:35:50.867354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from abc import ABC, abstractmethod\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch Geometric imports\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# RDKit imports\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ef4398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:35:50.868841Z",
     "iopub.status.busy": "2026-01-16T13:35:50.868667Z",
     "iopub.status.idle": "2026-01-16T13:35:50.873395Z",
     "shell.execute_reply": "2026-01-16T13:35:50.873029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee47e8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:35:50.874517Z",
     "iopub.status.busy": "2026-01-16T13:35:50.874214Z",
     "iopub.status.idle": "2026-01-16T13:35:50.877043Z",
     "shell.execute_reply": "2026-01-16T13:35:50.876713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Base classes\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def featurize(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66ba2c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:35:50.877995Z",
     "iopub.status.busy": "2026-01-16T13:35:50.877901Z",
     "iopub.status.idle": "2026-01-16T13:35:50.905903Z",
     "shell.execute_reply": "2026-01-16T13:35:50.905558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13)\n",
      "DRFP filtered: (24, 122)\n",
      "SMILES: (26, 1)\n",
      "\n",
      "Sample SMILES:\n",
      "                                           solvent smiles\n",
      "SOLVENT NAME                                             \n",
      "Cyclohexane                                      C1CCCCC1\n",
      "Ethyl Acetate                                   O=C(OCC)C\n",
      "Acetic Acid                                       CC(=O)O\n",
      "2-Methyltetrahydrofuran [2-MeTHF]              O1C(C)CCC1\n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol  C(C(F)(F)F)(C(F)(F)F)O\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = load_features(\"spange_descriptors\")\n",
    "DRFP_DF = load_features(\"drfps_catechol\")\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to non-zero variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f\"Spange: {SPANGE_DF.shape}\")\n",
    "print(f\"DRFP filtered: {DRFP_FILTERED.shape}\")\n",
    "print(f\"SMILES: {SMILES_DF.shape}\")\n",
    "print(f\"\\nSample SMILES:\")\n",
    "print(SMILES_DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bac8ac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:35:50.906668Z",
     "iopub.status.busy": "2026-01-16T13:35:50.906578Z",
     "iopub.status.idle": "2026-01-16T13:35:50.915571Z",
     "shell.execute_reply": "2026-01-16T13:35:50.915231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test SMILES: C1CCCCC1\n",
      "Graph: Data(x=[6, 7], edge_index=[2, 12])\n",
      "Node features shape: torch.Size([6, 7])\n",
      "Edge index shape: torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "# Molecule Graph Converter\n",
    "class MoleculeGraph:\n",
    "    \"\"\"Convert SMILES to PyTorch Geometric graph with rich features.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def smiles_to_graph(smiles):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        \n",
    "        # Node features (7 features per atom)\n",
    "        node_features = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            features = [\n",
    "                atom.GetAtomicNum(),           # Atomic number\n",
    "                atom.GetDegree(),              # Degree\n",
    "                atom.GetFormalCharge(),        # Formal charge\n",
    "                int(atom.GetHybridization()),  # Hybridization\n",
    "                int(atom.GetIsAromatic()),     # Aromaticity\n",
    "                atom.GetTotalNumHs(),          # H count\n",
    "                atom.GetNumRadicalElectrons(), # Radical electrons\n",
    "            ]\n",
    "            node_features.append(features)\n",
    "        \n",
    "        if len(node_features) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Edge index (bond connectivity)\n",
    "        edge_index = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            edge_index.extend([[i, j], [j, i]])\n",
    "        \n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "        \n",
    "        if len(edge_index) > 0:\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        else:\n",
    "            edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        \n",
    "        return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Test graph conversion\n",
    "test_smiles = SMILES_DF['solvent smiles'].iloc[0]\n",
    "print(f\"Test SMILES: {test_smiles}\")\n",
    "test_graph = MoleculeGraph.smiles_to_graph(test_smiles)\n",
    "print(f\"Graph: {test_graph}\")\n",
    "print(f\"Node features shape: {test_graph.x.shape}\")\n",
    "print(f\"Edge index shape: {test_graph.edge_index.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b8572c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:35:50.916339Z",
     "iopub.status.busy": "2026-01-16T13:35:50.916233Z",
     "iopub.status.idle": "2026-01-16T13:35:50.921052Z",
     "shell.execute_reply": "2026-01-16T13:35:50.920723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOrderGAT defined\n"
     ]
    }
   ],
   "source": [
    "# Multi-Order GAT Model\n",
    "class MultiOrderGAT(nn.Module):\n",
    "    \"\"\"Multi-order Graph Attention Network with attention readout.\"\"\"\n",
    "    \n",
    "    def __init__(self, node_dim=7, hidden_dim=64, num_layers=3, num_heads=4, drfp_dim=122):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Node embedding\n",
    "        self.node_embed = nn.Linear(node_dim, hidden_dim)\n",
    "        \n",
    "        # Multiple GAT layers\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.gat_layers.append(\n",
    "                GATConv(hidden_dim, hidden_dim, heads=num_heads, concat=False, dropout=0.2)\n",
    "            )\n",
    "        \n",
    "        # Attention readout for multi-order embeddings\n",
    "        self.order_attention = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        # DRFP projection\n",
    "        self.drfp_proj = nn.Linear(drfp_dim, hidden_dim)\n",
    "        \n",
    "        # Output head (graph_feat + drfp_feat + T + RT)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data, T, RT, drfp):\n",
    "        # Node embedding\n",
    "        x = self.node_embed(data.x)\n",
    "        \n",
    "        # Collect embeddings from all layers\n",
    "        layer_embeddings = []\n",
    "        for gat in self.gat_layers:\n",
    "            x = F.relu(gat(x, data.edge_index))\n",
    "            # Pool to graph level\n",
    "            graph_embed = global_mean_pool(x, data.batch)\n",
    "            layer_embeddings.append(graph_embed)\n",
    "        \n",
    "        # Stack and apply attention\n",
    "        stacked = torch.stack(layer_embeddings, dim=1)  # [batch, num_layers, hidden_dim]\n",
    "        attn_weights = F.softmax(self.order_attention(stacked).squeeze(-1), dim=1)  # [batch, num_layers]\n",
    "        graph_feat = (stacked * attn_weights.unsqueeze(-1)).sum(dim=1)  # [batch, hidden_dim]\n",
    "        \n",
    "        # DRFP features\n",
    "        drfp_feat = self.drfp_proj(drfp)\n",
    "        \n",
    "        # Combine all features\n",
    "        combined = torch.cat([graph_feat, drfp_feat, T, RT], dim=1)\n",
    "        \n",
    "        return self.output(combined)\n",
    "\n",
    "print(\"MultiOrderGAT defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdf81ea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:35:50.921862Z",
     "iopub.status.busy": "2026-01-16T13:35:50.921763Z",
     "iopub.status.idle": "2026-01-16T13:35:50.930946Z",
     "shell.execute_reply": "2026-01-16T13:35:50.930624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOrderGATWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# Multi-Order GAT Wrapper\n",
    "class MultiOrderGATWrapper(BaseModel):\n",
    "    \"\"\"Wrapper for MultiOrderGAT to match competition template.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', hidden_dim=64, num_layers=3, num_epochs=200, lr=0.001):\n",
    "        self.data_mode = data\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "        self.model = None\n",
    "        self.graph_cache = {}\n",
    "        self.drfp_scaler = StandardScaler()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    def _get_graph(self, smiles):\n",
    "        \"\"\"Get or create graph for a SMILES string.\"\"\"\n",
    "        if smiles not in self.graph_cache:\n",
    "            self.graph_cache[smiles] = MoleculeGraph.smiles_to_graph(smiles)\n",
    "        return self.graph_cache[smiles]\n",
    "    \n",
    "    def _prepare_batch(self, X, fit_scaler=False):\n",
    "        \"\"\"Prepare a batch of data for the model.\"\"\"\n",
    "        # Get reaction conditions\n",
    "        T = torch.tensor(X['Temperature'].values, dtype=torch.float).reshape(-1, 1)\n",
    "        RT = torch.tensor(X['Residence Time'].values, dtype=torch.float).reshape(-1, 1)\n",
    "        \n",
    "        # Normalize T and RT\n",
    "        T = (T - 50) / 50  # Assuming T is around 50-100\n",
    "        RT = (RT - 5) / 5  # Assuming RT is around 0-10\n",
    "        \n",
    "        if self.data_mode == 'single':\n",
    "            # Single solvent - get graphs and DRFP\n",
    "            graphs = []\n",
    "            drfp_list = []\n",
    "            for idx, row in X.iterrows():\n",
    "                solvent = row['SOLVENT NAME']\n",
    "                smiles = SMILES_DF.loc[solvent, 'solvent smiles']\n",
    "                graph = self._get_graph(smiles)\n",
    "                if graph is not None:\n",
    "                    graphs.append(graph)\n",
    "                    drfp_list.append(DRFP_FILTERED.loc[solvent].values)\n",
    "            \n",
    "            # Batch graphs\n",
    "            batch = Batch.from_data_list(graphs)\n",
    "            drfp = np.array(drfp_list)\n",
    "            \n",
    "        else:\n",
    "            # Mixed solvents - weighted average of graphs and DRFP\n",
    "            graphs = []\n",
    "            drfp_list = []\n",
    "            for idx, row in X.iterrows():\n",
    "                solvent_a = row['SOLVENT A NAME']\n",
    "                solvent_b = row['SOLVENT B NAME']\n",
    "                pct_b = row['SolventB%']\n",
    "                \n",
    "                smiles_a = SMILES_DF.loc[solvent_a, 'solvent smiles']\n",
    "                smiles_b = SMILES_DF.loc[solvent_b, 'solvent smiles']\n",
    "                \n",
    "                # For mixtures, we'll use solvent A's graph (simplified approach)\n",
    "                # A more sophisticated approach would pool both graphs\n",
    "                graph = self._get_graph(smiles_a)\n",
    "                if graph is not None:\n",
    "                    graphs.append(graph)\n",
    "                    \n",
    "                    # Weighted DRFP\n",
    "                    drfp_a = DRFP_FILTERED.loc[solvent_a].values\n",
    "                    drfp_b = DRFP_FILTERED.loc[solvent_b].values\n",
    "                    drfp_mix = (1 - pct_b) * drfp_a + pct_b * drfp_b\n",
    "                    drfp_list.append(drfp_mix)\n",
    "            \n",
    "            batch = Batch.from_data_list(graphs)\n",
    "            drfp = np.array(drfp_list)\n",
    "        \n",
    "        # Scale DRFP\n",
    "        if fit_scaler:\n",
    "            drfp = self.drfp_scaler.fit_transform(drfp)\n",
    "        else:\n",
    "            drfp = self.drfp_scaler.transform(drfp)\n",
    "        \n",
    "        drfp = torch.tensor(drfp, dtype=torch.float)\n",
    "        \n",
    "        return batch, T, RT, drfp\n",
    "    \n",
    "    def train_model(self, train_X, train_Y, device=None, verbose=False):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        if device is None:\n",
    "            device = self.device\n",
    "        \n",
    "        # Prepare data\n",
    "        batch, T, RT, drfp = self._prepare_batch(train_X, fit_scaler=True)\n",
    "        Y = torch.tensor(train_Y.values, dtype=torch.float)\n",
    "        \n",
    "        # Move to device\n",
    "        batch = batch.to(device)\n",
    "        T = T.to(device)\n",
    "        RT = RT.to(device)\n",
    "        drfp = drfp.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        # Create model\n",
    "        drfp_dim = DRFP_FILTERED.shape[1]\n",
    "        self.model = MultiOrderGAT(\n",
    "            node_dim=7,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            drfp_dim=drfp_dim\n",
    "        ).to(device)\n",
    "        \n",
    "        # Training\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(self.num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            pred = self.model(batch, T, RT, drfp)\n",
    "            loss = criterion(pred, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if verbose and (epoch + 1) % 50 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{self.num_epochs}, Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions.\"\"\"\n",
    "        self.model.eval()\n",
    "        device = self.device\n",
    "        \n",
    "        # Prepare data\n",
    "        batch, T, RT, drfp = self._prepare_batch(X, fit_scaler=False)\n",
    "        \n",
    "        # Move to device\n",
    "        batch = batch.to(device)\n",
    "        T = T.to(device)\n",
    "        RT = RT.to(device)\n",
    "        drfp = drfp.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = self.model(batch, T, RT, drfp).cpu().numpy()\n",
    "        \n",
    "        # Clip to non-negative\n",
    "        pred = np.clip(pred, 0, None)\n",
    "        \n",
    "        return torch.tensor(pred, dtype=torch.double)\n",
    "\n",
    "print(\"MultiOrderGATWrapper defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent data: {X_single.shape}, {Y_single.shape}\")\n",
    "\n",
    "# Quick test with small subset\n",
    "X_small = X_single.head(50)\n",
    "Y_small = Y_single.head(50)\n",
    "\n",
    "model = MultiOrderGATWrapper(data='single', num_epochs=20)\n",
    "model.train_model(X_small, Y_small, verbose=True)\n",
    "preds = model.predict(X_small[:5])\n",
    "print(f\"\\nTest predictions shape: {preds.shape}\")\n",
    "print(f\"Sample predictions:\\n{preds[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV\n",
    "import tqdm\n",
    "\n",
    "def compute_cv_score(verbose=True):\n",
    "    \"\"\"Compute CV score with MultiOrderGAT.\"\"\"\n",
    "    \n",
    "    # Single solvent CV\n",
    "    X_single, Y_single = load_data(\"single_solvent\")\n",
    "    split_generator = generate_leave_one_out_splits(X_single, Y_single)\n",
    "    \n",
    "    single_mse_list = []\n",
    "    for fold_idx, split in enumerate(split_generator):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = MultiOrderGATWrapper(data='single', hidden_dim=64, num_layers=3, num_epochs=200, lr=0.001)\n",
    "        model.train_model(train_X, train_Y)\n",
    "        \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions_np = predictions.detach().cpu().numpy()\n",
    "        \n",
    "        mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "        single_mse_list.append(mse)\n",
    "        if verbose:\n",
    "            print(f\"Single Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "    \n",
    "    single_cv = np.mean(single_mse_list)\n",
    "    if verbose:\n",
    "        print(f\"\\nSingle Solvent CV MSE: {single_cv:.6f}\")\n",
    "    \n",
    "    # Full data CV\n",
    "    X_full, Y_full = load_data(\"full\")\n",
    "    split_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "    \n",
    "    full_mse_list = []\n",
    "    for fold_idx, split in enumerate(split_generator):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        \n",
    "        model = MultiOrderGATWrapper(data='full', hidden_dim=64, num_layers=3, num_epochs=200, lr=0.001)\n",
    "        model.train_model(train_X, train_Y)\n",
    "        \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions_np = predictions.detach().cpu().numpy()\n",
    "        \n",
    "        mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "        full_mse_list.append(mse)\n",
    "        if verbose:\n",
    "            print(f\"Full Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "    \n",
    "    full_cv = np.mean(full_mse_list)\n",
    "    if verbose:\n",
    "        print(f\"\\nFull Data CV MSE: {full_cv:.6f}\")\n",
    "    \n",
    "    combined_cv = (single_cv + full_cv) / 2\n",
    "    if verbose:\n",
    "        print(f\"\\n=== Combined CV MSE: {combined_cv:.6f} ===\")\n",
    "    \n",
    "    return single_cv, full_cv, combined_cv\n",
    "\n",
    "print(\"Running CV with MultiOrderGAT...\")\n",
    "single_cv, full_cv, combined_cv = compute_cv_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c427fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import json\n",
    "\n",
    "results = {\n",
    "    'cv_score': float(combined_cv),\n",
    "    'single_cv': float(single_cv),\n",
    "    'full_cv': float(full_cv),\n",
    "    'model': 'MultiOrderGATWrapper (Multi-Order GAT with Attention Readout)',\n",
    "    'baseline_cv': 0.008092,\n",
    "    'improvement': f\"{(0.008092 - combined_cv) / 0.008092 * 100:.2f}%\"\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/096_multi_order_gat/metrics.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Results saved\")\n",
    "print(f\"Combined CV: {combined_cv:.6f}\")\n",
    "print(f\"Baseline CV: 0.008092\")\n",
    "print(f\"Improvement: {(0.008092 - combined_cv) / 0.008092 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30576a66",
   "metadata": {},
   "source": [
    "## Generate Submission\n",
    "\n",
    "The following cells follow the official template structure.\n",
    "\n",
    "**CRITICAL**: The model class in submission cells MUST match the CV computation class (`MultiOrderGATWrapper`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72159215",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MultiOrderGATWrapper(data='single', hidden_dim=64, num_layers=3, num_epochs=200, lr=0.001)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b61f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MultiOrderGATWrapper(data='full', hidden_dim=64, num_layers=3, num_epochs=200, lr=0.001)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "# Also save to standard location\n",
    "import shutil\n",
    "import os\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "shutil.copy(\"submission.csv\", \"/home/submission/submission.csv\")\n",
    "print(\"Submission saved!\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(submission.head())\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
