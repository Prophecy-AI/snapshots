{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91873a14",
   "metadata": {},
   "source": [
    "# Experiment 065: Multi-Task Gaussian Process\n",
    "\n",
    "**Goal:** Implement MTGP to potentially change the CV-LB relationship.\n",
    "\n",
    "**Key Insight:** The benchmark achieved MSE 0.0039 using multi-task GP. MTGP can \"borrow statistical strength\" from related tasks (solvents) to improve predictions on unseen solvents.\n",
    "\n",
    "**Approach:**\n",
    "1. Use GPyTorch for efficient MTGP implementation\n",
    "2. Treat each target (Product 2, Product 3, SM) as a task\n",
    "3. Learn shared covariance across tasks\n",
    "4. Ensemble with MLP+LGBM for robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350d2542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:51:29.064511Z",
     "iopub.status.busy": "2026-01-16T03:51:29.063997Z",
     "iopub.status.idle": "2026-01-16T03:51:30.701042Z",
     "shell.execute_reply": "2026-01-16T03:51:30.700648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1bd3aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:51:30.702194Z",
     "iopub.status.busy": "2026-01-16T03:51:30.702049Z",
     "iopub.status.idle": "2026-01-16T03:51:30.706420Z",
     "shell.execute_reply": "2026-01-16T03:51:30.706033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0dab78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:51:30.707752Z",
     "iopub.status.busy": "2026-01-16T03:51:30.707382Z",
     "iopub.status.idle": "2026-01-16T03:51:30.735479Z",
     "shell.execute_reply": "2026-01-16T03:51:30.735139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP filtered: (24, 122), ACS PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2105271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:51:30.736484Z",
     "iopub.status.busy": "2026-01-16T03:51:30.736401Z",
     "iopub.status.idle": "2026-01-16T03:51:30.740515Z",
     "shell.execute_reply": "2026-01-16T03:51:30.740139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleFeaturizer defined with 18 features\n"
     ]
    }
   ],
   "source": [
    "# Featurizer class\n",
    "class SimpleFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1]  # 18 features\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange])\n",
    "\n",
    "print(f'SimpleFeaturizer defined with {SimpleFeaturizer().feats_dim} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd0896e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:51:30.741454Z",
     "iopub.status.busy": "2026-01-16T03:51:30.741356Z",
     "iopub.status.idle": "2026-01-16T03:51:30.793849Z",
     "shell.execute_reply": "2026-01-16T03:51:30.793526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultitaskGPModel defined\n"
     ]
    }
   ],
   "source": [
    "# Multi-Task GP using GPyTorch\n",
    "import gpytorch\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import MultitaskGaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.distributions import MultitaskMultivariateNormal\n",
    "\n",
    "class MultitaskGPModel(ExactGP):\n",
    "    \"\"\"Multi-task GP that learns shared covariance across targets.\"\"\"\n",
    "    def __init__(self, train_x, train_y, likelihood, num_tasks=3):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ConstantMean(), num_tasks=num_tasks\n",
    "        )\n",
    "        # Use MultitaskKernel with rank=1 for efficiency\n",
    "        self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
    "            gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()),\n",
    "            num_tasks=num_tasks,\n",
    "            rank=1\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultitaskMultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "print('MultitaskGPModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25eec5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:51:30.794779Z",
     "iopub.status.busy": "2026-01-16T03:51:30.794631Z",
     "iopub.status.idle": "2026-01-16T03:51:30.800135Z",
     "shell.execute_reply": "2026-01-16T03:51:30.799789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTGPWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# Multi-Task GP Wrapper\n",
    "class MTGPWrapper:\n",
    "    def __init__(self, data='single', n_epochs=100):\n",
    "        self.data_type = data\n",
    "        self.n_epochs = n_epochs\n",
    "        self.featurizer = SimpleFeaturizer(mixed=(data=='full'))\n",
    "        self.model = None\n",
    "        self.likelihood = None\n",
    "        self.scaler = None\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Featurize\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_std, X_flip])\n",
    "            y_all = np.vstack([y_vals, y_vals])\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "        \n",
    "        # Scale features\n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X_all)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        train_x = torch.tensor(X_scaled, dtype=torch.double)\n",
    "        train_y = torch.tensor(y_all, dtype=torch.double)\n",
    "        \n",
    "        # Initialize likelihood and model\n",
    "        self.likelihood = MultitaskGaussianLikelihood(num_tasks=3)\n",
    "        self.model = MultitaskGPModel(train_x, train_y, self.likelihood, num_tasks=3)\n",
    "        \n",
    "        # Training\n",
    "        self.model.train()\n",
    "        self.likelihood.train()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.1)\n",
    "        mll = ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
    "        \n",
    "        for i in range(self.n_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            output = self.model(train_x)\n",
    "            loss = -mll(output, train_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X_std = self.featurizer.featurize(X_test, flip=False)\n",
    "        X_scaled = self.scaler.transform(X_std)\n",
    "        test_x = torch.tensor(X_scaled, dtype=torch.double)\n",
    "        \n",
    "        self.model.eval()\n",
    "        self.likelihood.eval()\n",
    "        \n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            predictions = self.likelihood(self.model(test_x))\n",
    "            mean = predictions.mean\n",
    "        \n",
    "        return torch.clamp(mean, 0, 1)\n",
    "\n",
    "print('MTGPWrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "892ad4ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:51:30.801008Z",
     "iopub.status.busy": "2026-01-16T03:51:30.800907Z",
     "iopub.status.idle": "2026-01-16T03:51:30.808981Z",
     "shell.execute_reply": "2026-01-16T03:51:30.808611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeightedMLPEnsemble defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model (same as exp_030)\n",
    "class MLPModelInternal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[32, 16], output_dim=3, dropout=0.05):\n",
    "        super(MLPModelInternal, self).__init__()\n",
    "        layers = [nn.BatchNorm1d(input_dim)]\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([nn.Linear(prev_dim, h_dim), nn.BatchNorm1d(h_dim), nn.ReLU(), nn.Dropout(dropout)])\n",
    "            prev_dim = h_dim\n",
    "        layers.extend([nn.Linear(prev_dim, output_dim), nn.Sigmoid()])\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class WeightedMLPEnsemble:\n",
    "    def __init__(self, hidden_dims=[32, 16], n_models=3, data='single'):\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.n_models = n_models\n",
    "        self.data_type = data\n",
    "        self.featurizer = SimpleFeaturizer(mixed=(data=='full'))\n",
    "        self.models = []\n",
    "        self.scaler = None\n",
    "\n",
    "    def train_model(self, X_train, y_train, epochs=150, batch_size=32, lr=5e-4):\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_std, X_flip])\n",
    "            y_all = np.vstack([y_vals, y_vals])\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X_all)\n",
    "        \n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.double)\n",
    "        y_tensor = torch.tensor(y_all, dtype=torch.double)\n",
    "        \n",
    "        input_dim = X_tensor.shape[1]\n",
    "        self.models = []\n",
    "        \n",
    "        for i in range(self.n_models):\n",
    "            model = MLPModelInternal(input_dim, self.hidden_dims, 3, dropout=0.05).double()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "            criterion = nn.MSELoss()\n",
    "            \n",
    "            dataset = TensorDataset(X_tensor, y_tensor)\n",
    "            loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                for X_batch, y_batch in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(X_batch)\n",
    "                    loss = criterion(pred, y_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_std = self.featurizer.featurize(X_test, flip=False)\n",
    "        X_scaled = self.scaler.transform(X_std)\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.double)\n",
    "        \n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for model in self.models:\n",
    "                preds.append(model(X_tensor))\n",
    "        \n",
    "        return torch.clamp(torch.stack(preds).mean(dim=0), 0, 1)\n",
    "\n",
    "print('WeightedMLPEnsemble defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d200536e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:51:30.809994Z",
     "iopub.status.busy": "2026-01-16T03:51:30.809895Z",
     "iopub.status.idle": "2026-01-16T03:51:30.814581Z",
     "shell.execute_reply": "2026-01-16T03:51:30.814200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Wrapper\n",
    "class LGBMWrapper:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.featurizer = SimpleFeaturizer(mixed=(data=='full'))\n",
    "        self.models = []\n",
    "        self.scaler = None\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_std, X_flip])\n",
    "            y_all = np.vstack([y_vals, y_vals])\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X_all)\n",
    "        \n",
    "        self.models = []\n",
    "        params = {'objective': 'regression', 'metric': 'mse', 'boosting_type': 'gbdt',\n",
    "                  'num_leaves': 31, 'learning_rate': 0.05, 'feature_fraction': 0.9,\n",
    "                  'bagging_fraction': 0.8, 'bagging_freq': 5, 'verbose': -1, 'seed': 42}\n",
    "        \n",
    "        for i in range(3):\n",
    "            train_data = lgb.Dataset(X_scaled, label=y_all[:, i])\n",
    "            model = lgb.train(params, train_data, num_boost_round=100)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_std = self.featurizer.featurize(X_test, flip=False)\n",
    "        X_scaled = self.scaler.transform(X_std)\n",
    "        \n",
    "        preds = []\n",
    "        for model in self.models:\n",
    "            preds.append(model.predict(X_scaled))\n",
    "        \n",
    "        return torch.clamp(torch.tensor(np.column_stack(preds), dtype=torch.double), 0, 1)\n",
    "\n",
    "print('LGBMWrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8025a826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:51:30.815421Z",
     "iopub.status.busy": "2026-01-16T03:51:30.815330Z",
     "iopub.status.idle": "2026-01-16T03:51:30.819092Z",
     "shell.execute_reply": "2026-01-16T03:51:30.818735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTGPMLPLGBMEnsemble defined: MTGP(0.3) + MLP(0.4) + LGBM(0.3)\n"
     ]
    }
   ],
   "source": [
    "# MTGP + MLP + LGBM Ensemble\n",
    "class MTGPMLPLGBMEnsemble:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mtgp = MTGPWrapper(data=data, n_epochs=50)  # Reduced epochs for speed\n",
    "        self.mlp = WeightedMLPEnsemble(hidden_dims=[32, 16], n_models=3, data=data)\n",
    "        self.lgbm = LGBMWrapper(data=data)\n",
    "        # Weights: MTGP 0.3, MLP 0.4, LGBM 0.3\n",
    "        self.weights = {'mtgp': 0.3, 'mlp': 0.4, 'lgbm': 0.3}\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        self.mtgp.train_model(X_train, y_train)\n",
    "        self.mlp.train_model(X_train, y_train)\n",
    "        self.lgbm.train_model(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        mtgp_pred = self.mtgp.predict(X_test)\n",
    "        mlp_pred = self.mlp.predict(X_test)\n",
    "        lgbm_pred = self.lgbm.predict(X_test)\n",
    "        \n",
    "        combined = (self.weights['mtgp'] * mtgp_pred + \n",
    "                    self.weights['mlp'] * mlp_pred + \n",
    "                    self.weights['lgbm'] * lgbm_pred)\n",
    "        return torch.clamp(combined, 0, 1)\n",
    "\n",
    "print('MTGPMLPLGBMEnsemble defined: MTGP(0.3) + MLP(0.4) + LGBM(0.3)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb3c8f7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:51:30.819852Z",
     "iopub.status.busy": "2026-01-16T03:51:30.819763Z",
     "iopub.status.idle": "2026-01-16T03:51:43.232070Z",
     "shell.execute_reply": "2026-01-16T03:51:43.231551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on one fold...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fold MSE: 0.041903\n",
      "Predictions shape: torch.Size([37, 3])\n"
     ]
    }
   ],
   "source": [
    "# Quick test on one fold\n",
    "print('Testing on one fold...')\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "split_gen = generate_leave_one_out_splits(X, Y)\n",
    "(train_X, train_Y), (test_X, test_Y) = next(split_gen)\n",
    "\n",
    "model = MTGPMLPLGBMEnsemble(data='single')\n",
    "model.train_model(train_X, train_Y)\n",
    "preds = model.predict(test_X)\n",
    "\n",
    "mse = ((preds.numpy() - test_Y.values) ** 2).mean()\n",
    "print(f'Test fold MSE: {mse:.6f}')\n",
    "print(f'Predictions shape: {preds.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MTGPMLPLGBMEnsemble(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MTGPMLPLGBMEnsemble(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV CALCULATION - This cell is AFTER the final submission cell\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "submission.to_csv('/home/submission/submission.csv', index=True)\n",
    "\n",
    "# Single solvent CV\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "split_gen = list(generate_leave_one_out_splits(X_single, Y_single))\n",
    "all_y_true, all_y_pred = [], []\n",
    "for fold_idx, split in enumerate(split_gen):\n",
    "    (_, _), (_, test_Y) = split\n",
    "    fold_preds = submission_single_solvent[submission_single_solvent['fold'] == fold_idx]\n",
    "    all_y_true.append(test_Y.values)\n",
    "    all_y_pred.append(fold_preds[['target_1', 'target_2', 'target_3']].values)\n",
    "mse_single = mean_squared_error(np.vstack(all_y_true), np.vstack(all_y_pred))\n",
    "\n",
    "# Full data CV\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "split_gen = list(generate_leave_one_ramp_out_splits(X_full, Y_full))\n",
    "all_y_true, all_y_pred = [], []\n",
    "for fold_idx, split in enumerate(split_gen):\n",
    "    (_, _), (_, test_Y) = split\n",
    "    fold_preds = submission_full_data[submission_full_data['fold'] == fold_idx]\n",
    "    all_y_true.append(test_Y.values)\n",
    "    all_y_pred.append(fold_preds[['target_1', 'target_2', 'target_3']].values)\n",
    "mse_full = mean_squared_error(np.vstack(all_y_true), np.vstack(all_y_pred))\n",
    "\n",
    "print(f'Single Solvent CV MSE: {mse_single:.6f}')\n",
    "print(f'Full Data CV MSE: {mse_full:.6f}')\n",
    "print(f'Submission saved with {len(submission)} rows')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
