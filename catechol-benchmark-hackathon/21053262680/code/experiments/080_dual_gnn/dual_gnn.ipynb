{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b908ee",
   "metadata": {},
   "source": [
    "# Dual-Encoder GNN with Fixed Mixture Handling\n",
    "\n",
    "**CRITICAL BUG FIX**: Previous GNN (exp_081) only used Solvent A's graph for mixtures, completely ignoring Solvent B. This means 65% of the data (1227 full data samples) was modeled with incomplete information.\n",
    "\n",
    "**This implementation fixes the bug by:**\n",
    "1. Using a shared GNN encoder for both solvents\n",
    "2. Encoding BOTH Solvent A and Solvent B graphs\n",
    "3. Combining embeddings with weighted pooling: `(1-pct_b)*emb_a + pct_b*emb_b`\n",
    "4. For single solvent data: pct_b=0, so only emb_a is used\n",
    "\n",
    "**Expected outcome**: If mixture handling is fixed, GNN should achieve CV closer to tabular (0.008-0.012). The benchmark achieved MSE 0.0039 with proper GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac37638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:49:02.961286Z",
     "iopub.status.busy": "2026-01-16T09:49:02.960765Z",
     "iopub.status.idle": "2026-01-16T09:49:04.144701Z",
     "shell.execute_reply": "2026-01-16T09:49:04.144273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9986b6ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:49:04.146222Z",
     "iopub.status.busy": "2026-01-16T09:49:04.145775Z",
     "iopub.status.idle": "2026-01-16T09:49:05.006015Z",
     "shell.execute_reply": "2026-01-16T09:49:05.005622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Geometric imports successful\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Geometric imports\n",
    "from torch_geometric.utils import from_smiles\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "\n",
    "print('PyTorch Geometric imports successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fad359c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:49:05.007195Z",
     "iopub.status.busy": "2026-01-16T09:49:05.007029Z",
     "iopub.status.idle": "2026-01-16T09:49:05.011302Z",
     "shell.execute_reply": "2026-01-16T09:49:05.010944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254a8224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:49:05.012177Z",
     "iopub.status.busy": "2026-01-16T09:49:05.012073Z",
     "iopub.status.idle": "2026-01-16T09:49:05.108913Z",
     "shell.execute_reply": "2026-01-16T09:49:05.108528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES lookup shape: (26, 1)\n",
      "\n",
      "Pre-computing molecular graphs...\n",
      "  Cyclohexane: 6 atoms\n",
      "  Ethyl Acetate: 6 atoms\n",
      "  Acetic Acid: 4 atoms\n",
      "  2-Methyltetrahydrofuran [2-MeTHF]: 6 atoms\n",
      "  1,1,1,3,3,3-Hexafluoropropan-2-ol: 10 atoms\n",
      "  IPA [Propan-2-ol]: 4 atoms\n",
      "  Ethanol: 3 atoms\n",
      "  Methanol: 2 atoms\n",
      "  Ethylene Glycol [1,2-Ethanediol]: 4 atoms\n",
      "  Acetonitrile: 3 atoms\n",
      "  Water: 1 atoms\n",
      "  Diethyl Ether [Ether]: 5 atoms\n",
      "  MTBE [tert-Butylmethylether]: 6 atoms\n",
      "  Dimethyl Carbonate: 6 atoms\n",
      "  tert-Butanol [2-Methylpropan-2-ol]: 5 atoms\n",
      "  DMA [N,N-Dimethylacetamide]: 6 atoms\n",
      "  2,2,2-Trifluoroethanol: 6 atoms\n",
      "  Dihydrolevoglucosenone (Cyrene): 9 atoms\n",
      "  Decanol: 11 atoms\n",
      "  Butanone [MEK]: 5 atoms\n",
      "  Ethyl Lactate: 8 atoms\n",
      "  Methyl Propionate: 6 atoms\n",
      "  THF [Tetrahydrofuran]: 5 atoms\n",
      "  Water.Acetonitrile: 4 atoms\n",
      "  Acetonitrile.Acetic Acid: 7 atoms\n",
      "  Water.2,2,2-Trifluoroethanol: 7 atoms\n",
      "\n",
      "Total solvents with graphs: 26\n"
     ]
    }
   ],
   "source": [
    "# Load SMILES and pre-compute molecular graphs\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "print(f'SMILES lookup shape: {SMILES_DF.shape}')\n",
    "\n",
    "# Pre-compute molecular graphs for all solvents\n",
    "print('\\nPre-computing molecular graphs...')\n",
    "SOLVENT_GRAPHS = {}\n",
    "for solvent_name, row in SMILES_DF.iterrows():\n",
    "    smiles = row['solvent smiles']\n",
    "    try:\n",
    "        graph = from_smiles(smiles)\n",
    "        SOLVENT_GRAPHS[solvent_name] = graph\n",
    "        print(f'  {solvent_name}: {graph.x.shape[0]} atoms')\n",
    "    except Exception as e:\n",
    "        print(f'  ERROR for {solvent_name}: {e}')\n",
    "\n",
    "print(f'\\nTotal solvents with graphs: {len(SOLVENT_GRAPHS)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a1d577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:49:05.109909Z",
     "iopub.status.busy": "2026-01-16T09:49:05.109808Z",
     "iopub.status.idle": "2026-01-16T09:49:05.115363Z",
     "shell.execute_reply": "2026-01-16T09:49:05.114998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DualGNN defined\n"
     ]
    }
   ],
   "source": [
    "# Dual-Encoder GNN Model - FIXES THE MIXTURE BUG\n",
    "class DualGNN(nn.Module):\n",
    "    \"\"\"GNN that properly handles both single solvents and mixtures.\n",
    "    \n",
    "    For mixtures: Encodes BOTH Solvent A and Solvent B, then combines\n",
    "    with weighted pooling based on mixture percentage.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=9, hidden_dim=64, out_dim=3):\n",
    "        super().__init__()\n",
    "        # Shared GNN encoder for both solvents\n",
    "        self.conv1 = GCNConv(in_channels, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        # MLP head: graph_emb (hidden_dim) + process_feats (5)\n",
    "        self.fc1 = nn.Linear(hidden_dim + 5, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def encode_graph(self, data):\n",
    "        \"\"\"Encode a single molecular graph to a fixed-size embedding.\"\"\"\n",
    "        x, edge_index, batch = data.x.float(), data.edge_index, data.batch\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Graph-level readout\n",
    "        return global_mean_pool(x, batch)\n",
    "        \n",
    "    def forward(self, graph_a, graph_b, pct_b, process_features):\n",
    "        \"\"\"Forward pass with proper mixture handling.\n",
    "        \n",
    "        Args:\n",
    "            graph_a: Batched graph for Solvent A\n",
    "            graph_b: Batched graph for Solvent B (same as A for single solvent)\n",
    "            pct_b: Fraction of Solvent B (0 for single solvent)\n",
    "            process_features: [T, RT, 1/T, ln(RT), interaction]\n",
    "        \"\"\"\n",
    "        # Encode BOTH solvents\n",
    "        emb_a = self.encode_graph(graph_a)\n",
    "        emb_b = self.encode_graph(graph_b)\n",
    "        \n",
    "        # Weighted combination based on mixture percentage\n",
    "        # pct_b shape: [batch_size]\n",
    "        pct_b = pct_b.unsqueeze(1)  # [batch_size, 1]\n",
    "        mixture_emb = (1 - pct_b) * emb_a + pct_b * emb_b\n",
    "        \n",
    "        # Concatenate with process features\n",
    "        x = torch.cat([mixture_emb, process_features], dim=1)\n",
    "        \n",
    "        # MLP head\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))  # Yields are in [0, 1]\n",
    "        \n",
    "        return x\n",
    "\n",
    "print('DualGNN defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e243f65e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:49:05.116415Z",
     "iopub.status.busy": "2026-01-16T09:49:05.116307Z",
     "iopub.status.idle": "2026-01-16T09:49:05.122197Z",
     "shell.execute_reply": "2026-01-16T09:49:05.121859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SolventDataset and collate_fn defined\n"
     ]
    }
   ],
   "source": [
    "# Custom Dataset for proper batching\n",
    "class SolventDataset:\n",
    "    def __init__(self, X, Y, data_type='single'):\n",
    "        self.X = X.reset_index(drop=True)\n",
    "        self.Y = Y.reset_index(drop=True) if Y is not None else None\n",
    "        self.data_type = data_type\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.X.iloc[idx]\n",
    "        \n",
    "        # Process features\n",
    "        T = row['Temperature']\n",
    "        RT = row['Residence Time']\n",
    "        T_K = T + 273.15\n",
    "        inv_T = 1000.0 / T_K\n",
    "        ln_RT = np.log(RT + 1e-6)\n",
    "        interaction = inv_T * ln_RT\n",
    "        process_feats = torch.tensor([T, RT, inv_T, ln_RT, interaction], dtype=torch.float)\n",
    "        \n",
    "        if self.data_type == 'single':\n",
    "            solvent_name = row['SOLVENT NAME']\n",
    "            graph_a = SOLVENT_GRAPHS[solvent_name].clone()\n",
    "            graph_b = SOLVENT_GRAPHS[solvent_name].clone()  # Same as A for single\n",
    "            pct_b = torch.tensor(0.0, dtype=torch.float)\n",
    "        else:\n",
    "            solvent_a = row['SOLVENT A NAME']\n",
    "            solvent_b = row['SOLVENT B NAME']\n",
    "            graph_a = SOLVENT_GRAPHS[solvent_a].clone()\n",
    "            graph_b = SOLVENT_GRAPHS[solvent_b].clone()\n",
    "            pct_b = torch.tensor(row['SolventB%'], dtype=torch.float)\n",
    "        \n",
    "        if self.Y is not None:\n",
    "            y = torch.tensor(self.Y.iloc[idx].values, dtype=torch.float)\n",
    "            return graph_a, graph_b, pct_b, process_feats, y\n",
    "        else:\n",
    "            return graph_a, graph_b, pct_b, process_feats\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for batching graphs.\"\"\"\n",
    "    if len(batch[0]) == 5:  # With labels\n",
    "        graphs_a, graphs_b, pct_bs, process_feats, ys = zip(*batch)\n",
    "        batch_a = Batch.from_data_list(graphs_a)\n",
    "        batch_b = Batch.from_data_list(graphs_b)\n",
    "        pct_b = torch.stack(pct_bs)\n",
    "        process_feats = torch.stack(process_feats)\n",
    "        y = torch.stack(ys)\n",
    "        return batch_a, batch_b, pct_b, process_feats, y\n",
    "    else:  # Without labels\n",
    "        graphs_a, graphs_b, pct_bs, process_feats = zip(*batch)\n",
    "        batch_a = Batch.from_data_list(graphs_a)\n",
    "        batch_b = Batch.from_data_list(graphs_b)\n",
    "        pct_b = torch.stack(pct_bs)\n",
    "        process_feats = torch.stack(process_feats)\n",
    "        return batch_a, batch_b, pct_b, process_feats\n",
    "\n",
    "print('SolventDataset and collate_fn defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ad82ec0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:49:05.123221Z",
     "iopub.status.busy": "2026-01-16T09:49:05.123119Z",
     "iopub.status.idle": "2026-01-16T09:49:05.129478Z",
     "shell.execute_reply": "2026-01-16T09:49:05.129117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DualGNNWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# Model Wrapper\n",
    "class DualGNNWrapper:\n",
    "    def __init__(self, data='single', hidden_dim=64, lr=0.001, epochs=100, batch_size=32):\n",
    "        self.data = data\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = None\n",
    "        self.train_mean = None\n",
    "        \n",
    "    def train_model(self, X, Y):\n",
    "        \"\"\"Train the dual-encoder GNN.\"\"\"\n",
    "        self.train_mean = Y.mean().values\n",
    "        \n",
    "        # Create dataset and dataloader\n",
    "        dataset = SolventDataset(X, Y, data_type=self.data)\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=self.batch_size, shuffle=True, collate_fn=collate_fn\n",
    "        )\n",
    "        \n",
    "        # Create model\n",
    "        self.model = DualGNN(in_channels=9, hidden_dim=self.hidden_dim, out_dim=3).to(device)\n",
    "        \n",
    "        # Training setup\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Training loop\n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0\n",
    "            for batch in loader:\n",
    "                batch_a, batch_b, pct_b, process_feats, y = batch\n",
    "                batch_a = batch_a.to(device)\n",
    "                batch_b = batch_b.to(device)\n",
    "                pct_b = pct_b.to(device)\n",
    "                process_feats = process_feats.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                out = self.model(batch_a, batch_b, pct_b, process_feats)\n",
    "                loss = criterion(out, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions.\"\"\"\n",
    "        dataset = SolventDataset(X, None, data_type=self.data)\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=self.batch_size, shuffle=False, collate_fn=collate_fn\n",
    "        )\n",
    "        \n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                batch_a, batch_b, pct_b, process_feats = batch\n",
    "                batch_a = batch_a.to(device)\n",
    "                batch_b = batch_b.to(device)\n",
    "                pct_b = pct_b.to(device)\n",
    "                process_feats = process_feats.to(device)\n",
    "                \n",
    "                out = self.model(batch_a, batch_b, pct_b, process_feats)\n",
    "                all_preds.append(out.cpu())\n",
    "        \n",
    "        return torch.cat(all_preds, dim=0)\n",
    "\n",
    "print('DualGNNWrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2453742f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:49:15.343206Z",
     "iopub.status.busy": "2026-01-16T09:49:15.342686Z",
     "iopub.status.idle": "2026-01-16T09:49:15.930711Z",
     "shell.execute_reply": "2026-01-16T09:49:15.930312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DualGNN model...\n",
      "Single solvent data: X=(656, 3), Y=(656, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions shape: torch.Size([10, 3])\n",
      "Test predictions (first 3):\n",
      "tensor([[0.8865, 0.0260, 0.4064],\n",
      "        [0.8678, 0.0271, 0.3886],\n",
      "        [0.8394, 0.0282, 0.3650]])\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "print('Testing DualGNN model...')\n",
    "X_single, Y_single = load_data('single_solvent')\n",
    "print(f'Single solvent data: X={X_single.shape}, Y={Y_single.shape}')\n",
    "\n",
    "# Test on a small subset\n",
    "test_model = DualGNNWrapper(data='single', epochs=5, batch_size=32)\n",
    "test_model.train_model(X_single.head(100), Y_single.head(100))\n",
    "test_preds = test_model.predict(X_single.head(10))\n",
    "print(f'Test predictions shape: {test_preds.shape}')\n",
    "print(f'Test predictions (first 3):\\n{test_preds[:3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f471cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for single solvent data\n",
    "print(\"=\"*60)\n",
    "print(\"Cross-validation: Single Solvent Data (Leave-One-Out)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent data: X={X_single.shape}, Y={Y_single.shape}\")\n",
    "\n",
    "all_mse_single = []\n",
    "for (train_X, train_Y), (test_X, test_Y) in tqdm.tqdm(generate_leave_one_out_splits(X_single, Y_single), total=24):\n",
    "    model = DualGNNWrapper(data='single', epochs=100, batch_size=32, lr=0.001)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mse = np.mean((preds - test_Y.values) ** 2)\n",
    "    all_mse_single.append(mse)\n",
    "\n",
    "mse_single = np.mean(all_mse_single)\n",
    "print(f\"\\nSingle Solvent MSE: {mse_single:.6f} (+/- {np.std(all_mse_single):.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51031e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for full data (MIXTURE DATA - THE KEY TEST)\n",
    "print(\"=\"*60)\n",
    "print(\"Cross-validation: Full Data (Leave-One-Ramp-Out)\")\n",
    "print(\"THIS IS THE KEY TEST - Mixture handling should now work!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "print(f\"Full data: X={X_full.shape}, Y={Y_full.shape}\")\n",
    "\n",
    "all_mse_full = []\n",
    "for (train_X, train_Y), (test_X, test_Y) in tqdm.tqdm(generate_leave_one_ramp_out_splits(X_full, Y_full), total=13):\n",
    "    model = DualGNNWrapper(data='full', epochs=100, batch_size=32, lr=0.001)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mse = np.mean((preds - test_Y.values) ** 2)\n",
    "    all_mse_full.append(mse)\n",
    "\n",
    "mse_full = np.mean(all_mse_full)\n",
    "print(f\"\\nFull Data MSE: {mse_full:.6f} (+/- {np.std(all_mse_full):.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ea7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall MSE\n",
    "N_single = len(X_single)\n",
    "N_full = len(X_full)\n",
    "N_total = N_single + N_full\n",
    "\n",
    "overall_mse = (mse_single * N_single + mse_full * N_full) / N_total\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDual-Encoder GNN (Fixed Mixture Handling):\")\n",
    "print(f\"  Single Solvent MSE: {mse_single:.6f}\")\n",
    "print(f\"  Full Data MSE: {mse_full:.6f}\")\n",
    "print(f\"  Overall MSE: {overall_mse:.6f}\")\n",
    "\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Previous GNN (broken mixture): 0.026222\")\n",
    "print(f\"  Best tabular (GP+MLP+LGBM): 0.008298\")\n",
    "print(f\"  This GNN vs Previous: {(overall_mse - 0.026222) / 0.026222 * 100:.2f}%\")\n",
    "print(f\"  This GNN vs Best tabular: {(overall_mse - 0.008298) / 0.008298 * 100:.2f}%\")\n",
    "\n",
    "# Expected LB based on CV-LB relationship\n",
    "expected_lb = 4.31 * overall_mse + 0.0525\n",
    "print(f\"\\nExpected LB (based on CV-LB line): {expected_lb:.4f}\")\n",
    "print(f\"Target LB: 0.0347\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc161237",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = DualGNNWrapper(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = DualGNNWrapper(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
