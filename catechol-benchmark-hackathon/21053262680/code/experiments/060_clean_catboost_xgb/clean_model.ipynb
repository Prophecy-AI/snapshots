{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e817b3c",
   "metadata": {},
   "source": [
    "# Experiment 060: Clean CatBoost + XGBoost Ensemble\n",
    "\n",
    "**Goal:** Create a clean, simple submission using our best-performing model.\n",
    "\n",
    "**Approach:**\n",
    "- CatBoost + XGBoost ensemble (60:40 weights)\n",
    "- Spange descriptors + Arrhenius kinetics features\n",
    "- NO extrapolation detection (it hurt CV)\n",
    "- Minimal code, following official template exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fcc1353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:33:45.387956Z",
     "iopub.status.busy": "2026-01-16T00:33:45.387358Z",
     "iopub.status.idle": "2026-01-16T00:33:46.775855Z",
     "shell.execute_reply": "2026-01-16T00:33:46.775403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "import tqdm\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "DATA_PATH = \"/home/data\"\n",
    "\n",
    "print(\"Imports complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74c65ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:33:46.777067Z",
     "iopub.status.busy": "2026-01-16T00:33:46.776907Z",
     "iopub.status.idle": "2026-01-16T00:33:46.781284Z",
     "shell.execute_reply": "2026-01-16T00:33:46.780927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "# Data loading\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "# CV functions\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    ramps = ramps.sort_values(by=[\"SOLVENT A NAME\", \"SOLVENT B NAME\"])\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print(\"Data functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab5d2a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:33:46.782113Z",
     "iopub.status.busy": "2026-01-16T00:33:46.782016Z",
     "iopub.status.idle": "2026-01-16T00:33:46.788119Z",
     "shell.execute_reply": "2026-01-16T00:33:46.787765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13)\n"
     ]
    }
   ],
   "source": [
    "# Load Spange descriptors\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "print(f'Spange: {SPANGE_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a17ba88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:33:46.789114Z",
     "iopub.status.busy": "2026-01-16T00:33:46.789016Z",
     "iopub.status.idle": "2026-01-16T00:33:46.791903Z",
     "shell.execute_reply": "2026-01-16T00:33:46.791543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base classes defined.\n"
     ]
    }
   ],
   "source": [
    "# Base classes\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self): raise NotImplementedError\n",
    "    def featurize(self, X): raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self): pass\n",
    "    def train_model(self, X_train, y_train): raise NotImplementedError\n",
    "    def predict(self): raise NotImplementedError\n",
    "\n",
    "print(\"Base classes defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "845b8f18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:33:46.792908Z",
     "iopub.status.busy": "2026-01-16T00:33:46.792807Z",
     "iopub.status.idle": "2026-01-16T00:33:46.799168Z",
     "shell.execute_reply": "2026-01-16T00:33:46.798812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostXGBoostEnsemble defined.\n"
     ]
    }
   ],
   "source": [
    "# Simple CatBoost + XGBoost Ensemble\n",
    "class CatBoostXGBoostEnsemble(BaseModel):\n",
    "    def __init__(self, data='single'):\n",
    "        self.data = data\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.cat_models = None\n",
    "        self.xgb_models = None\n",
    "        self.scaler = None\n",
    "    \n",
    "    def _prepare_features(self, X):\n",
    "        # Numeric + Arrhenius\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_k = X_vals[:, 1:2] + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(X_vals[:, 0:1] + 1e-6)\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, inv_temp * log_time])\n",
    "        \n",
    "        if self.data == 'single':\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            return np.hstack([X_kinetic, X_spange])\n",
    "        else:\n",
    "            A = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1) / 100.0\n",
    "            X_spange = A * (1 - pct) + B * pct\n",
    "            return np.hstack([X_kinetic, pct, X_spange])\n",
    "    \n",
    "    def train_model(self, train_X, train_Y, device=None, verbose=False):\n",
    "        X = self._prepare_features(train_X)\n",
    "        Y = train_Y.values\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # CatBoost\n",
    "        self.cat_models = []\n",
    "        for i in range(3):\n",
    "            m = CatBoostRegressor(iterations=500, depth=6, learning_rate=0.05, l2_leaf_reg=3.0, random_seed=42, verbose=False)\n",
    "            m.fit(X_scaled, Y[:, i])\n",
    "            self.cat_models.append(m)\n",
    "        \n",
    "        # XGBoost\n",
    "        self.xgb_models = []\n",
    "        for i in range(3):\n",
    "            m = XGBRegressor(n_estimators=400, max_depth=5, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8, random_state=42, verbosity=0)\n",
    "            m.fit(X_scaled, Y[:, i])\n",
    "            self.xgb_models.append(m)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_feat = self._prepare_features(X)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        cat_preds = np.column_stack([m.predict(X_scaled) for m in self.cat_models])\n",
    "        xgb_preds = np.column_stack([m.predict(X_scaled) for m in self.xgb_models])\n",
    "        \n",
    "        preds = 0.6 * cat_preds + 0.4 * xgb_preds\n",
    "        preds = np.clip(preds, 0.0, 1.0)\n",
    "        return torch.tensor(preds, dtype=torch.double)\n",
    "\n",
    "print(\"CatBoostXGBoostEnsemble defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74538d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:33:46.800024Z",
     "iopub.status.busy": "2026-01-16T00:33:46.799922Z",
     "iopub.status.idle": "2026-01-16T00:33:48.034426Z",
     "shell.execute_reply": "2026-01-16T00:33:48.034009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed! Predictions shape: torch.Size([37, 3])\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "split_gen = generate_leave_one_out_splits(X, Y)\n",
    "(train_X, train_Y), (test_X, test_Y) = next(split_gen)\n",
    "\n",
    "model = CatBoostXGBoostEnsemble()\n",
    "model.train_model(train_X, train_Y)\n",
    "preds = model.predict(test_X)\n",
    "print(f\"Test passed! Predictions shape: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a06ae1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:33:48.035587Z",
     "iopub.status.busy": "2026-01-16T00:33:48.035479Z",
     "iopub.status.idle": "2026-01-16T00:34:09.707138Z",
     "shell.execute_reply": "2026-01-16T00:34:09.706670Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:02,  1.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:03,  1.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:04,  1.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:05,  1.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:06,  1.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:06,  1.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:07,  1.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:08,  1.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:09,  1.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:10,  1.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:11,  1.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:12,  1.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:13,  1.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:14,  1.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:15,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:16,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:17,  1.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:18,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:18,  1.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:19,  1.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:20,  1.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:21,  1.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:21,  1.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = CatBoostXGBoostEnsemble() # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb497e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:34:09.708457Z",
     "iopub.status.busy": "2026-01-16T00:34:09.708353Z",
     "iopub.status.idle": "2026-01-16T00:34:25.290508Z",
     "shell.execute_reply": "2026-01-16T00:34:25.290126Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:01,  1.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:03,  1.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:04,  1.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:05,  1.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:07,  1.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:08,  1.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:09,  1.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:10,  1.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:12,  1.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:13,  1.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:14,  1.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:15,  1.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:15,  1.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = CatBoostXGBoostEnsemble(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3cdd1ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:34:25.291561Z",
     "iopub.status.busy": "2026-01-16T00:34:25.291457Z",
     "iopub.status.idle": "2026-01-16T00:34:25.300988Z",
     "shell.execute_reply": "2026-01-16T00:34:25.300635Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e72059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:34:40.849676Z",
     "iopub.status.busy": "2026-01-16T00:34:40.849083Z",
     "iopub.status.idle": "2026-01-16T00:35:17.744123Z",
     "shell.execute_reply": "2026-01-16T00:35:17.743691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating CV...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent CV: 0.011171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data CV: 0.013677\n",
      "\n",
      "FINAL CV: 0.011171\n",
      "Predicted LB: 0.1006\n"
     ]
    }
   ],
   "source": [
    "# Calculate CV\n",
    "print(\"\\nCalculating CV...\")\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "fold_mses = []\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X, Y)):\n",
    "    model = CatBoostXGBoostEnsemble()\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mse = np.mean((preds - test_Y.values) ** 2)\n",
    "    fold_mses.append(mse)\n",
    "single_cv = np.mean(fold_mses)\n",
    "print(f\"Single solvent CV: {single_cv:.6f}\")\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "full_fold_mses = []\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_ramp_out_splits(X, Y)):\n",
    "    model = CatBoostXGBoostEnsemble(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mse = np.mean((preds - test_Y.values) ** 2)\n",
    "    full_fold_mses.append(mse)\n",
    "full_cv = np.mean(full_fold_mses)\n",
    "print(f\"Full data CV: {full_cv:.6f}\")\n",
    "\n",
    "print(f\"\\nFINAL CV: {single_cv:.6f}\")\n",
    "print(f\"Predicted LB: {4.31 * single_cv + 0.0525:.4f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
