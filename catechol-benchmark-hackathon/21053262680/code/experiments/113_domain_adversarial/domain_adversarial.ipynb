{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e172ecca",
   "metadata": {},
   "source": [
    "# Experiment 113: Domain-Adversarial Training\n",
    "\n",
    "## Goal\n",
    "Learn solvent-invariant features that generalize better to unseen solvents.\n",
    "\n",
    "## Key Insight\n",
    "- ALL approaches fall on the SAME CV-LB line: LB = 4.09 Ã— CV + 0.0546\n",
    "- The intercept (0.0546) > target (0.0347) - target is UNREACHABLE with current approaches\n",
    "- We need to CHANGE THE RELATIONSHIP, not improve CV\n",
    "\n",
    "## Domain-Adversarial Strategy\n",
    "1. Feature extractor: Shared MLP that extracts features\n",
    "2. Predictor: Predicts yields from features\n",
    "3. Domain discriminator: Predicts which solvent the sample came from\n",
    "4. Training: Feature extractor is trained to FOOL the discriminator (gradient reversal)\n",
    "\n",
    "## Why This Might Work\n",
    "- Forces the model to learn features that don't depend on solvent identity\n",
    "- These features should generalize better to unseen solvents\n",
    "- Could reduce the extrapolation error (intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f595d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T20:27:37.259207Z",
     "iopub.status.busy": "2026-01-16T20:27:37.258737Z",
     "iopub.status.idle": "2026-01-16T20:27:38.424621Z",
     "shell.execute_reply": "2026-01-16T20:27:38.424168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n",
      "PyTorch version: 2.2.0+cu118\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add data path\n",
    "sys.path.append('/home/data/')\n",
    "\n",
    "from utils import (\n",
    "    INPUT_LABELS_FULL_SOLVENT, INPUT_LABELS_SINGLE_SOLVENT, \n",
    "    INPUT_LABELS_NUMERIC, INPUT_LABELS_SINGLE_FEATURES, \n",
    "    INPUT_LABELS_FULL_FEATURES,\n",
    "    generate_leave_one_out_splits, generate_leave_one_ramp_out_splits\n",
    ")\n",
    "\n",
    "# Override load functions to use local paths\n",
    "DATA_PATH = '/home/data/'\n",
    "TARGET_LABELS = ['Product 2', 'Product 3', 'SM']\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    assert name in [\"spange_descriptors\", \"acs_pca_descriptors\", \"drfps_catechol\", \"fragprints\", \"smiles\"]\n",
    "    features = pd.read_csv(f'{DATA_PATH}{name}_lookup.csv', index_col=0)\n",
    "    return features\n",
    "\n",
    "print(\"Imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c932c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T20:27:38.425870Z",
     "iopub.status.busy": "2026-01-16T20:27:38.425695Z",
     "iopub.status.idle": "2026-01-16T20:27:38.433773Z",
     "shell.execute_reply": "2026-01-16T20:27:38.433453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering functions defined\n"
     ]
    }
   ],
   "source": [
    "# Base classes and feature engineering\n",
    "from abc import ABC, abstractmethod\n",
    "from functools import reduce\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "    def featurize(X, Y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "    def predict(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "_SOLVENT_TABLE_CACHE = None\n",
    "\n",
    "def feature_priority(name: str) -> int:\n",
    "    if name.startswith(\"spange_\"): return 5\n",
    "    if name.startswith(\"acs_\"): return 4\n",
    "    if name.startswith(\"drfps_\"): return 3\n",
    "    if name.startswith(\"frag_\"): return 2\n",
    "    if name.startswith(\"smiles_\"): return 1\n",
    "    return 0\n",
    "\n",
    "def filter_correlated_features(df, threshold=0.8):\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    if numeric_df.shape[1] == 0:\n",
    "        return df, []\n",
    "    std = numeric_df.std(axis=0)\n",
    "    constant_cols = std[std == 0].index.tolist()\n",
    "    if constant_cols:\n",
    "        numeric_df = numeric_df.drop(columns=constant_cols)\n",
    "    corr = numeric_df.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool)).fillna(0.0)\n",
    "    cols = upper.columns.tolist()\n",
    "    to_drop = set()\n",
    "    high_corr_pairs = []\n",
    "    for i, col_i in enumerate(cols):\n",
    "        for j in range(i + 1, len(cols)):\n",
    "            col_j = cols[j]\n",
    "            cval = upper.iloc[i, j]\n",
    "            if cval > threshold:\n",
    "                high_corr_pairs.append((col_i, col_j, cval))\n",
    "    for col_i, col_j, cval in high_corr_pairs:\n",
    "        if col_i in to_drop or col_j in to_drop:\n",
    "            continue\n",
    "        p_i = feature_priority(col_i)\n",
    "        p_j = feature_priority(col_j)\n",
    "        if p_i > p_j:\n",
    "            drop = col_j\n",
    "        elif p_j > p_i:\n",
    "            drop = col_i\n",
    "        else:\n",
    "            idx_i = df.columns.get_loc(col_i)\n",
    "            idx_j = df.columns.get_loc(col_j)\n",
    "            drop = col_i if idx_i > idx_j else col_j\n",
    "        to_drop.add(drop)\n",
    "    all_to_drop = list(set(constant_cols).union(to_drop))\n",
    "    df_filtered = df.drop(columns=all_to_drop, errors=\"ignore\")\n",
    "    return df_filtered, all_to_drop\n",
    "\n",
    "def add_numeric_features(X_numeric):\n",
    "    X_num = X_numeric.copy()\n",
    "    cols = set(X_num.columns)\n",
    "    if {\"Temperature\", \"Residence Time\"} <= cols:\n",
    "        X_num[\"Temperature\"] = X_num[\"Temperature\"] + 273.15\n",
    "        T = X_num[\"Temperature\"]\n",
    "        rt = X_num[\"Residence Time\"]\n",
    "        X_num[\"T_x_RT\"] = T * rt\n",
    "        X_num[\"RT_log\"] = np.log(rt + 1e-6)\n",
    "        X_num[\"T_inv\"] = 1 / T\n",
    "        X_num[\"RT_scaled\"] = rt / rt.mean()\n",
    "    return X_num\n",
    "\n",
    "print(\"Feature engineering functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092276bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T20:27:38.434884Z",
     "iopub.status.busy": "2026-01-16T20:27:38.434626Z",
     "iopub.status.idle": "2026-01-16T20:27:38.440694Z",
     "shell.execute_reply": "2026-01-16T20:27:38.440299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_solvent_feature_table defined\n"
     ]
    }
   ],
   "source": [
    "def build_solvent_feature_table(threshold=0.90):\n",
    "    global _SOLVENT_TABLE_CACHE\n",
    "    if _SOLVENT_TABLE_CACHE is not None:\n",
    "        return _SOLVENT_TABLE_CACHE\n",
    "    print(\">>> Building solvent feature table...\")\n",
    "    sources = [\"spange_descriptors\", \"acs_pca_descriptors\", \"drfps_catechol\", \"fragprints\"]\n",
    "    dfs = []\n",
    "    for src in sources:\n",
    "        df_src = load_features(src).copy()\n",
    "        if \"SOLVENT NAME\" not in df_src.columns:\n",
    "            df_src = df_src.reset_index().rename(columns={\"index\": \"SOLVENT NAME\"})\n",
    "        if src in [\"drfps_catechol\", \"fragprints\"]:\n",
    "            prefix = \"drfps\" if src == \"drfps_catechol\" else \"frag\"\n",
    "            df_src = df_src.loc[:, (df_src != 0).any(axis=0)]\n",
    "            df_src = df_src.loc[:, (df_src != 1).any(axis=0)]\n",
    "            values = df_src.drop(columns={\"SOLVENT NAME\"})\n",
    "            count = values.sum(axis=0).T\n",
    "            drop_cols = count[count == 1].index\n",
    "            df_src = df_src.drop(columns=drop_cols)\n",
    "            cols_to_rename = [c for c in df_src.columns if c != \"SOLVENT NAME\"]\n",
    "            df_src = df_src.rename(columns={c: f\"{prefix}_{c}\" for c in cols_to_rename})\n",
    "        else:\n",
    "            if src == \"spange_descriptors\":\n",
    "                prefix = \"spange\"\n",
    "            elif src == \"acs_pca_descriptors\":\n",
    "                prefix = \"acs\"\n",
    "            else:\n",
    "                prefix = src\n",
    "            cols_to_rename = [c for c in df_src.columns if c != \"SOLVENT NAME\"]\n",
    "            df_src = df_src.rename(columns={c: f\"{prefix}_{c}\" for c in cols_to_rename})\n",
    "        dfs.append(df_src)\n",
    "    combined = reduce(lambda left, right: pd.merge(left, right, on=\"SOLVENT NAME\", how=\"outer\"), dfs)\n",
    "    combined = combined.set_index(\"SOLVENT NAME\")\n",
    "    print(f\"Combined feature table shape (before corr filter): {combined.shape}\")\n",
    "    combined, _ = filter_correlated_features(combined, threshold=threshold)\n",
    "    print(f\"Final solvent feature table shape: {combined.shape}\")\n",
    "    _SOLVENT_TABLE_CACHE = combined\n",
    "    return combined\n",
    "\n",
    "print(\"build_solvent_feature_table defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5396fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T20:27:38.441675Z",
     "iopub.status.busy": "2026-01-16T20:27:38.441551Z",
     "iopub.status.idle": "2026-01-16T20:27:38.448102Z",
     "shell.execute_reply": "2026-01-16T20:27:38.447739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizers defined\n"
     ]
    }
   ],
   "source": [
    "# Featurizers with WEIGHTED AVERAGE for mixtures\n",
    "class PrecomputedFeaturizer:\n",
    "    def __init__(self):\n",
    "        self.featurizer = build_solvent_feature_table()\n",
    "        dummy_num = pd.DataFrame([[0] * len(INPUT_LABELS_NUMERIC)], columns=INPUT_LABELS_NUMERIC)\n",
    "        numeric_dim = add_numeric_features(dummy_num).shape[1]\n",
    "        self.feats_dim = numeric_dim + self.featurizer.shape[1]\n",
    "\n",
    "    def featurize(self, X):\n",
    "        X_numeric = add_numeric_features(X[INPUT_LABELS_NUMERIC].copy())\n",
    "        X_solvent = self.featurizer.loc[X[\"SOLVENT NAME\"]]\n",
    "        X_out = np.concatenate([X_numeric.values, X_solvent.values], axis=1)\n",
    "        return torch.tensor(X_out, dtype=torch.double)\n",
    "    \n",
    "    def get_solvent_ids(self, X):\n",
    "        \"\"\"Get solvent IDs for domain classification\"\"\"\n",
    "        solvent_names = X[\"SOLVENT NAME\"].values\n",
    "        unique_solvents = sorted(self.featurizer.index.tolist())\n",
    "        solvent_to_id = {s: i for i, s in enumerate(unique_solvents)}\n",
    "        return torch.tensor([solvent_to_id.get(s, 0) for s in solvent_names], dtype=torch.long)\n",
    "\n",
    "class PrecomputedFeaturizerMixed:\n",
    "    def __init__(self):\n",
    "        self.featurizer = build_solvent_feature_table()\n",
    "        dummy_num = pd.DataFrame([[0] * len(INPUT_LABELS_NUMERIC)], columns=INPUT_LABELS_NUMERIC)\n",
    "        numeric_dim = add_numeric_features(dummy_num).shape[1]\n",
    "        self.feats_dim = numeric_dim + self.featurizer.shape[1]\n",
    "\n",
    "    def featurize(self, X):\n",
    "        X_numeric = add_numeric_features(X[INPUT_LABELS_NUMERIC].copy())\n",
    "        A = self.featurizer.loc[X[\"SOLVENT A NAME\"]].values\n",
    "        B = self.featurizer.loc[X[\"SOLVENT B NAME\"]].values\n",
    "        frac_B = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "        frac_A = 1 - frac_B\n",
    "        mixed = A * frac_A + B * frac_B  # WEIGHTED AVERAGE\n",
    "        X_out = np.concatenate([X_numeric.values, mixed], axis=1)\n",
    "        return torch.tensor(X_out, dtype=torch.double)\n",
    "    \n",
    "    def get_solvent_ids(self, X):\n",
    "        \"\"\"Get solvent IDs for domain classification (use primary solvent A)\"\"\"\n",
    "        solvent_names = X[\"SOLVENT A NAME\"].values\n",
    "        unique_solvents = sorted(self.featurizer.index.tolist())\n",
    "        solvent_to_id = {s: i for i, s in enumerate(unique_solvents)}\n",
    "        return torch.tensor([solvent_to_id.get(s, 0) for s in solvent_names], dtype=torch.long)\n",
    "\n",
    "print(\"Featurizers defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "958e2a8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T20:27:38.449068Z",
     "iopub.status.busy": "2026-01-16T20:27:38.448952Z",
     "iopub.status.idle": "2026-01-16T20:27:38.452608Z",
     "shell.execute_reply": "2026-01-16T20:27:38.452223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Reversal Layer defined\n"
     ]
    }
   ],
   "source": [
    "# Gradient Reversal Layer for domain-adversarial training\n",
    "class GradientReversalFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.alpha, None\n",
    "\n",
    "class GradientReversalLayer(nn.Module):\n",
    "    def __init__(self, alpha=1.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return GradientReversalFunction.apply(x, self.alpha)\n",
    "\n",
    "print(\"Gradient Reversal Layer defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d13388d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T20:27:38.453590Z",
     "iopub.status.busy": "2026-01-16T20:27:38.453486Z",
     "iopub.status.idle": "2026-01-16T20:27:38.457647Z",
     "shell.execute_reply": "2026-01-16T20:27:38.457289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANNModel defined\n"
     ]
    }
   ],
   "source": [
    "# Domain-Adversarial Neural Network\n",
    "class DANNModel(nn.Module):\n",
    "    def __init__(self, input_dim, n_solvents, hidden_dim=64, alpha=1.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature extractor\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Yield predictor\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 3),\n",
    "            nn.Sigmoid()  # Yields are in [0, 1]\n",
    "        )\n",
    "        \n",
    "        # Domain discriminator with gradient reversal\n",
    "        self.gradient_reversal = GradientReversalLayer(alpha)\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, n_solvents)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        predictions = self.predictor(features)\n",
    "        \n",
    "        # Domain classification with gradient reversal\n",
    "        reversed_features = self.gradient_reversal(features)\n",
    "        domain_logits = self.discriminator(reversed_features)\n",
    "        \n",
    "        return predictions, domain_logits\n",
    "    \n",
    "    def predict_only(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        predictions = self.predictor(features)\n",
    "        return predictions\n",
    "\n",
    "print(\"DANNModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009f4d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T20:27:38.458780Z",
     "iopub.status.busy": "2026-01-16T20:27:38.458444Z",
     "iopub.status.idle": "2026-01-16T20:27:38.464564Z",
     "shell.execute_reply": "2026-01-16T20:27:38.464194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DomainAdversarialModel defined\n"
     ]
    }
   ],
   "source": [
    "# Domain-Adversarial Model wrapper\n",
    "class DomainAdversarialModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Uses domain-adversarial training to learn solvent-invariant features.\n",
    "    \n",
    "    The key idea is to train a feature extractor that:\n",
    "    1. Produces features that are good for predicting yields\n",
    "    2. Produces features that are BAD for predicting which solvent the sample came from\n",
    "    \n",
    "    This forces the model to learn features that don't depend on solvent identity,\n",
    "    which should generalize better to unseen solvents.\n",
    "    \"\"\"\n",
    "    def __init__(self, data=\"single\", alpha=1.0, n_epochs=100, lr=0.001, verbose=False):\n",
    "        self.data_mode = data\n",
    "        self.alpha = alpha  # Strength of domain adversarial loss\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        if data == \"single\":\n",
    "            self.featurizer = PrecomputedFeaturizer()\n",
    "        else:\n",
    "            self.featurizer = PrecomputedFeaturizerMixed()\n",
    "        \n",
    "        self.model = None\n",
    "        self.n_solvents = 26  # Number of unique solvents\n",
    "    \n",
    "    def train_model(self, train_X, train_Y, device=None, verbose=False):\n",
    "        # Featurize\n",
    "        X_tensor = self.featurizer.featurize(train_X)\n",
    "        Y_tensor = torch.tensor(train_Y.values, dtype=torch.double)\n",
    "        domain_ids = self.featurizer.get_solvent_ids(train_X)\n",
    "        \n",
    "        input_dim = X_tensor.shape[1]\n",
    "        \n",
    "        # Create model\n",
    "        self.model = DANNModel(input_dim, self.n_solvents, alpha=self.alpha)\n",
    "        self.model.double()\n",
    "        \n",
    "        # Optimizers\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        # Loss functions\n",
    "        yield_criterion = nn.MSELoss()\n",
    "        domain_criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Training loop\n",
    "        self.model.train()\n",
    "        for epoch in range(self.n_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            yield_pred, domain_logits = self.model(X_tensor)\n",
    "            \n",
    "            # Compute losses\n",
    "            yield_loss = yield_criterion(yield_pred, Y_tensor)\n",
    "            domain_loss = domain_criterion(domain_logits, domain_ids)\n",
    "            \n",
    "            # Total loss (domain loss is already reversed by gradient reversal layer)\n",
    "            total_loss = yield_loss + domain_loss\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if self.verbose and (epoch + 1) % 20 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{self.n_epochs}, Yield Loss: {yield_loss.item():.6f}, Domain Loss: {domain_loss.item():.6f}\")\n",
    "        \n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_tensor = self.featurizer.featurize(X)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = self.model.predict_only(X_tensor)\n",
    "        \n",
    "        # Clip and normalize\n",
    "        out = predictions.numpy()\n",
    "        out = np.clip(out, a_min=0.0, a_max=None)\n",
    "        if out.shape[1] > 1:\n",
    "            totals = out.sum(axis=1, keepdims=True)\n",
    "            divisor = np.maximum(totals, 1.0)\n",
    "            out = out / divisor\n",
    "        \n",
    "        return torch.tensor(out, dtype=torch.double)\n",
    "\n",
    "print(\"DomainAdversarialModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37ff2954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T20:27:38.465446Z",
     "iopub.status.busy": "2026-01-16T20:27:38.465333Z",
     "iopub.status.idle": "2026-01-16T20:27:38.470605Z",
     "shell.execute_reply": "2026-01-16T20:27:38.470215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function defined\n"
     ]
    }
   ],
   "source": [
    "# Quick CV evaluation\n",
    "import tqdm\n",
    "\n",
    "def evaluate_cv(model_class, **kwargs):\n",
    "    \"\"\"Evaluate using leave-one-out CV\"\"\"\n",
    "    # Single solvent\n",
    "    X, Y = load_data(\"single_solvent\")\n",
    "    split_generator = generate_leave_one_out_splits(X, Y)\n",
    "    all_preds_single = []\n",
    "    all_true_single = []\n",
    "    \n",
    "    for fold_idx, split in tqdm.tqdm(enumerate(split_generator), desc=\"single\"):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        model = model_class(data='single', **kwargs)\n",
    "        model.train_model(train_X, train_Y)\n",
    "        predictions = model.predict(test_X)\n",
    "        all_preds_single.append(predictions.numpy())\n",
    "        all_true_single.append(test_Y.values)\n",
    "    \n",
    "    preds_single = np.vstack(all_preds_single)\n",
    "    true_single = np.vstack(all_true_single)\n",
    "    mse_single = np.mean((preds_single - true_single) ** 2)\n",
    "    print(f\"Single Solvent MSE: {mse_single:.6f}\")\n",
    "    \n",
    "    # Full data\n",
    "    X, Y = load_data(\"full\")\n",
    "    split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "    all_preds_full = []\n",
    "    all_true_full = []\n",
    "    \n",
    "    for fold_idx, split in tqdm.tqdm(enumerate(split_generator), desc=\"full\"):\n",
    "        (train_X, train_Y), (test_X, test_Y) = split\n",
    "        model = model_class(data='full', **kwargs)\n",
    "        model.train_model(train_X, train_Y)\n",
    "        predictions = model.predict(test_X)\n",
    "        all_preds_full.append(predictions.numpy())\n",
    "        all_true_full.append(test_Y.values)\n",
    "    \n",
    "    preds_full = np.vstack(all_preds_full)\n",
    "    true_full = np.vstack(all_true_full)\n",
    "    mse_full = np.mean((preds_full - true_full) ** 2)\n",
    "    print(f\"Full Data MSE: {mse_full:.6f}\")\n",
    "    \n",
    "    # Combined\n",
    "    n_single = preds_single.shape[0] * preds_single.shape[1]\n",
    "    n_full = preds_full.shape[0] * preds_full.shape[1]\n",
    "    combined_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "    print(f\"\\nCombined MSE (CV score): {combined_mse:.6f}\")\n",
    "    \n",
    "    return combined_mse, mse_single, mse_full\n",
    "\n",
    "print(\"Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf9e421",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T20:27:38.471520Z",
     "iopub.status.busy": "2026-01-16T20:27:38.471403Z",
     "iopub.status.idle": "2026-01-16T20:28:05.165722Z",
     "shell.execute_reply": "2026-01-16T20:28:05.165268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Testing DomainAdversarialModel with different alpha values\n",
      "============================================================\n",
      "\n",
      "--- Config: {'alpha': 0.5, 'n_epochs': 100, 'lr': 0.001} ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Building solvent feature table...\n",
      "Combined feature table shape (before corr filter): (26, 113)\n",
      "Final solvent feature table shape: (26, 66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 1it [00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 2it [00:01,  1.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 3it [00:01,  2.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 4it [00:01,  3.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 5it [00:01,  3.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 6it [00:01,  3.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 7it [00:02,  4.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 8it [00:02,  4.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 9it [00:02,  4.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 10it [00:02,  4.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 11it [00:03,  4.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 12it [00:03,  4.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 13it [00:03,  4.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 14it [00:03,  4.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 15it [00:03,  4.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 16it [00:04,  4.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 17it [00:04,  4.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 18it [00:04,  4.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 19it [00:04,  4.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 20it [00:04,  4.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 21it [00:05,  4.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 22it [00:05,  4.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 23it [00:05,  4.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [00:05,  4.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [00:05,  4.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Solvent MSE: 0.153842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 1it [00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 2it [00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 3it [00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 4it [00:01,  3.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 5it [00:01,  3.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 6it [00:01,  3.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 7it [00:02,  3.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 8it [00:02,  3.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 9it [00:02,  3.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 10it [00:02,  3.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 11it [00:03,  3.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 12it [00:03,  3.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [00:03,  3.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [00:03,  3.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data MSE: 0.196189\n",
      "\n",
      "Combined MSE (CV score): 0.181436\n",
      "Expected LB from line: 0.7967\n",
      "\n",
      "--- Config: {'alpha': 1.0, 'n_epochs': 100, 'lr': 0.001} ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 1it [00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 2it [00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 3it [00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 4it [00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 5it [00:01,  4.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 6it [00:01,  4.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 7it [00:01,  4.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 8it [00:01,  4.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 9it [00:01,  4.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 10it [00:02,  4.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 11it [00:02,  4.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 12it [00:02,  4.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 13it [00:02,  4.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 14it [00:02,  4.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 15it [00:03,  4.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 16it [00:03,  4.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 17it [00:03,  4.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 18it [00:03,  4.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 19it [00:04,  4.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 20it [00:04,  4.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 21it [00:04,  4.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 22it [00:04,  4.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 23it [00:04,  4.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [00:05,  4.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [00:05,  4.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Solvent MSE: 0.156925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 1it [00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 2it [00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 3it [00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 4it [00:01,  3.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 5it [00:01,  3.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 6it [00:01,  3.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 7it [00:01,  3.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 8it [00:02,  3.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 9it [00:02,  3.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 10it [00:02,  3.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 11it [00:02,  3.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 12it [00:03,  3.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [00:03,  3.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [00:03,  3.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data MSE: 0.174328\n",
      "\n",
      "Combined MSE (CV score): 0.168265\n",
      "Expected LB from line: 0.7428\n",
      "\n",
      "--- Config: {'alpha': 2.0, 'n_epochs': 100, 'lr': 0.001} ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 1it [00:00,  4.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 2it [00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 3it [00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 4it [00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 5it [00:01,  4.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 6it [00:01,  4.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 7it [00:01,  4.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 8it [00:01,  4.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 9it [00:01,  4.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 10it [00:02,  4.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 11it [00:02,  4.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 12it [00:02,  4.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 13it [00:02,  4.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 14it [00:02,  4.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 15it [00:03,  4.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 16it [00:03,  4.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 17it [00:03,  4.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 18it [00:03,  4.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 19it [00:04,  4.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 20it [00:04,  4.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 21it [00:04,  4.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 22it [00:04,  4.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 23it [00:04,  4.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [00:05,  4.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "single: 24it [00:05,  4.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Solvent MSE: 0.146408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 1it [00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 2it [00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 3it [00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 4it [00:01,  3.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 5it [00:01,  3.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 6it [00:01,  3.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 7it [00:01,  3.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 8it [00:02,  3.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 9it [00:02,  3.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 10it [00:02,  3.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 11it [00:02,  3.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 12it [00:03,  3.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [00:03,  3.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "full: 13it [00:03,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data MSE: 0.188014\n",
      "\n",
      "Combined MSE (CV score): 0.173519\n",
      "Expected LB from line: 0.7643\n",
      "\n",
      "============================================================\n",
      "Summary of Results\n",
      "============================================================\n",
      " alpha  n_epochs    lr       cv  single_mse  full_mse  expected_lb\n",
      "   0.5       100 0.001 0.181436    0.153842  0.196189     0.796674\n",
      "   1.0       100 0.001 0.168265    0.156925  0.174328     0.742805\n",
      "   2.0       100 0.001 0.173519    0.146408  0.188014     0.764294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test DomainAdversarialModel with different alpha values\n",
    "test_configs = [\n",
    "    {'alpha': 0.5, 'n_epochs': 100, 'lr': 0.001},\n",
    "    {'alpha': 1.0, 'n_epochs': 100, 'lr': 0.001},\n",
    "    {'alpha': 2.0, 'n_epochs': 100, 'lr': 0.001},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Testing DomainAdversarialModel with different alpha values\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for config in test_configs:\n",
    "    print(f\"\\n--- Config: {config} ---\")\n",
    "    cv, single_mse, full_mse = evaluate_cv(DomainAdversarialModel, **config)\n",
    "    expected_lb = 4.09 * cv + 0.0546\n",
    "    print(f\"Expected LB from line: {expected_lb:.4f}\")\n",
    "    results.append({\n",
    "        **config,\n",
    "        'cv': cv,\n",
    "        'single_mse': single_mse,\n",
    "        'full_mse': full_mse,\n",
    "        'expected_lb': expected_lb\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Summary of Results\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8837c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best configuration\n",
    "best_idx = results_df['cv'].idxmin()\n",
    "best_config = results_df.loc[best_idx]\n",
    "\n",
    "print(f\"\\nBest configuration:\")\n",
    "print(f\"  alpha: {best_config['alpha']}\")\n",
    "print(f\"  CV: {best_config['cv']:.6f}\")\n",
    "print(f\"  Expected LB from line: {best_config['expected_lb']:.4f}\")\n",
    "\n",
    "best_alpha = best_config['alpha']\n",
    "best_n_epochs = best_config['n_epochs']\n",
    "best_lr = best_config['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77defd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "import json\n",
    "\n",
    "metrics = {\n",
    "    'cv_score': float(best_config['cv']),\n",
    "    'mse_single': float(best_config['single_mse']),\n",
    "    'mse_full': float(best_config['full_mse']),\n",
    "    'alpha': float(best_alpha),\n",
    "    'n_epochs': int(best_n_epochs),\n",
    "    'lr': float(best_lr),\n",
    "    'all_results': results,\n",
    "    'notes': 'DomainAdversarialModel - learns solvent-invariant features using gradient reversal.'\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/113_domain_adversarial/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Metrics saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f9f88",
   "metadata": {},
   "source": [
    "## Submission Cells (CORRECT FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02005ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = DomainAdversarialModel(data='single', alpha=best_alpha, n_epochs=best_n_epochs, lr=best_lr)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = DomainAdversarialModel(data='full', alpha=best_alpha, n_epochs=best_n_epochs, lr=best_lr)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7437f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index(drop=True)\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/code/experiments/113_domain_adversarial/submission.csv\", index=True)\n",
    "\n",
    "# Also copy to main submission folder\n",
    "import shutil\n",
    "shutil.copy(\"/home/code/experiments/113_domain_adversarial/submission.csv\", \"/home/submission/submission.csv\")\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"Submission columns: {submission.columns.tolist()}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nLast 5 rows:\")\n",
    "print(submission.tail())\n",
    "\n",
    "# Read back and verify format\n",
    "sub_check = pd.read_csv(\"/home/submission/submission.csv\")\n",
    "print(f\"\\nRead back columns: {sub_check.columns.tolist()}\")\n",
    "expected_cols = ['id', 'task', 'fold', 'row', 'target_1', 'target_2', 'target_3']\n",
    "assert list(sub_check.columns) == expected_cols, f\"Wrong columns: {list(sub_check.columns)}\"\n",
    "print(f\"\\nâœ… FORMAT VERIFIED: {expected_cols}\")\n",
    "print(f\"\\nâœ… MODEL CLASS: DomainAdversarialModel (matches CV computation)\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
