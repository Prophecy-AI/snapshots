{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42e85818",
   "metadata": {},
   "source": [
    "# Graph Attention Network (GAT) with DRFP Integration\n",
    "\n",
    "**Problem**: CV-LB intercept (0.0525) > Target (0.0347). All tabular approaches fall on the same CV-LB line.\n",
    "\n",
    "**Solution**: Use Graph Attention Networks (GAT) which learn which atoms/bonds matter for each prediction.\n",
    "\n",
    "**Key insight from benchmark**: The benchmark paper achieved MSE 0.0039 using GAT + DRFP.\n",
    "\n",
    "**This notebook has EXACTLY 3 submission cells at the end.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37f3f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T08:00:59.861824Z",
     "iopub.status.busy": "2026-01-16T08:00:59.861286Z",
     "iopub.status.idle": "2026-01-16T08:01:02.224697Z",
     "shell.execute_reply": "2026-01-16T08:01:02.224266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch Geometric imports\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "# RDKit imports\n",
    "from rdkit import Chem\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2933d20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T08:01:02.225872Z",
     "iopub.status.busy": "2026-01-16T08:01:02.225700Z",
     "iopub.status.idle": "2026-01-16T08:01:02.230844Z",
     "shell.execute_reply": "2026-01-16T08:01:02.230483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcade038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T08:01:02.231860Z",
     "iopub.status.busy": "2026-01-16T08:01:02.231765Z",
     "iopub.status.idle": "2026-01-16T08:01:02.258881Z",
     "shell.execute_reply": "2026-01-16T08:01:02.258519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES lookup: 26 solvents\n",
      "DRFP filtered: (24, 122)\n"
     ]
    }
   ],
   "source": [
    "# Load SMILES lookup and DRFP features\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'SMILES lookup: {len(SMILES_DF)} solvents')\n",
    "print(f'DRFP filtered: {DRFP_FILTERED.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2cd06b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T08:01:02.259842Z",
     "iopub.status.busy": "2026-01-16T08:01:02.259755Z",
     "iopub.status.idle": "2026-01-16T08:01:02.271219Z",
     "shell.execute_reply": "2026-01-16T08:01:02.270870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed 26 solvent graphs\n",
      "Node feature dimension: 9\n"
     ]
    }
   ],
   "source": [
    "# SMILES to molecular graph conversion with rich atom features\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"Convert SMILES to PyTorch Geometric Data object with rich atom features.\"\"\"\n",
    "    if '.' in smiles:\n",
    "        smiles = smiles.split('.')[0]\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        raise ValueError(f\"Could not parse SMILES: {smiles}\")\n",
    "    \n",
    "    # Rich atom features (9 features per atom)\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        features = [\n",
    "            atom.GetAtomicNum(),\n",
    "            atom.GetDegree(),\n",
    "            atom.GetFormalCharge(),\n",
    "            int(atom.GetHybridization()),\n",
    "            int(atom.GetIsAromatic()),\n",
    "            atom.GetTotalNumHs(),\n",
    "            atom.GetNumRadicalElectrons(),\n",
    "            int(atom.IsInRing()),\n",
    "            atom.GetMass() / 100.0,  # Normalized mass\n",
    "        ]\n",
    "        atom_features.append(features)\n",
    "    \n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    \n",
    "    # Edge index from bonds\n",
    "    edge_index = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_index.extend([[i, j], [j, i]])\n",
    "    \n",
    "    if len(edge_index) == 0:\n",
    "        edge_index = [[0, 0]]\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Pre-compute all graphs\n",
    "SOLVENT_GRAPHS = {}\n",
    "for solvent_name in SMILES_DF.index:\n",
    "    smiles = SMILES_DF.loc[solvent_name, 'solvent smiles']\n",
    "    SOLVENT_GRAPHS[solvent_name] = smiles_to_graph(smiles)\n",
    "\n",
    "print(f'Pre-computed {len(SOLVENT_GRAPHS)} solvent graphs')\n",
    "print(f'Node feature dimension: {SOLVENT_GRAPHS[list(SOLVENT_GRAPHS.keys())[0]].x.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d23df3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T08:01:02.272057Z",
     "iopub.status.busy": "2026-01-16T08:01:02.271967Z",
     "iopub.status.idle": "2026-01-16T08:01:02.276189Z",
     "shell.execute_reply": "2026-01-16T08:01:02.275828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATModel defined\n"
     ]
    }
   ],
   "source": [
    "# Graph Attention Network Model\n",
    "class GATModel(nn.Module):\n",
    "    \"\"\"Graph Attention Network for molecular property prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, node_dim=9, hidden_dim=64, heads=4, drfp_dim=122, kinetics_dim=5):\n",
    "        super().__init__()\n",
    "        # GAT layers with multi-head attention\n",
    "        self.conv1 = GATConv(node_dim, hidden_dim, heads=heads, dropout=0.2)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, hidden_dim, heads=1, dropout=0.2)\n",
    "        \n",
    "        # Combine graph embedding with DRFP and kinetics\n",
    "        combined_dim = hidden_dim + drfp_dim + kinetics_dim\n",
    "        \n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, graph_batch, drfp, kinetics):\n",
    "        x, edge_index, batch = graph_batch.x, graph_batch.edge_index, graph_batch.batch\n",
    "        \n",
    "        # GAT layers\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        # Global mean pooling for graph-level representation\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Combine with DRFP and kinetics\n",
    "        combined = torch.cat([x, drfp, kinetics], dim=-1)\n",
    "        \n",
    "        return self.predictor(combined)\n",
    "\n",
    "print('GATModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d99001c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T08:01:02.277078Z",
     "iopub.status.busy": "2026-01-16T08:01:02.276983Z",
     "iopub.status.idle": "2026-01-16T08:01:02.281535Z",
     "shell.execute_reply": "2026-01-16T08:01:02.281161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATModelMixed defined\n"
     ]
    }
   ],
   "source": [
    "# GAT Model for mixed solvents\n",
    "class GATModelMixed(nn.Module):\n",
    "    \"\"\"Graph Attention Network for mixed solvent prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, node_dim=9, hidden_dim=64, heads=4, drfp_dim=122, kinetics_dim=5):\n",
    "        super().__init__()\n",
    "        # Shared GAT layers\n",
    "        self.conv1 = GATConv(node_dim, hidden_dim, heads=heads, dropout=0.2)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, hidden_dim, heads=1, dropout=0.2)\n",
    "        \n",
    "        # Combine two graph embeddings + DRFP + kinetics + percentage\n",
    "        combined_dim = hidden_dim * 2 + drfp_dim * 2 + kinetics_dim + 1\n",
    "        \n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def _encode_graph(self, graph_batch):\n",
    "        x, edge_index, batch = graph_batch.x, graph_batch.edge_index, graph_batch.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return global_mean_pool(x, batch)\n",
    "    \n",
    "    def forward(self, graph_batch_a, graph_batch_b, drfp_a, drfp_b, kinetics, pct):\n",
    "        # Encode both graphs\n",
    "        emb_a = self._encode_graph(graph_batch_a)\n",
    "        emb_b = self._encode_graph(graph_batch_b)\n",
    "        \n",
    "        # Combine all features\n",
    "        combined = torch.cat([emb_a, emb_b, drfp_a, drfp_b, kinetics, pct.unsqueeze(-1)], dim=-1)\n",
    "        \n",
    "        return self.predictor(combined)\n",
    "\n",
    "print('GATModelMixed defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e53050b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T08:01:02.282477Z",
     "iopub.status.busy": "2026-01-16T08:01:02.282382Z",
     "iopub.status.idle": "2026-01-16T08:01:02.293410Z",
     "shell.execute_reply": "2026-01-16T08:01:02.293053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATModelWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# GAT Wrapper class\n",
    "class GATModelWrapper:\n",
    "    \"\"\"Wrapper for GAT model with training and prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', hidden_dim=64, heads=4, n_models=3):\n",
    "        self.data_type = data\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.heads = heads\n",
    "        self.n_models = n_models\n",
    "        self.models = []\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def _get_kinetics(self, X):\n",
    "        \"\"\"Extract kinetics features.\"\"\"\n",
    "        time_m = X[\"Residence Time\"].values.reshape(-1, 1)\n",
    "        temp_c = X[\"Temperature\"].values.reshape(-1, 1)\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        return np.hstack([time_m, temp_c, inv_temp, log_time, interaction]).astype(np.float32)\n",
    "    \n",
    "    def _get_graphs(self, solvent_names):\n",
    "        \"\"\"Get pre-computed graphs for solvents.\"\"\"\n",
    "        return [SOLVENT_GRAPHS[name].clone() for name in solvent_names]\n",
    "    \n",
    "    def _get_drfp(self, solvent_names):\n",
    "        \"\"\"Get DRFP features for solvents.\"\"\"\n",
    "        return DRFP_FILTERED.loc[solvent_names].values.astype(np.float32)\n",
    "    \n",
    "    def train_model(self, X_train, Y_train, epochs=150):\n",
    "        Y_np = Y_train.values if hasattr(Y_train, 'values') else Y_train\n",
    "        \n",
    "        # Get features\n",
    "        kinetics = self._get_kinetics(X_train)\n",
    "        kinetics_scaled = self.scaler.fit_transform(kinetics)\n",
    "        kinetics_tensor = torch.tensor(kinetics_scaled, dtype=torch.float32).to(device)\n",
    "        Y_tensor = torch.tensor(Y_np, dtype=torch.float32).to(device)\n",
    "        \n",
    "        if self.data_type == 'single':\n",
    "            graphs = self._get_graphs(X_train[\"SOLVENT NAME\"].values)\n",
    "            drfp = self._get_drfp(X_train[\"SOLVENT NAME\"].values)\n",
    "            drfp_tensor = torch.tensor(drfp, dtype=torch.float32).to(device)\n",
    "        else:\n",
    "            graphs_a = self._get_graphs(X_train[\"SOLVENT A NAME\"].values)\n",
    "            graphs_b = self._get_graphs(X_train[\"SOLVENT B NAME\"].values)\n",
    "            drfp_a = self._get_drfp(X_train[\"SOLVENT A NAME\"].values)\n",
    "            drfp_b = self._get_drfp(X_train[\"SOLVENT B NAME\"].values)\n",
    "            drfp_a_tensor = torch.tensor(drfp_a, dtype=torch.float32).to(device)\n",
    "            drfp_b_tensor = torch.tensor(drfp_b, dtype=torch.float32).to(device)\n",
    "            pct = torch.tensor(X_train[\"SolventB%\"].values.astype(np.float32), dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Train multiple models\n",
    "        self.models = []\n",
    "        drfp_dim = DRFP_FILTERED.shape[1]\n",
    "        \n",
    "        for seed in range(self.n_models):\n",
    "            torch.manual_seed(42 + seed)\n",
    "            \n",
    "            if self.data_type == 'single':\n",
    "                model = GATModel(hidden_dim=self.hidden_dim, heads=self.heads, drfp_dim=drfp_dim).to(device)\n",
    "            else:\n",
    "                model = GATModelMixed(hidden_dim=self.hidden_dim, heads=self.heads, drfp_dim=drfp_dim).to(device)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "            criterion = nn.HuberLoss()\n",
    "            \n",
    "            model.train()\n",
    "            batch_size = 32\n",
    "            n_samples = len(Y_np)\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                indices = torch.randperm(n_samples)\n",
    "                for start in range(0, n_samples, batch_size):\n",
    "                    end = min(start + batch_size, n_samples)\n",
    "                    batch_idx = indices[start:end]\n",
    "                    \n",
    "                    batch_kinetics = kinetics_tensor[batch_idx]\n",
    "                    batch_y = Y_tensor[batch_idx]\n",
    "                    \n",
    "                    if self.data_type == 'single':\n",
    "                        batch_graphs = [graphs[i] for i in batch_idx]\n",
    "                        batch_graph = Batch.from_data_list(batch_graphs).to(device)\n",
    "                        batch_drfp = drfp_tensor[batch_idx]\n",
    "                        pred = model(batch_graph, batch_drfp, batch_kinetics)\n",
    "                    else:\n",
    "                        batch_graphs_a = [graphs_a[i] for i in batch_idx]\n",
    "                        batch_graphs_b = [graphs_b[i] for i in batch_idx]\n",
    "                        batch_graph_a = Batch.from_data_list(batch_graphs_a).to(device)\n",
    "                        batch_graph_b = Batch.from_data_list(batch_graphs_b).to(device)\n",
    "                        batch_drfp_a = drfp_a_tensor[batch_idx]\n",
    "                        batch_drfp_b = drfp_b_tensor[batch_idx]\n",
    "                        batch_pct = pct[batch_idx]\n",
    "                        pred = model(batch_graph_a, batch_graph_b, batch_drfp_a, batch_drfp_b, batch_kinetics, batch_pct)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    loss = criterion(pred, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            self.models.append(model)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        kinetics = self._get_kinetics(X_test)\n",
    "        kinetics_scaled = self.scaler.transform(kinetics)\n",
    "        kinetics_tensor = torch.tensor(kinetics_scaled, dtype=torch.float32).to(device)\n",
    "        \n",
    "        if self.data_type == 'single':\n",
    "            graphs = self._get_graphs(X_test[\"SOLVENT NAME\"].values)\n",
    "            graph_batch = Batch.from_data_list(graphs).to(device)\n",
    "            drfp = self._get_drfp(X_test[\"SOLVENT NAME\"].values)\n",
    "            drfp_tensor = torch.tensor(drfp, dtype=torch.float32).to(device)\n",
    "        else:\n",
    "            graphs_a = self._get_graphs(X_test[\"SOLVENT A NAME\"].values)\n",
    "            graphs_b = self._get_graphs(X_test[\"SOLVENT B NAME\"].values)\n",
    "            graph_batch_a = Batch.from_data_list(graphs_a).to(device)\n",
    "            graph_batch_b = Batch.from_data_list(graphs_b).to(device)\n",
    "            drfp_a = self._get_drfp(X_test[\"SOLVENT A NAME\"].values)\n",
    "            drfp_b = self._get_drfp(X_test[\"SOLVENT B NAME\"].values)\n",
    "            drfp_a_tensor = torch.tensor(drfp_a, dtype=torch.float32).to(device)\n",
    "            drfp_b_tensor = torch.tensor(drfp_b, dtype=torch.float32).to(device)\n",
    "            pct = torch.tensor(X_test[\"SolventB%\"].values.astype(np.float32), dtype=torch.float32).to(device)\n",
    "        \n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for model in self.models:\n",
    "                if self.data_type == 'single':\n",
    "                    pred = model(graph_batch, drfp_tensor, kinetics_tensor)\n",
    "                else:\n",
    "                    pred = model(graph_batch_a, graph_batch_b, drfp_a_tensor, drfp_b_tensor, kinetics_tensor, pct)\n",
    "                preds.append(pred.cpu())\n",
    "        \n",
    "        return torch.clamp(torch.stack(preds).mean(dim=0), 0, 1)\n",
    "\n",
    "print('GATModelWrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d795d0c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T08:01:02.294307Z",
     "iopub.status.busy": "2026-01-16T08:01:02.294179Z",
     "iopub.status.idle": "2026-01-16T08:01:17.658764Z",
     "shell.execute_reply": "2026-01-16T08:01:17.658348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test solvent: 1,1,1,3,3,3-Hexafluoropropan-2-ol\n",
      "Training samples: 619, Test samples: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fold MSE: 0.074600\n"
     ]
    }
   ],
   "source": [
    "# Quick test on single fold\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "test_solvent = sorted(X_single[\"SOLVENT NAME\"].unique())[0]\n",
    "mask = X_single[\"SOLVENT NAME\"] != test_solvent\n",
    "\n",
    "print(f\"Test solvent: {test_solvent}\")\n",
    "print(f\"Training samples: {mask.sum()}, Test samples: {(~mask).sum()}\")\n",
    "\n",
    "model = GATModelWrapper(data='single', n_models=2)\n",
    "model.train_model(X_single[mask], Y_single[mask], epochs=100)\n",
    "preds = model.predict(X_single[~mask])\n",
    "\n",
    "actuals = Y_single[~mask].values\n",
    "mse = np.mean((actuals - preds.numpy()) ** 2)\n",
    "print(f'Test fold MSE: {mse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99d9df7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T08:01:32.668367Z",
     "iopub.status.busy": "2026-01-16T08:01:32.667710Z",
     "iopub.status.idle": "2026-01-16T08:15:00.737378Z",
     "shell.execute_reply": "2026-01-16T08:15:00.736989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CV for single solvent data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:33, 33.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [01:06, 33.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:38, 32.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [02:10, 32.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:43, 32.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [03:16, 32.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [03:51, 33.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [04:25, 33.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [04:58, 33.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [05:31, 33.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [06:04, 33.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [06:38, 33.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [07:11, 33.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [07:45, 33.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [08:19, 33.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [08:53, 33.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [09:29, 34.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [10:03, 34.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [10:37, 34.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [11:12, 34.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [11:46, 34.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [12:20, 34.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [12:54, 34.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [13:28, 33.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [13:28, 33.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Solvent MSE: 0.016634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run full CV for single solvent\n",
    "print('Running CV for single solvent data...')\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_preds = []\n",
    "all_actuals = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = GATModelWrapper(data='single', n_models=3)\n",
    "    model.train_model(train_X, train_Y, epochs=150)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    all_preds.append(predictions_np)\n",
    "    all_actuals.append(test_Y.values)\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_actuals = np.vstack(all_actuals)\n",
    "mse_single = np.mean((all_preds - all_actuals) ** 2)\n",
    "print(f'\\nSingle Solvent MSE: {mse_single:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full CV for full data\n",
    "print('Running CV for full data...')\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_preds_full = []\n",
    "all_actuals_full = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = GATModelWrapper(data='full', n_models=3)\n",
    "    model.train_model(train_X, train_Y, epochs=150)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    all_preds_full.append(predictions_np)\n",
    "    all_actuals_full.append(test_Y.values)\n",
    "\n",
    "all_preds_full = np.vstack(all_preds_full)\n",
    "all_actuals_full = np.vstack(all_actuals_full)\n",
    "mse_full = np.mean((all_preds_full - all_actuals_full) ** 2)\n",
    "print(f'\\nFull Data MSE: {mse_full:.6f}')\n",
    "\n",
    "# Overall MSE\n",
    "n_single = len(all_actuals)\n",
    "n_full = len(all_actuals_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "print(f'\\nOverall MSE: {overall_mse:.6f}')\n",
    "print(f'Baseline (exp_030 GP+MLP+LGBM): CV 0.008298')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d442ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GATModelWrapper(data='single', n_models=3)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495566c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GATModelWrapper(data='full', n_models=3)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
