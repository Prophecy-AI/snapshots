## Current Status
- Best CV score: 0.0081 from exp_030 (GP+MLP+LGBM ensemble)
- Best LB score: 0.0877 (exp_030)
- Target: 0.0347 | Gap to target: 152.8%
- Experiments: 105 | Submissions: 23/5 used, 4 remaining

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.315 × CV + 0.0525 (R² = 0.9505)
- Intercept interpretation: Even at CV=0, expected LB is 0.0525
- Are all approaches on the same line? **YES** (all 12 valid submissions)
- **CRITICAL**: Intercept (0.0525) > Target (0.0347)
- Required CV for target: (0.0347 - 0.0525) / 4.315 = **-0.0041 (IMPOSSIBLE)**

**This means the target is UNREACHABLE with current approaches that follow this line.**
**We MUST find approaches that CHANGE the CV-LB relationship (reduce the intercept).**

## Response to Evaluator
- Technical verdict was TRUSTWORTHY. The bias correction experiment was correctly implemented.
- Evaluator's top priority: Implement extrapolation-aware conservative predictions. **AGREE** - this directly targets the intercept problem.
- Key concerns raised: 
  1. In-sample bias correction doesn't help because bias differs between train/test. **Correct diagnosis.**
  2. GNN/ChemBERTa experiments failed on submission. **Need to debug model class mismatch.**
  3. The intercept problem remains unsolved. **This is THE problem to solve.**

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop105_analysis.ipynb` for CV-LB analysis
- Key patterns:
  1. All tabular models (MLP, LGBM, XGB, CatBoost, GP, Ridge) fall on the SAME CV-LB line
  2. The intercept (0.0525) represents structural extrapolation error
  3. Similarity weighting (exp_073) was an outlier with LB=0.1451 (much worse)
  4. Bias correction made CV worse (0.0089 vs 0.0081)

## Recommended Approaches (PRIORITY ORDER)

### 1. EXTRAPOLATION-AWARE CONSERVATIVE PREDICTIONS (HIGHEST PRIORITY)
**Rationale**: Directly targets the intercept problem by making predictions more conservative when extrapolating.

**Implementation**:
```python
class ExtrapolationAwareModel(BaseModel):
    def __init__(self, base_model, blend_weight=0.3):
        self.base_model = base_model
        self.blend_weight = blend_weight
        
    def train_model(self, train_X, train_Y):
        # Train base model
        self.base_model.train_model(train_X, train_Y)
        
        # Store training statistics
        self.train_mean = train_Y.values.mean(axis=0)
        
        # Fit nearest neighbor model for extrapolation detection
        X_features = self.featurizer.featurize(train_X)
        self.nn = NearestNeighbors(n_neighbors=5).fit(X_features)
        
        # Compute training distances for threshold calibration
        train_distances, _ = self.nn.kneighbors(X_features)
        self.distance_threshold = np.percentile(train_distances.mean(axis=1), 90)
        
    def predict(self, test_X):
        # Get base predictions
        base_preds = self.base_model.predict(test_X)
        
        # Compute extrapolation score
        X_features = self.featurizer.featurize(test_X)
        distances, _ = self.nn.kneighbors(X_features)
        extrapolation_score = distances.mean(axis=1) / self.distance_threshold
        
        # Blend toward training mean when extrapolating
        weight = np.clip(extrapolation_score * self.blend_weight, 0, 0.5)
        weight = weight.reshape(-1, 1)
        
        final_preds = (1 - weight) * base_preds + weight * self.train_mean
        
        return final_preds
```

**Why this might work**:
- It doesn't try to improve the model's predictions on training-like data
- It specifically targets the extrapolation problem
- It makes predictions more conservative when we're uncertain
- The training mean is a reasonable fallback when extrapolating
- **This could change the CV-LB relationship (lower intercept)**

**Key insight**: The extrapolation detection should use SOLVENT FEATURES (Spange, DRFP, etc.), not the full feature set. This way, we detect when we're predicting for a solvent that's structurally different from training solvents.

### 2. PROPER GNN IMPLEMENTATION (HIGH PRIORITY)
**Rationale**: GNN operates on molecular graphs, not tabular features. This is a fundamentally different representation that might give a different CV-LB relationship.

**CRITICAL**: Previous GNN experiments failed on submission due to model class mismatch.
- CV was computed with `HybridGNNModelWrapper`
- Submission cells used `GNNModelWrapper` (DIFFERENT CLASS!)

**Implementation requirements**:
1. Define a single model class (e.g., `GNNModel`)
2. Use the SAME class for CV computation AND submission cells
3. Verify before running submission cells

### 3. UNCERTAINTY-WEIGHTED PREDICTIONS (MEDIUM PRIORITY)
**Rationale**: Use ensemble disagreement to identify uncertain predictions and make them more conservative.

**Implementation**:
```python
# Train multiple models with different seeds
models = [train_model(seed=i) for i in range(5)]

# Get predictions from each model
all_preds = [m.predict(X) for m in models]

# Compute mean and variance
mean_pred = np.mean(all_preds, axis=0)
var_pred = np.var(all_preds, axis=0)

# Blend toward training mean when variance is high
weight = np.clip(var_pred / var_threshold, 0, 0.5)
final_pred = (1 - weight) * mean_pred + weight * train_mean
```

### 4. PSEUDO-LABELING (MEDIUM PRIORITY)
**Rationale**: Use confident predictions on test set to augment training. Could help with distribution shift.

**Implementation**:
1. Train model on training data
2. Predict on test data
3. Select confident predictions (low variance across ensemble)
4. Add confident predictions to training data
5. Retrain model

## What NOT to Try
- ❌ More MLP/LGBM/XGB/CatBoost variants (all fall on the same CV-LB line)
- ❌ In-sample bias correction (doesn't help, exp_104 showed this)
- ❌ Similarity weighting without careful implementation (exp_073 was much worse)
- ❌ Multi-seed ensembles for variance reduction (we're 152% from target, not 1-2%)
- ❌ Hyperparameter tuning (won't change the intercept)

## Validation Notes
- CV scheme: Leave-One-Out (24 folds single, 13 folds full) - REQUIRED by competition
- The CV-LB relationship is LB = 4.315 × CV + 0.0525
- Any approach that improves CV but stays on this line will NOT reach target
- We need approaches that CHANGE the relationship (reduce intercept)

## CRITICAL REMINDERS
1. **VERIFY MODEL CLASS CONSISTENCY**: Before logging ANY experiment, verify that submission cells use the EXACT same model class as CV computation.
2. **FOCUS ON INTERCEPT REDUCTION**: Don't just improve CV. We need to change the CV-LB relationship.
3. **4 SUBMISSIONS REMAINING**: Use them wisely to test approaches that might change the relationship.
4. **TARGET IS REACHABLE**: The benchmark paper achieved MSE 0.0039. The target (0.0347) is between this and our best LB (0.0877). We need to find the right approach.

## IMMEDIATE NEXT EXPERIMENT: Extrapolation-Aware Conservative Predictions

Implement the extrapolation-aware model that:
1. Uses the best base model (CatBoost + XGBoost ensemble from ens-model kernel)
2. Computes distance to nearest training solvent using SOLVENT FEATURES ONLY
3. Blends toward training mean when extrapolating
4. Tests different blend weights (0.1, 0.2, 0.3, 0.4, 0.5)

**Expected outcome**:
- CV might be slightly worse (we're being more conservative)
- But LB might be better (conservative predictions hurt less on hard solvents)
- This could change the CV-LB relationship (lower intercept)