## Current Status
- Best CV score: 0.0081 from exp_049/050/053 (CatBoost+XGBoost)
- Best LB score: 0.0877 from exp_030 (GP+MLP+LGBM ensemble)
- Target: 0.0347 | Gap to target: 0.053 (152.8%)
- Submissions remaining: 3

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.09 × CV + 0.0546 (R² = 0.96)
- Intercept interpretation: Even at CV=0, expected LB is 0.0546
- Are all approaches on the same line? **YES**
- Required CV for target: (0.0347 - 0.0546) / 4.09 = -0.0049 (IMPOSSIBLE)

**CRITICAL FINDING**: The intercept (0.0546) is HIGHER than the target (0.0347).
This means the target is MATHEMATICALLY UNREACHABLE by improving CV alone.
We need approaches that CHANGE THE CV-LB RELATIONSHIP, not just improve CV.

## Response to Evaluator
- Technical verdict was TRUSTWORTHY. The per-class model was correctly implemented.
- Evaluator's top priority: DO NOT SUBMIT exp_121 (CV=0.0167, 107% worse than best).
- Key concerns raised: CV-LB intercept (0.0548) > target (0.0347).
- Evaluator correctly identified that the target requires CHANGING the CV-LB relationship.

**I AGREE with the evaluator's assessment.** After 124 experiments, all approaches fall on the same CV-LB line. The problem is NOT the model - it's DISTRIBUTION SHIFT between training and test solvents.

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop124_analysis.ipynb` for CV-LB analysis
- Key patterns:
  1. ALL model families (MLP, LGBM, XGB, CatBoost, GP, GNN, ChemBERTa) fall on same CV-LB line
  2. The intercept (0.0546) represents structural extrapolation error
  3. Test solvents are fundamentally different from training solvents
  4. GroupKFold gives HIGHER MSE than LOO (0.0136 vs 0.0086)

## What Has Been Exhaustively Tried (124 experiments)
- Tabular Models: MLP, LightGBM, XGBoost, CatBoost, GP, Ridge, RF
- GNN Attempts: GCNConv, GATConv, Simple GAT, Multi-order GAT, Hybrid GNN
- Transformer Attempts: ChemBERTa embeddings, ChemBERTa PCA, ChemBERTa frozen
- Feature Engineering: Spange, DRFP, ACS, Fragprints, Combined features
- Ensemble Methods: Mean, Weighted, Median, Stacking
- Distribution Shift: Pseudo-labeling, Domain adversarial, Uncertainty weighting
- Calibration: Shrink toward mean, Bias correction, Conservative blending
- Physics-Informed: Mass balance, Softmax normalization, Yield ratio
- Per-Class Models: Solvent class-specific models

**ALL APPROACHES FALL ON THE SAME CV-LB LINE!**

## Recommended Approaches (Priority Order)

### PRIORITY 1: Submit Best Available Model
Given only 3 submissions remaining and the structural CV-LB gap, we should:
1. **Submit exp_030** (best LB: 0.0877) to confirm it's still our best
2. This uses GP+MLP+LGBM ensemble with Spange+DRFP features

### PRIORITY 2: Try ONE More Fundamentally Different Approach
If we have time before final submission:
1. **True Molecular Transformer**: Use a pretrained molecular transformer (not just embeddings)
   - Fine-tune on this task instead of using frozen embeddings
   - This might give a different CV-LB relationship
   
2. **3D Conformer Features**: Use 3D molecular conformations instead of 2D graphs
   - RDKit can generate 3D conformers
   - This captures spatial information that 2D features miss

### PRIORITY 3: Aggressive Post-Processing (Last Resort)
If nothing else works:
1. **Clip predictions to training distribution**
   - Clip to [0.05, 0.95] quantiles of training targets
   - This reduces extreme predictions that hurt LB

2. **Blend toward population mean**
   - For samples that look like extrapolation, blend toward mean
   - Use distance to training distribution as weight

## What NOT to Try
- ❌ More MLP/LGBM/XGB/CatBoost variants (all on same line)
- ❌ More feature engineering (already tried Spange, DRFP, ACS, Fragprints)
- ❌ More ensemble weights (already optimized)
- ❌ Per-class models (made things worse)
- ❌ GroupKFold (gives higher MSE)
- ❌ Multi-seed optimization (too far from target)

## Validation Notes
- CV scheme: Leave-One-Out by solvent (24 folds single, 13 folds full)
- CV-LB relationship: LB = 4.09 × CV + 0.0546 (R² = 0.96)
- Expected LB for best CV (0.0081): 0.0877 (matches actual best LB!)

## STRATEGIC RECOMMENDATION

**Given the situation (124 experiments, 3 submissions, structural CV-LB gap), the most pragmatic approach is:**

1. **Accept that the target (0.0347) may be unreachable** with available techniques
2. **Submit our best model (exp_030, LB=0.0877)** to confirm final score
3. **Try ONE more fundamentally different approach** (molecular transformer or 3D conformers)
4. **If it falls on same line, submit best available**

The benchmark paper achieved MSE 0.0039 using GNN with full dataset access. We are predicting for UNSEEN solvents, which is fundamentally harder. The CV-LB gap (4.09x slope + 0.0546 intercept) represents this extrapolation challenge.

## IMPORTANT: Model Class Consistency
When implementing any new approach, ALWAYS verify:
1. The model class used for CV computation
2. The model class used in submission cells (last 3 cells)
3. They MUST be the SAME class

Previous experiments had model class mismatch (e.g., HybridGNNModelWrapper in CV but GNNModelWrapper in submission). This invalidates the experiment.
