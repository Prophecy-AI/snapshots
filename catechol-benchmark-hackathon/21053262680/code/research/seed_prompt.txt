## Current Status
- Best CV score: 0.0081 from exp_049/exp_050/exp_053 (Leave-One-Out validation)
- Best LB score: 0.0877 from exp_030
- Target: 0.0347 | Gap to target: 152.7%

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.31 × CV + 0.0525 (R² = 0.95)
- Intercept interpretation: Even at CV=0, expected LB is 0.0525
- Are all approaches on the same line? **YES** (all 12 valid submissions)
- **CRITICAL**: Intercept (0.0525) > Target (0.0347)
- Required CV for target: (0.0347 - 0.0525) / 4.31 = -0.0041 (IMPOSSIBLE)

**This is a DISTRIBUTION SHIFT problem, not a model optimization problem.**

## Response to Evaluator
- Technical verdict was **TRUSTWORTHY**. The exp_101 implementation is correct.
- Evaluator's top priority: **SUBMIT exp_101 to check CV-LB relationship**. I AGREE.
- Key concerns raised: 
  1. Negative predictions should be clipped to [0, 1] - Valid, should fix
  2. Weight difference from mixall [0.25 vs 0.4] - Minor, unlikely critical
  3. SolventB% scaling difference - Should verify
- The evaluator correctly identifies that we need to test if GroupKFold validation gives a different CV-LB relationship.

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop102_analysis.ipynb` for CV-LB analysis
- Key patterns:
  1. ALL tabular models (MLP, LGBM, XGB, CatBoost, RF, GP, Ridge) fall on SAME CV-LB line
  2. GNN and ChemBERTa attempts had higher CV (>0.014) and didn't break the line
  3. The intercept (0.0525) represents STRUCTURAL extrapolation error
  4. GroupKFold (5 splits) vs Leave-One-Out (24 folds) is a fundamentally different validation scheme

## Recommended Approaches

### IMMEDIATE: Submit exp_101 to check GroupKFold CV-LB relationship
- exp_101 has CV=0.014193 with GroupKFold (5 splits)
- If LB follows same line: Expected LB ≈ 0.114
- If LB < 0.10: GroupKFold might have different CV-LB relationship
- This is our best remaining hypothesis for breaking the intercept barrier

### PRIORITY 1: Physics-Informed Constraints (if GroupKFold doesn't help)
Based on web research, physics-informed approaches can improve OOD generalization:
1. **Yield sum constraint**: P2 + P3 + SM ≤ 1 (mass balance)
2. **Non-negativity constraint**: All yields ≥ 0
3. **Arrhenius temperature dependence**: k = A × exp(-Ea/RT)
4. **Implement as soft loss terms**: Add penalty for constraint violations

```python
# Physics-informed loss
def physics_loss(pred, target):
    mse = F.mse_loss(pred, target)
    # Yield sum constraint
    sum_penalty = F.relu(pred.sum(dim=1) - 1.0).mean()
    # Non-negativity (already handled by clipping, but add soft penalty)
    neg_penalty = F.relu(-pred).mean()
    return mse + 0.1 * sum_penalty + 0.1 * neg_penalty
```

### PRIORITY 2: Bayesian/Uncertainty-Weighted Predictions
From research on Bayesian CRNN and uncertainty quantification:
1. Train ensemble with dropout for uncertainty estimation
2. For high-uncertainty predictions, blend toward training mean
3. Use MC Dropout at test time to estimate prediction variance

```python
# Uncertainty-weighted prediction
def predict_with_uncertainty(model, X, n_samples=20):
    model.train()  # Enable dropout
    preds = [model(X) for _ in range(n_samples)]
    mean_pred = torch.stack(preds).mean(dim=0)
    std_pred = torch.stack(preds).std(dim=0)
    
    # Blend toward training mean for high uncertainty
    train_mean = torch.tensor([0.3, 0.3, 0.4])  # Approximate
    weight = torch.clamp(std_pred / 0.1, 0, 1)
    final_pred = (1 - weight) * mean_pred + weight * train_mean
    return final_pred
```

### PRIORITY 3: Reaction-Condition Contrastive Learning
From research on Egret model:
1. Pre-train with contrastive learning on reaction conditions
2. Pull together reactions with similar temperature/time
3. Push apart reactions with different conditions
4. This aligns latent space with physical invariants

### PRIORITY 4: Data Augmentation for Yield Prediction
From Schwaller et al. (2020):
1. Generate synthetic reactions by varying conditions
2. Ensure augmented examples obey mass-action and Arrhenius relations
3. Use test-time augmentation for uncertainty estimates

## What NOT to Try
- ❌ More MLP/LGBM/XGB/CatBoost variants (all on same CV-LB line)
- ❌ GNN from scratch (all attempts had CV > 0.018)
- ❌ ChemBERTa variants (all attempts had CV > 0.014)
- ❌ Multi-seed optimization (we're 152% from target)
- ❌ Hyperparameter tuning within current approaches

## Validation Notes
- Current: Leave-One-Out (24 folds for single, 13 for full)
- Alternative: GroupKFold (5 splits) - being tested in exp_101
- CV-LB gap is STRUCTURAL - no amount of CV improvement can reach target
- Need approaches that CHANGE the CV-LB relationship, not improve CV

## Submission Strategy (4 remaining)
1. **SUBMIT exp_101** - Check if GroupKFold has different CV-LB relationship
2. If GroupKFold helps: Optimize within that framework
3. If GroupKFold doesn't help: Try physics-informed constraints
4. Save 1-2 submissions for final ensemble

## Key Insight from Research
The web search confirms that OOD generalization in chemical reaction prediction is a fundamental challenge. The key strategies are:
1. **Physics-informed constraints** - Embed kinetic laws as loss terms
2. **Contrastive learning** - Align representations with physical invariants
3. **Data augmentation** - Generate physics-consistent synthetic data
4. **Uncertainty quantification** - Conservative predictions for OOD samples

The target IS reachable - the benchmark paper achieved MSE 0.0039. We need to find the approach that changes the CV-LB relationship.
