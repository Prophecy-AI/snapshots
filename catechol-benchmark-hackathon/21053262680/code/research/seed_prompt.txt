## Current Status
- Best CV score: 0.0081 from exp_049/exp_050/exp_053 (CatBoost+XGBoost ensemble)
- Best LB score: 0.0877 from exp_030 (GP+MLP+LGBM ensemble)
- Target: 0.0347 | Gap to target: 152.8%

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.31 * CV + 0.0525 (R² = 0.95)
- Intercept interpretation: Even at CV=0, expected LB is 0.0525
- **CRITICAL: Intercept (0.0525) > Target (0.0347)**
- Required CV for target: (0.0347 - 0.0525) / 4.31 = -0.0041 (IMPOSSIBLE!)
- All 12 submissions (excluding RF outlier) fall on the SAME LINE
- **We have a DISTRIBUTION SHIFT problem. Improving CV alone CANNOT reach target.**

## Response to Evaluator
- Technical verdict was TRUSTWORTHY for exp_082 (Dual-Encoder GNN)
- Evaluator's top priority: "Pivot away from training GNNs from scratch"
- **I AGREE**: GNN experiments consistently underperform (CV=0.024 vs tabular CV=0.008)
- The benchmark's GNN success (MSE 0.0039) likely came from pre-training, not architecture
- Key concern: CV-LB intercept problem persists across ALL approaches

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop83_analysis.ipynb` for CV-LB analysis
- Key patterns:
  1. All tabular models (MLP, LGBM, XGB, CatBoost, GP, Ridge) fall on SAME CV-LB line
  2. GNN experiments (exp_081, exp_082) achieved WORSE CV than tabular
  3. exp_073 (RF ensemble) is an outlier with LB=0.1451 (much worse than expected)
  4. The "mixall" kernel claims "good CV-LB" with GroupKFold(5) validation

## Key Insights from Public Kernels

### 1. "mixall" kernel (9 votes)
- Uses **GroupKFold(5)** instead of Leave-One-Out
- Claims "good CV/LB" correlation
- Ensemble: MLP + XGBoost + RF + LightGBM
- Runtime: only 2m 15s
- **HYPOTHESIS**: GroupKFold(5) might have a DIFFERENT CV-LB relationship

### 2. "Ens Model" kernel (7 votes)
- CatBoost + XGBoost ensemble
- Combined features: spange + acs_pca + drfps + fragprints + smiles
- Correlation-based feature filtering (threshold=0.90)
- Numeric feature engineering: T_x_RT, RT_log, T_inv, RT_scaled
- **Yield normalization**: clip to [0, inf], then normalize so sum ≤ 1
- Different weights for single vs full data (Single: 7:6, Full: 1:2)

## Recommended Approaches (Priority Order)

### 1. SUBMIT exp_079 (GroupKFold validation) - HIGHEST PRIORITY
- CV=0.01103 with GroupKFold(5)
- Expected LB from LOO line: 4.31 * 0.01103 + 0.0525 = 0.100
- **If LB is significantly better than 0.100, GroupKFold has a different CV-LB relationship**
- This is a quick test that could reveal a breakthrough
- **Rationale**: The "mixall" kernel claims "good CV-LB" - we need to verify this

### 2. Implement Yield Normalization (Domain Constraint)
- From "Ens Model" kernel: clip predictions to [0, inf], normalize so sum ≤ 1
- This is a **physics-based constraint** that should help generalization
- Yields are fractions that must sum to ≤ 1 (some product may be lost)
- Apply to ALL models, not just new ones

### 3. Extrapolation Detection + Conservative Predictions
- Compute distance to nearest training solvent for each test sample
- When extrapolation_score is high, blend toward training mean
- This directly addresses the distribution shift problem
```python
from sklearn.neighbors import NearestNeighbors
nn = NearestNeighbors(n_neighbors=5).fit(X_train_features)
distances, _ = nn.kneighbors(X_test_features)
extrapolation_score = distances.mean(axis=1)
weight = np.clip(extrapolation_score / threshold, 0, 1)
final_pred = (1 - weight) * model_pred + weight * train_mean
```

### 4. Try Pre-trained Molecular Embeddings (ChemBERTa Frozen)
- Instead of training GNN from scratch, use frozen ChemBERTa embeddings
- The benchmark's success likely came from pre-training
- Use embeddings as features for tabular models (CatBoost, XGBoost)

## What NOT to Try
- ❌ More MLP variants - exhaustively tested (50+ experiments)
- ❌ Training GNNs from scratch - consistently underperforms (CV=0.024 vs 0.008)
- ❌ Multi-seed ensembles - too far from target (152.8% gap)
- ❌ Hyperparameter optimization - won't change CV-LB relationship
- ❌ More feature engineering without yield normalization

## Validation Notes
- Current CV scheme: Leave-One-Out (24 folds for single, 13 for full)
- Alternative: GroupKFold(5) - faster, potentially different CV-LB relationship
- **CRITICAL**: After EVERY submission, check if it falls on the same CV-LB line
- If a new approach has a DIFFERENT CV-LB relationship, that's a breakthrough

## Submission Strategy (4 remaining)
1. **FIRST**: Submit exp_079 (GroupKFold) to test CV-LB relationship
2. **SECOND**: If GroupKFold shows different relationship, optimize within that approach
3. **THIRD**: If not, try yield normalization + extrapolation detection
4. **FOURTH**: Final best model

## CRITICAL REMINDER
The target IS reachable. The benchmark achieved MSE 0.0039. We need to find the approach that CHANGES the CV-LB relationship, not just improves CV. The intercept (0.0525) is the enemy, not the CV score.
