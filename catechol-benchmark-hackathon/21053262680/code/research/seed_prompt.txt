## Current Status
- Best CV score: 0.0081 from exp_049/050/053 (pending LB)
- Best LB score: 0.0877 from exp_030 (CV=0.0083)
- Target: 0.0347 | Gap to target: 0.0530 (152.7%)
- Remaining submissions: 3

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.09 × CV + 0.0546 (R² = 0.96)
- Intercept interpretation: Even at CV=0, expected LB is 0.0546
- Are all approaches on the same line? **YES** - all 13 valid submissions
- **CRITICAL**: Intercept (0.0546) > Target (0.0347)
- Required CV for target: (0.0347 - 0.0546) / 4.09 = -0.0049 (IMPOSSIBLE)

**The target is MATHEMATICALLY UNREACHABLE with current approaches.**
We MUST find an approach that CHANGES the CV-LB relationship, not just improves CV.

## Response to Evaluator
- Technical verdict was TRUSTWORTHY. Calibration experiment was correctly implemented.
- Evaluator's top priority: **PIVOT to physics-constrained predictions**. I AGREE.
- Key concerns raised: 
  1. Calibration (shrinking toward mean) is conceptually flawed - it doesn't address distribution shift
  2. Only 3 submissions remaining - each is precious
  3. The intercept problem means we need to CHANGE the relationship, not improve CV
- How I'm addressing: Recommending physics-constrained approaches and proper GNN implementation

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop116_analysis.ipynb` for CV-LB analysis
- Key patterns:
  1. ALL tabular models (MLP, LGBM, XGB, CatBoost, GP, Ridge) fall on the SAME CV-LB line
  2. GNN/ChemBERTa attempts had model class mismatch issues (CV model ≠ submission model)
  3. Calibration (shrinking toward mean) made CV WORSE, not better
  4. The benchmark paper achieved MSE 0.0039 using GNN with DRFP features

## Recommended Approaches (PRIORITY ORDER)

### 1. PROPERLY IMPLEMENTED GNN (HIGH PRIORITY)
The benchmark paper achieved MSE 0.0039 using GNN. Our GNN attempts had model class mismatch issues.

**CRITICAL CHECKLIST:**
- [ ] Define GNN model class (e.g., `SimpleGNN`)
- [ ] Use SAME class name in CV computation AND submission cells
- [ ] Verify: `model = SimpleGNN(data='single')` in BOTH places
- [ ] Use PyTorch Geometric with GCNConv or GATConv
- [ ] Use DRFP or Morgan fingerprints as node features

**Simple GNN Architecture:**
```python
import torch
import torch.nn as nn
from torch_geometric.nn import GCNConv, global_mean_pool

class SimpleGNN(nn.Module):
    def __init__(self, data='single', hidden_dim=64, num_layers=3):
        super().__init__()
        self.data_mode = data
        # Node embedding from atom features
        self.node_embed = nn.Linear(atom_feat_dim, hidden_dim)
        # GCN layers
        self.convs = nn.ModuleList([
            GCNConv(hidden_dim, hidden_dim) for _ in range(num_layers)
        ])
        # Output head
        self.head = nn.Sequential(
            nn.Linear(hidden_dim + 2, 64),  # +2 for T, RT
            nn.ReLU(),
            nn.Linear(64, 3),
            nn.Sigmoid()
        )
    
    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = self.node_embed(x)
        for conv in self.convs:
            x = conv(x, edge_index).relu()
        x = global_mean_pool(x, batch)  # Graph-level embedding
        # Concatenate with process conditions
        x = torch.cat([x, data.process_features], dim=1)
        return self.head(x)
```

### 2. PHYSICS-CONSTRAINED PREDICTIONS (HIGH PRIORITY)
Physics constraints that generalize to ANY solvent:

**a) Mass Balance Normalization:**
```python
# Yields should sum to ~1 (mass balance)
def constrained_predict(raw_preds):
    # Normalize predictions to sum to 1
    return raw_preds / raw_preds.sum(axis=1, keepdims=True)
```
This is already done in current models, but verify it's applied correctly.

**b) Arrhenius Temperature Dependence:**
```python
# k = A * exp(-Ea / RT)
# Add features: 1/T, ln(RT), T*RT
# These capture the physics of temperature-dependent reactions
```
This is already done. Consider making predictions more conservative at extreme temperatures.

**c) Conservative Predictions for Extrapolation:**
```python
# Detect extrapolation using nearest neighbor distance
from sklearn.neighbors import NearestNeighbors
nn = NearestNeighbors(n_neighbors=5).fit(X_train_features)
distances, _ = nn.kneighbors(X_test_features)
extrapolation_score = distances.mean(axis=1)

# Blend toward training mean when extrapolating
threshold = np.percentile(train_distances, 90)
weight = np.clip(extrapolation_score / threshold, 0, 1)
final_pred = (1 - weight) * model_pred + weight * train_mean
```

### 3. SOLVENT SIMILARITY-BASED WEIGHTING (MEDIUM PRIORITY)
Use Tanimoto similarity to weight predictions:

```python
from rdkit import Chem
from rdkit.Chem import AllChem, DataStructs

def compute_similarity(smiles1, smiles2):
    mol1 = Chem.MolFromSmiles(smiles1)
    mol2 = Chem.MolFromSmiles(smiles2)
    fp1 = AllChem.GetMorganFingerprintAsBitVect(mol1, 2, nBits=2048)
    fp2 = AllChem.GetMorganFingerprintAsBitVect(mol2, 2, nBits=2048)
    return DataStructs.TanimotoSimilarity(fp1, fp2)

# For each test solvent, find most similar training solvents
# Weight predictions by similarity
```

### 4. DOMAIN-ADVERSARIAL TRAINING (LOWER PRIORITY)
Train a model that can't distinguish between training and test solvents:

```python
# Add a domain classifier that predicts train vs test
# Use gradient reversal to make features domain-invariant
# This could help with distribution shift
```

## What NOT to Try
- ❌ More tabular model variants (MLP, LGBM, XGB, CatBoost) - all on same line
- ❌ Calibration/shrinkage toward mean - made CV worse
- ❌ Hyperparameter tuning - won't change the intercept
- ❌ Multi-seed ensembles - optimization is forbidden when 152% from target
- ❌ Any approach that just improves CV without changing the CV-LB relationship

## Validation Notes
- CV scheme: Leave-One-Out for single solvents (24 folds), Leave-One-Ramp-Out for full data (13 folds)
- **CRITICAL**: Verify model class consistency between CV and submission cells
- After EVERY submission, update CV-LB analysis to check if relationship changed

## Submission Strategy (3 remaining)
1. **Submission 1**: Best pending experiment (exp_049/050/053 with CV=0.0081) to verify CV-LB line
2. **Submission 2**: Properly implemented GNN (if CV is competitive)
3. **Submission 3**: Best approach that shows DIFFERENT CV-LB relationship

## Key Insight
The benchmark paper achieved MSE 0.0039. Our best LB is 0.0877. The target is 0.0347.
The benchmark used GNN with DRFP features. Our GNN attempts had model class mismatch issues.

**The path forward is to properly implement a GNN that:**
1. Uses the SAME model class in CV and submission cells
2. Operates on molecular graphs, not tabular features
3. Captures structural information that tabular models miss
4. Potentially changes the CV-LB relationship

## MANDATORY CHECKS BEFORE LOGGING ANY EXPERIMENT
1. What model class did you use for CV computation?
2. Open the submission cells (last 3 cells)
3. Verify BOTH `model = YourModel(data='single')` AND `model = YourModel(data='full')` use the SAME class
4. If they don't match, FIX THEM before running submission cells
5. If you can't fix them, DO NOT LOG the experiment
