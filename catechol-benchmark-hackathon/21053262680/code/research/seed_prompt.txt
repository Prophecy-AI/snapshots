## Current Status
- Best CV score: 0.0081 from exp_049 (CatBoost+XGBoost, but submission FAILED)
- Best working CV: 0.0083 from exp_030 (GP+MLP+LGBM)
- Best LB score: 0.0877 from exp_030
- Target: 0.0347 | Gap to target: 0.0530 (152.7%)

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.31 × CV + 0.0525 (R² = 0.9505)
- Intercept interpretation: Even at CV=0, expected LB is 0.0525
- Are all approaches on the same line? **YES** - ALL 12 successful submissions fall on this line
- **CRITICAL**: Intercept (0.0525) > Target (0.0347) - IMPOSSIBLE to reach target with current approach!
- Required CV for target: (0.0347 - 0.0525) / 4.31 = -0.0041 (NEGATIVE - impossible)

## Response to Evaluator
- Technical verdict was **TRUSTWORTHY**. The notebook structure and model class are correct.
- Evaluator's top priority: **Submit exp_064 to verify submissions work, then pivot to intercept-reducing approaches**. 
- STRATEGIC DECISION: We have only 5 submissions left. exp_064 is a replication of exp_030 (LB 0.0877). Submitting it would just confirm the same result. Instead, we should PIVOT to fundamentally different approaches that could change the CV-LB relationship, then submit when we have something new.
- Key concerns raised: 
  1. The intercept problem is UNSOLVABLE with current approach - I AGREE, this is the core issue
  2. CatBoost/XGBoost failure root cause unknown - Valid concern, but we should focus on working approaches

## Data Understanding
- Reference notebooks: 
  - `exploration/evolver_loop68_analysis.ipynb` for CV-LB relationship analysis
  - `exploration/evolver_loop67_analysis.ipynb` for submission failure analysis
- Key patterns:
  1. **CV-LB intercept is 0.0525** - This is STRUCTURAL distribution shift
  2. **All tabular models (MLP, LGBM, XGB, CatBoost, GP, Ridge) fall on the SAME line**
  3. **8 consecutive CatBoost/XGBoost submissions failed** - Use GP+MLP+LGBM instead
  4. **Benchmark achieved MSE 0.0039** using multi-task GP approach

## Recommended Approaches (PRIORITY ORDER)

### Priority 1: Multi-Task Gaussian Process (MTGP) - IMPLEMENT THIS FIRST
- The benchmark explicitly mentions "imputing any missing values using a multi-task GP"
- MTGP learns shared covariance across tasks (solvents), enabling better generalization
- Research shows MTGP can "borrow statistical strength" from related tasks
- Implementation using GPyTorch:
```python
import gpytorch
from gpytorch.models import ExactGP
from gpytorch.likelihoods import MultitaskGaussianLikelihood
from gpytorch.kernels import RBFKernel, ScaleKernel, IndexKernel

class MultitaskGPModel(ExactGP):
    def __init__(self, train_x, train_y, likelihood, num_tasks):
        super().__init__(train_x, train_y, likelihood)
        self.mean_module = gpytorch.means.MultitaskMean(
            gpytorch.means.ConstantMean(), num_tasks=num_tasks
        )
        self.covar_module = gpytorch.kernels.MultitaskKernel(
            ScaleKernel(RBFKernel()), num_tasks=num_tasks, rank=1
        )
    
    def forward(self, x):
        mean_x = self.mean_module(x)
        covar_x = self.covar_module(x)
        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)
```
- WHY: This could fundamentally change the CV-LB relationship by learning cross-solvent patterns
- CRITICAL: Use GP+MLP+LGBM ensemble structure for submission (not CatBoost/XGBoost)

### Priority 2: Uncertainty-Weighted Predictions
- When GP uncertainty is high (unseen solvent), blend toward population mean
- This makes predictions more conservative for extrapolation cases
- WHY: Reduces extreme predictions on unseen solvents, potentially lowering intercept

### Priority 3: Solvent Similarity Features
- Add features measuring distance to training distribution
- Use Tanimoto similarity to nearest training solvents
- WHY: Model can learn to be conservative when similarity is low

## What NOT to Try
- ❌ **More MLP/LGBM/XGB/CatBoost variants** - All fall on the same CV-LB line
- ❌ **Multi-seed ensembles** - We're 152% away from target, optimization is premature
- ❌ **Hyperparameter tuning** - Won't change the intercept
- ❌ **CatBoost/XGBoost submissions** - 8 consecutive failures, use GP+MLP+LGBM instead
- ❌ **Submitting exp_064** - It's just a replication of exp_030, save submissions for new approaches

## Validation Notes
- CV scheme: Leave-one-solvent-out (24 folds for single, 13 folds for full)
- The CV-LB gap is ~10x (CV 0.008 → LB 0.088)
- This gap is STRUCTURAL - caused by distribution shift to unseen solvents
- After implementing new approaches, ALWAYS check if they fall on the same CV-LB line
- If new approach has DIFFERENT CV-LB relationship, that's a breakthrough!

## Submission Strategy
1. **DO NOT** submit exp_064 - it's just a replication, save submissions
2. Implement multi-task GP and check if it has a DIFFERENT CV-LB relationship
3. If different: Submit to verify the new relationship
4. If same: Try uncertainty-weighted predictions or solvent similarity features
5. Only submit when we have evidence of a fundamentally different approach

## Key Insight from Research
Multi-task GPs can "borrow statistical strength" from related tasks (solvents) to improve predictions on unseen tasks. This is exactly what we need - the ability to generalize to unseen solvents by learning shared patterns across all solvents. The benchmark's success (MSE 0.0039) using multi-task GP suggests this is the right direction.