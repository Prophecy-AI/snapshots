## Current Status
- Best CV score: 0.0081 from exp_030 (GP+MLP+LGBM ensemble)
- Best LB score: 0.0877 (exp_030)
- Target: 0.0347 | Gap to target: 0.0530 (152.8%)

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.29 × CV + 0.0528 (R² = 0.95)
- Intercept interpretation: Even at CV=0, expected LB is 0.0528
- Are all approaches on the same line? **YES**
- **CRITICAL**: Intercept (0.0528) > Target (0.0347)
- Required CV for target: (0.0347 - 0.0528) / 4.29 = -0.0042 (IMPOSSIBLE)

## Response to Evaluator
- Technical verdict was **TRUSTWORTHY** - Implementation was correct
- Evaluator's top priority: **Submit exp_101 to check CV-LB relationship**
- Key concerns raised: 
  1. Negative predictions in submission (92 rows) - **THIS CAUSED THE FAILURE**
  2. Weight difference from mixall kernel (0.25 vs 0.4 for MLP)
  3. SolventB% scaling difference (divided by 100 vs not)
- **Submission FAILED** with "Evaluation metric raised an unexpected error"
- Root cause: Negative predictions are invalid for yields

## Data Understanding
- Reference notebooks: 
  - `exploration/evolver_loop102_analysis.ipynb` - Submission failure analysis
  - `research/kernels/matthewmaree_ens-model/ens-model.ipynb` - Shows proper clipping/renormalization
- Key patterns:
  1. Yields must be in [0, 1] range
  2. Sum of yields should not exceed 1 (physically impossible)
  3. The Ens Model kernel clips predictions and renormalizes

## IMMEDIATE FIX REQUIRED

The submission failed because predictions were not clipped. The fix is simple:

```python
def predict(self, test_X):
    # ... existing prediction code ...
    
    # CRITICAL: Clip predictions to valid range
    final_preds = np.clip(final_preds, 0.0, 1.0)
    
    # Optional: Renormalize if sum > 1
    totals = final_preds.sum(axis=1, keepdims=True)
    divisor = np.maximum(totals, 1.0)
    final_preds = final_preds / divisor
    
    return torch.tensor(final_preds)
```

## Recommended Approaches (Priority Order)

### 1. FIX THE SUBMISSION FAILURE (HIGHEST PRIORITY)
- Re-run exp_101 with prediction clipping
- Add `np.clip(final_preds, 0.0, 1.0)` in the predict method
- This will allow the submission to be evaluated

### 2. IMPLEMENT ENS MODEL APPROACH (FROM MATTHEWMAREE KERNEL)
The Ens Model kernel has several techniques we haven't tried:
- **Correlation-based feature filtering** with priority (spange > acs > drfps > frag > smiles)
- **Multiple feature sources**: spange, acs_pca, drfps, fragprints, smiles combined
- **CatBoost + XGBoost ensemble** with optimized weights:
  - Single: cat_weight=7.0, xgb_weight=6.0
  - Full: cat_weight=1.0, xgb_weight=2.0
- **Proper clipping and renormalization**

### 3. TRY APPROACHES THAT COULD CHANGE CV-LB RELATIONSHIP
Since all tabular approaches fall on the same CV-LB line, we need to try:

a) **Extrapolation detection + conservative predictions**:
```python
from sklearn.neighbors import NearestNeighbors
nn = NearestNeighbors(n_neighbors=5).fit(X_train_features)
distances, _ = nn.kneighbors(X_test_features)
extrapolation_score = distances.mean(axis=1)
# Blend toward mean when extrapolating
weight = np.clip(extrapolation_score / threshold, 0, 1)
final_pred = (1 - weight) * model_pred + weight * train_mean
```

b) **Domain constraints**:
- Yields must be non-negative
- Yields should sum to ≤1
- Apply Arrhenius temperature dependence

c) **Different representations** (GNN, ChemBERTa):
- All previous GNN attempts had CV > 0.018 (worse than baseline)
- But they might have different CV-LB relationship
- Need to verify submission cells match CV model class

## What NOT to Try
- ❌ More MLP/LGBM/XGB variants without clipping (exhaustively tested)
- ❌ Multi-seed optimization (too far from target - 152.8% gap)
- ❌ Hyperparameter tuning (won't change the CV-LB intercept)
- ❌ GroupKFold without fixing the negative predictions issue

## Validation Notes
- CV scheme: Leave-One-Out for single solvent (24 folds), Leave-One-Ramp-Out for full data (13 folds)
- **CRITICAL**: Always clip predictions to [0, 1] range before submission
- **CRITICAL**: Verify submission cells use the SAME model class as CV computation

## SPECIFIC INSTRUCTIONS FOR NEXT EXPERIMENT

1. **Create exp_102**: Fix exp_101 by adding prediction clipping
   - Copy the EnsembleModel from exp_101
   - Add `np.clip(final_preds, 0.0, 1.0)` in predict method
   - Optionally add renormalization if sum > 1
   - Re-run CV and generate submission

2. **If exp_102 submission succeeds**:
   - Check if the LB score follows the same CV-LB line
   - If LB is better than expected from the line, this approach is promising
   - If LB follows the line, we need to try different approaches

3. **If exp_102 submission fails again**:
   - Check for other invalid values (NaN, inf)
   - Verify submission format matches template exactly

## KEY INSIGHT

The fundamental problem is that the CV-LB intercept (0.0528) is HIGHER than the target (0.0347). This means:
- No amount of CV improvement can reach the target with current approaches
- We need to find an approach that CHANGES the CV-LB relationship
- The mixall kernel with GroupKFold was a hypothesis to test this
- But first, we need to fix the submission failure to get LB feedback
