## Current Status
- Best CV score: 0.0081 from exp_049 (CatBoost+XGBoost)
- Best LB score: 0.0877 from exp_030 (GP Ensemble)
- Target: 0.0347 | Gap to target: 152.8%

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.29 × CV + 0.0528 (R² = 0.9523)
- Intercept interpretation: Even at CV=0, expected LB is 0.0528
- Are all approaches on the same line? **YES** (12/13 submissions)
- **CRITICAL**: Intercept (0.0528) > Target (0.0347)
- Required CV for target: (0.0347 - 0.0528) / 4.29 = -0.0042 (IMPOSSIBLE)

## Response to Evaluator
- Technical verdict was **TRUSTWORTHY**. The SolventB% bug fix was correct.
- Evaluator's top priority: **SUBMIT exp_103 to check CV-LB relationship**. I partially agree - but exp_103 has higher CV (0.01124) than best (0.0081), so predicted LB would be worse. Instead, I recommend implementing bias correction first.
- Key concerns raised: CV (0.01124) is higher than best CV (0.0083), predicted LB ≈ 0.10 (worse than best). This is expected since GroupKFold (5 splits) is an easier validation task than leave-one-out (24 folds).
- **My synthesis**: Rather than submit exp_103 (which will likely give worse LB), implement bias correction on the best model first. This addresses the ROOT CAUSE (intercept) rather than just checking the relationship.

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop104_analysis.ipynb` for CV-LB analysis
- Key patterns:
  1. ALL tabular models (MLP, LGBM, XGB, CatBoost, GP, Ridge) fall on the SAME CV-LB line
  2. The intercept (0.0528) represents STRUCTURAL extrapolation error
  3. Test solvents are fundamentally different from training solvents
  4. No amount of CV improvement can reach target if intercept > target

## Recommended Approaches

### PRIORITY 1: Post-hoc Bias Correction (NEW - from web research)
**Rationale**: Web research revealed that post-hoc intercept-bias correction is a standard technique for reducing systematic offset when deploying models on unseen chemicals.

**Implementation**:
```python
# After training, compute average residual on validation set
preds = model.predict(X_val)
bias = preds.mean() - y_val.mean()

# Apply correction to test predictions
corrected_pred = model.predict(X_test) - bias
```

This directly addresses the intercept problem by calibrating predictions based on validation residuals.

**Key insight from web research**:
> "Apply a post‑hoc intercept‑bias correction – after fitting, compute the average residual on a small validation set of known compounds and subtract that mean bias from all future predictions."

### PRIORITY 2: Implement Bias Correction on Best Model (exp_030 approach)
**Rationale**: exp_030 achieved best LB (0.0877). Implement bias correction on the same model architecture.

**Steps**:
1. Replicate exp_030 model (GP Ensemble with MLP, LGBM, XGB, GP)
2. During CV, compute per-fold bias: `bias = preds.mean() - y_val.mean()`
3. Store average bias across folds
4. Apply bias correction to test predictions: `corrected = preds - avg_bias`

### PRIORITY 3: Per-Target Bias Correction
**Rationale**: Different targets (Product 2, Product 3, SM) may have different biases.

**Implementation**:
```python
# Compute per-target bias
for target_idx in range(3):
    bias[target_idx] = preds[:, target_idx].mean() - y_val[:, target_idx].mean()
```

### PRIORITY 4: Fold-Specific Bias Correction
**Rationale**: Different folds (solvents) may have different biases. Apply fold-specific correction.

### PRIORITY 5: Submit Best Bias-Corrected Model
**Rationale**: After implementing bias correction, submit to check if it reduces the intercept.

## What NOT to Try
- ❌ Submit exp_103 without bias correction (higher CV, predicted worse LB)
- ❌ More MLP/LGBM/XGB variants without bias correction (all fall on same line)
- ❌ GNN/ChemBERTa without proper model class verification (previous attempts had issues)
- ❌ Multi-seed ensembles (optimization is forbidden when gap > 5%)
- ❌ Hyperparameter tuning (doesn't change the intercept)

## Validation Notes
- CV scheme: Leave-One-Out (24 folds for single, 13 for full)
- Key insight: Bias correction should reduce the intercept, not just improve CV
- After submission, plot (CV, LB) point to check if it's BELOW the line

## Immediate Action Plan
1. **First**: Implement bias correction on the best model architecture (from exp_030)
2. **Second**: Compute CV with bias correction
3. **Third**: Generate submission with bias-corrected predictions
4. **Fourth**: Submit to check if bias correction reduces the intercept

## Template Compliance
- MUST follow the official template structure (last 3 cells)
- Model class in submission cells MUST match CV computation class
- Predictions must be clipped to [0, 1] and renormalized if sum > 1