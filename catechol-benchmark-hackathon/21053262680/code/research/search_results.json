{
  "query": "How does the catechol benchmark paper achieve MSE 0.0039 using graph attention networks and what specific architecture and training procedure do they use?",
  "results": [
    {
      "title": "ANSWER",
      "text": "The available search results do not provide details on the specific graph\u2011attention\u2011network architecture or training procedure the catechol benchmark paper used to obtain an MSE of\u202f0.0039. ([arXiv\u202f2512.19530](https://arxiv.org/abs/2512.19530))",
      "url": ""
    },
    {
      "title": "Learning Continuous Solvent Effects from Transient Flow Data - arXiv",
      "text": "[2512.19530] Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2512.19530\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2512.19530**(cs)\n[Submitted on 22 Dec 2025]\n# Title:Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\nAuthors:[Hongsheng Xing](https://arxiv.org/search/cs?searchtype=author&amp;query=Xing,+H),[Qiuxin Si](https://arxiv.org/search/cs?searchtype=author&amp;query=Si,+Q)\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n[View PDF](https://arxiv.org/pdf/2512.19530)[HTML (experimental)](https://arxiv.org/html/2512.19530v1)> > Abstract:\n> Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \\textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.\n> Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \\textbf{MSE of 0.0039} ($\\pm$ 0.0003), representing a 60\\% error reduction over competitive baselines and a $&gt;25\\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning. Comments:|13 pages, 6 figures|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI)|\nMSCclasses:|68T07, 92E20, 62M45|\nACMclasses:|I.2.1; I.2.6; J.2|\nCite as:|[arXiv:2512.19530](https://arxiv.org/abs/2512.19530)[cs.LG]|\n|(or[arXiv:2512.19530v1](https://arxiv.org/abs/2512.19530v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2512.19530](https://doi.org/10.48550/arXiv.2512.19530)\nFocus to learn more\narXiv-issued DOI via DataCite (pending registration)\n|\n## Submission history\nFrom: Hongsheng Xing [[view email](https://arxiv.org/show-email/9dc7457b/2512.19530)]\n**[v1]**Mon, 22 Dec 2025 16:19:01 UTC (2,198 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n* [View PDF](https://arxiv.org/pdf/2512.19530)\n* [HTML (experimental)](https://arxiv.org/html/2512.19530v1)\n* [TeX Source](https://arxiv.org/src/2512.19530)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2512.19530&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2512.19530&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2025-12](https://arxiv.org/list/cs.LG/2025-12)\nChange to browse by:\n[cs](https://arxiv.org/abs/2512.19530?context=cs)\n[cs.AI](https://arxiv.org/abs/2512.19530?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2512.19530)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2512.19530)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2512.19530)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2512.19530&amp;description=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2512.19530&amp;title=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.or...",
      "url": "https://arxiv.org/abs/2512.19530"
    },
    {
      "title": "Comparison Between CNN and GNN Pipelines for Analysing the Brain in ...",
      "text": "Comparison Between CNN and GNN Pipelines for Analysing the Brain\nin Development\nAntoine Bourlier1,2, Elodie Chaillou2, Jean-Yves Ramel3and Mohamed Slimane1\n1LIFAT, Universite de Tours, 64 Av. Jean Portalis, Tours, France \u00b4\n2\nINRAe, CNRS, Universite de Tours, Nouzilly, France \u00b4\n3LISTIC, Universite de Savoie Mont-Blanc, Chamb \u00b4 ery, France \u00b4\nKeywords: Graph, Machine Learning, MRI, Segmentation.\nAbstract: In this study, we present a new pipeline designed for the analysis and comparison of non-conventional animal\nbrain models, such as sheep, without relying on neuroanatomical priors. This innovative approach combines\nan automatic MRI segmentation with graph neural networks (GNNs) to overcome the limitations of traditional\nmethods. Conventional tools often depend on predefined anatomical atlases and are typically limited in their\nability to adapt to the unique characteristics of developing brains or non-conventional animal models. By\ngenerating regions of interest directly from MR images and constructing a graph representation of the brain,\nour method eliminates biases associated with predefined templates. Our results show that the GNN-based\npipeline is more efficient in terms of accuracy for an age prediction task (63.22%) compared to a classical\nCNN architecture (59.77%). GNNs offer notable advantages, including improved interpretability and the\nability to model complex relational structures within brain data. Overall, our approach provides a promising\nsolution for unbiased, adaptable, and interpretable analysis of brain MRIs, particularly for developing brains\nand non-conventional animal models.\n1 INTRODUCTION\nAutomated methods have facilitated brain MRI anal\u0002ysis, especially in humans and conventional animal\nmodels (Kaur and Gaba, 2021; Park and Friston,\n2013). However, such tools are rarely available to\nstudy developing brains or non-conventional animal\nmodels like sheep. In these cases, brain structures\nidentification is often manual or based on automatic\nsegmentation using signal intensity and templates,\nwhen available (Nitzsche et al., 2015; Ella et al.,\n2017). These methods depend on biological priors\nand the accuracy of atlases, which may not fully cap\u0002ture individual variations or patterns associated to dif\u0002ferent brain disorders. These issues are especially\nchallenging for developing brains, where contrast is\nweak, development is uneven, and some structures are\nnot visible (Li et al., 2019). Additionally, using pre\u0002defined regions may limit the discovery of new brain\ncorrelates.\nTo address segmentation bias, convolutional neu\u0002ral networks (CNNs) have been introduced, as they\nwork directly on MR images without segmentation\n(Srinivasan et al., 2024; Coupeau et al., 2022). CNNs\nprovide valuable whole-brain or abnormality-level in\u0002formation but require large labelled datasets to learn\nlow-level image features for classification or segmen\u0002tation tasks. This makes them unsuitable for the de\u0002veloping brain or non-conventional animal models\nwith small cohorts.\nIn this paper, we present a pipeline to address\nboth segmentation biases and CNN limitations. We\npropose generating regions of interest (ROIs) with\u0002out relying on neuro-anatomical priors. We use voxel\nintensities to create segmented images via 2 differ\u0002ent segmentation algorithms. Additionally, we use\ngraph neural networks (GNNs) to identify and anal\u0002yse anatomical patterns, as GNNs model the brain as\ninterconnected patches, capturing complex relation\u0002ships between regions (Cui et al., 2021; Li et al.,\n2021; Ravinder et al., 2023). By avoiding prede\u0002fined atlases, our method allows more flexible, image\u0002driven exploration of the brain. This approach is par\u0002ticularly useful for studying non-conventional animal\nmodels of brain development, such as sheep. It offers\nthe potential to discover new structures and patterns\nin both human and animal studies, enhancing under\u0002Bourlier, A., Chaillou, E., Ramel, J.-Y. and Slimane, M.\nComparison Between CNN and GNN Pipelines for Analysing the Brain in Development.\nDOI: 10.5220/0013173500003912\nPaper published under CC license (CC BY-NC-ND 4.0)\nIn Proceedings of the 20th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISIGRAPP 2025) - Volume 3: VISAPP, pages\n475-482\nISBN: 978-989-758-728-3; ISSN: 2184-4321\nProceedings Copyright \u00a9 2025 by SCITEPRESS \u2013 Science and Technology Publications, Lda.\n475\nstanding and improving the diagnosis and treatment\nof developing brain disorders.\nThis paper focuses on the specific task related to\nstudy the developing brain. We tested various GNN\narchitectures and compared them to a classical CNN\napproach. The comparison addresses the challenge of\npredicting brain age in non-conventional animal mod\u0002els without neuro-anatomical priors. The next sec\u0002tions discuss the limitations of classical brain MRI\nprocessing methods to study developing brain disor\u0002ders and non-conventional animal models. We de\u0002tail our pipeline, including segmentation, graph gen\u0002eration, and GNN prediction. Then, we present the\nexperimental comparison with a CNN approach, fol\u0002lowed by a discussion of its advantages and limita\u0002tions.\n2 RELATED WORKS\n2.1 Classical Approaches Used on Brain\nMRI\nThe 2 main tasks studied in the literature are im\u0002age/brain segmentation (Coupeau et al., 2022) and\nimage/brain classification (Srinivasan et al., 2024;\nKaur and Gaba, 2021; Poriya, 2023). In both cases,\nmachine learning algorithms provide powerful tools\nsuch as CNN and graph convolutional network (GCN)\nlayers that compute and find on its own the most rele\u0002vant features. Whether CNN or GNN is chosen, both\nrequire specific key such as pre-processing and patch\nextraction. The aim of the MRI pre-processing (de\u0002noising, normalisation etc.) is to adjust the inten\u0002sity values of the images to a standard range in or\u0002der to ensure consistency. A resampling step is used\nto align images to a common voxel size or resolution\nand a registration step can be added to align images\nto a standard anatomical space, often using a template\nbrain. To remove non-brain tissues (e.g., skull, scalp)\ncropping and skull-stripping are performed on MRI\nimages.\n2.1.1 Segmentation\nThe aim of segmentation is to delineate and identify\nanatomic ROI in the brain MRI, segmented images\nbeing used to create a graph representation. Segmen\u0002tation is performed manually or using atlases based\non individual brain images or templates (Van Essen\nand Drury, 1997; Yang et al., 2020; Fil et al., 2021).\nThey are used for ROI identification, delineating vari\u0002ous regions and structures or serve as reference points\nto align individual MRI scans to a common space, fa\u0002cilitating consistent and accurate analysis across sub\u0002jects.\n2.1.2 CNN Design\nA CNN typically consists of multiple layers, includ\u0002ing convolutional layers, pooling layers, and fully\nconnected layers. Using advanced CNN architec\u0002tures, such as AlexNet (Krizhevsky et al., 2012), or\nResNet (He et al., 2016), enhances the model\u2019s abil\u0002ity to learn complex patterns and achieve high per\u0002formance in various MRI analysis tasks, including\nclassification, clustering etc. Incorporating biologi\u0002cal priors through brain atlases can further refine these\nmethods, offering improved accuracy and consistency\nin brain MRI analysis. Concerning brain age predic\u0002tion, several CNN architectures have been proposed\nincluding VGG, ResNet, and DenseNet (Cole et al.,\n2017; Jiang et al., 2020).. More advanced CNN archi\u0002tectures including attention mechanisms have since\nbeen developed to boost the representational power\nand improve prediction accuracy (Lam et al., 2020;\nCheng et al., 2021).\n2.1.3 Graph Design\nNodes of a graph are usually defined at a region level\n(i.e., one node per brain structure). The way the re\u0002gions are chosen is really linked with the aim of the\nstudy and could represent neurons, anatomical struc\u0002tures, brain tissues, voxels, etc. From an anatomi\u0002cal point of view, node features provide information\nabout the positi...",
      "url": "https://www.scitepress.org/Papers/2025/131735/131735.pdf"
    },
    {
      "title": "Graph Attention Networks Paper Explained With Illustration and ...",
      "text": "Graph Attention Networks Paper Explained With Illustration and PyTorch Implementation | Ebrahim Pichka\n# Graph Attention Networks Paper Explained With Illustration and PyTorch Implementation\nA detailed and illustrated walkthrough of the \u201cGraph Attention Networks\u201d paper by Veli\u010dkovi\u0107 et al. with the PyTorch implementation of the proposed model.\n![](https://cdn-images-1.medium.com/max/4240/1*JeY2ChpCHoH84dyJ-Ugu3Q.png)\n# Introduction\nGraph neural networks (GNNs) are a powerful class of neural networks that operate on graph-structured data. They learn node representations (embeddings) by aggregating information from a node\u2019s local neighborhood. This concept is known as***\u2018message passing\u2019***in the graph representation learning literature.\nMessages (embeddings) are passed between nodes in the graph through multiple layers of the GNN. Each node**aggregates**the messages from its**neighbors**to**update**its representation. This process is repeated across layers, allowing nodes to obtain representations that encode richer information about the graph. Some of the important variants of GNNs can are GraphSAGE [2], Graph Convolution Network [3], etc. You can explore more GNN variants[here](https://paperswithcode.com/methods/category/graph-models).\n![](https://cdn-images-1.medium.com/max/2000/1*sJ01stdUwds-YN4-5SYiyQ.png)\n**Graph Attention Networks (GAT)**[1] are a special class of GNNs that were proposed to improve upon this message-passing scheme. They introduced a learnable**attention mechanism**that enables a node to decide which neighbor nodes are more important when aggregating messages from their local neighborhood by assigning a weight between each source and target node instead of aggregating information from all neighbors with equal weights.\nEmpirically, Graph Attention Networks have been shown to outperform many other GNN models on tasks such as node classification, link prediction, and graph classification. They demonstrated state-of-the-art performance on several benchmark graph datasets.\nIn this post, we will walk through the crucial part of the original \u201cGraph Attention Networks\u201d paper by Veli\u010dkovi\u0107 et al. [1], explain these parts, and simultaneously implement the notions proposed in the paper using PyTorch framework to better grasp the intuition of the GAT method.\nYou can also access the full code used in this post, containing the training and validation code in[this GitHub repository](https://github.com/ebrahimpichka/GAT-pt)\n# Going Through the Paper\n## Section 1 - Introduction\nAfter broadly reviewing the existing methods in the graph representation learning literature in Section 1, \u201c*Introduction*\u201d, the Graph Attention Network (GAT) is introduced. The authors mention:\n1. An overall view of the incorporated attention mechanism.\n2. Three properties of GATs, namely efficient computation, general applicability to all nodes, and usability in**inductive learning**.\n3. Benchmarks and Datasets on which they evaluated the GAT\u2019s performance.\n![](https://cdn-images-1.medium.com/max/3394/1*fsN-_tEJoW-3llxs34xxRQ.png)\nThen After comparing their approach to some existing methods and mentioning the general similarities and differences between them, they move forward to the next section of the paper.\n## Section 2 - GAT Architecture\nIn this section, which accounts for the main part of the paper, the Graph Attention Network architecture is laid out in detail. To move forward with the explanation, assume the proposed architecture performs on a graph with***N nodes (V = {v\u1d62}; i=1,\u2026,N)***and each node is represented with a**vector h\u1d62**of**F elements**, With any arbitrary setting of edges existing between nodes.\n![](https://cdn-images-1.medium.com/max/2000/1*HTBen2imL_rH-j0unv-LpQ.png)\nThe authors first start by characterizing a single**Graph Attention Layer**, and how it operates, which becomes the building blocks of a Graph Attention Network. In general, a single GAT layer is supposed to take a graph with its given node embeddings (representations) as input, propagate information to local neighbor nodes, and output an updated representation of nodes.\n![](https://cdn-images-1.medium.com/max/2000/1*bZu6PYombELP47kEkF5pEg.png)\nAs highlighted above, to do so, first, they state that all the input node feature vectors (***h\u1d62***) to the GA-layer are linearly transformed (i.e. multiplied by**a weight matrix*W***), in PyTorch, it is generally done as follows:\n![](https://cdn-images-1.medium.com/max/2288/1*iUfoc0v7-Nf5wMuv25RzfQ.png)\n```\n`importtorchfromtorchimportnn# in\\_features -&gt;&gt; F and out\\_feature -&gt;&gt; F'in\\_features=...out\\_feature=...# instanciate the learnable weight matrix W (FxF')W=nn.Parameter(torch.empty(size=(in\\_features,out\\_feature)))# Initialize the weight matrix Wnn.init.xavier\\_normal\\_(W)# multiply W and h (h is input features of all the nodes -&gt; NxF matrix)h\\_transformed=torch.mm(h,W)`\n```\nNow having in mind that we obtained a transformed version of our input node features (embeddings), we jump a few steps forward to observe and understand what is our final objective in a GAT layer.\nAs described in the paper, at the end of a graph attention layer,**for each node*i***, we need to obtain a new feature vector that is more structure- and context-aware from its neighborhood.\nThis is done by calculating a**weighted sum**of neighboring node features followed by a non-linear activation function*\u03c3*. This weighted sum is also known as the \u2018Aggregation Step\u2019 in the general GNN layer operations, according to Graph ML literature.\nThese**weights*\u03b1\u1d62\u2c7c***\u2208 [0, 1] are**learned**and computed by an attention mechanism that**denotes the importance**of the**neighbor*j***features for**node*i***during message passing and aggregation.\n![](https://cdn-images-1.medium.com/max/2204/1*1VOm2GtHtIFHk9N-mc2dEg.png)\n![](https://cdn-images-1.medium.com/max/2576/1*nMAaVyiVh_awOiu7iocyUA.png)\nNow let\u2019s see how these attention**weights*\u03b1\u1d62\u2c7c***are computed for each pair of node*i*and its neighbor*j*:\nIn short, attention**weights*\u03b1\u1d62\u2c7c***are calculated as below\n![](https://cdn-images-1.medium.com/max/2000/1*2tU3NKNVke4ytwVOCocgyQ.png)\nwhere the***e\u1d62\u2c7c***are***attention scores***and the Softmax function is applied so that all the weights are in the [0, 1] interval and sum to 1.\nThe attention**scores*e\u1d62\u2c7c***are now calculated between**each node*i***and its**neighbors*j*\u2208*N\u1d62***through the attention function***a*(\u2026)**as such:\n![](https://cdn-images-1.medium.com/max/3478/1*0-A9rQ5r7zOZKHxjq0cZGA.png)\nWhere**||**denotes the**concatenation**of two transformed node embeddings, and**a**is a vector of**learnable**parameters (i.e.,**attention parameters**) of the size*2 x F\u2019*(twice the size of transformed embeddings).\nAnd the**(a\u1d40)**is the**transpose**of the vector**a**, resulting in the whole expression**a\u1d40 [Wh\u1d62 || Wh\u2c7c]**being the**dot (inner) product**between \u201ca\u201d and the concatenation of transformed embeddings.\nThe whole operation is illustrated below:\n![](https://cdn-images-1.medium.com/max/3640/1*MY09NqbYWf-AmemC5YlmCA.png)\nIn PyTorch, to achieve these scores, we take a slightly different approach. Because it is more efficient to compute***e\u1d62\u2c7c***between**all pairs of nodes**and then select only those which represent existing edges between nodes. To calculate all***e\u1d62\u2c7c***:\n```\n`# instanciate the learnable attention parameter vector `a`a=nn.Parameter(torch.empty(size=(2\\*out\\_feature,1)))# Initialize the parameter vector `a`nn.init.xavier\\_normal\\_(a)# we obtained `h\\_transformed` in the previous code snippet# calculating the dot product of all node embeddings\n# and first half the attention vector parameters (corresponding to neighbor messages)source\\_scores=torch.matmul(h\\_transformed,self.a[:out\\_feature,:])# calculating the dot product of all node embeddings\n# and second half the attention vector parameters (corresponding to target node)target\\_scores=torch.matmul(h\\_transformed,self.a[out\\_feature:,:])# broadcast adde=source\\_scores+target\\_scores.Te=self.leakyrelu(e)`\n```\nThe last pa...",
      "url": "https://epichka.com/blog/2023/gat-paper-explained"
    },
    {
      "title": "The multiverse of data preprocessing and analysis in graph-based ...",
      "text": "<div><div><header></header><div><div><ul><li><a><span><span><span>View\u00a0<strong>PDF</strong></span></span></span></a></li><li></li></ul></div><div><article><div><p><a href=\"https://www.sciencedirect.com/journal/neuroscience-and-biobehavioral-reviews\"><span><span></span></span></a></p><p><a href=\"https://www.sciencedirect.com/journal/neuroscience-and-biobehavioral-reviews/vol/165/suppl/C\"><span><span></span></span></a></p></div><div><p><span>Under a Creative Commons </span><a href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"><span><span>license</span></span></a></p><p><span></span>Open access</p></div><div><div><h2>Highlights</h2><div><ul><li><span>\u2022</span><span><p>Data analysis variability in neuroimaging hinders replicability.</p></span></li><li><span>\u2022</span><span><p>Analyses across multiple defensible options examine the robustness of the results.</p></span></li><li><span>\u2022</span><span><p>We conducted a systematic literature review to identify analytical options.</p></span></li><li><span>\u2022</span><span><p>We identified 61 steps and 102 parameter settings in performing graph-fMRI analysis.</p></span></li><li><span>\u2022</span><span><p>Interactive visualization of these analytical choices is made available as a Shiny app.</p></span></li></ul></div></div><div><h2>Abstract</h2><div><p>The large number of different analytical choices used by researchers is partly responsible for the challenge of replication in neuroimaging studies. For an exhaustive robustness analysis, knowledge of the full space of analytical options is essential. We conducted a systematic literature review to identify the analytical decisions in functional neuroimaging data preprocessing and analysis in the emerging field of cognitive network neuroscience. We found 61 different steps, with 17 of them having debatable parameter choices. Scrubbing, global signal regression, and spatial smoothing are among the controversial steps. There is no standardized order in which different steps are applied, and the parameter settings within several steps vary widely across studies. By aggregating the pipelines across studies, we propose three taxonomic levels to categorize analytical choices: 1) inclusion or exclusion of specific steps, 2) parameter tuning within steps, and 3) distinct sequencing of steps. We have developed a decision support application with high educational value called METEOR to facilitate access to the data in order to design well-informed robustness (multiverse) analysis.</p></div></div></div><ul><li></li><li></li></ul><div><h2>Keywords</h2><p><span>Functional magnetic resonance imaging \u2013 fMRI</span></p><p><span>Network neuroscience</span></p><p><span>Graph theory</span></p><p><span>Robustness</span></p><p><span>Multiverse analysis</span></p><p><span>Forking paths</span></p><p><span>Data preprocessing</span></p><p><span>Shiny app</span></p></div><section><header><h2>Cited by (0)</h2></header></section><p><span>\u00a9 2024 The Author(s). Published by Elsevier Ltd.</span></p></article></div></div></div></div>",
      "url": "https://www.sciencedirect.com/science/article/pii/S0149763424003154"
    },
    {
      "title": "Graph Attention Networks. Graph Machine Learning | by Ashish Kumar",
      "text": "Graph Attention Networks. Graph Machine Learning | by Ashish Kumar | Medium\n[Sitemap](https://medium.com/sitemap/sitemap.xml)\n[Open in app](https://play.google.com/store/apps/details?id=com.medium.reader&amp;referrer=utm_source=mobileNavBar&amp;source=post_page---top_nav_layout_nav-----------------------------------------)\nSign up\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@ashish28082002.ak/graph-attention-networks-52f03591b3cc&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\n[\nWrite\n](https://medium.com/m/signin?operation=register&amp;redirect=https://medium.com/new-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n[\nSearch\n](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\nSign up\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@ashish28082002.ak/graph-attention-networks-52f03591b3cc&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n# Graph Attention Networks\n[\n![Ashish Kumar](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n](https://medium.com/@ashish28082002.ak?source=post_page---byline--52f03591b3cc---------------------------------------)\n[Ashish Kumar](https://medium.com/@ashish28082002.ak?source=post_page---byline--52f03591b3cc---------------------------------------)\n18 min read\n\u00b7Oct 20, 2023\n[\n](https://medium.com/m/signin?actionUrl=https://medium.com/_/vote/p/52f03591b3cc&amp;operation=register&amp;redirect=https://medium.com/@ashish28082002.ak/graph-attention-networks-52f03591b3cc&amp;user=Ashish+Kumar&amp;userId=a9750c595b3a&amp;source=---header_actions--52f03591b3cc---------------------clap_footer------------------)\n--\n[](https://medium.com/m/signin?actionUrl=https://medium.com/_/bookmark/p/52f03591b3cc&amp;operation=register&amp;redirect=https://medium.com/@ashish28082002.ak/graph-attention-networks-52f03591b3cc&amp;source=---header_actions--52f03591b3cc---------------------bookmark_footer------------------)\nListen\nShare\nGraph attention networks (GATs) can learn from graph-structured data, such as social networks, citation networks, or knowledge graphs. GATs use a mechanism called***attention***to assign different weights to the nodes and edges of a graph, based on their relevance and importance for a given task.\nThis way, GATs can capture both the local and global structure of a graph, as well as the features of its nodes and edges. In this blog post, we will explain how GATs work, and show some applications of GATs in various domains, and improvements in this field over time.\n## How it works :\nWe have some set of Node Features in the input layer :\nPress enter or click to view image in full size\n![]()\n> here, h : input to the layer , N : number of nodes, d : number of features for each node\nPress enter or click to view image in full size\n![]()\n> here, h\u2019 : output of the layer, N : Number of Nodes, d\u2019 : new representation of feature matrix for each node\nThe transformation from d to d\u2019 is done by the Weight Matrix :\n![]()\n**Self Attention**: We define an attention coefficient**e**that captures the importance of node j\u2019s features to node i.\n![]()\nThe clock part in the below figure shows the Leaky RELU step.\nPress enter or click to view image in full size\n![]()\n**Normalisation using Masked Attention :**The overall attention coefficient for node i needs to be normalised to bring it in range [0,1]. When doing so, we can consider normalising over only few nodes, e.g. here we are normalising over 1-hop neighbours of i. It is upon us that upto which hop neighbours we want to normalise.\n![]()\nN(vi) are the 1-hop neighbours of node vi\n**Output representation using weighted sum :**For the node i, we have the output representation as :\n![]()\nNow this can be repeated for all nodes, h1,h2,\u2026hN giving us h\u20191, h\u20192,...h\u2019N\nFor efficient learning, we can have***multi-head attention***in all the intermediate layers for each node :\nPress enter or click to view image in full size\n![]()\nK : number of heads\nthis increases the feature dimension to Kd\u2019.\nFor the output of the final prediction layer to be of dimension d\u2019, we normalise (average) it by dividing it by K:\nPress enter or click to view image in full size\n![]()\nPress enter or click to view image in full size\n![]()\nThe arrows shows different attention heads. In intermediate layers, we concat them. In Final Prediction Layer, we average them. [Graph Attention Networks Layer \u2014Image from[Petar Veli\u010dkovi\u0107](https://github.com/PetarV-/GAT).]\nIn this way, we get the final representation of each of the node i , following the attention mechanism.\n## **Applications :**\n### Recommendor Systems :\nIn a collaborative filtering task, the core problem is to find out how informative an entity would be for predicting the future behavior of a target user. Using an attention mechanism, we can enable Graph Convolution Networks to do such an analysis when the underlying data is modeled as a graph. For example,[GARec](https://arxiv.org/pdf/2201.05499.pdf)is a model-based recommender system that applies an attention mechanism along with a spatial GCN on a recommender graph to extract embeddings for users and items.\nPress enter or click to view image in full size\n![]()\nA sample of heterogeneous recommender system graph [[source](https://arxiv.org/pdf/2201.05499.pdf)]\nFigure above presents a sample of such a graph for explicit rating data, while the goal is to predict the weights of edges marked with \u2018?\u2019. Each user in the graph could connect to another user through instances of different meta-paths such as \u2018user-item-user\u2019 or \u2018user-content-user\u2019. Likewise, the items could connect through \u2018item-user-item\u2019 and \u2018item-content-item\u2019 meta-paths. The GARec is designed to predict the user u\u2019s interest to an item i.\n### Sentiment Analysis :\nAmid the surge in user-generated content online, understanding the sentiment of specific elements is crucial for both businesses and customers. Existing deep learning methods often overlook the connection between the sentiment of a particular aspect and the overall text structure. This hinders the effective use of syntactic information.[This paper](https://ieeexplore.ieee.org/document/8995381)uses a deep learning model that leverages graph neural networks and graph-based attention mechanisms to analyze sentiment based on different aspects. The given text is considered as a graph based on its syntactic structure and the target is the specific region of the graph.\nPress enter or click to view image in full size\n![]()\nAn example of the syntactic graph. [[source](https://ieeexplore.ieee.org/document/8995381)]\nStructural attention model and graph attention model are used to concentrate on relations between words and certain regions of the graph.The input text is treated as graph, emphasizing the relationship between words and specific areas within it using structural and graph-based attention models.\n### Fraud Detection :\nFraud detection, which is the task of identifying and preventing unauthorized or illegal activities, such as credit card fraud, identity theft, insurance fraud, etc. It is challenging because fraudsters often use sophisticated techniques to evade detection, such as creating fake accounts, hiding their identities, or manipulating their behaviors. We can benefit from using graph data to capture the complex relationships and patterns among entities, such as users, transactions, products, etc. e.g.[This paper](https://arxiv.org/abs/2202.06096)addresses fraud detection using an application of attention. Fraudsters often blend in with legitimate users through camouflage, either by connecting to them or providing ...",
      "url": "https://medium.com/@ashish28082002.ak/graph-attention-networks-52f03591b3cc"
    },
    {
      "title": "An end-to-end attention-based approach for learning on graphs",
      "text": "# Computer Science > Machine Learning\n\n**arXiv:2402.10793** (cs)\n\n\\[Submitted on 16 Feb 2024 ( [v1](https://arxiv.org/abs/2402.10793v1)), last revised 9 Jun 2025 (this version, v3)\\]\n\n# Title:An end-to-end attention-based approach for learning on graphs\n\nAuthors: [David Buterez](https://arxiv.org/search/cs?searchtype=author&query=Buterez,+D), [Jon Paul Janet](https://arxiv.org/search/cs?searchtype=author&query=Janet,+J+P), [Dino Oglic](https://arxiv.org/search/cs?searchtype=author&query=Oglic,+D), [Pietro Lio](https://arxiv.org/search/cs?searchtype=author&query=Lio,+P)\n\nView a PDF of the paper titled An end-to-end attention-based approach for learning on graphs, by David Buterez and 3 other authors\n\n[View PDF](https://arxiv.org/pdf/2402.10793) [HTML (experimental)](https://arxiv.org/html/2402.10793v3)\n\n> Abstract:There has been a recent surge in transformer-based architectures for learning on graphs, mainly motivated by attention as an effective learning mechanism and the desire to supersede handcrafted operators characteristic of message passing schemes. However, concerns over their empirical effectiveness, scalability, and complexity of the pre-processing steps have been raised, especially in relation to much simpler graph neural networks that typically perform on par with them across a wide range of benchmarks. To tackle these shortcomings, we consider graphs as sets of edges and propose a purely attention-based approach consisting of an encoder and an attention pooling mechanism. The encoder vertically interleaves masked and vanilla self-attention modules to learn an effective representations of edges, while allowing for tackling possible misspecifications in input graphs. Despite its simplicity, the approach outperforms fine-tuned message passing baselines and recently proposed transformer-based methods on more than 70 node and graph-level tasks, including challenging long-range benchmarks. Moreover, we demonstrate state-of-the-art performance across different tasks, ranging from molecular to vision graphs, and heterophilous node classification. The approach also outperforms graph neural networks and transformers in transfer learning settings, and scales much better than alternatives with a similar performance level or expressive power.\n\n|     |     |\n| --- | --- |\n| Comments: | Now published in Nature Communications |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI) |\n| Cite as: | [arXiv:2402.10793](https://arxiv.org/abs/2402.10793) \\[cs.LG\\] |\n| (or [arXiv:2402.10793v3](https://arxiv.org/abs/2402.10793v3) \\[cs.LG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2402.10793](https://doi.org/10.48550/arXiv.2402.10793) <br>Focus to learn more<br>arXiv-issued DOI via DataCite |\n| Journal\u00a0reference: | Nat Commun 16, 5244 (2025) |\n| Related DOI: | [https://doi.org/10.1038/s41467-025-60252-z](https://doi.org/10.1038/s41467-025-60252-z) <br>Focus to learn more<br>DOI(s) linking to related resources |\n\n## Submission history\n\nFrom: David Buterez \\[ [view email](https://arxiv.org/show-email/eeb04c22/2402.10793)\\] **[\\[v1\\]](https://arxiv.org/abs/2402.10793v1)**\nFri, 16 Feb 2024 16:20:11 UTC (613 KB)\n**[\\[v2\\]](https://arxiv.org/abs/2402.10793v2)**\nFri, 6 Dec 2024 15:44:46 UTC (1,434 KB)\n**\\[v3\\]**\nMon, 9 Jun 2025 13:24:10 UTC (5,649 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled An end-to-end attention-based approach for learning on graphs, by David Buterez and 3 other authors\n\n- [View PDF](https://arxiv.org/pdf/2402.10793)\n- [HTML (experimental)](https://arxiv.org/html/2402.10793v3)\n- [TeX Source](https://arxiv.org/src/2402.10793)\n\n[view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2402.10793&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2402.10793&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2024-02](https://arxiv.org/list/cs.LG/2024-02)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2402.10793?context=cs) [cs.AI](https://arxiv.org/abs/2402.10793?context=cs.AI)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2402.10793)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2402.10793)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2402.10793)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2402.10793) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2402.10793"
    },
    {
      "title": "Benchmarking Graphormer on Large-Scale Molecular Modeling Datasets",
      "text": "<div>\n<div>\n<p><a href=\"https://www.cornell.edu/\"></a>\n</p>\n<div>\n<p><a href=\"https://confluence.cornell.edu/x/ALlRF\">We gratefully acknowledge support from<br/>\nthe Simons Foundation and member institutions.</a>\n</p></div>\n</div>\n<div>\n<h2><a href=\"https://arxiv.org/\">\n</a></h2>\n</div>\n</div>",
      "url": "https://arxiv.org/abs/2203.04810"
    },
    {
      "title": "Benchmarking Graph Neural Networks",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/abs/2003.00982"
    }
  ]
}