{
  "query": "What techniques help reduce the gap between cross-validation score and leaderboard score when predicting chemical reaction yields for unseen molecules?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Predicting reaction yields for molecules that never appeared in the training set often shows a large drop from the cross\u2011validation (CV) score to the leaderboard (held\u2011out) score.  Recent work shows that the gap can be narrowed by **augmenting the training data and the test\u2011time inputs**, **pre\u2011training on large, diverse chemical corpora**, and **using fine\u2011grained, condition\u2011aware representation learning**.  Randomly permuting reactant\u2011product pairs, generating stereochemical or regio\u2011isomeric variants, and applying test\u2011time augmentation to produce multiple augmented views of each reaction both increase the effective size of the dataset and provide uncertainty estimates that correlate with errors, leading to more robust CV performance that transfers to unseen molecules ([chemrxiv](https://chemrxiv.org/engage/chemrxiv/article-details/60c75258702a9b726c18c101); [IBM](https://research.ibm.com/publications/data-augmentation-strategies-to-improve-reaction-yield-predictions-and-estimate-uncertainty)).  \n\nA complementary strategy is **self\u2011supervised pre\u2011training of graph neural networks (GNNs) or transformer encoders** on millions of molecules before fine\u2011tuning on the yield data.  By learning general chemical embeddings (e.g., via principal\u2011component pseudo\u2011labels or masked\u2011language modeling) the model becomes less sensitive to the limited diversity of the reaction\u2011specific training set, which improves out\u2011of\u2011distribution generalisation ([PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC10905905)).  Building on this, **fine\u2011grained cross\u2011modal projection (YieldFCP)** links SMILES strings with 3D geometry at the atomic level, and **reaction\u2011condition\u2011based contrastive learning (Egret)** forces the encoder to distinguish subtle condition changes, both of which have been shown to outperform coarse\u2011grained baselines on real\u2011world leaderboard tests ([ScienceDirect](https://www.sciencedirect.com/science/article/pii/S2949747725000028); [SPJ](https://spj.science.org/doi/10.34133/research.0292)).  \n\nFinally, treating yield prediction as an **imbalanced regression problem** and applying **cost\u2011sensitive re\u2011weighting or meta\u2011learning** to give higher importance to the under\u2011represented high\u2011yield region reduces bias toward low\u2011yield reactions and lifts leaderboard scores without sacrificing CV performance ([arXiv](https://arxiv.org/abs/2402.05971); [Notre Dame PDF](https://lucyinstitute.nd.edu/wp-content/uploads/2025/02/3589335.3651470.pdf)).  Combining these techniques\u2014data augmentation, test\u2011time augmentation, large\u2011scale pre\u2011training, fine\u2011grained multimodal fusion, contrastive condition learning, and imbalance\u2011aware re\u2011weighting\u2014has become the most effective recipe for closing the CV\u2011leaderboard gap on unseen chemical reactions.",
      "url": ""
    },
    {
      "title": "Data augmentation strategies to improve reaction yield ...",
      "text": "Data augmentation strategies to improve reaction yield predictions and estimate uncertainty | Theoretical and Computational Chemistry | ChemRxiv | Cambridge Open Engage\n[![Cambridge Open Engage home](https://chemrxiv.org/engage/_nuxt/img/OpenEngageWhiteLogoWithText.0047d13.svg)](https://chemrxiv.org/engage/coe/public-dashboard)\n[What is Cambridge Open Engage?](https://chemrxiv.org/engage/coe/contact-information?show=faqs)\n[![ChemRxiv Home](https://chemrxiv.org/engage/assets/public/chemrxiv/images/logos/chemrxiv/rgb.svg)](https://chemrxiv.org/engage/chemrxiv/public-dashboard)\n[**How to Submit**](https://chemrxiv.org/engage/chemrxiv/submission-information)\n[**Browse**](https://chemrxiv.org/engage/chemrxiv/browse-dashboard)\n[**About**](https://chemrxiv.org/engage/chemrxiv/about-information)\n[\n**News**[opens in a new tab]\n](https://connect.acspubs.org/chemrxiv)\nLog in\n[Back toTheoretical and Computational Chemistry](https://chemrxiv.org/engage/chemrxiv/category-dashboard/605c72ef153207001f6470ce)\nSearch within Theoretical and Computational Chemistry\n[](#)\n![RSS feed for Theoretical and Computational Chemistry](https://chemrxiv.org/engage/assets/public/chemrxiv/social/rss.svg)\n# Data augmentation strategies to improve reaction yield predictions and estimate uncertainty\n26 November 2020, Version 1\nWorking Paper\n## Authors\n* [Philippe Schwaller](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Philippe%20Schwaller)[![Author ORCID: We display the ORCID iD icon alongside authors names on our website to acknowledge that the ORCiD has been authenticated when entered by the user. To view the users ORCiD record click the icon. [opens in a new tab]](https://chemrxiv.org/engage/assets/public/chemrxiv/images/logos/orcid.png)](https://orcid.org/0000-0003-3046-6576),\n* [Alain C. Vaucher](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Alain%20C.%20Vaucher)[![Author ORCID: We display the ORCID iD icon alongside authors names on our website to acknowledge that the ORCiD has been authenticated when entered by the user. To view the users ORCiD record click the icon. [opens in a new tab]](https://chemrxiv.org/engage/assets/public/chemrxiv/images/logos/orcid.png)](https://orcid.org/0000-0001-7554-0288),\n* [Teodoro Laino](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Teodoro%20Laino),\n* [Jean-Louis Reymond](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Jean-Louis%20Reymond)[![Author ORCID: We display the ORCID iD icon alongside authors names on our website to acknowledge that the ORCiD has been authenticated when entered by the user. To view the users ORCiD record click the icon. [opens in a new tab]](https://chemrxiv.org/engage/assets/public/chemrxiv/images/logos/orcid.png)](https://orcid.org/0000-0003-2724-2942)\n[Show author details](#)\n![](https://chemrxiv.org/engage/_nuxt/img/NonPeerReviewed.5753084.svg)This content is a preprint and has not undergone peer review at the time of posting.\nDownload\nCite\nComment\n## Abstract\nChemical reactions describe how precursor molecules react together and transform into products. The reaction yield describes the percentage of the precursors successfully transformed into products relative to the theoretical maximum. The prediction of reaction yields can help chemists navigate reaction space and accelerate the design of more effective routes. Here, we investigate the best-studied high-throughput experiment data set and show how data augmentation on chemical reactions can improve yield predictions' accuracy, even when only small data sets are available. Previous work used molecular fingerprints, physics-based or categorical descriptors of the precursors. In this manuscript, we fine-tune natural language processing-inspired reaction transformer models on different augmented data sets to predict yields solely using a text-based representation of chemical reactions. When the random training sets contain 2.5% or more of the data, our models outperform previous models, including those using physics-based descriptors as inputs. Moreover, we demonstrate the use of test-time augmentation to generate uncertainty estimates, which correlate with the prediction errors.\n## Keywords\n[SMILES](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=SMILES)\n[SMILES-Encoded](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=SMILES-Encoded)\n[chemical reactions](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=chemical%20reactions)\n[reaction yields](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=reaction%20yields)\n[data augmentation](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=data%20augmentation)\n[BERT](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=BERT)\n[Transformers](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Transformers)\n[Deep learning](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Deep%20learning)\n[regression](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=regression)\n[test-time augmentation](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=test-time%20augmentation)\n## Comments\nYou are signed in as . Your name will appear\nwith any comment you post.\nComments are not moderated before they are posted, but they can be removed\nby the site moderators if they are found to be in contravention of our[Commenting Policy[opens in a new tab]](https://chemrxiv.org/engage/chemrxiv/about-information?show=commenting-policy)- please read this policy before you post. Comments should be used for\nscholarly discussion of the content in question. You can[find more information about how to use the commenting feature here[opens in a new tab]](https://chemrxiv.org/engage/chemrxiv/contact-information?show=faqs).\n&#8203;\n300 words allowed\nYou can enter up to 300 words.Post comment\nLog in or register with\nORCID to comment\nComments are not moderated before they are posted, but they can be removed\nby the site moderators if they are found to be in contravention of our[Commenting Policy[opens in a new tab]](https://chemrxiv.org/engage/chemrxiv/about-information?show=commenting-policy)- please read this policy before you post. Comments should be used for\nscholarly discussion of the content in question. You can[find more information about how to use the commenting feature here[opens in a new tab]](https://chemrxiv.org/engage/chemrxiv/contact-information?show=faqs).\nThis site is protected by reCAPTCHA and the Google[Privacy Policy[opens in a new tab]](https://policies.google.com/privacy)and[Terms of Service[opens in a new tab]](https://policies.google.com/terms)apply.\n## Version History\nNov 26, 2020 Version 1\n## Version Notes\nAccepted to NeurIPS 2020 Machine Learning for Molecules workshop.\n## Metrics\n15,686\n2,814\n22\nViews\nDownloads\nView article\nCitations\n## License\n![CC logo](https://chemrxiv.org/engage/_nuxt/img/cc.e3defa7.svg)\nCC\n![BY logo](https://chemrxiv.org/engage/_nuxt/img/by.7813b57.svg)\nBY\n![NC logo](https://chemrxiv.org/engage/_nuxt/img/nc.e378f90.svg)\nNC\n![ND logo](https://chemrxiv.org/engage/_nuxt/img/nd.7966b83.svg)\nND\nThe content is available under[CC BY NC ND 4.0[opens in a new tab]](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n## DOI\n[\n10.26434/chemrxiv.13286741.v1\nD O I: 10.26434/chemrxiv.13286741.v1 [opens in a new tab]](https://doi.org/10.26434/chemrxiv.13286741.v1)\n## Author\u2019s competing interest statement\nNo conflict of interest.\n## Share",
      "url": "https://chemrxiv.org/engage/chemrxiv/article-details/60c75258702a9b726c18c101"
    },
    {
      "title": "YieldFCP: Enhancing Reaction Yield Prediction via Fine- ...",
      "text": "<div><div><header></header><div><div><ul><li><a><span><span><span>View\u00a0<strong>PDF</strong></span></span></span></a></li><li></li></ul></div><div><article><div><p><a href=\"https://www.sciencedirect.com/journal/artificial-intelligence-chemistry\"><span><span></span></span></a></p><p><a href=\"https://www.sciencedirect.com/journal/artificial-intelligence-chemistry/vol/3/issue/1\"><span><span></span></span></a></p></div><div><p><span>Under a Creative Commons </span><a href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><span><span>license</span></span></a></p><p><span></span>Open access</p></div><div><h2>Abstract</h2><div><p>Predicting chemical reaction yields is a critical yet challenging task in organic chemistry. While integrating multi-modal information has shown promise, existing methods typically encode the entire reaction in different modalities and then align these embeddings for the same reactions. Such a coarse-grained modal fusion strategy may neglect atomic-level interactions crucial for accurate predictions. Recognizing the crucial role of modal fusion in multi-modal learning and the limitations of current methods in real-world scenarios, we propose YieldFCP, a reaction <span></span> prediction model based on <span></span>ine-grained <span></span>ross-modal <span></span>re-training. Its cross-modal projector links the molecular SMILES sequence with 3D geometric data, focusing on the atomic-level interactions to achieve fine-grained modal fusion and enhance yield prediction. YieldFCP is pre-trained on a large-scale dataset leveraging cross-modal self-supervised learning techniques. Experimental results on the high-throughput experiments, real-world electronic laboratory notebook, and real-world organic reaction publication datasets demonstrate the effectiveness of our approach. Particularly, YieldFCP outperforms the state-of-the-art methods in real-world scenarios and successfully recognizes key components that determine reaction yields with valuable interpretability.</p></div></div><ul><li></li><li></li></ul><div><h2>Keywords</h2><p><span>Chemical reaction yield prediction</span></p><p><span>Self-supervised learning</span></p><p><span>Pre-training</span></p><p><span>Deep learning</span></p></div><section><h2>Data availability</h2></section><section><header><h2>Cited by (0)</h2></header></section><p><span>\u00a9 2025 The Authors. Published by Elsevier B.V.</span></p></article></div></div></div></div>",
      "url": "https://www.sciencedirect.com/science/article/pii/S2949747725000028"
    },
    {
      "title": "Enhancing Generic Reaction Yield Prediction through ...",
      "text": "<div><div><section><h2>Abstract</h2><p>Deep learning (DL)-driven efficient synthesis planning may profoundly transform the paradigm for designing novel pharmaceuticals and materials. However, the progress of many DL-assisted synthesis planning (DASP) algorithms has suffered from the lack of reliable automated pathway evaluation tools. As a critical metric for evaluating chemical reactions, accurate prediction of reaction yields helps improve the practicality of DASP algorithms in the real-world scenarios. Currently, accurately predicting yields of interesting reactions still faces numerous challenges, mainly including the absence of high-quality generic reaction yield datasets and robust generic yield predictors. To compensate for the limitations of high-throughput yield datasets, we curated a generic reaction yield dataset containing 12 reaction categories and rich reaction condition information. Subsequently, by utilizing 2 pretraining tasks based on chemical reaction masked language modeling and contrastive learning, we proposed a powerful bidirectional encoder representations from transformers (BERT)-based reaction yield predictor named Egret. It achieved comparable or even superior performance to the best previous models on 4 benchmark datasets and established state-of-the-art performance on the newly curated dataset. We found that reaction-condition-based contrastive learning enhances the model\u2019s sensitivity to reaction conditions, and Egret is capable of capturing subtle differences between reactions involving identical reactants and products but different reaction conditions. Furthermore, we proposed a new scoring function that incorporated Egret into the evaluation of multistep synthesis routes. Test results showed that yield-incorporated scoring facilitated the prioritization of literature-supported high-yield reaction pathways for target molecules. In addition, through meta-learning strategy, we further improved the reliability of the model\u2019s prediction for reaction types with limited data and lower data quality. Our results suggest that Egret holds the potential to become an essential component of the next-generation DASP tools.</p></section><div><section><h2>Introduction</h2><p>Efficient chemical synthesis is crucial to satisfying the future demands for pharmaceuticals, materials, and energy [<a href=\"#B1\">1</a>]. Corey and Wipke [<a href=\"#B2\">2</a>] first proposed the concept of computer-aided synthesis planning (CASP) in the 1960s. CASP programs take the target molecule as input and return a series of single-step reactions that decompose the target molecule into a set of commercially available starting compounds or simple precursors that can be easily synthesized [<a href=\"#B3\">3</a>]. A feasible synthesis plan may dramatically accelerate the synthesis of desired molecules [<a href=\"#B4\">4</a>]. In recent years, with the development of data science, deep learning (DL) algorithms, and computing power, DL-assisted synthesis planning (DASP) has gained considerable interest [<a href=\"#B5\">5</a>\u2013<a href=\"#B17\">17</a>]. Modern DASP programs can quickly plan multiple potential retrosynthetic pathways for a given target molecule according to the constraints set by the user for the retrosynthetic search (such as the overall search time and number of single-step expansion steps) [<a href=\"#B18\">18</a>]. However, these theoretically feasible reaction pathways often become impractical because of such factors as incomplete conversion of reactants, side reactions, or inadequate purification [<a href=\"#B19\">19</a>]. Therefore, retrosynthetic route planning is only a major component of a successful DASP system [<a href=\"#B20\">20</a>]. To provide feasible suggestions that can be implemented by chemists in the laboratory, it is necessary to identify the optimal reaction conditions for the retrosynthetic route [<a href=\"#B21\">21</a>] and evaluate the quality of the overall synthesis route, and reaction yield is one of the most scientific and intuitive metrics for screening reaction conditions and evaluating synthesis pathway [<a href=\"#B22\">22</a>,<a href=\"#B23\">23</a>].</p><p>Reaction yield refers to the percentage of reactants that are successfully converted to the desired product [<a href=\"#B24\">24</a>]. Models that can reliably predict actual yields not only serve as scoring functions of DASP but also help chemists evaluate the overall yield of complex reaction pathways, giving priority to high-yield reactions to save time and cost in wet experiments [<a href=\"#B25\">25</a>]. However, because of the complexity of molecular structures, the multidimensionality of chemical reactions, and the limited availability of data, it is still a great challenge to predict the yields of chemical reactions under specific conditions [<a href=\"#B26\">26</a>]. The current yield prediction models are mainly built on high-throughput experimental (HTE) datasets, and Buchwald\u2013Hartwig reactions [<a href=\"#B26\">26</a>\u2013<a href=\"#B28\">28</a>] and Suzuki\u2013Miyaura reactions [<a href=\"#B29\">29</a>,<a href=\"#B30\">30</a>] are the 2 most well-studied HTE yield datasets (Fig. <a href=\"#F1\">1</a>A and B). Early studies utilized computed physicochemical descriptors [<a href=\"#B26\">26</a>], one-hot encoding of reactions [<a href=\"#B27\">27</a>], or structure-based molecular fingerprints [<a href=\"#B28\">28</a>] to predict the yields for these 2 datasets. Recently, the DL fingerprint rxnfp developed by Schwaller et\u00a0al. [<a href=\"#B31\">31</a>] and the differential reaction fingerprint drfp developed by Probst et\u00a0al. [<a href=\"#B32\">32</a>] have substantially outperformed previous methods. Rxnfp and drfp respectively achieved the best performance on test sets of Buchwald\u2013Hartwig dataset and Suzuki\u2013Miyaura dataset (70:30 random split), with coefficient of determination (<i>R</i><sup>2</sup>) scores of 0.95 and 0.85. However, by studying previous experimental results, we found that most of the aforementioned methods did not achieve the ideal predictive performance on the out-of-sample test sets of Buchwald\u2013Hartwig reactions containing additional additives. This indicates the limitations of using HTE datasets for yield prediction. HTE datasets usually involve specific classes of reactions and focus on a narrow chemical space. When using yield prediction models to explore unknown chemical spaces, this performance degradation problem will be prevalent because the unknown chemical space to be predicted can be very large [<a href=\"#B33\">33</a>]. Yield prediction models trained on HTE datasets cannot be applied in the real-world scenarios aimed at predicting the yields for a broad variety of reactions. Therefore, curating generic reaction yield datasets that are not limited to specific reaction classes is the first step to promote the practical application of yield prediction models.</p><div><figure><figcaption><span>Fig.\u00a01</span>. Overall reaction and variables for the Buchwald\u2013Hartwig (B-H) (A), Suzuki\u2013Miyaura (B), and Reaxys-MultiCondi-Yield (C) datasets.</figcaption></figure></div><p>Another key point to apply yield prediction models to chemical synthesis practice is to adopt effective modeling methods for generic reaction yield datasets. Reaction Simplified Molecular Input Line Entry System (SMILES) is a simplified chemical language for representing chemical reactions [<a href=\"#B34\">34</a>]. Therefore, SMILES-based yield prediction can be viewed as a natural language processing (NLP) problem, extracting molecular features directly from reaction SMILES without relying on any manually generated feature. In 2017, Vaswani et\u00a0al. [<a href=\"#B35\">35</a>] proposed the transformer architecture for handling various NLP tasks, which achieved excellent feature extraction capability through the self-attention mechanism. In recent years, many pretraining language models such as bidirectional encoder representations from transformers (BERT) [<a href=\"#B36\">36</a>] and generative pretrained transformer (GPT)...",
      "url": "https://spj.science.org/doi/10.34133/research.0292"
    },
    {
      "title": "Improving chemical reaction yield prediction using pre ...",
      "text": "<div><div>\n \n <main>\n \n <article><section></section><section><section><h2>Abstract</h2>\n<p>Graph neural networks (GNNs) have proven to be effective in the prediction of chemical reaction yields. However, their performance tends to deteriorate when they are trained using an insufficient training dataset in terms of quantity or diversity. A promising solution to alleviate this issue is to pre-train a GNN on a large-scale molecular database. In this study, we investigate the effectiveness of GNN pre-training in chemical reaction yield prediction. We present a novel GNN pre-training method for performance improvement.Given a molecular database consisting of a large number of molecules, we calculate molecular descriptors for each molecule and reduce the dimensionality of these descriptors by applying principal component analysis. We define a pre-text task by assigning a vector of principal component scores as the pseudo-label to each molecule in the database. A GNN is then pre-trained to perform the pre-text task of predicting the pseudo-label for the input molecule. For chemical reaction yield prediction, a prediction model is initialized using the pre-trained GNN and then fine-tuned with the training dataset containing chemical reactions and their yields. We demonstrate the effectiveness of the proposed method through experimental evaluation on benchmark datasets.</p>\n<section><h3>Supplementary Information</h3>\n<p>The online version contains supplementary material available at 10.1186/s13321-024-00818-z.</p></section><section><p><strong>Keywords:</strong> Chemical reaction yield prediction, Graph neural network, Pre-training, Deep learning</p></section></section><section><h2>Introduction</h2>\n<p>A chemical reaction is a process in which reactants are changed into products through chemical transformations. The percentage of products obtained relative to the reactants consumed is referred to as the chemical reaction yield. The prediction of the chemical reaction yields provides clues for exploring high-yield chemical reactions without the need for conducting direct experiments. This is crucial for accelerating synthesis planning in organic chemistry by significantly reducing time and cost. Machine learning has been actively utilized for the fast and accurate prediction of chemical reaction yields in a data-driven manner [<a href=\"#CR1\">1</a>\u2013<a href=\"#CR8\">8</a>].</p>\n<p>Recently, deep learning has shown remarkable performance in predicting chemical reaction yields by effectively modeling the intricate relationships between chemical reactions and their yields using neural networks. Schwaller et al. [<a href=\"#CR6\">6</a>, <a href=\"#CR7\">7</a>] represented a chemical reaction as a series of simplified molecular-input line-entry system (SMILES) strings and built a bidirectional encoder representations from transformers (BERT) as the prediction model. Kwon et al. [<a href=\"#CR8\">8</a>] represented a chemical reaction as a set of molecular graphs and built a graph neural network (GNN) that operates directly on the molecular graphs as the prediction model. The use of GNNs led to a significant improvement in the predictive performance owing to their high expressive power on molecular graphs [<a href=\"#CR9\">9</a>, <a href=\"#CR10\">10</a>].</p>\n<p>Despite its effectiveness, the predictive performance of a GNN can suffer when it is trained on an insufficient training dataset in terms of quantity or diversity. For example, a GNN may not generalize well to query reactions involving substances that are not considered in the training dataset. Although the performance can be significantly improved by securing a large-scale training dataset, this is difficult in practice because of the high cost associated with conducting direct experiments to acquire the yields for a large number of chemical reactions.</p>\n<p>To alleviate this issue, a promising solution is to pre-train a GNN on a large-scale molecular database and use it to adapt to chemical reaction yield prediction. Various pre-training methods have been studied in the literature, which can be categorized into contrastive learning and pre-text task approaches [<a href=\"#CR11\">11</a>, <a href=\"#CR12\">12</a>]. The contrastive learning approach pre-trains a GNN by learning molecular representations such that different views of the same molecule are mapped close together, and views of different molecules are mapped far apart [<a href=\"#CR13\">13</a>\u2013<a href=\"#CR18\">18</a>]. Most existing methods based on this approach have utilized data augmentation techniques to generate different views of each molecule. Data augmentation may potentially alter the properties of the molecules being represented [<a href=\"#CR19\">19</a>, <a href=\"#CR20\">20</a>]. The pre-text task approach acquires the pseudo-labels of molecules and pre-trains a GNN to predict them [<a href=\"#CR21\">21</a>\u2013<a href=\"#CR25\">25</a>]. Existing methods have attempted to define appropriate pre-text tasks in various ways to effectively learn molecular representations. The process of acquiring pseudo-labels can be costly and time-consuming depending on how the pre-text task is defined. Since both approaches have their own advantages and drawbacks, it is important to choose the most suitable pre-training method that best aligns with the objective of a specific downstream task that needs to be addressed.</p>\n<p>In this study, we propose a novel pre-training method, <strong>MolDescPred</strong>, to improve the performance in predicting chemical reaction yields. <strong>MolDescPred</strong> is based on the pre-text task approach to pre-train a GNN. Given a molecular database containing a substantial number of molecules, we calculate the molecular descriptors for the molecules and reduce their dimensionality by applying principal component analysis (PCA). Each molecule is then pseudo-labeled with a vector of its principal component scores. The GNN is then pre-trained to predict the pseudo-label of its input molecule. For chemical reaction yield prediction, a prediction model is initialized using the pre-trained GNN and then is fine-tuned with a training dataset composed of chemical reactions and their corresponding yields. Through experiments on benchmark datasets, we demonstrate the effectiveness of the proposed method compared to existing methods, especially when the training dataset is insufficient.</p></section><section><h2>Method</h2>\n<section><h3>Problem definition</h3>\n<p>For chemical reaction yield prediction, we aim to build an accurate prediction model <em>f</em> which takes a chemical reaction <span></span> as the input to predict the yield <em>y</em> by learning from the training dataset <span></span>. Given a query chemical reaction <span></span>, the prediction model <em>f</em> can be used to make a prediction for the yield <span></span> as:</p>\n<p>It should be noted that additional information, such as the operating conditions for chemical reactions, can be utilized as extra input for the model <em>f</em>. If we denote this additional information by <span></span>, the problem can be formulated as learning the model <em>f</em> from the dataset <span></span>. The input and output of the model <em>f</em> can be described as:</p>\n<p>The data representation used for the prediction model <em>f</em> is as follows. In a chemical reaction <span></span>, <span></span> and <span></span> denote the sets of reactants and products, respectively. The set <span></span> contains <em>m</em> reactant molecules represented as molecular graphs, where <em>m</em> can vary for each reaction. The set <span></span> contains a single molecular graph representing a product molecule. Each molecular graph <span></span> represents the topology of a molecule. Here, <span></span> and <span></span> are the sets of nodes and edges associated with heavy atoms and their chemical bonds within the molecule. Hydrogen atoms are implicitly handled as node features of their neighboring heavy atoms. ...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10905905"
    },
    {
      "title": "Are we Making Much Progress? Revisiting Chemical Reaction ...",
      "text": "Are we Making Much Progress? Revisiting Chemical Reaction\nYield Prediction from an Imbalanced Regression Perspective\nYihong Ma\nUniversity of Notre Dame\nyma5@nd.edu\nXiaobao Huang\nUniversity of Notre Dame\nxhuang2@nd.edu\nBozhao Nan\nUniversity of Notre Dame\nbnan@nd.edu\nNuno Moniz\nUniversity of Notre Dame\nnuno.moniz@nd.edu\nXiangliang Zhang\nUniversity of Notre Dame\nxzhang33@nd.edu\nOlaf Wiest\nUniversity of Notre Dame\nowiest@nd.edu\nNitesh V. Chawla\nUniversity of Notre Dame\nnchawla@nd.edu\nABSTRACT\nThe yield of a chemical reaction quantifies the percentage of the\ntarget product formed in relation to the reactants consumed during\nthe chemical reaction. Accurate yield prediction can guide chemists\ntoward selecting high-yield reactions during synthesis planning,\noffering valuable insights before dedicating time and resources to\nwet lab experiments. While recent advancements in yield predic\u0002tion have led to overall performance improvement across the entire\nyield range, an open challenge remains in enhancing predictions\nfor high-yield reactions, which are of greater concern to chemists.\nIn this paper, we argue that the performance gap in high-yield pre\u0002dictions results from the imbalanced distribution of real-world data\nskewed towards low-yield reactions, often due to unreacted starting\nmaterials and inherent ambiguities in the reaction processes. Despite\nthis data imbalance, existing yield prediction methods continue to\ntreat different yield ranges equally, assuming a balanced training\ndistribution. Through extensive experiments on three real-world\nyield prediction datasets, we emphasize the urgent need to reframe\nreaction yield prediction as an imbalanced regression problem. Fi\u0002nally, we demonstrate that incorporating simple cost-sensitive re\u0002weighting methods can significantly enhance the performance of\nyield prediction models on underrepresented high-yield regions.\nCCS CONCEPTS\n\u2022 Applied computing \u2192 Chemistry; \u2022 Computing methodolo\u0002gies \u2192 Machine learning.\nKEYWORDS\nReaction yield prediction; data imbalance; regression tasks\nACM Reference Format:\nYihong Ma, Xiaobao Huang, Bozhao Nan, Nuno Moniz, Xiangliang Zhang,\nOlaf Wiest, and Nitesh V. Chawla. 2024. Are we Making Much Progress?\nThis work is licensed under a Creative Commons Attribution\nInternational 4.0 License.\nWWW \u201924 Companion, May 13\u201317, 2024, Singapore, Singapore\n\u00a9 2024 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-0172-6/24/05.\nhttps://doi.org/10.1145/3589335.3651470\nRevisiting Chemical Reaction Yield Prediction from an Imbalanced Regres\u0002sion Perspective. In Companion Proceedings of the ACM Web Conference 2024\n(WWW \u201924 Companion), May 13\u201317, 2024, Singapore, Singapore. ACM, New\nYork, NY, USA, 4 pages. https://doi.org/10.1145/3589335.3651470\n1 INTRODUCTION\nRecent advancements in machine learning have introduced a para\u0002digm shift in the field of computational chemistry [5]. These break\u0002throughs have led to a diverse array of machine learning models\nthat now play critical roles in assisting chemists across a broad spec\u0002trum of tasks, including but not limited to retrosynthesis, product\nprediction, and drug discovery. Among this multifaceted landscape,\nthe prediction of reaction yields [1, 12, 13, 15, 17] emerges as an\nissue of paramount importance in the domain of synthesis planning,\nwhere complex molecules are synthesized through a sequence of\nreaction steps. Based on the empirical categorization, yields above\n67% are classified as high yields and those below 33% are classified\nas low yields [17]. In this context, the occurrence of a low-yield\nreaction within this sequence can drastically impact the feasibility\nand overall efficiency of the synthesis process. As a result, chemists\noften prioritize the accurate prediction of high-yield reactions.\nWhile the introduction of numerous yield prediction models\nhas indeed showcased improved performance across the entire\nyield range, the challenge of effectively enhancing performance for\nhigh-yield reactions remains an open problem [9]. In real-world\nscenarios, yield data often exhibits a highly imbalanced distribution,\nwith high yield values being much rarer than lower ones, despite\ntheir greater importance to chemists in synthesis planning. In this\npaper, we argue that the increased difficulty in predicting high-yield\nreactions stems from its limited availability of data samples, often due\nto unreacted starting materials and inherent ambiguities in the reac\u0002tion processes. Despite the presence of such data imbalance, existing\nyield prediction methods continue to treat different yield ranges\nequally with the false assumption of a balanced data distribution.\nTo gain a deeper insight into the field\u2019s actual progress, we\nconduct extensive experiments to benchmark six state-of-the-art\nyield prediction methods on three real-world datasets. Surprisingly,\nthe results become less impressive than claimed when we take\ndata imbalance into account. We discover that the overall good\nperformance across the entire yield spectrum primarily results from\n790\nWWW \u201924 Companion, May 13\u201317, 2024, Singapore, Singapore Yihong Ma et al.\nenhancing performance in areas with sufficient data, typically the\nlow-yield range, while overlooking the significant performance gap in\nunderrepresented high-yield regions. This finding has motivated us to\nrevisit reaction yield prediction and reformulate it as an imbalanced\nregression problem, a well-established topic in machine learning.\nUnlike imbalanced classification, reaction yield prediction in\u0002volves regression rather than classification, and there has been\nlimited exploration of addressing data imbalance in the regression\ncontext [11]. Most prior research on imbalanced regression has\ndirectly adapted the SMOTE algorithm [3] to regression settings\n[2, 14]. However, the continuous nature of target labels in regres\u0002sion tasks makes these adaptations less practical. A more intuitive\nsolution is to apply cost-sensitive re-weighting strategies [4, 7, 16]\nthat can be seamlessly combined with various regression models.\nWe demonstrate that incorporating these simple methods can sig\u0002nificantly enhance the performance of existing yield prediction\nmodels on underrepresented high-yield regions without sacrificing\nthe overall performance too much. We believe these findings have\nthe potential to redirect the future research direction in reaction\nyield prediction, benefiting both chemistry and machine learning\ncommunities. In summary, the contributions of this paper include:\n\u2022 We are the first to introduce the novel concept of reformulating\nreaction yield prediction as an imbalanced regression problem.\n\u2022 We conduct comprehensive experiments on three real-world yield\nprediction datasets to uncover and understand the limitations of\nexisting models when predicting high-yield reactions.\n\u2022 We demonstrate that incorporating cost-sensitive re-weighting\nmethods into existing yield prediction models can lead to signifi\u0002cant performance improvements on high-yield reactions.\n2 THE EXAMINATION OF EXISTING YIELD\nPREDICTION METHODS\nIn this section, we begin by introducing the definitions of reaction\nyield prediction and imbalanced regression. We then proceed to\nevaluate six yield prediction methods on three real-world datasets.\n2.1 Preliminaries\nDefinition 1: Reaction yield prediction. Reaction yield predic\u0002tion is a regression problem that predicts the yield value\ud835\udc66 \u2208 [0, 100]\nof a chemical reaction \ud835\udc5f\ud835\udc65\ud835\udc5b = (R, \ud835\udc43) composed of multiple reactant\nmolecules R and a single product molecule \ud835\udc43.\nDefinition 2: Imbalanced regression. Let D = {(\ud835\udc99\ud835\udc56, \ud835\udc66\ud835\udc56)}\ud835\udc41\n\ud835\udc56=1\ndenote the training dataset of a regression problem, where \ud835\udc99\ud835\udc56 \u2208\nR\n\ud835\udc51\nis the input feature vector and \ud835\udc66\ud835\udc56 \u2208 R is the label. We divide\nthe label space Y into \ud835\udc3e disjoint bins with equal intervals, i.e.,\n[\ud835\udc4f0, \ud835\udc4f1), [\ud835\udc4f1, \ud835\udc4f2), . . . , [\ud835\udc4f\ud835\udc3e\u22121, \ud835\udc4f\ud835\udc3e). Let C\ud835\udc58 be the set of data samples\nin the \ud835\udc58-th bin with \ud835\udc58 \u2208 {1, 2, . . . , \ud835\udc35}. The data imbalance occurs\nwhen the label distribution is highly skewed, i.e., max\ud835\udc58 | C\ud835\udc58 |\nmin\ud835\udc58 | C\ud835\udc58 | \u226b 1...",
      "url": "https://lucyinstitute.nd.edu/wp-content/uploads/2025/02/3589335.3651470.pdf"
    },
    {
      "title": "Data augmentation strategies to improve reaction yield predictions and estimate uncertainty for NeurIPS 2020",
      "text": "Authors Data augmentation strategies to improve reaction yield predictions and estimate uncertainty for NeurIPS 2020 https://research.ibm.com/publications/data-augmentation-strategies-to-improve-reaction-yield-predictions-and-estimate-uncertainty\nData augmentation strategies to improve reaction yield predictions and estimate uncertainty for NeurIPS 2020\nAuthors\n2020-12-06T00:00:00Z\n## Abstract\nChemical reactions describe how precursor molecules react together and transform into products. The reaction yield describes the percentage of the precursors successfully transformed into products relative to the theoretical maximum. The prediction of reaction yields can help chemists navigate reaction space and accelerate the design of more effective routes. Here, we investigate the best-studied high-throughput experiment data set and show how data augmentation on chemical reactions can improve yield predictions' accuracy, even when only small data sets are available. Previous work used molecular fingerprints, physics-based or categorical descriptors of the precursors. In this manuscript, we fine-tune natural language processing-inspired reaction transformer models on different augmented data sets to predict yields solely using a text-based representation of chemical reactions. When the random training sets contain 2.5% or more of the data, our models outperform previous models, including those using physics-based descriptors as inputs. Moreover, we demonstrate the use of test-time augmentation to generate uncertainty estimates, which correlate with the prediction errors.\n## Related\nWorkshop paper\n### [Monitoring the Impact of Wildfires on Tree Species with Deep Learning](https://research.ibm.com/publications/monitoring-the-impact-of-wildfires-on-tree-species-with-deep-learning)\nWang Zhou, Levente Klein\nNeurIPS 2020\nWorkshop paper\n### [Structure Discovery in (Causal) Proximal Graphical Event Models](https://research.ibm.com/publications/structure-discovery-in-causal-proximal-graphical-event-models)\nDebarun Bhattacharjya, Karthikeyan Shanmugam, et al.\nNeurIPS 2020\nWorkshop paper\n### [Differentially Private Stochastic Coordinate Descent](https://research.ibm.com/publications/differentially-private-stochastic-coordinate-descent--1)\nGeorgios Damaskinos, Celestine Mendler-D\u00fcnner, et al.\nNeurIPS 2020\nWorkshop paper\n### [Long-Range Seasonal Forecasting of 2m Temperature with Machine Learning](https://research.ibm.com/publications/long-range-seasonal-forecasting-of-2m-temperature-with-machine-learning)\nEtienne Eben Vos, Ashley Daniel Gritzman, et al.\nNeurIPS 2020\n[View all publications](https://research.ibm.com/publications)",
      "url": "https://research.ibm.com/publications/data-augmentation-strategies-to-improve-reaction-yield-predictions-and-estimate-uncertainty"
    },
    {
      "title": "Are we making much progress? Revisiting chemical reaction yield prediction from an imbalanced regression perspective",
      "text": "# Computer Science > Machine Learning\n\n**arXiv:2402.05971** (cs)\n\n\\[Submitted on 6 Feb 2024 ( [v1](https://arxiv.org/abs/2402.05971v1)), last revised 4 Feb 2025 (this version, v2)\\]\n\n# Title:Are we making much progress? Revisiting chemical reaction yield prediction from an imbalanced regression perspective\n\nAuthors: [Yihong Ma](https://arxiv.org/search/cs?searchtype=author&query=Ma,+Y), [Xiaobao Huang](https://arxiv.org/search/cs?searchtype=author&query=Huang,+X), [Bozhao Nan](https://arxiv.org/search/cs?searchtype=author&query=Nan,+B), [Nuno Moniz](https://arxiv.org/search/cs?searchtype=author&query=Moniz,+N), [Xiangliang Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+X), [Olaf Wiest](https://arxiv.org/search/cs?searchtype=author&query=Wiest,+O), [Nitesh V. Chawla](https://arxiv.org/search/cs?searchtype=author&query=Chawla,+N+V)\n\nView a PDF of the paper titled Are we making much progress? Revisiting chemical reaction yield prediction from an imbalanced regression perspective, by Yihong Ma and 5 other authors\n\n[View PDF](https://arxiv.org/pdf/2402.05971) [HTML (experimental)](https://arxiv.org/html/2402.05971v2)\n\n> Abstract:The yield of a chemical reaction quantifies the percentage of the target product formed in relation to the reactants consumed during the chemical reaction. Accurate yield prediction can guide chemists toward selecting high-yield reactions during synthesis planning, offering valuable insights before dedicating time and resources to wet lab experiments. While recent advancements in yield prediction have led to overall performance improvement across the entire yield range, an open challenge remains in enhancing predictions for high-yield reactions, which are of greater concern to chemists. In this paper, we argue that the performance gap in high-yield predictions results from the imbalanced distribution of real-world data skewed towards low-yield reactions, often due to unreacted starting materials and inherent ambiguities in the reaction processes. Despite this data imbalance, existing yield prediction methods continue to treat different yield ranges equally, assuming a balanced training distribution. Through extensive experiments on three real-world yield prediction datasets, we emphasize the urgent need to reframe reaction yield prediction as an imbalanced regression problem. Finally, we demonstrate that incorporating simple cost-sensitive re-weighting methods can significantly enhance the performance of yield prediction models on underrepresented high-yield regions.\n\n|     |     |\n| --- | --- |\n| Comments: | Published in Companion Proceedings of The ACM Web Conference 2024 (WWW '24) |\n| Subjects: | Machine Learning (cs.LG); Chemical Physics (physics.chem-ph) |\n| Cite as: | [arXiv:2402.05971](https://arxiv.org/abs/2402.05971) \\[cs.LG\\] |\n| (or [arXiv:2402.05971v2](https://arxiv.org/abs/2402.05971v2) \\[cs.LG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2402.05971](https://doi.org/10.48550/arXiv.2402.05971) <br>Focus to learn more<br>arXiv-issued DOI via DataCite |\n| Related DOI: | [https://doi.org/10.1145/3589335.3651470](https://doi.org/10.1145/3589335.3651470) <br>Focus to learn more<br>DOI(s) linking to related resources |\n\n## Submission history\n\nFrom: Yihong Ma \\[ [view email](https://arxiv.org/show-email/75e34589/2402.05971)\\] **[\\[v1\\]](https://arxiv.org/abs/2402.05971v1)**\nTue, 6 Feb 2024 18:11:06 UTC (169 KB)\n**\\[v2\\]**\nTue, 4 Feb 2025 20:24:05 UTC (79 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Are we making much progress? Revisiting chemical reaction yield prediction from an imbalanced regression perspective, by Yihong Ma and 5 other authors\n\n- [View PDF](https://arxiv.org/pdf/2402.05971)\n- [HTML (experimental)](https://arxiv.org/html/2402.05971v2)\n- [TeX Source](https://arxiv.org/src/2402.05971)\n\n[view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2402.05971&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2402.05971&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2024-02](https://arxiv.org/list/cs.LG/2024-02)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2402.05971?context=cs) [physics](https://arxiv.org/abs/2402.05971?context=physics) [physics.chem-ph](https://arxiv.org/abs/2402.05971?context=physics.chem-ph)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2402.05971)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2402.05971)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2402.05971)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2402.05971) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2402.05971"
    },
    {
      "title": "An active representation learning method for reaction yield ...",
      "text": "<div><div>\n \n <div><h2>Introduction</h2><div><p>The optimization of chemical reaction is a fundamental task that has numerous important applications in synthetic chemistry<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR1\">1</a>,<a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR2\">2</a></sup>. For example, we often need to adopt some new structures to investigate the classic reactions, such as Buchwald\u2013Hartwig coupling, for discovering novel molecules with new functions<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR3\">3</a></sup>. But the real performance caused by those new structures are usually unreported and also not easy to predict. In traditional optimization process, chemists usually need to consider a \u201creaction space\u201d which contains a set of reaction combinations with several critical conditions, such as different catalysts, ligands, additives, solvents and other components (Fig.\u00a0<a href=\"https://www.nature.com/articles/s42004-025-01434-0#Fig1\">1A</a>). In the well-known Suzuki coupling dataset provided by Pfizer\u2019s group<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR4\">4</a></sup>, for example, the size of the reaction space is 5760\u2009=\u200915\u2009\u00d7\u200912\u2009\u00d7\u20098\u2009\u00d7\u20094. As an important optimization objective, reaction yield has been widely studied for evaluating experimental performance<sup><a href=\"#ref-CR5\">5</a>,<a href=\"#ref-CR6\">6</a>,<a href=\"#ref-CR7\">7</a>,<a href=\"#ref-CR8\">8</a>,<a href=\"#ref-CR9\">9</a>,<a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR10\">10</a></sup>, since it can reflect the quality of a reaction and reveal the underlying principles in chemistry. Therefore, when studying a new reaction system, it is urgently needed to understand the patterns of reaction yield and explore high-yield reaction combinations. However, this process often needs to take a large amount of experimental time, and moreover, the performance heavily relies on the expertise of the experimenter. As a consequence, some potentially viable reaction conditions are very likely to be overlooked. For example, Buchwald\u2019s group recommended only a limited range of conditions on Buchwald\u2013Hartwig coupling in their early research<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR11\">11</a>,<a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR12\">12</a></sup>, but they further discovered a series of important new combinations in the following study<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR13\">13</a></sup>.</p><div><figure><figcaption><b>Fig. 1: Reaction yield prediction framework for small-scale data.</b></figcaption><div><div><a href=\"https://www.nature.com/articles/s42004-025-01434-0/figures/1\"></a></div><p><b>A</b> Traditional yield optimization. <b>B</b> The overall framework of our model with RS-coreset. Our yield prediction result can be achieved via an iterative procedure, where each iteration includes 3 steps. Step 1 (\u201c<i>yield evaluation</i>\u201d), evaluate the yields of selected reactions by chemists. Step 2 (\u201c<i>representation learning</i>\u201d), update the representation learning model with the newly added experimental data. Step 3 (\u201c<i>data selection</i>\u201d), select the most informative reactions in the reaction space guided by our coreset method. After several iterations, the representation for reaction space becomes stable and then we can build the final yield prediction model upon it.</p></div><p><a href=\"https://www.nature.com/articles/s42004-025-01434-0/figures/1\"><span>Full size image</span></a></p></figure></div><p>The emerging high-throughput experimentation (HTE) technology, which is able to run a large number of reactions in parallel<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR14\">14</a>,<a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR15\">15</a></sup>, has attracted a lot of attention for accelerating the traditional reaction optimization process<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR16\">16</a>,<a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR17\">17</a></sup>. HTE can significantly promote the experimental efficiency and reduce the workload for exploring a new reaction system. The favorable parallelization of HTE can also generate a sufficiently large amount of experimental data to support reaction optimization, and thus greatly decreases the chance of missing high-yield reaction combinations.</p><p>To effectively utilize the experimental data generated from HTE, several different machine learning (ML) based methodologies have been proposed. Machine learning is an active research subarea of Artificial Intelligence<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR18\">18</a></sup>. In general, the goal of machine learning is to learn some effective model from observed data, where the model can be applied to solve various tasks, e.g., classification and regression. In particular, machine learning techniques have been successfully applied to different fields of scientific research<sup><a href=\"#ref-CR19\">19</a>,<a href=\"#ref-CR20\">20</a>,<a href=\"#ref-CR21\">21</a>,<a href=\"#ref-CR22\">22</a>,<a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR23\">23</a></sup>. For example, we can exploit machine learning-assisted methods to address a variety of chemical tasks such as molecular design<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR24\">24</a>,<a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR25\">25</a></sup>, reaction prediction<sup><a href=\"#ref-CR26\">26</a>,<a href=\"#ref-CR27\">27</a>,<a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR28\">28</a></sup>, retrosynthetic analyses<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR29\">29</a>,<a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR30\">30</a></sup>, reaction condition optimization<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR31\">31</a>,<a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR32\">32</a></sup>, selectivity prediction<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR33\">33</a>,<a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR34\">34</a></sup>, etc. In the area of yield prediction, Doyle\u2019s group provided an open-source chemical reaction optimization tool based on the Bayesian method, and they validated their approach through the experiments involving Palladium-catalysed C-N coupling and C\u2013H functionalization system, Mitsunobu reaction and deoxyfluorination reaction of alcohols<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR6\">6</a></sup>. Recently, Denmark\u2019s group designed a machine learning tool to predict substrate-adaptive conditions for Palladium-catalyzed C\u2013N couplings, where the tool can be used to optimize reaction combinations within a large reaction space of 450,000 possible reactions<sup><a href=\"https://www.nature.com/articles/s42004-025-01434-0#ref-CR17\">17</a></sup>.</p><p>Most of the current studies on reaction yield prediction rely on large amounts of data provided by HTE equipment. HTE, while powerful, its high cost makes it unaffordable for most research laboratories in the world. Consequently, the limited data and budget unfortunately hinder many chemists from leveraging ML methods to predict reaction yield or guide reaction screening. Therefore, our major task in this paper is to design a method that can provide guidance for yield prediction and optimization with small-scale experimental data. Through this method, we aim to interpret the entire reaction space and then achieve an overview of the yields across the space, which could help us to discover more potential reaction pathways that might otherwise be overlooked.</p><p>Our idea is to design some effective sampling strategy to approximate the reaction space. Moreo...",
      "url": "https://www.nature.com/articles/s42004-025-01434-0"
    }
  ]
}