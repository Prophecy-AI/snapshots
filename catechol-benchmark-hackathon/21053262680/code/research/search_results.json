{
  "query": "How does the hybrid GNN architecture with Graph Attention Networks and mixture-aware solvent encodings achieve MSE 0.0039 on the catechol benchmark dataset?",
  "results": [
    {
      "title": "ANSWER",
      "text": "By coupling a Graph\u202fAttention Network that learns attentive representations of the reaction graph with a mixture\u2011aware solvent embedding (derived from differential reaction fingerprints) that is concatenated to the node features before message\u2011passing, the hybrid GNN jointly captures both molecular topology and continuous solvent effects, and this combined representation enables the model to attain an MSE of\u202f0.0039 on the catechol benchmark dataset. ([arxiv.org](https://arxiv.org/abs/2512.19530), [catalyzex.com](https://www.catalyzex.com/s/Chemical%20Reaction%20Prediction))",
      "url": ""
    },
    {
      "title": "Learning Continuous Solvent Effects from Transient Flow Data - arXiv",
      "text": "[2512.19530] Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2512.19530\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2512.19530**(cs)\n[Submitted on 22 Dec 2025]\n# Title:Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\nAuthors:[Hongsheng Xing](https://arxiv.org/search/cs?searchtype=author&amp;query=Xing,+H),[Qiuxin Si](https://arxiv.org/search/cs?searchtype=author&amp;query=Si,+Q)\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n[View PDF](https://arxiv.org/pdf/2512.19530)[HTML (experimental)](https://arxiv.org/html/2512.19530v1)> > Abstract:\n> Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \\textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.\n> Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \\textbf{MSE of 0.0039} ($\\pm$ 0.0003), representing a 60\\% error reduction over competitive baselines and a $&gt;25\\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning. Comments:|13 pages, 6 figures|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI)|\nMSCclasses:|68T07, 92E20, 62M45|\nACMclasses:|I.2.1; I.2.6; J.2|\nCite as:|[arXiv:2512.19530](https://arxiv.org/abs/2512.19530)[cs.LG]|\n|(or[arXiv:2512.19530v1](https://arxiv.org/abs/2512.19530v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2512.19530](https://doi.org/10.48550/arXiv.2512.19530)\nFocus to learn more\narXiv-issued DOI via DataCite (pending registration)\n|\n## Submission history\nFrom: Hongsheng Xing [[view email](https://arxiv.org/show-email/9dc7457b/2512.19530)]\n**[v1]**Mon, 22 Dec 2025 16:19:01 UTC (2,198 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n* [View PDF](https://arxiv.org/pdf/2512.19530)\n* [HTML (experimental)](https://arxiv.org/html/2512.19530v1)\n* [TeX Source](https://arxiv.org/src/2512.19530)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2512.19530&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2512.19530&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2025-12](https://arxiv.org/list/cs.LG/2025-12)\nChange to browse by:\n[cs](https://arxiv.org/abs/2512.19530?context=cs)\n[cs.AI](https://arxiv.org/abs/2512.19530?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2512.19530)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2512.19530)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2512.19530)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2512.19530&amp;description=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2512.19530&amp;title=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.or...",
      "url": "https://arxiv.org/abs/2512.19530"
    },
    {
      "title": "Chemical Reaction Prediction - CatalyzeX",
      "text": "Get our free extension to see links to code for papers anywhere online!Free add-on: code for papers everywhere!Free add-on: See code for papers anywhere!\n\n[![Chrome logo](https://www.catalyzex.com/static/images/google-chrome.svg)Add to Chrome - It's Free](https://chrome.google.com/webstore/detail/%F0%9F%92%BB-catalyzex-link-all-aim/aikkeehnlfpamidigaffhfmgbkdeheil)\n\nSearch Icon![Alert button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ffilter.cf288982.png&w=1080&q=75)\n\n# Topic: **Chemical Reaction Prediction**\n\n![Alert button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Falert_light_mode_icon.b8fca154.png&w=1080&q=75)\n\nWhat is Chemical Reaction Prediction? Chemical reaction prediction is the process of predicting the outcome of chemical reactions using machine learning models.\n\n### Papers and Code\n\n## [**Interpretable Deep Learning for Polar Mechanistic Reaction Prediction**](https://www.catalyzex.com/paper/interpretable-deep-learning-for-polar)\n\n[Github IconRequest Code](https://www.catalyzex.com/s/Chemical%20Reaction%20Prediction) Code for Similar Papers:![Code for Similar Papers](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Frelated_icon_transparent.98f57b13.png&w=96&q=75) [![Add code](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Faddcode_white.6afb879f.png&w=96&q=75)](https://www.catalyzex.com/add_code?title=Interpretable Deep Learning for Polar Mechanistic Reaction Prediction&paper_url=http://arxiv.org/abs/2504.15539)\n\n![Bookmark button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbookmark_outline.3a3e1c2c.png&w=828&q=75)\n\n![Alert button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Falert_light_mode_icon.b8fca154.png&w=1080&q=75)\n\nApr 22, 2025\n\nAuthors:[Ryan J. Miller](https://www.catalyzex.com/author/Ryan%20J.%20Miller), [Alexander E. Dashuta](https://www.catalyzex.com/author/Alexander%20E.%20Dashuta), [Brayden Rudisill](https://www.catalyzex.com/author/Brayden%20Rudisill), [David Van Vranken](https://www.catalyzex.com/author/David%20Van%20Vranken), [Pierre Baldi](https://www.catalyzex.com/author/Pierre%20Baldi)\n\nAbstract:Accurately predicting chemical reactions is essential for driving innovation in synthetic chemistry, with broad applications in medicine, manufacturing, and agriculture. At the same time, reaction prediction is a complex problem which can be both time-consuming and resource-intensive for chemists to solve. Deep learning methods offer an appealing solution by enabling high-throughput reaction prediction. However, many existing models are trained on the US Patent Office dataset and treat reactions as overall transformations: mapping reactants directly to products with limited interpretability or mechanistic insight. To address this, we introduce PMechRP (Polar Mechanistic Reaction Predictor), a system that trains machine learning models on the PMechDB dataset, which represents reactions as polar elementary steps that capture electron flow and mechanistic detail. To further expand model coverage and improve generalization, we augment PMechDB with a diverse set of combinatorially generated reactions. We train and compare a range of machine learning models, including transformer-based, graph-based, and two-step siamese architectures. Our best-performing approach was a hybrid model, which combines a 5-ensemble of Chemformer models with a two-step Siamese framework to leverage the accuracy of transformer architectures, while filtering away \"alchemical\" products using the two-step network predictions. For evaluation, we use a test split of the PMechDB dataset and additionally curate a human benchmark dataset consisting of complete mechanistic pathways extracted from an organic chemistry textbook. Our hybrid model achieves a top-10 accuracy of 94.9% on the PMechDB test set and a target recovery rate of 84.9% on the pathway dataset.\n\nVia![arxiv icon](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Farxiv.41e50dc5.png&w=128&q=75)\n\nGithub Icon [Access Paper or Ask Questions](https://www.catalyzex.com/paper/interpretable-deep-learning-for-polar)\n\n## [**Transferable Learning of Reaction Pathways from Geometric Priors**](https://www.catalyzex.com/paper/transferable-learning-of-reaction-pathways)\n\n[Github IconView Code](https://www.catalyzex.com/s/Chemical%20Reaction%20Prediction) Play IconNotebookCode for Similar Papers:![Code for Similar Papers](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Frelated_icon_transparent.98f57b13.png&w=96&q=75) [![Add code](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Faddcode_white.6afb879f.png&w=96&q=75)](https://www.catalyzex.com/add_code?title=Transferable Learning of Reaction Pathways from Geometric Priors&paper_url=http://arxiv.org/abs/2504.15370)\n\n![Bookmark button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbookmark_outline.3a3e1c2c.png&w=828&q=75)\n\n![Alert button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Falert_light_mode_icon.b8fca154.png&w=1080&q=75)\n\nApr 21, 2025\n\nAuthors:[Juno Nam](https://www.catalyzex.com/author/Juno%20Nam), [Miguel Steiner](https://www.catalyzex.com/author/Miguel%20Steiner), [Max Misterka](https://www.catalyzex.com/author/Max%20Misterka), [Soojung Yang](https://www.catalyzex.com/author/Soojung%20Yang), [Avni Singhal](https://www.catalyzex.com/author/Avni%20Singhal), [Rafael G\u00f3mez-Bombarelli](https://www.catalyzex.com/author/Rafael%20G%C3%B3mez-Bombarelli)\n\nAbstract:Identifying minimum-energy paths (MEPs) is crucial for understanding chemical reaction mechanisms but remains computationally demanding. We introduce MEPIN, a scalable machine-learning method for efficiently predicting MEPs from reactant and product configurations, without relying on transition-state geometries or pre-optimized reaction paths during training. The task is defined as predicting deviations from geometric interpolations along reaction coordinates. We address this task with a continuous reaction path model based on a symmetry-broken equivariant neural network that generates a flexible number of intermediate structures. The model is trained using an energy-based objective, with efficiency enhanced by incorporating geometric priors from geodesic interpolation as initial interpolations or pre-training objectives. Our approach generalizes across diverse chemical reactions and achieves accurate alignment with reference intrinsic reaction coordinates, as demonstrated on various small molecule reactions and \\[3+2\\] cycloadditions. Our method enables the exploration of large chemical reaction spaces with efficient, data-driven predictions of reaction pathways.\n\n_\\\\* 14 pages, 6 figures; Supporting Information in ancillary files_\n\nVia![arxiv icon](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Farxiv.41e50dc5.png&w=128&q=75)\n\nGithub Icon [Access Paper or Ask Questions](https://www.catalyzex.com/paper/transferable-learning-of-reaction-pathways)\n\n## [**Predicting Chemical Reaction Outcomes Based on Electron Movements Using Machine Learning**](https://www.catalyzex.com/paper/predicting-chemical-reaction-outcomes-based)\n\n[Github IconRequest Code](https://www.catalyzex.com/s/Chemical%20Reaction%20Prediction) Code for Similar Papers:![Code for Similar Papers](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Frelated_icon_transparent.98f57b13.png&w=96&q=75) [![Add code](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Faddcode_white.6afb879f.png&w=96&q=75)](https://www.catalyzex.com/add_code?title=Predicting Chemical Reaction Outcomes Based on Electron Movements Using Machine Learning&paper_url=http://arxiv.org/abs/2503.10197)\n\n![Bookmark button](https://www.catalyzex.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbookmark_outline.3a3e1c2c.png&w=828&q=75)\n\n![Alert button](https://www.catalyz...",
      "url": "https://www.catalyzex.com/s/Chemical%20Reaction%20Prediction"
    },
    {
      "title": "pstAmbition/DailyArXiv_Multimodal: Daily ArXiv Papers. - GitHub",
      "text": "GitHub - pstAmbition/DailyArXiv\\_Multimodal: Daily ArXiv Papers.\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/pstAmbition/DailyArXiv_Multimodal)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n</option></form>\nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n</option></form>\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n</option></form>\nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/pstAmbition/DailyArXiv_Multimodal)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=pstAmbition/DailyArXiv_Multimodal)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[pstAmbition](https://github.com/pstAmbition)/**[DailyArXiv\\_Multimodal](https://github.com/pstAmbition/DailyArXiv_Multimodal)**Public\n* [Notifications](https://github.com/login?return_to=/pstAmbition/DailyArXiv_Multimodal)You must be signed in to change notification settings\n* [Fork9](https://github.com/login?return_to=/pstAmbition/DailyArXiv_Multimodal)\n* [Star3](https://github.com/login?return_to=/pstAmbition/DailyArXiv_Multimodal)\nDaily ArXiv Papers.\n[3stars](https://github.com/pstAmbition/DailyArXiv_Multimodal/stargazers)[9forks](https://github.com/pstAmbition/DailyArXiv_Multimodal/forks)[Branches](https://github.com/pstAmbition/DailyArXiv_Multimodal/branches)[Tags](https://github.com/pstAmbition/DailyArXiv_Multimodal/tags)[Activity](https://github.com/pstAmbition/DailyArXiv_Multimodal/activity)\n[Star](https://github.com/login?return_to=/pstAmbition/DailyArXiv_Multimodal)\n[Notifications](https://github.com/login?return_to=/pstAmbition/DailyArXiv_Multimodal)You must be signed in to change notification settings\n# pstAmbition/DailyArXiv\\_Multimodal\nmaster\n[Branches](https://github.com/pstAmbition/DailyArXiv_Multimodal/branches)[Tags](https://github.com/pstAmbition/DailyArXiv_Multimodal/tags)\n[](https://github.com/pstAmbition/DailyArXiv_Multimodal/branches)[](https://github.com/pstAmbition/DailyArXiv_Multimodal/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[590 Commits](https://github.com/pstAmbition/DailyArXiv_Multimodal/commits/master/)\n[](https://github.com/pstAmbition/DailyArXiv_Multimodal/commits/master/)\n|\n[.github](https://github.com/pstAmbition/DailyArXiv_Multimodal/tree/master/.github)\n|\n[.github](https://github.com/pstAmbition/DailyArXiv_Multimodal/tree/master/.github)\n|\n|\n|\n[.gitignore](https://github.com/pstAmbition/DailyArXiv_Multimodal/blob/master/.gitignore)\n|\n[.gitignore](https://github.com/pstAmbition/DailyArXiv_Multimodal/blob/master/.gitignore)\n|\n|\n|\n[README.md](https://github.com/pstAmbition/DailyArXiv_Multimodal/blob/master/README.md)\n|\n[README.md](https://github.com/pstAmbition/DailyArXiv_Multimodal/blob/master/README.md)\n|\n|\n|\n[main.py](https://github.com/pstAmbition/DailyArXiv_Multimodal/blob/master/main.py)\n|\n[main.py](https://github.com/pstAmbition/DailyArXiv_Multimodal/blob/master/main.py)\n|\n|\n|\n[requirements.txt](https://github.com/pstAmbition/DailyArXiv_Multimodal/blob/master/requirements.txt)\n|\n[requirements.txt](https://github.com/pstAmbition/DailyArXiv_Multimodal/blob/master/requirements.txt)\n|\n|\n|\n[utils.py](https://github.com/pstAmbition/DailyArXiv_Multimodal/blob/master/utils.py)\n|\n[utils.py](https://github.com/pstAmbition/DailyArXiv_Multimodal/blob/master/utils.py)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# Daily Papers\n[](#daily-papers)\nThe project automatically fetches the latest papers from arXiv based on keywords.\nThe subheadings in the README file represent the search keywords.\nOnly the most recent articles for each keyword are retained, up to a maximum of 100 papers.\nYou can click the 'Watch' button to receive daily email notifications.\nLast update: 2026-01-07\n## Multimodal Learning\n[](#multimodal-learning)\n|**Title**|**Date**|**Abstract**|**Comment**|\n**[Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future](https://arxiv.org/abs/2512.16760v2)**|2026-01-04|Show\nAutonomous driving has long relied on modular \"Perception-Decision-Action\" pipelines, where hand-crafted interfaces and rule-based components often break down in complex or long-tailed scenarios. Their cascaded design further propagates perception errors, degrading downstream planning and control. Vision-Action (VA) models address some limitations by learning direct mappings from visual inputs to actions, but they remain opaque, sensitive to distribution shifts, and lack structured reasoning or instruction-following capabilities. Recent progress in Large Language Models (LLMs) and multimodal learning has motivated the emergence of Vision-Language-Action (VLA) frameworks, which integrate perception with language-grounded decision making. By unifying visual understanding, linguistic reasoning, and actionable outputs, VLAs offer a pathway toward more interpretable, generalizable, and human-aligned driving policies. This work provides a structured characterization of the emerging VLA landscape for autonomous driving. We trace the evolution from early VA approaches to modern VLA frameworks and organize existing methods into two principal paradigms: End-to-End VLA, which integrates perception, reasoning, and planning within a single model, and Dual-System VLA, which separates slow deliberation (via VLMs) from fast, safety-critical execution (via planners). Within these paradigms, we further distinguish subclasses such as textual vs. numerical action generators and explicit vs. implicit guidance mechanisms. We also summarize representative datasets and benchmarks for evaluating VLA-based driving systems and highlight key challenges and open directions, including robustness, interpretability, and instruction fidelity. Overall, this work aims to establish a coherent foundation for advancing human-compatible autonomous driving systems.\n|Surve...\nSurvey; 47 pages, 7 figures, 9 tables; GitHub Repo at[https://github.com/worldbench/awesome-vla-for-ad](https://github.com/worldbench/awesome-vla-for-ad)\n|\n**[Massively Multimodal Foundation Models: A Framework for Capturing Dependencies with Specialized Mixture-of-Experts](https://arxiv.org/abs/2509.25678v3)**|2026-01-02|Show\nModern applications increasingly involve dozens of heterogeneous input streams, such as clinical sensors, wearables, imaging, and text, each with distinct measurement models, sampling rates, and noise characteristics. This \\\\textit{massively multimodal} setting, where each sensor constitutes a separate modality, fundamentally differs from conventional multimodal learning focused on two or three modalities. As modality count grows, capturing their complex, time-varying dependencies becomes essential yet challenging. Mixture-of-Experts (MoE) architectures are naturally suited for this setting, their sparse routing mechanism enables efficient scaling across many modalities. Existing MoE architectures route tokens based on similarity alone, overlooking the rich temporal dependencies across modalities. We propose a framework t...",
      "url": "https://github.com/pstAmbition/DailyArXiv_Multimodal"
    },
    {
      "title": "Molecular Merged Hypergraph Neural Network for Explainable ... - NIH",
      "text": "Molecular Merged Hypergraph Neural Network for Explainable Solvation Gibbs Free Energy Prediction - PMC[Skip to main content](#main-content)\n![](https://pmc.ncbi.nlm.nih.gov/static/img/us_flag.svg)\nAn official website of the United States government\nHere's how you know\nHere's how you know\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-dot-gov.svg)\n**Official websites use .gov**\nA**.gov**website belongs to an official\ngovernment organization in the United States.\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-https.svg)\n**Secure .gov websites use HTTPS**\nA**lock**(LockLocked padlock icon) or**https://**means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n[![NCBI home page](https://pmc.ncbi.nlm.nih.gov/static/img/ncbi-logos/nih-nlm-ncbi--white.svg)](https://www.ncbi.nlm.nih.gov/)\nSearch\nLog in\n* [Dashboard](https://www.ncbi.nlm.nih.gov/myncbi/)\n* [Publications](https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/)\n* [Account settings](https://www.ncbi.nlm.nih.gov/account/settings/)\n* Log out\nSearch\u2026Search NCBI\n[](https://pmc.ncbi.nlm.nih.gov/)\nSearch PMC Full-Text ArchiveSearch in PMC![Search](https://pmc.ncbi.nlm.nih.gov/static/img/usa-icons-bg/search--white.svg)\n* [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n* [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n* * [](https://doi.org/10.34133/research.0740)\n* [](pdf/research.0740.pdf)\n* * * ## PERMALINK\nCopy\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\nLearn more:[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)|[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n![Research logo](https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-research.png)\nResearch (Wash D C)\n. 2025 Aug 15;8:0740. doi:[10.34133/research.0740](https://doi.org/10.34133/research.0740)\n# Molecular Merged Hypergraph Neural Network for Explainable Solvation Gibbs Free Energy Prediction\n[Wenjie Du](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Du W\"[Author]>)\n### Wenjie Du\n1Key Laboratory of Precision and Intelligent Chemistry, University of Science and Technology of China, Hefei, Anhui 230026, China.\n2Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, Jiangsu 215123, China.\nFind articles by[Wenjie Du](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Du W\"[Author]>)\n1,2,[Shuai Zhang](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Zhang S\"[Author]>)\n### Shuai Zhang\n2Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, Jiangsu 215123, China.\nFind articles by[Shuai Zhang](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Zhang S\"[Author]>)\n2,[Zhaohui Cai](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Cai Z\"[Author]>)\n### Zhaohui Cai\n3Suzhou Laboratory, Suzhou 215000, China.\n4School of Advanced Technology, Xi\u2019an Jiaotong\u2013Liverpool University, Suzhou 215123, China.\nFind articles by[Zhaohui Cai](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Cai Z\"[Author]>)\n3,4,[Xuqiang Li](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Li X\"[Author]>)\n### Xuqiang Li\n1Key Laboratory of Precision and Intelligent Chemistry, University of Science and Technology of China, Hefei, Anhui 230026, China.\n2Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, Jiangsu 215123, China.\nFind articles by[Xuqiang Li](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Li X\"[Author]>)\n1,2,[Zhiyuan Liu](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Liu Z\"[Author]>)\n### Zhiyuan Liu\n5School of Computing, National University of Singapore, Singapore 117417, Singapore.\nFind articles by[Zhiyuan Liu](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Liu Z\"[Author]>)\n5,[Junfeng Fang](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Fang J\"[Author]>)\n### Junfeng Fang\n5School of Computing, National University of Singapore, Singapore 117417, Singapore.\nFind articles by[Junfeng Fang](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Fang J\"[Author]>)\n5,\\*,[Jianmin Wang](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Wang J\"[Author]>)\n### Jianmin Wang\n6Department of Integrative Biotechnology, Yonsei University, Incheon 21983, Republic of Korea.\nFind articles by[Jianmin Wang](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Wang J\"[Author]>)\n6,\\*,[Xiang Wang](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Wang X\"[Author]>)\n### Xiang Wang\n5School of Computing, National University of Singapore, Singapore 117417, Singapore.\nFind articles by[Xiang Wang](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Wang X\"[Author]>)\n5,[Yang Wang](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Wang Y\"[Author]>)\n### Yang Wang\n1Key Laboratory of Precision and Intelligent Chemistry, University of Science and Technology of China, Hefei, Anhui 230026, China.\n2Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, Jiangsu 215123, China.\n7Anhui Provincial Key Laboratory of High Performance Computing, Hefei, China.\nFind articles by[Yang Wang](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Wang Y\"[Author]>)\n1,2,7,\\*\n* Author information\n* Article notes\n* Copyright and License information\n1Key Laboratory of Precision and Intelligent Chemistry, University of Science and Technology of China, Hefei, Anhui 230026, China.\n2Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, Jiangsu 215123, China.\n3Suzhou Laboratory, Suzhou 215000, China.\n4School of Advanced Technology, Xi\u2019an Jiaotong\u2013Liverpool University, Suzhou 215123, China.\n5School of Computing, National University of Singapore, Singapore 117417, Singapore.\n6Department of Integrative Biotechnology, Yonsei University, Incheon 21983, Republic of Korea.\n7Anhui Provincial Key Laboratory of High Performance Computing, Hefei, China.\n\\*\nAddress correspondence to:jmwang113@hotmail.com(J.W.);fangjf1997@gmail.com(J.F.);angyan@ustc.edu.cn(Y.W.)\nReceived 2025 Apr 1; Revised 2025 May 9; Accepted 2025 May 26; Collection date 2025.\nCopyright \u00a92025 Wenjie Du et\u00a0al.\nExclusive licensee Science and Technology Review Publishing House. No claim to original U.S. Government Works. Distributed under a[Creative Commons Attribution License (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/).\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\nPMCID: PMC12355008\u00a0\u00a0PMID:[40822120](https://pubmed.ncbi.nlm.nih.gov/40822120/)\n## Abstract\nSolvation free energies play a fundamental role in various fields of chemistry and biology. Accurately determining the solvation Gibbs free energy (\u0394Gsolv) of a molecule in a given solvent requires a deep understanding of the intrinsic relationships between solute and solvent molecules. While deep learning methods have been developed for\u0394Gsolvprediction, few explicitly model intermolecular interactions between solute and solvent molecules. The molecular modeling graph neural network more closely aligns with real-world chemical processes by explicitly capturing atomic-level interactions, such as hydrogen bonding. It achieves this by initially establishing indiscriminate connections between intermolecular atoms, which are subsequently refined using an attention-based aggregation mechanism tailored to specific solute\u2013solvent pairs. However, its sharply increasing computational complexity limits its scalability and broader applicability. Here, we introduce an improved framework, molecular merged hypergraph neural network (MMHNN), which leverages a predefined subgraph set and replaces subgraphs with supernodes to construct a hypergraph representation. This design effectively mitigates model complexity while preserving key molecular interactions. Furthermore, to handle noninteractive or repulsive atomic interactions, MMHNN incorporates an interpretation mechanism for nodes and edges within the merged graph, leveraging the graph information bottleneck theory to enhance model explainability. Extensive experimental valid...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12355008"
    },
    {
      "title": "Hybrid Learning Model of Global\u2013Local Graph Attention Network ...",
      "text": "Next Article in Journal\n\n[The Urban\u2013Rural Education Divide: A GIS-Based Assessment of the Spatial Accessibility of High Schools in Romania](https://www.mdpi.com/2220-9964/14/5/183)\n\nPrevious Article in Journal\n\n[The Integration of Geospatial Data for the BIM-Based Inventory of a Skatepark\u2014A Case Study](https://www.mdpi.com/2220-9964/14/5/181)\n\n## Journals\n\n[Active Journals](https://www.mdpi.com/about/journals) [Find a Journal](https://www.mdpi.com/about/journalfinder) [Journal Proposal](https://www.mdpi.com/about/journals/proposal) [Proceedings Series](https://www.mdpi.com/about/proceedings)\n\n[**Topics**](https://www.mdpi.com/topics)\n\n## Information\n\n[For Authors](https://www.mdpi.com/authors) [For Reviewers](https://www.mdpi.com/reviewers) [For Editors](https://www.mdpi.com/editors) [For Librarians](https://www.mdpi.com/librarians) [For Publishers](https://www.mdpi.com/publishing_services) [For Societies](https://www.mdpi.com/societies) [For Conference Organizers](https://www.mdpi.com/conference_organizers)\n\n[Open Access Policy](https://www.mdpi.com/openaccess) [Institutional Open Access Program](https://www.mdpi.com/ioap) [Special Issues Guidelines](https://www.mdpi.com/special_issues_guidelines) [Editorial Process](https://www.mdpi.com/editorial_process) [Research and Publication Ethics](https://www.mdpi.com/ethics) [Article Processing Charges](https://www.mdpi.com/apc) [Awards](https://www.mdpi.com/awards) [Testimonials](https://www.mdpi.com/testimonials)\n\n[**Author Services**](https://www.mdpi.com/authors/english)\n\n## Initiatives\n\n[Sciforum](https://sciforum.net) [MDPI Books](https://www.mdpi.com/books) [Preprints.org](https://www.preprints.org) [Scilit](https://www.scilit.com) [SciProfiles](https://sciprofiles.com) [Encyclopedia](https://encyclopedia.pub) [JAMS](https://jams.pub) [Proceedings Series](https://www.mdpi.com/about/proceedings)\n\n## About\n\n[Overview](https://www.mdpi.com/about) [Contact](https://www.mdpi.com/about/contact) [Careers](https://careers.mdpi.com) [News](https://www.mdpi.com/about/announcements) [Press](https://www.mdpi.com/about/press) [Blog](http://blog.mdpi.com/)\n\n[Sign In / Sign Up](https://www.mdpi.com/user/login)\n\n## Notice\n\nYou can make submissions to other journals\n[here](https://susy.mdpi.com/user/manuscripts/upload).\n\n_clear_\n\n## Notice\n\nYou are accessing a machine-readable page. In order to be human-readable, please install an RSS reader.\n\nContinueCancel\n\n_clear_\n\nAll articles published by MDPI are made immediately available worldwide under an open access license. No special\npermission is required to reuse all or part of the article published by MDPI, including figures and tables. For\narticles published under an open access Creative Common CC BY license, any part of the article may be reused without\npermission provided that the original article is clearly cited. For more information, please refer to\n[https://www.mdpi.com/openaccess](https://www.mdpi.com/openaccess).\n\nFeature papers represent the most advanced research with significant potential for high impact in the field. A Feature\nPaper should be a substantial original Article that involves several techniques or approaches, provides an outlook for\nfuture research directions and describes possible research applications.\n\nFeature papers are submitted upon individual invitation or recommendation by the scientific editors and must receive\npositive feedback from the reviewers.\n\nEditor\u2019s Choice articles are based on recommendations by the scientific editors of MDPI journals from around the world.\nEditors select a small number of articles recently published in the journal that they believe will be particularly\ninteresting to readers, or important in the respective research area. The aim is to provide a snapshot of some of the\nmost exciting work published in the various research areas of the journal.\n\nOriginal Submission Date Received: .\n\n[Submit to this Journal](https://susy.mdpi.com/user/manuscripts/upload?form%5Bjournal_id%5D%3D113) [Review for this Journal](https://susy.mdpi.com/volunteer/journals/review) [Propose a Special Issue](https://www.mdpi.com/journalproposal/sendproposalspecialissue/ijgi)\n\n[\u25ba\u25bc\\\nArticle Menu](https://www.mdpi.com/www.mdpi.com)\n\n## Article Menu\n\n- [Academic Editors](https://www.mdpi.com/www.mdpi.com#academic_editors)\n\n\n[Wolfgang Kainz](https://sciprofiles.com/profile/13097?utm_source=mdpi.com&utm_medium=website&utm_campaign=avatar_name)\n\n\n\n[Hartwig H. Hochmair](https://sciprofiles.com/profile/290940?utm_source=mdpi.com&utm_medium=website&utm_campaign=avatar_name)\n\n- [Subscribe SciFeed](https://www.mdpi.com/2220-9964/14/5/182/scifeed_display)\n- [Recommended Articles](https://www.mdpi.com/www.mdpi.com)\n- [Related Info Link](https://www.mdpi.com/www.mdpi.com#related)\n\n\n- [Google Scholar](http://scholar.google.com/scholar?q=Hybrid%20Learning%20Model%20of%20Global%E2%80%93Local%20Graph%20Attention%20Network%20and%20XGBoost%20for%20Inferring%20Origin%E2%80%93Destination%20Flows)\n\n- [More by Authors Links](https://www.mdpi.com/www.mdpi.com#authors)\n\n\n- on DOAJ\n\n\n- [Shan, Z.](http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Zhenyu%20Shan%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D)\n- [Yang, F.](http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Fei%20Yang%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D)\n- [Shi, X.](http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Xingzi%20Shi%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D)\n- [Cui, Y.](http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Yaping%20Cui%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D)\n\n- on Google Scholar\n\n\n- [Shan, Z.](http://scholar.google.com/scholar?q=Zhenyu%20Shan)\n- [Yang, F.](http://scholar.google.com/scholar?q=Fei%20Yang)\n- [Shi, X.](http://scholar.google.com/scholar?q=Xingzi%20Shi)\n- [Cui, Y.](http://scholar.google.com/scholar?q=Yaping%20Cui)\n\n- on PubMed\n\n\n- [Shan, Z.](http://www.pubmed.gov/?cmd=Search&term=Zhenyu%20Shan)\n- [Yang, F.](http://www.pubmed.gov/?cmd=Search&term=Fei%20Yang)\n- [Shi, X.](http://www.pubmed.gov/?cmd=Search&term=Xingzi%20Shi)\n- [Cui, Y.](http://www.pubmed.gov/?cmd=Search&term=Yaping%20Cui)\n\n/ajax/scifeed/subscribe\n\n[Article Views](https://www.mdpi.com/www.mdpi.com#metrics)\n\n[Citations-](https://www.mdpi.com/www.mdpi.com#metrics)\n\n- [Table of Contents](https://www.mdpi.com/www.mdpi.com#table_of_contents)\n\nAltmetric [_share_ Share](https://www.mdpi.com/www.mdpi.com) [_announcement_ Help](https://www.mdpi.com/www.mdpi.com) [_format\\_quote_ Cite](javascript:void(0);) [_question\\_answer_ Discuss in SciProfiles](https://sciprofiles.com/discussion-groups/public/10.3390/ijgi14050182?utm_source=mpdi.com&utm_medium=publication&utm_campaign=discuss_in_sciprofiles)\n\n## Need Help?\n\n### Support\n\nFind support for a specific problem in the support section of our website.\n\n[Get Support](https://www.mdpi.com/about/contactform)\n\n### Feedback\n\nPlease let us know what you think of our products and services.\n\n[Give Feedback](https://www.mdpi.com/feedback/send)\n\n### Information\n\nVisit our dedicated information section to learn more about MDPI.\n\n[Get Information](https://www.mdpi.com/authors)\n\n_clear_\n\n## JSmol Viewer\n\n_clear_\n\n_first\\_page_\n\n[Download PDF](https://www.mdpi.com/2220-9964/14/5/182/pdf?version=1745484704)\n\n_settings_\n\n[Order Article Reprints](https://www.mdpi.com/2220-9964/14/5/182/reprints)\n\nFont Type:\n\n_Arial__Georgia__Verdana_\n\nFont Size:\n\nAaAaAa\n\nLine Spacing:\n\n_\uf034__\uf034__\uf034_\n\nColumn Width:\n\n_\uf035__\uf035__\uf035_\n\nBackground:\n\nOpen AccessArticle\n\n# Hybrid Learning Model of Global\u2013Local Graph Attention Network and XGBoost for ...",
      "url": "https://www.mdpi.com/2220-9964/14/5/182"
    },
    {
      "title": "Hybrid Graph Neural Networks - Kumo.AI",
      "text": "[Kumo Wins Fast Company's Next Big Things in Tech Award for Advancing AI on Enterprise Data\\\n\\\nLearn More](https://kumo.ai/company/news/kumo-wins-fast-company-s-next-big-things-in-tech-award-for-advancing-ai-on-enterprise-data/)\n\n**Discover how Kumo AI utilizes hybrid graph neural networks (GNNs) to revolutionize recommendation systems. Explore the effectiveness of this approach in both Kaggle data science challenges and real-world customer scenarios.**\n\n## Hybrid GNNs: Transforming recommendation systems with Kumo AI\n\nRecommendation systems have been a subject of great innovation over the past few decades, starting with matrix factorization in the early 2000s and evolving into two-tower and other deep learning approaches in the 2010s. In recent times, graph neural networks emerged as the leading approach to power recommender systems, enabling many well known tech companies (such as Pinterest, Uber, Amazon, and others) to deliver magical customer experiences and double-digit lifts in business metrics. Kumo offers a robust architecture known as hybrid graph neural networks (hybrid GNNs), which has been empirically shown to deliver outstanding performance on both public Kaggle data science challenges, and real-world production deployments.\n\n## Understanding the complexity of recommendation systems\n\nAt their core, recommendation systems are responsible for recommending content or products to users, with the goal of providing inspiration to users. However, developing these systems is inherently challenging, due to fickle preferences and complex patterns of human behavior. Users vary significantly in preferences; some are explorers who constantly seek new experiences, while others are repeaters who prefer familiarity. This is made even more challenging in the face of big data, cold-start items, new users with very little interaction history, and lack of data diversity.\n\nBecause this problem is so challenging, many engineering teams have developed multi-stage recommendation pipelines involving numerous candidate generation steps followed by a complex ensemble of ranking models. These systems take tens of millions of dollars to build, in terms of human and infrastructure cost, and are challenging to maintain over time.\n\n## Introducing the hybrid GNN architecture\n\nTo address these challenges, Kumo developed a hybrid GNN approach that can create great recommendations with a single model, while capturing the nuanced behaviors of different users with remarkable accuracy. The hybrid GNN models two distinct user behaviors differently within a single backbone GNN model: repeated interactions and explorative interactions; hence, referring to this model as a\u00a0**_hybrid GNN_**. The hybrid GNN is the default model architecture for recommendation and personalization tasks at Kumo, and it can be fine tuned to your specific dataset using the Model Planner.\n\n## Why GNNs are ideal for recommendations\n\nGNNs are highly-suitable for recommendation tasks because, unlike traditional models, they can leverage rich graph connectivity patterns to gain a deeper understanding of user preferences and insights that are often missed by other algorithms.\n\nThe recommendation problem forms a\u00a0**_bipartite graph_**\u00a0between users and items, where nodes represent the users and items, and edges represent the user-item interactions. Edges often come with timestamps. Moreover, multiple edges may exist between pairs of nodes, since a user may repeatedly interact with the same item (e.g., repeat ordering of the same product in e-commerce). Given the bipartite graph of the past interactions, a recommendation task can be cast as a link prediction task\u2014one that calls for predicting future interactions between user nodes and item nodes.\n\n## Model input: Processing data with the hybrid GNN\n\nThe hybrid GNN model is designed to capture fine-grained user behaviors by leveraging graph connectivity. Similar to a standard GNN model (e.g., GraphSAGE), the Hybrid GNN model processes input through a subgraph centered around each user node. For simplicity and efficiency, consider a 1-hop neighbor sampler:\n\nA 1-hop neighbor subgraph contains items that a user previously interacted with, as well as features associated with the sampled users, items, and edges (e.g., timestamp, price etc). Given the subgraph, a hybrid GNN employs a heterogeneous GNN to compute embeddings of the user and items.\n\n## Exploring the hybrid GNN model architecture\n\nThe key innovation of the hybrid GNN is its\u00a0**_hybrid_**\u00a0approach to computing item scores per user, which are then sorted to produce the top K item recommendation for the user. Specifically, the\u00a0**hybrid GNN computes item scores differently based on whether or not items are sampled within the subgraph.**\n\nThese differing scoring approaches are as follows:\n\n**(1) For items sampled in the subgraph,** the Hybrid GNN computes the item scores by applying a multi-layer perceptron (MLP) over the GNN\u2019s item embeddings. Since the GNN\u2019s item embedding contains information about historical interactions between the user and the item, the MLP can be applied to the item embedding\u00a0**to predict whether or not the user would repeat the interaction with the item.**\n\n**(2) For items not sampled in the subgraph,**\u00a0the Hybrid GNN computes the item scores by taking an inner product between GNN\u2019s user embeddings with shallow item embeddings. As the low-dimensional item embeddings can capture similarity between items (\u00e0 la matrix factorization), GNNs can use this method\u00a0**to recommend similar items that a user has never interacted with before.**\n\nThe observation that\u00a0**_user behaviors are diverse_** is the final element that makes the hybrid GNN work. Some users prefer to repeatedly interact with the same set of items (better captured by the first hybrid GNN scoring approach), while others like to constantly explore new items (better captured by the second hybrid GNN scoring approach). To accommodate such diversity across different users, the hybrid GNN learns a\u00a0**_user-specific repetition scalar_**\u00a0predicted from GNN\u2019s user embeddings with another MLP. The scalar is added to the score of the first approach to capture the repetitiveness of each user\u2019s behavior. The more repetitive a user is, the hybrid GNN will predict a higher\u00a0**_user-specific repetition scalar_**. On the other hand, if users are highly explorative (i.e., they interact with new items a lot), the hybrid GNN will predict lower\u00a0**_user-specific repetition scalar_**.\n\n## Training and optimization: Maximizing performance with the hybrid GNN\n\nThe hybrid GNN is trained end-to-end, optimizing both types of item scores as well as the repetition scalar altogether to maximize the predictive performance of future user-item interactions.This way, the hybrid GNN will figure out the user behaviors from data on its own, producing highly accurate predictions that capture the complex nature of repetition versus exploration behaviors.\n\n## Empirical studies: Assessing hybrid GNN performance\n\nThe hybrid GNN performance was tested using a\u00a0[**Kaggle H&M recommendation challenge**](https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations). The challenge called for predicting the top 12 items each user would purchase in the next 7 days, with model performance measured by mean average precision (MAP) @ 12. The dataset contains two years of historical data consisting of 1.4M users, 106K items, and 31.7M interactions between them. The challenge attracted a total of 3,000+ teams that submitted results to the public Kaggle leaderboard, over the course of the 3-month competition held in 2022.\n\n## Comparing hybrid GNN results to top Kaggle competitors\n\nThe following are the results of the hybrid GNN, evaluated on the hidden test set after the competition (Kaggle allows post-competition submissions). A comparison of the hybrid GNN results to the top Kaggle competitor submissions is also provided below:\n\n| Model | MAP@12 score on Kaggle publi...",
      "url": "https://kumo.ai/research/hybrid-graph-neural-networks"
    },
    {
      "title": "Predicting drug solubility in binary solvent mixtures using graph convolutional networks: a comprehensive deep learning approach",
      "text": "Predicting drug solubility in binary solvent mixtures using graph convolutional networks: a comprehensive deep learning approach | Scientific Reports\n[Skip to main content](#content)\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\nthe best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\nInternet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\nand JavaScript.\nAdvertisement\n[![Scientific Reports](https://media.springernature.com/full/nature-cms/uploads/product/srep/header-d3c533c187c710c1bedbd8e293815d5f.svg)](https://www.nature.com/srep)\n* [View all journals](https://www.nature.com/siteindex)\n* [Search](#search-menu)\n* [Log in](https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41598-025-28272-3?error=cookies_not_supported&code=c609e51b-ee82-4770-b684-5ec22aa40b71)\n* [ContentExplore content](#explore)\n* [Aboutthe journal](#about-the-journal)\n* [Publishwith us](#publish-with-us)\n* [Sign up for alerts](https://journal-alerts.springernature.com/subscribe?journal_id&#x3D;41598)\n* [RSS feed](https://www.nature.com/srep.rss)\nPredicting drug solubility in binary solvent mixtures using graph convolutional networks: a comprehensive deep learning approach\n[Download PDF](https://www.nature.com/articles/s41598-025-28272-3.pdf)\n[Download PDF](https://www.nature.com/articles/s41598-025-28272-3.pdf)\n* Article\n* [Open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)\n* Published:29 November 2025# Predicting drug solubility in binary solvent mixtures using graph convolutional networks: a comprehensive deep learning approach\n* [Masoud Amiri](#auth-Masoud-Amiri-Aff1)[1](#Aff1)&amp;\n* [Farnaz Khaleseh](#auth-Farnaz-Khaleseh-Aff2)[2](#Aff2)\n[*Scientific Reports*](https://www.nature.com/srep)**volume15**, Article\u00a0number:45711(2025)[Cite this article](#citeas)\n* 1653Accesses\n* [Metricsdetails](https://www.nature.com/articles/s41598-025-28272-3/metrics)\n### Subjects\n* [Chemistry](https://www.nature.com/subjects/chemistry)\n* [Computational biology and bioinformatics](https://www.nature.com/subjects/computational-biology-and-bioinformatics)\n* [Drug discovery](https://www.nature.com/subjects/drug-discovery)\n* [Mathematics and computing](https://www.nature.com/subjects/mathematics-and-computing)\n## Abstract\nThe prediction of drug solubility represents a fundamental challenge in pharmaceutical development, with traditional experimental methods proving both time-intensive and resource-demanding. This study presents a comprehensive evaluation of Graph Convolutional Networks (GCNs) for predicting drug solubility in binary solvent mixtures across diverse temperature ranges. We used an extensive dataset comprising 27,000 solubility measurements encompassing 123 small-molecule solutes, 44 solvents, and 110 binary solvent combinations measured across varied temperatures (273\u2013373 K). Our GCN architecture incorporates multi-head attention mechanisms, hierarchical molecular representation learning, and sophisticated pooling strategies to capture complex molecular interactions. The proposed GCN model achieved exceptional performance with a mean absolute error (MAE) of 0.28\\\\(LogS\\\\)units, demonstrating a 15% improvement over traditional machine learning approaches. Through comprehensive ablation studies and attention visualization analyses, we demonstrate that GCNs excel particularly in modeling structure-solubility relationships for pharmaceutically relevant compounds. Prospective validation using four drug molecules confirmed the model\u2019s predictive reliability, with experimental verification yielding MAE\u2009&lt;\u20090.5\\\\(Log\\\\)S for compounds structurally similar to training data. This research establishes GCNs as powerful tools for accelerating pharmaceutical formulation development, potentially reducing experimental requirements by 60\u201380% while providing interpretable molecular insights through attention mechanisms. This work demonstrates that thoughtful integration of established graph neural network techniques, specifically optimized for binary solvent systems, can substantially advance computational solubility prediction for pharmaceutical applications.\n### Similar content being viewed by others\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-025-05535-7/MediaObjects/41598_2025_5535_Fig1_HTML.png)\n### [Machine learning-based analysis on pharmaceutical compounds interaction with polymer to estimate drug solubility in formulations](https://www.nature.com/articles/s41598-025-05535-7?fromPaywallRec=false)\nArticleOpen access02 July 2025\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-021-97193-8/MediaObjects/41598_2021_97193_Fig1_HTML.png)\n### [A machine learning framework for predicting drug\u2013drug interactions](https://www.nature.com/articles/s41598-021-97193-8?fromPaywallRec=false)\nArticleOpen access02 September 2021\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-025-19873-z/MediaObjects/41598_2025_19873_Fig1_HTML.png)\n### [Machine learning estimation and optimization for evaluation of pharmaceutical solubility in supercritical carbon dioxide for improvement of drug efficacy](https://www.nature.com/articles/s41598-025-19873-z?fromPaywallRec=false)\nArticleOpen access14 October 2025\n## Introduction\nDrug solubility constitutes a critical physicochemical parameter that fundamentally influences multiple aspects of pharmaceutical development, including drug discovery[1](#ref-CR1),[2](#ref-CR2),[3](https://www.nature.com/articles/s41598-025-28272-3#ref-CR3), analytical chemistry[4](https://www.nature.com/articles/s41598-025-28272-3#ref-CR4),[5](https://www.nature.com/articles/s41598-025-28272-3#ref-CR5), and formulation design[6](#ref-CR6),[7](#ref-CR7),[8](https://www.nature.com/articles/s41598-025-28272-3#ref-CR8). The accurate determination of solubility typically relies on established thermodynamic and kinetic methodologies[9](https://www.nature.com/articles/s41598-025-28272-3#ref-CR9),[10](https://www.nature.com/articles/s41598-025-28272-3#ref-CR10), where thermodynamic approaches measure equilibrium concentrations between dissolved and solid phases, while kinetic methods determine precipitation onset concentrations[11](https://www.nature.com/articles/s41598-025-28272-3#ref-CR11).\nDespite methodological advances aimed at enhancing experimental throughput[12](https://www.nature.com/articles/s41598-025-28272-3#ref-CR12),[13](https://www.nature.com/articles/s41598-025-28272-3#ref-CR13), significant challenges persist, particularly when dealing with high-value pharmaceutical compounds or when material availability is constrained. These limitations have catalyzed research into computational alternatives, with machine learning and deep learning approaches emerging as promising solutions[14](https://www.nature.com/articles/s41598-025-28272-3#ref-CR14),[15](https://www.nature.com/articles/s41598-025-28272-3#ref-CR15).\nThe majority of existing machine learning models focus on predicting solubility in single solvents[16](#ref-CR16),[17](#ref-CR17),[18](#ref-CR18),[19](#ref-CR19),[20](#ref-CR20),[21](#ref-CR21),[22](#ref-CR22),[23](#ref-CR23),[24](#ref-CR24),[25](https://www.nature.com/articles/s41598-025-28272-3#ref-CR25), primarily targeting aqueous systems due to abundant training data availability. While such solvent- specific models typically achieve higher accuracy by avoiding inter-solvent variability, their applicability remains limited to the specific solvents for which they were developed. Recent efforts have expanded toward multi-solvent systems, with notable contributions from Vasiliou et al.[26](https://www.nature.com/articles/s41598-025-28272-3#ref-CR26), who compiled 714 solubility measurements across ...",
      "url": "https://www.nature.com/articles/s41598-025-28272-3"
    },
    {
      "title": "Hierarchical attention graph learning with LLM enhancement for molecular solubility prediction",
      "text": "Hierarchical attention graph learning with LLM enhancement for molecular solubility prediction - Digital Discovery (RSC Publishing) DOI:10.1039/D5DD00407A\n[![Royal Society of Chemistry](https://pubs.rsc.org/content/NewImages/royal-society-of-chemistry-logo.png)](https://pubs.rsc.org/)\n[View\u00a0PDF\u00a0Version](https://pubs.rsc.org/en/content/articlepdf/2026/dd/d5dd00407a)\n[![Check for updates](https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_square.svg)](#)\n![](https://pubs.rsc.org/content/newimages/open_access_blue.png)Open Access Article\n![](https://pubs.rsc.org/content/newimages/CCBY-NC.svg)This Open Access Article is licensed under a[Creative Commons Attribution-Non Commercial 3.0 Unported Licence](http://creativecommons.org/licenses/by-nc/3.0/)\nDOI:[10.1039/D5DD00407A](https://doi.org/10.1039/D5DD00407A)(Paper)[Digital Discovery](https://doi.org/10.1039/2635-098X/2022), 2026, Advance Article\n# Hierarchical attention graph learning with LLM enhancement for molecular solubility prediction\nYangxin Fan[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0003-1728-9560)a,Yinghui Wu[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0003-3991-5155)a,Roger H. French[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-6162-0532)b,Danny Perez[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0003-3028-5249)c,Michael G. Taylor[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0003-4327-2746)candPing Yang[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0003-4726-2860)\\*c\naDepartment of Computer Science, Case Western Reserve University, Cleveland, OH, USA. E-mail:[yxf451@case.edu](mailto:yxf451@case.edu);[yxw1650@case.edu](mailto:yxw1650@case.edu)\nbDepartment of Material Science, Case Western Reserve University, Cleveland, OH, USA. E-mail:[rxf131@case.edu](mailto:rxf131@case.edu)\ncTheoretical Division, Los Alamos National Laboratory, Los Alamos, NM, USA. E-mail:[danny\\_perez@lanl.gov](mailto:danny_perez@lanl.gov);[mgt16@lanl.gov](mailto:mgt16@lanl.gov);[pyang@lanl.gov](mailto:pyang@lanl.gov)\nReceived 12th September 2025, Accepted 11th December 2025\nFirst published on 15th December 2025\n## Abstract\nSolubility quantifies the concentration of a molecule that can dissolve in a given solvent. Accurate prediction of solubility is essential for optimizing drug efficacy, improving chemical and separation processes, and waste management, among many other industrial and research applications. Predicting solubility from first principles remains a complex and computationally intensive physicochemical challenge. Recent successes of graph neural networks for molecular learning tasks inspire us to develop HASolGNN, a hierarchical\u2013attention graph neural network for solubility prediction. (1) HASolGNN adopts a three-level hierarchical attention framework to leverage atom-bond, molecular, and interaction-graph level features. This allows a more comprehensive modeling of both intra-molecular and inter-molecular interactions for solute\u2013solvent dissolution as a complex system. (2) To mitigate the impact of small amounts of annotated data, we also investigate the role of Large Language Models (LLMs), and introduce HASolGNN-LLMs, an LLM-enhanced predictive framework that leverages LLMs to infer annotated features and embeddings to improve representation learning. Our experiments verified that (1) HASolGNN outperforms the state-of-the-art methods in solubility prediction; and (2) HASolGNN-LLMs effectively exploits LLMs to enhance sparsely annotated data and further improves overall accuracy.\n## 1 Introduction\nSolubility is broadly relevant to many applications, including nuclear waste separation,[1,2](#cit1)environmental pollution control,[3](#cit3)development of advanced materials in the semi-conductor industry,[4,5](#cit4)autonomous robotics synthesis,[6,7](#cit6)crystallization,[8](#cit8)and protein ligand bonding in the biomedical field.[9,10](#cit9)In particular, aqueous solubility refers to the solubility of a solute in water. It plays an essential role in pharmaceutical science,[11\u201313](#cit11)since (1) accurate prediction of solubility is critical for selecting promising drug candidates during the screening process, and (2) all drugs in the body exert their therapeutic effects in the form of aqueous solutions, which means lower solubility diminishes both their efficacy and bioavailability. Therefore, high-precision computational methods for solubility prediction can substantially decrease the experimental costs and time associated with drug development[14](#cit14)while enabling chemists to develop formulations that maximize drug efficacy and improve patient outcomes.\n[Fig. 1](#imgfig1)shows a solubility prediction pipeline, involving four components: solubility dataset curation, description generation, model training, and solubility prediction. Solubility data typically refer to the SMILES[15](#cit15)of solute and solvent pairs, log![[thin space (1/6-em)]](https://www.rsc.org/images/entities/char_2009.gif)S(log-scale solubility), as well as the molecular features such as melting point (MP), molecular weight (MW), and volume. The pipeline then converts the SMILES into (1) molecular graphs and (2) molecular fingerprints (physiochemical features). Molecular graphs will be used to train graph neural networks (GNNs) and their variants (e.g., ref.[16\u201319](#cit16)), while molecular fingerprints are typically used by traditional machine learning and domain methods (e.g., ref.[20\u201323](#cit20)). Next, the models predict solubility for critical applications in areas such as drug discovery.\n[![image file: d5dd00407a-f1.tif](https://pubs.rsc.org/image/article/2026/DD/d5dd00407a/d5dd00407a-f1.gif)](https://pubs.rsc.org/image/article/2026/DD/d5dd00407a/d5dd00407a-f1_hi-res.gif)|\n|**Fig. 1**Solubility prediction pipeline. Solubility prediction models are categorized into three major types, with critical applications spanning fields such as material separation and drug discovery.||\n### 1.1 State-of-the-art\nSolubility prediction has been a long-standing challenge. A host of methods have been developed to predict the solubility of molecular systems. Recent approaches fall into three categories: (1) domain-specific methods, rooted in principles of quantum mechanics and thermodynamics; (2) traditional ML-based methods, which leverage established regression models and ensemble learning to predict solubility; and more recently, (3) graph neural network (GNN)-based methods, which utilize molecular graphs to model atoms and bonds and train GNNs as regression or classifiers.\n(1) Domain-specific methods adhere to the quantitative structure\u2013property relationship (QSPR) framework.[24](#cit24)They regress solubility against a selected set of molecular descriptors, capturing the structural and physicochemical properties of compounds. Depending on the underlying theoretical foundation, such methods employ a range of mathematical models, including differential and partial differential equations, to predict solubility.[22,23,25](#cit22)\n(2) Among ML-based methods, boosting methods such as XGBoost[20](#cit20)and random forest[21](#cit21)have been widely applied. Other ML models include multi-layer perceptron (MLP)[26](#cit26)and artificial neural networks (ANNs).[27,28](#cit27)These methods take molecular fingerprints as input features, leveraging the encoded molecular-level structural information to predict solubility.\n(3) Several GNN-based methods were developed, which exploit graph convolutional networks (GCNs),[16,17](#cit16)gated graph neural networks (GGNNs),[29,30](#cit29)node-level attention-based graph attention networks (GATs),[31,32](#cit31)and molecular representation learning integrating both node- and graph-level attention mec...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2026/dd/d5dd00407a"
    }
  ]
}