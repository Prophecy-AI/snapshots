{
  "query": "How do you improve generalization for chemical reaction yield prediction when test molecules are structurally different from training molecules using physics-informed constraints?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Improving the ability of a yield\u2011prediction model to generalize to test molecules that are **structurally out\u2011of\u2011distribution** can be achieved by tightly coupling the learning process to known chemical physics.  The following concise workflow incorporates the physics\u2011informed strategies reported in recent research:\n\n1. **Select a graph\u2011based reaction encoder** (e.g., a GNN that ingests reactant and reagent graphs) as the core representation learner.  This provides a flexible way to capture molecular topology while remaining compatible with physics\u2011based regularisation.\u202f([Wang\u202fet\u202fal., 2023\u20112024](https://arxiv.org/html/2405.11752v2))  \n\n2. **Embed universal kinetic laws as hard or soft constraints**:  \n   * **Mass\u2011action law** \u2013 force the predicted rate\u2011or\u2011yield to be proportional to the product of reactant concentrations.  \n   * **Arrhenius temperature dependence** \u2013 tie temperature\u2011sensitive parameters to the exponential form\u202f\\(k = A\u202fe^{-E_a/RT}\\).  \n   Implement these either by designing the output layer to compute yields from these formulas or by adding a penalty term to the loss that measures deviation from them.\u202f([Deng\u202f2023, Bayesian CRNN](https://pubs.rsc.org/en/content/articlehtml/2023/cp/d2cp05083h))  \n\n3. **Apply physics\u2011informed meta\u2011learning for rapid adaptation**:  \n   * Pre\u2011train the GNN on a large, diverse reaction corpus.  \n   * During meta\u2011training, treat the physics constraints as *inner\u2011loop* objectives that must be satisfied after each adaptation step.  \n   * At test time, fine\u2011tune the model on a few reactions containing the novel scaffolds while keeping the physics\u2011regularisation active.  This \u201cphysics\u2011informed adaptation\u201d has been shown to improve OOD performance on unseen chemistries.\u202f([Wang\u202fet\u202fal., 2025, Foundation Model for Reactor Modeling](https://arxiv.org/html/2405.11752v2))  \n\n4. **Enrich the training set with physics\u2011consistent data augmentation**: generate synthetic reactions by varying concentrations, temperatures, or by swapping chemically equivalent substructures, ensuring each augmented example still obeys the mass\u2011action and Arrhenius relations.  Such augmentation broadens the structural distribution without breaking physical realism.\u202f([Schwaller\u202f2020, Data augmentation for yield prediction](https://chemrxiv.org/engage/chemrxiv/article-details/60c75258702a9b726c18c101))  \n\n5. **Use contrastive learning on reaction conditions** to pull together representations of reactions that share the same underlying physics (e.g., same temperature regime) and push apart those with different conditions.  This \u201ccondition\u2011based contrastive\u201d objective further aligns the model\u2019s latent space with physical invariants, helping it extrapolate to new molecular scaffolds.\u202f([Yin\u202f2024, Reaction\u2011condition contrastive learning](https://pubmed.ncbi.nlm.nih.gov/38213662))  \n\n6. **Validate on structure\u2011level OOD splits** (e.g., hold\u2011out patents, new authors, or time\u2011based splits) as recommended in the OOD benchmark suite.  Report both standard yield\u2011error metrics and the degree to which physics constraints are satisfied on the test set.\u202f([Wang\u202fet\u202fal., 2023, OOD kinetic property prediction](https://arxiv.org/pdf/2310.03152))  \n\nBy **embedding kinetic physics directly into the model**, **meta\u2011learning with those constraints**, and **augmenting/contrastively training on condition\u2011consistent data**, the predictor learns representations that are less tied to specific molecular fingerprints and more to the underlying reaction mechanisms\u2014thereby achieving better generalization when faced with structurally novel test molecules.",
      "url": ""
    },
    {
      "title": "Towards Foundation Model for Chemical Reactor Modeling: Meta-Learning with Physics-Informed Adaptation",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/html/2405.11752v2"
    },
    {
      "title": "",
      "text": "Towards out-of-distribution generalizable predictions\nof chemical kinetic properties\nZihao Wang\u2217\nCSE, HKUST\nzwanggc@cse.ust.hk\nYongqiang Chen\u2217\nCSE, CUHK\nyqchen@cse.cuhk.edu.hk\nYang Duan, Weijiang Li\nCS, UIUC\n{yangd4,wl13}@illinois.edu\nBo Han\nCS, HKBU\nbhanml@comp.hkbu.edu.hk\nJames Cheng\nCSE, CUHK\njcheng@cse.cuhk.edu.hk\nHanghang Tong\nCS, UIUC\nhtong@illinois.edu\nAbstract\nMachine Learning (ML) techniques have found applications in estimating chem\u0002ical kinetic properties. With the accumulated drug molecules identified through\n\u201cAI4drug discovery\u201d, the next imperative lies in AI-driven design for high\u0002throughput chemical synthesis processes, with the estimation of properties of\nunseen reactions with unexplored molecules. To this end, the existing ML ap\u0002proaches for kinetics property prediction are required to be Out-Of-Distribution\n(OOD) generalizable. In this paper, we categorize the OOD kinetic property pre\u0002diction into three levels (structure, condition, and mechanism), revealing unique\naspects of such problems. Under this framework, we create comprehensive datasets\nto benchmark (1) the state-of-the-art ML approaches for reaction prediction in the\nOOD setting and (2) the state-of-the-art graph OOD methods in kinetics property\nprediction problems. Our results demonstrated the challenges and opportunities\nin OOD kinetics property prediction. Our datasets and benchmarks can further\nsupport research in this direction. The github repository for code and data can be\nfound in https://github.com/zihao-wang/ReactionOOD.\n1 Introduction\nIn recent years, graph machine learning has been widely used in scientific discovery [Wang et al.,\n2023, Zhang et al., 2023] and gained particular success in chemistry [Gilmer et al., 2017, Jumper\net al., 2021, Mullowney et al., 2023]. The underlying rationale is the long-standing structure-property\nrelationship [Mihalic and Trinajsti \u00b4 c\u00b4, 1992] in chemistry. For example, Graph Neural Networks\n(GNNs) can efficiently encode information at both the molecular structure level and the atom level\nwithin a molecule, which reveal compelling properties of the molecule [Gilmer et al., 2017]. Such\nmethods yield efficient, cheap, but still effective predictions of the properties of unseen molecules\nbefore expensive experiments or computations, which can serve as valuable reference information for\ndrug discovery [Mullowney et al., 2023].\nOne of the next questions to be answered after the discovery of a proper but unseen molecule is\nHow to efficiently obtain unseen molecules through chemical synthesis. In contrast to the molecule\nproperty estimation problem that concerns a single molecule, chemical synthesis processes involve the\nproper arrangement of various reactions that encompass multiple molecules under optimal conditions.\nTherefore, the very first step of achieving a high-throughput synthesis of unseen molecules is to\nestimate the properties of chemical reactions [Warr, 2014], especially kinetics properties that describe\n\u2217Equal contribution.\nNeurIPS 2023 Workshop in AI for Scientific Discovery: From Theory to Practice.\narXiv:2310.03152v2 [cs.LG] 4 Dec 2023\nthe \u201crate\u201d of reactions. This prediction task is expected to be Out-Of-Distribution (OOD) generalizable\nso that the kinetic properties of OOD reactions with unseen molecules can be well predicted.\nRecently, machine learning methods have been applied to predict the kinetic properties of reac\u0002tions [Heid and Green, 2021]. In existing studies, chemical reactions are assumed to be Independently\nand Identically Distributed (IID), and models are trained and tested within random splits [Heid and\nGreen, 2021, Stuyver and Coley, 2022, Heid et al., 2023]. However, results from such IID assump\u0002tions provide little credible insight into the performances of existing ML methods in OOD reaction\nproperty prediction. Meanwhile, existing theoretical and empirical studies for OOD generalization\non graphs [Ji et al., 2022, Gui et al., 2022], are restricted to problems with a single graph. How OOD\nmethods perform reaction properties prediction with multiple molecules is still unknown.\nTo fill this gap, this paper discusses the out-of-distribution generalization issue when applying\nmachine learning methods to the prediction of chemical reaction properties. We propose three levels\nof OOD shifts for ML-based reaction prediction: Structure OOD, Mechanism OOD, and Conditional\nOOD. Then, we reorganize recent reaction kinetic databases [Johnson et al., 2022] and create a\ncomprehensive dataset in three levels of OOD. Furthermore, we empirically justify the performance\nof state-of-the-art kinetic property prediction produced by state-of-the-art OOD methods for general\nand graph inputs. Our results demonstrated that there remain huge ID-OOD performance gaps under\ndifferent distribution shifts in chemical reactions for existing OOD methods.\n2 Related works\nIncreasing efforts have been made to devise machine learning approaches for various aspects of\nchemical reaction systems [Davies, 2019, Stocker et al., 2020, Meuwly, 2021, Strieth-Kalthoff\net al., 2022], such as reaction classification [Schwaller et al., 2021b, Bur\u00e9s and Larrosa, 2023],\nreaction optimization [Felton et al., 2021], atom mapping [Schwaller et al., 2021a], and the most\nfundamentally, reaction property prediction [Heid and Green, 2021]. With the burst of chemical\nreaction data [von Rudorff et al., 2020, Spiekermann et al., 2022, Johnson et al., 2022, Choi, 2023,\nStuyver et al., 2023, Zhao et al., 2023], the Graph Neural Network (GNN) based methods [Heid and\nGreen, 2021, Stuyver and Coley, 2022, Heid et al., 2023] are demonstrated its clear advantage over\ntraditional methods by leveraging the structure of reactants and products.\nOut-of-distribution shift is one of the long-standing problems in machine learning [Vapnik, 1991,\nQuinonero-Candela et al., 2008, Shen et al., 2021]. Recently, OOD generalizable graph neural net\u0002works have been discussed extensively [Bevilacqua et al., 2021, Zhu et al., 2021, Wu et al., 2022b,a,\nChen et al., 2022]. When it comes to scientific discovery, out-of-distribution generalization capabili\u0002ties enable machine learning methods to find more reliable discoveries from existing observations. A\nthorough investigation of the intersection of OOD and drug discovery can be found at Ji et al. [2022]\nand Gui et al. [2022]. However, as we will identify in the incoming parts, the out-of-distribution\nshifts for chemical reactions are radically different from those with existing graph OOD settings [Gui\net al., 2022], and existing OOD methods do not perform well.\n3 Preliminary\n3.1 Chemical reactions and kinetic property prediction\nA chemical reaction R is described by the reactants r1, . . . , rm, products p1, . . . , pn, and the condi\u0002tions c1, . . . , cl\n.\n2\nr1 + \u00b7 \u00b7 \u00b7 + rm\nc1,...,cl =\u21d2 p1 + \u00b7 \u00b7 \u00b7 + pn. (1)\nMultiple molecules (including atoms, ions, and other species) are involved in one reaction, which\ndiffers from molecule property prediction tasks where only one molecule structure is considered.3\nEach molecule ri, pj is considered as a molecule graph, with atoms as attributed nodes and bonds as\nattributed edges. For a chemical reaction R, R[R] (P[R]) denotes the graph of reactants (products)\n2\nIn chemistry literature, different arrow types indicate different reaction types. We use =\u21d2 for simplicity.\n3\nIn this paper, we assume reactions adhere to the law of conservation of matter, ensuring both atoms and\nelectrons are equally represented on either side of the reaction equation.\n2\nTable 1: Two types of distribution shifts. [X] denotes the domain index of the input X.\nDistribution shifts P([X]) P(Y |[X])\nCovariate shift P\ntrain([X]) \u0338= Ptest([X]) Ptrain(Y |[X]) = Ptest(Y |[X])\nConcept shift P\ntrain([X]) = Ptest([X]) Ptrain(Y |[X]) \u0338= Ptest(Y |[X])\nas the union of the reactant (product) molecule graphs. C[R] denotes the set of conditions. GR (GP )\nand C denote the space of graphs for reactants (products) and the space of conditions, resp...",
      "url": "https://arxiv.org/pdf/2310.03152"
    },
    {
      "title": "Data augmentation strategies to improve reaction yield predictions and estimate uncertainty",
      "text": "Data augmentation strategies to improve reaction yield predictions and estimate uncertainty | Theoretical and Computational Chemistry | ChemRxiv | Cambridge Open Engage\n[![Cambridge Open Engage home](https://chemrxiv.org/engage/_nuxt/img/OpenEngageWhiteLogoWithText.0047d13.svg)](https://chemrxiv.org/engage/coe/public-dashboard)\n[What is Cambridge Open Engage?](https://chemrxiv.org/engage/coe/contact-information?show=faqs)\n[![ChemRxiv Home](https://chemrxiv.org/engage/assets/public/chemrxiv/images/logos/chemrxiv/rgb.svg)](https://chemrxiv.org/engage/chemrxiv/public-dashboard)\n[**How to Submit**](https://chemrxiv.org/engage/chemrxiv/submission-information)\n[**Browse**](https://chemrxiv.org/engage/chemrxiv/browse-dashboard)\n[**About**](https://chemrxiv.org/engage/chemrxiv/about-information)\n[\n**News**[opens in a new tab]\n](https://connect.acspubs.org/chemrxiv)\nLog in\n[Back toTheoretical and Computational Chemistry](https://chemrxiv.org/engage/chemrxiv/category-dashboard/605c72ef153207001f6470ce)\nSearch within Theoretical and Computational Chemistry\n[](#)\n![RSS feed for Theoretical and Computational Chemistry](https://chemrxiv.org/engage/assets/public/chemrxiv/social/rss.svg)\n# Data augmentation strategies to improve reaction yield predictions and estimate uncertainty\n26 November 2020, Version 1\nWorking Paper\n## Authors\n* [Philippe Schwaller](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Philippe%20Schwaller)[![Author ORCID: We display the ORCID iD icon alongside authors names on our website to acknowledge that the ORCiD has been authenticated when entered by the user. To view the users ORCiD record click the icon. [opens in a new tab]](https://chemrxiv.org/engage/assets/public/chemrxiv/images/logos/orcid.png)](https://orcid.org/0000-0003-3046-6576),\n* [Alain C. Vaucher](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Alain%20C.%20Vaucher)[![Author ORCID: We display the ORCID iD icon alongside authors names on our website to acknowledge that the ORCiD has been authenticated when entered by the user. To view the users ORCiD record click the icon. [opens in a new tab]](https://chemrxiv.org/engage/assets/public/chemrxiv/images/logos/orcid.png)](https://orcid.org/0000-0001-7554-0288),\n* [Teodoro Laino](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Teodoro%20Laino),\n* [Jean-Louis Reymond](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Jean-Louis%20Reymond)[![Author ORCID: We display the ORCID iD icon alongside authors names on our website to acknowledge that the ORCiD has been authenticated when entered by the user. To view the users ORCiD record click the icon. [opens in a new tab]](https://chemrxiv.org/engage/assets/public/chemrxiv/images/logos/orcid.png)](https://orcid.org/0000-0003-2724-2942)\n[Show author details](#)\n![](https://chemrxiv.org/engage/_nuxt/img/NonPeerReviewed.5753084.svg)This content is a preprint and has not undergone peer review at the time of posting.\nDownload\nCite\nComment\n## Abstract\nChemical reactions describe how precursor molecules react together and transform into products. The reaction yield describes the percentage of the precursors successfully transformed into products relative to the theoretical maximum. The prediction of reaction yields can help chemists navigate reaction space and accelerate the design of more effective routes. Here, we investigate the best-studied high-throughput experiment data set and show how data augmentation on chemical reactions can improve yield predictions' accuracy, even when only small data sets are available. Previous work used molecular fingerprints, physics-based or categorical descriptors of the precursors. In this manuscript, we fine-tune natural language processing-inspired reaction transformer models on different augmented data sets to predict yields solely using a text-based representation of chemical reactions. When the random training sets contain 2.5% or more of the data, our models outperform previous models, including those using physics-based descriptors as inputs. Moreover, we demonstrate the use of test-time augmentation to generate uncertainty estimates, which correlate with the prediction errors.\n## Keywords\n[SMILES](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=SMILES)\n[SMILES-Encoded](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=SMILES-Encoded)\n[chemical reactions](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=chemical%20reactions)\n[reaction yields](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=reaction%20yields)\n[data augmentation](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=data%20augmentation)\n[BERT](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=BERT)\n[Transformers](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Transformers)\n[Deep learning](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Deep%20learning)\n[regression](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=regression)\n[test-time augmentation](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=test-time%20augmentation)\n## Comments\nYou are signed in as . Your name will appear\nwith any comment you post.\nComments are not moderated before they are posted, but they can be removed\nby the site moderators if they are found to be in contravention of our[Commenting Policy[opens in a new tab]](https://chemrxiv.org/engage/chemrxiv/about-information?show=commenting-policy)- please read this policy before you post. Comments should be used for\nscholarly discussion of the content in question. You can[find more information about how to use the commenting feature here[opens in a new tab]](https://chemrxiv.org/engage/chemrxiv/contact-information?show=faqs).\n&#8203;\n300 words allowed\nYou can enter up to 300 words.Post comment\nLog in or register with\nORCID to comment\nComments are not moderated before they are posted, but they can be removed\nby the site moderators if they are found to be in contravention of our[Commenting Policy[opens in a new tab]](https://chemrxiv.org/engage/chemrxiv/about-information?show=commenting-policy)- please read this policy before you post. Comments should be used for\nscholarly discussion of the content in question. You can[find more information about how to use the commenting feature here[opens in a new tab]](https://chemrxiv.org/engage/chemrxiv/contact-information?show=faqs).\nThis site is protected by reCAPTCHA and the Google[Privacy Policy[opens in a new tab]](https://policies.google.com/privacy)and[Terms of Service[opens in a new tab]](https://policies.google.com/terms)apply.\n## Version History\nNov 26, 2020 Version 1\n## Version Notes\nAccepted to NeurIPS 2020 Machine Learning for Molecules workshop.\n## Metrics\n15,686\n2,814\n22\nViews\nDownloads\nView article\nCitations\n## License\n![CC logo](https://chemrxiv.org/engage/_nuxt/img/cc.e3defa7.svg)\nCC\n![BY logo](https://chemrxiv.org/engage/_nuxt/img/by.7813b57.svg)\nBY\n![NC logo](https://chemrxiv.org/engage/_nuxt/img/nc.e378f90.svg)\nNC\n![ND logo](https://chemrxiv.org/engage/_nuxt/img/nd.7966b83.svg)\nND\nThe content is available under[CC BY NC ND 4.0[opens in a new tab]](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n## DOI\n[\n10.26434/chemrxiv.13286741.v1\nD O I: 10.26434/chemrxiv.13286741.v1 [opens in a new tab]](https://doi.org/10.26434/chemrxiv.13286741.v1)\n## Author\u2019s competing interest statement\nNo conflict of interest.\n## Share",
      "url": "https://chemrxiv.org/engage/chemrxiv/article-details/60c75258702a9b726c18c101"
    },
    {
      "title": "Enhancing Generic Reaction Yield Prediction through Reaction Condition-Based Contrastive Learning - PubMed",
      "text": "Clipboard, Search History, and several other advanced features are temporarily unavailable.\n\n [Skip to main page content](https://pubmed.ncbi.nlm.nih.gov/pubmed.ncbi.nlm.nih.gov#article-details)\n\n**The .gov means it\u2019s official.**\nFederal government websites often end in .gov or .mil. Before\nsharing sensitive information, make sure you\u2019re on a federal\ngovernment site.\n\n**The site is secure.**\nThe **https://** ensures that you are connecting to the\nofficial website and that any information you provide is encrypted\nand transmitted securely.\n\n[Access keys](https://www.ncbi.nlm.nih.gov/guide/browsers/#ncbi_accesskeys) [NCBI Homepage](https://www.ncbi.nlm.nih.gov) [MyNCBI Homepage](https://pubmed.ncbi.nlm.nih.gov/myncbi/) [Main Content](https://pubmed.ncbi.nlm.nih.gov/pubmed.ncbi.nlm.nih.gov#maincontent) [Main Navigation](https://pubmed.ncbi.nlm.nih.gov/pubmed.ncbi.nlm.nih.gov)\n\nSearch:\nSearch\n\n[Advanced](https://pubmed.ncbi.nlm.nih.gov/advanced/) [Clipboard](https://pubmed.ncbi.nlm.nih.gov/clipboard/)\n\n[User Guide](https://pubmed.ncbi.nlm.nih.gov/help/)\n\nSave\n\nEmail\n\nSend to\n\n- [Clipboard](https://pubmed.ncbi.nlm.nih.gov/pubmed.ncbi.nlm.nih.gov)\n- [My Bibliography](https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpubmed.ncbi.nlm.nih.gov%2F38213662%2F%23open-bibliography-panel)\n- [Collections](https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpubmed.ncbi.nlm.nih.gov%2F38213662%2F%23open-collections-panel)\n- [Citation manager](https://pubmed.ncbi.nlm.nih.gov/pubmed.ncbi.nlm.nih.gov)\n\nDisplay options\n\nDisplay options\n\nFormat\nAbstractPubMedPMID\n\n## Save citation to file\n\nFormat:\nSummary (text)PubMedPMIDAbstract (text)CSV\n\nCreate file\n\nCancel\n\n## Email citation\n\nEmail address has not been verified. Go to\n[My NCBI account settings](https://account.ncbi.nlm.nih.gov/settings/) to confirm your email and then refresh this page.\n\nTo:\n\nSubject:\n\nBody:\n\nFormat:\nSummarySummary (text)AbstractAbstract (text)\n\nMeSH and other data\n\nSend email\n\nCancel\n\n### Add to Collections\n\n- Create a new collection\n- Add to an existing collection\n\nName your collection:\n\nName must be less than 100 characters\n\nChoose a collection:\n\nUnable to load your collection due to an error\n[Please try again](https://pubmed.ncbi.nlm.nih.gov/pubmed.ncbi.nlm.nih.gov)\n\nAdd\n\nCancel\n\n### Add to My Bibliography\n\n- My Bibliography\n\nUnable to load your delegates due to an error\n[Please try again](https://pubmed.ncbi.nlm.nih.gov/pubmed.ncbi.nlm.nih.gov)\n\nAdd\n\nCancel\n\n## Your saved search\n\nName of saved search:\n\nSearch terms:\n\n[Test search terms](https://pubmed.ncbi.nlm.nih.gov/pubmed.ncbi.nlm.nih.gov)\n\nWould you like email updates of new search results?Saved Search Alert Radio Buttons\n\n- Yes\n- No\n\nEmail:\n( [change](https://www.ncbi.nlm.nih.gov/account/settings/))\n\nFrequency:\nMonthlyWeeklyDaily\n\nWhich day?\nThe first SundayThe first MondayThe first TuesdayThe first WednesdayThe first ThursdayThe first FridayThe first SaturdayThe first dayThe first weekday\n\nWhich day?\nSundayMondayTuesdayWednesdayThursdayFridaySaturday\n\nReport format:\nSummarySummary (text)AbstractAbstract (text)PubMed\n\nSend at most:\n1 item5 items10 items20 items50 items100 items200 items\n\nSend even when there aren't any new results\n\nOptional text in email:\n\nSave\n\nCancel\n\n## Create a file for external citation management software\n\nCreate file\n\nCancel\n\n## Your RSS Feed\n\nName of RSS Feed:\n\nNumber of items displayed:\n510152050100\n\nCreate RSS\n\nCancel\n\nRSS Link\nCopy\n\nFull text links\nCite\n\nDisplay options\n\nDisplay options\n\nFormat\nAbstractPubMedPMID\n\n## Abstract\n\nDeep learning (DL)-driven efficient synthesis planning may profoundly transform the paradigm for designing novel pharmaceuticals and materials. However, the progress of many DL-assisted synthesis planning (DASP) algorithms has suffered from the lack of reliable automated pathway evaluation tools. As a critical metric for evaluating chemical reactions, accurate prediction of reaction yields helps improve the practicality of DASP algorithms in the real-world scenarios. Currently, accurately predicting yields of interesting reactions still faces numerous challenges, mainly including the absence of high-quality generic reaction yield datasets and robust generic yield predictors. To compensate for the limitations of high-throughput yield datasets, we curated a generic reaction yield dataset containing 12 reaction categories and rich reaction condition information. Subsequently, by utilizing 2 pretraining tasks based on chemical reaction masked language modeling and contrastive learning, we proposed a powerful bidirectional encoder representations from transformers (BERT)-based reaction yield predictor named Egret. It achieved comparable or even superior performance to the best previous models on 4 benchmark datasets and established state-of-the-art performance on the newly curated dataset. We found that reaction-condition-based contrastive learning enhances the model's sensitivity to reaction conditions, and Egret is capable of capturing subtle differences between reactions involving identical reactants and products but different reaction conditions. Furthermore, we proposed a new scoring function that incorporated Egret into the evaluation of multistep synthesis routes. Test results showed that yield-incorporated scoring facilitated the prioritization of literature-supported high-yield reaction pathways for target molecules. In addition, through meta-learning strategy, we further improved the reliability of the model's prediction for reaction types with limited data and lower data quality. Our results suggest that Egret holds the potential to become an essential component of the next-generation DASP tools.\n\nCopyright \u00a9 2024 Xiaodan Yin et\u00a0al.\n\n[PubMed Disclaimer](https://pubmed.ncbi.nlm.nih.gov/disclaimer/)\n\n## Conflict of interest statement\n\nCompeting interests: The authors declare that they have no competing interests.\n\n## Figures\n\n**Fig. 1.**\n\nOverall reaction and variables for\u2026\n\n**Fig. 1.**\n\nOverall reaction and variables for the Buchwald\u2013Hartwig (B-H) (A), Suzuki\u2013Miyaura (B), and Reaxys-MultiCondi-Yield\u2026\n\n**Fig.\u00a01.**\n\nOverall reaction and variables for the Buchwald\u2013Hartwig (B-H) (A), Suzuki\u2013Miyaura (B), and Reaxys-MultiCondi-Yield (C) datasets.\n\n**Fig. 2.**\n\nOverview of Egret. (A) Pretraining\u2026\n\n**Fig. 2.**\n\nOverview of Egret. (A) Pretraining task 1: MLM task; (B) pretraining task 2:\u2026\n\n**Fig.\u00a02.**\n\nOverview of Egret. (A) Pretraining task 1: MLM task; (B) pretraining task 2: reaction-condition-based contrastive learning task.\n\n**Fig. 3.**\n\nVisualization of the Egret model\u2026\n\n**Fig. 3.**\n\nVisualization of the Egret model performance based on modeling strategies. (A) Reaction category\u2026\n\n**Fig.\u00a03.**\n\nVisualization of the Egret model performance based on modeling strategies. (A) Reaction category composition of the Reaxys-MultiCondi-Yield dataset; (B) prediction performance on the Reaxys-MultiCondi-Yield dataset.\n\n**Fig. 4.**\n\nRegression plots of the Buchwald\u2013Hartwig\u2026\n\n**Fig. 4.**\n\nRegression plots of the Buchwald\u2013Hartwig dataset using 11 different data partitioning methods. (A\u2026\n\n**Fig.\u00a04.**\n\nRegression plots of the Buchwald\u2013Hartwig dataset using 11 different data partitioning methods. (A to G) Seven splits with training set proportions ranging from 2.5% to 70%; (I to L) 4 out-of-sample test splits.\n\n**Fig. 5.**\n\nVisualization of the effects of\u2026\n\n**Fig. 5.**\n\nVisualization of the effects of the reaction-condition-based comparative learning task.\n\n**Fig.\u00a05.**\n\nVisualization of the effects of the reaction-condition-based comparative learning task.\n\n**Fig. 6.**\n\nWorkflow of the multistep retrosynthetic\u2026\n\n**Fig. 6.**\n\nWorkflow of the multistep retrosynthetic pipeline embedded with MC-Egret. (A) Single-step route prediction;\u2026\n\n**Fig.\u00a06.**\n\nWorkflow of the multistep retrosynthetic pipeline embedded with MC-Egret. (A) Single-step route prediction; (B) single-step reaction condition prediction; (C) single-step reaction yield prediction.\n\n**Fig. 7.**\n\nThe optimal synthesis routes for\u2026\n\n**Fig. 7....",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38213662"
    },
    {
      "title": "Bayesian chemical reaction neural network for autonomous kinetic uncertainty quantification",
      "text": "<div><div><p><span></span></p><div><p><span>Received \n 30th October 2022\n </span><span>, Accepted 11th January 2023</span></p><p>First published on 12th January 2023</p><hr/><div><h2>Abstract</h2><p>Chemical reaction neural network (CRNN), a recently developed tool for autonomous discovery of reaction models, has been successfully demonstrated on a variety of chemical engineering and biochemical systems. It leverages the extraordinary data-fitting capacity of modern deep neural networks (DNNs) while preserving high interpretability and robustness by embedding widely applicable physical laws such as the law of mass action and the Arrhenius law. In this paper, we further developed Bayesian CRNN to not only reconstruct but also quantify the uncertainty of chemical kinetic models from data. Two methods, the Markov chain Monte Carlo algorithm and variational inference, were used to perform the Bayesian CRNN, with the latter mainly adopted for its speed. We demonstrated the capability of Bayesian CRNN in the kinetic uncertainty quantification of different types of chemical systems and discussed the importance of embedding physical laws in data-driven modeling. Finally, we discussed the adaptation of Bayesian CRNN for incomplete measurements and model mixing for global uncertainty quantification.</p></div><hr/>\n \n \n <h2><span>1 Introduction</span></h2>\n <p><span>Chemical kinetic modeling plays an important role in the design and analysis of chemical processes, such as combustion,<a href=\"#cit1\"><sup><span>1</span></sup></a> pyrolysis,<a href=\"#cit2\"><sup><span>2</span></sup></a> and air pollution.<a href=\"#cit3\"><sup><span>3</span></sup></a> Numerical simulations based on accurate chemical kinetic models could replace a large number of experiments in prototyping, hence reducing the cost of product development.<a href=\"#cit4\"><sup><span>4</span></sup></a> It can also be used to aid in the discovery of new scientific laws and rules.<a href=\"#cit1\"><sup><span>1</span></sup></a> In all these applications, the predictability of numerical simulation largely depends on a reliable chemical kinetic model.</span></p><p>Traditional methods for chemical model construction are based on either expert knowledge or first-principle quantum chemistry calculations.<a href=\"#cit5\"><sup><span>5</span></sup></a> However, complex chemical systems can involve hundreds or even thousands of species, leading to even more potential reaction pathways.<a href=\"#cit6\"><sup><span>6</span></sup></a> Consequently, prior expert knowledge is limited and first-principle simulation is computationally intractable, making the construction of chemical reaction models challenging. On the other hand, the development of diagnostics facilitates the generation of various measurements,<a href=\"#cit7\"><sup><span>7</span></sup></a> which lays the foundation for using data-driven approaches as a new paradigm for kinetic model construction.<a href=\"#cit8\"><sup><span>8\u201310</span></sup></a></p>\n <p>Deterministic<a href=\"#cit11\"><sup><span>11</span></sup></a> and probabilistic<a href=\"#cit12\"><sup><span>12\u201314</span></sup></a> data-driven tools have been developed to infer the reaction rate constants from experimental data based on reaction template, the generation of which still relies on expert knowledge. Previously, symbolic and sparse regression have been utilized to determine the reaction pathways,<a href=\"#cit15\"><sup><span>15,16</span></sup></a> but these techniques are limited to simple systems due to difficulties related to handling high-dimensional problems. In recent years, neural networks have shown amazing performance in high-dimensional tasks such as image classification<a href=\"#cit17\"><sup><span>17</span></sup></a> and natural language processing.<a href=\"#cit18\"><sup><span>18</span></sup></a> Therefore, it feels natural to use neural networks as a black box to represent kinetic models.<a href=\"#cit19\"><sup><span>19</span></sup></a> However, the lack of physical interpretability, and thus generalizability, limit the usage of such models.</p>\n <p>Chemical reaction neural network<a href=\"#cit20\"><sup><span>20</span></sup></a> (CRNN) was introduced for autonomous and simultaneous determination of reaction pathways and chemical kinetic parameters from the time histories of species concentration. Physical laws, such as the law of mass action and the Arrhenius law, are hard-encoded in the architecture of CRNN to improve its generalizability. In this way, the weights and biases of the NN can be interpreted as stoichiometry coefficients and rate constants of the reactions, making the model fully interpretable and transparent to users. The applicability and robustness of CRNN have been tested on a wide variety of cases.<a href=\"#cit20\"><sup><span>20,21</span></sup></a></p>\n <p>Uncertainty quantification (UQ) of a constructed chemical reaction model is crucial for further reliable application of the model.<a href=\"#cit22\"><sup><span>22,23</span></sup></a> The importance of UQ is two-fold: the uncertainty of identified parameters would inform the direction of future experiments; the uncertainty of species profiles simulated by the constructed model would provide confidence for predictions. Many methods have been developed for the inverse UQ of kinetic models<a href=\"#cit11\"><sup><span>11\u201314</span></sup></a> under the framework of traditional mechanism construction methods,<a href=\"#cit24\"><sup><span>24\u201326</span></sup></a> as well as for the forward UQ of predictions.<a href=\"#cit27\"><sup><span>27,28</span></sup></a> However, these methods again rely on either expert knowledge or computationally expensive first-principle calculations.</p>\n <p>In this paper, we will extend the capability of the proposed CRNN<a href=\"#cit20\"><sup><span>20,21</span></sup></a> with uncertainty quantification by Bayesian inference, resulting in the Bayesian chemical reaction neural networks (B-CRNN). B-CRNN will not only allow autonomous reaction pathway discovery but also the uncertainty quantification of the associated stoichiometric coefficients and chemical kinetic parameters. We will introduce the efficient implementation algorithm, Bayes by Backprop, and demonstrate both the inverse and predictive UQ on a variety of reaction systems including a temperature-dependent mechanism, reversible system, and catalytic system. We will also demonstrate how B-CRNN is different from a pure data-fitting tool, how B-CRNN can be useful in incomplete information scenarios, and how to comprehensively incorporate the influence of different but viable kinetic models.</p>\n \n \n \n <h2><span>2 Bayesian chemical reaction neural networks</span></h2>\n <p><span>In this section, we will first briefly review the deterministic version of the CRNN,<a href=\"#cit20\"><sup><span>20</span></sup></a> and then introduce two methods to perform uncertainty quantification of the CRNN results, <span>i.e.</span>, the Bayesian CRNN.</span></p><h3><span>2.1 Chemical reaction neural network</span></h3>\n <p><span>First, we consider an elementary reaction involving four species A, B, C, D, with stoichiometric coefficients <span>v</span><small><sub>A</sub></small>, <span>v</span><small><sub>B</sub></small>, <span>v</span><small><sub>C</sub></small>, <span>v</span><small><sub>D</sub></small><table><tbody><tr><td>\u00a0</td></tr><tr><td><span><span><span>v</span><small><sub>A</sub></small><span>A</span> + <span>v</span><small><sub>B</sub></small><span>B</span> \u2192 <span>v</span><small><sub>C</sub></small><span>C</span> + <span>v</span><small><sub>D</sub></small><span>D</span>.</span></span></td><td>(1)</td></tr></tbody></table>With the law of mass action, the reaction rate <span>r</span> of <a href=\"#eqn1\">eqn (1)</a> can be expressed as<table><tbody><tr><td>\u00a0</td></tr><tr><td><span><a href=\"https://pubs.rsc.org/image/article/2023/CP/d2cp05083h/d2cp05083h-t1_hi-res.gif\"></a></span></td><td>(2)</td></tr></tbody></table>where <span>k</span> is the rate constant, and [<span>A</span>...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2023/cp/d2cp05083h"
    },
    {
      "title": "\ud835\uddc5\ud835\uddc8\ud835\uddc0 \u2062 - \u2062 \ud835\uddb1\ud835\uddb1\ud835\udda8\ud835\uddac \ud835\uddc5\ud835\uddc8\ud835\uddc0 - \ud835\uddb1\ud835\uddb1\ud835\udda8\ud835\uddac \\mathop{\\mathsf{log\\text{-}RRIM}}\\limits sansserif_log - sansserif_RRIM : Yield Prediction via Local-to-global Reaction Representation Learning and Interaction Modeling",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/html/2411.03320v3"
    },
    {
      "title": "Challenging reaction prediction models to generalize to novel chemistry",
      "text": "# Challenging reaction prediction models to generalize to novel chemistry\n\nJohn Bradshaw\u2020\u2020\\\\dagger\u2020\n\nAnji Zhang\u2020\u2020\\\\dagger\u2020\n\nBabak Mahjour\u2020\u2020\\\\dagger\u2020\n\nDavid E. Graff\u266f\u266f\\\\sharp\u266f\u2020\u2020\\\\dagger\u2020\n\nMarwin H.S. Segler\u00a7\u00a7\\\\mathsection\u00a7\n\nConnor W. Coley\u2020\u2020\\\\dagger\u2020\u2021\u2021\\\\ddagger\u2021\u2020\u2020\\\\dagger\u2020 Department of Chemical Engineering, Massachusetts Institute of Technology ({jbrad, anji\\_z, bmahjour, ccoley}@mit.edu);\n\u266f\u266f\\\\sharp\u266f Department of Chemistry and Chemical Biology, Harvard University (deg711@g.harvard.edu);\n\u00a7\u00a7\\\\mathsection\u00a7 Microsoft Research AI for Science;\n\u2021\u2021\\\\ddagger\u2021 Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology.\n\n###### Abstract\n\nDeep learning models for anticipating the products of organic reactions have found many use\ncases, including validating retrosynthetic pathways and constraining synthesis-based molecular design tools.\nDespite compelling performance on popular benchmark tasks, strange and erroneous predictions sometimes ensue when using these models in practice.\nThe core issue is that common\nbenchmarks test models in an _in-distribution_ setting, whereas many real-world uses for these models are\nin _out-of-distribution_ settings and require a greater degree of extrapolation.\nTo better understand how current reaction predictors work in out-of-distribution domains, we report a\nseries of more challenging evaluations of a prototypical SMILES-based deep learning model.\nFirst, we illustrate how performance on randomly sampled datasets is overly optimistic compared to performance when generalizing to new patents or new authors.\nSecond, we conduct time splits that evaluate how models perform when tested on reactions published in years after those in their training set, mimicking real-world deployment.\nFinally, we consider extrapolation across reaction classes to reflect what would be required for the discovery of novel reaction types.\nThis panel of tasks can reveal the capabilities and limitations of today\u2019s reaction predictors, acting as\na crucial first step in the\ndevelopment of tomorrow\u2019s next-generation models capable of reaction discovery.\n\n## 1 Introduction\n\nReaction prediction\u2014the task of anticipating in silico the products of a chemical reaction given the reactants (Fig.\u00a0[1](https://arxiv.org/html/2501.06669v1#S1.F1); \\[ [90](https://arxiv.org/html/2501.06669v1#bib.bib90), [22](https://arxiv.org/html/2501.06669v1#bib.bib22), [65](https://arxiv.org/html/2501.06669v1#bib.bib65), [84](https://arxiv.org/html/2501.06669v1#bib.bib84)\\])\u2014is a crucial technology in (a) the validation of retrosynthetic pathways \\[ [2](https://arxiv.org/html/2501.06669v1#bib.bib2), [66](https://arxiv.org/html/2501.06669v1#bib.bib66), [97](https://arxiv.org/html/2501.06669v1#bib.bib97), [32](https://arxiv.org/html/2501.06669v1#bib.bib32)\\], (b) as a component of synthesis-based de novo design algorithms \\[ [18](https://arxiv.org/html/2501.06669v1#bib.bib18), [8](https://arxiv.org/html/2501.06669v1#bib.bib8), [12](https://arxiv.org/html/2501.06669v1#bib.bib12), [86](https://arxiv.org/html/2501.06669v1#bib.bib86), [38](https://arxiv.org/html/2501.06669v1#bib.bib38), [23](https://arxiv.org/html/2501.06669v1#bib.bib23), [29](https://arxiv.org/html/2501.06669v1#bib.bib29), [77](https://arxiv.org/html/2501.06669v1#bib.bib77), [7](https://arxiv.org/html/2501.06669v1#bib.bib7), [87](https://arxiv.org/html/2501.06669v1#bib.bib87)\\], and potentially (c) for the discovery of new reactions \\[ [5](https://arxiv.org/html/2501.06669v1#bib.bib5), [28](https://arxiv.org/html/2501.06669v1#bib.bib28), [68](https://arxiv.org/html/2501.06669v1#bib.bib68), [89](https://arxiv.org/html/2501.06669v1#bib.bib89), [48](https://arxiv.org/html/2501.06669v1#bib.bib48)\\].\nEncouragingly, there has been a burst of recent works developing a variety of machine learning\u2013based reaction predictors that achieve very high accuracies on common benchmark tasks \\[ [65](https://arxiv.org/html/2501.06669v1#bib.bib65), [14](https://arxiv.org/html/2501.06669v1#bib.bib14), [33](https://arxiv.org/html/2501.06669v1#bib.bib33), [61](https://arxiv.org/html/2501.06669v1#bib.bib61), [4](https://arxiv.org/html/2501.06669v1#bib.bib4), [83](https://arxiv.org/html/2501.06669v1#bib.bib83), [6](https://arxiv.org/html/2501.06669v1#bib.bib6), [91](https://arxiv.org/html/2501.06669v1#bib.bib91), [31](https://arxiv.org/html/2501.06669v1#bib.bib31), [15](https://arxiv.org/html/2501.06669v1#bib.bib15), [50](https://arxiv.org/html/2501.06669v1#bib.bib50), [79](https://arxiv.org/html/2501.06669v1#bib.bib79), [16](https://arxiv.org/html/2501.06669v1#bib.bib16), [35](https://arxiv.org/html/2501.06669v1#bib.bib35)\\].\nWith the best of these models matching or outperforming human chemists (see, e.g., \\[ [33](https://arxiv.org/html/2501.06669v1#bib.bib33), \u00a74.2\\]) and reporting top-5 accuracies above 95% (meaning that the correct answer is found in the top five predictions of the model over 95% of the time; see, e.g., \\[ [79](https://arxiv.org/html/2501.06669v1#bib.bib79), p.9\\]), performance seems to have saturated. Distinguishing best-performing models has become challenging. It is also natural to wonder if the task of reaction prediction has been \u201csolved\u201d to a meaningful degree.\n\nWhen using these models in practice, it quickly becomes apparent that the answer is a resounding no.\nIn fact, when using reaction predictors in new domains, not only might a model make an incorrect prediction, it might hallucinate a product preposterous to a human chemist.\nThe discrepancy between the reported performance on benchmarks with the subjective performance that can be seen in practice can be explained by the setting in which the model is evaluated.\nBenchmark tasks (such as USPTO\\_Stereo, USPTO\\_MIT, Pistachio, etc. \\[ [47](https://arxiv.org/html/2501.06669v1#bib.bib47), [64](https://arxiv.org/html/2501.06669v1#bib.bib64), [33](https://arxiv.org/html/2501.06669v1#bib.bib33), [49](https://arxiv.org/html/2501.06669v1#bib.bib49)\\]) evaluate models on in-distribution (ID) data, where the reactions in the test set come from the same distribution as that used to train the model, for example, using a random partition of a reaction dataset.\nHowever, in practice we often want to evaluate a model on out-of-distribution (OOD) data, meaning the test reactions are sampled from a different distribution than that used to train the model (Fig.\u00a0[1](https://arxiv.org/html/2501.06669v1#S1.F1)). In fact, using these models for reaction discovery is by definition an out-of-distribution task.\n\nThe unrealistic nature of current evaluations not only robs us of a sense of how existing methods perform, but it does so in such a way that overstates performance, stymieing analysis of where methods fall short and how to improve them.\nTo address this, we reassess what it means to evaluate a reaction predictor. We discuss and develop new tasks to test how well reaction predictors can do in different out-of-distribution domains, investigating when and how they are able to generalize and extrapolate in such settings.\nConcretely, we seek to answer the following questions:\n\n1. 1.\n\n\nHow over-optimistic are the random splits that are currently the most popular style of split for this task, and what is a more realistic evaluation of a reaction predictor\u2019s performance?\n\n2. 2.\n\n\nIf we want to use reaction predictors trained today on future datasets, how should we design benchmarks to test models prospectively?\n\n3. 3.\n\n\nWhen, and under what circumstances, might reaction predictors be able to discover new reactions?\n\n\n{subcaptiongroup}\\\\phantomcaption\n\n\\\\phantomcaption\n\nFigure 1: [1](https://arxiv.org/html/2501.06669v1#S1.F1)\nReaction prediction, in the context of this manuscript, is the task of predicting the major product(s) of a reaction given the reactants.\n(Note that by \u201creaction\u201d we mean specific reported reaction examples, rather than generic reaction \u201ctypes\u201d or \u201cclasses\u201d that cover a large group of related specific examples\u2014we will come back to the conc...",
      "url": "https://arxiv.org/html/2501.06669v1"
    },
    {
      "title": "",
      "text": "# Computer Science > Machine Learning\n\n**arXiv:2501.06669** (cs)\n\n\\[Submitted on 11 Jan 2025\\]\n\n# Title:Challenging reaction prediction models to generalize to novel chemistry\n\nAuthors: [John Bradshaw](https://arxiv.org/search/cs?searchtype=author&query=Bradshaw,+J), [Anji Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+A), [Babak Mahjour](https://arxiv.org/search/cs?searchtype=author&query=Mahjour,+B), [David E. Graff](https://arxiv.org/search/cs?searchtype=author&query=Graff,+D+E), [Marwin H.S. Segler](https://arxiv.org/search/cs?searchtype=author&query=Segler,+M+H), [Connor W. Coley](https://arxiv.org/search/cs?searchtype=author&query=Coley,+C+W)\n\nView a PDF of the paper titled Challenging reaction prediction models to generalize to novel chemistry, by John Bradshaw and 5 other authors\n\n[View PDF](https://arxiv.org/pdf/2501.06669) [HTML (experimental)](https://arxiv.org/html/2501.06669v1)\n\n> Abstract:Deep learning models for anticipating the products of organic reactions have found many use cases, including validating retrosynthetic pathways and constraining synthesis-based molecular design tools. Despite compelling performance on popular benchmark tasks, strange and erroneous predictions sometimes ensue when using these models in practice. The core issue is that common benchmarks test models in an in-distribution setting, whereas many real-world uses for these models are in out-of-distribution settings and require a greater degree of extrapolation. To better understand how current reaction predictors work in out-of-distribution domains, we report a series of more challenging evaluations of a prototypical SMILES-based deep learning model. First, we illustrate how performance on randomly sampled datasets is overly optimistic compared to performance when generalizing to new patents or new authors. Second, we conduct time splits that evaluate how models perform when tested on reactions published in years after those in their training set, mimicking real-world deployment. Finally, we consider extrapolation across reaction classes to reflect what would be required for the discovery of novel reaction types. This panel of tasks can reveal the capabilities and limitations of today's reaction predictors, acting as a crucial first step in the development of tomorrow's next-generation models capable of reaction discovery.\n\n|     |     |\n| --- | --- |\n| Subjects: | Machine Learning (cs.LG); Chemical Physics (physics.chem-ph) |\n| Cite as: | [arXiv:2501.06669](https://arxiv.org/abs/2501.06669) \\[cs.LG\\] |\n| (or [arXiv:2501.06669v1](https://arxiv.org/abs/2501.06669v1) \\[cs.LG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2501.06669](https://doi.org/10.48550/arXiv.2501.06669) <br>Focus to learn more<br>arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: John Bradshaw \\[ [view email](https://arxiv.org/show-email/47bd441c/2501.06669)\\] **\\[v1\\]**\nSat, 11 Jan 2025 23:49:14 UTC (2,297 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Challenging reaction prediction models to generalize to novel chemistry, by John Bradshaw and 5 other authors\n\n- [View PDF](https://arxiv.org/pdf/2501.06669)\n- [HTML (experimental)](https://arxiv.org/html/2501.06669v1)\n- [TeX Source](https://arxiv.org/src/2501.06669)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2501.06669&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2501.06669&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2025-01](https://arxiv.org/list/cs.LG/2025-01)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2501.06669?context=cs) [physics](https://arxiv.org/abs/2501.06669?context=physics) [physics.chem-ph](https://arxiv.org/abs/2501.06669?context=physics.chem-ph)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2501.06669)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2501.06669)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2501.06669)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2501.06669) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2501.06669"
    }
  ]
}