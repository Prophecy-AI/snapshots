{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24719cb4",
   "metadata": {},
   "source": [
    "# Loop 34 Analysis: Understanding the CV-LB Gap\n",
    "\n",
    "**Current State:**\n",
    "- Best CV: 0.008465 (exp_026)\n",
    "- Best LB: 0.0887 (exp_026)\n",
    "- Target: 0.0347\n",
    "- CV-LB Gap: ~10.5x\n",
    "\n",
    "**Key Question:** Why is there such a large gap? What can we do to reduce it?\n",
    "\n",
    "**Hypotheses to Test:**\n",
    "1. Distribution shift between train/test solvents\n",
    "2. Overfitting to specific solvents in CV\n",
    "3. The test set has fundamentally different characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64cae7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:38:09.995542Z",
     "iopub.status.busy": "2026-01-14T19:38:09.995002Z",
     "iopub.status.idle": "2026-01-14T19:38:10.609357Z",
     "shell.execute_reply": "2026-01-14T19:38:10.608982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Solvent Data:\n",
      "  Shape: (656, 13)\n",
      "  Solvents: 24\n",
      "  Samples per solvent: count    24.000000\n",
      "mean     27.333333\n",
      "std      13.528285\n",
      "min       5.000000\n",
      "25%      18.000000\n",
      "50%      22.000000\n",
      "75%      37.000000\n",
      "max      59.000000\n",
      "dtype: float64\n",
      "\n",
      "Full Data (Mixtures):\n",
      "  Shape: (1227, 19)\n",
      "  Unique ramps: 13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "# Load all data\n",
    "df_single = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "df_full = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "\n",
    "print('Single Solvent Data:')\n",
    "print(f'  Shape: {df_single.shape}')\n",
    "print(f'  Solvents: {df_single[\"SOLVENT NAME\"].nunique()}')\n",
    "print(f'  Samples per solvent: {df_single.groupby(\"SOLVENT NAME\").size().describe()}')\n",
    "\n",
    "print('\\nFull Data (Mixtures):')\n",
    "print(f'  Shape: {df_full.shape}')\n",
    "print(f'  Unique ramps: {df_full.groupby([\"SOLVENT A NAME\", \"SOLVENT B NAME\"]).ngroups}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a05888b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:38:10.610424Z",
     "iopub.status.busy": "2026-01-14T19:38:10.610327Z",
     "iopub.status.idle": "2026-01-14T19:38:10.614740Z",
     "shell.execute_reply": "2026-01-14T19:38:10.614387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Target Distribution Analysis ===\n",
      "\n",
      "Product 2:\n",
      "  Single: mean=0.1499, std=0.1431, min=0.0000, max=0.4636\n",
      "  Full:   mean=0.1646, std=0.1535, min=0.0000, max=0.4636\n",
      "\n",
      "Product 3:\n",
      "  Single: mean=0.1234, std=0.1315, min=0.0000, max=0.5338\n",
      "  Full:   mean=0.1437, std=0.1458, min=0.0000, max=0.5338\n",
      "\n",
      "SM:\n",
      "  Single: mean=0.5222, std=0.3602, min=0.0000, max=1.0000\n",
      "  Full:   mean=0.4952, std=0.3794, min=0.0000, max=1.0833\n"
     ]
    }
   ],
   "source": [
    "# Analyze target distributions\n",
    "print('=== Target Distribution Analysis ===')\n",
    "for col in ['Product 2', 'Product 3', 'SM']:\n",
    "    print(f'\\n{col}:')\n",
    "    print(f'  Single: mean={df_single[col].mean():.4f}, std={df_single[col].std():.4f}, min={df_single[col].min():.4f}, max={df_single[col].max():.4f}')\n",
    "    print(f'  Full:   mean={df_full[col].mean():.4f}, std={df_full[col].std():.4f}, min={df_full[col].min():.4f}, max={df_full[col].max():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e131fb45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:38:10.615756Z",
     "iopub.status.busy": "2026-01-14T19:38:10.615655Z",
     "iopub.status.idle": "2026-01-14T19:38:10.935016Z",
     "shell.execute_reply": "2026-01-14T19:38:10.934602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CV-LB Relationship ===\n",
      "Linear fit: LB = 4.25 * CV + 0.0530\n",
      "R² = 0.9622\n",
      "\n",
      "To hit target LB = 0.0347:\n",
      "  Required CV = (0.0347 - 0.0530) / 4.25 = -0.004308\n",
      "\n",
      "⚠️ WARNING: Linear extrapolation suggests target is unreachable!\n",
      "This means we need a FUNDAMENTALLY DIFFERENT approach, not incremental CV improvement.\n"
     ]
    }
   ],
   "source": [
    "# Analyze CV-LB relationship from submissions\n",
    "submissions = [\n",
    "    ('exp_000', 0.0111, 0.0982),\n",
    "    ('exp_001', 0.0123, 0.1065),\n",
    "    ('exp_003', 0.0105, 0.0972),\n",
    "    ('exp_005', 0.0104, 0.0969),\n",
    "    ('exp_006', 0.0097, 0.0946),\n",
    "    ('exp_007', 0.0093, 0.0932),\n",
    "    ('exp_009', 0.0092, 0.0936),\n",
    "    ('exp_012', 0.0090, 0.0913),\n",
    "    ('exp_024', 0.0087, 0.0893),\n",
    "    ('exp_026', 0.0085, 0.0887),\n",
    "]\n",
    "\n",
    "cv_scores = [s[1] for s in submissions]\n",
    "lb_scores = [s[2] for s in submissions]\n",
    "\n",
    "# Linear fit\n",
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_scores, lb_scores)\n",
    "\n",
    "print('=== CV-LB Relationship ===')\n",
    "print(f'Linear fit: LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nTo hit target LB = 0.0347:')\n",
    "print(f'  Required CV = (0.0347 - {intercept:.4f}) / {slope:.2f} = {(0.0347 - intercept) / slope:.6f}')\n",
    "\n",
    "# But this gives negative CV, which is impossible\n",
    "if (0.0347 - intercept) / slope < 0:\n",
    "    print('\\n⚠️ WARNING: Linear extrapolation suggests target is unreachable!')\n",
    "    print('This means we need a FUNDAMENTALLY DIFFERENT approach, not incremental CV improvement.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25342c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:38:10.936399Z",
     "iopub.status.busy": "2026-01-14T19:38:10.936217Z",
     "iopub.status.idle": "2026-01-14T19:38:10.939235Z",
     "shell.execute_reply": "2026-01-14T19:38:10.938896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNEXPLORED APPROACHES ===\n",
      "\n",
      "1. **Quantile Regression** - Predict median instead of mean\n",
      "   - Could reduce impact of outliers\n",
      "   - CatBoost supports this natively\n",
      "\n",
      "2. **Beta Regression** - Model yields as Beta distribution\n",
      "   - Natural for [0,1] bounded data\n",
      "   - Handles heteroscedasticity\n",
      "\n",
      "3. **Mixture of Experts** - Different models for different solvent types\n",
      "   - Alcohols vs Esters vs Others\n",
      "   - Could capture different kinetics\n",
      "\n",
      "4. **Feature Selection via Permutation Importance**\n",
      "   - Remove features that hurt generalization\n",
      "   - Focus on most robust features\n",
      "\n",
      "5. **Adversarial Validation**\n",
      "   - Identify which features cause train/test shift\n",
      "   - Remove or transform those features\n",
      "\n",
      "6. **Ensemble with Different Feature Sets**\n",
      "   - Model 1: Only Spange (13 features)\n",
      "   - Model 2: Only DRFP (122 features)\n",
      "   - Model 3: Only Kinetics (5 features)\n",
      "   - Blend predictions\n",
      "\n",
      "7. **Temperature/Time Stratified CV**\n",
      "   - Ensure CV folds have similar T/t distributions\n",
      "   - May reduce CV-LB gap\n",
      "\n",
      "8. **Pseudo-Labeling**\n",
      "   - Use model predictions on test set as soft labels\n",
      "   - Retrain with augmented data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('=== UNEXPLORED APPROACHES ===')\n",
    "print('''\n",
    "1. **Quantile Regression** - Predict median instead of mean\n",
    "   - Could reduce impact of outliers\n",
    "   - CatBoost supports this natively\n",
    "\n",
    "2. **Beta Regression** - Model yields as Beta distribution\n",
    "   - Natural for [0,1] bounded data\n",
    "   - Handles heteroscedasticity\n",
    "\n",
    "3. **Mixture of Experts** - Different models for different solvent types\n",
    "   - Alcohols vs Esters vs Others\n",
    "   - Could capture different kinetics\n",
    "\n",
    "4. **Feature Selection via Permutation Importance**\n",
    "   - Remove features that hurt generalization\n",
    "   - Focus on most robust features\n",
    "\n",
    "5. **Adversarial Validation**\n",
    "   - Identify which features cause train/test shift\n",
    "   - Remove or transform those features\n",
    "\n",
    "6. **Ensemble with Different Feature Sets**\n",
    "   - Model 1: Only Spange (13 features)\n",
    "   - Model 2: Only DRFP (122 features)\n",
    "   - Model 3: Only Kinetics (5 features)\n",
    "   - Blend predictions\n",
    "\n",
    "7. **Temperature/Time Stratified CV**\n",
    "   - Ensure CV folds have similar T/t distributions\n",
    "   - May reduce CV-LB gap\n",
    "\n",
    "8. **Pseudo-Labeling**\n",
    "   - Use model predictions on test set as soft labels\n",
    "   - Retrain with augmented data\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "404d9faf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:38:10.940089Z",
     "iopub.status.busy": "2026-01-14T19:38:10.939995Z",
     "iopub.status.idle": "2026-01-14T19:38:10.945014Z",
     "shell.execute_reply": "2026-01-14T19:38:10.944669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Solvent Analysis ===\n",
      "Solvents in Spange lookup: 26\n",
      "Solvents in single data: 24\n",
      "\n",
      "Solvents in single data:\n",
      "['1,1,1,3,3,3-Hexafluoropropan-2-ol', '2,2,2-Trifluoroethanol', '2-Methyltetrahydrofuran [2-MeTHF]', 'Acetonitrile', 'Acetonitrile.Acetic Acid', 'Butanone [MEK]', 'Cyclohexane', 'DMA [N,N-Dimethylacetamide]', 'Decanol', 'Diethyl Ether [Ether]', 'Dihydrolevoglucosenone (Cyrene)', 'Dimethyl Carbonate', 'Ethanol', 'Ethyl Acetate', 'Ethyl Lactate', 'Ethylene Glycol [1,2-Ethanediol]', 'IPA [Propan-2-ol]', 'MTBE [tert-Butylmethylether]', 'Methanol', 'Methyl Propionate', 'THF [Tetrahydrofuran]', 'Water.2,2,2-Trifluoroethanol', 'Water.Acetonitrile', 'tert-Butanol [2-Methylpropan-2-ol]']\n",
      "\n",
      "Solvents in Spange lookup:\n",
      "['1,1,1,3,3,3-Hexafluoropropan-2-ol', '2,2,2-Trifluoroethanol', '2-Methyltetrahydrofuran [2-MeTHF]', 'Acetic Acid', 'Acetonitrile', 'Acetonitrile.Acetic Acid', 'Butanone [MEK]', 'Cyclohexane', 'DMA [N,N-Dimethylacetamide]', 'Decanol', 'Diethyl Ether [Ether]', 'Dihydrolevoglucosenone (Cyrene)', 'Dimethyl Carbonate', 'Ethanol', 'Ethyl Acetate', 'Ethyl Lactate', 'Ethylene Glycol [1,2-Ethanediol]', 'IPA [Propan-2-ol]', 'MTBE [tert-Butylmethylether]', 'Methanol', 'Methyl Propionate', 'THF [Tetrahydrofuran]', 'Water', 'Water.2,2,2-Trifluoroethanol', 'Water.Acetonitrile', 'tert-Butanol [2-Methylpropan-2-ol]']\n"
     ]
    }
   ],
   "source": [
    "# Check if there's a pattern in which solvents are harder to predict\n",
    "# Load Spange descriptors\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "print('=== Solvent Analysis ===')\n",
    "print(f'Solvents in Spange lookup: {len(SPANGE_DF)}')\n",
    "print(f'Solvents in single data: {df_single[\"SOLVENT NAME\"].nunique()}')\n",
    "print(f'\\nSolvents in single data:')\n",
    "print(sorted(df_single['SOLVENT NAME'].unique()))\n",
    "print(f'\\nSolvents in Spange lookup:')\n",
    "print(sorted(SPANGE_DF.index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b53fc2d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:38:10.945980Z",
     "iopub.status.busy": "2026-01-14T19:38:10.945753Z",
     "iopub.status.idle": "2026-01-14T19:38:10.953895Z",
     "shell.execute_reply": "2026-01-14T19:38:10.953567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Per-Solvent Target Variance ===\n",
      "                                   Product 2         Product 3          \\\n",
      "                                        mean     std      mean     std   \n",
      "SOLVENT NAME                                                             \n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol     0.3197  0.0928    0.2854  0.0717   \n",
      "2,2,2-Trifluoroethanol                0.1568  0.0736    0.0500  0.0559   \n",
      "2-Methyltetrahydrofuran [2-MeTHF]     0.1506  0.1459    0.1006  0.0884   \n",
      "Acetonitrile                          0.1564  0.1476    0.0890  0.0902   \n",
      "Acetonitrile.Acetic Acid              0.0193  0.0113    0.0206  0.0080   \n",
      "Butanone [MEK]                        0.0472  0.0184    0.0430  0.0165   \n",
      "Cyclohexane                           0.0839  0.0893    0.0493  0.0500   \n",
      "DMA [N,N-Dimethylacetamide]           0.1171  0.1265    0.0976  0.1026   \n",
      "Decanol                               0.1948  0.1747    0.2080  0.1844   \n",
      "Diethyl Ether [Ether]                 0.0811  0.0966    0.0631  0.0715   \n",
      "Dihydrolevoglucosenone (Cyrene)       0.1690  0.0687    0.1408  0.0568   \n",
      "Dimethyl Carbonate                    0.0581  0.0197    0.0314  0.0106   \n",
      "Ethanol                               0.1419  0.1515    0.1533  0.1660   \n",
      "Ethyl Acetate                         0.0430  0.0142    0.0397  0.0134   \n",
      "Ethyl Lactate                         0.1275  0.0428    0.1367  0.0470   \n",
      "Ethylene Glycol [1,2-Ethanediol]      0.2757  0.1796    0.3229  0.2141   \n",
      "IPA [Propan-2-ol]                     0.2538  0.2195    0.2662  0.2280   \n",
      "MTBE [tert-Butylmethylether]          0.0441  0.0174    0.0357  0.0232   \n",
      "Methanol                              0.1698  0.1368    0.1485  0.1206   \n",
      "Methyl Propionate                     0.0261  0.0110    0.0193  0.0070   \n",
      "THF [Tetrahydrofuran]                 0.1203  0.1209    0.0863  0.0865   \n",
      "Water.2,2,2-Trifluoroethanol          0.2408  0.1278    0.2084  0.0835   \n",
      "Water.Acetonitrile                    0.3084  0.1708    0.2740  0.1531   \n",
      "tert-Butanol [2-Methylpropan-2-ol]    0.0723  0.0285    0.0653  0.0276   \n",
      "\n",
      "                                        SM          \n",
      "                                      mean     std  \n",
      "SOLVENT NAME                                        \n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol   0.1706  0.2434  \n",
      "2,2,2-Trifluoroethanol              0.2792  0.3432  \n",
      "2-Methyltetrahydrofuran [2-MeTHF]   0.5590  0.3257  \n",
      "Acetonitrile                        0.5805  0.3994  \n",
      "Acetonitrile.Acetic Acid            0.4781  0.4539  \n",
      "Butanone [MEK]                      0.7169  0.0537  \n",
      "Cyclohexane                         0.5458  0.2945  \n",
      "DMA [N,N-Dimethylacetamide]         0.5453  0.3964  \n",
      "Decanol                             0.4331  0.4313  \n",
      "Diethyl Ether [Ether]               0.8040  0.2165  \n",
      "Dihydrolevoglucosenone (Cyrene)     0.6233  0.1153  \n",
      "Dimethyl Carbonate                  0.8718  0.0454  \n",
      "Ethanol                             0.5045  0.3788  \n",
      "Ethyl Acetate                       0.6934  0.0557  \n",
      "Ethyl Lactate                       0.6590  0.0863  \n",
      "Ethylene Glycol [1,2-Ethanediol]    0.3804  0.3897  \n",
      "IPA [Propan-2-ol]                   0.4734  0.4526  \n",
      "MTBE [tert-Butylmethylether]        0.8793  0.0403  \n",
      "Methanol                            0.4247  0.3900  \n",
      "Methyl Propionate                   0.7189  0.0377  \n",
      "THF [Tetrahydrofuran]               0.5752  0.3404  \n",
      "Water.2,2,2-Trifluoroethanol        0.3351  0.3539  \n",
      "Water.Acetonitrile                  0.3167  0.3772  \n",
      "tert-Butanol [2-Methylpropan-2-ol]  0.6988  0.0678  \n"
     ]
    }
   ],
   "source": [
    "# Check the variance of targets per solvent\n",
    "print('=== Per-Solvent Target Variance ===')\n",
    "solvent_stats = df_single.groupby('SOLVENT NAME')[['Product 2', 'Product 3', 'SM']].agg(['mean', 'std'])\n",
    "print(solvent_stats.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab50cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:38:10.954730Z",
     "iopub.status.busy": "2026-01-14T19:38:10.954638Z",
     "iopub.status.idle": "2026-01-14T19:38:10.957031Z",
     "shell.execute_reply": "2026-01-14T19:38:10.956675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CRITICAL INSIGHT ===\n",
      "\n",
      "The CV-LB gap of ~10x is ABNORMAL.\n",
      "\n",
      "Our CV (LOO/LORO) should be pessimistic, not optimistic.\n",
      "Yet LB is 10x worse than CV.\n",
      "\n",
      "This suggests:\n",
      "1. The test set has FUNDAMENTALLY DIFFERENT characteristics\n",
      "2. OR our model is overfitting to training solvents in a way CV doesn't catch\n",
      "\n",
      "The linear fit shows:\n",
      "- LB = 4.22 * CV + 0.0533\n",
      "- Intercept = 0.0533 > Target = 0.0347\n",
      "\n",
      "This means even with PERFECT CV (0.0), we'd still get LB = 0.0533 > 0.0347!\n",
      "\n",
      "IMPLICATION: We need to REDUCE THE INTERCEPT, not just improve CV.\n",
      "The intercept represents the \"irreducible\" gap - likely due to distribution shift.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Key insight: The CV-LB gap is ~10x\n",
    "# This is NOT normal. Typical gaps are 1.1-1.5x\n",
    "# \n",
    "# Possible causes:\n",
    "# 1. Test set has solvents NOT in training (out-of-distribution)\n",
    "# 2. Test set has different T/t ranges\n",
    "# 3. Test set has different mixture compositions\n",
    "# 4. Our CV scheme is too optimistic (leakage?)\n",
    "\n",
    "print('=== CRITICAL INSIGHT ===')\n",
    "print('''\n",
    "The CV-LB gap of ~10x is ABNORMAL.\n",
    "\n",
    "Our CV (LOO/LORO) should be pessimistic, not optimistic.\n",
    "Yet LB is 10x worse than CV.\n",
    "\n",
    "This suggests:\n",
    "1. The test set has FUNDAMENTALLY DIFFERENT characteristics\n",
    "2. OR our model is overfitting to training solvents in a way CV doesn't catch\n",
    "\n",
    "The linear fit shows:\n",
    "- LB = 4.22 * CV + 0.0533\n",
    "- Intercept = 0.0533 > Target = 0.0347\n",
    "\n",
    "This means even with PERFECT CV (0.0), we'd still get LB = 0.0533 > 0.0347!\n",
    "\n",
    "IMPLICATION: We need to REDUCE THE INTERCEPT, not just improve CV.\n",
    "The intercept represents the \"irreducible\" gap - likely due to distribution shift.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a23f2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:38:10.957846Z",
     "iopub.status.busy": "2026-01-14T19:38:10.957747Z",
     "iopub.status.idle": "2026-01-14T19:38:10.960324Z",
     "shell.execute_reply": "2026-01-14T19:38:10.959985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STRATEGIES TO REDUCE CV-LB INTERCEPT ===\n",
      "\n",
      "1. **Simpler Models** - Less capacity = less overfitting to train distribution\n",
      "   - Already tried: [32,16] MLP is best\n",
      "   - Could try: Linear models with regularization\n",
      "\n",
      "2. **Feature Engineering for Robustness**\n",
      "   - Use only features that are stable across distributions\n",
      "   - Remove features that are highly correlated with specific solvents\n",
      "\n",
      "3. **Domain Adaptation**\n",
      "   - If we knew which solvents are in test, we could adapt\n",
      "   - Without that, use techniques like CORAL, MMD\n",
      "\n",
      "4. **Ensemble Diversity**\n",
      "   - Different models may have different biases\n",
      "   - Averaging could cancel out some bias\n",
      "\n",
      "5. **Calibration**\n",
      "   - Post-hoc calibration using validation set\n",
      "   - Platt scaling, isotonic regression\n",
      "\n",
      "6. **Conservative Predictions**\n",
      "   - Shrink predictions toward mean\n",
      "   - Reduces variance at cost of bias\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What could reduce the intercept?\n",
    "print('=== STRATEGIES TO REDUCE CV-LB INTERCEPT ===')\n",
    "print('''\n",
    "1. **Simpler Models** - Less capacity = less overfitting to train distribution\n",
    "   - Already tried: [32,16] MLP is best\n",
    "   - Could try: Linear models with regularization\n",
    "\n",
    "2. **Feature Engineering for Robustness**\n",
    "   - Use only features that are stable across distributions\n",
    "   - Remove features that are highly correlated with specific solvents\n",
    "\n",
    "3. **Domain Adaptation**\n",
    "   - If we knew which solvents are in test, we could adapt\n",
    "   - Without that, use techniques like CORAL, MMD\n",
    "\n",
    "4. **Ensemble Diversity**\n",
    "   - Different models may have different biases\n",
    "   - Averaging could cancel out some bias\n",
    "\n",
    "5. **Calibration**\n",
    "   - Post-hoc calibration using validation set\n",
    "   - Platt scaling, isotonic regression\n",
    "\n",
    "6. **Conservative Predictions**\n",
    "   - Shrink predictions toward mean\n",
    "   - Reduces variance at cost of bias\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f140d0d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:38:10.961106Z",
     "iopub.status.busy": "2026-01-14T19:38:10.961003Z",
     "iopub.status.idle": "2026-01-14T19:38:10.964178Z",
     "shell.execute_reply": "2026-01-14T19:38:10.963820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GAP TO TOP SOLUTION ===\n",
      "Our best LB: 0.0887\n",
      "Top LB: 0.0173\n",
      "Gap: 0.0714 (413.6% worse)\n",
      "\n",
      "To match top LB, we need to reduce error by 80.5%\n",
      "\n",
      "This is a MASSIVE gap. The top solution must have:\n",
      "  1. A fundamentally different approach\n",
      "  2. Domain knowledge we are missing\n",
      "  3. Better handling of distribution shift\n",
      "  4. Or access to information we don't have\n"
     ]
    }
   ],
   "source": [
    "# Let's check what the top LB score (0.01727) implies\n",
    "target_lb = 0.01727\n",
    "best_lb = 0.0887\n",
    "\n",
    "print('=== GAP TO TOP SOLUTION ===')\n",
    "print(f'Our best LB: {best_lb:.4f}')\n",
    "print(f'Top LB: {target_lb:.4f}')\n",
    "print(f'Gap: {best_lb - target_lb:.4f} ({(best_lb - target_lb) / target_lb * 100:.1f}% worse)')\n",
    "print(f'\\nTo match top LB, we need to reduce error by {(best_lb - target_lb) / best_lb * 100:.1f}%')\n",
    "print(f'\\nThis is a MASSIVE gap. The top solution must have:')\n",
    "print('  1. A fundamentally different approach')\n",
    "print('  2. Domain knowledge we are missing')\n",
    "print('  3. Better handling of distribution shift')\n",
    "print('  4. Or access to information we don\\'t have')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
