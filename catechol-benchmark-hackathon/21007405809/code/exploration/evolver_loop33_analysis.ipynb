{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ee40398",
   "metadata": {},
   "source": [
    "# Loop 33 Analysis: Strategy Review\n",
    "\n",
    "## Situation\n",
    "- Best CV: 0.008465 (exp_026)\n",
    "- Best LB: 0.0887 (exp_026)\n",
    "- Target: 0.0347\n",
    "- CV-LB gap: ~10.5x\n",
    "\n",
    "## Key Questions\n",
    "1. What's the CV-LB relationship across all submissions?\n",
    "2. What CV would we need to hit target 0.0347?\n",
    "3. What approaches haven't been tried?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c677b484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:45:20.252662Z",
     "iopub.status.busy": "2026-01-14T19:45:20.252136Z",
     "iopub.status.idle": "2026-01-14T19:45:21.114431Z",
     "shell.execute_reply": "2026-01-14T19:45:21.114057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Submission History ===\n",
      "    exp     cv     lb\n",
      "exp_000 0.0111 0.0982\n",
      "exp_001 0.0123 0.1065\n",
      "exp_003 0.0105 0.0972\n",
      "exp_005 0.0104 0.0969\n",
      "exp_006 0.0097 0.0946\n",
      "exp_007 0.0093 0.0932\n",
      "exp_009 0.0092 0.0936\n",
      "exp_012 0.0090 0.0913\n",
      "exp_024 0.0087 0.0893\n",
      "exp_026 0.0085 0.0887\n",
      "\n",
      "CV-LB ratio: 9.62x\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('=== Submission History ===')\n",
    "print(df.to_string(index=False))\n",
    "print(f'\\nCV-LB ratio: {df[\"lb\"].mean() / df[\"cv\"].mean():.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f0d36fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:45:21.115671Z",
     "iopub.status.busy": "2026-01-14T19:45:21.115526Z",
     "iopub.status.idle": "2026-01-14T19:45:21.119701Z",
     "shell.execute_reply": "2026-01-14T19:45:21.119376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CV-LB Linear Fit ===\n",
      "LB = 4.2497 * CV + 0.0530\n",
      "R-squared = 0.9622\n",
      "\n",
      "To hit target LB = 0.0347:\n",
      "Required CV = (0.0347 - 0.0530) / 4.2497 = -0.004308\n",
      "\n",
      "WARNING: Required CV is NEGATIVE!\n",
      "This means the intercept alone is already higher than target.\n",
      "The linear model predicts we CANNOT hit target with any CV improvement.\n",
      "\n",
      "This suggests we need a FUNDAMENTALLY DIFFERENT approach.\n"
     ]
    }
   ],
   "source": [
    "# Linear regression to understand CV-LB relationship\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "\n",
    "print(f'=== CV-LB Linear Fit ===')\n",
    "print(f'LB = {slope:.4f} * CV + {intercept:.4f}')\n",
    "print(f'R-squared = {r_value**2:.4f}')\n",
    "print(f'\\nTo hit target LB = 0.0347:')\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f'Required CV = (0.0347 - {intercept:.4f}) / {slope:.4f} = {required_cv:.6f}')\n",
    "\n",
    "if required_cv < 0:\n",
    "    print('\\nWARNING: Required CV is NEGATIVE!')\n",
    "    print('This means the intercept alone is already higher than target.')\n",
    "    print('The linear model predicts we CANNOT hit target with any CV improvement.')\n",
    "    print('\\nThis suggests we need a FUNDAMENTALLY DIFFERENT approach.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d51aebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:45:21.120514Z",
     "iopub.status.busy": "2026-01-14T19:45:21.120423Z",
     "iopub.status.idle": "2026-01-14T19:45:21.124619Z",
     "shell.execute_reply": "2026-01-14T19:45:21.124282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Experiment Summary (sorted by CV) ===\n",
      "exp_026: CV 0.008465 - Weighted Loss BEST\n",
      "exp_022: CV 0.008601 - ACS PCA Features \n",
      "exp_028: CV 0.008674 - Four-Model Ensemble \n",
      "exp_024: CV 0.008689 - ACS PCA Fixed \n",
      "exp_011: CV 0.008785 - Simple Ensemble \n",
      "exp_010: CV 0.008829 - Diverse Ensemble \n",
      "exp_012: CV 0.009004 - Compliant Ensemble \n",
      "exp_025: CV 0.009068 - Per-Target Models \n",
      "exp_027: CV 0.009150 - Simple Features \n",
      "exp_009: CV 0.009192 - Single Layer [16] \n",
      "exp_007: CV 0.009262 - Even Simpler [32,16] \n",
      "exp_006: CV 0.009749 - Simpler [64,32] \n",
      "exp_031: CV 0.009984 - CatBoost RFE \n",
      "exp_005: CV 0.010430 - Large Ensemble 15 \n",
      "exp_003: CV 0.010501 - Spange + DRFP \n",
      "exp_032: CV 0.010983 - CatBoost 18 Features \n",
      "exp_000: CV 0.011081 - MLP Baseline \n",
      "exp_008: CV 0.011509 - Ridge Regression \n",
      "exp_001: CV 0.012297 - LightGBM \n",
      "exp_029: CV 0.016180 - Normalization (FAILED) \n",
      "exp_002: CV 0.016948 - DRFP + PCA \n",
      "exp_030: CV 0.017057 - Gaussian Process (FAILED) \n",
      "exp_004: CV 0.051912 - Deep Residual (FAILED) \n"
     ]
    }
   ],
   "source": [
    "# What experiments have we tried?\n",
    "experiments = [\n",
    "    ('exp_000', 0.011081, 'MLP Baseline'),\n",
    "    ('exp_001', 0.012297, 'LightGBM'),\n",
    "    ('exp_002', 0.016948, 'DRFP + PCA'),\n",
    "    ('exp_003', 0.010501, 'Spange + DRFP'),\n",
    "    ('exp_004', 0.051912, 'Deep Residual (FAILED)'),\n",
    "    ('exp_005', 0.010430, 'Large Ensemble 15'),\n",
    "    ('exp_006', 0.009749, 'Simpler [64,32]'),\n",
    "    ('exp_007', 0.009262, 'Even Simpler [32,16]'),\n",
    "    ('exp_008', 0.011509, 'Ridge Regression'),\n",
    "    ('exp_009', 0.009192, 'Single Layer [16]'),\n",
    "    ('exp_010', 0.008829, 'Diverse Ensemble'),\n",
    "    ('exp_011', 0.008785, 'Simple Ensemble'),\n",
    "    ('exp_012', 0.009004, 'Compliant Ensemble'),\n",
    "    ('exp_022', 0.008601, 'ACS PCA Features'),\n",
    "    ('exp_024', 0.008689, 'ACS PCA Fixed'),\n",
    "    ('exp_025', 0.009068, 'Per-Target Models'),\n",
    "    ('exp_026', 0.008465, 'Weighted Loss'),\n",
    "    ('exp_027', 0.009150, 'Simple Features'),\n",
    "    ('exp_028', 0.008674, 'Four-Model Ensemble'),\n",
    "    ('exp_029', 0.016180, 'Normalization (FAILED)'),\n",
    "    ('exp_030', 0.017057, 'Gaussian Process (FAILED)'),\n",
    "    ('exp_031', 0.009984, 'CatBoost RFE'),\n",
    "    ('exp_032', 0.010983, 'CatBoost 18 Features'),\n",
    "]\n",
    "\n",
    "print('=== Experiment Summary (sorted by CV) ===')\n",
    "for exp, cv, name in sorted(experiments, key=lambda x: x[1]):\n",
    "    status = 'BEST' if cv == 0.008465 else ''\n",
    "    print(f'{exp}: CV {cv:.6f} - {name} {status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b5ede85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:45:21.125912Z",
     "iopub.status.busy": "2026-01-14T19:45:21.125609Z",
     "iopub.status.idle": "2026-01-14T19:45:21.128744Z",
     "shell.execute_reply": "2026-01-14T19:45:21.128421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CRITICAL INSIGHT ===\n",
      "\n",
      "The CV-LB gap is ~10x, and the intercept of the linear fit is ~0.053.\n",
      "This means even with PERFECT CV (0.0), the predicted LB would be ~0.053.\n",
      "The target is 0.0347, which is BELOW the intercept.\n",
      "\n",
      "This suggests one of two things:\n",
      "1. The linear relationship breaks down at lower CV values\n",
      "2. We need a fundamentally different approach\n",
      "\n",
      "The top LB score on the leaderboard is 0.01727.\n",
      "If someone achieved that, they must have found a way to break the CV-LB relationship.\n",
      "\n",
      "Possible explanations:\n",
      "- They use a different validation scheme that better matches LB\n",
      "- They use domain adaptation to reduce distribution shift\n",
      "- They use a model that generalizes better (e.g., physics-based)\n",
      "- They exploit some structure in the data we are missing\n"
     ]
    }
   ],
   "source": [
    "# The CRITICAL insight\n",
    "print('=== CRITICAL INSIGHT ===')\n",
    "print()\n",
    "print('The CV-LB gap is ~10x, and the intercept of the linear fit is ~0.053.')\n",
    "print('This means even with PERFECT CV (0.0), the predicted LB would be ~0.053.')\n",
    "print('The target is 0.0347, which is BELOW the intercept.')\n",
    "print()\n",
    "print('This suggests one of two things:')\n",
    "print('1. The linear relationship breaks down at lower CV values')\n",
    "print('2. We need a fundamentally different approach')\n",
    "print()\n",
    "print('The top LB score on the leaderboard is 0.01727.')\n",
    "print('If someone achieved that, they must have found a way to break the CV-LB relationship.')\n",
    "print()\n",
    "print('Possible explanations:')\n",
    "print('- They use a different validation scheme that better matches LB')\n",
    "print('- They use domain adaptation to reduce distribution shift')\n",
    "print('- They use a model that generalizes better (e.g., physics-based)')\n",
    "print('- They exploit some structure in the data we are missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9dae73c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:45:21.129552Z",
     "iopub.status.busy": "2026-01-14T19:45:21.129458Z",
     "iopub.status.idle": "2026-01-14T19:45:21.132761Z",
     "shell.execute_reply": "2026-01-14T19:45:21.132377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNEXPLORED OR UNDEREXPLORED APPROACHES ===\n",
      "\n",
      "1. TARGET TRANSFORM (Logit) - Tried but FAILED (exp_032)\n",
      "   - Logit transform made things worse\n",
      "   - BUT: Maybe the implementation was wrong?\n",
      "\n",
      "2. QUANTILE REGRESSION - NOT TRIED\n",
      "   - CatBoost supports quantile loss\n",
      "   - Could help with bounded [0,1] predictions\n",
      "\n",
      "3. BETA REGRESSION - NOT TRIED\n",
      "   - Specifically designed for [0,1] bounded data\n",
      "   - Uses Beta distribution for likelihood\n",
      "\n",
      "4. PHYSICS-INFORMED CONSTRAINTS - PARTIALLY TRIED\n",
      "   - Arrhenius features used\n",
      "   - But no explicit kinetic model fitting\n",
      "\n",
      "5. DOMAIN ADAPTATION - NOT TRIED\n",
      "   - The CV-LB gap suggests distribution shift\n",
      "   - Could try domain adaptation techniques\n",
      "\n",
      "6. DIFFERENT VALIDATION SCHEME - NOT TRIED\n",
      "   - Current: LOO for single, LORO for full\n",
      "   - Maybe the validation is too optimistic?\n",
      "\n",
      "7. STACKING WITH META-LEARNER - PARTIALLY TRIED\n",
      "   - Simple averaging tried\n",
      "   - But no proper stacking with held-out predictions\n"
     ]
    }
   ],
   "source": [
    "# What approaches haven't been tried or could be improved?\n",
    "print('=== UNEXPLORED OR UNDEREXPLORED APPROACHES ===')\n",
    "print()\n",
    "print('1. TARGET TRANSFORM (Logit) - Tried but FAILED (exp_032)')\n",
    "print('   - Logit transform made things worse')\n",
    "print('   - BUT: Maybe the implementation was wrong?')\n",
    "print()\n",
    "print('2. QUANTILE REGRESSION - NOT TRIED')\n",
    "print('   - CatBoost supports quantile loss')\n",
    "print('   - Could help with bounded [0,1] predictions')\n",
    "print()\n",
    "print('3. BETA REGRESSION - NOT TRIED')\n",
    "print('   - Specifically designed for [0,1] bounded data')\n",
    "print('   - Uses Beta distribution for likelihood')\n",
    "print()\n",
    "print('4. PHYSICS-INFORMED CONSTRAINTS - PARTIALLY TRIED')\n",
    "print('   - Arrhenius features used')\n",
    "print('   - But no explicit kinetic model fitting')\n",
    "print()\n",
    "print('5. DOMAIN ADAPTATION - NOT TRIED')\n",
    "print('   - The CV-LB gap suggests distribution shift')\n",
    "print('   - Could try domain adaptation techniques')\n",
    "print()\n",
    "print('6. DIFFERENT VALIDATION SCHEME - NOT TRIED')\n",
    "print('   - Current: LOO for single, LORO for full')\n",
    "print('   - Maybe the validation is too optimistic?')\n",
    "print()\n",
    "print('7. STACKING WITH META-LEARNER - PARTIALLY TRIED')\n",
    "print('   - Simple averaging tried')\n",
    "print('   - But no proper stacking with held-out predictions')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
