{
  "query": "How can machine learning models extrapolate to unseen chemical compounds or solvents not in training data?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Machine\u2011learning (ML) can reach beyond the compounds or solvents that appear in a training set when the model is equipped with descriptors that capture underlying physics rather than relying solely on cheap structural fingerprints.  One effective strategy is to train on **quantum\u2011mechanical (QM) descriptors** (e.g., orbital energies, dipoles) that vary smoothly across chemical space; a benchmark study showed that a linear\u2011regression model built on a QM\u2011derived \u201cQMex\u201d descriptor set achieved state\u2011of\u2011the\u2011art extrapolative performance on small\u2011data molecular properties, while still being interpretable\u202f([nature.com](https://www.nature.com/articles/s41524-023-01194-2)).  Similarly, a \u201cleave\u2011one\u2011group\u2011out\u201d cross\u2011validation scheme forces the model to predict entirely new chemical families and has been shown to improve accuracy for novel non\u2011fullerene acceptors when physical descriptors are included\u202f([pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC9189862)).\n\nAnother practical route is to **augment scarce experimental data with large synthetic datasets** and then fine\u2011tune the model on the real measurements.  A SMILES\u2011to\u2011properties transformer was first trained on 10\u202fmillion synthetic activity\u2011coefficient points from COSMO\u2011RS and subsequently refined on ~20\u202f000 experimental data, halving the prediction error for unknown molecules compared with traditional UNIFAC or COSMO\u2011RS models\u202f([pubs.rsc.org](https://pubs.rsc.org/en/content/articlehtml/2022/dd/d2dd00058j)).  Linear or single\u2011feature regressions, which are less prone to over\u2011fitting, have also been found to outperform black\u2011box methods for extrapolation tasks in drug\u2011discovery datasets\u202f([frontiersin.org](https://www.frontiersin.org/journals/pharmacology/articles/10.3389/fphar.2022.832120/full)).\n\nFinally, **generalized fingerprinting combined with broader, more diverse training libraries** can extend applicability to new solvent\u2011polymer pairs.  Although performance drops when a solvent is unseen\u2014largely because the solvent set is small\u2014expanding the solvent database and using interpretable features (e.g., physicochemical properties) is expected to improve extrapolation as the data grow\u202f([pubs.rsc.org](https://pubs.rsc.org/en/content/articlepdf/2022/cp/d2cp03735a)).  Together, these approaches\u2014physics\u2011based descriptors, synthetic\u2011data pre\u2011training, careful validation schemes, and linear\u2011model bias\u2014provide a toolkit for ML models to make reliable predictions on truly unseen chemical compounds and solvents.",
      "url": ""
    },
    {
      "title": "Limitations of machine learning models when predicting compounds ...",
      "text": "<div><div>\n \n <main>\n \n <article><section></section><section><section><h2>Abstract</h2>\n<p>We try to determine if machine learning (ML) methods, applied to the discovery of new materials on the basis of existing data sets, have the power to predict completely new classes of compounds (extrapolating) or perform well only when interpolating between known materials. We introduce the leave-one-group-out cross-validation, in which the ML model is trained to explicitly perform extrapolations of unseen chemical families. This approach can be used across materials science and chemistry problems to improve the added value of ML predictions, instead of using extrapolative ML models that were trained with a regular cross-validation. We consider as a case study the problem of the discovery of non-fullerene acceptors because novel classes of acceptors are naturally classified into distinct chemical families. We show that conventional ML methods are not useful in practice when attempting to predict the efficiency of a completely novel class of materials. The approach proposed in this work increases the accuracy of the predictions to enable at least the categorization of materials with a performance above and below the median value.</p></section><section><hr/>\n<p>We try to determine if machine learning (ML) methods, applied to the discovery of new materials on the basis of existing data sets, have the power to predict new classes of compounds or perform well only when interpolating between known materials.<a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=9189862_d2dd00004k-ga.jpg\"></a></p></section><section><h2>I. Introduction</h2>\n<p>One of the most exciting recent developments of materials discovery is the adoption of machine learning (ML) to guide the exploration of chemical and materials space.<sup><a href=\"#cit1\">1\u20134</a></sup> In a typical application, existing datasets of experimental characterizations are often combined with computed features of the same materials and used to predict the property of interest of novel materials. The field is very frequently reviewed,<sup><a href=\"#cit5\">5\u20139</a></sup> and some examples include alloys,<sup><a href=\"#cit10\">10</a></sup> polymers,<sup><a href=\"#cit11\">11</a></sup> perovskites<sup><a href=\"#cit12\">12</a></sup> and other inorganic solids.<sup><a href=\"#cit13\">13\u201318</a></sup> Although the results are impressive and have prompted a widespread adoption of such methods across all areas of materials discovery, there is still some uncertainty over the ability of ML to explore completely new chemical/material spaces.<sup><a href=\"#cit19\">19</a></sup> In general, the predictive ability of ML is computed <em>via</em> cross-validation, <em>i.e.</em>, predicting the performance of materials in a testing set that has not been included in the training set to optimize the ML algorithm, where training and testing sets are randomly generated from all data available in various ways. It is known that such algorithms perform better with larger data sets and with training data as close as possible to the ones to be predicted. Cross-validation generally gives the same weight to all predictions, whether they are for entries very close to existing ones in the training set (producing, in essence, an interpolation) or they are entirely novel (producing a much more challenging extrapolation). Moreover, materials are generally clustered by scientists into families based on their related chemical structures. Any discovery of a new family of compounds is regarded as a breakthrough, while discovering a novel member of an existing family is considered a more incremental advance. Therefore, accurate predictions within the families of known compounds and outside such families have a completely different value to the community. It should be noted that there are other non-random cross-validation methods, like scaffold-splits, time-splits and stratified-splits, which offer an alternative way to evaluate models. The general impact of such methods on the evaluation of the model can be found in ref. <a href=\"#cit20\">20</a> and <a href=\"#cit21\">21</a>. Stratified sampling has also been used to train models in organic solar cells, although is has a minimal impact.<sup><a href=\"#cit22\">22</a></sup> In our preliminary work with this dataset, time-splits do not perform well, as the validation families are developed at similar points in time. Scaffold splits would use certain structural properties to split the data into groups, although here we opted for a combination of structural and electronic characteristics to categorize in groups, as explained in Section 3 of the ESI.<a href=\"#fn1\">\u2020</a></p>\n<p>The goal of this work is to assess the ability of ML to predict the efficiency of interesting energy materials from completely new families and offer a new method to do so. In this context, by completely new, we mean materials that belong to a chemical family that is not present when training the model, and can be generated using chemical intuition, database searching or generative models.<sup><a href=\"#cit23\">23</a></sup> Then, one can use our methodology to screen these candidates and decide which ones will have a larger performance, reducing the number of candidates and accelerating the production of materials from new families. The methodology, in the most general terms, consists of constructing an ML model that is trained without any information on a new family of materials and assessing its quality in predicting the property of known elements of such family. Note that here we refer to training as the process of finding the optimum hyperparameters through a specific validation method. A practical problem is that the definition of \u201cnew\u201d is not mathematically accurate, and the novelty of a material is related to (a combination of) electronic, geometric or synthetic features that cannot be captured by an algorithm, while they will appear as self-evident to any expert in the relevant scientific domain. The problem of predicting the target properties of data outside of the training domain is also often tackled with transfer learning, where a previously trained method is used a starting point when predicting data in a new domain. We chose to study the ability of ML to explore new chemical space in the context of predicting novel non-fullerene acceptors for organic solar cells (OSCs).<sup><a href=\"#cit24\">24\u201326</a></sup> The topic is of significant contemporary interest as the identification of non-fullerene acceptors is considered essential to develop a competitive OSC technology and recent improvements have seen an almost three-fold increase in efficiency in five years since the report of non-fullerene electron acceptor (ITIC).<sup><a href=\"#cit27\">27,28</a></sup> For this scientific problem, there are well-defined families of acceptors recognized by the community and used to categorize the recent advances in the field. We can, therefore, ask whether new families of non-fullerene acceptors could have been predicted without any information on any member of that family. In this work, we discuss how a conventional cross-validation results in an overoptimistic evaluation of models when they are eventually used to predict new classes of compounds. We aim to draw conclusions on the specific field of computer-aided discovery of OSCs acceptors but also, more generally, on a practical approach to assess the usefulness of ML methods for more exploratory research. There have been other recent studies that evaluate ML models with out-of-sample tests in materials discovery.<sup><a href=\"#cit29\">29,30</a></sup> There has been similar work to predict out-of-sample reaction yields,<sup><a href=\"#cit31\">31,32</a></sup> and work in risk minimization applied to organic molecules to improve domain generalization.<sup><a href=\"#cit33\">33</a></sup> We introduce in this work a modificati...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC9189862"
    },
    {
      "title": "Extrapolative prediction of small-data molecular property using ...",
      "text": "[![npj Computational Materials](https://media.springernature.com/full/nature-cms/uploads/product/npjcompumats/header-4baba14304e9c3518bdc0d6f35b470b9.svg)](https://www.nature.com/npjcompumats)\n\nExtrapolative prediction of small-data molecular property using quantum mechanics-assisted machine learning\n\n[Download PDF](https://www.nature.com/articles/s41524-023-01194-2.pdf)\n\n[Download PDF](https://www.nature.com/articles/s41524-023-01194-2.pdf)\n\n### Subjects\n\n- [Computational methods](https://www.nature.com/subjects/computational-methods)\n- [Theoretical chemistry](https://www.nature.com/subjects/theoretical-chemistry)\n\n## Abstract\n\nData-driven materials science has realized a new paradigm by integrating materials domain knowledge and machine-learning (ML) techniques. However, ML-based research has often overlooked the inherent limitation in predicting unknown data: extrapolative performance, especially when dealing with small-scale experimental datasets. Here, we present a comprehensive benchmark for assessing extrapolative performance across 12 organic molecular properties. Our large-scale benchmark reveals that conventional ML models exhibit remarkable performance degradation beyond the training distribution of property range and molecular structures, particularly for small-data properties. To address this challenge, we introduce a quantum-mechanical (QM) descriptor dataset, called QMex, and an interactive linear regression (ILR), which incorporates interaction terms between QM descriptors and categorical information pertaining to molecular structures. The QMex-based ILR achieved state-of-the-art extrapolative performance while preserving its interpretability. Our benchmark results, QMex dataset, and proposed model serve as valuable assets for improving extrapolative predictions with small experimental datasets and for the discovery of novel materials/molecules that surpass existing candidates.\n\n### Similar content being viewed by others\n\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41524-024-01339-x/MediaObjects/41524_2024_1339_Fig1_HTML.png)\n\n### [Learning together: Towards foundation models for machine learning interatomic potentials with meta-learning](https://www.nature.com/articles/s41524-024-01339-x?fromPaywallRec=false)\n\nArticleOpen access17 July 2024\n\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41570-022-00416-3/MediaObjects/41570_2022_416_Figa_HTML.png)\n\n### [Extending machine learning beyond interatomic potentials for predicting molecular properties](https://www.nature.com/articles/s41570-022-00416-3?fromPaywallRec=false)\n\nArticle25 August 2022\n\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41597-025-04720-7/MediaObjects/41597_2025_4720_Fig1_HTML.png)\n\n### [The QCML dataset, Quantum chemistry reference data from 33.5M DFT and 14.7B semi-empirical calculations](https://www.nature.com/articles/s41597-025-04720-7?fromPaywallRec=false)\n\nArticleOpen access08 March 2025\n\n## Introduction\n\nMaterials science has greatly benefited from advancements in machine learning (ML) and deep learning (DL) techniques[1](https://www.nature.com/www.nature.com#ref-CR1), [2](https://www.nature.com/www.nature.com#ref-CR2), [3](https://www.nature.com/www.nature.com#ref-CR3), [4](https://www.nature.com/www.nature.com#ref-CR4), [5](https://www.nature.com/www.nature.com#ref-CR5), [6](https://www.nature.com/articles/s41524-023-01194-2#ref-CR6). These techniques have revolutionized the prediction of molecular properties, leveraging traditional computational approaches, such as the group contribution (GC) method[7](https://www.nature.com/www.nature.com#ref-CR7), [8](https://www.nature.com/www.nature.com#ref-CR8), [9](https://www.nature.com/articles/s41524-023-01194-2#ref-CR9), quantitative structure-activity/property relationship (QSAR/QSPR) method[10](https://www.nature.com/www.nature.com#ref-CR10), [11](https://www.nature.com/www.nature.com#ref-CR11), [12](https://www.nature.com/www.nature.com#ref-CR12), [13](https://www.nature.com/articles/s41524-023-01194-2#ref-CR13), quantum mechanics (QM), and molecular dynamics (MD) calculations[14](https://www.nature.com/www.nature.com#ref-CR14), [15](https://www.nature.com/www.nature.com#ref-CR15), [16](https://www.nature.com/www.nature.com#ref-CR16), [17](https://www.nature.com/www.nature.com#ref-CR17), [18](https://www.nature.com/www.nature.com#ref-CR18), [19](https://www.nature.com/www.nature.com#ref-CR19), [20](https://www.nature.com/www.nature.com#ref-CR20), [21](https://www.nature.com/www.nature.com#ref-CR21), [22](https://www.nature.com/www.nature.com#ref-CR22), [23](https://www.nature.com/www.nature.com#ref-CR23), [24](https://www.nature.com/www.nature.com#ref-CR24), [25](https://www.nature.com/www.nature.com#ref-CR25), [26](https://www.nature.com/articles/s41524-023-01194-2#ref-CR26). Graph neural networks (GNNs) have emerged as a promising DL-based method for property prediction by embedding molecular structures in a graph architecture[27](https://www.nature.com/articles/s41524-023-01194-2#ref-CR27), [28](https://www.nature.com/articles/s41524-023-01194-2#ref-CR28). Moreover, pre-trained GNNs, which employ self-supervised or transfer learning, have demonstrated the highest accuracies across various benchmarks in molecular property prediction[29](https://www.nature.com/www.nature.com#ref-CR29), [30](https://www.nature.com/www.nature.com#ref-CR30), [31](https://www.nature.com/www.nature.com#ref-CR31), [32](https://www.nature.com/www.nature.com#ref-CR32), [33](https://www.nature.com/articles/s41524-023-01194-2#ref-CR33). ML/DL techniques continue to enhance the accuracy and speed of property prediction, serving as indispensable tools for data-driven materials science.\n\nHowever, a fundamental contradiction persists in ML/DL techniques regarding their inherent extrapolation difficulty, i.e., the ability to predict beyond the available data. In molecular property prediction, two main limitations arise from the range of molecular properties and the diversity of molecular structures (see Fig. [1](https://www.nature.com/articles/s41524-023-01194-2#Fig1)). The primary objective of data-driven materials exploration is to identify high-performance molecules/materials that are not yet represented in databases. Hence, ML/DL models must possess the capability to extrapolate unexplored data solely from the available data. However, materials datasets often consist of small experimental results, typically containing fewer than 500 data points[34](https://www.nature.com/www.nature.com#ref-CR34), [35](https://www.nature.com/www.nature.com#ref-CR35), [36](https://www.nature.com/www.nature.com#ref-CR36), [37](https://www.nature.com/www.nature.com#ref-CR37), [38](https://www.nature.com/www.nature.com#ref-CR38), [39](https://www.nature.com/articles/s41524-023-01194-2#ref-CR39), which inevitably carries biases due to molecular structures and property ranges. It is crucial to determine whether ML/DL models can overcome these biases and effectively extrapolate molecular properties, even when dealing with limited data, to discover novel materials/molecules that outperform existing ones.\n\n**Fig. 1: Overview of extrapolative prediction of molecular property based on the range of molecular properties and the diversity of molecular structures.**\n\n[![figure 1](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41524-023-01194-2/MediaObjects/41524_2023_1194_Fig1_HTML.png)](https://www.nature.com/articles/s41524-023-01194-2/figures/1)\n\nThe interpolation task represents predictions within the available property range and molecular structures, while the extrapolation task represents predictions outside the training distribution of existing data. Plot illustrates the relationship between 1D-UMAP (Uniform Manifold Approximation and Projection[90](https://www.nature.com/articles/s41524-023-01194-2#ref-CR90)) compo...",
      "url": "https://www.nature.com/articles/s41524-023-01194-2"
    },
    {
      "title": "Limits of Prediction for Machine Learning in Drug Discovery - Frontiers",
      "text": "Your new experience awaits. Try the new design now and help us make it even better\n\nSwitch to the new experience\n\nORIGINAL RESEARCH article\n\nFront. Pharmacol., 10 March 2022\n\nSec. Experimental Pharmacology and Drug Discovery\n\nVolume 13 - 2022 \\| [https://doi.org/10.3389/fphar.2022.832120](https://doi.org/10.3389/fphar.2022.832120)\n\nThis article is part of the Research TopicChemoinformatics Approaches to Structure- and Ligand-Based Drug Design, Volume II[View all 20 articles](https://www.frontiersin.org/research-topics/21797/chemoinformatics-approaches-to-structure--and-ligand-based-drug-design-volume-ii/magazine)\n\n# Limits of Prediction for Machine Learning in Drug Discovery\n\n[Modest von Korff](https://loop.frontiersin.org/people/1564739)\\*[Thomas Sander](https://loop.frontiersin.org/people/1652606)\n\n- Idorsia Pharmaceuticals Ltd., Allschwil, Switzerland\n\nIn drug discovery, molecules are optimized towards desired properties. In this context, machine learning is used for extrapolation in drug discovery projects. The limits of extrapolation for regression models are known. However, a systematic analysis of the effectiveness of extrapolation in drug discovery has not yet been performed. In response, this study examined the capabilities of six machine learning algorithms to extrapolate from 243 datasets. The response values calculated from the molecules in the datasets were molecular weight, cLogP, and the number of sp3-atoms. Three experimental set ups were chosen for response values. Shuffled data were used for interpolation, whereas data for extrapolation were sorted from high to low values, and the reverse. Extrapolation with sorted data resulted in much larger prediction errors than extrapolation with shuffled data. Additionally, this study demonstrated that linear machine learning methods are preferable for extrapolation.\n\n## Introduction\n\nIn drug discovery, new molecules undergo clinical trials in human subjects only after numerous checks for safety and potency in biological test systems. Often, a drug suitable for oral administration is desired, i.e., a molecule that can cross cellular membranes separating the gastrointestinal system and blood vessels. After absorption, blood vessels distribute the molecule throughout the organism and to its site of action. Blood contains many proteins that bind a substantial fraction of any compound. During distribution, molecules pass through the liver, which contains enzymes able to metabolize many types of chemical substances, thus reducing the concentration of the active drug (clearance). An important measure used in the optimization of a bioactive molecule is plasma exposure after oral administration, often expressed as \u201carea under the curve\u201d (AUC), i.e., the concentration of the active molecule in blood plasma integrated over time. Bioavailability depends on multiple properties of the molecule including cell layer permeability and clearance in the liver. When a molecule reaches the target protein, it must bind in such a way that it has the desired effect. A specific assay is usually developed to measure the effect of the molecule on the target protein. At present, it is still not possible to design a successful drug, fulfilling all necessary requirements, without biological tests. However, biological testing requires time and resources, which limit the number of compounds that can be explored. Medicinal chemists require quantitative models allowing prioritization the most promising molecules for biological testing.\n\n### Related Work\n\nThe use of quantitative structure-activity relationships (QSAR) is essential in drug discovery and has been investigated in multiple publications ( [Gramatica, 2007](https://www.frontiersin.org/www.frontiersin.org#B8); [Cherkasov et al., 2014](https://www.frontiersin.org/www.frontiersin.org#B3)). Recently, huge efforts has been undertaken to find appropriate meta-parameter for QSAR models ( [Olier et al., 2018](https://www.frontiersin.org/www.frontiersin.org#B19)). It is well known that statistical models lose their predictive power when they are outside the range of calibration. Outside the calibration range, confidence intervals become infinite. These limits have been previously discussed for QSAR from ( [Tong et al., 2005](https://www.frontiersin.org/www.frontiersin.org#B26)) and were formulated in OECD policies for the validation of QSAR models ( [Member countries, 2004](https://www.frontiersin.org/www.frontiersin.org#B15); [OECD, 2014](https://www.frontiersin.org/www.frontiersin.org#B18)). Closely related to the calibration range is the term applicability domain. The term applicability domain is used in cheminformatics for quantitative structure activity models. The OECD guideline demands to consider the applicability domain but does not give a binding definition. By Roy et al. the application domain was defined as \u201cThe AD is a theoretical region in chemical space encompassing both the model descriptors and modeled response which allows one to estimate the uncertainty in the prediction of a particular compound based on how similar it is to the training compounds employed in the model development\u201d ( [Roy et al., 2015](https://www.frontiersin.org/www.frontiersin.org#B20)). If the predicted molecules are similar to the training molecules in descriptor space, they are in the application domain ( [Jaworska et al., 2005](https://www.frontiersin.org/www.frontiersin.org#B9)). In drug discovery, the modeled response are molecular properties which the medicinal chemists aim to optimise. So, the properties medicinal chemists would like to predict are often outside the range of response values, which were already covered by experiments. At the start of a drug discovery project, a few molecules are usually identified which show modest activity at the target protein site. Starting compounds are modified by medicinal chemists to improve their properties. By adding all available information into the new compounds, they improve their characteristics over time. The next compound is often designed with the aim to show a lower binding constant to the target protein. Usually, this compound is similar to the already synthesized compounds and therefore in the applicability domain. During this optimization process, the desired response values are outside the range of the available response values. A model that aims to support the medicinal chemist in his work needs the capability of extrapolation. Recently, the use of extrapolation through machine learning, to assess the bioactivity of a molecule in drug discovery, has been evaluated ( [Cort\u00e9s-Ciriano et al., 2018](https://www.frontiersin.org/www.frontiersin.org#B4)). Extrapolation outside the upper limits of the measured value range is wanted for the plasma exposure after oral administration. The plasma exposure should be as high as possible, but in a drug discovery project it is often to low. Additionally, frequently the majority of available response values are far away from the desired value range.\n\n### Our Work\n\nThe missing information in QSAR literature about differences between the errors of interpolation and extrapolation triggered a question. How effective can extrapolation of response values for chemical molecules be? To answer this question, we decided to use organic molecule datasets with calculated physicochemical properties. The physicochemical properties were used as response values in this study and were calculated from the molecular structure. Mathematically, a molecule is represented as a small graph with colored edges and colored nodes. This molecular graph cannot directly be used as input for the applied machine learning methods. The graph must be transformed into a vector, a chemical descriptor. Machine learning creates models that relate descriptor vectors to the corresponding response values. With our setup a fully correct machine learning model was theoretically possible. The complete information needed to predict the r...",
      "url": "https://www.frontiersin.org/journals/pharmacology/articles/10.3389/fphar.2022.832120/full"
    },
    {
      "title": "Solvent selection for polymers enabled by generalized chemical fingerprinting and machine learning",
      "text": "This journal is \u00a9 the Owner Societies 2022 Phys. Chem. Chem. Phys., 2022, 24, 26547\u201326555 | 26547\nCite this: Phys. Chem. Chem. Phys.,\n2022, 24, 26547\nSolvent selection for polymers enabled by\ngeneralized chemical fingerprinting and machine\nlearning\u2020\nJoseph Kern, Shruti Venkatram, Manali Banerjee, Blair Brettmann and\nRampi Ramprasad*\nWe present machine learning models trained on experimental data to predict room-temperature\nsolubility for any polymer\u2013solvent pair. The new models are a significant advancement over past data\u0002driven work, in terms of protocol, validity, and versatility. A generalizable fingerprinting method is used\nfor the polymers and solvents, making it possible, in principle, to handle any polymer\u2013solvent combi\u0002nation. Our data-driven approach achieves high accuracy when either both the polymer and solvent or\njust the polymer has been seen during the training phase. Model performance is modest though when a\nsolvent (in a newly queried polymer\u2013solvent pair) is not part of the training set. This is likely because the\nnumber of unique solvents in our data set is small (much smaller than the number of polymers). Never\u0002theless, as the data set increases in size, especially as the solvent set becomes more diverse, the overall\npredictive performance is expected to improve.\n1 Introduction\nSolvent selection is an important component of polymer synth\u0002esis and processing as well as a multitude of polymer applica\u0002tions like microlithography, membrane formation, drug\ndelivery systems, recycling, and waste processing.1 In micro\u0002lithography, polymers are exposed to electromagnetic radiation\nto cause changes to their chemical structure, then immersed in\na solvent to dissolve either the exposed or unexposed region.2\nWhen forming membranes using non-solvent induced phase\nseparation, a polymer is dissolved in a solvent to create a\nhomogeneous dope solution. This solution is cast as a liquid\nfilm on a substrate which is then placed in a coagulation non\u0002solvent bath to remove the solvent and form the membrane.3 In\ndrug delivery systems, water soluble polymers are used to\nincrease the solubility of poorly soluble drugs by dispersing\nthe drug in the polymer structure.4,5 Water soluble polymers\nare also used as stabilisers and mechanical supports for sus\u0002tained release of drugs.6 In efforts to chemically recycle indust\u0002rially relevant polymers like polystyrene and high-density\npolyethylene in a single process stream, solvent selection was\nidentified as the most critical parameter.7 In water treatment,\nwater-soluble polymeric materials are used to remove heavy\nmetal ions and arsenic.8 Water soluble polymers used in\ncosmetics and laundry detergents can also leach into the\nenvironment and need to be removed via sorption.9 When\nusing solvents during the creation of polymers, toxic solvents\ncan remain in the polymers post-processing and come into\ncontact with humans, so ideally safe alternatives to commonly\nused solvents could also be determined for every polymer.10\nGiven how important polymer solubility is in these numerous\nprocesses, it is critical to have a method of estimating what\nsolvents will dissolve polymers.\nTo enable informed solvent identification, several empirical\nmethods have been proposed with varying degrees of success,\nincluding the Hildebrand and Hansen methods. In the Hildeb\u0002rand method, polymers and solvents with similar Hildebrand\nparametric values (which are related to the cohesive energy\ndensity) are predicted as good solvents and those with values\ndiffering by more than a threshold are predicted as bad\nsolvents.1,11 In the Hansen method, the difference between\nthree parameters quantifying dispersion, dipolar, and hydro\u0002gen bonding interactions for the polymer and solvent are used\nto provide an estimate of the solubility of the polymer in the\nsolvent.12 Previous work by Venkatram et al. showed the\nHansen method performed only marginally better than\nthe Hildebrand method despite its greater complexity.13\nSeveral computational approaches have been used to esti\u0002mate these solubility parameters, including group contribution\nmethods14 and a variety of machine learning techniques.\nSchool of Materials Science and Engineering, College of Engineering, Georgia\nInstitute of Technology, 771 Ferst Drive, J. Erskine Love Building, Atlanta, GA\n30332-0245, USA. E-mail: rampi.ramprasad@mse.gatech.edu\n\u2020 Electronic supplementary information (ESI) available. See DOI: https://doi.org/\n10.1039/d2cp03735a\nReceived 13th August 2022,\nAccepted 22nd October 2022\nDOI: 10.1039/d2cp03735a\nrsc.li/pccp\nPCCP\nPAPER\nPublished on 31 October 2022. Downloaded on 11/6/2025 1:28:45 AM. View Article Online View Journal | View Issue\n26548 | Phys. Chem. Chem. Phys., 2022, 24, 26547\u201326555 This journal is \u00a9 the Owner Societies 2022\nSanchez-Lengeling et al. used Gaussian process regression with\nMorgan and MACCS fingerprints to estimate Hansen solubility\nparameters for 31 polymers and 193 solvents, achieving reason\u0002able R2 performance (0.56\u20130.83).15 Kurotani et al. used only four\npieces of analytical data to predict Hansen solubility para\u0002meters for polymers as well, and while their R2 performance\nwas lower than Sanchez-Lengeling et al., they posited that it\nmay be useful for new polymers with unknown SMILES\nstrings.16 Others have used descriptors derived from atomic\nstructure and quantum chemical calculation for small mole\u0002cules representing polymer repeat units to predict the Hil\u0002debrand solubility parameters using kernel ridge regression\nand multi-linear regression models.17 Most recently, Liu\net al. collected data on 81 polymers and 1221 solvents and\ncreated more easily interpretable regression models to pre\u0002dict Chi, Hildebrand, and Hansen parameters.18 They fea\u0002turized their polymers and solvents using RDKit generated\nchemical fingerprints such as the count, density and\nweighted sum for atoms, and 2nd order features generated\nfrom the 3d structures of trimers and solvents such as\nLUMO, HOMO and heat of formation.\nMeanwhile, previous work by Chandrasekaran et al.,\n19\ninspired by the promise of machine learning in the materials\ndomain,20,21 showed that a deep neural network trained on a\ndata set of 4595 polymers and 24 solvents could dramatically\noutperform the Hildebrand approach to estimating\nsolubility.1,11 This method utilized chemical features to repre\u0002sent polymers and a one-hot (label-based) encoding to repre\u0002sent the solvents which were used to train a multilayer\nperceptron neural network that could classify whether a parti\u0002cular polymer\u2013solvent combination was soluble or insoluble.\nThey also found that a Hildebrand Gaussian process model\u2019s\nclassification accuracy was much worse than the neural net\u0002work, correctly classifying good-solvents only 50% of the time\nand bad solvents 70% as opposed to the over 90% accuracy for\nthe neural network. The downside to their neural network\napproach, however, was that solubility estimations could be\nperformed for only the 24 solvents within the training data due\nto the one-hot encoding; i.e., predictions could not be general\u0002ized to cases outside the list of 24 solvents.\nIn the present work, we demonstrate a method to generalize\nmachine learning models to any solvent so predictions can be\nmade on previously unseen solvents. Moreover, we perform a\ncritical analysis of the strengths and weaknesses of any such\ndata-driven approach and identify situations where caution is\nmandated. First, a data set of 3373 polymers and 51 solvents\nwas collected. Next, we structurally fingerprinted the polymers\nand solvents using a hierarchical methodology that is general\u0002izable to any polymer\u2013solvent pair, unlike the one-hot encoding\nmethod. Finally, these fingerprints and solubility data were\nused to train a random forest classifier and a deep neural\nnetwork binary classifier that predicts if a polymer\u2013solvent pair\nis soluble or insoluble. A production version of the random\nforest model has been deployed to our online polymer infor\u0002matics platform, polyme...",
      "url": "https://pubs.rsc.org/en/content/articlepdf/2022/cp/d2cp03735a"
    },
    {
      "title": "A smile is all you need: predicting limiting activity coefficients from SMILES with natural language processing",
      "text": "<div><div><p><span></span></p><div><p><span>Received \n 10th June 2022\n </span><span>, Accepted 27th September 2022</span></p><p>First published on 29th September 2022</p><hr/><div><h2>Abstract</h2><p>The knowledge of mixtures\u2019 phase equilibria is crucial in nature and technical chemistry. Phase equilibria calculations of mixtures require activity coefficients. However, experimental data on activity coefficients are often limited due to the high cost of experiments. For an accurate and efficient prediction of activity coefficients, machine learning approaches have been recently developed. However, current machine learning approaches still extrapolate poorly for activity coefficients of unknown molecules. In this work, we introduce a SMILES-to-properties-transformer (SPT), a natural language processing network, to predict binary limiting activity coefficients from SMILES codes. To overcome the limitations of available experimental data, we initially train our network on a large dataset of synthetic data sampled from COSMO-RS (10 million data points) and then fine-tune the model on experimental data (20870 data points). This training strategy enables the SPT to accurately predict limiting activity coefficients even for unknown molecules, cutting the mean prediction error in half compared to state-of-the-art models for activity coefficient predictions such as COSMO-RS and UNIFAC<small><sub>Dortmund</sub></small>, and improving on recent machine learning approaches.</p></div><hr/>\n \n \n <h2><span>1 Introduction</span></h2>\n <p><span>With over 500000 molecules registered even in the CAS common chemicals database,<a href=\"#cit1\"><sup><span>1</span></sup></a> the chemical design space of molecules is substantially larger than our capacity to measure their thermodynamic property data. This gap further increases when considering that properties usually depend on temperature and pressure, and even more for mixtures due to combinatorics and dependency on mixture composition. Binary activity coefficients are of particular interest in chemical engineering, as activity coefficients govern the phase equilibria in distillation and extraction, the key separations of many chemical processes. However, even large property databases, such as the Dortmund Datenbank (DDB), only hold experimental data for the activity coefficients of 31000 binary systems, a tiny fraction of all possible molecular combinations.<a href=\"#cit2\"><sup><span>2</span></sup></a></span></p><p>To overcome the inherent lack of experimental data, predictive thermodynamic property models have been developed over recent decades for many molecular properties, <span>e.g.</span>, COSMO-RS,<a href=\"#cit3\"><sup><span>3</span></sup></a> COSMO-SAC,<a href=\"#cit4\"><sup><span>4</span></sup></a> SAFT-\u03b3 Mie,<a href=\"#cit5\"><sup><span>5</span></sup></a> and UNIFAC.<a href=\"#cit6\"><sup><span>6</span></sup></a> These models can predict thermodynamic properties with increasing accuracy and are therefore particularly beneficial for molecule mixtures with missing experimental data. However, despite the vital advantages of predictive thermodynamic models, these models come with shortcomings. For example, calculating the surface charges of molecules for COSMO models is time-consuming, whilst UNIFAC is limited to known functional groups parametrized to experimental data. Moreover, these physically based predictive models are still less accurate than experiments.<a href=\"#cit7\"><sup><span>7</span></sup></a></p>\n <p>Computationally efficient alternatives to physically based predictive models are data-driven models using machine learning. Machine learning is currently a rising topic in chemical engineering, as summarized in multiple recent reviews<a href=\"#cit8\"><sup><span>8\u201310</span></sup></a> that identify challenges in many areas such as optimal decision making, introduction and enforcing of physics, information and knowledge representation, and safety and trust.<a href=\"#cit11\"><sup><span>11</span></sup></a> The application of machine learning has also already led to recent advances in thermodynamic property prediction. Alshehri <span>et al.</span><a href=\"#cit12\"><sup><span>12</span></sup></a> developed a data-driven model to predict 25 pure component properties based on a Gaussian process. The developed model surpasses classical group contribution models in accuracy. Chen <span>et al.</span><a href=\"#cit13\"><sup><span>13</span></sup></a> use a transformer-convolutional model to predict the sigma profiles of pure components with high accuracy.</p>\n <p>To predict activity coefficients, matrix completion methods have been recently proposed that represent the limiting activity coefficient of binary mixtures as a matrix. In matrix completion methods, all mixtures are sorted into a solvent-by-solute matrix. Known mixtures are used to learn embeddings for each solvent/solute, which then can be used to fill the matrix by interpolating towards unknown combinations. Jirasek <span>et al.</span><a href=\"#cit14\"><sup><span>14</span></sup></a> proposed a matrix completion method to predict the limiting activity coefficients of binary mixtures at 298.15 K that exceeded the accuracy achieved by UNIFAC. Recently, Damay <span>et al.</span><a href=\"#cit15\"><sup><span>15</span></sup></a> extended the method of Jirasek <span>et al.</span><a href=\"#cit14\"><sup><span>14</span></sup></a> to capture temperature dependencies. The proposed model has a higher accuracy for the temperature-dependent prediction of limiting activity coefficients than UNIFAC. Chen <span>et al.</span><a href=\"#cit16\"><sup><span>16</span></sup></a> developed an approach to extend the UNIFAC-Il model<a href=\"#cit17\"><sup><span>17</span></sup></a> for predicting limiting activity coefficients in ionic liquids by combining matrix completion with convolutional networks. These proposed approaches exceed the accuracy of the widely employed UNIFAC model in predicting limiting activity coefficients. Moreover, matrix completion approaches do not require any characterization of the molecules to train the model and predict thermodynamic properties, as the model solely learns from the correlations within the matrix. However, their lack of molecular characterization prevents matrix completion methods from extrapolating beyond the space of molecules available for training. Recently, Sanchez Medina <span>et al.</span><a href=\"#cit18\"><sup><span>18</span></sup></a> developed a graph neural network to predict limiting activity coefficients at constant temperature. In principle, this graph neural network is capable of extrapolating to unknown solvents and solutes, but the extrapolatory capabilities of the network were not tested. Thus, it is still unclear how well machine learning methods can extrapolate out of the realm of training data onto unknown solutes and solvents.</p>\n <p>Here, we present a SMILES-to-property-transformer (SPT), a data-driven model with high accuracy for interpolation and extrapolation that can predict temperature-dependent limiting activity coefficients from nearly arbitrary SMILES, based on natural language processing and a transformer architecture.<a href=\"#cit19\"><sup><span>19</span></sup></a> Due to their ability to learn structural relationships, transformer models have recently shown to be successful in predicting the pure component properties of various molecules and pharmaceuticals.<a href=\"#cit20\"><sup><span>20,21</span></sup></a> However, transformer models require large amounts of training data, which is typically unavailable for thermodynamic properties from experiments. To overcome the lack of experimental training data, we propose a two-step approach: first, the model is trained on a large amount of synthetic data from a physically based predictive model for limiting activity coefficients to convey the grammar of SMILES and the underlying physics of activity coefficients to the model. Second, the pretrained model is fine-tuned using available experime...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2022/dd/d2dd00058j"
    },
    {
      "title": "On modeling and utilizing chemical compound information with ...",
      "text": "- View\u00a0**PDF**\n\nUnder a Creative Commons [license](http://creativecommons.org/licenses/by-nc-nd/4.0/)\n\nOpen access\n\n## Abstract\n\nA large number of chemical compounds are available in databases such as PubChem and ZINC. However, currently known compounds, though large, represent only a fraction of possible compounds, which is known as chemical space. Many of these compounds in the databases are annotated with properties and assay data that can be used for drug discovery efforts. For this goal, a number of machine learning algorithms have been developed and recent deep learning technologies can be effectively used to navigate chemical space, especially for unknown chemical compounds, in terms of drug-related tasks. In this article, we survey how deep learning technologies can model and utilize chemical compound information in a task-oriented way by exploiting annotated properties and assay data in the chemical compounds databases. We first compile what kind of tasks are trying to be accomplished by machine learning methods. Then, we survey deep learning technologies to show their modeling power and current applications for accomplishing drug related tasks. Next, we survey deep learning techniques to address the insufficiency issue of annotated data for more effective navigation of chemical space. Chemical compound information alone may not be powerful enough for drug related tasks, thus we survey what kind of information, such as assay and gene expression data, can be used to improve the prediction power of deep learning models. Finally, we conclude this survey with four important newly developed technologies that are yet to be fully incorporated into computational analysis of chemical information.\n\n## Keywords\n\nChemical space\n\nDeep learning\n\nComputer-aided drug discovery\n\nData augmentation\n\nChemical information modeling\n\n\u00a9 2022 The Author(s). Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology.",
      "url": "https://www.sciencedirect.com/science/article/pii/S2001037022003300"
    },
    {
      "title": "Interpretable models for extrapolation in scientific machine learning",
      "text": "[View\u00a0PDF\u00a0Version](https://pubs.rsc.org/en/content/articlepdf/2023/dd/d3dd00082f)[Previous\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2023/dd/d3dd00071k)[Next\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2023/dd/d3dd00083d)\n\nOpen Access Article\nThis Open Access Article is licensed under a [Creative Commons Attribution 3.0 Unported Licence](http://creativecommons.org/licenses/by/3.0/)\n\nDOI:\u00a0[10.1039/D3DD00082F](https://doi.org/10.1039/D3DD00082F)\n(Paper)\n[Digital Discovery](https://doi.org/10.1039/2635-098X/2022), 2023, **2**, 1425-1435\n\n# Interpretable models for extrapolation in scientific machine learning [\u2020](https://pubs.rsc.org/pubs.rsc.org\\#fn1)\n\nEric S.\nMuckley\na,\nJames E.\nSaal\n\\*a,\nBryce\nMeredig\na,\nChristopher S.\nRoper\nb and John H.\nMartin\nbaCitrine Informatics, Redwood City, CA 94063, USA. E-mail: [jsaal@citrine.io](mailto:jsaal@citrine.io)bHRL Laboratories, Malibu, CA 90265, USA\n\nReceived\n30th April 2023\n, Accepted 17th August 2023\n\nFirst published on 21st August 2023\n\n## Abstract\n\nData-driven models are central to scientific discovery. In efforts to achieve state-of-the-art model accuracy, researchers are employing increasingly complex machine learning algorithms that often outperform simple regressions in interpolative settings (e.g. random k-fold cross-validation) but suffer from poor extrapolation performance, portability, and human interpretability, which limits their potential for facilitating novel scientific insight. Here we examine the trade-off between model performance and interpretability across a broad range of science and engineering problems with an emphasis on materials science datasets. We compare the performance of black box random forest and neural network machine learning algorithms to that of single-feature linear regressions which are fitted using interpretable input features discovered by a simple random search algorithm. For interpolation problems, the average prediction errors of linear regressions were twice as high as those of black box models. Remarkably, when prediction tasks required extrapolation, linear models yielded average error only 5% higher than that of black box models, and outperformed black box models in roughly 40% of the tested prediction tasks, which suggests that they may be desirable over complex algorithms in many extrapolation problems because of their superior interpretability, computational overhead, and ease of use. The results challenge the common assumption that extrapolative models for scientific machine learning are constrained by an inherent trade-off between performance and interpretability.\n\n## Introduction\n\nMachine learning has become a principal catalyst for scientific discovery, particularly in the design of novel functional materials. [1,2](https://pubs.rsc.org/pubs.rsc.org#cit1) In efforts to build predictive models with state-of-the-art performance, researchers are employing increasingly complex black box algorithms, including large-scale ensembles and deep neural networks, because of their ability to approximate high-dimensional response surfaces with arbitrary precision. [3](https://pubs.rsc.org/pubs.rsc.org#cit3) Recent availability of low-cost data storage and computing resources has unlocked model architectures capable of handling large numbers (105\u2013107) of input features, [4,5](https://pubs.rsc.org/pubs.rsc.org#cit4) enabling the development of deep learning models such as Elemnet [6](https://pubs.rsc.org/pubs.rsc.org#cit6) and SchNet [7](https://pubs.rsc.org/pubs.rsc.org#cit7) which can learn feature encodings directly from the elemental compositions of input materials. While the complexity of these models often leads them to outperform traditional regression techniques by standard cross-validation scoring metrics, they also suffer from notable disadvantages. [8,9](https://pubs.rsc.org/pubs.rsc.org#cit8)\n\nIncreases in model complexity are generally accompanied by corresponding decreases in model portability and usability by non-experts. Many state-of-the-art black box algorithms require significant computational resources and hyperparameter optimization during training, which limits their usefulness in edge computing environments and necessitates experienced practitioners for managing model serialization, programming environments and version control systems, and input data compatibility. [10,11](https://pubs.rsc.org/pubs.rsc.org#cit10) Growing complexity also inherently limits model interpretability by humans, [12,13](https://pubs.rsc.org/pubs.rsc.org#cit12) which increases the likelihood of model overfitting, reduces researcher trust in predictions, and creates difficulty in troubleshooting. [14](https://pubs.rsc.org/pubs.rsc.org#cit14) Perhaps most importantly, poor model interpretability impedes domain expert intuition by obscuring natural underlying patterns that often guide researchers toward novel insights and new physics. [1,15,16](https://pubs.rsc.org/pubs.rsc.org#cit1)\n\nThe use of simple interpretable models has garnered renewed attention amid mounting evidence that the trade-off between model performance and interpretability is often overstated. [1,14](https://pubs.rsc.org/pubs.rsc.org#cit1) Interpretability aids in diagnosis of model biases, management of multi-objective trade-offs, and mitigation of unexpected results, [8,17\u201320](https://pubs.rsc.org/pubs.rsc.org#cit8) which are essential considerations in the design of materials and chemicals for novel drugs, electronics, catalysts, and alloys. [2,21](https://pubs.rsc.org/pubs.rsc.org#cit2) The primary challenge of materials informatics, accurate prediction of the physical properties of a material from its chemistry or other known characteristics, relies on the discovery of interpretable physics-informed input features: empirically or theoretically derived vectors of known quantities which can be used to predict the value of a target property using simple mappings, such as a linear transformations. [6,22](https://pubs.rsc.org/pubs.rsc.org#cit6) Ideal input features are (i) general: they maintain predictive performance across a broad range of materials, (ii) extensible: they can be constructed from readily available data sources or simple calculations, and (iii) interpretable: they can provide insights into underlying physics or correlations which aid in predicting the material property of interest. [23](https://pubs.rsc.org/pubs.rsc.org#cit23)\n\nThe discovery of features meeting the aforementioned three criteria remains one of the primary challenges of scientific machine learning (SciML) and represents a principal roadblock on the path toward interpretable physics-informed models. [24,25](https://pubs.rsc.org/pubs.rsc.org#cit24) Features for materials informatics models are often engineered to encode one or more material properties, including those derived from chemical composition, topology, electronic behavior, or structural fingerprints. [18](https://pubs.rsc.org/pubs.rsc.org#cit18) The most commonly used features are composition-based vectors constructed from properties of the constituent elements of the material [12,26](https://pubs.rsc.org/pubs.rsc.org#cit12) such as those included in the Magpie feature set, [27](https://pubs.rsc.org/pubs.rsc.org#cit27) which provides descriptive statistics such as minimum, maximum, mean, and range of a set of tabulated element properties for a given chemical composition. Magpie has been used for building successful models across a broad range of materials classes [22,28,29](https://pubs.rsc.org/pubs.rsc.org#cit22) and serves as the foundation for the widely-used Matminer suite of open-source materials informatics tools. [30](https://pubs.rsc.org/pubs.rsc.org#cit30) While the standard Magpie library enables simple human-interpretable featurization of chemical composition, its strong reliance on elemental composition generally leads to a lack of robust encoding of underlying interactions beyond those of the material's constituent elements. Featurization...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2023/dd/d3dd00082f"
    },
    {
      "title": "Can Machine Learning Find Extraordinary Materials? - ChemRxiv",
      "text": "We use cookies to distinguish you from other users and to provide you with a better experience on our websites.Close this message to accept cookies or find out how to manage your cookie settings. [Learn more about our Privacy Notice...\\\n\\[opens in a new tab\\]](https://www.cambridge.org/about-us/legal-notices/privacy-notice/)\n\n[Back to\\\nTheoretical and Computational Chemistry](https://chemrxiv.org/engage/chemrxiv/category-dashboard/605c72ef153207001f6470ce)\n\nSearch within Theoretical and Computational Chemistry\n\n![RSS feed for Theoretical and Computational Chemistry](https://chemrxiv.org/engage/assets/public/chemrxiv/social/rss.svg)\n\n# Can Machine Learning Find Extraordinary Materials?\n\n09 August 2019, Version 1\n\nWorking Paper\n\n## Authors\n\n- [Steven Kauwe](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Steven%20Kauwe)[![Author ORCID: We display the ORCID iD icon alongside authors names on our website to acknowledge that the ORCiD has been authenticated when entered by the user. To view the users ORCiD record click the icon. [opens in a new tab]](https://chemrxiv.org/engage/assets/public/chemrxiv/images/logos/orcid.png)](https://orcid.org/0000-0002-7352-5532),\n- [Jake Graser](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Jake%20Graser),\n- [Ryan Murdock](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Ryan%20Murdock),\n- [Taylor Sparks](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Taylor%20Sparks)\n\n[Show author details](https://chemrxiv.org/engage/chemrxiv/article-details/60c743ab567dfed2f4ec4141)\n\n![](https://chemrxiv.org/engage/_nuxt/img/NonPeerReviewed.5753084.svg)This content is a preprint and has not undergone peer review at the time of posting.\n\nDownload\n\nCite\n\nComment\n\n## Abstract\n\nOne of the most common criticisms of machine learning is an\nassumed inability for models to extrapolate, i.e. to identify extraordinary\nmaterials with properties beyond those present in the training data set. To\ninvestigate whether this is indeed the case, this work takes advantage of\ndensity functional theory calculated properties (bulk modulus, shear modulus,\nthermal conductivity, thermal expansion, band gap and Debye temperature) to\ninvestigate whether machine learning is truly capable of predicting materials\nwith properties that extend beyond previously seen values. We refer to these\nmaterials as extraordinary, meaning they represent the top 1% of values in the\navailable data set. Interestingly, we show that even when machine learning is\ntrained on a fraction of the bottom 99% we can consistently identify 3/4 of the\nhighest performing compositions for all considered properties with a precision\nthat is typically above 0.5. Moreover, we investigate a few different modeling\nchoices and demonstrate how a classification approach can identify an\nequivalent amount of extraordinary compounds but with significantly fewer false\npositives than a regression approach. Finally, we discuss cautions and\npotential limitations in implementing such an approach to discover new\nrecord-breaking materials.\n\n## Keywords\n\n[Machine learning](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Machine%20learning)\n\n[Extrapolation](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Extrapolation)\n\n[Materials screening](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Materials%20screening)\n\n[Materials Informatics](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Materials%20Informatics)\n\n[Support vector machine](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Support%20vector%20machine)\n\n[regression](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=regression)\n\n[chemical white space](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=chemical%20white%20space)\n\n[materials discovery](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=materials%20discovery)\n\n## Comments\n\nYou are signed in as . Your name will appear\nwith any comment you post.\n\nComments are not moderated before they are posted, but they can be removed\nby the site moderators if they are found to be in contravention of our\n[Commenting Policy\\\n\\[opens in a new tab\\]](https://chemrxiv.org/engage/chemrxiv/about-information?show=commenting-policy)\n\\- please read this policy before you post. Comments should be used for\nscholarly discussion of the content in question. You can\n[find more information about how to use the commenting feature here\\\n\\[opens in a new tab\\]](https://chemrxiv.org/engage/chemrxiv/contact-information?show=faqs)\n.\n\n\u200b\n\n300 words allowed\n\nYou can enter up to 300 words.\nPost comment\n\nLog in or register with\nORCID to comment\n\nComments are not moderated before they are posted, but they can be removed\nby the site moderators if they are found to be in contravention of our\n[Commenting Policy\\\n\\[opens in a new tab\\]](https://chemrxiv.org/engage/chemrxiv/about-information?show=commenting-policy)\n\\- please read this policy before you post. Comments should be used for\nscholarly discussion of the content in question. You can\n[find more information about how to use the commenting feature here\\\n\\[opens in a new tab\\]](https://chemrxiv.org/engage/chemrxiv/contact-information?show=faqs)\n.\n\nThis site is protected by reCAPTCHA and the Google\n[Privacy Policy\\\n\\[opens in a new tab\\]](https://policies.google.com/privacy)\nand\n[Terms of Service\\\n\\[opens in a new tab\\]](https://policies.google.com/terms)\napply.\n\n## Now Published\n\n[**Can machine learning find extraordinary materials?**\\[opens in a new tab\\]](https://doi.org/10.1016/j.commatsci.2019.109498)\n\nSteven K. Kauwe, Jake Graser, Ryan Murdock, Taylor D. Sparksjournal article\n\n_Computational Materials Science_, Volume 174\n\nPrint publication date: Mar, 2020\n\n## Version History\n\nAug 09, 2019 Version 1\n\n## Metrics\n\n5,440\n\n1,671\n\n0\n\nViews\n\nDownloads\n\nCitations\n\n## License\n\n![CC logo](https://chemrxiv.org/engage/_nuxt/img/cc.e3defa7.svg)\n\nCC\n\n![BY logo](https://chemrxiv.org/engage/_nuxt/img/by.7813b57.svg)\n\nBY\n\n![NC logo](https://chemrxiv.org/engage/_nuxt/img/nc.e378f90.svg)\n\nNC\n\n![ND logo](https://chemrxiv.org/engage/_nuxt/img/nd.7966b83.svg)\n\nND\n\nThe content is available under\n[CC BY NC ND 4.0\\[opens in a new tab\\]](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n\n## DOI\n\n[10.26434/chemrxiv.9396623.v1\\\nD O I: 10.26434/chemrxiv.9396623.v1 \\[opens in a new tab\\]](https://doi.org/10.26434/chemrxiv.9396623.v1)\n\n## Funding\n\nNSF 1651668\n\n## Author\u2019s competing interest statement\n\nNo conflict of interest\n\n## Share",
      "url": "https://chemrxiv.org/engage/chemrxiv/article-details/60c743ab567dfed2f4ec4141"
    }
  ]
}