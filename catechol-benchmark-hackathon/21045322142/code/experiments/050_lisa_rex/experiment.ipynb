{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6072fe12",
   "metadata": {},
   "source": [
    "# Experiment 050: LISA Selective Augmentation + REx Loss\n",
    "\n",
    "**Hypothesis**: Domain adaptation techniques (LISA + REx) can learn domain-invariant predictors that generalize better to unseen solvents.\n",
    "\n",
    "**Based on**: \n",
    "- ICML 2022 paper \"Improving Out-of-Distribution Robustness via Selective Augmentation\" (LISA)\n",
    "- \"Out-of-Distribution Generalization via Risk Extrapolation\" (REx)\n",
    "\n",
    "**Implementation**:\n",
    "1. LISA: Interpolate samples with similar labels but different solvents\n",
    "2. REx: Penalize variance of per-solvent losses\n",
    "3. Use the exp_030 architecture (GP + MLP + LGBM)\n",
    "\n",
    "**Success criteria**:\n",
    "- Not just better CV, but better worst-case performance\n",
    "- Lower variance of per-solvent errors\n",
    "- If CV is similar but per-solvent variance is lower, this could change the CV-LB relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc986696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T01:47:38.143217Z",
     "iopub.status.busy": "2026-01-16T01:47:38.142499Z",
     "iopub.status.idle": "2026-01-16T01:47:40.637626Z",
     "shell.execute_reply": "2026-01-16T01:47:40.637072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Single solvent: (656, 3), Mixtures: (1227, 5)\n",
      "Spange: (26, 13), DRFP: (24, 2048)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/code/experiments/049_manual_ood_handling')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, Matern\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "from utils_local import load_data, load_features, generate_leave_one_out_splits, generate_leave_one_ramp_out_splits\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X_single_raw, Y_single = load_data(\"single_solvent\")\n",
    "X_full_raw, Y_full = load_data(\"full\")\n",
    "\n",
    "print(f\"Single solvent: {X_single_raw.shape}, Mixtures: {X_full_raw.shape}\")\n",
    "\n",
    "# Load features\n",
    "spange = load_features(\"spange_descriptors\")\n",
    "drfp = load_features(\"drfps_catechol\")\n",
    "print(f\"Spange: {spange.shape}, DRFP: {drfp.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed05807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T01:47:40.639724Z",
     "iopub.status.busy": "2026-01-16T01:47:40.639515Z",
     "iopub.status.idle": "2026-01-16T01:47:40.706122Z",
     "shell.execute_reply": "2026-01-16T01:47:40.705553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent dataset: (656, 2064)\n",
      "Mixture dataset: (1227, 2067)\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets with features\n",
    "def prepare_single_solvent_dataset(X_raw, spange, drfp):\n",
    "    \"\"\"Prepare single solvent dataset with all features\"\"\"\n",
    "    solvent_name = X_raw['SOLVENT NAME'].values\n",
    "    spange_features = spange.loc[solvent_name].values\n",
    "    drfp_features = drfp.loc[solvent_name].values\n",
    "    time = X_raw['Residence Time'].values\n",
    "    temp = X_raw['Temperature'].values\n",
    "    \n",
    "    spange_cols = spange.columns.tolist()\n",
    "    drfp_cols = [f'DRFP_{i}' for i in range(drfp.shape[1])]\n",
    "    \n",
    "    df = pd.DataFrame(spange_features, columns=spange_cols)\n",
    "    df_drfp = pd.DataFrame(drfp_features, columns=drfp_cols)\n",
    "    df = pd.concat([df, df_drfp], axis=1)\n",
    "    df['TEMPERATURE'] = temp\n",
    "    df['TIME'] = time\n",
    "    df['SOLVENT NAME'] = solvent_name\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_mixture_dataset(X_raw, spange, drfp):\n",
    "    \"\"\"Prepare mixture dataset with all features\"\"\"\n",
    "    solvent_a = X_raw['SOLVENT A NAME'].values\n",
    "    solvent_b = X_raw['SOLVENT B NAME'].values\n",
    "    solvent_b_pct = X_raw['SolventB%'].values / 100.0\n",
    "    \n",
    "    spange_a = spange.loc[solvent_a].values\n",
    "    spange_b = spange.loc[solvent_b].values\n",
    "    spange_mix = (1 - solvent_b_pct[:, None]) * spange_a + solvent_b_pct[:, None] * spange_b\n",
    "    \n",
    "    drfp_a = drfp.loc[solvent_a].values\n",
    "    drfp_b = drfp.loc[solvent_b].values\n",
    "    drfp_mix = (1 - solvent_b_pct[:, None]) * drfp_a + solvent_b_pct[:, None] * drfp_b\n",
    "    \n",
    "    solvent_name = [f\"{a}.{b}\" for a, b in zip(solvent_a, solvent_b)]\n",
    "    time = X_raw['Residence Time'].values\n",
    "    temp = X_raw['Temperature'].values\n",
    "    \n",
    "    spange_cols = spange.columns.tolist()\n",
    "    drfp_cols = [f'DRFP_{i}' for i in range(drfp.shape[1])]\n",
    "    \n",
    "    df = pd.DataFrame(spange_mix, columns=spange_cols)\n",
    "    df_drfp = pd.DataFrame(drfp_mix, columns=drfp_cols)\n",
    "    df = pd.concat([df, df_drfp], axis=1)\n",
    "    df['TEMPERATURE'] = temp\n",
    "    df['TIME'] = time\n",
    "    df['SOLVENT NAME'] = solvent_name\n",
    "    df['SOLVENT A NAME'] = solvent_a\n",
    "    df['SOLVENT B NAME'] = solvent_b\n",
    "    df['SolventB%'] = X_raw['SolventB%'].values\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_single = prepare_single_solvent_dataset(X_single_raw, spange, drfp)\n",
    "X_mix = prepare_mixture_dataset(X_full_raw, spange, drfp)\n",
    "\n",
    "print(f\"Single solvent dataset: {X_single.shape}\")\n",
    "print(f\"Mixture dataset: {X_mix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93c9891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T01:47:40.708407Z",
     "iopub.status.busy": "2026-01-16T01:47:40.707897Z",
     "iopub.status.idle": "2026-01-16T01:47:40.714213Z",
     "shell.execute_reply": "2026-01-16T01:47:40.713725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction functions defined\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction functions\n",
    "def get_spange_features(X_data):\n",
    "    spange_cols = ['dielectric constant', 'ET(30)', 'alpha', 'beta', 'pi*', \n",
    "                   'SA', 'SB', 'SP', 'SdP', 'N', 'n', 'f(n)', 'delta']\n",
    "    return X_data[spange_cols].values\n",
    "\n",
    "def get_arrhenius_features(X_data):\n",
    "    T = X_data['TEMPERATURE'].values\n",
    "    t = X_data['TIME'].values\n",
    "    T_kelvin = T + 273.15\n",
    "    inv_T = 1.0 / T_kelvin\n",
    "    ln_t = np.log(t + 1e-6)\n",
    "    interaction = inv_T * ln_t\n",
    "    return np.column_stack([inv_T, ln_t, interaction, T, t])\n",
    "\n",
    "def prepare_features(X_data, drfp_mask=None, include_drfp=True):\n",
    "    spange = get_spange_features(X_data)\n",
    "    arrhenius = get_arrhenius_features(X_data)\n",
    "    \n",
    "    if include_drfp:\n",
    "        drfp_cols = [col for col in X_data.columns if col.startswith('DRFP_')]\n",
    "        drfp_data = X_data[drfp_cols].values\n",
    "        if drfp_mask is not None:\n",
    "            drfp_data = drfp_data[:, drfp_mask]\n",
    "        features = np.hstack([spange, drfp_data, arrhenius])\n",
    "    else:\n",
    "        features = np.hstack([spange, arrhenius])\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"Feature extraction functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd5693d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T01:47:40.715909Z",
     "iopub.status.busy": "2026-01-16T01:47:40.715674Z",
     "iopub.status.idle": "2026-01-16T01:47:40.723215Z",
     "shell.execute_reply": "2026-01-16T01:47:40.722728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LISA augmentation function defined (fixed)\n"
     ]
    }
   ],
   "source": [
    "# LISA Augmentation - Fixed to work with prepared features\n",
    "def lisa_augmentation(X_scaled, Y_values, solvents, alpha=0.5, n_augment=None):\n",
    "    \"\"\"\n",
    "    LISA: Interpolate samples with similar labels but different solvents.\n",
    "    This encourages the model to learn domain-invariant features.\n",
    "    \n",
    "    Args:\n",
    "        X_scaled: Already scaled feature matrix (numpy array)\n",
    "        Y_values: Target values (numpy array)\n",
    "        solvents: Solvent names (numpy array)\n",
    "        alpha: Beta distribution parameter for mixup\n",
    "        n_augment: Number of augmented samples to create\n",
    "    \"\"\"\n",
    "    if n_augment is None:\n",
    "        n_augment = len(X_scaled)  # Augment same number as original\n",
    "    \n",
    "    augmented_X = []\n",
    "    augmented_Y = []\n",
    "    augmented_solvents = []\n",
    "    \n",
    "    for _ in range(n_augment):\n",
    "        # Randomly select a sample\n",
    "        i = np.random.randint(len(X_scaled))\n",
    "        \n",
    "        # Find samples with similar labels but different solvents\n",
    "        label_diff = np.abs(Y_values - Y_values[i]).sum(axis=1)\n",
    "        same_label_mask = label_diff < 0.15  # Threshold for \"similar\" labels\n",
    "        diff_solvent_mask = solvents != solvents[i]\n",
    "        candidates = np.where(same_label_mask & diff_solvent_mask)[0]\n",
    "        \n",
    "        if len(candidates) > 0:\n",
    "            j = np.random.choice(candidates)\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "            \n",
    "            # Interpolate features and labels\n",
    "            x_mix = lam * X_scaled[i] + (1 - lam) * X_scaled[j]\n",
    "            y_mix = lam * Y_values[i] + (1 - lam) * Y_values[j]\n",
    "            \n",
    "            augmented_X.append(x_mix)\n",
    "            augmented_Y.append(y_mix)\n",
    "            augmented_solvents.append('MIXED')\n",
    "    \n",
    "    if len(augmented_X) > 0:\n",
    "        augmented_X = np.array(augmented_X)\n",
    "        augmented_Y = np.array(augmented_Y)\n",
    "        augmented_solvents = np.array(augmented_solvents)\n",
    "        return augmented_X, augmented_Y, augmented_solvents\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "print(\"LISA augmentation function defined (fixed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e37eddb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T01:47:40.724988Z",
     "iopub.status.busy": "2026-01-16T01:47:40.724803Z",
     "iopub.status.idle": "2026-01-16T01:47:40.734094Z",
     "shell.execute_reply": "2026-01-16T01:47:40.733625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP with REx loss defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model with REx Loss\n",
    "class MLPModelREx(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 64], dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, 3))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def train_mlp_rex(X_train, Y_train, solvents, input_dim, epochs=200, lr=5e-4, \n",
    "                  weight_decay=1e-4, hidden_dims=[128, 64], rex_beta=1.0):\n",
    "    \"\"\"\n",
    "    Train MLP with REx loss: penalize variance of per-solvent losses.\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = MLPModelREx(input_dim, hidden_dims=hidden_dims).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=20)\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    Y_tensor = torch.FloatTensor(Y_train).to(device)\n",
    "    \n",
    "    # Get unique solvents and their indices\n",
    "    unique_solvents = np.unique(solvents)\n",
    "    solvent_indices = {s: np.where(solvents == s)[0] for s in unique_solvents}\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_tensor)\n",
    "        \n",
    "        # Compute per-solvent losses\n",
    "        per_solvent_losses = []\n",
    "        for solvent, indices in solvent_indices.items():\n",
    "            if len(indices) > 0:\n",
    "                solvent_loss = F.mse_loss(pred[indices], Y_tensor[indices])\n",
    "                per_solvent_losses.append(solvent_loss)\n",
    "        \n",
    "        if len(per_solvent_losses) > 1:\n",
    "            per_solvent_losses = torch.stack(per_solvent_losses)\n",
    "            mean_loss = torch.mean(per_solvent_losses)\n",
    "            var_loss = torch.var(per_solvent_losses)\n",
    "            \n",
    "            # REx loss = mean + beta * variance\n",
    "            loss = mean_loss + rex_beta * var_loss\n",
    "        else:\n",
    "            loss = F.mse_loss(pred, Y_tensor)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"MLP with REx loss defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbda0fae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T01:47:40.735789Z",
     "iopub.status.busy": "2026-01-16T01:47:40.735575Z",
     "iopub.status.idle": "2026-01-16T01:47:40.749047Z",
     "shell.execute_reply": "2026-01-16T01:47:40.748562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LISARExModel defined (fixed)\n"
     ]
    }
   ],
   "source": [
    "# LISA + REx Model - Fixed\n",
    "class LISARExModel:\n",
    "    \"\"\"\n",
    "    Model that uses LISA augmentation and REx loss for domain-invariant learning.\n",
    "    \"\"\"\n",
    "    def __init__(self, gp_weight=0.15, mlp_weight=0.55, lgbm_weight=0.3, \n",
    "                 lisa_alpha=0.5, rex_beta=1.0):\n",
    "        self.gp_weight = gp_weight\n",
    "        self.mlp_weight = mlp_weight\n",
    "        self.lgbm_weight = lgbm_weight\n",
    "        self.lisa_alpha = lisa_alpha\n",
    "        self.rex_beta = rex_beta\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        self.gp_models = []\n",
    "        self.mlp_models = []\n",
    "        self.lgbm_models = []\n",
    "        \n",
    "        self.drfp_mask = None\n",
    "        self.input_dim = None\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"Train with LISA augmentation and REx loss\"\"\"\n",
    "        # Get DRFP mask\n",
    "        drfp_cols = [col for col in X_train.columns if col.startswith('DRFP_')]\n",
    "        drfp_data = X_train[drfp_cols].values\n",
    "        self.drfp_mask = drfp_data.var(axis=0) > 0\n",
    "        \n",
    "        # Prepare features\n",
    "        X_features = prepare_features(X_train, self.drfp_mask, include_drfp=True)\n",
    "        self.input_dim = X_features.shape[1]\n",
    "        X_scaled = self.scaler.fit_transform(X_features)\n",
    "        \n",
    "        Y_values = Y_train.values\n",
    "        solvents = X_train['SOLVENT NAME'].values\n",
    "        \n",
    "        # Apply LISA augmentation on scaled features\n",
    "        aug_X, aug_Y, aug_solvents = lisa_augmentation(X_scaled, Y_values, solvents, \n",
    "                                                        alpha=self.lisa_alpha)\n",
    "        if aug_X is not None:\n",
    "            # Combine original and augmented data\n",
    "            X_combined = np.vstack([X_scaled, aug_X])\n",
    "            Y_combined = np.vstack([Y_values, aug_Y])\n",
    "            solvents_combined = np.concatenate([solvents, aug_solvents])\n",
    "        else:\n",
    "            X_combined = X_scaled\n",
    "            Y_combined = Y_values\n",
    "            solvents_combined = solvents\n",
    "        \n",
    "        # Train GP (on original data only, for speed)\n",
    "        n_gp = min(200, len(X_scaled))\n",
    "        idx_gp = np.random.choice(len(X_scaled), n_gp, replace=False)\n",
    "        for i in range(3):\n",
    "            kernel = Matern(nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "            gp = GaussianProcessRegressor(kernel=kernel, alpha=0.1, n_restarts_optimizer=2)\n",
    "            gp.fit(X_scaled[idx_gp], Y_values[idx_gp, i])\n",
    "            self.gp_models.append(gp)\n",
    "        \n",
    "        # Train MLP with REx loss (on combined data)\n",
    "        for _ in range(3):\n",
    "            mlp = train_mlp_rex(X_combined, Y_combined, solvents_combined, \n",
    "                               self.input_dim, epochs=200, hidden_dims=[128, 64],\n",
    "                               rex_beta=self.rex_beta)\n",
    "            self.mlp_models.append(mlp)\n",
    "        \n",
    "        # Train LightGBM (on combined data)\n",
    "        lgbm_params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mse',\n",
    "            'learning_rate': 0.03,\n",
    "            'max_depth': 6,\n",
    "            'num_leaves': 31,\n",
    "            'reg_alpha': 0.1,\n",
    "            'reg_lambda': 0.1,\n",
    "            'verbose': -1,\n",
    "            'n_estimators': 500\n",
    "        }\n",
    "        for i in range(3):\n",
    "            model = lgb.LGBMRegressor(**lgbm_params)\n",
    "            model.fit(X_combined, Y_combined[:, i])\n",
    "            self.lgbm_models.append(model)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict using ensemble\"\"\"\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        X_features = prepare_features(X_test, self.drfp_mask, include_drfp=True)\n",
    "        X_scaled = self.scaler.transform(X_features)\n",
    "        \n",
    "        # GP predictions\n",
    "        gp_preds = np.zeros((len(X_test), 3))\n",
    "        for i, gp in enumerate(self.gp_models):\n",
    "            gp_preds[:, i] = gp.predict(X_scaled)\n",
    "        gp_preds = np.clip(gp_preds, 0, 1)\n",
    "        \n",
    "        # MLP predictions\n",
    "        mlp_preds = []\n",
    "        X_tensor = torch.FloatTensor(X_scaled).to(device)\n",
    "        for mlp in self.mlp_models:\n",
    "            mlp.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = mlp(X_tensor).cpu().numpy()\n",
    "            mlp_preds.append(pred)\n",
    "        mlp_pred = np.mean(mlp_preds, axis=0)\n",
    "        \n",
    "        # LightGBM predictions\n",
    "        lgbm_pred = np.zeros((len(X_test), 3))\n",
    "        for i, model in enumerate(self.lgbm_models):\n",
    "            lgbm_pred[:, i] = model.predict(X_scaled)\n",
    "        lgbm_pred = np.clip(lgbm_pred, 0, 1)\n",
    "        \n",
    "        # Ensemble\n",
    "        final_pred = self.gp_weight * gp_preds + self.mlp_weight * mlp_pred + self.lgbm_weight * lgbm_pred\n",
    "        \n",
    "        return np.clip(final_pred, 0, 1)\n",
    "\n",
    "print(\"LISARExModel defined (fixed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e085aca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T01:47:40.751189Z",
     "iopub.status.busy": "2026-01-16T01:47:40.750656Z",
     "iopub.status.idle": "2026-01-16T01:51:07.535367Z",
     "shell.execute_reply": "2026-01-16T01:51:07.534520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Single Solvent CV with LISA + REx Model...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folds: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1: 1,1,1,3,3,3-Hexafluoropropan-2-ol             MSE = 0.047835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  2: 2,2,2-Trifluoroethanol                        MSE = 0.019111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  3: 2-Methyltetrahydrofuran [2-MeTHF]             MSE = 0.004584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  4: Acetonitrile                                  MSE = 0.012244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  5: Acetonitrile.Acetic Acid                      MSE = 0.028923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  6: Butanone [MEK]                                MSE = 0.028776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  7: Cyclohexane                                   MSE = 0.008340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  8: DMA [N,N-Dimethylacetamide]                   MSE = 0.010872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  9: Decanol                                       MSE = 0.014774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10: Diethyl Ether [Ether]                         MSE = 0.014629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 11: Dihydrolevoglucosenone (Cyrene)               MSE = 0.007376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 12: Dimethyl Carbonate                            MSE = 0.035863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 13: Ethanol                                       MSE = 0.010598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 14: Ethyl Acetate                                 MSE = 0.002462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 15: Ethyl Lactate                                 MSE = 0.006037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 16: Ethylene Glycol [1,2-Ethanediol]              MSE = 0.014251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 17: IPA [Propan-2-ol]                             MSE = 0.012698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 18: MTBE [tert-Butylmethylether]                  MSE = 0.016111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 19: Methanol                                      MSE = 0.013715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 20: Methyl Propionate                             MSE = 0.010011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 21: THF [Tetrahydrofuran]                         MSE = 0.004474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 22: Water.2,2,2-Trifluoroethanol                  MSE = 0.003622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 23: Water.Acetonitrile                            MSE = 0.016660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 24: tert-Butanol [2-Methylpropan-2-ol]            MSE = 0.002605\n",
      "\n",
      "LISA + REx Single Solvent CV MSE: 0.014455 +/- 0.010858\n"
     ]
    }
   ],
   "source": [
    "# Run CV for single solvents with LISA + REx\n",
    "print(\"Running Single Solvent CV with LISA + REx Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "splits = list(generate_leave_one_out_splits(X_single, Y_single))\n",
    "print(f\"Number of folds: {len(splits)}\")\n",
    "\n",
    "solvent_errors_lisa = {}\n",
    "all_preds_lisa = []\n",
    "all_true_lisa = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(splits):\n",
    "    X_train = X_single.iloc[train_idx]\n",
    "    Y_train = Y_single.iloc[train_idx]\n",
    "    X_test = X_single.iloc[test_idx]\n",
    "    Y_test = Y_single.iloc[test_idx]\n",
    "    \n",
    "    test_solvent = X_test['SOLVENT NAME'].iloc[0]\n",
    "    \n",
    "    # Train model with LISA + REx\n",
    "    model = LISARExModel(lisa_alpha=0.5, rex_beta=1.0)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predict\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = np.mean((preds - Y_test.values) ** 2)\n",
    "    solvent_errors_lisa[test_solvent] = mse\n",
    "    \n",
    "    all_preds_lisa.append(preds)\n",
    "    all_true_lisa.append(Y_test.values)\n",
    "    \n",
    "    print(f\"Fold {fold_idx+1:2d}: {test_solvent:45s} MSE = {mse:.6f}\")\n",
    "\n",
    "all_preds_lisa = np.vstack(all_preds_lisa)\n",
    "all_true_lisa = np.vstack(all_true_lisa)\n",
    "single_mse_lisa = np.mean((all_preds_lisa - all_true_lisa) ** 2)\n",
    "single_std_lisa = np.std([solvent_errors_lisa[s] for s in solvent_errors_lisa])\n",
    "\n",
    "print(f\"\\nLISA + REx Single Solvent CV MSE: {single_mse_lisa:.6f} +/- {single_std_lisa:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-solvent errors\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Per-Solvent Error Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sorted_errors = sorted(solvent_errors_lisa.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 10 highest error solvents:\")\n",
    "for i, (solvent, mse) in enumerate(sorted_errors[:10]):\n",
    "    print(f\"  {i+1:2d}. {solvent:40s}: {mse:.6f}\")\n",
    "\n",
    "print(\"\\nTop 10 lowest error solvents:\")\n",
    "for i, (solvent, mse) in enumerate(sorted_errors[-10:]):\n",
    "    print(f\"  {i+1:2d}. {solvent:40s}: {mse:.6f}\")\n",
    "\n",
    "# Calculate variance of per-solvent errors\n",
    "error_variance = np.var(list(solvent_errors_lisa.values()))\n",
    "print(f\"\\nVariance of per-solvent errors: {error_variance:.6f}\")\n",
    "print(f\"Std dev of per-solvent errors: {np.sqrt(error_variance):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd987dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV for mixtures with LISA + REx\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Running Mixture CV with LISA + REx Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mix_splits = list(generate_leave_one_ramp_out_splits(X_mix, Y_full))\n",
    "print(f\"Number of folds: {len(mix_splits)}\")\n",
    "\n",
    "mix_errors_lisa = {}\n",
    "mix_preds_lisa = []\n",
    "mix_true_lisa = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(mix_splits):\n",
    "    X_train = X_mix.iloc[train_idx]\n",
    "    Y_train = Y_full.iloc[train_idx]\n",
    "    X_test = X_mix.iloc[test_idx]\n",
    "    Y_test = Y_full.iloc[test_idx]\n",
    "    \n",
    "    test_mixture = X_test['SOLVENT NAME'].iloc[0]\n",
    "    \n",
    "    # Train model with LISA + REx\n",
    "    model = LISARExModel(lisa_alpha=0.5, rex_beta=1.0)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predict\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = np.mean((preds - Y_test.values) ** 2)\n",
    "    mix_errors_lisa[test_mixture] = mse\n",
    "    \n",
    "    mix_preds_lisa.append(preds)\n",
    "    mix_true_lisa.append(Y_test.values)\n",
    "    \n",
    "    print(f\"Fold {fold_idx+1:2d}: {test_mixture:55s} MSE = {mse:.6f}\")\n",
    "\n",
    "mix_preds_lisa = np.vstack(mix_preds_lisa)\n",
    "mix_true_lisa = np.vstack(mix_true_lisa)\n",
    "mix_mse_lisa = np.mean((mix_preds_lisa - mix_true_lisa) ** 2)\n",
    "mix_std_lisa = np.std([mix_errors_lisa[s] for s in mix_errors_lisa])\n",
    "\n",
    "print(f\"\\nLISA + REx Mixture CV MSE: {mix_mse_lisa:.6f} +/- {mix_std_lisa:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6321617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall CV score\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LISA + REx Model Overall Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_single = len(all_true_lisa)\n",
    "n_mix = len(mix_true_lisa)\n",
    "n_total = n_single + n_mix\n",
    "\n",
    "overall_mse_lisa = (n_single * single_mse_lisa + n_mix * mix_mse_lisa) / n_total\n",
    "\n",
    "print(f\"\\nSingle Solvent CV MSE: {single_mse_lisa:.6f} +/- {single_std_lisa:.6f} (n={n_single})\")\n",
    "print(f\"Mixture CV MSE: {mix_mse_lisa:.6f} +/- {mix_std_lisa:.6f} (n={n_mix})\")\n",
    "print(f\"Overall CV MSE: {overall_mse_lisa:.6f}\")\n",
    "\n",
    "print(f\"\\nBaseline (exp_030): CV = 0.008298\")\n",
    "print(f\"Improvement: {(0.008298 - overall_mse_lisa) / 0.008298 * 100:.1f}%\")\n",
    "\n",
    "if overall_mse_lisa < 0.008298:\n",
    "    print(\"\\n✓ BETTER than baseline!\")\n",
    "else:\n",
    "    print(\"\\n✗ WORSE than baseline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc84d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 050 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nLISA + REx Model:\")\n",
    "print(f\"  Single Solvent CV: {single_mse_lisa:.6f}\")\n",
    "print(f\"  Mixture CV: {mix_mse_lisa:.6f}\")\n",
    "print(f\"  Overall CV: {overall_mse_lisa:.6f}\")\n",
    "print(f\"  vs Baseline: {(overall_mse_lisa - 0.008298) / 0.008298 * 100:+.1f}%\")\n",
    "\n",
    "print(f\"\\nPer-solvent error variance: {error_variance:.6f}\")\n",
    "print(f\"Per-solvent error std: {np.sqrt(error_variance):.6f}\")\n",
    "\n",
    "print(\"\\nKey insights:\")\n",
    "print(\"1. LISA augmentation creates interpolated samples across solvents\")\n",
    "print(\"2. REx loss penalizes variance of per-solvent losses\")\n",
    "print(\"3. Together they encourage domain-invariant features\")\n",
    "\n",
    "if overall_mse_lisa < 0.008298:\n",
    "    print(\"\\nCONCLUSION: LISA + REx IMPROVES overall CV!\")\n",
    "    print(\"Consider submitting to test if this changes the CV-LB relationship.\")\n",
    "else:\n",
    "    print(\"\\nCONCLUSION: LISA + REx does NOT improve overall CV.\")\n",
    "    print(\"The domain adaptation techniques don't help for this problem.\")\n",
    "\n",
    "print(f\"\\nRemaining submissions: 5\")\n",
    "print(f\"Best model: exp_030 (GP 0.15 + MLP 0.55 + LGBM 0.3) with CV 0.008298, LB 0.0877\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
