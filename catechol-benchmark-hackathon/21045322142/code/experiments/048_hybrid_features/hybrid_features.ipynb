{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06efdee7",
   "metadata": {},
   "source": [
    "# Experiment 048: Hybrid Feature Ensemble\n",
    "\n",
    "**Key Insight from exp_047:** Simpler features (Spange only) dramatically reduced error on outlier solvents:\n",
    "- Cyclohexane: 0.014 vs 0.198 (93% better!)\n",
    "- HFIP: 0.040 vs 0.096 (58% better!)\n",
    "\n",
    "But simpler features hurt overall CV (13.2% worse).\n",
    "\n",
    "**Hypothesis:** Combine strengths of both approaches:\n",
    "- Model A: Full features (Spange + DRFP) - good for in-distribution solvents\n",
    "- Model B: Simple features (Spange only) - good for OOD solvents\n",
    "- Adaptive weighting based on solvent similarity to training set\n",
    "\n",
    "**Implementation:**\n",
    "1. Compute similarity of test solvent to training solvents (using Spange descriptors)\n",
    "2. If similar (in-distribution): weight Model A higher\n",
    "3. If dissimilar (out-of-distribution): weight Model B higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa57538e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:38:14.040670Z",
     "iopub.status.busy": "2026-01-16T00:38:14.040120Z",
     "iopub.status.idle": "2026-01-16T00:38:16.834290Z",
     "shell.execute_reply": "2026-01-16T00:38:16.833418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256590f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:38:16.837397Z",
     "iopub.status.busy": "2026-01-16T00:38:16.836566Z",
     "iopub.status.idle": "2026-01-16T00:38:16.908551Z",
     "shell.execute_reply": "2026-01-16T00:38:16.907853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: 13 features\n",
      "DRFP: 2048 features\n",
      "Single solvent: 656 samples\n",
      "Full data: 1227 samples\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[[\"SM\", \"Product 2\", \"Product 3\"]]\n",
    "    return X, Y\n",
    "\n",
    "# Load feature lookup tables\n",
    "spange_df = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "drfp_df = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "\n",
    "SPANGE_COLS = [c for c in spange_df.columns if c != 'solvent smiles']\n",
    "DRFP_COLS = [c for c in drfp_df.columns if str(c).isdigit() or isinstance(c, int)]\n",
    "\n",
    "print(f'Spange: {len(SPANGE_COLS)} features')\n",
    "print(f'DRFP: {len(DRFP_COLS)} features')\n",
    "\n",
    "# Load data\n",
    "X_single, Y_single = load_data('single_solvent')\n",
    "X_full, Y_full = load_data('full')\n",
    "\n",
    "print(f'Single solvent: {len(X_single)} samples')\n",
    "print(f'Full data: {len(X_full)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "975b4e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:38:16.911042Z",
     "iopub.status.busy": "2026-01-16T00:38:16.910609Z",
     "iopub.status.idle": "2026-01-16T00:38:16.924889Z",
     "shell.execute_reply": "2026-01-16T00:38:16.924250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction functions defined\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction functions\n",
    "def get_features_full(X, data_type='single'):\n",
    "    \"\"\"Full features: Spange + DRFP + kinetics.\"\"\"\n",
    "    features_list = []\n",
    "    \n",
    "    for idx, row in X.iterrows():\n",
    "        time_m = row['Residence Time']\n",
    "        temp_c = row['Temperature']\n",
    "        temp_k = temp_c + 273.15\n",
    "        \n",
    "        kinetics = np.array([time_m, temp_c, 1.0/temp_k, np.log(time_m+1), time_m/temp_k], dtype=np.float32)\n",
    "        \n",
    "        if data_type == 'single':\n",
    "            solvent = row['SOLVENT NAME']\n",
    "            spange = spange_df.loc[solvent, SPANGE_COLS].values.astype(np.float32) if solvent in spange_df.index else np.zeros(len(SPANGE_COLS), dtype=np.float32)\n",
    "            drfp = drfp_df.loc[solvent, DRFP_COLS].values.astype(np.float32) if solvent in drfp_df.index else np.zeros(len(DRFP_COLS), dtype=np.float32)\n",
    "        else:\n",
    "            solvent_a, solvent_b = row['SOLVENT A NAME'], row['SOLVENT B NAME']\n",
    "            pct_b = row['SolventB%'] / 100.0\n",
    "            pct_a = 1 - pct_b\n",
    "            \n",
    "            sp_a = spange_df.loc[solvent_a, SPANGE_COLS].values.astype(np.float32) if solvent_a in spange_df.index else np.zeros(len(SPANGE_COLS), dtype=np.float32)\n",
    "            sp_b = spange_df.loc[solvent_b, SPANGE_COLS].values.astype(np.float32) if solvent_b in spange_df.index else np.zeros(len(SPANGE_COLS), dtype=np.float32)\n",
    "            spange = pct_a * sp_a + pct_b * sp_b\n",
    "            \n",
    "            dr_a = drfp_df.loc[solvent_a, DRFP_COLS].values.astype(np.float32) if solvent_a in drfp_df.index else np.zeros(len(DRFP_COLS), dtype=np.float32)\n",
    "            dr_b = drfp_df.loc[solvent_b, DRFP_COLS].values.astype(np.float32) if solvent_b in drfp_df.index else np.zeros(len(DRFP_COLS), dtype=np.float32)\n",
    "            drfp = pct_a * dr_a + pct_b * dr_b\n",
    "        \n",
    "        features = np.concatenate([kinetics, spange, drfp])\n",
    "        features_list.append(features)\n",
    "    \n",
    "    return np.array(features_list, dtype=np.float32)\n",
    "\n",
    "def get_features_simple(X, data_type='single'):\n",
    "    \"\"\"Simple features: Spange + kinetics only (no DRFP).\"\"\"\n",
    "    features_list = []\n",
    "    \n",
    "    for idx, row in X.iterrows():\n",
    "        time_m = row['Residence Time']\n",
    "        temp_c = row['Temperature']\n",
    "        temp_k = temp_c + 273.15\n",
    "        \n",
    "        kinetics = np.array([time_m, temp_c, 1.0/temp_k, np.log(time_m+1), time_m/temp_k], dtype=np.float32)\n",
    "        \n",
    "        if data_type == 'single':\n",
    "            solvent = row['SOLVENT NAME']\n",
    "            spange = spange_df.loc[solvent, SPANGE_COLS].values.astype(np.float32) if solvent in spange_df.index else np.zeros(len(SPANGE_COLS), dtype=np.float32)\n",
    "        else:\n",
    "            solvent_a, solvent_b = row['SOLVENT A NAME'], row['SOLVENT B NAME']\n",
    "            pct_b = row['SolventB%'] / 100.0\n",
    "            pct_a = 1 - pct_b\n",
    "            \n",
    "            sp_a = spange_df.loc[solvent_a, SPANGE_COLS].values.astype(np.float32) if solvent_a in spange_df.index else np.zeros(len(SPANGE_COLS), dtype=np.float32)\n",
    "            sp_b = spange_df.loc[solvent_b, SPANGE_COLS].values.astype(np.float32) if solvent_b in spange_df.index else np.zeros(len(SPANGE_COLS), dtype=np.float32)\n",
    "            spange = pct_a * sp_a + pct_b * sp_b\n",
    "        \n",
    "        features = np.concatenate([kinetics, spange])\n",
    "        features_list.append(features)\n",
    "    \n",
    "    return np.array(features_list, dtype=np.float32)\n",
    "\n",
    "print('Feature extraction functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d00570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:38:16.927483Z",
     "iopub.status.busy": "2026-01-16T00:38:16.926864Z",
     "iopub.status.idle": "2026-01-16T00:38:16.934335Z",
     "shell.execute_reply": "2026-01-16T00:38:16.933616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModel defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[32, 16]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([nn.Linear(prev_dim, h_dim), nn.BatchNorm1d(h_dim), nn.ReLU(), nn.Dropout(0.3)])\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, 3))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print('MLPModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51df7622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:38:16.936396Z",
     "iopub.status.busy": "2026-01-16T00:38:16.936141Z",
     "iopub.status.idle": "2026-01-16T00:38:16.961362Z",
     "shell.execute_reply": "2026-01-16T00:38:16.960668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of Cyclohexane to training set: 0.9995\n",
      "Similarity of Ethanol to training set: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Compute solvent similarity using Spange descriptors\n",
    "def compute_solvent_similarity(test_solvent, train_solvents):\n",
    "    \"\"\"Compute similarity of test solvent to training solvents.\n",
    "    \n",
    "    Returns a value between 0 (very different) and 1 (very similar).\n",
    "    \"\"\"\n",
    "    # Get Spange descriptors for test solvent\n",
    "    if test_solvent not in spange_df.index:\n",
    "        return 0.5  # Default to middle if unknown\n",
    "    \n",
    "    test_desc = spange_df.loc[test_solvent, SPANGE_COLS].values.reshape(1, -1)\n",
    "    \n",
    "    # Get Spange descriptors for training solvents\n",
    "    train_descs = []\n",
    "    for s in train_solvents:\n",
    "        if s in spange_df.index:\n",
    "            train_descs.append(spange_df.loc[s, SPANGE_COLS].values)\n",
    "    \n",
    "    if len(train_descs) == 0:\n",
    "        return 0.5\n",
    "    \n",
    "    train_descs = np.array(train_descs)\n",
    "    \n",
    "    # Compute cosine similarity to each training solvent\n",
    "    similarities = cosine_similarity(test_desc, train_descs)[0]\n",
    "    \n",
    "    # Return max similarity (how similar is test to the most similar training solvent)\n",
    "    return np.max(similarities)\n",
    "\n",
    "# Test similarity computation\n",
    "test_solvent = 'Cyclohexane'\n",
    "train_solvents = [s for s in X_single['SOLVENT NAME'].unique() if s != test_solvent]\n",
    "sim = compute_solvent_similarity(test_solvent, train_solvents)\n",
    "print(f\"Similarity of {test_solvent} to training set: {sim:.4f}\")\n",
    "\n",
    "test_solvent = 'Ethanol'\n",
    "sim = compute_solvent_similarity(test_solvent, train_solvents)\n",
    "print(f\"Similarity of {test_solvent} to training set: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365f157b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:38:16.963552Z",
     "iopub.status.busy": "2026-01-16T00:38:16.963341Z",
     "iopub.status.idle": "2026-01-16T00:38:16.984168Z",
     "shell.execute_reply": "2026-01-16T00:38:16.983478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridFeatureEnsemble defined\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Feature Ensemble Model\n",
    "class HybridFeatureEnsemble:\n",
    "    \"\"\"Ensemble that adaptively weights full vs simple features based on solvent similarity.\n",
    "    \n",
    "    - For in-distribution solvents (high similarity): use full features (Spange + DRFP)\n",
    "    - For OOD solvents (low similarity): use simple features (Spange only)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', similarity_threshold=0.9, alpha_id=0.8, alpha_ood=0.2):\n",
    "        self.data_type = data\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.alpha_id = alpha_id  # Weight for full features when in-distribution\n",
    "        self.alpha_ood = alpha_ood  # Weight for full features when OOD\n",
    "        \n",
    "        # Model A: Full features (GP + MLP + LGBM)\n",
    "        self.scaler_full = None\n",
    "        self.gp_models_full = []\n",
    "        self.mlp_models_full = []\n",
    "        self.lgbm_models_full = []\n",
    "        \n",
    "        # Model B: Simple features (MLP + LGBM)\n",
    "        self.scaler_simple = None\n",
    "        self.mlp_models_simple = []\n",
    "        self.lgbm_models_simple = []\n",
    "        \n",
    "        self.train_solvents = None\n",
    "    \n",
    "    def train_model(self, X_train, y_train, epochs=200):\n",
    "        y_np = y_train.values.astype(np.float32)\n",
    "        \n",
    "        # Store training solvents for similarity computation\n",
    "        if self.data_type == 'single':\n",
    "            self.train_solvents = X_train['SOLVENT NAME'].unique().tolist()\n",
    "        else:\n",
    "            self.train_solvents = X_train['SOLVENT A NAME'].unique().tolist()\n",
    "        \n",
    "        # === Train Model A: Full features ===\n",
    "        X_full = get_features_full(X_train, self.data_type)\n",
    "        self.scaler_full = StandardScaler()\n",
    "        X_full_scaled = self.scaler_full.fit_transform(X_full)\n",
    "        \n",
    "        # GP models (use only first 18 features)\n",
    "        self.gp_models_full = []\n",
    "        for i in range(3):\n",
    "            kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "            gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=2, random_state=42)\n",
    "            gp.fit(X_full_scaled[:, :18], y_np[:, i])\n",
    "            self.gp_models_full.append(gp)\n",
    "        \n",
    "        # MLP models\n",
    "        self.mlp_models_full = []\n",
    "        for _ in range(3):\n",
    "            model = MLPModel(X_full_scaled.shape[1]).to(device)\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "            \n",
    "            X_tensor = torch.tensor(X_full_scaled).to(device)\n",
    "            y_tensor = torch.tensor(y_np).to(device)\n",
    "            dataset = TensorDataset(X_tensor, y_tensor)\n",
    "            loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "            \n",
    "            model.train()\n",
    "            for epoch in range(epochs):\n",
    "                for X_batch, y_batch in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(X_batch)\n",
    "                    loss = nn.MSELoss()(pred, y_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                scheduler.step()\n",
    "            model.eval()\n",
    "            self.mlp_models_full.append(model)\n",
    "        \n",
    "        # LGBM models\n",
    "        self.lgbm_models_full = []\n",
    "        for i in range(3):\n",
    "            lgbm = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.05, max_depth=5, verbose=-1)\n",
    "            lgbm.fit(X_full_scaled, y_np[:, i])\n",
    "            self.lgbm_models_full.append(lgbm)\n",
    "        \n",
    "        # === Train Model B: Simple features ===\n",
    "        X_simple = get_features_simple(X_train, self.data_type)\n",
    "        self.scaler_simple = StandardScaler()\n",
    "        X_simple_scaled = self.scaler_simple.fit_transform(X_simple)\n",
    "        \n",
    "        # MLP models\n",
    "        self.mlp_models_simple = []\n",
    "        for _ in range(3):\n",
    "            model = MLPModel(X_simple_scaled.shape[1]).to(device)\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "            \n",
    "            X_tensor = torch.tensor(X_simple_scaled).to(device)\n",
    "            y_tensor = torch.tensor(y_np).to(device)\n",
    "            dataset = TensorDataset(X_tensor, y_tensor)\n",
    "            loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "            \n",
    "            model.train()\n",
    "            for epoch in range(epochs):\n",
    "                for X_batch, y_batch in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(X_batch)\n",
    "                    loss = nn.MSELoss()(pred, y_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                scheduler.step()\n",
    "            model.eval()\n",
    "            self.mlp_models_simple.append(model)\n",
    "        \n",
    "        # LGBM models\n",
    "        self.lgbm_models_simple = []\n",
    "        for i in range(3):\n",
    "            lgbm = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.05, max_depth=5, verbose=-1)\n",
    "            lgbm.fit(X_simple_scaled, y_np[:, i])\n",
    "            self.lgbm_models_simple.append(lgbm)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # Get features\n",
    "        X_full = get_features_full(X_test, self.data_type)\n",
    "        X_full_scaled = self.scaler_full.transform(X_full)\n",
    "        \n",
    "        X_simple = get_features_simple(X_test, self.data_type)\n",
    "        X_simple_scaled = self.scaler_simple.transform(X_simple)\n",
    "        \n",
    "        # Model A predictions (full features)\n",
    "        gp_preds = np.zeros((len(X_test), 3))\n",
    "        for i, gp in enumerate(self.gp_models_full):\n",
    "            gp_preds[:, i] = gp.predict(X_full_scaled[:, :18])\n",
    "        \n",
    "        mlp_preds_full = []\n",
    "        for model in self.mlp_models_full:\n",
    "            with torch.no_grad():\n",
    "                pred = model(torch.tensor(X_full_scaled).to(device)).cpu().numpy()\n",
    "            mlp_preds_full.append(pred)\n",
    "        mlp_preds_full = np.mean(mlp_preds_full, axis=0)\n",
    "        \n",
    "        lgbm_preds_full = np.zeros((len(X_test), 3))\n",
    "        for i, lgbm in enumerate(self.lgbm_models_full):\n",
    "            lgbm_preds_full[:, i] = lgbm.predict(X_full_scaled)\n",
    "        \n",
    "        pred_full = 0.15 * gp_preds + 0.55 * mlp_preds_full + 0.3 * lgbm_preds_full\n",
    "        \n",
    "        # Model B predictions (simple features)\n",
    "        mlp_preds_simple = []\n",
    "        for model in self.mlp_models_simple:\n",
    "            with torch.no_grad():\n",
    "                pred = model(torch.tensor(X_simple_scaled).to(device)).cpu().numpy()\n",
    "            mlp_preds_simple.append(pred)\n",
    "        mlp_preds_simple = np.mean(mlp_preds_simple, axis=0)\n",
    "        \n",
    "        lgbm_preds_simple = np.zeros((len(X_test), 3))\n",
    "        for i, lgbm in enumerate(self.lgbm_models_simple):\n",
    "            lgbm_preds_simple[:, i] = lgbm.predict(X_simple_scaled)\n",
    "        \n",
    "        pred_simple = 0.6 * mlp_preds_simple + 0.4 * lgbm_preds_simple\n",
    "        \n",
    "        # Adaptive weighting based on solvent similarity\n",
    "        final_preds = []\n",
    "        for idx, row in X_test.iterrows():\n",
    "            if self.data_type == 'single':\n",
    "                test_solvent = row['SOLVENT NAME']\n",
    "            else:\n",
    "                test_solvent = row['SOLVENT A NAME']\n",
    "            \n",
    "            similarity = compute_solvent_similarity(test_solvent, self.train_solvents)\n",
    "            \n",
    "            # Adaptive alpha: higher similarity -> more weight on full features\n",
    "            if similarity >= self.similarity_threshold:\n",
    "                alpha = self.alpha_id  # In-distribution: use mostly full features\n",
    "            else:\n",
    "                alpha = self.alpha_ood  # OOD: use mostly simple features\n",
    "            \n",
    "            i = X_test.index.get_loc(idx)\n",
    "            final_pred = alpha * pred_full[i] + (1 - alpha) * pred_simple[i]\n",
    "            final_preds.append(final_pred)\n",
    "        \n",
    "        final_preds = np.array(final_preds)\n",
    "        final_preds = np.clip(final_preds, 0, 1)\n",
    "        \n",
    "        return torch.tensor(final_preds, dtype=torch.float32)\n",
    "\n",
    "print('HybridFeatureEnsemble defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15caa3f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T00:38:40.239152Z",
     "iopub.status.busy": "2026-01-16T00:38:40.238496Z",
     "iopub.status.idle": "2026-01-16T01:05:38.994041Z",
     "shell.execute_reply": "2026-01-16T01:05:38.993449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hybrid feature ensemble on single solvent data...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,1,3,3,3-Hexafluoropropan-2-ol: MSE = 0.038187, Similarity = 0.9952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,2,2-Trifluoroethanol: MSE = 0.015347, Similarity = 0.9984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-Methyltetrahydrofuran [2-MeTHF]: MSE = 0.002187, Similarity = 0.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acetonitrile: MSE = 0.008555, Similarity = 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acetonitrile.Acetic Acid: MSE = 0.021528, Similarity = 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Butanone [MEK]: MSE = 0.004194, Similarity = 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cyclohexane: MSE = 0.004116, Similarity = 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMA [N,N-Dimethylacetamide]: MSE = 0.007208, Similarity = 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decanol: MSE = 0.012753, Similarity = 0.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diethyl Ether [Ether]: MSE = 0.012611, Similarity = 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dihydrolevoglucosenone (Cyrene): MSE = 0.007900, Similarity = 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimethyl Carbonate: MSE = 0.012755, Similarity = 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethanol: MSE = 0.002654, Similarity = 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethyl Acetate: MSE = 0.001168, Similarity = 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethyl Lactate: MSE = 0.002163, Similarity = 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethylene Glycol [1,2-Ethanediol]: MSE = 0.014847, Similarity = 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPA [Propan-2-ol]: MSE = 0.011289, Similarity = 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTBE [tert-Butylmethylether]: MSE = 0.007583, Similarity = 0.9989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methanol: MSE = 0.004234, Similarity = 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methyl Propionate: MSE = 0.001243, Similarity = 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THF [Tetrahydrofuran]: MSE = 0.001263, Similarity = 0.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water.2,2,2-Trifluoroethanol: MSE = 0.004976, Similarity = 0.9983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water.Acetonitrile: MSE = 0.011855, Similarity = 0.9923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tert-Butanol [2-Methylpropan-2-ol]: MSE = 0.002610, Similarity = 0.9991\n",
      "\n",
      "=== Hybrid Feature Ensemble CV Results ===\n",
      "Mean MSE: 0.008884 +/- 0.008128\n",
      "Baseline (exp_030): CV = 0.008298\n"
     ]
    }
   ],
   "source": [
    "# Test hybrid feature ensemble on single solvent data\n",
    "print(\"Testing hybrid feature ensemble on single solvent data...\")\n",
    "print()\n",
    "\n",
    "all_solvents = sorted(X_single[\"SOLVENT NAME\"].unique())\n",
    "fold_mses = []\n",
    "fold_details = []\n",
    "\n",
    "for test_solvent in all_solvents:\n",
    "    mask = X_single[\"SOLVENT NAME\"] != test_solvent\n",
    "    \n",
    "    model = HybridFeatureEnsemble(data='single', similarity_threshold=0.9, alpha_id=0.8, alpha_ood=0.2)\n",
    "    model.train_model(X_single[mask], Y_single[mask], epochs=150)\n",
    "    preds = model.predict(X_single[~mask])\n",
    "    \n",
    "    actuals = Y_single[~mask].values\n",
    "    mse = np.mean((actuals - preds.numpy())**2)\n",
    "    fold_mses.append(mse)\n",
    "    \n",
    "    # Compute similarity for this fold\n",
    "    train_solvents = [s for s in all_solvents if s != test_solvent]\n",
    "    sim = compute_solvent_similarity(test_solvent, train_solvents)\n",
    "    fold_details.append((test_solvent, mse, sim))\n",
    "    print(f\"{test_solvent}: MSE = {mse:.6f}, Similarity = {sim:.4f}\")\n",
    "\n",
    "mean_mse = np.mean(fold_mses)\n",
    "std_mse = np.std(fold_mses)\n",
    "print(f\"\\n=== Hybrid Feature Ensemble CV Results ===\")\n",
    "print(f\"Mean MSE: {mean_mse:.6f} +/- {std_mse:.6f}\")\n",
    "print(f\"Baseline (exp_030): CV = 0.008298\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
