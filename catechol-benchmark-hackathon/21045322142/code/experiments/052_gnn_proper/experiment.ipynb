{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ebf31d",
   "metadata": {},
   "source": [
    "# Experiment 052: Proper GNN Implementation\n",
    "\n",
    "**Hypothesis**: The GNN benchmark achieved MSE 0.0039 on this exact dataset. A proper GNN with Graph Attention Networks can achieve much better generalization than MLP/LGBM/GP ensembles.\n",
    "\n",
    "**Key differences from exp_040 (failed GNN attempt):**\n",
    "1. Full CV evaluation (all 24 folds for single, 13 for mixtures)\n",
    "2. More training epochs (200 instead of 50)\n",
    "3. Proper molecular graph construction from SMILES\n",
    "4. Learned solvent embeddings combined with graph features\n",
    "5. Arrhenius kinetics features\n",
    "\n",
    "**Architecture:**\n",
    "- Convert SMILES to molecular graphs using RDKit\n",
    "- Use GAT layers to learn solvent representations\n",
    "- Combine with Arrhenius features\n",
    "- MLP head for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec3af3b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:17:39.202700Z",
     "iopub.status.busy": "2026-01-16T02:17:39.201931Z",
     "iopub.status.idle": "2026-01-16T02:17:43.237221Z",
     "shell.execute_reply": "2026-01-16T02:17:43.236620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Geometric version: 2.7.0\n",
      "PyTorch version: 2.2.0+cu118\n",
      "CUDA available: True\n",
      "GPU: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/code/experiments/049_manual_ood_handling')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch Geometric\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "# RDKit for molecular graphs\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711b83f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:17:43.239252Z",
     "iopub.status.busy": "2026-01-16T02:17:43.238902Z",
     "iopub.status.idle": "2026-01-16T02:17:43.299517Z",
     "shell.execute_reply": "2026-01-16T02:17:43.298954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Single solvent: (656, 3), Mixtures: (1227, 5)\n",
      "Spange: (26, 13), DRFP: (24, 2048)\n",
      "SMILES available for 26 solvents\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "from utils_local import load_data, load_features, generate_leave_one_out_splits, generate_leave_one_ramp_out_splits\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X_single_raw, Y_single = load_data(\"single_solvent\")\n",
    "X_full_raw, Y_full = load_data(\"full\")\n",
    "\n",
    "print(f\"Single solvent: {X_single_raw.shape}, Mixtures: {X_full_raw.shape}\")\n",
    "\n",
    "# Load features\n",
    "spange = load_features(\"spange_descriptors\")\n",
    "drfp = load_features(\"drfps_catechol\")\n",
    "smiles_df = pd.read_csv('/home/data/smiles_lookup.csv', index_col=0)\n",
    "\n",
    "print(f\"Spange: {spange.shape}, DRFP: {drfp.shape}\")\n",
    "print(f\"SMILES available for {len(smiles_df)} solvents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c040e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:17:43.301292Z",
     "iopub.status.busy": "2026-01-16T02:17:43.300894Z",
     "iopub.status.idle": "2026-01-16T02:17:43.328455Z",
     "shell.execute_reply": "2026-01-16T02:17:43.327918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building molecular graphs for all solvents...\n",
      "  Cyclohexane: 6 atoms, 6 bonds\n",
      "  Ethyl Acetate: 6 atoms, 5 bonds\n",
      "  Acetic Acid: 4 atoms, 3 bonds\n",
      "  2-Methyltetrahydrofuran [2-MeTHF]: 6 atoms, 6 bonds\n",
      "  1,1,1,3,3,3-Hexafluoropropan-2-ol: 10 atoms, 9 bonds\n",
      "  IPA [Propan-2-ol]: 4 atoms, 3 bonds\n",
      "  Ethanol: 3 atoms, 2 bonds\n",
      "  Methanol: 2 atoms, 1 bonds\n",
      "  Ethylene Glycol [1,2-Ethanediol]: 4 atoms, 3 bonds\n",
      "  Acetonitrile: 3 atoms, 2 bonds\n",
      "  Water: 1 atoms, 0 bonds\n",
      "  Diethyl Ether [Ether]: 5 atoms, 4 bonds\n",
      "  MTBE [tert-Butylmethylether]: 6 atoms, 5 bonds\n",
      "  Dimethyl Carbonate: 6 atoms, 5 bonds\n",
      "  tert-Butanol [2-Methylpropan-2-ol]: 5 atoms, 4 bonds\n",
      "  DMA [N,N-Dimethylacetamide]: 6 atoms, 5 bonds\n",
      "  2,2,2-Trifluoroethanol: 6 atoms, 5 bonds\n",
      "  Dihydrolevoglucosenone (Cyrene): 9 atoms, 10 bonds\n",
      "  Decanol: 11 atoms, 10 bonds\n",
      "  Butanone [MEK]: 5 atoms, 4 bonds\n",
      "  Ethyl Lactate: 8 atoms, 7 bonds\n",
      "  Methyl Propionate: 6 atoms, 5 bonds\n",
      "  THF [Tetrahydrofuran]: 5 atoms, 5 bonds\n",
      "  Water.Acetonitrile: 4 atoms, 2 bonds\n",
      "  Acetonitrile.Acetic Acid: 7 atoms, 5 bonds\n",
      "  Water.2,2,2-Trifluoroethanol: 7 atoms, 5 bonds\n",
      "\n",
      "Successfully built graphs for 26 solvents\n"
     ]
    }
   ],
   "source": [
    "# Molecular graph construction from SMILES\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"\n",
    "    Convert SMILES to PyTorch Geometric Data object.\n",
    "    Node features: atomic number, degree, formal charge, hybridization, aromaticity\n",
    "    Edge features: bond type, is_conjugated, is_in_ring\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    # Node features\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        features = [\n",
    "            atom.GetAtomicNum(),\n",
    "            atom.GetDegree(),\n",
    "            atom.GetFormalCharge(),\n",
    "            int(atom.GetHybridization()),\n",
    "            int(atom.GetIsAromatic()),\n",
    "            atom.GetTotalNumHs(),\n",
    "            int(atom.IsInRing()),\n",
    "        ]\n",
    "        atom_features.append(features)\n",
    "    \n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    \n",
    "    # Edge index and features\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        \n",
    "        # Add both directions\n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])\n",
    "        \n",
    "        # Bond features\n",
    "        bond_features = [\n",
    "            float(bond.GetBondTypeAsDouble()),\n",
    "            int(bond.GetIsConjugated()),\n",
    "            int(bond.IsInRing()),\n",
    "        ]\n",
    "        edge_attr.append(bond_features)\n",
    "        edge_attr.append(bond_features)  # Same for both directions\n",
    "    \n",
    "    if len(edge_index) == 0:\n",
    "        # Single atom molecule\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.zeros((0, 3), dtype=torch.float)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "# Build graph cache for all solvents\n",
    "print(\"Building molecular graphs for all solvents...\")\n",
    "solvent_graphs = {}\n",
    "for solvent_name, row in smiles_df.iterrows():\n",
    "    smiles = row['solvent smiles']\n",
    "    graph = smiles_to_graph(smiles)\n",
    "    if graph is not None:\n",
    "        solvent_graphs[solvent_name] = graph\n",
    "        print(f\"  {solvent_name}: {graph.x.shape[0]} atoms, {graph.edge_index.shape[1]//2} bonds\")\n",
    "    else:\n",
    "        print(f\"  {solvent_name}: FAILED to parse SMILES '{smiles}'\")\n",
    "\n",
    "print(f\"\\nSuccessfully built graphs for {len(solvent_graphs)} solvents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40d9b30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:17:43.330298Z",
     "iopub.status.busy": "2026-01-16T02:17:43.329900Z",
     "iopub.status.idle": "2026-01-16T02:17:43.396120Z",
     "shell.execute_reply": "2026-01-16T02:17:43.395580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent dataset: (656, 2064)\n",
      "Mixture dataset: (1227, 2067)\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets with features\n",
    "def prepare_single_solvent_dataset(X_raw, spange, drfp):\n",
    "    \"\"\"Prepare single solvent dataset with all features\"\"\"\n",
    "    solvent_name = X_raw['SOLVENT NAME'].values\n",
    "    spange_features = spange.loc[solvent_name].values\n",
    "    drfp_features = drfp.loc[solvent_name].values\n",
    "    time = X_raw['Residence Time'].values\n",
    "    temp = X_raw['Temperature'].values\n",
    "    \n",
    "    spange_cols = spange.columns.tolist()\n",
    "    drfp_cols = [f'DRFP_{i}' for i in range(drfp.shape[1])]\n",
    "    \n",
    "    df = pd.DataFrame(spange_features, columns=spange_cols)\n",
    "    df_drfp = pd.DataFrame(drfp_features, columns=drfp_cols)\n",
    "    df = pd.concat([df, df_drfp], axis=1)\n",
    "    df['TEMPERATURE'] = temp\n",
    "    df['TIME'] = time\n",
    "    df['SOLVENT NAME'] = solvent_name\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_mixture_dataset(X_raw, spange, drfp):\n",
    "    \"\"\"Prepare mixture dataset with all features\"\"\"\n",
    "    solvent_a = X_raw['SOLVENT A NAME'].values\n",
    "    solvent_b = X_raw['SOLVENT B NAME'].values\n",
    "    solvent_b_pct = X_raw['SolventB%'].values / 100.0\n",
    "    \n",
    "    spange_a = spange.loc[solvent_a].values\n",
    "    spange_b = spange.loc[solvent_b].values\n",
    "    spange_mix = (1 - solvent_b_pct[:, None]) * spange_a + solvent_b_pct[:, None] * spange_b\n",
    "    \n",
    "    drfp_a = drfp.loc[solvent_a].values\n",
    "    drfp_b = drfp.loc[solvent_b].values\n",
    "    drfp_mix = (1 - solvent_b_pct[:, None]) * drfp_a + solvent_b_pct[:, None] * drfp_b\n",
    "    \n",
    "    solvent_name = [f\"{a}.{b}\" for a, b in zip(solvent_a, solvent_b)]\n",
    "    time = X_raw['Residence Time'].values\n",
    "    temp = X_raw['Temperature'].values\n",
    "    \n",
    "    spange_cols = spange.columns.tolist()\n",
    "    drfp_cols = [f'DRFP_{i}' for i in range(drfp.shape[1])]\n",
    "    \n",
    "    df = pd.DataFrame(spange_mix, columns=spange_cols)\n",
    "    df_drfp = pd.DataFrame(drfp_mix, columns=drfp_cols)\n",
    "    df = pd.concat([df, df_drfp], axis=1)\n",
    "    df['TEMPERATURE'] = temp\n",
    "    df['TIME'] = time\n",
    "    df['SOLVENT NAME'] = solvent_name\n",
    "    df['SOLVENT A NAME'] = solvent_a\n",
    "    df['SOLVENT B NAME'] = solvent_b\n",
    "    df['SolventB%'] = X_raw['SolventB%'].values\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_single = prepare_single_solvent_dataset(X_single_raw, spange, drfp)\n",
    "X_mix = prepare_mixture_dataset(X_full_raw, spange, drfp)\n",
    "\n",
    "print(f\"Single solvent dataset: {X_single.shape}\")\n",
    "print(f\"Mixture dataset: {X_mix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a8088e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:17:43.398072Z",
     "iopub.status.busy": "2026-01-16T02:17:43.397892Z",
     "iopub.status.idle": "2026-01-16T02:17:43.406630Z",
     "shell.execute_reply": "2026-01-16T02:17:43.406081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN models defined\n"
     ]
    }
   ],
   "source": [
    "# GNN Model with GAT layers\n",
    "class SolventGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention Network for solvent representation learning.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_features=7, hidden_dim=64, output_dim=32, heads=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # GAT layers\n",
    "        self.gat1 = GATConv(node_features, hidden_dim, heads=heads, dropout=dropout)\n",
    "        self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=heads, dropout=dropout)\n",
    "        self.gat3 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False, dropout=dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # GAT layers with residual-like connections\n",
    "        x = F.elu(self.gat1(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = F.elu(self.gat2(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = self.gat3(x, edge_index)\n",
    "        \n",
    "        # Global mean pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class GNNYieldPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Full model: GNN for solvent + MLP for prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, gnn_output_dim=32, arrhenius_dim=5, hidden_dim=64, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gnn = SolventGNN(output_dim=gnn_output_dim, dropout=dropout)\n",
    "        \n",
    "        # MLP head\n",
    "        combined_dim = gnn_output_dim + arrhenius_dim\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(combined_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, graph_batch, arrhenius_features):\n",
    "        # Get GNN embeddings\n",
    "        gnn_emb = self.gnn(graph_batch)\n",
    "        \n",
    "        # Combine with Arrhenius features\n",
    "        combined = torch.cat([gnn_emb, arrhenius_features], dim=1)\n",
    "        \n",
    "        # Predict\n",
    "        return self.mlp(combined)\n",
    "\n",
    "print(\"GNN models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "514924ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:17:43.408663Z",
     "iopub.status.busy": "2026-01-16T02:17:43.408483Z",
     "iopub.status.idle": "2026-01-16T02:17:43.420943Z",
     "shell.execute_reply": "2026-01-16T02:17:43.420380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNModel wrapper defined\n"
     ]
    }
   ],
   "source": [
    "# GNN Model wrapper for CV\n",
    "class GNNModel:\n",
    "    \"\"\"\n",
    "    GNN model wrapper that handles training and prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, epochs=200, lr=1e-3, weight_decay=1e-4, dropout=0.2):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.model = None\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.arrhenius_scaler = StandardScaler()\n",
    "    \n",
    "    def _get_arrhenius_features(self, X_data):\n",
    "        \"\"\"Extract Arrhenius kinetics features\"\"\"\n",
    "        T = X_data['TEMPERATURE'].values\n",
    "        t = X_data['TIME'].values\n",
    "        T_kelvin = T + 273.15\n",
    "        inv_T = 1000.0 / T_kelvin\n",
    "        ln_t = np.log(t + 1e-6)\n",
    "        interaction = inv_T * ln_t\n",
    "        return np.column_stack([T, t, inv_T, ln_t, interaction])\n",
    "    \n",
    "    def _get_solvent_graphs(self, X_data):\n",
    "        \"\"\"Get molecular graphs for solvents\"\"\"\n",
    "        graphs = []\n",
    "        solvent_names = X_data['SOLVENT NAME'].values\n",
    "        \n",
    "        for solvent in solvent_names:\n",
    "            # Handle mixture solvents\n",
    "            if '.' in solvent:\n",
    "                # For mixtures, use the first solvent's graph (simplified)\n",
    "                parts = solvent.split('.')\n",
    "                base_solvent = parts[0]\n",
    "            else:\n",
    "                base_solvent = solvent\n",
    "            \n",
    "            if base_solvent in solvent_graphs:\n",
    "                graphs.append(solvent_graphs[base_solvent])\n",
    "            else:\n",
    "                # Fallback: create a dummy graph\n",
    "                print(f\"Warning: No graph for {base_solvent}, using dummy\")\n",
    "                dummy = Data(x=torch.zeros((1, 7)), edge_index=torch.zeros((2, 0), dtype=torch.long))\n",
    "                graphs.append(dummy)\n",
    "        \n",
    "        return graphs\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"Train the GNN model\"\"\"\n",
    "        # Get features\n",
    "        arrhenius = self._get_arrhenius_features(X_train)\n",
    "        arrhenius_scaled = self.arrhenius_scaler.fit_transform(arrhenius)\n",
    "        graphs = self._get_solvent_graphs(X_train)\n",
    "        \n",
    "        Y_values = Y_train.values\n",
    "        \n",
    "        # Create model\n",
    "        self.model = GNNYieldPredictor(dropout=self.dropout).to(self.device)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=20)\n",
    "        criterion = nn.HuberLoss()\n",
    "        \n",
    "        # Convert to tensors\n",
    "        arrhenius_tensor = torch.FloatTensor(arrhenius_scaled).to(self.device)\n",
    "        Y_tensor = torch.FloatTensor(Y_values).to(self.device)\n",
    "        \n",
    "        # Training loop\n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Batch graphs\n",
    "            graph_batch = Batch.from_data_list(graphs).to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred = self.model(graph_batch, arrhenius_tensor)\n",
    "            loss = criterion(pred, Y_tensor)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict using the trained model\"\"\"\n",
    "        # Get features\n",
    "        arrhenius = self._get_arrhenius_features(X_test)\n",
    "        arrhenius_scaled = self.arrhenius_scaler.transform(arrhenius)\n",
    "        graphs = self._get_solvent_graphs(X_test)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        arrhenius_tensor = torch.FloatTensor(arrhenius_scaled).to(self.device)\n",
    "        \n",
    "        # Predict\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            graph_batch = Batch.from_data_list(graphs).to(self.device)\n",
    "            pred = self.model(graph_batch, arrhenius_tensor).cpu().numpy()\n",
    "        \n",
    "        return np.clip(pred, 0, 1)\n",
    "\n",
    "print(\"GNNModel wrapper defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c82db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV for single solvents with GNN\n",
    "print(\"Running Single Solvent CV with GNN Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "splits = list(generate_leave_one_out_splits(X_single, Y_single))\n",
    "print(f\"Number of folds: {len(splits)}\")\n",
    "\n",
    "solvent_errors_gnn = {}\n",
    "all_preds_gnn = []\n",
    "all_true_gnn = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(splits):\n",
    "    X_train = X_single.iloc[train_idx]\n",
    "    Y_train = Y_single.iloc[train_idx]\n",
    "    X_test = X_single.iloc[test_idx]\n",
    "    Y_test = Y_single.iloc[test_idx]\n",
    "    \n",
    "    test_solvent = X_test['SOLVENT NAME'].iloc[0]\n",
    "    \n",
    "    # Train model\n",
    "    model = GNNModel(epochs=200, lr=1e-3, dropout=0.2)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predict\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = np.mean((preds - Y_test.values) ** 2)\n",
    "    solvent_errors_gnn[test_solvent] = mse\n",
    "    \n",
    "    all_preds_gnn.append(preds)\n",
    "    all_true_gnn.append(Y_test.values)\n",
    "    \n",
    "    print(f\"Fold {fold_idx+1:2d}: {test_solvent:45s} MSE = {mse:.6f}\")\n",
    "\n",
    "all_preds_gnn = np.vstack(all_preds_gnn)\n",
    "all_true_gnn = np.vstack(all_true_gnn)\n",
    "single_mse_gnn = np.mean((all_preds_gnn - all_true_gnn) ** 2)\n",
    "single_std_gnn = np.std([solvent_errors_gnn[s] for s in solvent_errors_gnn])\n",
    "\n",
    "print(f\"\\nGNN Single Solvent CV MSE: {single_mse_gnn:.6f} +/- {single_std_gnn:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV for mixtures with GNN\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Running Mixture CV with GNN Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mix_splits = list(generate_leave_one_ramp_out_splits(X_mix, Y_full))\n",
    "print(f\"Number of folds: {len(mix_splits)}\")\n",
    "\n",
    "mix_errors_gnn = {}\n",
    "mix_preds_gnn = []\n",
    "mix_true_gnn = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(mix_splits):\n",
    "    X_train = X_mix.iloc[train_idx]\n",
    "    Y_train = Y_full.iloc[train_idx]\n",
    "    X_test = X_mix.iloc[test_idx]\n",
    "    Y_test = Y_full.iloc[test_idx]\n",
    "    \n",
    "    test_mixture = X_test['SOLVENT NAME'].iloc[0]\n",
    "    \n",
    "    # Train model\n",
    "    model = GNNModel(epochs=200, lr=1e-3, dropout=0.2)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predict\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = np.mean((preds - Y_test.values) ** 2)\n",
    "    mix_errors_gnn[test_mixture] = mse\n",
    "    \n",
    "    mix_preds_gnn.append(preds)\n",
    "    mix_true_gnn.append(Y_test.values)\n",
    "    \n",
    "    print(f\"Fold {fold_idx+1:2d}: {test_mixture:55s} MSE = {mse:.6f}\")\n",
    "\n",
    "mix_preds_gnn = np.vstack(mix_preds_gnn)\n",
    "mix_true_gnn = np.vstack(mix_true_gnn)\n",
    "mix_mse_gnn = np.mean((mix_preds_gnn - mix_true_gnn) ** 2)\n",
    "mix_std_gnn = np.std([mix_errors_gnn[s] for s in mix_errors_gnn])\n",
    "\n",
    "print(f\"\\nGNN Mixture CV MSE: {mix_mse_gnn:.6f} +/- {mix_std_gnn:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall CV score\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GNN Model Overall Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_single = len(all_true_gnn)\n",
    "n_mix = len(mix_true_gnn)\n",
    "n_total = n_single + n_mix\n",
    "\n",
    "overall_mse_gnn = (n_single * single_mse_gnn + n_mix * mix_mse_gnn) / n_total\n",
    "\n",
    "print(f\"\\nSingle Solvent CV MSE: {single_mse_gnn:.6f} +/- {single_std_gnn:.6f} (n={n_single})\")\n",
    "print(f\"Mixture CV MSE: {mix_mse_gnn:.6f} +/- {mix_std_gnn:.6f} (n={n_mix})\")\n",
    "print(f\"Overall CV MSE: {overall_mse_gnn:.6f}\")\n",
    "\n",
    "print(f\"\\nBaseline (exp_030): CV = 0.008298\")\n",
    "print(f\"GNN Benchmark: MSE = 0.0039\")\n",
    "print(f\"Improvement vs baseline: {(0.008298 - overall_mse_gnn) / 0.008298 * 100:.1f}%\")\n",
    "\n",
    "if overall_mse_gnn < 0.008298:\n",
    "    print(\"\\n✓ BETTER than baseline!\")\n",
    "else:\n",
    "    print(\"\\n✗ WORSE than baseline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 052 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nGNN Model:\")\n",
    "print(f\"  Single Solvent CV: {single_mse_gnn:.6f}\")\n",
    "print(f\"  Mixture CV: {mix_mse_gnn:.6f}\")\n",
    "print(f\"  Overall CV: {overall_mse_gnn:.6f}\")\n",
    "print(f\"  vs Baseline (exp_030): {(overall_mse_gnn - 0.008298) / 0.008298 * 100:+.1f}%\")\n",
    "\n",
    "print(\"\\nKey insights:\")\n",
    "print(\"1. GNN uses molecular graph structure from SMILES\")\n",
    "print(\"2. GAT layers learn attention-weighted node aggregation\")\n",
    "print(\"3. Combined with Arrhenius kinetics features\")\n",
    "\n",
    "if overall_mse_gnn < 0.008298:\n",
    "    print(\"\\nCONCLUSION: GNN IMPROVES overall CV!\")\n",
    "    print(\"This is a fundamentally different approach that may change the CV-LB relationship.\")\n",
    "    print(\"Consider submitting to test the new relationship.\")\n",
    "else:\n",
    "    print(\"\\nCONCLUSION: GNN does NOT improve overall CV.\")\n",
    "    print(\"The GNN benchmark's success may be due to different implementation details.\")\n",
    "\n",
    "print(f\"\\nRemaining submissions: 5\")\n",
    "print(f\"Best model: exp_030 (GP 0.15 + MLP 0.55 + LGBM 0.3) with CV 0.008298, LB 0.0877\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
