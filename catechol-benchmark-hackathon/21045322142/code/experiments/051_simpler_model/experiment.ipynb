{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a45bd8",
   "metadata": {},
   "source": [
    "# Experiment 051: Simpler Model Based on exp_000's Best Residual\n",
    "\n",
    "**Hypothesis**: exp_000 has the best residual (-0.002136), meaning it performed BETTER on LB than predicted by its CV. A simpler model may generalize better to LB.\n",
    "\n",
    "**Based on**: exp_000 used:\n",
    "- Spange descriptors (13 features)\n",
    "- Arrhenius kinetics features (3 features)\n",
    "- MLP with hidden_dims=[128, 128, 64], dropout=0.2\n",
    "- 3 models bagged\n",
    "- 200 epochs\n",
    "\n",
    "**This experiment**: Recreate exp_000's approach with stronger regularization to see if we can improve the residual further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85918171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:03:28.288718Z",
     "iopub.status.busy": "2026-01-16T02:03:28.288138Z",
     "iopub.status.idle": "2026-01-16T02:03:30.483411Z",
     "shell.execute_reply": "2026-01-16T02:03:30.482718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Single solvent: (656, 3), Mixtures: (1227, 5)\n",
      "Spange: (26, 13)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/code/experiments/049_manual_ood_handling')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "from utils_local import load_data, load_features, generate_leave_one_out_splits, generate_leave_one_ramp_out_splits\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X_single_raw, Y_single = load_data(\"single_solvent\")\n",
    "X_full_raw, Y_full = load_data(\"full\")\n",
    "\n",
    "print(f\"Single solvent: {X_single_raw.shape}, Mixtures: {X_full_raw.shape}\")\n",
    "\n",
    "# Load features\n",
    "spange = load_features(\"spange_descriptors\")\n",
    "print(f\"Spange: {spange.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab3c857",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:03:30.485480Z",
     "iopub.status.busy": "2026-01-16T02:03:30.485284Z",
     "iopub.status.idle": "2026-01-16T02:03:30.498309Z",
     "shell.execute_reply": "2026-01-16T02:03:30.497845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent dataset: (656, 16)\n",
      "Mixture dataset: (1227, 19)\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets with Spange features ONLY (no DRFP)\n",
    "def prepare_single_solvent_dataset(X_raw, spange):\n",
    "    \"\"\"Prepare single solvent dataset with Spange features only\"\"\"\n",
    "    solvent_name = X_raw['SOLVENT NAME'].values\n",
    "    spange_features = spange.loc[solvent_name].values\n",
    "    time = X_raw['Residence Time'].values\n",
    "    temp = X_raw['Temperature'].values\n",
    "    \n",
    "    spange_cols = spange.columns.tolist()\n",
    "    df = pd.DataFrame(spange_features, columns=spange_cols)\n",
    "    df['TEMPERATURE'] = temp\n",
    "    df['TIME'] = time\n",
    "    df['SOLVENT NAME'] = solvent_name\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_mixture_dataset(X_raw, spange):\n",
    "    \"\"\"Prepare mixture dataset with Spange features only\"\"\"\n",
    "    solvent_a = X_raw['SOLVENT A NAME'].values\n",
    "    solvent_b = X_raw['SOLVENT B NAME'].values\n",
    "    solvent_b_pct = X_raw['SolventB%'].values / 100.0\n",
    "    \n",
    "    spange_a = spange.loc[solvent_a].values\n",
    "    spange_b = spange.loc[solvent_b].values\n",
    "    spange_mix = (1 - solvent_b_pct[:, None]) * spange_a + solvent_b_pct[:, None] * spange_b\n",
    "    \n",
    "    solvent_name = [f\"{a}.{b}\" for a, b in zip(solvent_a, solvent_b)]\n",
    "    time = X_raw['Residence Time'].values\n",
    "    temp = X_raw['Temperature'].values\n",
    "    \n",
    "    spange_cols = spange.columns.tolist()\n",
    "    df = pd.DataFrame(spange_mix, columns=spange_cols)\n",
    "    df['TEMPERATURE'] = temp\n",
    "    df['TIME'] = time\n",
    "    df['SOLVENT NAME'] = solvent_name\n",
    "    df['SOLVENT A NAME'] = solvent_a\n",
    "    df['SOLVENT B NAME'] = solvent_b\n",
    "    df['SolventB%'] = X_raw['SolventB%'].values\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_single = prepare_single_solvent_dataset(X_single_raw, spange)\n",
    "X_mix = prepare_mixture_dataset(X_full_raw, spange)\n",
    "\n",
    "print(f\"Single solvent dataset: {X_single.shape}\")\n",
    "print(f\"Mixture dataset: {X_mix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b408119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:03:30.500181Z",
     "iopub.status.busy": "2026-01-16T02:03:30.499721Z",
     "iopub.status.idle": "2026-01-16T02:03:30.507296Z",
     "shell.execute_reply": "2026-01-16T02:03:30.506840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction functions defined\n",
      "Feature dimension: 13 (Spange) + 5 (Arrhenius) = 18\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction with Arrhenius kinetics (same as exp_000)\n",
    "def get_spange_features(X_data):\n",
    "    spange_cols = ['dielectric constant', 'ET(30)', 'alpha', 'beta', 'pi*', \n",
    "                   'SA', 'SB', 'SP', 'SdP', 'N', 'n', 'f(n)', 'delta']\n",
    "    return X_data[spange_cols].values\n",
    "\n",
    "def get_arrhenius_features(X_data):\n",
    "    \"\"\"Arrhenius kinetics features (same as exp_000)\"\"\"\n",
    "    T = X_data['TEMPERATURE'].values\n",
    "    t = X_data['TIME'].values\n",
    "    T_kelvin = T + 273.15\n",
    "    inv_T = 1000.0 / T_kelvin  # Scaled inverse temperature\n",
    "    ln_t = np.log(t + 1e-6)\n",
    "    interaction = inv_T * ln_t\n",
    "    return np.column_stack([T, t, inv_T, ln_t, interaction])\n",
    "\n",
    "def prepare_features(X_data):\n",
    "    \"\"\"Prepare features (Spange + Arrhenius)\"\"\"\n",
    "    spange = get_spange_features(X_data)\n",
    "    arrhenius = get_arrhenius_features(X_data)\n",
    "    return np.hstack([spange, arrhenius])\n",
    "\n",
    "print(\"Feature extraction functions defined\")\n",
    "print(f\"Feature dimension: 13 (Spange) + 5 (Arrhenius) = 18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee967b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:03:30.508846Z",
     "iopub.status.busy": "2026-01-16T02:03:30.508661Z",
     "iopub.status.idle": "2026-01-16T02:03:30.518965Z",
     "shell.execute_reply": "2026-01-16T02:03:30.518484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple MLP model defined\n"
     ]
    }
   ],
   "source": [
    "# Simple MLP Model (same as exp_000)\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 128, 64], dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = [nn.BatchNorm1d(input_dim)]\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, 3))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def train_simple_mlp(X_train, Y_train, input_dim, epochs=200, lr=5e-4, \n",
    "                     weight_decay=1e-5, hidden_dims=[128, 128, 64], dropout=0.2):\n",
    "    \"\"\"Train simple MLP (same as exp_000)\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = SimpleMLP(input_dim, hidden_dims=hidden_dims, dropout=dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=20)\n",
    "    criterion = nn.HuberLoss()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    Y_tensor = torch.FloatTensor(Y_train).to(device)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_tensor)\n",
    "        loss = criterion(pred, Y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Simple MLP model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "806de12c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:03:30.520498Z",
     "iopub.status.busy": "2026-01-16T02:03:30.520331Z",
     "iopub.status.idle": "2026-01-16T02:03:30.529156Z",
     "shell.execute_reply": "2026-01-16T02:03:30.528637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleModel defined\n"
     ]
    }
   ],
   "source": [
    "# Simple Model (recreating exp_000)\n",
    "class SimpleModel:\n",
    "    \"\"\"\n",
    "    Simple MLP model with Spange + Arrhenius features.\n",
    "    Recreating exp_000 which has the best residual.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_models=3, hidden_dims=[128, 128, 64], dropout=0.2):\n",
    "        self.n_models = n_models\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = []\n",
    "        self.input_dim = None\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"Train n_models MLPs\"\"\"\n",
    "        # Prepare features\n",
    "        X_features = prepare_features(X_train)\n",
    "        self.input_dim = X_features.shape[1]\n",
    "        X_scaled = self.scaler.fit_transform(X_features)\n",
    "        \n",
    "        Y_values = Y_train.values\n",
    "        \n",
    "        # Train multiple models for bagging\n",
    "        for _ in range(self.n_models):\n",
    "            mlp = train_simple_mlp(X_scaled, Y_values, self.input_dim, \n",
    "                                   epochs=200, hidden_dims=self.hidden_dims,\n",
    "                                   dropout=self.dropout)\n",
    "            self.models.append(mlp)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict using ensemble of MLPs\"\"\"\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        X_features = prepare_features(X_test)\n",
    "        X_scaled = self.scaler.transform(X_features)\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        preds = []\n",
    "        X_tensor = torch.FloatTensor(X_scaled).to(device)\n",
    "        for mlp in self.models:\n",
    "            mlp.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = mlp(X_tensor).cpu().numpy()\n",
    "            preds.append(pred)\n",
    "        \n",
    "        # Average predictions\n",
    "        final_pred = np.mean(preds, axis=0)\n",
    "        return np.clip(final_pred, 0, 1)\n",
    "\n",
    "print(\"SimpleModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8005bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV for single solvents\n",
    "print(\"Running Single Solvent CV with Simple Model (exp_000 style)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "splits = list(generate_leave_one_out_splits(X_single, Y_single))\n",
    "print(f\"Number of folds: {len(splits)}\")\n",
    "\n",
    "solvent_errors = {}\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(splits):\n",
    "    X_train = X_single.iloc[train_idx]\n",
    "    Y_train = Y_single.iloc[train_idx]\n",
    "    X_test = X_single.iloc[test_idx]\n",
    "    Y_test = Y_single.iloc[test_idx]\n",
    "    \n",
    "    test_solvent = X_test['SOLVENT NAME'].iloc[0]\n",
    "    \n",
    "    # Train model\n",
    "    model = SimpleModel(n_models=3, hidden_dims=[128, 128, 64], dropout=0.2)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predict\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = np.mean((preds - Y_test.values) ** 2)\n",
    "    solvent_errors[test_solvent] = mse\n",
    "    \n",
    "    all_preds.append(preds)\n",
    "    all_true.append(Y_test.values)\n",
    "    \n",
    "    print(f\"Fold {fold_idx+1:2d}: {test_solvent:45s} MSE = {mse:.6f}\")\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_true = np.vstack(all_true)\n",
    "single_mse = np.mean((all_preds - all_true) ** 2)\n",
    "single_std = np.std([solvent_errors[s] for s in solvent_errors])\n",
    "\n",
    "print(f\"\\nSimple Model Single Solvent CV MSE: {single_mse:.6f} +/- {single_std:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a1a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV for mixtures\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Running Mixture CV with Simple Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mix_splits = list(generate_leave_one_ramp_out_splits(X_mix, Y_full))\n",
    "print(f\"Number of folds: {len(mix_splits)}\")\n",
    "\n",
    "mix_errors = {}\n",
    "mix_preds = []\n",
    "mix_true = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(mix_splits):\n",
    "    X_train = X_mix.iloc[train_idx]\n",
    "    Y_train = Y_full.iloc[train_idx]\n",
    "    X_test = X_mix.iloc[test_idx]\n",
    "    Y_test = Y_full.iloc[test_idx]\n",
    "    \n",
    "    test_mixture = X_test['SOLVENT NAME'].iloc[0]\n",
    "    \n",
    "    # Train model\n",
    "    model = SimpleModel(n_models=3, hidden_dims=[128, 128, 64], dropout=0.2)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predict\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = np.mean((preds - Y_test.values) ** 2)\n",
    "    mix_errors[test_mixture] = mse\n",
    "    \n",
    "    mix_preds.append(preds)\n",
    "    mix_true.append(Y_test.values)\n",
    "    \n",
    "    print(f\"Fold {fold_idx+1:2d}: {test_mixture:55s} MSE = {mse:.6f}\")\n",
    "\n",
    "mix_preds = np.vstack(mix_preds)\n",
    "mix_true = np.vstack(mix_true)\n",
    "mix_mse = np.mean((mix_preds - mix_true) ** 2)\n",
    "mix_std = np.std([mix_errors[s] for s in mix_errors])\n",
    "\n",
    "print(f\"\\nSimple Model Mixture CV MSE: {mix_mse:.6f} +/- {mix_std:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6090e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall CV score\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Simple Model Overall Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_single = len(all_true)\n",
    "n_mix = len(mix_true)\n",
    "n_total = n_single + n_mix\n",
    "\n",
    "overall_mse = (n_single * single_mse + n_mix * mix_mse) / n_total\n",
    "\n",
    "print(f\"\\nSingle Solvent CV MSE: {single_mse:.6f} +/- {single_std:.6f} (n={n_single})\")\n",
    "print(f\"Mixture CV MSE: {mix_mse:.6f} +/- {mix_std:.6f} (n={n_mix})\")\n",
    "print(f\"Overall CV MSE: {overall_mse:.6f}\")\n",
    "\n",
    "print(f\"\\nBaseline (exp_030): CV = 0.008298\")\n",
    "print(f\"exp_000 (original): CV = 0.011081\")\n",
    "print(f\"Improvement vs exp_030: {(0.008298 - overall_mse) / 0.008298 * 100:.1f}%\")\n",
    "print(f\"Improvement vs exp_000: {(0.011081 - overall_mse) / 0.011081 * 100:.1f}%\")\n",
    "\n",
    "# Calculate predicted LB based on CV-LB relationship\n",
    "predicted_lb = 4.29 * overall_mse + 0.0528\n",
    "print(f\"\\nPredicted LB (based on CV-LB relationship): {predicted_lb:.4f}\")\n",
    "print(f\"exp_000 actual LB: 0.0856\")\n",
    "print(f\"exp_000 residual: -0.002136 (beat predicted LB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220347ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 051 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nSimple Model (exp_000 style):\")\n",
    "print(f\"  Single Solvent CV: {single_mse:.6f}\")\n",
    "print(f\"  Mixture CV: {mix_mse:.6f}\")\n",
    "print(f\"  Overall CV: {overall_mse:.6f}\")\n",
    "print(f\"  vs Baseline (exp_030): {(overall_mse - 0.008298) / 0.008298 * 100:+.1f}%\")\n",
    "print(f\"  vs exp_000: {(overall_mse - 0.011081) / 0.011081 * 100:+.1f}%\")\n",
    "\n",
    "print(\"\\nKey insights:\")\n",
    "print(\"1. exp_000 has the best residual (-0.002136) despite worse CV\")\n",
    "print(\"2. This suggests simpler models may generalize better to LB\")\n",
    "print(\"3. The CV-LB relationship may not hold for simpler models\")\n",
    "\n",
    "if overall_mse < 0.008298:\n",
    "    print(\"\\nCONCLUSION: Simple model IMPROVES overall CV!\")\n",
    "else:\n",
    "    print(\"\\nCONCLUSION: Simple model does NOT improve overall CV.\")\n",
    "    print(\"But exp_000's best residual suggests it may still perform better on LB.\")\n",
    "\n",
    "print(f\"\\nRemaining submissions: 5\")\n",
    "print(f\"Best model: exp_030 (GP 0.15 + MLP 0.55 + LGBM 0.3) with CV 0.008298, LB 0.0877\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
