{
  "query": "What is the best approach for predicting chemical reaction yields when test solvents are completely unseen during training?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Predicting reaction yields for solvents that never appear in the training set requires a model that treats the solvent as a **continuous, physics\u2011based descriptor** rather than a categorical label.  Recent work shows that embedding solvents with quantum\u2011chemical or spectroscopic features (e.g., dipole moment, dielectric constant, solvatochromic parameters, or DFT\u2011derived solvation energies) lets a neural network learn the underlying solvent\u2011reaction relationship and extrapolate to completely new solvents\u202f([rsc.org](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a),\u202f[arxiv.org](https://arxiv.org/abs/2512.19530)).  Graph\u2011based architectures are especially effective because they can ingest both the molecular graph of the reactants/products and a separate \u201csolvent graph\u201d whose node attributes are these continuous descriptors; an attributed graph neural network (AGNN) trained on high\u2011throughput experimentation (HTE) data has already matched or outperformed prior fingerprint\u2011based models on Suzuki\u2013Miyaura and Buchwald\u2013Hartwig yields\u202f([ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC10189898)).  \n\nWhen only limited solvent data are available, **active transfer learning** or **meta\u2011learning** can bridge the gap.  By first pre\u2011training a transformer\u2011based yield predictor on a large, solvent\u2011agnostic reaction corpus (e.g., the RXN\u2011yields dataset) and then fine\u2011tuning it with a small set of reactions measured in the new solvent, the model adapts its solvent embedding without over\u2011fitting\u202f([github.io](https://rxn4chemistry.github.io/rxn_yields),\u202f[pubs.rsc.org](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b)).  Combining this fine\u2011tuning with uncertainty\u2011aware loss functions (e.g., aleatoric uncertainty estimation) further guards against unreliable predictions on truly unseen solvents\u202f([nature.com](https://www.nature.com/articles/s41467-025-62717-7)).  \n\nIn practice, the most robust pipeline therefore (1) encodes solvents with quantum\u2011chemical or spectroscopic continuous features, (2) feeds reactant, product, and solvent graphs into an AGNN or transformer backbone, and (3) employs active/transfer learning to update the solvent embedding with a few experimentally measured yields.  This strategy has been demonstrated to generalize across solvent families and to maintain high predictive accuracy even when the test solvent was absent from the training data.",
      "url": ""
    },
    {
      "title": "Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates",
      "text": "[Jump to main content ![](https://www.rsc-cdn.org/oxygen/assets/icons/arrow-right-o-light.png)](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a#maincontent) [Jump to site search ![](https://www.rsc-cdn.org/oxygen/assets/icons/arrow-right-o-light.png)](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a#SearchText)\n\n[Issue 7, 2024](https://pubs.rsc.org/en/journals/journal/sc?issueid=sc015007&type=current&issnprint=2041-6520)\n\n[![](https://pubs.rsc.org/en/Image/Get?imageInfo.ImageType=CoverIssue&imageInfo.ImageIdentifier.SerCode=SC&imageInfo.ImageIdentifier.IssueId=SC015007)\\\n\\\nFrom the journal: **Chemical Science**](https://pubs.rsc.org/en/journals/journal/sc)\n\n## Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates [\u2020](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a\\#fn1)\n\n![Check for updates](https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_horizontal.svg)\n\n[Yunsie\\\nChung](https://pubs.rsc.org/en/results?searchtext=Author%3AYunsie%20Chung) [![ORCID logo](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/orcid_16x16.png)](https://orcid.org/0000-0002-3097-010X)_a_\nand\n[William H.\\\nGreen](https://pubs.rsc.org/en/results?searchtext=Author%3AWilliam%20H.%20Green)[![ORCID logo](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/orcid_16x16.png)](https://orcid.org/0000-0003-2603-9694)\n\\*_a_\n\n[Author affiliations](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a)\n\n\\\\* Corresponding authors\n\naDepartment of Chemical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA\n\n**E-mail:** [whgreen@mit.edu](mailto:whgreen@mit.edu)\n\n### Abstract\n\nFast and accurate prediction of solvent effects on reaction rates are crucial for kinetic modeling, chemical process design, and high-throughput solvent screening. Despite the recent advance in machine learning, a scarcity of reliable data has hindered the development of predictive models that are generalizable for diverse reactions and solvents. In this work, we generate a large set of data with the COSMO-RS method for over 28\u2006000 neutral reactions and 295 solvents and train a machine learning model to predict the solvation free energy and solvation enthalpy of activation (\u0394\u0394 _G_\u2021solv, \u0394\u0394 _H_\u2021solv) for a solution phase reaction. On unseen reactions, the model achieves mean absolute errors of 0.71 and 1.03 kcal mol\u22121 for \u0394\u0394 _G_\u2021solv and \u0394\u0394 _H_\u2021solv, respectively, relative to the COSMO-RS calculations. The model also provides reliable predictions of relative rate constants within a factor of 4 when tested on experimental data. The presented model can provide nearly instantaneous predictions of kinetic solvent effects or relative rate constants for a broad range of neutral closed-shell or free radical reactions and solvents only based on atom-mapped reaction SMILES and solvent SMILES strings.\n\n![Graphical abstract: Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates](https://pubs.rsc.org/en/Image/Get?imageInfo.ImageType=GA&imageInfo.ImageIdentifier.ManuscriptID=D3SC05353A&imageInfo.ImageIdentifier.Year=2024)\n\n- This article is part of the themed collections:\n[#MyFirstChemSci 2024](https://pubs.rsc.org/en/journals/articlecollectionlanding?sercode=sc&themeid=26a1e262-5929-453c-b3a7-f61b43147ce2) and [Most popular 2024 physical, theoretical and computational chemistry articles](https://pubs.rsc.org/en/journals/articlecollectionlanding?sercode=sc&themeid=777d3e88-b794-457a-8932-5995aa89df7b)\n\nThis article is Open Access\n\n![](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/Ajax-GA-Loader.gif)\nPlease wait while we load your content...\nSomething went wrong. [Try again?](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a)\n\n[About](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a#pnlAbstract)\n\n[Cited by](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a#pnlCitation)\n\n[Related](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a#pnlRelatedContent)\n\n[Download options Please wait...](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a)\n\n## Supplementary files\n\n- [Supplementary information\\\nPDF (4245K)](https://www.rsc.org/suppdata/d3/sc/d3sc05353a/d3sc05353a1.pdf)\n\n## Transparent peer review\n\nTo support increased transparency, we offer authors the option to publish the peer review history alongside their article.\n\n[View this article\u2019s peer review history](https://www.webofscience.com/api/gateway/wos/peer-review/10.1039/D3SC05353A)\n\n## Article information\n\nDOI[https://doi.org/10.1039/D3SC05353A](https://doi.org/10.1039/D3SC05353A)\n\n**Article type**Edge Article\n\nSubmitted10 Oct 2023\n\nAccepted04 Jan 2024\n\nFirst published10 Jan 2024\n\n![](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/open-access-icon-orange.png)\n\n**This article is Open Access**\n\nAll publication charges for this article have been paid for by the Royal Society of Chemistry[![Creative Commons BY license](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/CCBY.svg)](http://creativecommons.org/licenses/by/3.0/)\n\n### Download Citation\n\n_**Chem. Sci.**_, 2024, **15**, 2410-2424\n\nBibTexEndNoteMEDLINEProCiteReferenceManagerRefWorksRIS\n\n### Permissions\n\n[Request permissions](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a)\n\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/cross.png)](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a)\n\n### Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates\n\nY. Chung and W. H. Green,\n_Chem. Sci._, 2024,\u00a0**15**, 2410\n**DOI:** 10.1039/D3SC05353A\n\nThis article is licensed under a [Creative Commons Attribution 3.0 Unported Licence](https://creativecommons.org/licenses/by/3.0/). **You can use material from this article**\n**in other publications without requesting further permissions** from the RSC, provided that the\ncorrect acknowledgement is given.\n\nRead more about [how to correctly acknowledge RSC content](https://www.rsc.org/journals-books-databases/journal-authors-reviewers/licences-copyright-permissions/#acknowledgements).\n\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/cross.png)](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a)\n\n### Social activity\n\n[![](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/twitter.svg)Tweet](https://twitter.com/intent/tweet/?text=Machine+learning+from+quantum+chemistry+to+predict+experimental+solvent+effects+on+reaction+rates+-+now+published+in+Chemical+Science&url=https%3a%2f%2fpubs.rsc.org%2fen%2fcontent%2farticlelanding%2f2024%2fsc%2fd3sc05353a)\n\n[![](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/wechat.svg)Share](https://pubs.rsc.org/en/Image/GetQrCode?url=https%3A%2F%2Fpubs.rsc.org%2Fen%2Fcontent%2Farticlelanding%2F2024%2Fsc%2Fd3sc05353a)\n\n## Search articles by author\n\nYunsie Chung\n\nWilliam H. Green\n\n![](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/Ajax-GA-Loader.gif)\nFetching data from CrossRef.\n\nThis may take some time to load.\n\nLoading related content![](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/Ajax-GA-Loader.gif)\n\n### Spotlight\n\n### Advertisements\n\nThis website collects cookies to deliver a better user experience.\nSee how this site uses [Cookies](https://pubs.rsc.org/en/content/cookies).\n[Do not sell my personal data](https://pubs.rsc.org/en/content/cookies).\n\nEste site coleta cookies para oferecer uma melhor experi\u00eancia ao usu\u00e1rio.\nVeja como este site usa [Cookies](https://pubs.rsc.org/en/content/cookies).",
      "url": "https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a"
    },
    {
      "title": "Predicting reaction conditions from limited data through active transfer learning",
      "text": "[![Royal Society of Chemistry](https://pubs.rsc.org/content/NewImages/royal-society-of-chemistry-logo.png)](https://pubs.rsc.org/)\n\n[View\u00a0PDF\u00a0Version](https://pubs.rsc.org/en/content/articlepdf/2022/sc/d1sc06932b)[Previous\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d2sc01662a)[Next\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc05681f)\n\n[![Check for updates](https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_square.svg)](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b)\n\n![](https://pubs.rsc.org/content/newimages/open_access_blue.png) Open Access Article\n\n![](https://pubs.rsc.org/content/newimages/CCBY-NC.svg)\nThis Open Access Article is licensed under a [Creative Commons Attribution-Non Commercial 3.0 Unported Licence](http://creativecommons.org/licenses/by-nc/3.0/)\n\nDOI:\u00a0[10.1039/D1SC06932B](https://doi.org/10.1039/D1SC06932B)\n(Edge Article)\n[Chem. Sci.](https://doi.org/10.1039/2041-6539/2010), 2022, **13**, 6655-6668\n\n# Predicting reaction conditions from limited data through active transfer learning [\u2020](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b\\#fn1)\n\nEunjae\nShim\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-4085-9659)a,\nJoshua A.\nKammeraad\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0003-0386-7198)ab,\nZiping\nXu\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-2591-0356)b,\nAmbuj\nTewari\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0001-6969-7844)bc,\nTim\nCernak\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0001-5407-0643)\\*ad and Paul M.\nZimmerman\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-7444-1314)\\*a\n\naDepartment of Chemistry, University of Michigan, Ann Arbor, MI, USA. E-mail: [paulzim@umich.edu](mailto:paulzim@umich.edu)\n\nbDepartment of Statistics, University of Michigan, Ann Arbor, MI, USA\n\ncDepartment of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA\n\ndDepartment of Medicinal Chemistry, University of Michigan, Ann Arbor, MI, USA. E-mail: [tcernak@med.umich.edu](mailto:tcernak@med.umich.edu)\n\nReceived\n10th December 2021\n, Accepted 10th May 2022\n\nFirst published on 11th May 2022\n\n* * *\n\n## Abstract\n\nTransfer and active learning have the potential to accelerate the development of new chemical reactions, using prior data and new experiments to inform models that adapt to the target area of interest. This article shows how specifically tuned machine learning models, based on random forest classifiers, can expand the applicability of Pd-catalyzed cross-coupling reactions to types of nucleophiles unknown to the model. First, model transfer is shown to be effective when reaction mechanisms and substrates are closely related, even when models are trained on relatively small numbers of data points. Then, a model simplification scheme is tested and found to provide comparative predictivity on reactions of new nucleophiles that include unseen reagent combinations. Lastly, for a challenging target where model transfer only provides a modest benefit over random selection, an active transfer learning strategy is introduced to improve model predictions. Simple models, composed of a small number of decision trees with limited depths, are crucial for securing generalizability, interpretability, and performance of active transfer learning.\n\n* * *\n\n## Introduction\n\nComputers are becoming increasingly capable of performing high-level chemical tasks. [1\u20134](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit1) Machine learning approaches have demonstrated viable retrosynthetic analyses, [5\u20137](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit5) product prediction, [8\u201311](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit8) reaction condition suggestion, [12\u201316](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit12) prediction of stereoselectivity, [17\u201320](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit17) regioselectivity, [19,21\u201324](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit19) and reaction yield [25,26](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit25) and optimization of reaction conditions. [27\u201330](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit27) These advances allow computers to assist synthesis planning for functional molecules using well-established chemistry. For machine learning to aid the development of new reactions, a model based on established chemical knowledge must be able to generalize its predictions to reactivity that lies outside of the dataset. However, because most supervised learning algorithms learn how features (e.g. reaction conditions) within a particular domain relate to an outcome (e.g. yield), the model is not expected to be accurate outside its domain. This situation requires chemists to consider other machine learning methods for navigating new reactivity.\n\nExpert knowledge based on known reactions plays a central role in the design of new reactions. The assumption that substrates with chemically similar reaction centers have transferable performance provides a plausible starting point for experimental exploration. This concept of chemical similarity, together with literature data, guides expert chemists in the development of new reactions. Transfer learning, which assumes that data from a nearby domain, called the source domain, can be leveraged to model the problem of interest in a new domain, called the target domain, [31](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit31) emulates a tactic commonly employed by human chemists.\n\nTransfer learning is a promising strategy when limited data is available in the domain of interest, but a sizeable dataset is available in a related domain. [31,32](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit31) Models are first created using the source data, then transferred to the target domain using various algorithms. [19,33\u201335](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit19) For new chemical targets where no labeled data is available, the head start in predictivity a source model can provide becomes important. However, when a shift in distribution of descriptor values occurs (e.g., descriptors outside of the original model ranges) in the target data, making predictions becomes challenging. For such a situation, the objective of transfer learning becomes training a model that is as predictive in the target domain as possible. [31,36](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit31) Toward this end, cross-validation is known to improve generalizability by providing a procedure to avoid overfitting on the training data. [37](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit37) The reduction of generalization error, however, may not be sufficient outside the source domain. Accordingly, new methods that enhance the applicability of a transferred model to new targets would be beneficial for reaction condition prediction.\n\nAnother machine learning method that can help tackle data scarcity is active learning. By making iterative queries of labeling a small number of datapoints, active learning updates models with knowledge from newly labeled data. As a result, exploration is guided into the most informative areas and avoids collection of unnecessary data. [38,39](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit38) Active learning is therefore well-suited for reaction development, which greatly benefits from efficient exploration and where chemists conduct the next batch of reactions based on previous experimental result...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b"
    },
    {
      "title": "Predicting Chemical Reaction Yields",
      "text": "Predicting Chemical Reaction Yields | RXN yield prediction\n* * [rxn\\_yields](#)\n* [Overview](https://rxn4chemistry.github.io/rxn_yields//)\n* [Data](https://rxn4chemistry.github.io/rxn_yields/data)\n* [Training Tutorial](https://rxn4chemistry.github.io/rxn_yields/model_training)\n* [Evaluation Buchwald Hartwig](https://rxn4chemistry.github.io/rxn_yields/results_evaluation_of_buchwald_hartwig_yields_prediction)\n* [Evaluation Suzuki Miyaura](https://rxn4chemistry.github.io/rxn_yields/results_evaluation_of_suzuki_miyaura_yields_prediction)\n* [USPTO Exploration](https://rxn4chemistry.github.io/rxn_yields/uspto_data_exploration)\n# Predicting Chemical Reaction Yields\nPredicting the yield of a chemical reaction from a reaction SMILES using Transformers\nArtificial intelligence is driving one of the most important revolutions in organic chemistry. Multiple platforms, including tools for reaction prediction and synthesis planning based on machine learning, successfully became part of the organic chemists\u2019 daily laboratory, assisting in domain-specific synthetic problems. Unlike reaction prediction and retrosynthetic models, reaction yields models have been less investigated, despite the enormous potential of accurately predicting them. Reaction yields models, describing the percentage of the reactants that is converted to the desired products, could guide chemists and help them select high-yielding reactions and score synthesis routes, reducing the number of attempts. So far, yield predictions have been predominantly performed for high-throughput experiments using a categorical (one-hot) encoding of reactants, concatenated molecular fingerprints, or computed chemical descriptors. Here, we extend the application of natural language processing architectures to predict reaction properties given a text-based representation of the reaction, using an encoder transformer model combined with a regression layer. We demonstrate outstanding prediction performance on two high-throughput experiment reactions sets. An analysis of the yields reported in the open-source USPTO data set shows that their distribution differs depending on the mass scale, limiting the dataset applicability in reaction yields predictions.\nThis repository complements our studies on[predicting chemical reaction yields](https://iopscience.iop.org/article/10.1088/2632-2153/abc81d)(published in Machine Learning: Science and Technology) and[data augmentation and uncertainty estimation for yield predictions](https://doi.org/10.26434/chemrxiv.13286741)(presented at the Machine Learning for Molecules Workshop at NeurIPS 2020).\n## Install[](#Install)\nAs the library is based on the chemoinformatics toolkit[RDKit](http://www.rdkit.org)it is best installed using the[Anaconda](https://docs.conda.io/en/latest/miniconda.html)package manager. Once you have conda, you can simply run:\n```\n`conda create -n yields python=3.6 -y\nconda activate yields\nconda install -c rdkit rdkit=2020.03.3.0 -y\nconda install -c tmap tmap -y`\n```\n```\n`git clone https://github.com/rxn4chemistry/rxn\\_yields.git\ncd rxn\\_yields\npip install -e .`\n```\n**NOTE:**\nIf you are fine-tuning your own models. Make sure that the pretrained model (from which you start training) is loaded from a folder with the same structure as for our[rxnfp models](https://github.com/rxn4chemistry/rxnfp/tree/master/rxnfp/models/transformers/bert_pretrained).\n## Approach - predicting yields from reaction SMILES[](#Approach---predicting-yields-from-reaction-SMILES)\nTransformer models have recently revolutionised Natural Language Processing and were also successfully applied to task in chemistry, using a text-based representation of molecules and chemical reactions called Simplified molecular-input line-entry system (SMILES).\nSequence-2-Sequence transformers as in[Attention is all you need](http://papers.nips.cc/paper/7181-attention-is-all-you-need)were used for:\n* Chemical Reaction Prediction\n* [Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction](https://pubs.acs.org/doi/full/10.1021/acscentsci.9b00576)\n* [Carbohydrate Transformer: Predicting Regio- and Stereoselective Reactions Using Transfer Learning](http://dx.doi.org/10.26434/chemrxiv.11935635)\n* Multi-step retrosynthesis\n* [Predicting retrosynthetic pathways using a combined linguistic model and hyper-graph exploration strategy](http://dx.doi.org/10.1039/c9sc05704h)\n* [Unassisted Noise-Reduction of Chemical Reactions Data Sets](https://chemrxiv.org/articles/Unassisted_Noise-Reduction_of_Chemical_Reactions_Data_Sets/12395120/1)\nEncoder Transformers like[BERT](https://openreview.net/forum?id=SkZmKmWOWH)and[ALBERT](https://openreview.net/forum?id=H1eA7AEtvS)for:\n* Reaction fingerprints and classification\n* [Mapping the Space of Chemical Reactions using Attention-Based Neural Networks](https://chemrxiv.org/articles/Data-Driven_Chemical_Reaction_Classification_with_Attention-Based_Neural_Networks/9897365)\n* Atom rearrangements during chemical reactions\n* [Unsupervised Attention-Guided Atom-Mapping](https://chemrxiv.org/articles/Unsupervised_Attention-Guided_Atom-Mapping/12298559)\nThose studies show that Transformer models are able to learn organic chemistry and chemical reactions from SMILES.\nHere we asked the question, how well a**BERT**model would perform when applied to a**yield prediction**task:\n![](https://rxn4chemistry.github.io/rxn_yields/images/pipeline.jpg)\n**Figure:**Pipeline and task description.\nTo do so, we started with the reaction fingerprint models from the[rxnfp](https://rxn4chemistry.github.io/rxnfp/)library and added a fine-tuning regression head through[SimpleTransformers.ai](https://simpletransformers.ai). As we don't need to change the hyperparameters of the base model, we only tune the learning rate for the training and the dropout probability.\nWe explored two high-throughput experiment (HTE) data sets and then also the yields data found in the USPTO data base.\n## Buchwald-Hartwig HTE data set[](#Buchwald-Hartwig-HTE-data-set)\n### Canonical reaction representation[](#Canonical-reaction-representation)\nOne of the best studied reaction yield is the one that was published by Ahneman et al. in[Predicting reaction performance in C\u2013N cross-coupling using machine learning](https://science.sciencemag.org/content/360/6385/186.full), where the authors have used DFT-computed descriptors as inputs to different machine learning descriptors. There best model was a random forest model. More recently,[one-hot encodings](https://science.sciencemag.org/content/362/6416/eaat8603)and[multi-fingerprint features (MFF)](https://www.sciencedirect.com/science/article/pii/S2451929420300851)as input representations were investigated. Here, we show competitive results starting simply from a text-based reaction SMILES input to our models.\n![](https://rxn4chemistry.github.io/rxn_yields/images/buchwald_hartwig.jpg)\n**Figure:**a) Summary of the results on the Buchwald\u2013Hartwig data set. b) Example regression plot for the first random-split.\n### Augmentated reaction representations[](#Augmentated-reaction-representations)\nWe were able to further improve the results on this data set using data augmentation on reaction SMILES (molecule order permuations and SMILES randomisations). This extension will be presented at the NeurIPS 2020[Machine Learning for Molecules Workshop](https://nips.cc/Conferences/2020/ScheduleMultitrack?event=16136).\n![](https://rxn4chemistry.github.io/rxn_yields/images/rxn_randomizations.png)\n**Figure:**The two different data augmentation techniques investigated in the NeurIPS workshop paper.\n#### Results[](#Results)\n![](https://rxn4chemistry.github.io/rxn_yields/images/results_augm.png)\n**Figure:**a) Results on the 70/30 random splits, averaged over 10 splits. b) Comparison of DFT descriptors + RF, canonical SMILES and data augmented randomized SMILES on reduced training sets. c) Out-of-sample test sets\nOn random splits 70/30 in a), the data augmented Yield-BERT models perform better than ...",
      "url": "https://rxn4chemistry.github.io/rxn_yields"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2512.19530] Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2512.19530\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2512.19530**(cs)\n[Submitted on 22 Dec 2025]\n# Title:Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\nAuthors:[Hongsheng Xing](https://arxiv.org/search/cs?searchtype=author&amp;query=Xing,+H),[Qiuxin Si](https://arxiv.org/search/cs?searchtype=author&amp;query=Si,+Q)\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n[View PDF](https://arxiv.org/pdf/2512.19530)[HTML (experimental)](https://arxiv.org/html/2512.19530v1)> > Abstract:\n> Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \\textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.\n> Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \\textbf{MSE of 0.0039} ($\\pm$ 0.0003), representing a 60\\% error reduction over competitive baselines and a $&gt;25\\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning. Comments:|13 pages, 6 figures|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI)|\nMSCclasses:|68T07, 92E20, 62M45|\nACMclasses:|I.2.1; I.2.6; J.2|\nCite as:|[arXiv:2512.19530](https://arxiv.org/abs/2512.19530)[cs.LG]|\n|(or[arXiv:2512.19530v1](https://arxiv.org/abs/2512.19530v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2512.19530](https://doi.org/10.48550/arXiv.2512.19530)\nFocus to learn more\narXiv-issued DOI via DataCite (pending registration)\n|\n## Submission history\nFrom: Hongsheng Xing [[view email](https://arxiv.org/show-email/9dc7457b/2512.19530)]\n**[v1]**Mon, 22 Dec 2025 16:19:01 UTC (2,198 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n* [View PDF](https://arxiv.org/pdf/2512.19530)\n* [HTML (experimental)](https://arxiv.org/html/2512.19530v1)\n* [TeX Source](https://arxiv.org/src/2512.19530)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2512.19530&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2512.19530&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2025-12](https://arxiv.org/list/cs.LG/2025-12)\nChange to browse by:\n[cs](https://arxiv.org/abs/2512.19530?context=cs)\n[cs.AI](https://arxiv.org/abs/2512.19530?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2512.19530)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2512.19530)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2512.19530)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2512.19530&amp;description=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2512.19530&amp;title=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.or...",
      "url": "https://arxiv.org/abs/2512.19530"
    },
    {
      "title": "On the use of real-world datasets for reaction yield prediction",
      "text": "<div><div>\n \n <main>\n \n <article><section></section><section><section><h2>Abstract</h2>\n<p>The lack of publicly available, large, and unbiased datasets is a key bottleneck for the application of machine learning (ML) methods in synthetic chemistry. Data from electronic laboratory notebooks (ELNs) could provide less biased, large datasets, but no such datasets have been made publicly available. The first real-world dataset from the ELNs of a large pharmaceutical company is disclosed and its relationship to high-throughput experimentation (HTE) datasets is described. For chemical yield predictions, a key task in chemical synthesis, an attributed graph neural network (AGNN) performs as well as or better than the best previous models on two HTE datasets for the Suzuki\u2013Miyaura and Buchwald\u2013Hartwig reactions. However, training the AGNN on an ELN dataset does not lead to a predictive model. The implications of using ELN data for training ML-based models are discussed in the context of yield predictions.</p></section><section><hr/>\n<p>An attributed graph neural network predicts the yield of Suzuki\u2013Miyaura and Buchwald\u2013Hartwig reactions for datasets from high-throughput experimentation (HTE) but not for a more diverse real-world dataset from electronic lab notebooks (ELNs).<a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=10189898_d2sc06041h-ga.jpg\"></a></p></section><section><h2>Introduction</h2>\n<p>The development of predictive methods is a long-standing goal of computational chemistry. Initially, physics based modeling techniques such as DFT or force field methods were used to understand reaction mechanisms and predict <em>e.g.</em> the stereochemical outcome of reactions<sup><a href=\"#cit1\">1</a></sup> or suitable catalysts for their acceleration.<sup><a href=\"#cit2\">2</a></sup> More recently, machine leaning (ML) methods<sup><a href=\"#cit3\">3</a></sup> have been used to predict the likely products of reactions (forward synthesis prediction)<sup><a href=\"#cit4\">4,5</a></sup> and promising pathways for the synthesis of organic molecules with a range of complexity.<sup><a href=\"#cit6\">6\u20139</a></sup></p>\n<p>The prediction of yields of chemical reactions is a particularly challenging task because it is influenced not only by the variables of the reaction under study, but also by all possible side reactions. At the same time, it is an extremely important task due to the significant effort needed to optimize the yield of a reaction by variation of reaction conditions and catalysts. Doyle and coworkers<sup><a href=\"#cit10\">10\u201312</a></sup> sought to address this challenge for the case of predicting the effect of heterocyclic poisons on the yield of the widely used Buchwald\u2013Hartwig amination by training a ML model on a dataset of 4608 reactions from high-throughput experimentation (HTE). Using a random forest (RF) model and computed physics-based features such as NMR shifts or HOMO/LUMO energies, an <em>R</em><sup>2</sup> of 0.92 was achieved (<a href=\"#fig1\">Fig. 1 A</a>). More complex models such as neural networks did not provide higher predictivity.<sup><a href=\"#cit10\">10</a></sup> Fu <em>et al.</em><sup><a href=\"#cit13\">13</a></sup> used a dataset of 387 Suzuki\u2013Miyaura reactions<sup><a href=\"#cit14\">14</a></sup> and features from DFT calculations to train a deep neural network, resulting in a model with an <em>R</em><sup>2</sup> of 0.92. Both HTE datasets have subsequently been successfully used in a range of ML models for yield predictions.<sup><a href=\"#cit15\">15\u201317</a></sup> Bayesian optimizers<sup><a href=\"#cit18\">18,19</a></sup> and deep reinforcement learning<sup><a href=\"#cit20\">20</a></sup> were also successful in the iterative optimization of reaction conditions for a variety of reactions. As will be discussed in more detail below, the use of HTE datasets in ML predictions has some significant drawbacks in that these datasets represent a very narrow part of the reaction space, are very time- and resource intensive and present challenges with overfitting of the models.</p>\n<figure><h3>Fig. 1. Previous work on yield predictions using ML models: (A) HTE-generated datasets using random forest models<sup><a href=\"#cit18\">18</a></sup> (B) HTE (blue) and USPTO derived (red) datasets using the BERT model.<sup><a href=\"#cit22\">22</a></sup>.</h3>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=10189898_d2sc06041h-f1.jpg\"></a></p>\n</figure><p>In contrast, the use of legacy datasets from published scientific or patent literature for yield prediction has been less successful. The attempt to classify reaction yields as above or below 65% based on a training set of \u223c10<sup>6</sup> reactions from the Reaxys database using a large number of descriptors and ML methods gave an accuracy of 65 \u00b1 5%, <em>i.e.</em> a 35% error.<sup><a href=\"#cit21\">21</a></sup> The authors of that study attributed this finding to the deficiencies of \u201ccurrently available chemical descriptors\u201d, but it should also be noted that the reaction space represented in their dataset is vast. Schwaller <em>et al.</em><sup><a href=\"#cit22\">22</a></sup> developed a modification of the bidirectional encoder representations from transformers (BERT) model,<sup><a href=\"#cit23\">23</a></sup> which uses natural language processing to build a reaction SMILES encoder trained on a large corpus of reactions, followed by a classification or regression layer for a specific task. This approach was successful for product predictions<sup><a href=\"#cit5\">5</a></sup> as well as for reaction yield predictions of the Suzuki\u2013Miyaura (blue in <a href=\"#fig1\">Fig. 1B</a>) and Buchwald\u2013Hartwig reactions.<sup><a href=\"#cit22\">22</a></sup> While this approach achieves <em>R</em><sup>2</sup> values of 0.81 and 0.95, respectively, in line with other ML models when trained on these HTE datasets,<sup><a href=\"#cit10\">10,24</a></sup> training on a dataset of Suzuki\u2013Miyaura reactions from the US Patent database (USPTO)<sup><a href=\"#cit22\">22,25</a></sup> led to a maximum <em>R</em><sup>2</sup> score of 0.388 (red in <a href=\"#fig1\">Fig. 1B</a>). When the training set was limited to reactions run on a gram scale, the <em>R</em><sup>2</sup> value dropped further to 0.277, which was attributed to the strong bias of this dataset towards high-yielding reactions.<sup><a href=\"#cit22\">22</a></sup> Similarly, a recent study on the predictions of optimal conditions by Burke and Grzybowski showed that even when limiting the dataset to a single reaction, in their case 16\u2009748 Suzuki\u2013Miyaura reactions curated from the literature, a range of ML models did not perform better than a model based only on the popularity of a set of reaction conditions.<sup><a href=\"#cit26\">26</a></sup> Finally, Reymond and coworkers<sup><a href=\"#cit27\">27</a></sup> constructed a more qualitative \u201cdata-driven cheat-sheet\u201d for the recommendation of conditions for the Buchwald\u2013Hartwig reaction based on a dataset of 62\u2009000 examples from a variety of databases.</p>\n<p>Taken together, these previous findings highlight the challenges in using legacy datasets to train ML yield prediction models. As in other areas of ML, there is a lack of suitable datasets to train and validate the models. Although most of the chemical literature is summarized in commercial databases, they are proprietary. The USPTO, which was converted into a widely used dataset,<sup><a href=\"#cit4\">4</a></sup> and the recently introduced Open Reaction Database<sup><a href=\"#cit28\">28</a></sup> are exceptions. As a result, studies using commercial databases do not include the data the models were built with.<sup><a href=\"#cit27\">27,29</a></sup> Furthermore, databases such as Reaxys frequently do not contain complete reaction information and reflect the bias of the published literature towards high-yielding r...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10189898"
    },
    {
      "title": "Data-driven organic solubility prediction at the limit of aleatoric uncertainty",
      "text": "Data-driven organic solubility prediction at the limit of aleatoric uncertainty | Nature Communications\n[Skip to main content](#content)\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\nthe best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\nInternet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\nand JavaScript.\nAdvertisement\n[![Nature Communications](https://media.springernature.com/full/nature-cms/uploads/product/ncomms/header-7001f06bc3fe2437048388e9f2f44215.svg)](https://www.nature.com/ncomms)\n* [View all journals](https://www.nature.com/siteindex)\n* [Search](#search-menu)\n* [Log in](https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41467-025-62717-7?error=cookies_not_supported&code=af4d9c9d-c53a-46a7-a76a-9deaf6dad1b7)\n* [ContentExplore content](#explore)\n* [Aboutthe journal](#about-the-journal)\n* [Publishwith us](#publish-with-us)\n* [Sign up for alerts](https://journal-alerts.springernature.com/subscribe?journal_id&#x3D;41467)\n* [RSS feed](https://www.nature.com/ncomms.rss)\nData-driven organic solubility prediction at the limit of aleatoric uncertainty\n[Download PDF](https://www.nature.com/articles/s41467-025-62717-7.pdf)\n[Download PDF](https://www.nature.com/articles/s41467-025-62717-7.pdf)\n* Article\n* [Open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)\n* Published:19 August 2025# Data-driven organic solubility prediction at the limit of aleatoric uncertainty\n* [Lucas Attia](#auth-Lucas-Attia-Aff1)[ORCID:orcid.org/0000-0002-9941-3846](https://orcid.org/0000-0002-9941-3846)[1](#Aff1)[na1](#na1),\n* [Jackson W. Burns](#auth-Jackson_W_-Burns-Aff1)[ORCID:orcid.org/0000-0002-0657-9426](https://orcid.org/0000-0002-0657-9426)[1](#Aff1)[na1](#na1),\n* [Patrick S. Doyle](#auth-Patrick_S_-Doyle-Aff1)[ORCID:orcid.org/0000-0003-2147-9172](https://orcid.org/0000-0003-2147-9172)[1](#Aff1)&amp;\n* \u2026* [William H. Green](#auth-William_H_-Green-Aff1)[ORCID:orcid.org/0000-0003-2603-9694](https://orcid.org/0000-0003-2603-9694)[1](#Aff1)Show authors\n[*Nature Communications*](https://www.nature.com/ncomms)**volume16**, Article\u00a0number:7497(2025)[Cite this article](#citeas)\n* 16kAccesses\n* 10Citations\n* 66Altmetric\n* [Metricsdetails](https://www.nature.com/articles/s41467-025-62717-7/metrics)\n### Subjects\n* [Chemical engineering](https://www.nature.com/subjects/chemical-engineering)\n* [Cheminformatics](https://www.nature.com/subjects/cheminformatics)\n* [Machine learning](https://www.nature.com/subjects/machine-learning)\n* [Medicinal chemistry](https://www.nature.com/subjects/medicinal-chemistry)\n* [Scientific data](https://www.nature.com/subjects/scientific-data)\n## Abstract\nSmall molecule solubility is a critically important property which affects the efficiency, environmental impact, and phase behavior of synthetic processes. Experimental determination of solubility is a time- and resource-intensive process and existing methods for in silico estimation of solubility are limited by their generality, speed, and accuracy. This work presents two models derived from the FASTPROP and CHEMPROP architectures and trained on BigSolDB which are capable of predicting solubility at arbitrary temperatures for a wide range of small molecules in organic solvent. Both extrapolate to unseen solutes 2\u20133 times more accurately than the current state-of-the-art model and we demonstrate that they are approaching the aleatoric limit (0.5\u20131\\\\(\\\\log S\\\\)) of available test data, suggesting that further improvements in prediction accuracy require more accurate datasets. The FASTPROP-derived model (called FASTSOLV) and the CHEMPROP-based model are open source, freely accessible via a Python package and web interface, highly reproducible, and up to 2 orders of magnitude faster than current alternatives.\n### Similar content being viewed by others\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41597-025-05559-8/MediaObjects/41597_2025_5559_Fig1_HTML.png)\n### [BigSolDB 2.0, dataset of solubility values for organic compounds in different solvents at various temperatures](https://www.nature.com/articles/s41597-025-05559-8?fromPaywallRec=false)\nArticleOpen access15 July 2025\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs42004-022-00770-9/MediaObjects/42004_2022_770_Fig1_HTML.png)\n### [A semi-automated material exploration scheme to predict the solubilities of tetraphenylporphyrin derivatives](https://www.nature.com/articles/s42004-022-00770-9?fromPaywallRec=false)\nArticleOpen access22 November 2022\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41597-024-03105-6/MediaObjects/41597_2024_3105_Fig1_HTML.png)\n### [Will we ever be able to accurately predict solubility?](https://www.nature.com/articles/s41597-024-03105-6?fromPaywallRec=false)\nArticleOpen access18 March 2024\n## Introduction\nThe solubility of organic solids in various solvents is an essential molecular property that impacts the efficiency[1](https://www.nature.com/articles/s41467-025-62717-7#ref-CR1), environmental impact[2](https://www.nature.com/articles/s41467-025-62717-7#ref-CR2),[3](https://www.nature.com/articles/s41467-025-62717-7#ref-CR3), and phase behavior[4](https://www.nature.com/articles/s41467-025-62717-7#ref-CR4)of synthetic processes. Solubility is crucial in wide-ranging chemical processes spanning length and time scales including crystallization and filtration[4](https://www.nature.com/articles/s41467-025-62717-7#ref-CR4), membrane-based chemical separations[5](https://www.nature.com/articles/s41467-025-62717-7#ref-CR5),[6](https://www.nature.com/articles/s41467-025-62717-7#ref-CR6), pharmaceutical design and discovery[7](https://www.nature.com/articles/s41467-025-62717-7#ref-CR7), drug delivery and formulation[8](https://www.nature.com/articles/s41467-025-62717-7#ref-CR8), the environmental fate of per-and polyfluoroalkyl substances (PFAS)[9](https://www.nature.com/articles/s41467-025-62717-7#ref-CR9)and geological-scale dissolved organic carbon flux[10](https://www.nature.com/articles/s41467-025-62717-7#ref-CR10). By convention, solubility*S*in*m**o**l**L*\u22121is expressed as\\\\({\\\\log }\\_{10}S\\\\)since values can range over several orders of magnitude. Experimental methods for determining solubility are notoriously time- and resource-intensive[11](https://www.nature.com/articles/s41467-025-62717-7#ref-CR11)and error prone, thus many published values are suspected of being highly inaccurate. The challenges of measuring solubility are especially painful in pharmaceutical development where organic solubility complicates synthesis and purification[12](https://www.nature.com/articles/s41467-025-62717-7#ref-CR12)and aqueous solubility limits in vivo efficacy[13](https://www.nature.com/articles/s41467-025-62717-7#ref-CR13). Given that solubility as a function of temperature is often desired, experimental determination becomes even more onerous. For these reasons a priori estimation of\\\\(\\\\log S\\\\)has long been of immense interest to the chemical sciences.\nCritically, the experimental error is typically systematic rather than random because organic molecules are often isolated as an amorphous solid, hydrate, polymorph, or impure cocrystal rather than the desired most-stable pure crystal, confounding accurate measurement[14](https://www.nature.com/articles/s41467-025-62717-7#ref-CR14). The reported standard deviation in inter-laboratory measurements in\\\\(\\\\log S\\\\)typically ranges between 0.5 and 0.7\\\\(\\\\log\\\\)units for aqueous solubility. For example, Katritzky et al.[15](https://www.nature.com/articles/s41467-025-62717-7#ref-CR15)notably found the average inter-laboratory standard deviation of 411 compounds to be 0.58. Other reported average standard dev...",
      "url": "https://www.nature.com/articles/s41467-025-62717-7"
    },
    {
      "title": "Spectroscopy-Guided Deep Learning Predicts Solid\u2013Liquid Surface Adsorbate Properties in Unseen Solvents",
      "text": "![](https://d.adroll.com/cm/b/out?adroll_fpc=ff8b72eb7a295a66281c0d03561c4051-1720306675079&pv=14480128167.775885&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Ffull%2F10.1021%2Fjacs.3c10921&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/g/out?adroll_fpc=ff8b72eb7a295a66281c0d03561c4051-1720306675079&pv=14480128167.775885&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Ffull%2F10.1021%2Fjacs.3c10921&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/index/out?adroll_fpc=ff8b72eb7a295a66281c0d03561c4051-1720306675079&pv=14480128167.775885&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Ffull%2F10.1021%2Fjacs.3c10921&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/n/out?adroll_fpc=ff8b72eb7a295a66281c0d03561c4051-1720306675079&pv=14480128167.775885&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Ffull%2F10.1021%2Fjacs.3c10921&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/o/out?adroll_fpc=ff8b72eb7a295a66281c0d03561c4051-1720306675079&pv=14480128167.775885&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Ffull%2F10.1021%2Fjacs.3c10921&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/outbrain/out?adroll_fpc=ff8b72eb7a295a66281c0d03561c4051-1720306675079&pv=14480128167.775885&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Ffull%2F10.1021%2Fjacs.3c10921&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/pubmatic/out?adroll_fpc=ff8b72eb7a295a66281c0d03561c4051-1720306675079&pv=14480128167.775885&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Ffull%2F10.1021%2Fjacs.3c10921&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/r/out?adroll_fpc=ff8b72eb7a295a66281c0d03561c4051-1720306675079&pv=14480128167.775885&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Ffull%2F10.1021%2Fjacs.3c10921&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/taboola/out?adroll_fpc=ff8b72eb7a295a66281c0d03561c4051-1720306675079&pv=14480128167.775885&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Ffull%2F10.1021%2Fjacs.3c10921&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/triplelift/out?adroll_fpc=ff8b72eb7a295a66281c0d03561c4051-1720306675079&pv=14480128167.775885&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Ffull%2F10.1021%2Fjacs.3c10921&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/x/out?adroll_fpc=ff8b72eb7a295a66281c0d03561c4051-1720306675079&pv=14480128167.775885&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2Ffull%2F10.1021%2Fjacs.3c10921&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)\n\nRecently Viewed [close modal](javascript:void(0))\n\nRecently Viewed\n\n#### You have not visited any articles yet, Please visit some articles to see contents here.\n\nPair your accounts.\n\nExport articles to Mendeley\n\nGet article recommendations from ACS based on references in your Mendeley library.\n\nPair your accounts.\n\nExport articles to Mendeley\n\nGet article recommendations from ACS based on references in your Mendeley library.\n\nYou\u2019ve supercharged your research process with ACS and Mendeley!\n\nContinue\n\n###### STEP 1:\n\nLogin with ACS IDLogged in SuccessClick to create an ACS ID\n\n###### STEP 2:\n\nLogin with MendeleyLogged in Success [Create a Mendeley account](https://id.elsevier.com/as/authorization.oauth2?state=c33c27125763433d4d32a15accaacc18&prompt=login&scope=openid%20email%20profile%20els_auth_info&authType=SINGLE_SIGN_IN&response_type=code&platSite=MDY%2Fmendeley&redirect_uri=https%3A%2F%2Fwww.mendeley.com%2Fcallback%2F&client_id=MENDELEY)\n\nPlease note: If you switch to a different device, you may be asked to login again with only your ACS ID.\n\nPlease note: If you switch to a different device, you may be asked to login again with only your ACS ID.\n\nPlease note: If you switch to a different device, you may be asked to login again with only your ACS ID.\n\nPlease login with your ACS ID before connecting to your Mendeley account.\n\nLogin with ACS ID\n\nMENDELEY PAIRING EXPIREDReconnect\n\nYour Mendeley pairing has expired. Please reconnect\n\n![Figure 1](https://pubs.acs.org/doi/full/10.1021/jacs.3c10921)![Loading Img](https://pubs.acs.org/specs/products/achs/releasedAssets/images/loading/loading-018624cffd023ad5641b8e99931a80e6.gif)\n\n[Download Hi-Res Image](https://pubs.acs.org/doi/full/10.1021/jacs.3c10921) [Download to MS-PowerPoint](https://pubs.acs.org/doi/full/10.1021/jacs.3c10921) [**Cite This:**](https://pubs.acs.org/action/showCitFormats?doi=10.1021/jacs.3c10921&href=/doi/full/10.1021/jacs.3c10921) _J. Am. Chem. Soc._ 2024, 146, 1, 811-823\n\n[ADVERTISEMENT](http://acsmediakit.org)\n\n[RETURN TO ISSUE](https://pubs.acs.org/toc/jacsat/146/1) [PREV](https://pubs.acs.org/doi/10.1021/jacs.3c10864) Article [NEXT](https://pubs.acs.org/doi/10.1021/jacs.3c10963)\n\n[![Journal Logo](https://pubs.acs.org/doi/full/10.1021/specs/products/achs/releasedAssets/images/loading/loader-128b5db1cc3a83761a15cf2e5c9b452d.gif)](https://pubs.acs.org/journal/jacsat)\n\n[Get e-Alerts](https://pubs.acs.org/doi/full/10.1021/jacs.3c10921) close\n\n# Spectroscopy-Guided Deep Learning Predicts Solid\u2013Liquid Surface Adsorbate Properties in Unseen Solvents\n\n- Wenjie Du\n\n\n\n\nWenjie Du\n\n\n\n\n\nKey Laboratory of Precision and Intelligent Chemistry, University of Science and Technology of China, Hefei, Anhui 230026, China\n\n\n\nSchool of Software Engineering, University of Science and Technology of China, Hefei, Anhui 230026, China\n\n\n\nSuzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, Jiangsu 215123, China\n\n\n\n\n\nMore by [Wenjie Du](https://pubs.acs.org/action/doSearch?field1=Contrib&text1=Wenjie++Du)\n\n- ,\n- Fenfen Ma\n\n\n\n\nFenfen Ma\n\n\n\n\n\nKey Laboratory of Precision and Intelligent Chemistry, University of Science and Technology of China, Hefei, Anhui 230026, China\n\n\n\nSchool of Chemistry and Materials Science, University of Science and Technology of China, Hefei, Anhui 230026, China\n\n\n\nGusu Laboratory of Materials, Suzhou, Jiangsu 215123, China\n\n\n\n\n\nMore by [Fenfen Ma](https://pubs.acs.org/action/doSearch?field1=Contrib&text1=Fenfen++Ma)\n\n- ,\n- Baicheng Zhang\n\n\n\n\nBaicheng Zhang\n\n\n\n\n\nKey Laboratory of Precision and Intelligent Chemistry, University of Science and Technology of China, Hefei, Anhui 230026, China\n\n\n\nSchool of Chemistry and Materials Science, University of Science and Technology of China, Hefei, Anhui 230026, China\n\n\n\n\n\nMore by [Baicheng Zhang](https://pubs.acs.org/action/doSearch?field1=Contrib&text1=Baicheng++Zhang)\n\n\n\n![Orcid](https://pubs.acs.org/products/achs/releasedAssets/images/orchid-2856f829046fbda55b90e1582edf0e9a.png)[https://orcid.org/0000-0002-1899-028X](https://orcid.org/0000-0002-1899-028X)\n\n- ,\n- Jiahui Zhang\n\n\n\n\nJiahui Zhang\n\n\n\n\n\nSchool of Software Engineering, University of Science and Technology of China, Hefei, Anhui 230026, China\n\n\n\nSuzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, Jiangsu 215123, China\n\n\n\n\n\nMore by [Jiahui Zhang](https://pubs.acs.org/action/doSearch?field1=Contrib&text1=Jiahui++Zhang)\n\n- ,\n- Di Wu\n\n\n\n\nDi Wu\n\n\n\n\n\nSchool of Software Engineering, University of Science and Technology of China, Hefei, Anhui 230026, China\n\n\n\nSuzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, Jiangsu 215123, China\n\n\n\n\n\nMore by [Di Wu](https://pubs.acs.org/action/doSearch?field1=Contrib&text1=Di++Wu)\n\n- ,\n- Edward Sharman\n\n\n\n\nEdward Sharman\n\n\n\n\n\nDepartment of Neurology, University of California, Irvine, California 92697, United States\n\n\n\n\n\nMore by [Edward Sharman](https://pubs.acs.org/action/doSearch?field1=Contrib&text1=Edward++Sharman)\n\n- ,\n- Jun Jiang **\\***\n\n\n\n\nJun Jiang\n\n\n\n\n\nKey Laboratory of Precision and Intelligent Chemistry, University of Science and Technology of China, Hefei, Anhui 230026, China\n\n\n\nSchool of Chemistry and Materials Science, University of Science and Technology of China, Hefei, Anhui 230026, China\n\n\n\n**\\*** Email: [jiangj1@ustc.edu.cn](mailto:jiangj1@ustc.edu.cn)\n\nMore by [Jun Jiang](https://pubs.acs.org/action/doSearch?field1=Contrib&text1=Jun++Jiang)\n\n\n\n![Orcid](https://pubs.acs.org/products/a...",
      "url": "https://pubs.acs.org/doi/full/10.1021/jacs.3c10921"
    },
    {
      "title": "Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates",
      "text": "[Skip to main content](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#main-content)\n\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-dot-gov.svg)\n\n**Official websites use .gov**\n\nA\n**.gov** website belongs to an official\ngovernment organization in the United States.\n\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-https.svg)\n\n**Secure .gov websites use HTTPS**\n\nA **lock** (\nLock\nLocked padlock icon\n) or **https://** means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n\nSearch PMC Full-Text ArchiveSearch in PMC![Search](https://pmc.ncbi.nlm.nih.gov/static/img/usa-icons-bg/search--white.svg)\n\n- [Advanced Search](https://www.ncbi.nlm.nih.gov/pmc/advanced/)\n- [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n- [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n\nNewTry this search in PMC Beta Search\n\n- ## PERMALINK\n\n\n\nCopy\n\n\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\n\nLearn more:\n[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)\n\\|\n[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\n![Chemical Science logo](https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-chemsci.gif)\n\nChem Sci\n\n. 2024 Jan 10;15(7):2410\u20132424. doi: [10.1039/d3sc05353a](https://doi.org/10.1039/d3sc05353a)\n\n# Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates[\u2020](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/\\#fn1)\n\n[Yunsie Chung](https://pubmed.ncbi.nlm.nih.gov/?term=%22Chung%20Y%22%5BAuthor%5D)\n\n### Yunsie Chung\n\naDepartment of Chemical Engineering, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA, Email: whgreen@mit.edu\n\nFind articles by [Yunsie Chung](https://pubmed.ncbi.nlm.nih.gov/?term=%22Chung%20Y%22%5BAuthor%5D)\n\na, [William H Green](https://pubmed.ncbi.nlm.nih.gov/?term=%22Green%20WH%22%5BAuthor%5D)\n\n### William H Green\n\naDepartment of Chemical Engineering, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA, Email: whgreen@mit.edu\n\nFind articles by [William H Green](https://pubmed.ncbi.nlm.nih.gov/?term=%22Green%20WH%22%5BAuthor%5D)\n\na,\u2709\n\n- Author information\n- Article notes\n- Copyright and License information\n\naDepartment of Chemical Engineering, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA, Email: whgreen@mit.edu\n\n\u2709\n\nCorresponding author.\n\nReceived 2023 Oct 10; Accepted 2024 Jan 4; Collection date 2024 Feb 14.\n\nThis journal is \u00a9 The Royal Society of Chemistry\n\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nPMCID: PMC10866337\u00a0\u00a0PMID: [38362410](https://pubmed.ncbi.nlm.nih.gov/38362410/)\n\n## Abstract\n\nFast and accurate prediction of solvent effects on reaction rates are crucial for kinetic modeling, chemical process design, and high-throughput solvent screening. Despite the recent advance in machine learning, a scarcity of reliable data has hindered the development of predictive models that are generalizable for diverse reactions and solvents. In this work, we generate a large set of data with the COSMO-RS method for over 28\u2009000 neutral reactions and 295 solvents and train a machine learning model to predict the solvation free energy and solvation enthalpy of activation (\u0394\u0394 _G_\u2021solv, \u0394\u0394 _H_\u2021solv) for a solution phase reaction. On unseen reactions, the model achieves mean absolute errors of 0.71 and 1.03 kcal mol\u22121 for \u0394\u0394 _G_\u2021solv and \u0394\u0394 _H_\u2021solv, respectively, relative to the COSMO-RS calculations. The model also provides reliable predictions of relative rate constants within a factor of 4 when tested on experimental data. The presented model can provide nearly instantaneous predictions of kinetic solvent effects or relative rate constants for a broad range of neutral closed-shell or free radical reactions and solvents only based on atom-mapped reaction SMILES and solvent SMILES strings.\n\n* * *\n\nA machine learning model, trained on a large COSMO-RS dataset, enables accurate and rapid predictions of solvation effects on reaction rates for diverse reactions and solvents only based on atom-mapped reaction SMILES and solvent SMILES. [![graphic file with name d3sc05353a-ga.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/5ada/10866337/94a59c069033/d3sc05353a-ga.jpg)](https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=10866337_d3sc05353a-ga.jpg)\n\n## 1\\. Introduction\n\nAccurate prediction of reaction rates is essential for modeling a variety of chemical kinetic systems such as pyrolysis,[1,2](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit1) polymerization,[3](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit3) oxidative degradation,[4,5](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit4) and atmospheric chemistry.[6](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit6) Detailed kinetic models enable one to predict key products, identify major kinetic pathways, and optimize reaction conditions for complex chemical systems. Kinetic mechanisms often involve hundreds to tens of thousands of elementary reactions,[7](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit7) and a fast, high-throughput method to estimate reaction rates is thus needed. _Ab initio_ methods like quantum mechanics/molecular mechanics (QM/MM) can provide accurate predictions of rate constants, but their high computational cost has been a major limiting factor for large-scale, automated predictions. As more kinetic data become available, data-driven approaches such as linear group contribution,[8\u201310](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit8) decision tree based rate rules,[11,12](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit11) and machine learning (ML) models[13\u201319](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit13) have emerged as more popular choices for estimating kinetic parameters. Several ML models[15\u201317](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit15) have successfully predicted barrier heights and rate constants of diverse gas phase reactions only based on readily available 2D information ( _e.g._ SMILES strings) of reactants and products. However, such data-driven models for liquid/solution phase reactions have been lightly investigated with limited applicability,[20](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit20) and most approaches rely on the _ab initio_ methods with either implicit or explicit solvation models.[21,22](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit21)\n\nSolvents can have significant impacts on reaction rates and outcomes, and it is crucial to accurately predict these kinetic solvent effects. Recent research efforts have been devoted to employing ML ( _e.g._ deep neural network) for free energy predictions of condensed phase reactions.[15,18,19,23\u201328](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit15) Many of these studies[18,19,23\u201325,28](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit18) combine the ML models with semi-empirical or lower-level QM/MM methods to obtain the energy predictions that match the accuracy of higher-level QM/MM methods. For example, G\u00f3mez-Flores _et al._ [19](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit19) used a ML approach to predict the energy difference between the density functional tight-binding model and other higher level QM methods for a thiol-disulfide exchange reaction in water. In a study by Pan _et al._,[18](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit18) a ML model was trained to reproduce _ab initio_ QM/MM potentials in free energy simulations for the aqueous Menshutkin reaction between ammonia and chloromethane. Farrar and Grayson[28](https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337/#cit28) employed ML models to predict DFT-quality activation barriers for various nitro-Michael ad...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10866337"
    }
  ]
}