## Current Status
- Best CV score: 0.008298 from exp_030 (GP 0.15 + MLP 0.55 + LGBM 0.3)
- Best LB score: 0.0877 from exp_030
- CV-LB gap: LB = 4.31*CV + 0.0525 (R²=0.95)
- **CRITICAL**: Intercept (0.0525) > Target (0.0347) → Required CV is NEGATIVE (-0.004130)
- This means the target is UNREACHABLE via CV improvement alone
- We need to CHANGE the CV-LB relationship
- Remaining submissions: 5
- Loop: 50 (last 19 experiments all worse than exp_030)

## Response to Evaluator

**Technical verdict**: TRUSTWORTHY - exp_049 was well-executed.

**Evaluator's top priority**: Focus on approaches that could change the CV-LB relationship.

**My response**: I AGREE completely. The evaluator correctly identified that:
1. All three approaches in exp_049 (Manual OOD, Mixall-style, Ensemble Disagreement) performed WORSE
2. Simpler features (Spange only) hurt performance - DRFP is important
3. The CV-LB relationship has intercept > target, so we CANNOT reach target by improving CV alone
4. We need fundamentally different approaches

**Key concerns raised**:
1. Last 19 experiments all worse than exp_030 → We are in a local optimum
2. CV-LB intercept (0.0525) > target (0.0347) → Need to change the relationship
3. The GNN benchmark (MSE 0.0039) proves much better performance is possible

**How I'm addressing**:
- STOP trying to improve CV with the same model family
- Focus on approaches that could CHANGE the CV-LB relationship
- Try domain adaptation / selective augmentation techniques

## Data Understanding

Reference notebooks:
- `exploration/eda.ipynb` - Initial EDA
- `exploration/evolver_loop50_analysis.ipynb` - CV-LB relationship analysis
- `exploration/evolver_loop49_analysis.ipynb` - Solvent clustering and outlier analysis

Key patterns:
1. **CV-LB relationship**: LB = 4.31*CV + 0.0525 (R²=0.95)
   - Intercept (0.0525) > Target (0.0347)
   - Required CV to hit target: -0.004130 (IMPOSSIBLE)
   - We need to CHANGE this relationship, not improve CV

2. **Best residual experiments** (beat predicted LB):
   - exp_000: residual = -0.002213 (best!)
   - exp_024: residual = -0.000758
   - exp_030: residual = -0.000632

3. **High-error solvents**:
   - HFIP (Fluorinated): CV error = 0.038
   - TFE (Fluorinated): CV error = 0.015
   - Cyclohexane (Non-polar outlier): CV error = 0.026
   - These are chemically DIFFERENT from training data

## Recommended Approaches

### Priority 1: LISA (Selective Augmentation) - HIGHEST PRIORITY
**Hypothesis**: Mixup-based selective augmentation can learn domain-invariant predictors.

**Based on**: ICML 2022 paper "Improving Out-of-Distribution Robustness via Selective Augmentation"

**Implementation**:
```python
# Intra-label LISA: interpolate samples with same label but different solvents
def lisa_augmentation(X_train, Y_train, alpha=0.5):
    """
    For each sample, find another sample with:
    - Same label (similar yield values)
    - Different solvent (different domain)
    Then interpolate features and labels
    """
    augmented_X = []
    augmented_Y = []
    
    for i in range(len(X_train)):
        # Find samples with similar labels but different solvents
        same_label_mask = (Y_train - Y_train.iloc[i]).abs().sum(axis=1) < 0.1
        diff_solvent_mask = X_train['SOLVENT NAME'] != X_train.iloc[i]['SOLVENT NAME']
        candidates = X_train[same_label_mask & diff_solvent_mask]
        
        if len(candidates) > 0:
            j = np.random.choice(candidates.index)
            lam = np.random.beta(alpha, alpha)
            
            # Interpolate features
            x_mix = lam * X_train.iloc[i] + (1 - lam) * X_train.iloc[j]
            y_mix = lam * Y_train.iloc[i] + (1 - lam) * Y_train.iloc[j]
            
            augmented_X.append(x_mix)
            augmented_Y.append(y_mix)
    
    return augmented_X, augmented_Y
```

**Why this could work**:
- Encourages model to learn features that are invariant across solvents
- Cancels out solvent-specific spurious correlations
- Simple to implement and doesn't require architectural changes
- Proven effective on WILDS benchmarks

### Priority 2: Risk Extrapolation (REx)
**Hypothesis**: Penalizing variance of risks across solvents encourages invariant features.

**Implementation**:
```python
# REx: penalize variance of per-solvent losses
def rex_loss(predictions, targets, solvents, beta=1.0):
    """
    REx loss = mean(per_solvent_loss) + beta * var(per_solvent_loss)
    """
    unique_solvents = solvents.unique()
    per_solvent_losses = []
    
    for solvent in unique_solvents:
        mask = solvents == solvent
        solvent_loss = F.mse_loss(predictions[mask], targets[mask])
        per_solvent_losses.append(solvent_loss)
    
    mean_loss = torch.mean(torch.stack(per_solvent_losses))
    var_loss = torch.var(torch.stack(per_solvent_losses))
    
    return mean_loss + beta * var_loss
```

**Why this could work**:
- Explicitly penalizes models that perform differently across solvents
- Encourages learning features that work well for ALL solvents
- Could reduce the CV-LB gap by improving worst-case performance

### Priority 3: Simpler Model with Better Generalization
**Hypothesis**: Our best model (exp_030) may be overfitting to CV. A simpler model might generalize better.

**Observation**: exp_000 has the BEST residual (-0.002213) despite worse CV.

**Implementation**:
- Try the exp_000 architecture (simpler MLP) with current best features
- Use stronger regularization (higher dropout, weight decay)
- Use fewer features (only the most robust ones)

**Why this could work**:
- exp_000's residual suggests it generalizes better to LB
- Simpler models often have smaller CV-LB gaps
- The GNN benchmark may have used simpler features

### Priority 4: Ensemble with Diverse CV-LB Characteristics
**Hypothesis**: Combine models with different CV-LB relationships.

**Implementation**:
- Train multiple models with different characteristics
- Select models that have NEGATIVE residuals (beat predicted LB)
- Ensemble them with weights optimized for LB performance

**Why this could work**:
- Different models may have different CV-LB relationships
- Combining models with negative residuals could reduce the intercept
- This is different from our current ensemble (which optimizes for CV)

## What NOT to Try

1. **Further refinements to GP + MLP + LGBM** - Last 19 experiments show this is exhausted
2. **Manual OOD handling** - Tested in exp_049, made things worse
3. **Mixall-style ensemble** - Tested in exp_049, made things worse
4. **Ensemble disagreement** - Tested in exp_049, made things worse
5. **Simpler features (Spange only)** - DRFP is important, removing it hurts
6. **GNN (AttentiveFP)** - Tried in exp_040, failed badly (needs more work but risky)
7. **ChemBERTa** - Tried in exp_041, 25.5% worse

## Validation Notes

- Use Leave-One-Out (24 folds) for single solvents - matches competition template
- Use Leave-One-Ramp-Out (13 folds) for mixtures - matches competition template
- CV-LB relationship: LB ≈ 4.31*CV + 0.0525
- **Key insight**: To reach target (0.0347), we need to CHANGE the relationship

## Submission Strategy (5 remaining)

Given the CV-LB gap analysis, I recommend:

1. **DO NOT submit** models that only improve CV
   - Even CV = 0 would give LB = 0.0525 > target
   - We need models that change the CV-LB relationship

2. **SUBMIT** models that show:
   - Different CV-LB characteristics (lower intercept)
   - Better worst-case performance on high-error solvents
   - Fundamentally different approach (LISA, REx)

3. **Save submissions** for:
   - Testing if LISA/REx changes the relationship
   - Final ensemble based on LB feedback

## Critical Reminder

**THE TARGET IS REACHABLE.** The GNN benchmark achieved 0.0039. The path forward is:

1. **STOP** trying to improve CV with the same model family
2. **START** trying approaches that could change the CV-LB relationship
3. **FOCUS** on domain adaptation / selective augmentation techniques

The last 19 experiments have all been worse than exp_030. This is a clear signal that we need a FUNDAMENTALLY DIFFERENT approach, not incremental improvements.

## Experiment 050 Recommendation

**Name**: LISA Selective Augmentation + REx Loss

**Implementation**:
1. Use LISA to augment training data (intra-label interpolation)
2. Use REx loss to penalize variance across solvents
3. Use the exp_030 architecture (GP + MLP + LGBM)
4. Compare CV AND per-solvent error distribution

**Success criteria**:
- Not just better CV, but better worst-case performance
- Lower variance of per-solvent errors
- If CV is similar but per-solvent variance is lower, SUBMIT to test if this changes CV-LB relationship