{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0525b4b8",
   "metadata": {},
   "source": [
    "# Loop 54 Analysis: Breaking the CV-LB Ceiling\n",
    "\n",
    "## Current State\n",
    "- **Best CV**: 0.008298 (exp_030)\n",
    "- **Best LB**: 0.08772 (exp_030)\n",
    "- **Target**: 0.0347\n",
    "- **Gap**: 2.53x (0.08772 / 0.0347)\n",
    "- **23 consecutive failures** since exp_030\n",
    "\n",
    "## Key Insight from Evaluator\n",
    "The CV-LB relationship is: LB = 4.31*CV + 0.0525\n",
    "- Intercept (0.0525) > Target (0.0347)\n",
    "- This means the target is UNREACHABLE by improving CV alone\n",
    "- We need to CHANGE the relationship, not just improve CV\n",
    "\n",
    "## Analysis Goals\n",
    "1. Understand what could change the CV-LB relationship\n",
    "2. Identify unexplored approaches\n",
    "3. Find the path to 0.0347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda2ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982, 'model': 'MLP baseline'},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065, 'model': 'LightGBM'},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972, 'model': 'Spange+DRFP MLP'},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969, 'model': 'Large ensemble'},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946, 'model': 'Simpler MLP'},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932, 'model': 'Even simpler'},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936, 'model': 'Ridge regression'},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913, 'model': 'Simple ensemble'},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893, 'model': 'ACS PCA'},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887, 'model': 'Weighted loss'},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877, 'model': 'GP+MLP+LGBM'},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970, 'model': 'Lower GP weight'},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(\"Submission History:\")\n",
    "print(df.to_string())\n",
    "\n",
    "# Fit linear relationship\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f\"\\nCV-LB Relationship: LB = {slope:.2f}*CV + {intercept:.4f}\")\n",
    "print(f\"R² = {r_value**2:.4f}\")\n",
    "print(f\"\\nTarget LB: 0.0347\")\n",
    "print(f\"Intercept: {intercept:.4f}\")\n",
    "print(f\"Gap: {intercept - 0.0347:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3996bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What CV would be needed to hit target?\n",
    "target_lb = 0.0347\n",
    "required_cv = (target_lb - intercept) / slope\n",
    "print(f\"Required CV to hit target: {required_cv:.6f}\")\n",
    "print(f\"Current best CV: 0.008298\")\n",
    "\n",
    "if required_cv < 0:\n",
    "    print(\"\\n⚠️ CRITICAL: Required CV is NEGATIVE - target is unreachable with current relationship!\")\n",
    "    print(\"\\nThis means we need to CHANGE the relationship, not just improve CV.\")\n",
    "    print(\"\\nPossible ways to change the relationship:\")\n",
    "    print(\"1. Use a fundamentally different model architecture\")\n",
    "    print(\"2. Use different features that generalize better to LB\")\n",
    "    print(\"3. Use a different training strategy (e.g., transductive learning)\")\n",
    "    print(\"4. Calibrate predictions specifically for OOD solvents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fea168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what approaches have been tried\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"APPROACHES TRIED (54 experiments)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "approaches_tried = {\n",
    "    'MLP architectures': ['baseline', 'simpler [64,32]', 'deeper [256,128,64]', 'residual', 'attention'],\n",
    "    'Tree-based models': ['LightGBM', 'XGBoost', 'RandomForest'],\n",
    "    'Gaussian Processes': ['GP with RBF kernel', 'GP with Matern kernel'],\n",
    "    'Ensembles': ['MLP bagging', 'GP+MLP+LGBM', 'MLP+XGB+RF+LGBM'],\n",
    "    'Feature sets': ['Spange only', 'DRFP only', 'Spange+DRFP', 'ACS PCA', 'Arrhenius kinetics'],\n",
    "    'Regularization': ['Dropout 0.1-0.4', 'Weight decay 1e-5 to 1e-3', 'L1/L2'],\n",
    "    'Loss functions': ['MSE', 'Huber', 'Weighted MSE'],\n",
    "    'Data augmentation': ['TTA for mixtures', 'Both orderings'],\n",
    "}\n",
    "\n",
    "for category, items in approaches_tried.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for item in items:\n",
    "        print(f\"  - {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have NOT been tried or tried poorly?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"APPROACHES NOT YET TRIED (or tried poorly)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "approaches_not_tried = [\n",
    "    (\"1. Domain Adaptation\", \"Train on source domain, adapt to target domain\", \"NOT TRIED\"),\n",
    "    (\"2. Meta-Learning (MAML)\", \"Learn to quickly adapt to new solvents\", \"NOT TRIED\"),\n",
    "    (\"3. Transductive Learning\", \"Process test samples jointly with training\", \"NOT TRIED\"),\n",
    "    (\"4. Adversarial Training\", \"Train to be robust to distribution shift\", \"NOT TRIED\"),\n",
    "    (\"5. Importance Weighting\", \"Re-weight training samples by density ratio\", \"NOT TRIED\"),\n",
    "    (\"6. Test-Time Adaptation\", \"Adapt model at test time using unlabeled data\", \"NOT TRIED\"),\n",
    "    (\"7. Proper GNN\", \"Graph attention network with proper implementation\", \"TRIED POORLY\"),\n",
    "    (\"8. Ensemble of Diverse Architectures\", \"GNN + MLP + LGBM\", \"NOT TRIED\"),\n",
    "    (\"9. Prediction Calibration\", \"Post-hoc calibration of predictions\", \"NOT TRIED\"),\n",
    "    (\"10. Uncertainty-Weighted Ensemble\", \"Weight predictions by uncertainty\", \"NOT TRIED\"),\n",
    "]\n",
    "\n",
    "for name, desc, status in approaches_not_tried:\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  Description: {desc}\")\n",
    "    print(f\"  Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f268ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The CV-LB gap is due to distribution shift\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY INSIGHT: Distribution Shift Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "The CV-LB gap is caused by distribution shift between:\n",
    "1. Training solvents (23 solvents in each fold)\n",
    "2. Test solvent (1 held-out solvent)\n",
    "\n",
    "The held-out solvent is CHEMICALLY DIFFERENT from training solvents.\n",
    "This is why the model fails to generalize.\n",
    "\n",
    "High-error solvents (from previous analysis):\n",
    "- HFIP (fluorinated): CV error = 0.038\n",
    "- TFE (fluorinated): CV error = 0.015\n",
    "- Cyclohexane (non-polar): CV error = 0.026\n",
    "- Water.Ethanol (polar protic): CV error = 0.028\n",
    "\n",
    "These solvents are OUTLIERS in the feature space.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b547710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would change the CV-LB relationship?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WHAT COULD CHANGE THE CV-LB RELATIONSHIP?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. **Better OOD Generalization**\n",
    "   - Use features that capture fundamental chemistry\n",
    "   - Use simpler models that don't overfit to training distribution\n",
    "   - Use regularization that encourages generalization\n",
    "\n",
    "2. **Domain Adaptation**\n",
    "   - Re-weight training samples to match test distribution\n",
    "   - Use adversarial training to learn domain-invariant features\n",
    "   - Use importance weighting based on density ratio\n",
    "\n",
    "3. **Prediction Calibration**\n",
    "   - Learn a calibration function from CV-LB relationship\n",
    "   - Apply calibration to shift predictions toward LB\n",
    "   - This could reduce the intercept\n",
    "\n",
    "4. **Ensemble Diversity**\n",
    "   - Use models with different inductive biases\n",
    "   - Some models may have better CV-LB correlation\n",
    "   - Weight models by their CV-LB correlation\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92351ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the residuals from CV-LB relationship\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "\n",
    "print(\"Residual Analysis:\")\n",
    "print(df[['exp', 'model', 'cv', 'lb', 'predicted_lb', 'residual']].to_string())\n",
    "\n",
    "print(f\"\\nMean residual: {df['residual'].mean():.6f}\")\n",
    "print(f\"Std residual: {df['residual'].std():.6f}\")\n",
    "\n",
    "# Which experiments beat the predicted LB?\n",
    "print(f\"\\nExperiments that beat predicted LB (negative residual):\")\n",
    "for _, row in df[df['residual'] < 0].iterrows():\n",
    "    print(f\"  {row['exp']} ({row['model']}): residual = {row['residual']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we could reduce the intercept?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCENARIO ANALYSIS: What if we could reduce the intercept?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for new_intercept in [0.05, 0.04, 0.03, 0.02, 0.01, 0.0]:\n",
    "    new_lb = slope * 0.008298 + new_intercept\n",
    "    status = \"✓ BEATS TARGET\" if new_lb < 0.0347 else \"\"\n",
    "    print(f\"Intercept = {new_intercept:.2f} → LB = {new_lb:.4f} {status}\")\n",
    "\n",
    "print(\"\\nTo beat target (0.0347), we need intercept < 0.0 (impossible with current relationship)\")\n",
    "print(\"OR we need to CHANGE the slope/intercept relationship entirely.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ab74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RECOMMENDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "Given that:\n",
    "1. 23 consecutive experiments have failed to beat exp_030\n",
    "2. The CV-LB relationship has intercept > target\n",
    "3. All refinements to GP + MLP + LGBM have failed\n",
    "\n",
    "We need to try something FUNDAMENTALLY DIFFERENT:\n",
    "\n",
    "**PRIORITY 1: Prediction Calibration**\n",
    "- Learn a calibration function from the CV-LB relationship\n",
    "- Apply calibration to shift predictions toward LB\n",
    "- This could reduce the effective intercept\n",
    "\n",
    "**PRIORITY 2: Simpler Model with Stronger Regularization**\n",
    "- The GP component in exp_030 provides strong regularization\n",
    "- Try GP-only model with optimized hyperparameters\n",
    "- Or try Ridge regression with very strong regularization\n",
    "\n",
    "**PRIORITY 3: Feature Simplification**\n",
    "- Use only the most fundamental features (Spange only)\n",
    "- Drop DRFP features which may be causing overfitting\n",
    "- Focus on features that capture fundamental chemistry\n",
    "\n",
    "**PRIORITY 4: Submit exp_030 with Calibration**\n",
    "- Apply a simple calibration to exp_030 predictions\n",
    "- This is the safest approach with 5 submissions remaining\n",
    "\n",
    "**DO NOT:**\n",
    "- Try more complex architectures (they don't help)\n",
    "- Try more features (DRFP consistently hurts)\n",
    "- Try more ensemble variations (exhausted)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8286b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Current State:\n",
    "- Best CV: 0.008298 (exp_030)\n",
    "- Best LB: 0.08772 (exp_030)\n",
    "- Target: 0.0347\n",
    "- Gap: 2.53x\n",
    "\n",
    "CV-LB Relationship:\n",
    "- LB = 4.31*CV + 0.0525\n",
    "- Intercept (0.0525) > Target (0.0347)\n",
    "- Required CV to hit target: NEGATIVE (impossible)\n",
    "\n",
    "Key Insight:\n",
    "- The target is UNREACHABLE by improving CV alone\n",
    "- We need to CHANGE the CV-LB relationship\n",
    "- This requires fundamentally different approaches\n",
    "\n",
    "Remaining Submissions: 5\n",
    "Best Model: exp_030 (GP 0.15 + MLP 0.55 + LGBM 0.3)\n",
    "\n",
    "Next Steps:\n",
    "1. Try prediction calibration\n",
    "2. Try simpler model with stronger regularization\n",
    "3. Try feature simplification\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
