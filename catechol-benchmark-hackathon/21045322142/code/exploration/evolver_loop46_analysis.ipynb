{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93ebe4c9",
   "metadata": {},
   "source": [
    "# Loop 46 Analysis: Post Mean Reversion - What's Next?\n",
    "\n",
    "## Key Findings from Experiment 045:\n",
    "- Mean reversion HURTS CV performance (alpha=1.0 is best)\n",
    "- The predictions are NOT systematically biased away from the mean\n",
    "- The CV-LB intercept problem is NOT due to prediction bias\n",
    "\n",
    "## Evaluator's Key Insight:\n",
    "The evaluator discovered that public kernels use **GroupKFold (5 splits)** instead of **Leave-One-Out (24 folds)**!\n",
    "\n",
    "This could explain the entire CV-LB gap. Let me investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load submission history and analyze CV-LB relationship\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submission history:')\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f'CV-LB Relationship: LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'RÂ² = {r_value**2:.4f}')\n",
    "print(f'Intercept = {intercept:.4f}')\n",
    "print(f'Target = 0.0347')\n",
    "print()\n",
    "print(f'CRITICAL: Intercept ({intercept:.4f}) > Target (0.0347)')\n",
    "print(f'This means even CV=0 would give LB={intercept:.4f}, which is ABOVE target!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what CV would be needed to hit target\n",
    "target = 0.0347\n",
    "required_cv = (target - intercept) / slope\n",
    "print(f'Required CV to hit target: {required_cv:.6f}')\n",
    "print(f'Current best CV: 0.008298')\n",
    "print()\n",
    "if required_cv < 0:\n",
    "    print('IMPOSSIBLE: Required CV is negative!')\n",
    "    print('The current CV-LB relationship CANNOT reach the target.')\n",
    "    print()\n",
    "    print('We need to CHANGE the relationship, not just improve CV.')\n",
    "else:\n",
    "    print(f'Gap: {(0.008298 - required_cv) / 0.008298 * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db074764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the CV-LB gap for each submission\n",
    "print('CV-LB Gap Analysis:')\n",
    "print('-' * 60)\n",
    "for _, row in df.iterrows():\n",
    "    gap = row['lb'] - row['cv']\n",
    "    ratio = row['lb'] / row['cv']\n",
    "    print(f\"{row['exp']}: CV={row['cv']:.4f}, LB={row['lb']:.4f}, Gap={gap:.4f}, Ratio={ratio:.1f}x\")\n",
    "\n",
    "print()\n",
    "print('Average ratio:', df['lb'].mean() / df['cv'].mean())\n",
    "print('This means LB is ~10x worse than CV on average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f5e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The evaluator mentioned that public kernels use GroupKFold\n",
    "# Let me check if this could explain the gap\n",
    "\n",
    "print('=== EVALUATOR\\'S KEY INSIGHT ===')\n",
    "print()\n",
    "print('Public kernels use GroupKFold (5 splits) instead of Leave-One-Out (24 folds)!')\n",
    "print()\n",
    "print('Why this matters:')\n",
    "print('1. Leave-one-out CV (24 folds) is EXTREMELY pessimistic')\n",
    "print('   - Each fold tests on a completely unseen solvent')\n",
    "print('   - This is the hardest possible generalization task')\n",
    "print()\n",
    "print('2. GroupKFold (5 splits) is LESS pessimistic')\n",
    "print('   - Each fold tests on ~5 solvents at once')\n",
    "print('   - Some solvents in test set may be similar to training solvents')\n",
    "print()\n",
    "print('3. The LB evaluation may use a different scheme than our local CV')\n",
    "print('   - If LB uses something like GroupKFold, our CV is ~4x more pessimistic')\n",
    "print('   - This could explain the entire CV-LB gap!')\n",
    "print()\n",
    "print('4. The model that\\'s best under GroupKFold may be DIFFERENT from')\n",
    "print('   the model that\\'s best under leave-one-out')\n",
    "print('   - We may be optimizing for the wrong metric!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and test GroupKFold vs Leave-One-Out\n",
    "import sys\n",
    "sys.path.insert(0, '/home/code')\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "df_single = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "X_single = df_single[['Residence Time', 'Temperature', 'SOLVENT NAME']]\n",
    "Y_single = df_single[['SM', 'Product 2', 'Product 3']]\n",
    "\n",
    "print(f'Single solvent data: {len(df_single)} samples')\n",
    "print(f'Number of unique solvents: {X_single[\"SOLVENT NAME\"].nunique()}')\n",
    "print()\n",
    "print('Solvents:', sorted(X_single['SOLVENT NAME'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Leave-One-Out vs GroupKFold\n",
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "\n",
    "groups = X_single['SOLVENT NAME']\n",
    "\n",
    "# Leave-One-Out (current approach)\n",
    "logo = LeaveOneGroupOut()\n",
    "n_loo_folds = logo.get_n_splits(X_single, Y_single, groups)\n",
    "print(f'Leave-One-Out: {n_loo_folds} folds')\n",
    "print('  - Each fold tests on 1 solvent (~27 samples)')\n",
    "print('  - Training on 23 solvents (~629 samples)')\n",
    "print()\n",
    "\n",
    "# GroupKFold (5 splits)\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "n_gkf_folds = gkf.get_n_splits(X_single, Y_single, groups)\n",
    "print(f'GroupKFold (5 splits): {n_gkf_folds} folds')\n",
    "print('  - Each fold tests on ~5 solvents (~131 samples)')\n",
    "print('  - Training on ~19 solvents (~525 samples)')\n",
    "print()\n",
    "\n",
    "# GroupKFold (3 splits)\n",
    "gkf3 = GroupKFold(n_splits=3)\n",
    "n_gkf3_folds = gkf3.get_n_splits(X_single, Y_single, groups)\n",
    "print(f'GroupKFold (3 splits): {n_gkf3_folds} folds')\n",
    "print('  - Each fold tests on ~8 solvents (~219 samples)')\n",
    "print('  - Training on ~16 solvents (~437 samples)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b260c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a simple model under both CV schemes\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load Spange descriptors\n",
    "spange_df = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "SPANGE_COLS = [c for c in spange_df.columns if c != 'solvent smiles']\n",
    "\n",
    "def get_simple_features(X):\n",
    "    features = []\n",
    "    for _, row in X.iterrows():\n",
    "        time_m = row['Residence Time']\n",
    "        temp_c = row['Temperature']\n",
    "        temp_k = temp_c + 273.15\n",
    "        \n",
    "        kinetics = np.array([time_m, temp_c, 1.0/temp_k, np.log(time_m+1), time_m/temp_k])\n",
    "        \n",
    "        solvent = row['SOLVENT NAME']\n",
    "        spange = spange_df.loc[solvent, SPANGE_COLS].values if solvent in spange_df.index else np.zeros(len(SPANGE_COLS))\n",
    "        \n",
    "        features.append(np.concatenate([kinetics, spange]))\n",
    "    return np.array(features)\n",
    "\n",
    "X_feat = get_simple_features(X_single)\n",
    "y = Y_single.values\n",
    "\n",
    "print(f'Features shape: {X_feat.shape}')\n",
    "print(f'Targets shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4937510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Leave-One-Out CV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_feat)\n",
    "\n",
    "# Leave-One-Out\n",
    "logo = LeaveOneGroupOut()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "loo_preds = cross_val_predict(ridge, X_scaled, y, cv=logo, groups=groups)\n",
    "loo_mse = np.mean((y - loo_preds)**2)\n",
    "print(f'Leave-One-Out CV MSE: {loo_mse:.6f}')\n",
    "\n",
    "# GroupKFold (5 splits)\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "gkf_preds = cross_val_predict(ridge, X_scaled, y, cv=gkf, groups=groups)\n",
    "gkf_mse = np.mean((y - gkf_preds)**2)\n",
    "print(f'GroupKFold (5) CV MSE: {gkf_mse:.6f}')\n",
    "\n",
    "# GroupKFold (3 splits)\n",
    "gkf3 = GroupKFold(n_splits=3)\n",
    "gkf3_preds = cross_val_predict(ridge, X_scaled, y, cv=gkf3, groups=groups)\n",
    "gkf3_mse = np.mean((y - gkf3_preds)**2)\n",
    "print(f'GroupKFold (3) CV MSE: {gkf3_mse:.6f}')\n",
    "\n",
    "print()\n",
    "print(f'Ratio LOO/GKF5: {loo_mse/gkf_mse:.2f}x')\n",
    "print(f'Ratio LOO/GKF3: {loo_mse/gkf3_mse:.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The CV scheme matters!\n",
    "print('=== KEY INSIGHT ===')\n",
    "print()\n",
    "print(f'Leave-One-Out MSE: {loo_mse:.6f}')\n",
    "print(f'GroupKFold (5) MSE: {gkf_mse:.6f}')\n",
    "print(f'GroupKFold (3) MSE: {gkf3_mse:.6f}')\n",
    "print()\n",
    "print(f'LOO is {loo_mse/gkf_mse:.1f}x more pessimistic than GKF5')\n",
    "print(f'LOO is {loo_mse/gkf3_mse:.1f}x more pessimistic than GKF3')\n",
    "print()\n",
    "print('This suggests:')\n",
    "print('1. The LB evaluation may use a scheme closer to GroupKFold')\n",
    "print('2. Our LOO CV is ~2-3x more pessimistic than the LB evaluation')\n",
    "print('3. The model that\\'s best under LOO may not be best under GKF')\n",
    "print()\n",
    "print('HOWEVER: The competition rules require LOO CV!')\n",
    "print('We cannot change the CV scheme in the submission.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('=== APPROACHES NOT YET TRIED ===')\n",
    "print()\n",
    "print('1. DOMAIN ADAPTATION / TRANSFER LEARNING')\n",
    "print('   - Pre-train on mixture data, fine-tune on single solvents')\n",
    "print('   - Use mixture data as auxiliary task')\n",
    "print()\n",
    "print('2. META-LEARNING')\n",
    "print('   - MAML or similar for few-shot adaptation to new solvents')\n",
    "print('   - Learn to learn from limited solvent data')\n",
    "print()\n",
    "print('3. ENSEMBLE OF FUNDAMENTALLY DIFFERENT MODELS')\n",
    "print('   - Current ensemble: GP + MLP + LGBM (all similar features)')\n",
    "print('   - Try: Physics-based + Data-driven + Similarity-based')\n",
    "print()\n",
    "print('4. SOLVENT SIMILARITY WEIGHTING')\n",
    "print('   - Weight training samples by similarity to test solvent')\n",
    "print('   - Use Spange descriptors to compute similarity')\n",
    "print('   - exp_037 tried this but may not have been optimal')\n",
    "print()\n",
    "print('5. UNCERTAINTY-WEIGHTED PREDICTIONS')\n",
    "print('   - Use GP uncertainty to weight predictions')\n",
    "print('   - Blend toward mean when uncertainty is high')\n",
    "print()\n",
    "print('6. ADVERSARIAL VALIDATION')\n",
    "print('   - Identify which solvents are most different from test')\n",
    "print('   - Focus on improving predictions for those solvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which solvents have highest error\n",
    "print('=== PER-SOLVENT ERROR ANALYSIS ===')\n",
    "print()\n",
    "\n",
    "solvent_errors = {}\n",
    "for solvent in X_single['SOLVENT NAME'].unique():\n",
    "    mask = X_single['SOLVENT NAME'] == solvent\n",
    "    solvent_y = y[mask]\n",
    "    solvent_pred = loo_preds[mask]\n",
    "    solvent_mse = np.mean((solvent_y - solvent_pred)**2)\n",
    "    solvent_errors[solvent] = solvent_mse\n",
    "\n",
    "# Sort by error\n",
    "sorted_errors = sorted(solvent_errors.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print('Top 10 hardest solvents (highest MSE):')\n",
    "for solvent, mse in sorted_errors[:10]:\n",
    "    print(f'  {solvent}: MSE = {mse:.6f}')\n",
    "\n",
    "print()\n",
    "print('Top 5 easiest solvents (lowest MSE):')\n",
    "for solvent, mse in sorted_errors[-5:]:\n",
    "    print(f'  {solvent}: MSE = {mse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe68bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate contribution to total error\n",
    "print('=== ERROR CONTRIBUTION ANALYSIS ===')\n",
    "print()\n",
    "\n",
    "total_mse = loo_mse\n",
    "print(f'Total LOO MSE: {total_mse:.6f}')\n",
    "print()\n",
    "\n",
    "print('Error contribution by solvent:')\n",
    "cumulative = 0\n",
    "for solvent, mse in sorted_errors[:10]:\n",
    "    n_samples = (X_single['SOLVENT NAME'] == solvent).sum()\n",
    "    contribution = mse * n_samples / len(X_single)\n",
    "    cumulative += contribution\n",
    "    pct = contribution / total_mse * 100\n",
    "    cum_pct = cumulative / total_mse * 100\n",
    "    print(f'  {solvent}: {pct:.1f}% (cumulative: {cum_pct:.1f}%)')\n",
    "\n",
    "print()\n",
    "print(f'Top 10 solvents account for {cum_pct:.1f}% of total error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print('=== SUMMARY AND RECOMMENDATIONS ===')\n",
    "print()\n",
    "print('KEY FINDINGS:')\n",
    "print('1. Mean reversion HURTS CV (exp_045) - predictions are NOT biased away from mean')\n",
    "print('2. CV-LB intercept (0.0528) > Target (0.0347) - current approach CANNOT reach target')\n",
    "print('3. LOO CV is ~2-3x more pessimistic than GroupKFold')\n",
    "print('4. Top 10 hardest solvents account for most of the error')\n",
    "print()\n",
    "print('CRITICAL INSIGHT:')\n",
    "print('The competition uses LOO CV for evaluation, but the LB may use a different scheme.')\n",
    "print('We cannot change the CV scheme, but we can optimize for better generalization.')\n",
    "print()\n",
    "print('RECOMMENDED APPROACHES:')\n",
    "print('1. UNCERTAINTY-WEIGHTED ENSEMBLE')\n",
    "print('   - Use GP uncertainty to weight predictions')\n",
    "print('   - When uncertainty is high, blend toward a more conservative prediction')\n",
    "print('   - This is different from mean reversion (which failed)')\n",
    "print()\n",
    "print('2. SOLVENT-SPECIFIC ADAPTATION')\n",
    "print('   - Identify which solvents are hardest to predict')\n",
    "print('   - Use different models or features for different solvent types')\n",
    "print()\n",
    "print('3. SIMPLER MODEL WITH BETTER GENERALIZATION')\n",
    "print('   - exp_007 (simpler model) achieved LB 0.0932 with CV 0.0093')\n",
    "print('   - exp_030 (complex ensemble) achieved LB 0.0877 with CV 0.0083')\n",
    "print('   - The simpler model has better CV-LB ratio!')\n",
    "print()\n",
    "print('4. FOCUS ON HARDEST SOLVENTS')\n",
    "print('   - HFIP, DCM, etc. dominate the error')\n",
    "print('   - Improving predictions for these could have outsized impact')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
