{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89b29a0",
   "metadata": {},
   "source": [
    "# Loop 50 Analysis: Breaking Out of the Local Optimum\n",
    "\n",
    "## Key Observations\n",
    "\n",
    "1. **Last 19 experiments have ALL been worse than exp_030** (CV = 0.008298)\n",
    "2. **CV-LB relationship**: LB = 4.29*CV + 0.0528 (R²=0.95)\n",
    "3. **CRITICAL**: Intercept (0.0528) > Target (0.0347) → Target UNREACHABLE via CV improvement alone\n",
    "4. **Best LB**: 0.0877 from exp_030\n",
    "5. **Target**: 0.0347\n",
    "\n",
    "## Analysis Goals\n",
    "\n",
    "1. Understand WHY the CV-LB relationship has such a high intercept\n",
    "2. Identify what could CHANGE this relationship\n",
    "3. Find approaches that haven't been tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c97d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(\"Submission History:\")\n",
    "print(df.to_string())\n",
    "\n",
    "# Fit linear relationship\n",
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f\"\\nCV-LB Relationship: LB = {slope:.2f}*CV + {intercept:.4f}\")\n",
    "print(f\"R² = {r_value**2:.4f}\")\n",
    "print(f\"\\nTarget LB: 0.0347\")\n",
    "print(f\"Intercept: {intercept:.4f}\")\n",
    "print(f\"Gap: {intercept - 0.0347:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What CV would be needed to hit target?\n",
    "target_lb = 0.0347\n",
    "required_cv = (target_lb - intercept) / slope\n",
    "print(f\"Required CV to hit target: {required_cv:.6f}\")\n",
    "print(f\"Current best CV: 0.008298\")\n",
    "print(f\"Gap: {0.008298 - required_cv:.6f}\")\n",
    "\n",
    "if required_cv < 0:\n",
    "    print(\"\\n⚠️ CRITICAL: Required CV is NEGATIVE - target is unreachable with current relationship!\")\n",
    "    print(\"\\nThis means we need to CHANGE the relationship, not just improve CV.\")\n",
    "    print(\"\\nPossible ways to change the relationship:\")\n",
    "    print(\"1. Use a fundamentally different model architecture\")\n",
    "    print(\"2. Use different features that generalize better to LB\")\n",
    "    print(\"3. Use a different training strategy (e.g., transductive learning)\")\n",
    "    print(\"4. Calibrate predictions specifically for OOD solvents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a076b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the residuals from the CV-LB relationship\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "\n",
    "print(\"Residual Analysis:\")\n",
    "print(df[['exp', 'cv', 'lb', 'predicted_lb', 'residual']].to_string())\n",
    "\n",
    "print(f\"\\nMean residual: {df['residual'].mean():.6f}\")\n",
    "print(f\"Std residual: {df['residual'].std():.6f}\")\n",
    "\n",
    "# Which experiments beat the predicted LB?\n",
    "df['beats_prediction'] = df['residual'] < 0\n",
    "print(f\"\\nExperiments that beat predicted LB:\")\n",
    "print(df[df['beats_prediction']][['exp', 'cv', 'lb', 'predicted_lb', 'residual']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063392d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: exp_030 has the best LB but not the best residual\n",
    "# Let's see which experiments have the best residuals\n",
    "df_sorted = df.sort_values('residual')\n",
    "print(\"Experiments sorted by residual (best first):\")\n",
    "print(df_sorted[['exp', 'cv', 'lb', 'residual']].to_string())\n",
    "\n",
    "print(\"\\nKey insight: The experiments with best residuals are:\")\n",
    "for _, row in df_sorted.head(3).iterrows():\n",
    "    print(f\"  {row['exp']}: residual = {row['residual']:.6f}, LB = {row['lb']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would happen if we could reduce the intercept?\n",
    "print(\"Scenario Analysis: What if we could reduce the intercept?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for new_intercept in [0.04, 0.03, 0.02, 0.01, 0.0]:\n",
    "    new_lb = slope * 0.008298 + new_intercept\n",
    "    print(f\"Intercept = {new_intercept:.2f} → LB = {new_lb:.4f} (target: 0.0347)\")\n",
    "    if new_lb < 0.0347:\n",
    "        print(f\"  ✓ Would beat target!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dae490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print(\"\\nApproaches NOT yet tried (or tried poorly):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "approaches = [\n",
    "    (\"1. Domain Adaptation\", \"Train on source domain, adapt to target domain\", \"NOT TRIED\"),\n",
    "    (\"2. Meta-Learning (MAML)\", \"Learn to quickly adapt to new solvents\", \"NOT TRIED\"),\n",
    "    (\"3. Transductive Learning\", \"Process test samples jointly with training\", \"NOT TRIED\"),\n",
    "    (\"4. Adversarial Training\", \"Train to be robust to distribution shift\", \"NOT TRIED\"),\n",
    "    (\"5. Importance Weighting\", \"Re-weight training samples by density ratio\", \"NOT TRIED\"),\n",
    "    (\"6. Test-Time Adaptation\", \"Adapt model at test time using unlabeled data\", \"NOT TRIED\"),\n",
    "    (\"7. Proper GNN\", \"Graph attention network with proper implementation\", \"TRIED POORLY (exp_040)\"),\n",
    "    (\"8. Ensemble of Diverse Architectures\", \"GNN + MLP + LGBM\", \"NOT TRIED\"),\n",
    "]\n",
    "\n",
    "for name, desc, status in approaches:\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  Description: {desc}\")\n",
    "    print(f\"  Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key insight from the mixall kernel\n",
    "print(\"\\nKey Insight from Mixall Kernel:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"The mixall kernel OVERWRITES the utility functions to use GroupKFold (5 splits)\n",
    "instead of Leave-One-Out (24 folds). This means:\n",
    "\n",
    "1. Their local CV scores are NOT comparable to ours\n",
    "2. The LB evaluation uses the OFFICIAL scheme (Leave-One-Out)\n",
    "3. Their success on LB is due to their MODEL, not their validation scheme\n",
    "\n",
    "What the mixall kernel uses:\n",
    "- MLP + XGBoost + RandomForest + LightGBM ensemble\n",
    "- Spange descriptors only (no DRFP)\n",
    "- Optuna hyperparameter tuning\n",
    "- Weights: [MLP, XGBoost, RF, LightGBM]\n",
    "\n",
    "Our exp_049 tried this approach but with DRFP features and got CV = 0.014196.\n",
    "The mixall kernel uses Spange ONLY.\n",
    "\n",
    "However, our experiments show that DRFP features HELP (exp_003 vs exp_000).\n",
    "So the mixall approach may not be optimal for us.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0dc683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the theoretical minimum LB we could achieve?\n",
    "print(\"\\nTheoretical Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# The GNN benchmark achieved MSE 0.0039\n",
    "print(\"GNN Benchmark: MSE = 0.0039\")\n",
    "print(\"Our best LB: MSE = 0.0877\")\n",
    "print(f\"Gap: {0.0877 / 0.0039:.1f}x worse\")\n",
    "\n",
    "print(\"\\nThis proves that MUCH better performance is possible.\")\n",
    "print(\"The question is: what's different about the GNN benchmark?\")\n",
    "print(\"\\nPossible differences:\")\n",
    "print(\"1. Different validation scheme (not Leave-One-Out)\")\n",
    "print(\"2. Different features (molecular graphs vs descriptors)\")\n",
    "print(\"3. Different architecture (attention mechanisms)\")\n",
    "print(\"4. Different training strategy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f82d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RECOMMENDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "Given that:\n",
    "1. Last 19 experiments have all been worse than exp_030\n",
    "2. The CV-LB relationship has intercept > target\n",
    "3. All refinements to GP + MLP + LGBM have failed\n",
    "\n",
    "We need to try something FUNDAMENTALLY DIFFERENT:\n",
    "\n",
    "1. **PRIORITY 1: Importance Weighting / Domain Adaptation**\n",
    "   - Re-weight training samples to match test distribution\n",
    "   - Use adversarial validation to identify drifting features\n",
    "   - This could CHANGE the CV-LB relationship\n",
    "\n",
    "2. **PRIORITY 2: Per-Solvent Model Selection**\n",
    "   - Train multiple models with different characteristics\n",
    "   - Select the best model for each solvent based on similarity\n",
    "   - This is different from our current ensemble approach\n",
    "\n",
    "3. **PRIORITY 3: Simpler is Better**\n",
    "   - Our best model (exp_030) uses GP + MLP + LGBM\n",
    "   - Maybe we're overfitting to CV\n",
    "   - Try a simpler model that generalizes better\n",
    "\n",
    "4. **PRIORITY 4: Submit exp_030 variations**\n",
    "   - We have 5 submissions left\n",
    "   - Use them to test hypotheses about the CV-LB gap\n",
    "   - Each submission should test a specific hypothesis\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we know about the high-error solvents\n",
    "print(\"\\nHigh-Error Solvents Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "high_error_solvents = {\n",
    "    'HFIP': {'cv_error': 0.038, 'cluster': 'Fluorinated'},\n",
    "    'TFE': {'cv_error': 0.015, 'cluster': 'Fluorinated'},\n",
    "    'Cyclohexane': {'cv_error': 0.026, 'cluster': 'Outlier (non-polar)'},\n",
    "    'Acetonitrile.Acetic Acid': {'cv_error': 0.022, 'cluster': 'Polar'},\n",
    "    'Water.Ethanol': {'cv_error': 0.028, 'cluster': 'Polar protic'},\n",
    "}\n",
    "\n",
    "print(\"High-error solvents and their characteristics:\")\n",
    "for solvent, info in high_error_solvents.items():\n",
    "    print(f\"  {solvent}: CV error = {info['cv_error']:.3f}, Cluster = {info['cluster']}\")\n",
    "\n",
    "print(\"\\nKey insight: The high-error solvents are CHEMICALLY DIFFERENT from the training data.\")\n",
    "print(\"This suggests that the model is not generalizing well to OOD solvents.\")\n",
    "print(\"\\nPossible solutions:\")\n",
    "print(\"1. Use simpler features that capture fundamental chemistry\")\n",
    "print(\"2. Use domain adaptation to bridge the gap\")\n",
    "print(\"3. Use ensemble disagreement to identify OOD samples\")\n",
    "print(\"4. Use transductive learning to adapt to new solvents\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
